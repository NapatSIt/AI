Abstract,Class
"Background Remote psychosocial intervention has been used by most health care organizations since the beginning of COVID-19 pandemic. However, the rapid introduction of this type of practice generates new methods of intervention that raise many questions, particularly about men who, in general, use face-to-face psychosocial intervention less than women. This documentary research aims to report on current knowledge on remote psychosocial intervention with men. Methods PICO technique was used to find relevant documents to achieve the objective of this research. In accord with our criteria, 62 documents were selected in several databases and search engines. The selected texts were subject to an analysis process consisting of two stages: the creation of reading sheets followed by a content analysis. Results The results underline the lack of scientific data on the men's experience when they initiate a request for help, the commitment process, and the effectiveness of the remote intervention. Several elements seem potentially promising, including patients' perceptions of having more power and freedom which could favorize engagement of men who have a traditional vision of masculinity. Conclusions It appears that gender-related variables are not commonly used when it comes to analyze the effects of distance psychosocial intervention. Other studies will be needed to have a holistic vision of the realities experienced by men towards the offer of remote psychosocial intervention.",TestAnalysis
"Purpose: The present study aims to contribute to the understanding of digital participation in heritage collections as a democratizing practice by identifying and challenging silent assumptions concerning how the insufficient influence of participants is conceived of as a problem. Design/methodology/approach: Three carefully selected scholarly texts incorporating problematizations of insufficient participatory agency were analyzed in detail using a method inspired by Carol Bacchi's approach “what's the problem represented to be?” (WPR), with special emphasis on analysis of ontological elements of the problematizations. Findings: Participation is problematized based on the assumption that participatory agency risks jeopardizing the protection of heritage and leads to parts of the public memory being forgotten. To challenge the idea that participatory agency is destructive, the present article argues for elaborating an understanding of what forgetting entails for heritage. Framing forgetting as a potentially both harmful and generative concept enables a separation of destructive forgetting (e.g. destruction of historical evidence) and constructive forgetting (re-contextualization). Research limitations/implications: The study is based on a limited number of texts, and problematizations are investigated in relation to a specific perspective on participatory agency. Practical implications: By understanding forgetting as a potentially beneficial activity for representation and heritage construction, the article provides a conceptual rationale for facilitating re-contextualization in the design of multi-layered information structures for heritage collections. Originality/value: There is little earlier research on the silent assumptions that affect how participation is understood and implemented. © 2022, Emerald Publishing Limited.",TestAnalysis
"Dancers need adequate cardiorespiratory fitness (CRF) levels in order to cope with the demands of dance classes and choreographies. Screening and monitoring of CRF is advised. The aim of this systematic review was to provide an overview of tests used to assess CRF in dancers and to examine the measurement properties of these tests. A literature search was performed in three online databases (PubMed, EMBASE, and SPORTDiscus) up until August 16, 2021. Study inclusion criteria were: 1. a CRF test was used; 2. participants were ballet, contemporary or modern, or jazz dancers; and 3. English full-text peer-reviewed article. General study information, participant information, CRF test used, and study outcome were extracted. If available, measurement property data were extracted (i.e., test reliability, validity, responsiveness, and interpretability). Of the 48 articles included in the review, most used a maximal treadmill test (n = 22) or the multistage Dance Specific Aerobic Fitness test (DAFT; n = 11). Out of the 48 included studies, only six examined the measurement properties of CRF tests: Aerobic Power Index (API), Ballet-specific Aerobic Fitness Test (B-DAFT), DAFT, High-Intensity Dance Performance Fitness Test (HIDT), Seifert Assessment of Functional Capactiy for Dancers (SAFD), and the 3-minute step test. Good test-retest reliability was found for the B-DAFT, DAFT, HIDT, and SAFD. Criterion validity was determined for the VO2peak of the API, the 3-MST, HIDT, and SAFD. For HRpeak, criterion validity was studied for the 3-MST, HIDT, and SAFD. While different CRF tests are being used in descriptive and experimental research within dance populations, the body of research supporting the measurement properties of such tests is very small. As many studies have methodological flaws (e.g., small participant numbers or no statistical analysis for validity or reliability), additional good quality research is required to re-examine and complement current measurement property results of the API, B-DAFT, DAFT, HIDT, SAFD, and 3-MST. © The Author(s) 2023.",TestAnalysis
"Against caricatures of the poet-philosopher Friedrich Schiller as an unoriginal popularizer of Kant, or a forerunner of totalitarianism, Frederick Beiser reinterprets him as an innovative, classical republican, broadening his analysis to include Schiller s poetry, plays, and essays not widely available in English translation, such as the remarkable essay, On Grace and Dignity. In that spirit, the present article argues that the latter text, misperceived by Anglophone critics as self-contradictory, is better understood as centering on gender and dance. In brief, grace is a virtuous power of beautiful gestures associated with women, while dignity is a power of sublime gestures associated with men, and the improvised combination thereof is a divinely androgynous power of gesture that I term stateliness, in a three-step choreography of aesthetic education. © 2023 Philosophy Documentation Center. All rights reserved.",TestAnalysis
"Purpose: Knowledge organization (KO) has been advancing at a progressively rapid pace under the influence of information technology. This study aims to explore the topics, characteristics, and trends of KO research in the 21st century. Design/methodology/approach: The full text of 4,360 KO-related articles published from 2000 to 2021 is collected. Through content analysis, this study identifies the topics, research methods, and application areas of each article, and the statistics are presented through a series of visualizations. Findings: In total, 13 main topics, 105 sub-topics, 16 research methods, and 57 application areas are identified. Notably, classification has always been an important topic, while linked data, automated techniques, and ontology have become popular topics recently. Significant changing features have also occurred. The versatile use of research methods has increased, with empirical research becoming the mainstream. Application areas show a trend of refinement from subject areas to specific scenarios. Construction techniques present a combination of automated techniques, crowdsourcing, and experts. Originality/value: KO has evolved and diversified due to technological developments. This study is the first to focus on the continuous changing features over an extended, 21-year period, as opposed to sampling a few years. It also provides clues and insights for researchers and practitioners interested in KO to understand how it has changed in the Semantic Web and big data context. © 2022, Emerald Publishing Limited.",TestAnalysis
"Communication-based interventions are popular among both governmental and nongovernmental organizations in many environmental domains. Yet, studies on the role of humor in social media communication to stimulate pro-environmental behavior have received limited attention. This study employs an experimental approach to assess the effect of using humor (in the form of satirical cartoons) either alongside, or in place of, factual pro-environmental messages in social media communication. It assesses the impact of humor in stimulating a reaction to a pro-environmental message on social media, a share, or a declared intent to change behavior. Our findings reveal that the inclusion of humor elicits a greater response than a factual message alone but that combining a humorous cartoon with a factual text creates the greatest difference. These findings are fairly consistent across six environmental domains and survive formal regression analysis which controlled for the impacts of co-determinants such as age, gender, education, social media engagement, and environmental preferences. © 2023 by the authors. Licensee MDPI, Basel, Switzerland.",TestAnalysis
"WhatsApp is one of the most popular mobile applications providing instant messaging and ease of access. It uses web-based systems to send and receive texts, calls, and videos and even offers video chat. However, during the current healthcare crisis, WhatsApp's role is comparatively more prominent and needs more consideration. In this context, we conducted this research to examine the factors motivating students to rely more on WhatsApp during the Covid-19 pandemic. Based on the Uses and Gratifications Approach, we adopted a cross-sectional design and gathered data from university students in Islamabad, Pakistan. Findings from n= 302 university-level students affirmed communication (p≥ .000), learning (p≥ .002), Teamwork (p≥ .041), and information sharing (p≥ .000) as the motivating factors behind increased WhatsApp usage (p≥ .011) during the healthcare crisis. Similarly, path analysis results also validated a strong correlation between the variables, further affirming the strength of the proposed conceptual framework. Thus, WhatsApp not only provided ease of communication during Covid-19 but also helped sustain educational activities. Here we recommend more studies to examine other different factors, especially personality factors that can affect one's WhatsApp usage. © 2023 Authors",TestAnalysis
"[Objective] This paper addresses the challenges facing the traditional static word vector embedding method, aiming to handle polysemy in Chinese texts effectively. It also excavates the contextual emotional features and internal semantic association structure. [Methods] In one channel, we integrated the sentiment elements related to the text into Word2Vec and FastText word vectors through rough data reasoning. We also used CNN to extract the local features of the text. In the other channel, we employed BERT for word embedding supplement and used BiLSTM to obtain the global features of the texts. Finally, we added the attention calculation module for the deep interaction of dual channel features. [Results] The experiment on three Chinese datasets achieved the highest accuracy of 92.43%, representing an improvement of 0.81% over the best value of the benchmark model. [Limitations] The selected datasets are only for modelling coarse-grained sentiment classification. We did not conduct experiments in the fine-grained domain. [Conclusions] The proposed model could effectively improve the performance of Chinese text sentiment classification. © 2023 The Author(s).",TestAnalysis
"As the mean age of first-time motherhood continues to rise throughout most of the western world, and increasingly also in emerging economies (OECD), normative notions of ""ideal"" first-time pregnancy age have shifted, and purely biological conceptualizations of fertility have been matched (and often challenged) by the emergence of the notion of ""social fertility"", which is often at a disconnect with biological fertility. The increasingly widespread availability of Assisted Reproductive Technologies (ARTs) has further extended the upper limits of childbearing age to the point that it has been possible for post-menopausal women to give birth. This has brought about a shift in the boundaries of ""normal"" - or even ""natural"" - motherhood, challenging the applicability of commonly accepted definitions of age-telated ""norms"" to women's life stages. ""While this process has been strongly contested, with charges of unnaturalness being levelled at older mothers, and especially at those who resort to ARTs, acceptance of older motherhood has become gradually more widespread. The linguistic strategies increasingly deployed in its representation have both reflected and contributed to this change. This chapter addresses discursive aspects of the construction of ""older mothers"" identities in contemporary discourses of age-related reproductive health and opportunities, focusing on medical discourse on the one hand, and self-representations of older motherhood on the other. While stigmatization of women who choose to postpone motherhood persists across multiple discursive domains, a shift is detectable in a growing body of texts which explicitly aims to neutralize social stigma by opting for categorizations which rely on more linguistically neutral terms. The chapter raises questions about the ideological implications of labelling strategies and about the impact of such labelling on discursive identity constructions, and offers insights into ""older"" first-time mothers' strategies of self-representation. © Peter Lang Group AG, International Academic Publishers, Bern 2023. All rights reserved.",TestAnalysis
"PURPOSE The purpose of this study is to analyze the type of and interest in home training video contents using the YouTube platform. METHODS Web crawling was performed using Python and a total of 3,937 sets ofvideo information (title, content, number of views, upload date) were obtained, 3,155 of which were finally selected for the study material. Overlapping and unrelated content were excluded. The data of text underwent 3 stages of preprocessing, the TF and TF-IDF of the keywords were calculated to identify the main keywords, and the LDA algorithm was applied in the topic modeling to successfully identify the types. In order to understand the level of interest by type, the number of views was subdivided into the percentage of the assigned type. RESULTS First, the types of home training videos were classified into bare whole body exercise for aerobic and muscular power strengthening, Pilates exercise for core and upper body strengthening, upper body exercise using tools, lower body line exercise, posture correction and upper body stretching exercise for pain relief, hip-up exercise, dance and tabata exercise for diet, diet and lower body correction stretching exercise for diet, and bare body exercise for core and lower body strengthening. Second, it was found that the proportion and interest were high in the contents of bare whole body exercise for aerobic and muscular power strengthening, dance and tabata exercise for diet, diet and lower body correction stretching exercise for diet. CONCLUSIONS The findings of this study may provide baseline data about the development of the active online home training videos in the market. © Korea Institute of Sport Science.",TestAnalysis
"The current study aims to shed light on the often-overlooked Islamic history and its lasting legacy, countering the dominant western discourse. It seeks to highlight the creativity, innovation, and technology that emerged from the rich classical Islamic heritage. The remarkable civilization forged by Muslim scholars and scientists across various fields of human knowledge was only made possible due to their profound belief and religious duty to promote creativity in human existence. Therefore, the current research aims to present, a philosophical study of innovation and creativity based on the Qur’ān and Sunnah supported by classical and modern Islamic literature. This study also deploys an analytical and descriptive approach to conduct an analysis of present literature on Islamic origin. Moreover, this article is a scholarly attempt to demystify the principles and values that regulate the philosophy of creativity and innovation in Islām. Additionally, it presents an Islamic view on Muslim’s existing moral issues of innovation, creativity, and technology by drawing upon the teachings and principles of Qur’ān and Sunnah. To achieve the proposed goals of this article, many Islāmic texts that urge innovation, creativity, and pay a special concern to the talented and skilled, were consulted. Hence, the research determined that Islamic heritage has a lot to contribute to the modern conceptualization of innovative and creative human life, which motivates Muslims’ to compete with others in this regard. Consequently, there is no such thing in Islam that prevents a Muslim from excelling in technology, which brings benefits and repels harm, while following the principles and teachings of the Qur’ān and Sunnah. © The Authors.",TestAnalysis
"Aim: Continuing medical education (CME) informs physicians on current research. The Concussion Awareness Training Tool (CATT) provides education on concussion diagnosis and treatment. The aims of this study were to explore physician CME practices and preferences, understand barriers and facilitators to implementing the CATT as CME, and provide recommendations. Materials & methods: Physicians in British Columbia, Canada participated in an online survey and telephone interview. Descriptive analysis of quantitative data, and text-based data analysis were undertaken to identify themes. Results: Barriers included lack of time and awareness of the resource. Facilitators were its ease of use, accessibility, conciseness and comprehensiveness. Conclusion: The perceptions of barriers and facilitators reported by physicians are important to understand and better promote the use of the CATT.  © 2023 The Authors.",TestAnalysis
"[Purpose/Significance] As an important entry scenario into the application layer of the meta universe, digital collections can not only solve the identity authentication and rights governance problems of digital resources in the meta universe, but also become an important interface connecting a library's physical entity and the virtual space of the meta universe. At present, digital collections have attracted much attention in digital art, digital publishing, digital cultural creation, museums and other fields, but relatively little attention has been paid in the field of libraries. As a new business form in the digital economy era, digital collectibles have typical characteristics such as uniqueness, traceability, immutability, and ease of ownership confirmation. They are the perfect display of digitalization, virtualization, and ownership confirmation of library collection resources (such as books, ancient books, map literature resources, and various digital resources) in the metaverse space of libraries. Therefore, based on a scientific definition of the connotation and characteristics of library digital collections, we attempt to explore their value chain of ""resources creativity casting dissemination service"". [Method/Process] This article analyzes the differences and connections between the metaverse and digital collectibles, explains the connotation and characteristics of library digital collectibles, and conducts in-depth analysis of the paradigm construction of library digital collectibles' value chain from the perspective of the metaverse from five dimensions: resource end, creative end, casting end, distribution end, and service end. The scene embedding of its value chain is divided into structural embedding. There are three modes of functional embedding and memory embedding and they are explained separately. [Result/Conclusion] Research suggests that digital collections mainly originate from NFT, which is a local concept of NFT's localization of digital assets in China. Digital collections mainly include works of art, ancient books and documents, precious cultural relics, digital cultural creation, digital publications, model surroundings, news collections, digital music, 3D models and other types. Their digital resources are mainly text, images, audio, video and 3D models. Their creation sources are mainly from physical entity resources and virtual digital resources. Library digital collections are generated based on the policy environment, technical conditions, resource structure, business characteristics, and cultural precipitation in which Chinese libraries are located. They strip away the attributes of NFT virtual finance and virtual currency, and have Chinese characteristics and library business characteristics. Blockchain (especially alliance chain) technology is used to digitize the casting, distribution, and circulation of library specific collection resources, literature resources, or digital resources, the only trusted digital rights certificate provided for collection and use. © 2023 Authors. All rights reserved.",TestAnalysis
"Background: The coronavirus disease 2019 (COVID-19) pandemic is potentially associated with numerous changes in the life of the general population; nevertheless, to date there is hardly any evidence on which effects are experienced as particularly severe and negative, how these effects and their evaluations changed over the course of the pandemic and which wishes for support arose in this context. Method: Longitudinal data from an online study with 10 assessments over the first 2 years of the pandemic (March 2020–April 2022) were analyzed in a mixed methods approach. The sample of 8337 adults from the general population in Germany answered qualitative free text questions about the most severe consequences of the pandemic on their lives and need/wishes for support. In addition, the evaluation of the consequences over the course of the pandemic and their associations with psychological distress were quantitatively examined. Results: The consequences experienced and especially their evaluation changed over the course of the pandemic. On average, consequences targeting social and life in general aspects were experienced as particularly severe and negative. Negatively experienced consequences were cross-sectionally and partly also longitudinally associated with stronger anxiety and depressive symptoms. Psychotherapeutic and evaluative communicative support was particularly frequently requested in the context of the pandemic. Conclusion: Subjectively negatively experienced consequences of the pandemic should if possible be mitigated by adequate measures. The dynamic changes of the consequences and thus also the need for support over the course of the pandemic should be taken into account. Possible support options range from very low-threshold offers (e.g., tips online) up to psychotherapy. © 2022, The Author(s).",TestAnalysis
"Purpose: This paper explores the effect the regional technological environment has on technology-driven performance, measured by enterprise resource planning (ERP). Design/methodology/approach: This study specifies a productivity-based production function driven by ERP system adoption. Employing a quasi-experimental research design, the author disentangles two effects – the average effect of ERP adoption and the moderation effect of the regional technological environment. The novelty of this study is that it merges publicly available information retrieved via text-mining tools and official financial reports published by companies. Findings: The total effect of technology adoption on productivity varies from almost 3%–9% in different technological environments. Moreover, this study’s results revealed that the regional technological environment could enhance the effect of adopting different ERP systems. Originality/value: While some papers investigate the relationship between ERP adoption and firm performance regarding the environmental context of a firm, the effect of the regional technological environment on the relationship between technology adoption and firm performance is understudied. Thus, this research tries to contribute to a deeper understanding of the regional context's impact on technology-driven performance. The authors used automated content analysis to collect data on technology adoption; by doing so, this study contributes to the growing body of research utilising the text-mining approach to extract data stored in Internet-based information sources. © 2022, Emerald Publishing Limited.",TestAnalysis
"Understanding different aspects of public concerns and sentiments during large health emergencies, such as the COVID-19 pandemic, is essential for public health agencies to develop effective communication strategies, deliver up-to-date and accurate health information, and mitigate potential impacts of emerging misinformation. Current infoveillance systems generally focus on discussion intensity (i.e., number of relevant posts) as an approximation of public awareness, while largely ignoring the rich and diverse information in texts with granular information of varying public concerns and sentiments. In this study, we address this grand challenge by developing a novel natural language processing (NLP) infoveillance workflow based on bidirectional encoder representation from transformers (BERT). We first used a smaller COVID-19 tweet sample to develop a content classification and sentiment analysis model using COVID-Twitter-BERT. The classification accuracy was between 0.77 and 0.88 across the five identified topics. In the sentiment analysis with a three-class classification task (positive/negative/neutral), BERT achieved decent accuracy, 0.7. We then applied the content topic and sentiment classifiers to a much larger dataset with more than 4 million tweets in a 15-month period. We specifically analyzed non-pharmaceutical intervention (NPI) and social issue content topics. There were significant differences in terms of public awareness and sentiment towards the overall COVID-19, NPI, and social issue content topics across time and space. In addition, key events were also identified to associate with abrupt sentiment changes towards NPIs and social issues. This novel NLP-based AI workflow can be readily adopted for real-time granular content topic and sentiment infoveillance beyond the health context. © 2023 by the authors. Licensee MDPI, Basel, Switzerland.",TestAnalysis
"This study explored the effect of English language learners’ breadth and depth of vocabulary knowledge on their understanding and grades of reading English texts. Sixty-one Jordanian EFL undergraduates were assigned three tests, which were the Vocabulary Levels Test Version 2 (VLT), the Word Associates Test (WAT), and Academic International English Language Testing System (IELTS). The collected data was analysed utilizing Pearson correlation analysis and multiple linear regression. According to the empirical outcomes, breadth and depth of vocabulary knowledge correlated positively with each other and with reading comprehension. Further, the significant predictor of the overall variance of reading comprehension was vocabulary depth, while the breadth of vocabulary knowledge was the less significant one. The results demonstrate the importance of expanding and deepening EFL learners’ vocabulary knowledge in classrooms. © 2023 JJMLL Publishers/Yarmouk University. All Rights Reserved.",TestAnalysis
"Now that students in our introductory object-oriented programming course are more familiar with Zoom and screen sharing, we consider novel assessments that leverage these tools. We developed a style of assessment where students submit a recorded screencast of them tracing a submitted program. We describe the design of the assessment and tracing prompts, and we report on an analysis of 59 submitted student videos. Our findings include common mistakes and aspects of student understanding that were expressed in the video but not in the text and code submitted by students. For example, we observed different strategies that yielded the same correct trace of a loop, as well as incorrect traces of students' own correct recursive programs. These guide us towards ways to refine the assessment and prompts in future iterations. © 2023 Owner/Author.",TestAnalysis
"[Purpose/Significance] Interdisciplinary research can creatively solve complex problems in natural environment and human society through knowledge integration and penetration. With the increase of interdisciplinary research results, the evaluation of interdisciplinarity becomes increasingly necessary. How to establish an effective method for interdisciplinarity measurement and achieve a comprehensive measurement of scientific research papers is an urgent problem to be solved. [Method/Process] Based on the above background, this study takes the data of scientific research papers as the analysis source, deconstructs the interdisciplinarity of scientific research papers from multiple dimensions, constructs the feature set of interdisciplinarity of scientific research papers, and on this basis proposes the method for measuring interdisciplinarity based on the adaptive method of machine learning, and conducts a comprehensive measurement of interdisciplinarity. This study has certain positive significance for researchers to understand the interdisciplinary papers in the field. The work process is as follows: First of all, the basic concepts of interdisciplinarity are sorted out and related concepts are discriminated, and the index of interdisciplinarity of different dimensions is analyzed. Based on the connotation and characteristics of interdisciplinary research, the characteristic index of interdisciplinarity of scientific research papers is extracted from three dimensions: subject attribute, knowledge network topology and knowledge integration text content. Secondly, an interdisciplinarity measurement method based on machine learning is constructed. By analyzing information gain and feature similarity of input indexes and data in feature sets, a feature selection calculation method based on adaptive feature selection is proposed, and the accuracy of feature classification is maximized by machine learning classifier. At the same time, the feature subset that can best express the interdisciplinary is selected based on the adaptive selection of the minimum number of features, and the selected adaptive feature set is used in the calculation of the interdisciplinary of the paper, and the results of the calculation of the original feature set are analyzed comprehensively. Finally, an empirical study was carried out in the field of plant nanobiotechnology to verify the effectiveness of the index system and adaptive feature selection listed above, identify and screen papers with high interdisciplinarity in the field, measure the interdisciplinarity of papers and identify key influencing factors based on the calculation of subject attributes, knowledge network topology and knowledge integration text content features. [Results/Conclusions] The main empirical results show that, among the subject attributes, the balance degree and the difference degree have a greater effect on the interdisciplinary evaluation. The overall effect of knowledge network topology structure features is satisfactory, the distribution breadth of knowledge integration text content features has a greater effect on interdisciplinary evaluation, and the calculation effect is further improved by fitness weighted summation of each feature. The results demonstrate that the adaptive feature selection proposed in this paper can effectively screen the interdisciplinary related feature indexes, improve the reliability of the results, and achieve a comprehensive and in-depth measurement of the interdisciplinary of scientific research papers. This measure method avoids the subjective defects that may occur in qualitative evaluation and the problems that different measure indicators may produce contradictory results. It provides a new idea and direction for interdisciplinary measurement. © 2022 Institute of Cultural Heritage of the Academy of Sciences of Moldova. All rights reserved.",TestAnalysis
"Between 1987 and 2015, Terry Pratchett published eleven novels and one short story within his Discworld universe that came to be known as his “Witches” sub-series. In these texts he engaged with the narrative imperatives, preoccupations, and tropes which together make up the consensus fantasy universe, and those deeper mythologies and legendarium with which the author necessarily has an intertextual relationship. This paper focuses upon one aspect of that consensus universe, which is the difference between male and female magical practitioners—witches and wizards—in the fantasy canon, and how Pratchett sought to challenge and subvert the stereotypes of the genre in his own work. The primary means by which Pratchett achieved this, I have argued, is by exposing the fictionality of these stereotypes through parody and satire, whilst at the same time embedding these same tropes within his own universe as the building blocks of his secondary world. The period during which the “Witches” novels were produced is roughly commensurate with a timeframe in which the range of academic and activist positions which are broadly regarded as constituting second-wave feminism were giving rise to, being overtaken by (or in some cases were in direct conflict with) a multiplicity of newer scholarly approaches which have been described as comprising a third wave. Whilst it would be wrong-footed to attempt to position Pratchett’s ‘Witches” novels as a direct engagement with any of these theories, we can see in his writing an awareness of the shifting landscape of feminist thought, with themes in the earliest novels that take up ideas of equality of access similar to those that dominated first-wave discourse, as well as a growing cast of characters and range of thematic concerns that come to reflect the divergence of second and third-wave debates about biological sex and gender identity. Although Pratchett’s work does not itself constitute feminist scholarship, I have argued that through his engagement with some of the evolving ideas about women and their relative position in society, his “Witches” novels can be read as an attempt to change the way that women are portrayed in fantasy literature by intersecting with ideas that are external to it. In this respect, and by interpreting his work in terms of de Beauvoir’s archetypal stereotypes and her theory of Other, as well as Grosz’s work on feminine corporeality and Butler’s ideas of gender performativity, I have sought to illuminate how Pratchett’s fiction not only sits within a wider body of feminist discourse but can also bear the weight of such critical analysis. © 2023, The Mythopoeic Society. All rights reserved.",TestAnalysis
"[Purpose/Significance] Literature classification is a fundamental task in library and information service, which is of great value for information resource management, and literature retrieval and acquisition. Deep learning-based literature classification methods are the current mainstream methods in text classification, which employ neural networks to model and use the textual content for literature classification. This approach only utilizes the information of the literature itself, but ignores the knowledge of the association between the literature. By observing the data, we found that literature in the same category tends to share more keyword information. The literature can build association networks through keywords to form structural relationships between literature. We attempt to utilize this structural in-formation to improve the performance of literature classification. [Methods/Process] This paper proposes a method that can model the structural representation of the literature and employ this representation to enhance traditional literature classification methods. Specifi-cally, we first constructed a large-scale keyword dictionary based on the collected data from about 930,000 documents. Second, we extracted the keyword set from the titles and abstracts of papers by a two-way maximum matching algorithm and constructed the keyword-literature graph data with the literature and keywords as nodes and the inclusion relationship between the documents and keywords as edges. The literature was connected with each other by keywords. Furthermore, we employed graph convolutional neural network to model the literature graph and learn the representation of literature and keywords in the keyword-literature graph. The literature representation generated by graph neural network contained the structural relationships between the literature. In addition, we employed Bert+BiLSTM to model the textual content representation of literature. Finally, the structural and textual representations of the literature were concatenated, and the classification of the literature was performed based on this representation. [Results/Conclusions] We constructed a literature classification dataset containing 423 classes and divided the training set, validation set and test set according to the ratio of 8:1:1. We conducted literature classification experiments on this dataset. The experimental results show that the structural information of literature can effectively enhance the performance of traditional literature classification methods. The results of the stripping experiments also show that the structural information alone is insufficient for the literature classification task. Through detailed analysis of the error data, we found that the model still has problems in handling some less frequent keywords and concepts. In the future, we plan to use small-sample learning methods to solve the classification problem for literature categories with less data. © Agricultural Information Institute, Chinese Academy of Agricultural Sciences. All Rights Reserved.",TestAnalysis
"An effective pain management strategy requires understanding of the epidemiology of pain in the population of interest and accurate measurement upon which to base quality improvement plans. The aims of this study were to estimate the incidence of pain in the prehospital setting and to explore features that impact on (1) documentation of pain; (2) severity of pain reported by patients. This retrospective cohort study included 212,401 care episodes attended by National Ambulance Service practitioners during 2020. Descriptive analysis of patient and care episode characteristics and regression analyses for the outcomes pain recorded and severity of pain were performed. We also used text pattern-matching of the notes field to estimate the proportion of patients in pain for whom a pain score assessment had not been documented. Sixty-five percent of all patients had a pain score documented and 29.5% were in pain (11% in severe pain). Likelihood of pain being recorded was most strongly associated with: Glasgow Coma Scale (GCS) Score, working diagnosis of the patient, location of the incident, and patient age. Likelihood of pain severity was most strongly associated with: transport status of patient, GCS score, and patient age. We treated missing data as a separate category and found consistent associations between the outcomes and missing data. We also found that pain was a symptom in approximately 15% of cases where no formal pain score assessment was documented. The data showed associations between routinely collected variables and the likelihood of pain recording and pain severity. Our findings also demonstrate the impact of missing data. To mitigate missing data impact, we suggest that EMS agencies consider making pain score assessment a mandatory requirement of their reporting for every patient. We also recommend that services report the extent and impact of missing data when measuring clinical performance. © The Author(s) 2023.",TestAnalysis
"Contrary to deconstruction and its destructive pursuit, the concept of undermining the familiar seeks to refute the constants and its known limitations. It is done through the process of receiving and what is imposed by the formation of the word or text or the structural and design structure in general, along with the Arabic calligraphy in particular. This is based on the recipient's understanding and interpretation of the dual phenomenon and the content's manifestation. More accurately, the disclosure of its reality through its expressive phenomenology; for that sake, the research was devoted to studying “undermining the familiar and embodiment content in Arabic calligraphy” including four chapters. The first chapter comprised the methodological introduction, the second chapter dealt with the concept of undermining the familiar and its representations in Arabic calligraphy, and to embodiment the content along with its use in Arabic calligraphy. While, the third chapter represented the research procedures and the community reached (32) compositions, in which the analysis concluded several results. The fourth chapter clarified the most important concept. The sample calligraphers were able to focus on the design relationships of the theoretical framework. The current study acquainted with undermining the familiar and embodiment of the content for those concerned and interested in the art of Arabic calligraphy, it also focused to benefit from the energies of letters and their constructive movements in building, modernizing, and renewing the arts of Arabic calligraphy. Moreover, the research also suggested studying the design treatments in order to embody the content in the formations of Arabic calligraphy. © The Authors.",TestAnalysis
"Objective: New Technologies and Innovative Solutions in creating a multimedia corpus of texts about the ""Mezen Robinsons"" aims to preserve the memory of an event that occurred in the 18th century and to study the history of Spitsbergen development. This article presents a multimedia corpus of Russian-language texts about the ""Mezen Robinsons"" written in 1766–2022. Observations show that the history of the survival of the Mezen hunters on Edge Island in 1743–1749 has repeatedly attracted the attention of specialists from various fields of knowledge: historians, archaeologists, publicists, professional writers, translators, etc. The corpus unites texts, audio, video, and multimedia resources. Methods: continuous sampling was used to collect the material; when analyzing and describing the data, we applied a descriptive method, a biographical method of studying literature, statistical data processing, philological analysis, observation, assessment, and corpus modeling methods. Findings: the methodology and technology of building an independent multimedia corpus, its architecture, and its design are described. Novelty: the multimedia corpus is a contribution to the development of a new approach to studying the subjectology of Russian literature. Practical significance: the findings can become the basis for studying the biographies and creativity of various authors who built their works on the plot of the Mezen industrialists and for further comparison of various interpretations of one event from the history of the development of the Arctic. © Authors retain all copyrights.",TestAnalysis
"A discourse containing one or more sentences describes daily issues and events for people to communicate their thoughts and opinions. As sentences are normally consist of multiple text segments, correct understanding of the theme of a discourse should take into consideration of the relations in between text segments. Although sometimes a connective exists in raw texts for conveying relations, it is more often the cases that no connective exists in between two text segments but some implicit relation does exist in between them. The task of implicit discourse relation recognition (IDRR) is to detect implicit relation and classify its sense between two text segments without a connective. Indeed, the IDRR task is important to diverse downstream natural language processing tasks, such as text summarization, machine translation and so on. This article provides a comprehensive and up-to-date survey for the IDRR task. We first summarize the task definition and data sources widely used in the field. We categorize the main solution approaches for the IDRR task from the viewpoint of its development history. In each solution category, we present and analyze the most representative methods, including their origins, ideas, strengths and weaknesses. We also present performance comparisons for those solutions experimented on a public corpus with standard data processing procedures. Finally, we discuss future research directions for discourse relation analysis.  © 2023 Association for Computing Machinery.",TestAnalysis
"Purpose: Searching, identifying and analysing the scientific literature on “corporate communication” published in scientific journals during the twenty-first century (2000–2021) and indexed in the Scopus database, as well as its possible relationship with COVID-19. Design/methodology/approach: A systematic bibliographic search was carried out in Scopus and a subsequent analysis of the literature, based on variables such as year of publication, authorship, original language of the text, most used terms and concepts, journal titles, keywords and possible allusions to COVID-19 or the pandemic. Findings: 2023 results were initially identified, but after applying the filters that limited the results in time (2000–2021) and discriminated—according to the type of document—the results only to scientific articles, the sample finally analysed was 1,280 articles relating to “corporate communication”. It was found that these were mainly published in journals such as Corporate Communications and Journal of Communication Management, in English, and with an accentuated thematic dispersion, but mostly related to public relations, advertising and communication in general. Originality/value: There is an article published in 2012, before the COVID-19 pandemic, in the Italian journal Igiene e sanità publica, which already established the relevance of researching the challenges and solutions to communication risks in health crisis situations. © 2022, Emerald Publishing Limited.",TestAnalysis
"COVID-19 has demonstrated the fragility of EU free movement rules when we are faced with an unknown virus of such magnitude and strength that it threatens our lives, health systems, economies and society. The aim of this text is to show the dynamics between the threat of COVID-19 and the rules imposed as a response to the pandemic, which have impacted the functioning of the EU internal market and the Schengen area. The text will concentrate on the application of the precautionary principle and public health restrictions, caused by COVID-19, to free movement of persons in the EU. The analysis will lead to three conclusions. First, it will be shown that the decisions to apply free movement restrictions and the logic followed in the EU COVID-19-related documents can be viewed as a triumph of the precautionary principle. Second, it will be argued that implementing the precautionary principle has a transformative effect on the application of the principle of proportionality in EU law. Finally, it will be shown that COVID-19 has emphasised and increased the difference between the conditions for the applicability of public health restrictions when compared to restrictions based on public policy and public security grounds.  © 2021 The Author(s).",TestAnalysis
"With the rapid development of consumer-grade unmanned aerial vehicles (UAVs), aerial photographs from UAVs become a new source of data for destination image research, and provide support for the observation perspective from the ground to the sky. Taking Tibet as the research object, this study used UAV aerial photos, text profiles and location coordinates in the forum ""SkyPixel"", based on the ""cognitive-emotion"" model in destination image perception theory, applied computer vision analysis, social network analysis, computer text sentiment analysis and GIS spatial analysis to explore the perception of destination image in Tibet from the perspective of UAVs. The research results show that: The natural landscape accounts for the largest proportion of all visual cognitive images, and the majestic mountains and magnificent water features are the most prominent visual scenes of Tibet from the perspective of UAVs. The text profile of the photo is dominated by positive emotions, and the number of positive descriptions is far more than neutral and negative emotions. Negative emotions mainly come from the impact of difficult environments on shooting and self-driving. The overall image of Tibet is reflected in the magnificent plateau scenery and unique Tibetan architecture, specifically in four aspects: ""magnificent mountains and rivers"", ""holy waters"", ""plateau idyll"" and ""Tibetan architecture"", and the overall image perception is positive. The spatial distribution of the visual image reveals a pattern of ""One core and multi-segment areas"" distributed in ""east-west direction"". Finally, this study explored the ground-sky transition mechanism of Tibet destination visual image from four aspects: UAV photographer, UAV equipment, UAV perspective, destination visual marketing and construction, and put forward optimization suggestions for Tibet destination image construction based on the characteristics of environmental resources and UAVs. © 2023 Zhejiang University Press. All rights reserved.",TestAnalysis
"Through intertextual analysis of ancient stone and metal images as well as written texts, this article explores the origins and identities of Tārā and Cundā, two Buddhist goddesses that are widely worshipped in the Indic and Tibetan Mahāyāna and Vajrayāna traditions. By charting the goddesses' iconographic characteristics, their quality, and their relationships with Avalokiteśvara, it argues that the prototype of Tārā is Yaśodharā-to-be, and that Cundā is based on Sujata, the girl who gave the Buddha-to-be milk rice. The first part of the analysis shows clear coherence throughout ancient visual narratives, namely images featuring the girl in the Dīpamkara Buddha story, images featuring Avalokiteśvara and Tārā, and independent images of Tārā. The second part demonstrates clear coherence in the evolution of the visual narratives, which feature Sujata holding a vessel to see the Buddha-to-be and independent Cundā images. The article also shows that the visual narratives have intrinsic fidelity. Copyright © 2023 The Journal of Feminist Studies in Religion, Inc.",TestAnalysis
"The machine learning (ML) research community has landed on automated hate speech detection as the vital tool in the mitigation of bad behavior online. However, it is not clear that this is a widely supported view outside of the ML world. Such a disconnect can have implications for whether automated detection tools are accepted or adopted. Here we lend insight into how other key stakeholders understand the challenge of addressing hate speech and the role automated detection plays in solving it. To do so, we develop and apply a structured approach to dissecting the discourses used by online platform companies, governments, and not-for-profit organizations when discussing hate speech. We find that, where hate speech mitigation is concerned, there is a profound disconnect between the computer science research community and other stakeholder groups—which puts progress on this important problem at serious risk. We identify urgent steps that need to be taken to incorporate computational researchers into a single, coherent, multistakeholder community that is working towards civil discourse online. Copyright © 2023 the Author(s). Published by PNAS.",TestAnalysis
"Importance: Many clinical trial outcomes are documented in free-text electronic health records (EHRs), making manual data collection costly and infeasible at scale. Natural language processing (NLP) is a promising approach for measuring such outcomes efficiently, but ignoring NLP-related misclassification may lead to underpowered studies. Objective: To evaluate the performance, feasibility, and power implications of using NLP to measure the primary outcome of EHR-documented goals-of-care discussions in a pragmatic randomized clinical trial of a communication intervention. Design, Setting, and Participants: This diagnostic study compared the performance, feasibility, and power implications of measuring EHR-documented goals-of-care discussions using 3 approaches: (1) deep-learning NLP, (2) NLP-screened human abstraction (manual verification of NLP-positive records), and (3) conventional manual abstraction. The study included hospitalized patients aged 55 years or older with serious illness enrolled between April 23, 2020, and March 26, 2021, in a pragmatic randomized clinical trial of a communication intervention in a multihospital US academic health system. Main Outcomes and Measures: Main outcomes were natural language processing performance characteristics, human abstractor-hours, and misclassification-adjusted statistical power of methods of measuring clinician-documented goals-of-care discussions. Performance of NLP was evaluated with receiver operating characteristic (ROC) curves and precision-recall (PR) analyses and examined the effects of misclassification on power using mathematical substitution and Monte Carlo simulation. Results: A total of 2512 trial participants (mean [SD] age, 71.7 [10.8] years; 1456 [58%] female) amassed 44324 clinical notes during 30-day follow-up. In a validation sample of 159 participants, deep-learning NLP trained on a separate training data set from identified patients with documented goals-of-care discussions with moderate accuracy (maximal F1score, 0.82; area under the ROC curve,0.924; area under the PR curve, 0.879). Manual abstraction of the outcome from the trial data set would require an estimated 2000 abstractor-hours and would power the trial to detect a risk difference of 5.4% (assuming 33.5% control-arm prevalence, 80% power, and 2-sided α =.05). Measuring the outcome by NLP alone would power the trial to detect a risk difference of 7.6%. Measuring the outcome by NLP-screened human abstraction would require 34.3 abstractor-hours to achieve estimated sensitivity of 92.6% and would power the trial to detect a risk difference of 5.7%. Monte Carlo simulations corroborated misclassification-adjusted power calculations. Conclusions and Relevance: In this diagnostic study, deep-learning NLP and NLP-screened human abstraction had favorable characteristics for measuring an EHR outcome at scale. Adjusted power calculations accurately quantified power loss from NLP-related misclassification, suggesting that incorporation of this approach into the design of studies using NLP would be beneficial.. © 2023 American Medical Association. All rights reserved.",TestAnalysis
"The literature of documentary ethics began to emerge in the West during the 1970s. If one carefully studies documentary films on Taiwan’s indigenous peoples, which have been the subject for over a hundred years, from the perspective of documentary ethics, then there are probably many films worth discussing. However, only the 2007 documentary “Honey Peach Grandma” provides more discussion on documentary ethics. When the documentaries “Turning 18” in 2019 and “The Way Home” in 2020 were released, they caused many protests from young indigenous people regarding the ethical issues raised in these two films, but received scant attention. Therefore, this research specifically discusses these two films from the perspective of documentary ethics. It should be emphasized that the ethical controversy of representing indigenous peoples in documentaries can occur regardless of whether the author(s) are indigenous or non-indigenous. This essay chooses these two films, not because of the ethnicity of the authors, but because these two films caused controversy that did not receive enough attention. The main focus of this study is to analyze whether the subjects’ right to informed consent was properly exercised in two documentary films. Could the subjects potentially be harmed by the screening of the films? Did the content of the documentaries lack relevant historical context, thereby making it apolitical? What kind of impact could the screening of these films have on the audience and the subjects? This study transcribes every scene of the two films into text to establish the films’ structure. Additionally, relevant media reports, personal statements, and discussions from social media related to the ethics of the documentaries are collected and compared for analysis of the films. Furthermore, young people who were involved in the filming process of the documentary “The Way Home” were interviewed to gain insights into the documentary filmmakers’ contact with the protesting family, the shooting process, and the family’s reactions after the film premiere. This study finds that both films are controversial in terms of the informed consent of the subjects. In “Turning 18”, it is worth investigating whether the subjects had the legal capacity to consent to being filmed during the shooting period, and whether they were capable of understanding the potential impact of the film’s exposure. In “The Way Home”, the tribe and some of its members who were filmed were never given the opportunity to exercise their right to informed consent, and they were already filmed and included in the film as an important element of the plot. Additionally, when the members refused to be filmed or expressed different opinions on the story, the documentary filmmaker seemed to have ignored their requests. In terms of the historical context, both films fail to fully present the complex context behind the difficult situations faced by the subjects. The main focus of both films is to create an aesthetic, poetic, or humorous style of sound and image that make the viewers be moved and to sympathize with the subjects. The political nature of these films originally should have had been erased. The lack of historical context has far-reaching consequences. In terms of stereotypes, “Turning 18” replicates common stereotypes of indigenous peoples such as heavy drinking, poverty, backwardness, and overly optimism, but fails to help the audience understand the reasons behind these stereotypes. This may lead viewers to confirm that indigenous peoples can be described with simplified characteristics and are “others” who are somewhat different from the audience’s own ethnic group. In terms of spectacle, both films successfully depict the overly optimistic indigenous peoples when facing stunningly difficult situations, but fail to prompt viewers to think deeply about the reasons why indigenous peoples have fallen into such difficult situations. This prompts both films to serve as dazzling spectacles and visual consumer goods. The lives of the subjects in “Turning 18” are not too far from their perceptions, while the story created in “The Way Home” deviates to some extent from the perceptions of some of the subjects due to the lack of family historical context, insufficient field investigation, and distorted on-site event contexts. This type of inspiring spectacle may not help viewers understand Paiwan culture, but instead may mislead them and may create negative impressions of such culture. Regarding the harm caused to the subjects after the screening, “Turning 18” provides insufficient protection for the two girls and their families, making it easy for them to be identified. This may result in negative discussions and criticism of the film’s content for many years. “The Way Home” has caused great distress to Gao Yujin and her family, who even resorted to legal action to protest against the film. Documentary filmmakers can return to their original lives safely after filming and screening, but if they do not handle the film properly, then those who appear in the film with their true identities and faces may have to live with the impact and harm brought by the film for the rest of their lives. This study suggests that when documentary filmmakers are shooting films with the difficult situation of Indigenous peoples as the main theme, they should conduct detailed field investigations and literature research, interview those who are being filmed, and respect their opinions. Filmmakers should try to present a detailed family history context or a larger historical, political, and economic context. Before shooting, those who are being filmed should exercise their right to informed consent. If the person being filmed decides not to participate, then the filmmaker should stop filming and delete any relevant footage. If the person being filmed agrees to participate, then the filmmaker should do one’s best to provide adequate protection and minimize the impact on the subject’s future lives. Regardless of whether filmmakers are Indigenous persons or not, they need to invest more time and energy to understand the unique culture and complex history behind the stories of those who are being filmed in order to produce works that respect Indigenous people and their views as well as avoid creating works that are apolitical due to the lack of historical context. © 2023 National Chengchi University. All rights reserved.",TestAnalysis
"PURPOSE The purpose of this study was to understand the current market trend for golf apparel rental services and to present basic data to revitalize the golf apparel rental service market and prepare continuous growth plans. METHODS The following keywords were selected for data collection: ""golf wear + rental (렌탈),"" ""golf wear + rental (대여),"" ""golf apparel + rental (렌탈),"" and ""golf apparel + rental (대여).“ The analysis period was limited to two years and seven months from January 1, 2020 to July 31, 2022, when COVID-19 began. The analysis was focused on the top 60 keywords to simplify the network. RESULTS Various keywords were extracted through text mining, TF-IDF, connection centrality, emotional analysis, and semantic network analysis of big data analysis. These were then categorized into four factors: “golf apparel rental service,” “self-expression and authentication,” “sharing economy,” and “emotion.” CONCLUSIONS The results of this study show that young golfers are unreluctant and are generally positive in renting golf apparel. Therefore, if the growing paradigm of the consumption behavior of MZ-generation golfers is recognized and analyzed and the requirements are continuously satisfied through various strategies, there will be a higher possibility to help expand the golf apparel rental market. © Korea Institute of Sport Science.",TestAnalysis
"The twentieth century was a prolific period in the appearance of different models for the construction of states. Proposals were put forward across disciplines such as politics, economics, philosophy and religion. In the political sphere, during the pre-Internet era of mass media, the discourse was one of the main channels for the transmission of ideas. As a result, speeches are nowadays a multifaceted source for research. José Antonio Primo de Rivera was a productive author who left numerous texts. Primo de Rivera's discourse evolved from initial conservatism to an attempt to appeal to the working class with left-wing rhetoric. His staging proposed to transcend the traditional concepts of right and left in order to bring together followers from across the political spectrum. In this research, we use computer tools to analyse the model of state proposed by José Antonio Primo de Rivera through his speeches as well as his relationship with other concepts widely used in his rallies and articles. This analysis of the Falangist leader allows us to identify the fundamental elements of the system he intended to establish. We also corroborate the sources of the discourse and demonstrate some of the particularities of José Antonio's thought through the proposed computer methodology. © 2023 Universidad Pompeu Fabra. All rights reserved.",TestAnalysis
"PURPOSE This study aims to critically read the film <Run-Off 2> in a manner in which its narrative represents and constructs the multicultural subject as the fearful and compassionate “other,” and its structure and meanings reconciles with the concept of cultural citizenship. METHODS This research is informed by two methods: 1) text analysis by deconstructing the narrative structure and flow, and 2) contextual interpretation focussing on understanding the significance of the filmic representation in the Korean historical, political, social, and cultural contexts. RESULTS The narrative of the film portrays and constructs the multicultural subject as a cultural other, with specific styles of representation, in which stereotypical description, otherizing tropes of double process, and recognition struggle for cultural citizenship. CONCLUSIONS The study summarized the present research and laid out some suggestions for critical studies of sport films from an interdisciplinary approach and cultural studies-based methods. © Korea Institute of Sport Science.",TestAnalysis
"Transitioning from block-based programming environments to text-based programming environments can be challenging as it requires students to learn new programming language concepts. In this paper, we identify and classify the issues encountered when transitioning from block-based to text-based programming. In particular, we investigate differences that emerge in learners when using a structured editor compared to an unstructured editor. We followed 26 high school students (ages 12-16; M=14 years) as they transitioned from Scratch to Python in three phases: (i) learning Scratch, (ii) transitioning from Scratch to Python using either a structured or unstructured editor, and (iii) evaluating Python coding skills using an unstructured editor. We identify 27 distinct types of issues and show that learners who used a structured editor during the transition phase had 4.6x less syntax issues and 1.9x less data-type issues compared to those who did not. When these learners switched to an unstructured editor for evaluation, they kept a lower rate on data-type issues but faced 4x more syntax errors. © 2023 ACM.",TestAnalysis
"Background: Missed nursing care (MNC) is experienced in nearly all healthcare facilities. Awareness of the aspects involved in the MNC can improve the quality of patient care. The objective of this systematic review is to provide insights into the factors that contribute to the occurrence of MNC. Methods: The review will adhere to the 2020 preferred reporting items for systematic review and meta-analyses (PRISMA) statement and includes studies published in peer-reviewed journals from 2012 to 2022. The databases used in the literature search include ScienceDirect, Cochrane Library, PubMed, ProQuest, and the Wiley Online Library. The eligibility criteria were determined based on population, intervention, comparison, outcomes, and study (PICOS) guidelines. To evaluate the quality of the studies, the NIH quality assessment tool for observational cohort and cross-sectional studies was employed, while the risk of bias was assessed using the Cochrane collaboration’s risk of bias tool. Three authors independently performed data extraction using qualitative analysis and reached a final agreement. Results: A total of 3611 articles were found in the database search. After removing duplicates and ineligible articles, review studies, case reports, letters to editors, incomplete texts, dissertations, and book chapters, 16 articles were finally eligible for further analysis. In general, there were three categories of factors related to MNC, including labor resources (workload, staff adequacy, staff characteristics, nurse-patient ratio, shift work, and nurse job satisfaction), material sources (work environment, personal protective equipment, patient care equipment), and teamwork and communication (communication within nursing team, and communication with medical staff). The most common influencing factor seemed to be staffing adequacy. Conclusion: The role of healthcare service management and leadership is central to mitigating the factors contributing to MNCs’ emergence, especially labor resources. Meta-analytic studies are needed to find the most influential factors of MNC based on the results of all available studies. © 2023 Kohat University of Science and Technology. All rights reserved.",TestAnalysis
"Introduction The burden of disease attributed to drinking water from private wells is not well characterised. The Wells and Enteric disease Transmission trial is the first randomised controlled trial to estimate the burden of disease that can be attributed to the consumption of untreated private well water. To estimate the attributable incidence of gastrointestinal illness (GI) associated with private well water, we will test if the household treatment of well water by ultraviolet light (active UV device) versus sham (inactive UV device) decreases the incidence of GI in children under 5 years of age. Methods and analysis The trial will enrol (on a rolling basis) 908 families in Pennsylvania, USA, that rely on private wells and have a child 3 years old or younger. Participating families are randomised to either an active whole-house UV device or a sham device. During follow-up, families will respond to weekly text messages to report the presence of signs and symptoms of gastrointestinal or respiratory illness and will be directed to an illness questionnaire when signs/symptoms are present. These data will be used to compare the incidence of waterborne illness between the two study groups. A randomly selected subcohort submits untreated well water samples and biological specimens (stool and saliva) from the participating child in both the presence and absence of signs/symptoms. Samples are analysed for the presence of common waterborne pathogens (stool and water) or immunoconversion to these pathogens (saliva). Ethics Approval has been obtained from Temple University's Institutional Review Board (Protocol 25665). The results of the trial will be published in peer-reviewed journals. Trial registration number NCT04826991.  © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.",TestAnalysis
"This study investigates how Taiwan Indigenous Television’s news represents indigenous people’s traditional knowledge, explains the relationship between climate events and indigenous cultures, and further explores the intention of cultural dissemination. The results herein can promote communication, education, and news content design in regards to the indigenous culture. It first presents a literature review to examine the impact of climate change on indigenous culture, to clarify the concepts of and interactions between indigenous people’s traditional knowledge and resilience, and to evaluate their power relationships in their discourse on climate change. Discussions covering the influence of climate change on indigenous people has shifted focus from the tangible loss involved in climate change to the non-economic or spiritual aspects of influence. However, discourse on climate change has not appeared in the context of indigenous people’s traditional knowledge (e.g., local legends, rituals, and socioecological knowledge). Traditional knowledge is qualitative-, subjective-, and experience-based and emphasizes contextualized micro-narratives of the locals as opposed to scientific knowledge, which can be explained through quantitative, empirical, rational, and predictable grand narratives. This does not negate the applicability of ethnic-, culture-, and spirit-centered traditional knowledge of an indigenous group to other indigenous groups; rather, intergroup exchanges occur, because of similar sociocultural and ecological conditions. The resilience and recovery processes of indigenous people are collective, and their traditional knowledge is tightly connected through their worldview of relationships. As news related to climate change transitions from scientifically-focused toward more socially- and culturally-focused content, the discourse on disaster management and environmental vulnerability has mainly responded to the dominant political, economic, cultural, and social groups as well as their values. Therefore, indigenous people’s cultural experiences are often overlooked. This study conducts a narrative analysis by retrieving documents from the Taiwan Indigenous Television channel. It collects news reports from 2011 to 2021 by searching keywords such as “climate change” and “global warming.” Similarity analysis principles allows us to select climate events that affect indigenous people and have features distinct from others. By rereading and retelling, it analyzes texts for background, sources, routes, resources, perspectives, cultural identity, and members involved to explore the timing, purpose, meaning, and symbolism of representing indigenous people’s traditional knowledge. In the text analysis, 82 news reports are selected and categorized under 4 cultural frameworks according to similarities of their content for the narrative analysis. The 4 frameworks are ecological signals, open indigenous tribes, resilient relationships, and intercultural others frameworks. The analysis results are as follows. (1) The ecological signals framework represents “traditional normality.” Indigenous people regard ecological signals as critical cultural events. The presence of abnormal signals indicates that other activities will be affected and that corresponding actions are required. If the news audience lacks understanding of the cultural background and interpretation associated with the animals, plants, and the environment mentioned in news, they may fail to develop a deeper cultural understanding (e.g., of rituals and myths). (2) The open tribes framework connects the identities of indigenous peoples. Discussions on climate change involve an examination of one another’s tribal cultures (e.g., in seminars, forums, workshops, and award ceremonies). The open tribes framework produces understanding and value recognition and introduces traditional knowledge to the outside world. The audience’s lack of exchange with and understanding of other indigenous tribes and its unawareness of the actions taken by other tribes may impose challenges in that the audience may interpret the news content through their local context (e.g., the elders, memories, and myths of their own tribes). (3) The resilient relationships framework focuses on events related to relational ethics. Narratives revolve around the living space of tribes (e.g., fishing, construction, crop farming, and livestock farming). The study examines existing resilient relationships in a meaningful environment to obtain knowledge for generating dynamic resilience. The resilient relationships framework provides a dynamic interpretation of indigenous people’s resilience through both traditional and modern knowledge. (4) The intercultural others framework explains how indigenous peoples worldwide share their traditional knowledge, fight for their cultural rights in protection of their tight relationships with nature and the land, respond to interactions between the continuation of traditional knowledge and external forces (e.g., globalization, business markets, and systemic environmental threats), and handle the power relationships involved in the interactions. This framework emphasizes the connection of cultural actions taken by indigenous people around the world in response to climate change. The resilient actions of indigenous people maintain the unique cultural boundaries of tribes in which similar beliefs and values are shared with changes to the traditional territorial behavior. Traditions are continued to retain tribal identity and accentuate the inclusivity of tribal culture. The news produced by Taiwan Indigenous Television is typically based on cultural topics, and the narratives closely relate to the traditional knowledge of indigenous people. Although a single piece of news cannot present the entire picture of Taiwan’s indigenous peoples, their traditional knowledge may be scattered across various news texts. In the overall cultural context, indices can be created to connect related news texts to reveal how an event is culturally unique to each indigenous group. These texts could be utilized as materials for cultural dissemination, education, and design (e.g., art creations and development of teaching materials), which can shape and mediatize the indigenous knowledge system for various purposes. Taiwan Indigenous Television demonstrates the diversity of media culture in climate change topics. The production of indigenous people’s traditional knowledge is not limited to compiling ancient texts, as it provides a basis for reflecting how cultural texts are produced in other media. Building upon the narratives under the 4 frameworks, indigenous people and reporters can, with both of them being a subject of the narrative, collaborate to produce and apply traditional knowledge as they situate themselves in the present while looking back on ancient memories. By asking themselves whose traditional knowledge they are discussing, they can produce in-depth experimental narratives that are relevant to resilience and culturally responsive to climate change (or sustainability). © 2023 National Chengchi University. All rights reserved.",TestAnalysis
"Memristors, emerging non-volatile memory devices, have shown promising potential in neuromorphic hardware designs, especially in spiking neural network (SNN) hardware implementation. Memristor-based SNNs have been successfully applied in a wide range of applications, including image classification and pattern recognition. However, implementing memristor-based SNNs in text classification is still under exploration. One of the main reasons is that training memristor-based SNNs for text classification is costly due to the lack of efficient learning rules and memristor non-idealities. To address these issues and accelerate the research of exploring memristor-based SNNs in text classification applications, we develop a simulation framework with a virtual memristor array using an empirical memristor model. We use this framework to demonstrate a sentiment analysis task in the IMDB movie reviews dataset. We take two approaches to obtain trained SNNs with memristor models: (1) by converting a pre-trained artificial neural network (ANN) to a memristor-based SNN, or (2) by training a memristor-based SNN directly. These two approaches can be applied in two scenarios: offline classification and online training. We achieve the classification accuracy of 85.88% by converting a pre-trained ANN to a memristor-based SNN and 84.86% by training the memristor-based SNN directly, given that the baseline training accuracy of the equivalent ANN is 86.02%. We conclude that it is possible to achieve similar classification accuracy in simulation from ANNs to SNNs and from non-memristive synapses to data-driven memristive synapses. We also investigate how global parameters such as spike train length, the read noise, and the weight updating stop conditions affect the neural networks in both approaches. This investigation further indicates that the simulation using statistic memristor models in the two approaches presented by this paper can assist the exploration of memristor-based SNNs in natural language processing tasks. © 2023 The Author(s). Published by IOP Publishing Ltd.",TestAnalysis
"Many birthday greeting cards not only mention a specific age, such as 30, 40, 50 and so on, but they also express attitudes towards particular ages, either directly or indirectly, in their texts. Past has looked at attitudes towards aging and ageism in birthday cards. However, there is a lack of recent scholarship employing a detailed linguistic analysis of the texts of age-related birthday cards and implied attitudes and ideologies. The purpose of this study was to take a closer look at English language textual discourses in a popular cultural genre, online birthday greeting cards, and how they construct attitudes and ideologies of age in contemporary Western society. The data sample consists of the texts of ten birthday cards for each of ten different ages, ranging from five years to one hundred years, for a total of 100 cards. The cards were obtained from the online websites of two greeting card companies in the United States. The methodology involves a qualitative discourse analysis that examines specific linguistic devices in the texts. The results of this analysis confirm the presence of negative attitudes towards every age group except the two youngest ones (five years old and twenty-one years old). Moreover, even though these two groups were portrayed in a more positive light than the others, there were also age-related stereotypes in many of the cards for these two age categories. This study contributes to the research on aging and ageism, age stereotyping in greeting cards and the field of discourse analysis in an online modality. © Peter Lang Group AG, International Academic Publishers, Bern 2023. All rights reserved.",TestAnalysis
"Acute burn surgery has long been associated with significant intra-operative bleeding. Several techniques were introduced to limit hemorrhage, including tourniquets, tumescent infiltration, and topical agents. To date, no study has comprehensively investigated the available data regarding topical hemostatic agents in burn surgery. A systematic review was performed by two independent reviewers using electronic databases (PubMed, Scopus, Web of Science) from first available to September 10, 2021. Articles were included if they were published in English and described or evaluated topical hemostatic agents used in burn excision and/or grafting. Data were extracted on the agent(s) used, their dosage, mode of delivery, hemostasis outcomes, and complications. The search identified 1982 nonduplicate citations, of which 134 underwent full-text review, and 49 met inclusion criteria. In total, 32 studies incorporated a vasoconstrictor agent, and 28 studies incorporated a procoagulant agent. Four studies incorporated other agents (hydrogen peroxide, tranexamic acid, collagen sheets, and TT-173). The most common vasoconstrictor used was epinephrine, with doses ranging from 1:1000 to 1:1,000,000. The most common procoagulant used was thrombin, with doses ranging from 10 to 1000 IU/ml. Among the comparative studies, outcomes of blood loss were not reported in a consistent manner, therefore meta-analysis could not be performed. The majority of studies (94%) were level of evidence III-V. Determining the optimal topical hemostatic agent is limited by low-quality data and challenges with consistent reporting of intra-operative blood loss. Given the routine use of topical hemostatic agents in burn surgery, high-quality research is essential to determine the optimal agent, dosage, and mode of delivery. © The Author(s) 2022. Published by Oxford University Press on behalf of the American Burn Association. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com.",TestAnalysis
"The rapid adoption of online social media platforms has transformed the way of communication and interaction. On these platforms, discussions in the form of trending topics provide a glimpse of events happening around the world in real-time. Also, these trends are used for political campaigns, public awareness, and brand promotions. Consequently, these trends are sensitive to manipulation by malicious users who aim to mislead the mass audience. In this article, we identify and study the characteristics of users involved in the manipulation of Twitter trends in Pakistan. We propose 'Manipify'-a framework for automatic detection and analysis of malicious users in Twitter trends. Our framework consists of three distinct modules: (1) user classifier, (2) hashtag classifier, and (3) trend analyzer. The user classifier module introduces a novel approach to automatically detect manipulators using tweet content and user behaviour features. Also, the module classifies human and bot users. Next, the hashtag classifier categorizes trending hashtags into six categories assisting in examining manipulators behaviour across different categories. Finally, the trend analyzer module examines users, hashtags, and tweets for hashtag reach, linguistic features, and user behaviour. Our user classifier module achieves 0.92 and 0.98 accuracy in classifying manipulators and bots, respectively. We further test Manipify on the dataset comprising 652 trending hashtags with 5.4 million tweets and 1.9 million users. The analysis of trends reveals that the trending panel is mostly dominated by political hashtags. In addition, our results show a higher contribution of human accounts in trend manipulation as compared to bots.  © 2020 Tsinghua University Press.",TestAnalysis
"Whether Marx's economics and Marxist political economy can be formalized using mathematics is a controversial and divisive issue. From studying the text of Capital and its manuscripts, it emerges that Marx's research on the capitalist mode of production involves the application of mathematical methods. Marx creates a set of symbols related to the social production of capitalism, and on that basis constructs an economic model corresponding to his theoretical analysis. Obviously, the mathematical method is an integral part of Marx's economic methodology. In a certain sense, using mathematical methods to study and formalize Marx's economics is in line with Marx's approach to economic topics. However, the formalization of Marx's economics must strictly observe the relevant principles; otherwise, it will lead to serious problems. © 2023 Pluto Journals. All rights reserved.",TestAnalysis
"First, some electoral processes and then the COVID-19 crisis have brought offensive and dangerous disinformation events in social media into the spotlight. This research analyses an event concerning disinformation and the launch and dissemination of the hashtag #ExposeBillGates, through the 183,016 tweets that used this hashtag during its period of activity in June 2020. Through network analysis and by processing the content of the messages through text mining, it was observed that the size of the event was highly dependent on the participation of a small number of accounts, and some violent and abusive communication was found, although not hate speech. The need to deeply study the relationship between two macro communicative phenomena of a different nature, but more intertwined in their “problematic” origin than may appear, is discussed. © 2023 Revista de los Estudios de Derecho y Ciencia Política. All rights reserved.",TestAnalysis
"The text engages with the ongoing discussion about the role played by religion in social life, with attention paid to transnational dynamics of religiosity in migrants’ individual experiences, expectations and modes of involvement. We concentrate on the research problem: how does the Roman Catholic Church, through the networks of the faithful, facilitate, challenge, and intersect with the adaptation or integration of migrants in their new settings? The study draws on a survey conducted with a sample (n = 620) Polish Catholics in Great Britain in 2019. With the cluster analysis, we distinguished five categories of participants in parish life. The results of the study concern the declared expectations of the respondents in the confessional and non-confessional (charity, leisure, tourist, or cultural) activities. It shows two paths of respondents’ religious experience: the old parochialism and the new one. The first attitude, represents a general religious-community context, while the second one emphasizes socio-cultural background and cooperative style of work based on associations and goals-achievement. Our findings concern the socio-cultural specificity of migrants resulting from belonging to migrant parishes outside Poland and how this specificity can be juxtaposed with information concerning mainstream Catholic parishes in Great Britain. © Religious Research Association 2023.",TestAnalysis
"PURPOSE: Nonsteroidal anti-inflammatory drugs (NSAIDs) are often recommended as opioid-sparing agents. The objective of this scoping review was to conduct a thorough search of the current literature to determine whether in adult critically ill patients there is an association between exposure to NSAIDs vs no NSAIDs and the subsequent development of serious adverse events, particularly gastrointestinal bleeding and acute kidney injury (AKI). METHODS: The Preferred Reporting Items for Systematic Reviews and Meta-Analysis extension for Scoping Reviews was utilized as a guideline for reporting. Searches were performed in PubMed (National Library of Medicine), Cochrane Library (Wiley), EMBASE (Elsevier), Stat!Ref (Teton), and Access Pharmacy (McGraw Hill) for articles published from January 2016 to August 2022. RESULTS: Of the 3,062 citations and titles identified in the search, 2,737 titles remained after removal of duplicates, 2,588 were excluded at title and abstract screening, and 149 articles remained for full-text review. None of the studies involved heterogeneous groups of critically ill patients in nonspecialty intensive care unit settings. Most studies evaluated were conducted in the perioperative setting and had limited adverse events reporting, particularly with respect to serious NSAID-related adverse effects of concern in critically ill patients. CONCLUSION: In published studies primarily involving perioperative patients, there is insufficient detail concerning the definitions and reporting of NSAID-related serious adverse events such as bleeding and AKI. These events are of particular concern in heterogeneous critically ill patient populations predisposed to such complications. In most (if not all) critically ill patients, sustained dosing of NSAIDs should be avoided regardless of COX-1 selectivity due to the paucity of safety data. © American Society of Health-System Pharmacists 2022. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com.",TestAnalysis
"Introduces students to appropriate use of computer programming within the scientific disciplines using Python. Discusses several common applications of programming and implementation using real world examples and hands on programming exercises. Students learn how to model situations such as image recognition, medical diagnosis, spread of disease, and others. The text could be used by students and lecturers for courses in Python, Numerical Methods, or as a first course in Data Science. Introduces students majoring in the scientific disciplines to programming using Python. Discusses common applications of programming and implementation so that students can see the power and effectiveness of such methods. © 2023 Walter de Gruyter GmbH.",TestAnalysis
"Objective To analyze the information related to child‑prohibition in drug labels in China. Methods The existing drug labels for chemical drugs and biological products included in the China Pharmacopoeia 2020 (Ch. P) were collected through searching websites such as ""Yaozhiwang"" ""Dingxiangyuan"" and ""Yimaitong"", and information related to child‑prohibition was extracted. The expres‑ sion and existing problems of information about child‑prohibition were analyzed. Results A total of 1 741 and 149 chemical and biological products were included in the Ch.P, respectively, of which 411 (23.6%) and 6 (4.0%) products involved information of child‑prohibition. Information of child‑prohibition was expressed in 18 ways, such as ""prohibited"" ""not recommended"" and ""try not to"", etc. Issues of child‑prohibition infor‑ mation in drug labels of the same drug from different manufacturers were inconsistent text descriptions, inconsistent age range, and incomplete information on whether there was benzyl alcohol; issues in the same drug label was different age ranges for child-prohibition in different chapters. Conclusions There are inconsistencies and non‑standard issues in information related to child-prohibition in the existing drug instructions in China. Drug manufacturers should conduct full lifecycle management of drug labels in accor‑ dance with the ""Technical Guidelines for Writing Information on Children′s Medication in the Instructions of Chemical Drugs and Therapeutic Biological Products (trial)"", and continuously standardize and improve the information of child-prohibition. © 2023 The Author(s).",TestAnalysis
"The space is considered as a significant element per se. It can give us light about ethos, insomuch as the human existence expresses itself spatially. Our purpose is to describe the characteristics that space has in the poetry of Fabio Morábito in order to show how the lived space exhibit ways of life, shortly, a certain ethos. The analysis of the text follows some tensive semiotics principles. It is found that, in Fabio Morábito’s poetry there is a predilection for open spaces. The figures of virgin terrain or waste lot mean values such as distention, the inchoative, the inconclusive, the open identity. In synthesis, the openness expresses a certain way of living associated with the uprootedness. It is concluded that the amplitude and the openness, favor the intelligible, thus the subject has a greater judgment capacity. © 2023 Universidad Nacional de Mar del Plata. All rights reserved.",TestAnalysis
"Algorithms designed to translate textual content into sign language (SL) expressed through avatars have been used to reduce accessibility barriers. Our research aimed to identify whether the VLibras tool, widely adopted on Brazilian government websites, is an effective accessibility solution for automatic translation into SL. It is an exploratory and applied qualitative research project involving a bibliographic review and support from expert interpreters. We conducted two experimental studies using sequential chronological cuts and applying prescriptive and semantic analyses. We present evidence that there is no actual translation into SL in the automatic translation process performed by the VLibras translation algorithm (TA) but only a transposition of part of the SL lexicon to the Portuguese morphosyntactic structure. The automatic translation of long texts and texts with complex syntactic structures results in excessive pauses and dactylology for words that have a sign registered in the basic SL dictionary. Using human–computer interaction concepts to evaluate automatic translation into sign language by the VLibras TA expands the existing theoretical discussion. It also contributes to minimizing communication problems caused by the discrepancy between the original message and the machine translation, a practical applicability of this study. © The Author(s) 2022. Published by Oxford University Press on behalf of The British Computer Society. All rights reserved.",TestAnalysis
"This article focuses on issues related to risk assessment when maneuvering a loaded bulk carrier in close proximity to a vessel performing underwater work at the time. It is based on a detailed analysis of an incident that took place in the Gulf of Gdansk. The write-up explains real turns of events, conditions and factors that contributed to the incident, but also its consequences are explained. Some other aspects of this article focuses on, are the processes of examination of the direct causes of the incident and identification not compliance with regulations, requirements, or procedures that help to find out the human, technical, and organizational errors. The authors of this text indicate the safety guards that have failed, give the reasons for their failure and, where it was possible, point out the safety guards that should or must be established. The article does not take into account theoretical models for the described accidents, but only practical aspects, human errors and applicable local and international laws and regulations. Particular attention was devoted to the analysis of human errors made by officers maneuvering the surface vessel in the close vicinity of divers performing underwater works. © 2023, Faculty of Navigation, Gdynia Maritime University. All rights reserved.",TestAnalysis
"This sophisticated and empathetic study explores a suite of important Australian literary works from the Chinese diaspora. Using memory studies to trace connections and contiguities, Dr Chen maps an emotionally charged literary network that is compelled by the past to confront the future. The result is a richly revealing exploration of transnational literary identity and complex forms of belonging and attachment across time and place. (Professor Nicole Moore, UNSW Canberra) If memory is the broken mirror of history, diasporic memories are intricate mosaics of multitudinous pasts: personal, collective, national, cosmopolitan, cultural and political. Reading Chinese Australian literature as a mimesis of memory, Beibei Chen offers invaluable insights into the entanglement of past and present and its effect on diasporic identity. (Professor Wenche Ommundsen, University of Wollongong) Inspired by the transnational turn in global literature, this book explores the significance of transnational memory and identity in Chinese-Australian literature by closely examining representations of these two concepts in selected texts. By attending to diverse forms of memory such as collective memory, individual memory, cosmopolitan memory and transgenerational memory, this book offers unique observations on how different types of memory exert influence on the formation of identity in Chinese diasporic writings and tackles the complexity of reading literary texts in light of theories of memory, sociological studies and psychological analysis. © Peter Lang Group AG 2023. All rights reserved.",TestAnalysis
"The use of history textbooks in order to instill particular images of the nation and national identity has been widely recognized, with a proliferation of studies focused on the problematic content in textbooks. Yet, history textbooks rely on a range of other media like maps, graphs, illustrated timelines, and photographs, which also play an important role in visually signposting the nation. While some of these images serve primarily as a form of representation aligned with the text itself, other aspects of visual content distinctly and autonomously construct national identity. In this piece, relying on qualitative visual analysis, we point to the function played by images in symbolically constructing the nation in contemporary primary school textbooks in five post-Yugoslav republics, Bosnia and Herzegovina, Croatia, Montenegro, Serbia, and Slovenia. © 2023, Berghahn Journals. All rights reserved.",TestAnalysis
"Researchers working with administrative crime data often must classify offense narratives into a common scheme for analysis purposes. No comprehensive standard currently exists, nor is there a mapping tool to transform raw descriptions into offense types. This paper introduces a new schema, the Uniform Crime Classification Standard (UCCS), and the Text-based Offense Classification (TOC) tool to address these shortcomings. The UCCS schema draws from existing efforts, aiming to better reflect offense severity and improve type disambiguation. The TOC tool is a machine learning algorithm that uses a hierarchical, multilayer perceptron classification framework, built on 313,209 hand-coded offense descriptions from 24 states, to translate raw descriptions into UCCS codes. We test how variations in data processing and modeling approaches affect recall, precision, and F1 scores to assess their relative influence on model performance. The code scheme and classification tool are collaborations between Measures for Justice and the Criminal Justice Administrative Records System. Copyright © 2023 The Authors, some rights reserved;",TestAnalysis
"It analyzes the editorials of the Peruvian newspaper La República published from May 5 to June 6, 2021, dates in which the political campaigns for the second round of elections for the presidency of Peru took place. The aim is to discover relevant information to understand the use of the terminologies communicated through the written language in that newspaper. Using the text mining technique and machine learning algorithms for the analysis of unstructured data, a dendrogram and clusters were created to validate and estimate the groupings of the most frequent terms. In relation to each candidate, the regression analysis shows a differentiated association in the use of words. These words form a network that expresses the political conjuncture of the period under study and is reinforced by the construction of a cloud of words with the highest frequency of use. It is concluded that the media construct their own social representations on various local and national issues in a way that consciously or unconsciously evidences their preferences. These preferences are not foreign in the editorials of the newspaper La República. The importance of conducting this type of study lies in the potential of the theory of social representations to place the researcher in front of the position held by the subjects, who construct and communicate the antagonistic onslaughts of the national social reality. © 2023 University of Piura. All rights reserved.",TestAnalysis
"This paper presents pieces of evidence of the use of Politeness Strategies and Face threateningActs in dialogues between characters in two drama texts: Death and the King’s Horseman by Wole Soyinka, a Nigerian author (text A) and Othello by William Shakespeare, an English author (text B). This research analyses the relationship between Pilkings, Amusa and Joseph in Death and the King’s Horseman and the relationship between Othello and Iago in Othello. The analysis utilisesthe politeness theory by Brown and Levinson (1978 and 1987) which revolves around the concept of face by Erving Goffman(1967). The thrust of thistheory is to minimise conflict and foster harmony in social interaction. In order to answer the following questions, the data werepurposively selected and qualitative research design is utilized: Do the speeches in the texts satisfy the principle of politeness? What kind of meaning interpretation is depicted in these drama texts? How has speech been used to show the kind of relationship that exists between these characters? It was discovered that while Amusa is utilising negative strategy, Pilkings always makesuse of negative face-threatening actsto avoid his subordinates losing their fear and respect for him; he usespositive face strategy when he dearly needshis subordinates to give him the response he needs. In Othello, the positive face strategy is deployed to enhance an ideal and harmonious master-servant relationship. This paper concludes that the use of politeness strategies is contextualised by the use of power relations between speaker and listener. © 2023 The Author(s).",TestAnalysis
"Objective This scoping review aims to identify the COVID-19-related stressors and the corresponding coping strategies among emergency physicians during and following the pandemic. Introduction In the midst of an unprecedented COVID-19 crisis, healthcare professionals confront a diverse set of difficulties. Emergency physicians are under immense pressure. They must provide frontline care and make quick decisions in a high-pressure environment. This can lead to a variety of physical and psychological stressors, including extended working hours, increased workload, personal risk of infection and the emotional toll of caring for infected patients. It is critical that they be informed of the numerous stressors they face, as well as the various coping methods accessible to them, in order to deal with these pressures. Inclusion criteria This paper will summarise the findings of primary or secondary investigations on emergency physicians' stressors and coping strategies during and following the COVID-19 epidemic. All journals and grey literature in English and Mandarin published after January 2020 are eligible. Methods The Joanna Briggs Institute (JBI) method will be used to conduct the scoping review. A thorough literature search will be performed on OVID Medline, Scopus and Web of Science to find eligible studies, using the keywords related to emergency physicians, stress and coping strategies. Two reviewers will independently revise all of the full-text articles, extract data and evaluate the study quality. A narrative overview of the findings from included studies will be given. Ethics and dissemination This review will involve secondary analysis of published literature, and therefore ethics approval is not required. The Preferred Reporting Items for Systematic reviews and Meta-Analyses checklist will be used to guide translation of findings. Results will be disseminated through peer-reviewed journals and presented in conferences via abstract and presentation.  © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.",TestAnalysis
"The steady growth of tourism is increasing the demand for tourism translation. Cultural words (CWs) translation is challenging since they are absent from target cultures. This systematic review examines studies on CWs translation in tourism texts to comprehend the literature and explore future research tendencies. Following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses, researchers did a comprehensive literature review. Twenty-one articles met the inclusion criteria after the protocol-required data selection and screening. The findings reveal that scholars are increasingly concerned with CWs translation in tourism texts. Moreover, all the included articles used varied theories. Most of them focused on applying various taxonomies of translation strategies to compensate for the losses of cultural connotations in cultural words' rendition. Besides, other researchers focused on CWs translation from different perspectives, such as translation quality assessment, Eco-translatology, meaning equivalence, cultural manipulation, and relevance theory. © 2023 ACADEMY PUBLICATION.",TestAnalysis
"Importance: Despite advances in the understanding of dietary therapies in children with drug-resistant epilepsy, no quantitative comparison exists between different dietary interventions. Objective: To evaluate the comparative efficacy and safety of various dietary therapies in childhood drug-resistant epilepsy. Data Sources: Systematic review and network meta-analysis (frequentist) of studies in PubMed, Embase, Cochrane, and Ovid published from inception to April 2022 using the search terms ketogenic diet, medium chain triglyceride diet, modified Atkins diet, low glycemic index therapy, and refractory epilepsy. Study Selection: Randomized clinical trials comparing different dietary therapies (ketogenic diet, modified Atkins diet, and low glycemic index therapy) with each other or care as usual in childhood drug-resistant epilepsy were included. Abstract, title, and full text were screened independently by 2 reviewers. Data Extraction and Synthesis: Data extraction was conducted following Preferred Reporting Items for Systematic Reviews and Meta-analyses reporting guideline. Cochrane risk-of-bias tool was used to assess the study quality. Effect sizes were calculated as odds ratio with 95% CI using random-effects model. The hierarchy of competing interventions was defined using the surface under the cumulative ranking curve. Main Outcomes and Measures: Short-term (≤3 months) 50% or higher and 90% or higher reduction in seizure frequency and treatment withdrawal due to adverse events were the primary efficacy and safety outcomes. Results: Of 2158 citations, 12 randomized clinical trials (907 patients) qualified for inclusion. In the short term, all dietary interventions were more efficacious than care as usual for 50% or higher seizure reduction (low glycemic index therapy: odds ratio [OR], 24.7 [95% CI, 5.3-115.4]; modified Atkins diet: OR, 11.3 [95% CI, 5.1-25.1]; ketogenic diet: OR, 8.6 [95% CI, 3.7-20.0]), while ketogenic diet (OR, 6.5 [95% CI, 2.3-18.0]) and modified Atkins diet (OR, 5.1 [95% CI, 2.2-12.0]) were better than care as usual for seizure reduction of 90% or higher. However, adverse event-related discontinuation rates were significantly higher for ketogenic diet (OR, 8.6 [95% CI, 1.8-40.6]) and modified Atkins diet (OR, 6.5 [95% CI, 1.4-31.2]) compared with care as usual. Indirectly, there was no significant difference between dietary therapies in efficacy and safety outcomes. Conclusions and Relevance: This study found that all dietary therapies are effective in the short term. However, modified Atkins diet had better tolerability, higher probability for 50% or higher seizure reduction, and comparable probability for 90% or higher seizure reduction and may be a sounder option than ketogenic diet. Direct head-to-head comparison studies are needed to confirm these findings.. © 2023 American Medical Association. All rights reserved.",TestAnalysis
"Aim: Grape seed extract (GSE) is considered a herbal alternative and has been noted for its remineralization potential. Thus, this systematic review is to analyze the in-vitro remineralization effectiveness of the natural remineralizing agent, GSE, helping to reinstate new investigative possibilities in the field of restorative dentistry. Materials and Methods: This systematic review was undertaken using objectives and transparent methods as per the PRISMA guideline and was registered with PROSPERO (CRD42021269585). Studies that had assessed the remineralizing efficacy of GSE on human primary teeth for the past 20 years published in English language were included. Electronic and manual searches were conducted to identify suitable citations, and electronic search was performed using various databases such as PubMed, Trip Database, Google Scholar, EBSCOhost Database, Scopus, and Web of Science. Those articles that were written in English and those that had full text available were considered because of its use in dentistry, whereas unpublished data and literature written in other languages and articles with only abstracts were excluded. The search was focussed on the effect of GSEs on primary teeth. Results: The search identified 446 citations, and 12 articles were chosen and reviewed in full texts, among which 2 relevant citations met the eligibility criteria for the final inclusion in the systematic review. The studies were of good quality and meta-analyses showed inconsistent evidence on the remineralization potential of GSE when compared with fluoride [mean difference: 16.63 (95% confidence interval: -62.48, 95.73); P = 0.004]. Conclusion: Within the limitations of the present study, the findings of this systematic review suggest that GSE has a remineralizing effect on primary teeth but strong literature-based clinical evidence in favor of GSE is lacking and also the remineralizing effectiveness is lesser when compared with fluoride. This reinforces the need for further in-vivo, in-vitro, and comparative clinical studies. © 2023 Wolters Kluwer Medknow Publications. All rights reserved.",TestAnalysis
"We investigated the possibility of automating the prediction of the 16-factor personality traits by R. Cattell from text posts of social media users. The proposed new method of automating the evaluation of R. Kettell’s 16-factor personality test traits includes language models and neural networks. Implementation of the method involves several steps. At the first step text posts are extracted from user accounts of social media, pre-processed with language model RuBERT and previously trained over a full-connected neural network. The result of this step is a normalized empirical distribution of the posts by the previously introduced classes for each user. Subsequently, based on the distribution of user posts the evaluation of the expression of psychological features of the user is made with the help of support vector machine, random forest and Naive Bayesian classifier. The final data set for model building and further testing their performance was made up of 183 respondents who took the R. Cattell test, with links to their public social media accounts. Classifiers predicting results for six factors (A, B, F, I, N, Q1) of R. Cattells 16-factor personality test were constructed. The results can be used to create a prototype of automated system for predicting the severity of psychological features of social media users. Results of work are useful in the applied and research systems connected with marketing, psychology and sociology, and also in the field of protection of users from social engineering attacks. © ITMO University. All Rights Reserved.",TestAnalysis
"Deaf education research and practice have not always lived up to the ideal of improving deaf students’ lives. Consequently, we have constructed novel arguments supporting deaf pedagogy using pragmatic ethics, the aim of which is to increase benefit and decrease harm to individuals and society. The ideal of harm reduction asks the pragmatist to pursue the path of action least likely to result in injury to others. Besides applying ideas that reduce harm, educators must also increase benefits for deaf students. Our analysis synthesizes Vygotskian perspectives on deaf pedagogy and pragmatic ideals about reducing harm and increasing benefit. We propose six arguments that can enable deaf educators to think about and enact deaf-positive concepts and strengths-based classroom interactions, including the use of sign language, images, and text, among other modes, such as speech. Our goal is to reduce the threat of harm from language deprivation. © 2023, Gallaudet University Press. All rights reserved.",TestAnalysis
"In the originally published version of this manuscript, a sentence in French was erroneously inserted into the text: 'Furthermore, these lymphocytes evolve through more differentiation stages successively comprising naive (Tn)/stem central memory (Tscm), central memory (Tcm), effector memory (Tem) and terminally differJe n'ai pas de manip sur des cellules, mais, si le confinement doit se prolonger au delá de 3 semaines, il faudrait juste que je rajoute ponctuellement du solvant dans la nanoLC pour eviter que les tubulures et les joints ne s`echent.entiated (Temra) lymphocytes.' The correct version of this sentence is 'Furthermore, these lymphocytes evolve through more differentiation stages successively comprising naive (Tn)/stem central memory (Tscm), central memory (Tcm), effector memory (Tem) and terminally differentiated (Temra) lymphocytes.' These details have been corrected only in this correction notice to preserve the published version of record.  © 2023 The Author(s).",TestAnalysis
"Introduction Mental health symptoms such as depression, anxiety and sleep problems are commonly observed in individuals suffering from acute COVID-19 infection to post-COVID-19 syndrome. Studies have provided preliminary evidence for the efficacies of cognitive behavioural therapy, mindfulness-based interventions, acceptance and commitment therapy, and many other treatments for this population. Although there have been attempts to synthesise the literature on these psychological interventions, previous reviews have been limited in terms of the sources, symptoms and interventions that they included. Furthermore, most studies reviewed were conducted in early 2020, when COVID-19 had only recently been classified as a global pandemic. Since then, substantial research has been conducted. As such, we sought to provide an updated synthesis of the available evidence of treatments for the range of mental health symptoms associated with COVID-19. Methods and analysis This scoping review protocol was developed according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews. Systematic searches were carried out on scientific databases (PubMed, Web of Science, PsycINFO and Scopus) and clinical trial registries (ClinicalTrials.gov, WHO ICTRP, EU Clinical Trials Register and Cochrane Central Register of Controlled Trials) to identify studies that have or will assess the efficacy or any aspects of psychological treatment for acute to post-COVID-19 syndrome. The search was conducted on 14 October 2022 and identified 17 855 potentially eligible sources/studies published since 1 January 2020 (duplicates removed). Six investigators will independently carry out titles and abstract screening, full-text screening and data charting and the results will be summarised using descriptive statistics and narrative synthesis. Ethics and dissemination Ethical approval is not required for this review. The results will be disseminated through a peer-reviewed journal, conference presentations and/or academic newspapers. This scoping review has been registered with Open Science Framework (https://osf.io/wvr5t).  © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.",TestAnalysis
"Background: According to numerous research related to learning styles and also the difference of these styles in students, this study was designed in order to determine the status of learning styles in medical students in Iran. Methods: This study was conducted as a systematic review and meta-analysis. Searching for articles in this study was done from September 24 to October 15, 2022 in databases: Proquest, PubMed, Iran medex, Scopus, Sid, Magiran, Google Scholar, Eric and medical education journals. The research environment of Iran has been Mashhad. Using the PICOTS model, the keywords: learning styles, clubs, medical students were used to search the mentioned databases. OR, AND operators and possible combinations of keywords were used when searching for articles in databases. The extracted articles were first evaluated in terms of the research title, then the abstract of the article, and finally the text of the article using the ""PRISMA Checklist"". In each stage, repetitive articles and articles that did not mention the percentage of learning styles were excluded from the study, and the articles that met the inclusion criteria were stored in the (EndNote software, version 20, Clarivate, USA), and at the end, 53 articles were analyzed. Results: The results of the study showed that the most used learning styles among students of medical sciences in Iran was convergent learning style (32% with 95% confidence interval). In the investigation of the adaptive learning style in the fields of basic sciences during the years 2006 to 2021, the percentage of using this style increased and this trend was statistically significant (P=0.0078). Conclusion: According to the findings of the study, the most used learning style in medical sciences in Iran is convergent learning style, and considering the characteristics of convergent people, it is necessary to provide effective and efficient training in medical sciences to Students' learning styles should be given special attention so that training can be guided based on their learning styles. Copyright © 2023 Hosseini et al. Published by Tehran University of Medical Sciences.",TestAnalysis
"The celebration of the nation and the state is a defining feature of school textbooks across the country. The present article aims to understand the textual means and pedagogic methods used in evolving a pan-Odia identity in the school textbooks of Odisha. The study has used Odia language and social science textbooks prescribed by the state as sources of sociological analysis. It aims to analyse patterns of regional representation, cultural and religious articulation and linguistic standardisation in constructing the ideal Odia identity. The study found that historical events, such as the Kalinga war, the Khandagiri site and the Paik rebellion have been used as memory posters. Though Odisha represents the highest form of linguistic diversity, there is an attempt to idealise Sanskritised Odia as authentic Odia which tends to delegitimise the region’s multiple dialects and tongues. The article has also noted that only the cultural and linguistic practices of the coastal region have been used as a means of defining the cultural identity of Odisha. Thus, we argue that textbooks work as an ideological state apparatus, organised on principles of recognition and de-recognition of text and traditions of languages, regions, religions and cultural pathways of caste and the adivasi community of Odisha. © 2023 CSD.",TestAnalysis
"Extending a nascent line of Asian philosophical research in music education, we mine Indian philosophies of music and education. Three key questions guide our project: What are Vedic philosophies of music? What are Vedic philosophies of education? Taken together, what insights can we draw for contemporary music education writ large? To address our questions, we analyze key passages from the Upanishads and synthesize ideas from these texts. A quartet of inter-related ideas emerge from our analysis: the guru, the shishya, vidya, and moksha. In brief, the guru (teacher) is revered as one would god, for it is the teacher who leads the shishya (student) toward vidya (knowledge) and through that toward moksha (liberation of the soul), which can also be attained via making music, such as the singing of Om (the absolute sound). In addition to proffering insights for contemporary music education, particularly in terms of how the ancient Vedic guru-shishya parampara adds nuance to contemporary discussions on the master-apprentice model of music education, we imagine how music education philosophy might look like if it were to be sung. Copyright © 2023, The Trustees of Indiana University.",TestAnalysis
"Phosphorylation-dependent signal transduction plays an important role in regulating the functions and fate of skeletal muscle cells. Central players in the phospho-signaling network are the protein kinases AKT, S6K, and RSK as part of the PI3K-AKT-mTOR-S6K and RAF-MEK-ERK-RSK pathways. However, despite their functional importance, knowledge about their specific targets is incomplete because these kinases share the same basophilic substrate motif RxRxxp[ST]. To address this, we performed a multifaceted quantitative phosphoproteomics study of skeletal myotubes following kinase inhibition. Our data corroborate a cross talk between AKT and RAF, a negative feedback loop of RSK on ERK, and a putative connection between RSK and PI3K signaling. Altogether, we report a kinase target landscape containing 49 so far unknown target sites. AKT, S6K, and RSK phosphorylate numerous proteins involved in muscle development, integrity, and functions, and signaling converges on factors that are central for the skeletal muscle cytoskeleton. Whereas AKT controls insulin signaling and impinges on GTPase signaling, nuclear signaling is characteristic for RSK. Our data further support a role of RSK in glucose metabolism. Shared targets have functions in RNA maturation, stability, and translation, which suggests that these basophilic kinases establish an intricate signaling network to orchestrate and regulate processes involved in translation. © 2023 The Authors. Published by American Chemical Society.",TestAnalysis
"Purpose: In the era of information overload, the density of tourism information and the increasingly sophisticated information needs of consumers have created information confusion for tourists and scenic-area managers. The study aims to help scenic-area managers determine the strengths and weaknesses in the development process of scenic areas and to solve the practical problem of tourists' difficulty in quickly and accurately obtaining the destination image of a scenic area and finding a scenic area that meets their needs. Design/methodology/approach: The study uses a variety of machine learning methods, namely, the latent Dirichlet allocation (LDA) theme extraction model, term frequency-inverse document frequency (TF-IDF) weighting method and sentiment analysis. This work also incorporates probabilistic hesitant fuzzy algorithm (PHFA) in multi-attribute decision-making to form an enhanced tourism destination image mining and analysis model based on visitor expression information. The model is intended to help managers and visitors identify the strengths and weaknesses in the development of scenic areas. Jiuzhaigou is used as an example for empirical analysis. Findings: In the study, a complete model for the mining analysis of tourism destination image was constructed, and 24,222 online reviews on Jiuzhaigou, China were analyzed in text. The results revealed a total of 10 attributes and 100 attribute elements. From the identified attributes, three negative attributes were identified, namely, crowdedness, tourism cost and accommodation environment. The study provides suggestions for tourists to select attractions and offers recommendations and improvement measures for Jiuzhaigou in terms of crowd control and post-disaster reconstruction. Originality/value: Previous research in this area has used small sample data for qualitative analysis. Thus, the current study fills this gap in the literature by proposing a machine learning method that incorporates PHFA through the combination of the ideas of management and multi-attribute decision theory. In addition, the study considers visitors' emotions and thematic preferences from the perspective of their expressed information, based on which the tourism destination image is analyzed. Optimization strategies are provided to help managers of scenic spots in their decision-making. © 2021, Emerald Publishing Limited.",TestAnalysis
"This article explores three understudied Middle English versions of the popular anti-Judaic Marian miracle tale of Theophilus. I demonstrate how these versions of Theophilus draw upon widely known medieval imagery of Ecclesia and Synagoga to depict Theophilus’s journey as one of soteriological regression. A comparative analysis of the two related Northern Homily Cycle versions of Theophilus demonstrates how Synagoga is evoked in the portrayal of Theophilus’s despair, which is shown to be a supersessionist issue in his misunderstanding of the Holy Spirit and Trinitarian theology. These two versions then depict Theophilus engaging with Davidic lineage in relation to Marian power, the manner of which unsettles the Christian supersessionist project of the texts and, I argue, earns him physical retribution. I show how these insecurities are resolved in the later Rawlinson version of Theophilus with an invocation of Synagoga in her “return” to Christianity, taken from eschatological readings of Song of Songs 6:13. © 2023 Johns Hopkins University Press.",TestAnalysis
"The way a subject is approached in the academic world depends on the discursive practices involved in its conception. These practices can assume specific orientations according to the language and the social context in which they take place. Agroforestry is a field of knowledge whose scientific affiliation is in a full evolutionary process. Hence the objective of this study is to analyze the lexicon used to describe it in two languages (English and Spanish), as well as the way in which this lexicon is related to the agroforestry concept. From the lines of Corpus Linguistics (CL) and by using frequency analysis tools and three-level cluster diagrams in the program Nvivo, version 2020, two corpora of academic texts related to agroforestry were analyzed, each representing the two languages mentioned, from a text collection of the period 2015 to 2020. The interpretation was based on Systemic Functional Grammar (SFG). Both similarities and lexical differences were found in the Spanish and English academic communities' treatment of agroforestry, with Spanish having a theoretical and practical (holistic) orientation, while English privileges the empirical tendency. It is concluded that the social meaning represented in the lexicon to describe agroforestry depends on how the users of a concept conceive a field of knowledge, which is linked to the historical and cultural value of the concept. Both LC and GSF are useful for observing the functioning of agroforestry discourse. © 2023 Universidad Pompeu Fabra. All rights reserved.",TestAnalysis
"The article argues that the intertextuality of country of origin information (COI) plays a significant part in constructing asylum decisions and therefore the lives and futures of those affected by forced migration. COI in asylum decisions is based on COI reports, which in turn are based on other COI reports, interviews, or media materials. This makes them intertextual, that is, referring to and transforming other texts. That is, COI reports typically include dozens or even hundreds of pages of information, which are abbreviated in order to be used in a few paragraphs of asylum decisions. This is done through recontextualisation, that is, by selecting certain parts of the text and reformulating them to the new context. The article analyses COI in 67 negative first-instance asylum decisions and in 38 COI reports and similar sources through the concept of intertextuality. It argues that COI has two functions in the asylum decisions, personal and general. Personal COI is used to assess the truthfulness of the asylum applicant's persecution narrative, whereas general COI is used to evaluate the overall security and human rights situation in the country of origin. The article shows that even though the decisions tend to present COI as objective information, it can easily be biased, irrelevant, and illogical, therefore creating an illusion of objectivity.  © 2022 The Author(s). Published by Oxford University Press.",TestAnalysis
"Journal of Chinese Agricultural Mechanization is an academic journal with the research theme of agricultural mechanization, which is an important carrier of advanced research theories and achievements in the field. In order to accurately and objectively reflect the development status of Journal of Chinese agricultural mechanization in the past ten years, and further clarify the distribution of hot research topics in the field of agricultural mechanization, this paper is based on the full-text database of Chinese journals on CNKI. By using the bibliometric method, the academic papers published in the Journal of Chinese Agricultural Mechanization from 2012 to 2021 were sorted out and analyzed visually. The research results show the bibliometrics characteristics and academic influence of the journals in the past ten years, and reveal the research hotspots and trends of the journals to a certain extent, and provide suggestions for the current status and development of the journals, but also provide a meaningful reference for observing the development trend of agricultural mechanization from the perspective of the journals. © 2023 Journal of Chinese Agricultural Mechanization. All rights reserved.",TestAnalysis
"Background and Aims: Insulinoma is the most common functional neuroendocrine tumor of the pancreas. However, there have been few bibliometric studies on insulinoma. Therefore, this study was conducted to describe the hotspots and trends in insulinoma research over the past 20 years through bibliometric analysis. Methods: Publications related to insulinoma between 1999 and 2021 were searched in the Web of Science Core Collection (WoSCC), and the results were imported in plain text format into VOSviewer and CiteSpace software for bibliometric analysis. The data was processed using bibliometric methods to conduct visual analysis of authors, countries, institutions, highly cited works, co-citations, keywords, and references. Results: A total of 3 863 publications were retrieved, including 19 310 authors, 3 268 organizations, 83 countries/regions, and 1 005 journals. The literature cited a total of 85 078 articles authored by 55 619 individuals from 7 494 journals. Among them, research on insulinoma was mainly conducted in the United States, with Lernmark A being the most prolific author and the University of Washington being the most significant contributor. The Journal of Biological Chemistry was the main journal for publishing research in the insulinoma field. Keyword analysis showed that the current focus is mainly on ""Pancreatic Neuroendocrine Tumor"" ""ENTS Consensus Guideline"" ""Marker"" ""Management"" and ""Neoplasm"" indicating that the focus of insulinoma research has gradually shifted from a simple overview, diagnosis, clinical manifestations, and complications of this disease to the exploration of neuroendocrine tumors as a whole. Conclusions: In the past 20 years, the publication output of insulinoma has remained at a highly explosive level. The United States has an unshakable position in this field. In addition, the efficacy of emerging tumor markers and how to develop more rational management modes are likely to become future research hotspots. Our study will help predict the development and trends in the field of insulinoma. © 2023 Central South University. All right reserved.",TestAnalysis
"Published studies on social representations of migration in the media offer two pictures that have become crystallized over time. On the one hand, migration is constructed as a social threat for hosting countries; on the other, victimization of migrants is emphasized. This study aims to investigate how literary texts written by the protagonists of migratory experiences contribute to creating a possible alternative view of migrants. The results highlight a tension in the discourse on migration. They show that this literature conveys different worldviews, which can be arranged in two macro-groups. Narratives of victimization emerge, but are counterbalanced by narratives of resilience, post-traumatic growth, and the ability to react and cope with difficulties, and also by narrative of resistance oriented toward ensuring the recognition of the identity of second-generation Italians. This contribution concludes with reflections on the pragmatic value of conducting psychosocial research on literary texts. © The Author(s) 2023.",TestAnalysis
"This article deals with exemption clauses and specifically with respect to their definition, types, and validity. It tackles clauses that exempt the obligor from liability for his or his employees' non-performance. The article presents and analyses the legal provisions on exemption clauses under the Unidroit Principles and the Qatar Civil Code and discusses the case law made under these legislative instruments. In addition, the article draws a comparison between the legal texts at issue in order to conclude with a solution that best serves the parties' interests.  © 2023 The Author(s) (2023). Published by Oxford University Press on behalf of Unidroit.",TestAnalysis
"Marketing has changed fundamentally in the new millennium. At the same time, sustainable marketing strategies have evolved to meet the challenges of environmental issues. In this study, we examined the trends in sustainable marketing strategies and the role of social media in these. Based on specific keywords per the objective, this study collected 33 published articles from the Scopus database from 1991 to 2022 (2012–2022). The KNIME (Konstanz Information Miner) and VOSviewer tools were deployed to provide detailed classification and prediction of the various trends in sustainable marketing, with a particular focus on the role of social media. The study method applied text mining and latent semantic analysis to predict the latest trends. The top three trends were Green Marketing and Consumer Behavior, Sustainable Social Media Marketing, and Influencer Social Media Marketing Practices. This NLP-based review and the clustering of research directions provide immense value to marketers and policymakers. © 2023 by the authors. Licensee MDPI, Basel, Switzerland.",TestAnalysis
"Purpose: To examine the risk factors (RFs), associated with Sudden Unexpected Death in Epilepsy (SUDEP), and the quantitative standards required to measure them Methods: The literature on RFs associated with SUDEP was systematically reviewed up to August 2020 in databases, including PubMed, the Cochrane Database and Embase. Revised Newcastle-Ottawa Scale (NOS) was performed to determine the quality of each study in this meta-analysis (MA), with a score of ≥ 3, indicating good quality. Any controversies in data extraction and quality assessment were resolved through counsel or adjudication with a third researcher. Results: An initial screening of the literature following the search strategy and manual inclusion yielded a total of 767 studies. After excluding duplicates as well as articles that did not match the topic, 112 studies remained. Twenty-nine studies were finally selected based on the inclusion and exclusion criteria. After a careful review of the full text, nine studies were included in the MA. Conclusion: The five RFs for SUDEP included age at the onset of epilepsy ≤15 years, generalized-tonic-clonic seizure, seizure frequency ≥50 seizures/year, treatment with a combination of multiple antiepileptic drugs, and history of alcohol abuse. © Pharmacotherapy Group, Faculty of Pharmacy, University of Benin, Benin City, 300001 Nigeria. © 2023 The authors.",TestAnalysis
"In order to explore the causes of maritime accidents in the Yangtze River Estuary waters, a ship traffic accident analysis method considering the coupling effect of multiple factors was proposed. Firstly, this paper conducted an in-depth analysis of multi-source maritime accident investigation reports and related literatures based on text mining technolog. A set of factors that induced maritime accidents in the Yangtze River Estuary waters was constructed from the environment, ship, human and organizational aspects. Then, the chi-square test was used to analyze the coupling relationship between these risk factors. A BN model of maritime accidents in the Yangtze River Estuary waters was constructed under the action of multi-factor coupling. Finally, the prevention and control countermeasures for ship traffic accidents in the Yangtze River Estuary waters were proposed by performing a sensitivity analysis on the model. The results show that: there are eight causal chains that induce ship traffic accidents in the Yangtze River Estuary waters, and wind, improper cargo stowage, ship type, unsafe speed, negligence of lookout, failure to fully estimate the danger, failure to perform the duty of giving way and failure of control equipment are the eight mutual risk factors that induce ship traffic accidents in the Yangtze River Estuary waters. © 2023 China Safety Science Journal. All rights reserved.",TestAnalysis
"Introduction: A patient experience survey was undertaken as part of the role of the Macmillan Consultant Therapy Radiographer for the bone and brain metastases patients to inform future development of the service. Method: A questionnaire was developed and approved by the Trust's local Questionnaire, Interview and Survey Group to survey the experiences and satisfaction of the service including the informed consent process, radiotherapy appointments and overall experience and satisfaction. The survey used qualitative and quantitative methods, including Likert Scales and free comment boxes. The responses were analysed by counting the frequency of each response and identifying any themes in free text responses. Results: Most patients were satisfied with the consent process with 1/36 patients reporting a lack of understandable information and 4/36 wanting more side effect information. The option of plan and treat was a preference of 53% of patients due to travelling back and forth to the centre; however, only 6% stated that they wanted two separate appointments. Ninety-four percent of patients felt that they had complete confidence and trust in the professional who consented them and 86% did not feel fully involved in the decision-making process. Overall, the service was rated as 10/10 by 61% of patients (n = 36). Conclusions: The patients surveyed were satisfied with their experience of the Palliative Radiotherapy Service; however, it needs to be developed further to meet the needs and expectations of the service users.  © 2023 The Author(s). Published by Cambridge University Press.",TestAnalysis
"Humor is a pervasive communicative device; nevertheless, its portability from one language to another remains challenging for computer machines and even humans. In this work, we investigate the problem of humor recognition from a cross-language and cross-domain perspective, focusing on English and Spanish languages. To this aim, we rely on two strategies: the first is based on multilingual transformer models for exploiting the cross-language knowledge distilled by them, and the second introduces machine translation to learn and make predictions in a single language. Experiments showed that models struggle in front of the humor complexity when it is translated, effectively tracking a degradation in the humor perception when messages flow from one language to another. However, when multilingual models face a cross-language scenario, exclusive between the fine-tuning and evaluation data languages, humor translation helps to align the knowledge learned in fine-tuning phase. According to this, a mean increase of 11% in F1 score was observed when classifying English-written texts with models fine-tuned with a Spanish dataset. These results are encouraging and constitute the first step towards a computationally cross-language analysis of humor. ©2023 Sociedad Española para el Procesamiento del Lenguaje Natural.",TestAnalysis
"This article examines the question of touch in Laurence Nobécourt's La Démengeaison. It seeks to connect Nobécourt's text to recent research on the tactile and more broadly the haptic function of literature. In this article, I will show that skin forms a border in the text, which prevents touch and contact with the world. I will discuss firstly the ways in which the surface/depth paradigm is applied to the untouchable skin of the narrator, excluding her from humanity. Thus, in the second part of my analysis, I will reflect on the ways in which the skin's touchability is reconfigured through the narrator's compulsive itching, and particularly through the exploration of the skin's erogenous dimension. Although this reconfiguration fails in the diegesis and leads only to violence, I will argue that the text succeeds in its haptic aesthetics, and its attempt to touch the reader. © 2023. Edinburgh University Press.",TestAnalysis
"This study explores the possibilities of using digitally produced multimodal language learning histories (MLLHs) to understand the experiences of learning a second language (L2) of a group of university students in Japan (N = 21). The study observes that learners’ MLLHs are texts in which the visual elements of language, place, person, learning resource, and self-analysis of learning process are represented visually. It also identifies 4 patterns in the ways the MLLHs are constructed by focusing on a certain type of visual element. Person-oriented MLLHs focus on L2 learning as emotional experience. In resource-oriented MLLHs, learning is perceived to occur because of engaging with language via favorite media. In analysis-oriented MLLHs, learning is regarded as a matter of going up and down the scale of linguistic measures. Place-oriented MLLHs emphasize being on site at an L2-speaking region as being the key in the era of globalization and mobility. These patterns reflect learners’ beliefs on L2 learning as viewed from a contextual perspective. This study further argues that a multimodal approach can have a significant influence on making visible learners’ subjective perspectives and beliefs as lenses through which they frame their learning experiences, as well as visualizing the dynamics and individualities of learning. © National Federation of Modern Language Teachers Associations.",TestAnalysis
"Abstract: This work deals with the interrelated problems of assessing the closeness of a text to the most rational (reference) form of conveying its sense and the formation of a reference text collection, in relation to which the assessment itself is performed. The texts under analysis for closeness to the semantic standard are abstracts of scientific articles together with their titles. The solution is based on the comparison of values for the 5th percentile of the empirical distribution corresponding to an array of fractions for nonzero values of the term frequency (TF) for separate phrases within each abstract relative to each document under consideration for inclusion into the reference collection. A variant for numerical estimation the significance of the abstract for calculating the mentioned percentile for candidate documents with maximum precision in the case of selection of the most significant for the reference collection is offered. © 2023, Pleiades Publishing, Ltd.",TestAnalysis
"Background/Aims Maintaining staff satisfaction is a major ambition for healthcare leaders worldwide, as it is directly linked with patient outcomes. Despite this, there is a dearth of literature on the job satisfaction of radiographers. This study aimed to explore the job satisfaction and role perceptions of radiographers and assistant practitioners at a local district general hospital. Methods All radiographers and assistant practitioners (n=39) working in the general X-ray department of a small-medium sized NHS trust were invited to complete either an online or physical copy of a semi-structured, mixed-methods questionnaire regarding their job satisfaction and perceptions of their role. Items included quantitative (multiple choice) and qualitative (free-text) questions. Quantitative data were analysed using descriptive statistics while qualitative data were analysed using content analysis. Results A total of 21 individuals completed the questionnaire, giving a 53.8% response rate. The mean score for happiness in their current role was fairly high at 7.3/10, but staff with more experience had lower average happiness scores relating to their role and working hours. Respondents were confident working in most clinical areas, including mobile units, but lacked confidence working in computed tomography and fluoroscopy. Conclusions Strategies are needed to understand and address issues that may be causing more experienced radiography staff to experience less happiness in their job role. Lack of experience in computed tomography and fluoroscopy also needs to be addressed, possibly by ensuring that radiography staff regularly work in these areas to build their confidence. © 2023 MA Healthcare Ltd. All rights reserved.",TestAnalysis
"The aedes mosquito-borne dengue viruses cause dengue fever, an arboviral disease (DENVs). In 2019, the World Health Organization forecasts a yearly occurrence of infections from 100 million to 400 million, the maximum number of dengue cases ever testified worldwide, prompting WHO to label the virus one of the world’s top ten public health risks. Dengue hemorrhagic fever can progress into dengue shock syndrome, which can be fatal. Dengue hemorrhagic fever can also advance into dengue shock syndrome. To provide accessible and timely supportive care and therapy, it is necessary to have indispensable practical instruments that accurately differentiate Dengue and its subcategories in the early stages of illness development. Dengue fever can be predicted in advance, saving one’s life by warning them to seek proper diagnosis and treatment. Predicting infectious diseases such as dengue is difficult, and most forecast systems are still in their primary stages. In developing dengue predictive models, data from microarrays and RNA-Seq have been used significantly. Bayesian inferences and support vector machine algorithms are two examples of statistical methods that can mine opinions and analyze sentiment from text. In general, these methods are not very strong semantically, and they only work effectively when the text passage inputs are at the level of the page or the paragraph; they are poor miners of sentiment at the level of the sentence or the phrase. In this research, we propose to construct a machine learning method to forecast dengue fever. © 2023 by the authors.",TestAnalysis
"Abstract: This paper represents a summary of studies done by the Russian Artificial Intelligence Research Institute of the Federal Research Center “Computer Science and Control” of the Russian Academy of Sciences, in the area of pattern recognition for various applications. They are based on the general recognition problem statement by Yu.I. Zhuravlev combined with various models, metrics, and solution methods. Invariant moments, stable cognitive images, image spectra, and other features have been used as informative parameters. Multimodal problem solving that relies on simultaneous use of text query and image analysis is considered. A model is proposed, which combines the semiotic approach represented by a sign-based world model with vector symbolic architectures. Specific examples are used to demonstrate the effectiveness of the proposed approaches and recognition methods © 2023, Pleiades Publishing, Ltd.",TestAnalysis
"Aims: The purpose of this systematic review is to determine how various innovative non-suture silk and silk-containing products are being used in clinical practice, and compare patient outcomes following their use. Methods: A systematic review of PubMed, Web of Science, and Cochrane was completed. A qualitative synthesis of all included studies was then performed. Results: Our electronic search identified 868 silk-related publications, which yielded 32 studies for full-text review. After exclusion, nine studies from 2011 to 2018 were included for qualitative analysis. A total of 346 patients were included which consisted of 37 males and 309 females. The mean age range was between 18–79 years old. The follow-up among studies ranged between one to twenty-nine months. Three studies addressed the application of silk in wound dressings, one on the topical application of silk-derived products, one on silk-derived scaffold in breast reconstruction, and three on silk underwear as adjunct for the treatment of gynecological conditions. All studies showed good outcomes alone or in comparison to controls. Conclusion: This systematic review concludes that silk products’ structural, immune, and wound-healing modulating properties are advantageous clinical assets. Nevertheless, more studies are needed to strengthen and establish the benefit of those products. © 2023 by the authors.",TestAnalysis
"The Iliad is a masterpiece of Western culture and a source of meaning for the clarification of human communication. The study of the poem has focused on an analysis based on the referential meaning of the value concepts, eliding the conversational background from which they emerge and acquire meaning. In this article, this background is studied through an amalgamation of discursive psychology and the psychology of world visions. With the discursive action model, speech acts, attitudes, values and contexts displayed by the characters in conversational sequences god-god, hero-hero and god-hero are analyzed. It was found that there is a prevalence of direct executive and behavioral speech patterns, active objective attitudes, individualistic competitive values and contradiction contexts. With this approach, a new vitality is given to the conceptual study of the Homeric poem and new studies are projected. © 2023 Pontificia Universidad Catolica de Chile. All rights reserved.",TestAnalysis
"Topic modeling methods such as latent Dirichlet allocation (LDA) are powerful tools for analyzing massive amounts of textual data. They have been used extensively in information systems (IS) and business discipline research to identify latent topics for data exploration and as a feature engineering mechanism to derive new variables for analyses. However, existing topic modeling approaches are mostly unsupervised and only leverage textual data, while ignoring additional useful metadata often associated with text, such as star ratings in customer reviews or categories of posts in online forums. As a result, the identified topics and variables derived based on the learned topic model may not be accurate, which could lead to incorrect estimations that affect subsequent empirical analysis and to inferior performance on predictive tasks. In this study, we propose a novel supervised deep topic modeling approach called sDTM, which combines a neural variational autoencoder model and a recurrent neural network. sDTM leverages the auxiliary data associated with text to enhance the topic modeling capability. We conduct empirical case studies and predictive analytics on an online consumer review data set and an online knowledge community data set. Experimental results show that in comparison with benchmark methods, sDTM can enhance both the empirical estimation and predictive performance. sDTM makes methodological contributions to the IS literature and has direct relevance for research using text analytics. © 2022 INFORMS.",TestAnalysis
"Research in computational textual aesthetics has shown that there are textual correlates of preference in prose texts. The present study investigates whether textual correlates of preference vary across different time periods (contemporary texts versus texts from the 19th and early 20th centuries). Preference is operationalized in different ways for the two periods, in terms of canonization for the earlier texts, and through sales figures for the contemporary texts. As potential textual correlates of preference, we measure degrees of (un)predictability in the distributions of two types of low-level observables, parts of speech and sentence length. Specifically, we calculate two entropy measures, Shannon Entropy as a global measure of unpredictability, and Approximate Entropy as a local measure of surprise (unpredictability in a specific context). Preferred texts from both periods (contemporary bestsellers and canonical earlier texts) are characterized by higher degrees of unpredictability. However, unlike canonicity in the earlier texts, sales figures in contemporary texts are reflected in global (text-level) distributions only (as measured with Shannon Entropy), while surprise in local distributions (as measured with Approximate Entropy) does not have an additional discriminating effect. Our findings thus suggest that there are both time-invariant correlates of preference, and period-specific correlates. © 2023 by the authors.",TestAnalysis
"The Internet of Things (IoT) has pervaded practically all aspects of our lives. In this exploratory study, we survey its applications in the field of education. It is evident that technology in general, and, in particular IoT, has been increasingly altering the educational landscape. The goal of this paper is to review the academic literature on IoT applications in education to provide an understanding of the transformation that is underway. Using topic modeling and keyword co-occurrence analysis techniques, we identified five dominant clusters of research. Our findings demonstrate that IoT research in education has mainly focused on the technical aspects; however, the social aspects remain largely unexplored. In addition to providing an overview of IoT research on education, this paper offers suggestions for future research. © 2023, Journal of Information Systems Education. All Rights Reserved.",TestAnalysis
"Different spices have been reported containing antimicrobial compounds that can prevent or reduce the microbiological spoilage or pathogenic bacteria in meat or poultry products with various results. This study evaluated the effect of essential oils and extracts of spices in reducing bacteria in meat/poultry products using a meta-analysis approach by comparing the Hedges’d effect size (standardized mean difference, SMD, and 95% confidence interval, CI). A total of 240 data, extracted from 10 articles that were selected by Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) from 121 full-text articles, were analyzed using Meta Essential tools. The results showed that essential oils had a better cumulative significant effect in reducing bacterial loads of meat/poultry products (SMD=-4.37, 95%CI=-5.63 to -3.10) in comparison to the extracts (SMD=-3.66, 95%Cl=-4.56 to -2.76). As essential oils, cassia (SMD=-58.17, 95%CI=-109.88 to -6.47) showed the best effect size, whereas as extract, ganghwayassuk (SMD=-4.19, 95%CI=-6.22 to -2.16) was the most significant. Furthermore, the total plate count was significantly affected by cassia (SMD=-58.17, 95%CI=-109.88 to -6.47), Enterobacteriaceae by sage (SMD=-5.93, 95%CI=-8.32 to -3.54), and coliform also by sage (SMD=-3.79, 95%CI=-6.76 to -0.82). In general, Salmonella spp. was found as pathogenic bacterium that was the most affected (SMD=-19.68 and 95%CI=-39.01 to -0.35). In the form of essential oils, dipping was the best way in reducing microorganisms, while as extracts, adding them in the products was the best method. This study provided reliable data in selecting spices for applications to improve the quality and safety of meat and poultry products. © 2023 Penerbit Universiti Kebangsaan Malaysia. All rights reserved.",TestAnalysis
"User-generated content is critical for tourism destination management as it could help them identify their customers' opinions and come up with solutions to upgrade their tourism organizations as it could help them identify customer opinions. There are many reviews on social media, and it is difficult for these organizations to analyze them manually. By applying sentiment classification, reviews can be classified into several classes and help ease decision-making. The reviews contain noisy contents, such as typos and emoticons, which could affect the accuracy of the classifiers. This study evaluates the reviews using Support Vector Machine and Random Forest models to identify a suitable classifier. The main phases in this study are data collection, preparation, labeling, and modeling. The reviews are labeled into three sentiments; positive, neutral, and negative. During pre-processing, steps such as removing the missing value, tokenization, case folding, stop words removal, stemming, and applying n-grams are performed. The result of this research is evaluated by looking at the performance of the models based on accuracy, where the result with the highest accuracy is chosen as the solution. In this study, data is data from TripAdvisor and Google reviews using web scraping tools. The findings show that the Support Vector Machine model with 5-fold cross-validation is the most suitable classifier with an accuracy of 67.97% compared to Naive Bayes with 61.33% accuracy and the Random Forest classifier with 63.55% accuracy. In conclusion, the result of this paper could provide important information in tourism besides determining the suitable algorithm to be used for Sentiment Analysis related to the tourism domain. © 2023, Universitas Ahmad Dahlan. All rights reserved.",TestAnalysis
"The composition of the Al-’Arabiyyatu baina Yadaika (ABY) Arabic language textbook perpetuates gender inequality. This textbook not only constitutes language elements but also incorporates texts and illustrations that depict gender dynamics. This research examines the representation of gender imbalance in the composition of the textbook, including its contents and illustrations, and analyzes the portrayal of gender roles as depicted in the textbook’s examples. The study is founded on data gathered from reviewing, recording, and analyzing the textbook, with consideration given to gender relationships. The focal point of this research analysis is the ABY textbook, tailored for non-native Arabic speakers. The findings of the study reveal that the construction of the Arabic language textbook perpetuates a gender-unbalanced representation in both the text and visual depictions of males and females. This study advocates for the development of language textbooks that promote gender equality and fairness in their social and cultural elements. © 2023 Muassomah, Halimi, Yasmadi, Kamal, Zaini, and Jasmine.",TestAnalysis
"Video-based action quality assessment (AQA) is a non-trivial task due to the subtle visual differences between data produced by experts and non-experts. Current methods are extended from the action recognition domain where most are based on temporal pattern matching. AQA has additional requirements where order and tempo matter for rating the quality of an action. We present a novel dataset of ranked TikTok dance videos, and a pairwise AQA method for predicting which video of a same-label pair was sourced from the better dancer. Exhaustive pairings of same-label videos were randomly assigned to 100 human annotators, ultimately producing a ranked list per label category. Our method relies on a successful detection of the subject’s 2D pose inside successive query frames where the order and tempo of actions are encoded inside a produced String sequence. The detected 2D pose returns a top-matching Visual word from a Codebook to represent the current frame. Given a same-label pair, we generate a String value of concatenated Visual words for each video. By computing the edit distance score between each String value and the Gold Standard’s (i.e., the top-ranked video(s) for that label category), we declare the video with the lower score as the winner. The pairwise AQA method is implemented using two schemes, i.e., with and without text compression. Although the average precision for both schemes over 12 label categories is low, at 0.45 with text compression and 0.48 without, precision values for several label categories are comparable to past methods’ (median: 0.47, max: 0.66). © 2023, Universitas Ahmad Dahlan. All rights reserved.",TestAnalysis
"There is scarce research assessing the productivity of scientific articles on forestry topics. The objective of this study was to analyze the scientific production on forestry topics that originated in Mexico and were published in Mexican journals from 1996 to 2019 and to identify the causes that determine the impact factor of such publications and the space-time evolution of forestry research in Mexico. In addition, to analyze whether researchers tend to publish in journals published by their affiliation institutions. The study considered 2384 scientific articles from seven journals belonging to category VI of Biotechnology and Agricultural Sciences listed in the Journals Classification System by the National Council of Science and Technology that publishes forestry topics. Bibliometric indicators were generated through text mining and analysis of co-authorship networks. It was found that forestry research in Mexico from 1996 to 2019 presented exponential growth in the number of publications. Forestry scientific production was concentrated in the center of the country. It was dominated by researchers from three of 122 institutions: Instituto Nacional de Investigaciones Forestales, Agrícolas y Pecuarias (13.88%), Colegio de Postgraduados (12.50%), and Universidad Autonoma Chapingo (10.44%). The journals with the highest number of publications were: Revista Mexicana de Ciencias Forestales (26.51%), Revista Chapingo Serie Ciencias Forestales y del Ambiente (20.34%), and Madera y Bosques (18.88%). Results show that forestry researchers in Mexico published mostly in journals edited by their affiliation institutions, which restricts constructive criticism of peer review and increases academic endogamy. Also showed the need to generate more forestry research for the southeast of the country on topics such as climate change, carbon capture, forest biometry, and remote perception, which are relevant aspects when we consider that no published research evaluated the development of the forestry sector in Mexico. © 2023 by the authors.",TestAnalysis
"This article examines the portrayal of Islam and Muslim women in Renaissance England by considering the historical framework and the changes in the attitudes towards Islam at that time. It contends that Renaissance drama has presented Islam as the Other and the Muslim world as antithetical to Christendom. This article examines two specific Muslim women characters in two early English plays, Queen Tota in Thomas Heywood’s The Fair Maid of the West Parts I and II, and the Turkish queen in George Peele’s The Battle of Alcazar. The work relies on the ideas of several critics, historians and theorists in its analysis of these dramatic works. The two texts are read from a New Historicist perspective. Historical, socio-political and economic factors prevalent during the time are brought back to life and the plays will be explored in light of these. © The Author(s)",TestAnalysis
"This article [1] has been retracted at the request of the corresponding author. The reason for retracting the article is: ""Three isolates (HID9047, HID9048, and HID9049) were listed in the original text as belonging to subgroup 2a during phylogenetic analysis. However, it was later determined by adding PEDV reference strains that they actually belonged to subgroup 2b. Therefore, we retract the former article"". © 2023 The Korean Society of Veterinary Science.",TestAnalysis
"The task of analyzing sentiment has been extensively researched for a variety of languages. However, due to a dearth of readily available Natural Language Processing methods, Urdu sentiment analysis still necessitates additional study by academics. When it comes to text processing, Urdu has a lot to offer because of its rich morphological structure. The most difficult aspect is determining the optimal classifier. Several studies have incorporated ensemble learning into their methodology to boost performance by decreasing error rates and preventing overfitting. However, the baseline classifiers and the fusion procedure limit the performance of the ensemble approaches. This research made several contributions to incorporate the symmetries concept into the deep learning model and architecture: firstly, it presents a new meta-learning ensemble method for fusing basic machine learning and deep learning models utilizing two tiers of meta-classifiers for Urdu. The proposed ensemble technique combines the predictions of both the inter- and intra-committee classifiers on two separate levels. Secondly, a comparison is made between the performance of various committees of deep baseline classifiers and the performance of the suggested ensemble Model. Finally, the study’s findings are expanded upon by contrasting the proposed ensemble approach efficiency with that of other, more advanced ensemble techniques. Additionally, the proposed model reduces complexity, and overfitting in the training process. The results show that the classification accuracy of the baseline deep models is greatly enhanced by the proposed MLE approach. © 2023 by the authors.",TestAnalysis
"The think-aloud method is a widely used method for evaluating the usability of websites and software. However, it can also be used with cartographic products, an area which has been neglected up to now. It is a method in which test participants verbalise all their thought processes aloud. The participants are given a test scenario containing tasks to be completed. The method aims to reveal the participants’ subjective attitudes toward a product in order to evaluate its usability. The present paper describes the use of the think-aloud method to evaluate the usability of a cartographic work—the regional atlas of the Moravian-Silesian Region. The study includes (I) a complete review of the method, based on the studies conducted; (II) testing tools for working with recorded data; (III) designing an experiment for evaluating the usability of the atlas; and (IV) the resulting qualitative and quantitative evaluation of the atlas based on the obtained results. During the study, three approaches were proposed to process and analyse the audio recordings. The first option was to separate the audio recordings into individual annotations and analyse them. The second option was to convert the recordings to text and perform a linguistic analysis. The third supplementary option was to use all the material produced and to analyse it subjectively and retrospectively, from the researcher’s perspective. All three options were used in the final assessment of the atlas. Based on the participants’ statements, any shortcomings in the studied atlas were identified for each topic (e.g., non-dominant maps or exceedingly complex infographics), and recommendations for their elimination were proposed. © 2023 by the authors.",TestAnalysis
"ChatGPT has shown the potential of emerging general artificial intelligence capabilities, as it has demonstrated competent performance across many natural language processing tasks. In this work, we evaluate the capabilities of ChatGPT to perform text classification on three affective computing problems, namely, big-five personality prediction, sentiment analysis, and suicide tendency detection. We utilize three baselines, a robust language model (RoBERTa-base), a legacy word model with pretrained embeddings (Word2Vec), and a simple bag-of-words (BoW) baseline. Results show that the RoBERTa model trained for a specific downstream task generally has a superior performance. On the other hand, ChatGPT provides decent results and is relatively comparable to the Word2Vec and BoW baselines. ChatGPT further shows robustness against noisy data, where the Word2Vec model achieves worse results due to noise. Results indicate that ChatGPT is a good generalist model that is capable of achieving good results across various problems without any specialized training; however, it is not as good as a specialized model for a downstream task. © 2001-2011 IEEE.",TestAnalysis
"Named Entity Recognition (NER) is an important task in Natural Language Processing, as it is a key information extraction sub-task with numerous applications, such as information retrieval and machine learning. However, resources are still scarce for some languages, as it is the case of Portuguese. Thus, the objective of this research is to map NER techniques, methods and resources for the Portuguese language. Manual and automated searches were applied, retrieving 447 primary studies, of which 45 were included in our review. The growing number of studies reveal a greater interest of researchers in the area. 21 studies focused on the comparative analysis between techniques and tools. 24 new or updated NER corpora were mapped, in several domains. The most used text pre-processing techniques were tokenization, embeddings, and PoS Tagging, while the most used methods/algorithms were based on BiLSTM, CRF, and BERT models. The most relevant researchers, institutions and countries were also mapped, as well as the evolution of publications. © 2023 Sociedad Espanola para el Procesamiento del Lenguaje Natural. All rights reserved.",TestAnalysis
"In this paper, we analyzed the performance of different transformer models for regret and hope speech detection on two novel datasets. For the regret detection task, we compared the averaged macro-scores of the transformer models to the previous state-of-the-art results. We found that the transformer models outperformed the previous approaches. Specifically, the roberta-based model achieved the highest averaged macro F1-score of 0.83, beating the previous state-of-the-art score of 0.76. For the hope speech detection task, the bert-based, uncased model achieved the highest averaged-macro F1-score of 0.72 among the transformer models. However, the specific performance of each model varied slightly depending on the task and dataset. Our findings highlight the effectiveness of transformer models for hope speech and regret detection tasks, and the importance of considering the effects of context, specific transformer architectures, and pre-training on their performance. © 2023 by the authors.",TestAnalysis
"With a never-ending stream of reviews propagating online, consumers encounter countless good and bad reviews. Depending on which reviews consumers read, they get a different impression of the product. In this paper, we focused on the relationship between the text and numerical information of reviews to gain a better understanding of the decision-making process of consumers affected by the reviews. We evaluated the decisions that consumers made when encountering the review structure of star ratings paired with comments, with respect to three research questions: (1) how consumers compare two products with reviews, (2) how they individually perceive a product based on the corresponding reviews, and (3) how they interpret star ratings and comments. Through the user study, we confirmed that consumers consider reviews differently according to product presentation conditions. When consumers were comparing products, they were more influenced by star ratings, whereas when they were evaluating individual products, they were more influenced by comments. Additionally, consumers planning to buy a product examined star ratings by more stringent criteria than those who had already purchased the product. © 2023 by the authors.",TestAnalysis
"This paper aims to account for the formation of governance networks with strong power to influence Uruguayan educational policies, constituted by a diversity of actors with a common interest in disputing the traditional hegemony of public education in the country. The starting point is a conceptual framework influenced by the post-foundationalist perspective in the social sciences, which is particularly interested in the constitution of political networks and governance networks in the framework of the promotion and definition of educational policies. A methodological strategy based on a network ethnography perspective (Howard, 2002) is proposed, based on the analysis of institutional documents, educational policy texts, various websites and press releases. The paper aims to show the incidence of two local think tanks (CERES and Eduy21) in the production of meanings and proposals that dispute the public meaning of education in Uruguay. The text is part of a broader research entitled ""Disputes around the public nature of education in Uruguay"" (Martinis, 2022), based in the Grupo de Estudios en Políticas y Prácticas Educativas of the Facultad de Humanidades y Ciencias de la Educación of the Universidad de la República de Uruguay. © 2023 Grupo de Investigacion FORCE. All rights reserved.",TestAnalysis
"mHealth interventions have been reported to improve adherence to long-term therapies in chronic conditions. Therefore, this study aimed at determining the effectiveness of mHealth interventions in medication adherence among patients with cardiovascular diseases (CVDs), a leading cause of mortality globally. Relying on our inclusion criteria and the PRISMA recommendations, a literature search was carried out in the PubMed, Medline, and ProQuest databases for primary studies that investigated the impact of mHealth on medication adherence for cardiovascular disease (CVD) between 2000–2021. A total of 23 randomized controlled trials with 34,915 participants matched the selection criteria. The mHealth interventions used included text messages, mobile phone applications, and voice calls, which were used either as a single intervention or combined. Additionally, studies on enhancing drug adherence had contradictory findings: most of the studies elaborated positive results; however, six studies were unable to reveal any significant effect. Finally, a risk bias analysis revealed varying outcomes across all studies. This review, as a whole, supported the notion that mHealth interventions can be effective in improving adherence to CVD medication even though they could not improve adherence to all CVD medications when compared with controls. Further trials with more refined designs integrated with comprehensive interventions are needed to produce better health outcomes. © 2023 by the authors.",TestAnalysis
"This study aims to understand the effects of face mask on speech production between Mandarin Chinese and English, and on the automatic classification of mask/no mask speech and individual speakers. A cross-linguistic study on mask speech between Mandarin Chinese and English was then conducted. Continuous speech of the phonetically balanced texts in both Chinese and English versions were recorded from thirty native speakers of Mandarin Chinese (i.e., 15 males and 15 females) with and without wearing a surgical mask. The results of acoustic analyses showed that mask speech exhibited higher F0, intensity, HNR, and lower jitter and shimmer than no mask speech for Mandarin Chinese, whereas higher HNR and lower jitter and shimmer were observed for English mask speech. The results of classification analyses showed that, based on the four supervised learning algorithms (i.e., Linear Discriminant Analysis, Naïve Bayes Classifier, Random Forest, and Support Vector Machine), undesirable performances (i.e., lower than 50%) in classifying the speech with and without a face mask, and highly-variable accuracies (i.e., ranging from 40% to 89.2%) in identifying individual speakers were achieved. These findings imply that the speakers tend to conduct acoustic adjustments to improve their speech intelligibility when wearing surgical mask. However, a cross-linguistic difference in speech strategies to compensate for intelligibility was observed that Mandarin speech was produced with higher F0, intensity, and HNR, while English was produced with higher HNR. Besides, the highly-variable accuracies of speaker identification might suggest that surgical mask would impact the general performance of the accuracy of automatic speaker recognition. In general, therefore, it seems wearing a surgical mask would impact both acoustic-phonetic and automatic speaker recognition approaches to some extent, thus suggesting particular cautions in the real-case practice of forensic speaker identification. Copyright: © 2023 Geng et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Nowadays, in communications, the main criteria are ensuring the digital information and communication in the network. The normal two users' communication exchanges confidential data and files via the web. Secure data communication is the most crucial problem for message transmission networks. To resolve this problem, cryptography uses mathematical encryption and decryption data on adaptation by converting data from a key into an unreadable format. Cryptography provides a method for performing the transmission of confidential or secure communication. The proposed AES (Advanced Encryption Standard)-based Padding Key Encryption (PKE) algorithm encrypts the Data; it generates the secret key in an unreadable format. The receiver decrypts the data using the private key in a readable format. In the proposed PKE algorithm, the sender sends data into plain Text to cypher-text using a secret key to the authorized person; the unauthorized person cannot access the data through the Internet; only an authorized person can view the data through the private key. A method for identifying user groups was developed. Support vector machines (SVM) were used in user behaviour analysis to estimate probability densities so that each user could be predicted to launch applications and sessions independently. The results of the proposed simulation offer a high level of security for transmitting sensitive data or files to recipients compared to other previous methods and user behaviour analysis. © 2023 International Journal on Recent and Innovation Trends in Computing and Communication. All rights reserved.",TestAnalysis
"Following the results of a qualitative study on Virginie Despentes’ reception in Spain carried out between 2018 and 2022, we propose an analysis of one of the French author’s texts, considering existing theoretical contributions on translation studies from a feminist perspective. Through the comparative analysis between the source text and the Spanish translation of Despentes’ novel Les Chiennes savantes (1996), we reflect on the relationship nowadays between literature, translation and reception. © 2023 Facultad de Filologia - Universidad de La Laguna. All rights reserved.",TestAnalysis
"Objective: The human papillomavirus (HPV) vaccine is regarded as one of the most effective ways of preventing cervical cancer. Despite the massive burden of this disease, only two countries in the Eastern Mediterranean Region (EMR) have implemented a national HPV vaccination program. The aim of the present study was to assess the main barriers to the integration of HPV vaccination in the national vaccination programs of EMR countries. Material and Methods: We performed a narrative review with no inclusion and exclusion criteria. The electronic databases we searched included Medline, Scopus, Embase, and Web of Science (last update; December 2021). The search was not subject to any limitation in terms of time or method. Studies that dealt with the obstacles or the needs of vaccination programs in EMR countries were included in the investigation. Results: After a full-text screening, the report comprised of 31 studies from 15 EMR countries. All of the studies were descriptive. The most common barriers to HPV vaccination are the following: a) lack of knowledge and awareness, b) economic barriers in terms of the cost-effectiveness of the HPV vaccination program, c) social insecurity in conflict zones, d) cultural norms and religion. Conclusion: EMR countries should focus on modifiable barriers to the vaccination program. Steps to improve HPV vaccination coverage in these countries should include enhancing social awareness and mobilization, ensuring the support of the Global Alliance for Vaccines and Immunization in eligible countries, using national resources in an optimal way, and addressing HPV vaccination in undergraduate medicine and paramedic curriculums. (J Turk Ger Gynecol Assoc 2023; 24: 48-56). © 2023 by the Turkish-German Gynecological Education and Research Foundation.",TestAnalysis
"Background: In August 2017, the European Commission awarded the “European Study on Clinical Diagnostic Reference Levels (DRL) for X-ray Medical Imaging” project to the European Society of Radiology to provide up-to-date Diagnostic Reference Levels based on clinical indications. This work aimed to conduct an extensive literature review by analyzing the most recent studies published and the data provided by the National Competent Authorities to understand the current situation regarding Diagnostic Reference Levels based on clinical indications for Radiation Therapy Computed Tomography. Objective: To review the literature on established DRLs and methodologies for establishing Diagnostic reference levels in radiation therapy planning computed tomography (RTCT). Methods: Eligibility criteria: A cohort study (observational design) reporting DRLs in adult patients undergoing computed tomography (CT) for radiation therapy for the region head and neck or pelvis were included. The comprehensive literature searches for the relevant studies published between 2000 and 2021 were performed using PubMed, Scopus, CINHAL, Web of Science, and ProQuest. Results: Three hundred fifty-six articles were identified through an extensive literature search. Sixty-eight duplicate reports were removed. The title and abstract of 288 studies were assessed and excluded if they did not meet the inclusion criteria. Sixteen of 288 articles were selected for full-text screening (studies conducted between 2000 and 2021). Five articles were included in the review after the full-text screening. Conclusions: A globally approved standard protocol that includes scanning techniques, dose measurement method, and DRL percentile needs to be established to make a valuable and accurate comparison with international DRLs. © 2023 by the authors.",TestAnalysis
"Despite many studies on translation and power, little has been done to examine the power relations in tourism translation. This systematic literature review aims to investigate publications on tourism translation and power in the translation field. With Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) as the framework, this study employed two primary journal databases in English and Chinese, namely Scopus and CNKI. Following an eight-step guide, a total of eight articles, including seven journals and one book chapter, were included in the final research. Based on systematic literature review and thematic analysis methods, four main themes were identified concerning the power issues in tourism translation. The first theme showed the subjective exertion of power by the translators in tourism translation to promote tourism in a destination. The second theme demonstrated the power exertion in translating tourism texts for economic reasons. The third and fourth themes referred to ideology-related and culture-related power exertion in the process of translating tourism texts. Apart from the emerging themes, the most notable study outcome indicated three research gaps in tourism translation and power, concerning language pairs, translation strategies, and research methodology. © 2023 Authors. All rights reserved.",TestAnalysis
"Background: International public health strategies indicate a need for equitable resources for wellness in younger children and their caregivers. Reflective functioning, a proxy for emotional regulation abilities, is a key area in this domain. As an emerging area, reflective functioning has not been mapped comprehensively and requires systematic investigation. This review examines “what qualitative and quantitative evidence is there for the value of reflective functioning assessment and intervention studies in caregiver–child dyads?” Methods: This scoping review focused on data published to September 2021, focusing on caregivers of children ≤36 months of age (including Medline, PsycINFO, CINAHL, ERIC, Scopus, Web of Science, and Embase). Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews guidelines were followed. Results: From 5162 initial articles, 608 papers were screened for full text yielding a final 181 papers. Only 69 studies included multiple ethnicities. Seven of the 69 studies included at least 1 Indigenous person. No studies were conducted in low-to middle-income countries, and no studies reported data on gender identity. Conclusion: This review comprises a novel and comprehensive mapping of the reflective functioning literature in terms of both assessment and intervention studies. The present mapping of the reflective functioning literature indicates the importance of health disparities in caregiver–child dyads (these include gaps and needs for future research). In relation to gaps, studies of adverse childhood experience, consideration of equity, diversity, and inclusion, and global mental health are underrepresented. Future research is needed to provide information on the relevance of gender identity and low-to middle-income countries in relation to the impact on reflective functioning in this context. © 2023, AVES. All rights reserved.",TestAnalysis
"When a severe diagnosis is made before or after birth, perinatal palliative care (PPC) can be provided to support the infant, parents and involved healthcare providers. An integrative and systematic overview of effectiveness and working components of existing PPC programs was needed. An integrative search was conducted in MEDLINE, Embase, CENTRAL, CINAHL, PsycInfo and Web of Science. Study designs examining the effect of PPC compared to regular care, and (empirical) articles describing the components of care included in existing PPC initiatives were included. Three independent authors reviewed titles, abstracts and full texts against eligibility criteria. PRISMA guidelines were followed; 21.893 records were identified; 69 publications met inclusion criteria. Twelve publications (17.4%) discussed the effect of a PPC program. Other publications concerned the description of PPC programs, most often by means of a program description (22/69; 31.9%), guidelines (14/769; 20.3%) or case study (10/69; 14.5%). Outcome measures envisioned four main target categories: care coordination, parents and family members, care for the fetus/neonate and healthcare providers. No trials exist to date. Analysis of working components revealed components related to changes directed to the policy of the hospital wards and components involving actual care being provided within the PPC program, directed to the fetus or infant, the family, involved healthcare providers or external actors. PPC is a growing research field where evidence consists mainly of descriptive studies and guidelines. The extensive list of possible PPC components can serve as a checklist for developing future initiatives worldwide. PPC includes several important actors: the fetus/infant and their family and included healthcare providers on both maternity and neonatal wards. This leads to a large variety of possible care components. However, while some studies show proof of concept, an evidence base to determine which components are actually effective is lacking. © 2023 by the authors.",TestAnalysis
"Problems of the analysis of natural language texts are considered. In particular, approaches to the partial solution to problems of logical consistency/inconsistency of facts derived from the text, searching for antimems, and constructing ontologies based on the results of the linguistic (semantic-syntactic) analysis of the text are proposed. Logical analysis of the text is performed on the basis of the propositional calculus and methods of proof in this calculus. © 2023, Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"Backgrounds and Objectives: Multiple sclerosis is a common cause of neurological disabilities worldwide. Diet is a potential risk factor for the pathogenesis of multiple sclerosis and dietary intervention can be used as a prevention method for multiple sclerosis. The purpose of this study was the investigation of relationships between the type of meat consumed by the patients and multiple sclerosis. Materials and Methods: In this systematic review and meta-analysis, Persian and English databases were searched, including PubMed, MEDLINE, Web of Science, Scopus, Google Scholar, Springer, Cochrane library, Magiran and Gray Literature (Bibliograph, Congress abstracts), for the publications of 1998–2020, using keywords of meat, fish meat, red meat, multiple sclerosis, processed and non-processed meat. Out of 186 selected articles, 30 full-text articles were entered into the quality assessment process and results of 10 articles were analyzed in this study. Results: The sample size of ten selected studies was 11024. Statistically significant decreasing effects were identified for white meat on multiple sclerosis disease with the odds ratio of 0.81 [95% confidence interval (0.74, 0.88)] and significant correlations were detected between non-processed meat and multiple sclerosis with the odds ratio of 0.85 [95% confidence interval (0.75, 0.95)]. Calculated odds ratio between the processed meat and multiple sclerosis was 1.21 [95% confidence interval (0.93, 1.49)]. Conclusion: Processed red meat consumption increases risks of multiple sclerosis. Diets of non-processed red meats as well as white meats include protective effects on this disease. © 2023, National Nutrition and Food Technology Research Institute. All rights reserved.",TestAnalysis
"Digital learning environments afford intensive and rapid interaction for learners, which leads to a learning duration within a short learning period. Therefore, it is essential to know how to design information presentations when the learning duration is short and learning tasks are intensive. The current study designed learning tasks with different types of vocabulary glosses (e.g., corresponding pictures or sounds) and learning duration (3, 5, or 7 seconds per word). Learning results were analyzed considering learners’ word recognition and passive recall of the meaning of vocabulary with descriptive analysis. Learners' characteristics (i.e., working memory capacity, executive function, and strategy in allocating information) were collected and analyzed through three types of phonological working memory capacity tests, one visuospatial working memory capacity test, and a vocabulary encoding survey. The result indicates that text-only glosses with 3s per word (15s whole learning task) learning duration led to the highest learning result in supporting learners' word recognition. Meanwhile, text + picture glosses with 5s per word (25s whole learning task) lead to the highest learning result in learners' passive recall of vocabulary meaning. However, when the learning duration is extended, image glosses may become redundant information. Besides, the result indicates that learners with higher phonological working memory, may store more redundant phonological information which disturbs the information processes. However, if learners have a better executive function, the negative effects may be relieved. © 2023 AsiaTEFL All rights reserved.",TestAnalysis
"Negative, tragic, traumatic and suffering representations continue to dominate the discussions and content on social media in the stories and content related to Syrian refugees. The public, while browsing social media, finds that this representation is the dominant one that dominates the image of refugees. Thus, there is a potential risk that the public’s compassion will be negatively affected after repeated exposure to the dominant representation in light of the inability to put an end to that situation. This study discusses the perspectives of Syrian refugees living in Jordan and Turkey on whether they feel such repeated negative and tragic content about their stories and news on social media could affect the empathy of the audience in hosting communities with them, especially since social media is an open-source platform that all people at any time and from any place can post, re-share, comment and create content by adding texts, photos and videos, not like traditional media, which are controlled more than social media platforms for open participatory content. This study aims to explore how a vulnerable population, such as Syrian refugees in Istanbul and Amman, sees the effect of negative representation on themselves and their image in the hosting communities and does not aim to examine or offer any conclusion as to whether the public in Jordan and Turkey have experienced compassion fatigue. This study provides and extracts some useful insights, but proves no hypotheses or conclusive evidence regarding the occurrence of compassion fatigue in the public; thus, the study opens the door for the debate on the role that social media plays as a source of compassion fatigue among citizens towards refugees, mainly when they are repeatedly exposed to such negative stories and content, as well as calls for an in-depth and extensive study on the topic from the point of view of the public and citizens in the hosting countries, after examining, understanding and analyzing the opinions and their dimensions of the sample of refugees in this study. © 2023 by the author.",TestAnalysis
"This article discusses the ways in which the practical benefit of poetry, as a source of healing power to reduce distress, is enhanced through incorporating a detailed analysis of literary texts and their sources that relate to the author's depiction of the human predicament and suggestions for liberation from it. This article focuses on two Romantic poems as case studies, Percy Bysshe Shelley's ""Mutability""(1816) and John Keats's ""Ode on Melancholy""(1820), to highlight an effective way of inspiring students to recognize the poets' representations of anxiety and their poems' therapeutic effects. By pointing out the limitations of recent studies promoting the curative power of poetry, the article examines precise literary aspects of the two works, which facilitate the relief from inner affliction for readers as they discuss in detail the concept of affliction in its association with the realities of instability and depression. It suggests a method of providing poetry education that reveals the paradox of suffering and self-remedy and thereby reinforces comprehension. © 2023 Board of Trustees of the University of Illinois.",TestAnalysis
"Background: Croton tiglium Linn. (CT) which is commonly called Jaypal is used in Ayurvedic preparations like Ichhabhedi Ras, Asvakancuki Rasa. Due to its toxic contents, seeds of Croton tiglium are purified before use, by the process mentioned in classical Ayurvedic texts called Shodhana meaning purification. Objectives: The objective of the present study is to study the impact of Ayurvedic Purification process on cytotoxicity and genotoxicity of Croton tiglium Linn. Materials and methods: Croton tiglium Linn. Seeds were processed for Shodhana by soaking in water, heating with milk (Snehan) and later grinding in Lemon Juice (Bhavana). Aqueous and Hydroalcoholic extracts were prepared before and after purification i.e. Shodhana. Cytotoxicity of the Croton tiglium was studied against Chinese Hamster Ovary cell line by MTT assay. Ames test was performed to study the mutagenicity of the extracts in Salmonella typhi TA 98, 100 and 102 strains. Phytoconstituents were studied by using LCMS analysis. Results: The results indicated decrease in cytotoxic concentration (IC50) of Croton tiglium seeds after purificationa from 3.03 mg/mL to 0.99 mg/mL in aqueous extract and 18.56 mg/mL to 5.45 mg/mL. Genotoxicity study by Ames test indicated Croton tiglium Linn. Croton tiglium Linn. Seeds are non-genotoxic in strains like S. typhi, TA 98, 100 and 102. There was change in Phytochemical profile before and after shodhana. Conclusion: Although both the concentrations are practically non-toxic, the decrease in cytotoxic concentration indicates Purification process as described in classical ayurvedic texts i.e. Shodhana has definitely increased the potency of the seeds of Croton tiglium Linn. © 2023 The Authors",TestAnalysis
"This study aims to evaluate the applicability of a text mining approach for extracting UUX-related issues from a dataset of user comments and not to evaluate the Instagram (IG) app. This study analyses textual data mined from reviews in English written by IG mobile application users. The article's authors used text mining (based on the LDA algorithm) to identify the main UUX-related topics. Next, they mapped the identified topics with known theoretical constructs to place them in their nomological network relevant to the usability (the 5Es framework by Quesenbery) and UX (the Honeycomb model by Morville). Finally, to expand the study with an emotional diagnosis, sentiment analysis was performed on two levels: (i) for each recognised topic, and (ii) for the full dataset to uncover general insights into users' emotions within all reviews. The case study of the IG app confirms the usefulness of user feedback data for software development and points out that the review data have the potential for the early detection of frustration and negative feelings introduced during the use of the application. Conducting conventional UUX evaluations with users is problematic since they are remotely located, and the user-generated content of a social app undergoes continuous and frequent changes. Thus, the consecutive stages of the proposed methodology, based on text mining algorithms, constitute a proposed framework for examining the user-perceived quality projection of applications from user feedback, and they are the main contribution of this article. The used approach can be valuable for helping developers, designers and researchers to reveal user problems and fulfil user satisfaction regarding UUX aspects for specific software features.  © 2023 Anna Baj-Rogowska et al., published by Sciendo.",TestAnalysis
"Sentiment analysis (SA) is an area of study currently being investigated in text mining. SA is the computational handling of a text’s views, emotions, subjectivity, and subjective nature. The researchers realized that generating generic sentiment from textual material was inadequate, so they developed SA to extract expressions from textual information. The problem of removing emotional aspects through multi-labeling based on data from certain aspects may be resolved. This article proposes the swarm-based hybrid model residual networks with sand cat swarm optimization (ResNet-SCSO), a novel method for increasing the precision and variation of learning the text with the multi-labeling method. Contrary to existing multi-label training approaches, ResNet-SCSO highlights the diversity and accuracy of methodologies based on multi-labeling. Five distinct datasets were analyzed (movies, research articles, medical, birds, and proteins). To achieve accurate and improved data, we initially used preprocessing. Secondly, we used the GloVe and TF-IDF to extract features. Thirdly, a word association is created using the word2vec method. Additionally, the enhanced data are utilized for training and validating the ResNet model (tuned with SCSO). We tested the accuracy of ResNet-SCSO on research article, medical, birds, movie, and protein images using the aspect-based multi-labeling method. The accuracy was 95%, 96%, 97%, 92%, and 96%, respectively. With multi-label datasets of varying dimensions, our proposed model shows that ResNet-SCSO is significantly better than other commonly used techniques. Experimental findings confirm the implemented strategy’s success compared to existing benchmark methods. © 2023 by the authors.",TestAnalysis
"The boom in artificial intelligence and automated technology in the journalistic profession has given rise to what are called synthetic media (Crusafon, 2022), media outlets that produce and publish texts, audio, videos, and other news content through processes executed solely by algorithms, without any intervention from journalists. This research has several objectives: to identify the first synthetic media outlets already operating, to describe how these newsrooms without journalists work, to better understand the type of content they produce, and to find out whether these are iso-lated and ephemeral operations or if, on the contrary, they mark the beginning of a trend toward journalism without the direct intervention of journalists. To this end, we have used an exploratory methodology, enabling us to identify four synthetic media outlets, which have been taken as an analysis sample: JX Press Corp (Japan); Reuters News Tracer (United Kingdom), News Republic (France), and Videre AI (Spain). An analysis of the news content on each project’s web pages was combined with in-depth semistructured interviews with the heads of technology and communication of the three European ventures. The Japanese initiative has no human staff, so its chatbot was the only way to obtain information. The purpose was to learn about the initiatives’ news production process, their impact on the journalistic profession, and their viability. This analysis helps demonstrate that the journalistic world’s reliance on artificial intelligence is becoming increasingly evident and that communication agencies are the first companies to invest in developing and distributing synthetic content to benchmark media. These initiatives, although still limited, are the most recent step in the process of gradually integrating artificial intelligence into news production. © 2023, El Profesional de la Informacion. All rights reserved.",TestAnalysis
"Research finds that lexical bundles are vital to fluent language processing as they reduce cognitive load when memorized as chunked sequences of language, especially for second-language (L2) learners. Although lexical bundles in academic and political discourse have been studied, their use in podcasts is a less-researched domain in corpus linguistics even though podcasts are an increasingly popular medium that offers authentic public discourse for diverse audiences, including L2 learners and instructors. To address this gap, this study investigates the most frequently occurring and widely dispersed lexical bundles in an English-language, general-audience Saudi podcast. A specific corpus consisting of 10 podcast episodes (almost one hour each) was submitted to AntConc for the identification of lexical bundles based on three predefined parameters: length, frequency, and distribution. A lexical bundle was extracted if it consisted of a four-word sequence that occurred at least five times in at least five texts. From a podcast corpus of 111,174 words, 56 four-word lexical bundles were identified and ranked according to frequency, and their grammatical structures were analyzed. Results show that lexical bundles such as thank you so much, a lot of people, be honest with you, and and I was like are high on the list. Structurally, they consist of nominal, verb-based, and prepositional phrases among others, although verb-based bundles are the most common. The study concludes by providing a list of lexical bundles that may be used for podcast-based learning practice in a L2 listening class or for independent learning. Copyrights Copyright for this article is retained by the author(s), with first publication rights granted to the journal.",TestAnalysis
"Dysgraphia is a neurodevelopmental disorder specific to handwriting. Classical diagnosis is based on the evaluation of speed and quality of the final handwritten text: it is therefore delayed as it is conducted only when handwriting is mastered, in addition to being highly language-dependent and not always easily accessible. This work presents a solution able to anticipate dysgraphia screening when handwriting has not been learned yet, in order to prevent negative consequences on the individuals’ academic and daily life. To quantitatively measure handwriting-related characteristics and monitor their evolution over time, we leveraged the Play-Draw-Write iPad application to collect data produced by children from the last year of kindergarten through the second year of elementary school. We developed a meta-model based on deep learning techniques (ensemble techniques and Quasi-SVM) which receives as input raw signals collected after a processing phase based on dimensionality reduction techniques (autoencoder and Time2Vec) and mathematical tools for high-level feature extraction (Procrustes Analysis). The final dysgraphia classifier can identify “at-risk” children with 84.62% Accuracy and 100% Precision more than two years earlier than current diagnostic techniques. © 2023 by the authors.",TestAnalysis
"Writing is a complex process at the center of much of modern human activity. Despite appearing to be a linear process, writing conceals many highly non-linear processes. Previous research has focused on three phases of writing: planning, translation and transcription, and revision. While research has shown these are non-linear, they are often treated linearly when measured. Here, we introduce measures to detect and quantify subcycles of planning (exploration) and translation (exploitation) during the writing process. We apply these to a novel dataset that recorded the creation of a text in all its phases, from early attempts to the finishing touches on a final version. This dataset comes from a series of writing workshops in which, through innovative versioning software, we were able to record all the steps in the construction of a text. 61 junior researchers in science wrote a scientific essay intended for a general readership. We recorded each essay as a writing cloud, defined as a complex topological structure capturing the history of the essay itself. Through this unique dataset of writing clouds, we expose a representation of the writing process that quantifies its complexity and the writer’s efforts throughout the draft and through time. Interestingly, this representation highlights the phases of “translation flow”, where authors improve existing ideas, and exploration, where creative deviations appear as the writer returns to the planning phase. These turning points between translation and exploration become rarer as the writing process progresses and the author approaches the final version. Our results and the new measures introduced have the potential to foster the discussion about the non-linear nature of writing and support the development of tools that can lead to more creative and impactful writing processes. Copyright: © 2023 Lo Sardo et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Legal judgments are generally very long, and relevant information is often scattered throughout the text. To complete a legal judgment summarization, capturing important, relevant information comprehensively from a lengthy text is crucial. The existing abstractive-summarization models based on pre-trained language have restrictions on the length of an input text. Another concern is that the generated summaries have not been well integrated with the legal judgment’s technical terms and specific topics. In this paper, we used raw legal judgments as information of different granularities and proposed a two-stage text-summarization model to handle different granularities of information. Specifically, we treated the legal judgments as a sequence of sentences and selected key sentence sets from the full texts as an input corpus for summary generation. In addition, we extracted keywords related to technical terms and specific topics in the legal texts and introduced them into the summary-generation model as an attention mechanism. The experimental results on the CAIL2020 and the LCRD datasets showed that our model achieved an overall 0.19–0.41 improvement in its ROUGE score, as compared to the baseline models. Further analysis also showed that our method could comprehensively capture essential and relevant information from lengthy legal texts and generate better legal judgment summaries. © 2023 by the authors.",TestAnalysis
"Aim: The aim of this study was to evaluate the effect upon postoperative pain in teeth of patients suffering from apical periodontitis or necrotic pulp when treated with calcium hydroxide and compare it with other intracanal medicaments. Materials and Methods: MEDLINE database, PubMed and Google Scholar databases were searched based on the filters and inclusion and exclusion criteria. The screening was done to finally acquire 9 articles from the mass of searched articles. The data extraction followed the screening process, and qualitative and quantitative data were recorded. The risk of bias was conducted with the Cochrane Collaboration tool, and meta-analysis was done using Review Manager version 5.3. Results: A total of 9 studies over the past five decades met the inclusion criteria for full-text reading, and all 9 of them were included for further analysis. When we assessed for pain outcome, in comparison with CHX and Ca(OH), the cumulative mean difference was -4.57 (confidence interval: -16.25, 7.11). The heterogeneity was significant I 2 = 95%, hence we applied the random effects model. The mean difference showed that the mean pain outcome was more in the control (Ca(OH)) group, as compared to the intervention group. Conclusion: Calcium hydroxide is effective in reducing posttreatment pain when it is used alone, but its effectiveness can be increased when used in combination with other medicaments such as chlorhexidine.  © 2023 Indian Journal of Medical Research, published by Wolters Kluwer - Medknow for Director-General, Indian Council of Medical Research.",TestAnalysis
"In avian species, heat stress (HS) is usually the result of being exposed to high ambient temperatures, whereas oxidative stress (OS) results from the overproduction of reactive oxygen species. The current literature suggests that HS often leads to OS. Therefore, this systematic review and meta-analysis was conducted to assess the effects of dietary supplementation of glutamine on the antioxidant status and growth performances in heat-stressed broilers. A total of 13 studies were deemed eligible after an exhaustive search of the literature from Google Scholar, PubMed, and Scopus. Briefly, the following criteria were used to select the studies: trials performed on broilers; publication in peer-review journals using English as the text language; and sufficient details about the design and inclusion of dietary glutamine as a treatment for HS. Two main categories of outcomes were extracted from the studies included in the review: growth parameters and OS markers. For the meta-analysis, a random effect model was used when the heterogeneity was higher than 50%, and a fixed effect model was applied otherwise. Pooled standardized mean differences (SMD), and mean differences (MD) with their confidence intervals (CI) from the studies revealed that dietary glutamine could increase body weight gain (SMD = 0.70, CI = 0.50 to 0.90, p < 0.05), and feed intake (FI) (SMD = 0.64, CI = 0.43 to 0.86, p < 0.05), and reduce the feed conversion ratio (MD = −0.05, CI = −0.07 to −0.02, p < 0.05) in heat-exposed birds. Additionally, higher glutamine (SMD = 1.21, CI = 1.00 to 1.43, p < 0.05), glutathione (SMD = 1.25, CI = 0.88 to 1.62, p < 0.05), superoxide dismutase (SOD) (SMD = 0.97, CI = 0.58 to 1.36, p < 0.05), and catalase (SMD = 0.94, CI = 0.72 to 1.16, p < 0.05) levels were recorded in the serum, breast, and thigh muscle after supplementation of glutamine. Furthermore, the subgroup analysis revealed that malondialdehydes levels were decreased only in the serum (SMD = −0.83, CI = −1.25 to −0.41, p < 0.001) and thigh muscle (SMD = −1.30, CI = −1.86 to −0.35, p < 0.001) while glutathione peroxidase (GPX) activity was increased in the breast (SMD = 1.32, CI = 0.95 to 1.68, p < 0.05) and thigh muscle (SMD = 1.53, CI = 1.06 to 1.99, p < 0.05). Meta-regression models indicated that longer periods of heat exposure were inversely associated with the effectiveness of dietary glutamine in increasing FI, GPX, and SOD (p < 0.05). Besides, increasing the dietary concentration of glutamine led to higher GPX and SOD levels (p < 0.05). Taken together, results suggest that dietary supplementation of glutamine can effectively mitigate the deleterious effects of HS by enhancing the antioxidant status and increasing growth performances in broilers. © 2023 by the authors.",TestAnalysis
"Synagogues remain among the best studied institutions of Late Antiquity. Associated scholarship commonly considers activities of prayer or scriptural recitation once conducted within synagogues and impacts of their architectural and visual programs on visitors. Yet, regardless of recent interest in embodied dimensions of ancient life, attention to Jews’ sensory experiences inside these buildings remains rare. As inspired by Karaite critiques of Jewish practices of lighting lamps and incense in late ancient synagogues, this analysis addresses this lacuna by taking a distinctive approach. It reconsiders diverse artifacts discovered in excavations of synagogues and their surroundings in the Levant, North Africa, and Europe, including fragments of glass, stone, bronze, and ceramic lamps; preserved images in floor mosaics; and remains of bronze and ceramic censers. Read in tandem with rabbinic textual evidence from Roman Palestine, assessments of these texts and artifacts inspire considerations of how historical uses of lamps and incense burners implicate atmospheric elements of ancient synagogues, including experiential illumination and olfaction, which heretofore evaded notice. The ensuing discussion thus inspires new vantages on Jewish sensory and devotional landscapes in past time and challenges bifurcated notions of public versus private expressions of piety among Jews inside their synagogues, homes, and study halls. © 2023 Johns Hopkins University Press.",TestAnalysis
"Assigning predefined classes to natural language texts, based on their content, is a necessary component in many tasks in organizations. This task is carried out by classifying documents within a set of predefined categories using models and computational methods. Text representation for classification purposes has traditionally been performed using a vector space model due to its good performance and simplicity. Moreover, the classification of texts via multilabeling has typically been approached by using simple label classification methods, which require the transformation of the problem studied to apply binary techniques, or by adapting binary algorithms. Over the previous decade, text classification has been extended using deep learning models. Compared to traditional machine learning methods, deep learning avoids rule design and feature selection by humans, and automatically provides semantically meaningful representations for text analysis. However, deep learning-based text classification is data-intensive and computationally complex. Interest in deep learning models does not rule out techniques and models based on shallow learning. This situation is true when the set of training cases is smaller, and when the set of features is small. White box approaches have advantages over black box approaches, where the feasibility of working with relatively small sets of data and the interpretability of the results stand out. This research evaluates a weighting function of the words in texts to modify the representation of the texts during multilabel classification, using a combination of two approaches: problem transformation and model adaptation. This weighting function was tested in 10 referential textual data sets, and compared with alternative techniques based on three performance measures: Hamming Loss, Accuracy, and macro- (Formula presented.). The best improvement occurs on the macro- (Formula presented.) when the data sets have fewer labels, fewer documents, and smaller vocabulary sizes. In addition, the performance improves in data sets with higher cardinality, density, and diversity of labels. This proves the usefulness of the function on smaller data sets. The results show improvements of more than 10% in terms of macro- (Formula presented.) in classifiers based on our method in almost all of the cases analyzed. © 2023 by the authors.",TestAnalysis
"Denture stomatitis is a common inflammation of the palatal mucosa beneath removable dentures. The objective of this article was to examine the systematic reviews and clinical trials pertaining to the treatment of denture stomatitis. For this research, electronic databases (PubMed, Embase, Scopus, and ISI Web of Science) were searched from January 2000 to June 2021 using specified MESH keywords. Irrelevant articles were eliminated in three steps based on their titles, abstracts, and body texts. In the final analysis, 47 papers were selected, which included 12 systematic reviews and 35 clinical trials. Herbal compounds and denture disinfection were the interventions most commonly indicated. We concluded that, possibly due to the complex nature of this lesion's etiology, there is no present definitive therapy guideline for this prevalent lesion.  © 2023 Nader Navabi et al., published by Sciendo.",TestAnalysis
"This study aimed at evaluating a PISA-like reading test developed by teachers participating in the teacher training for teaching PISA-like reading. To serve this purpose, an experimental test was administered to 107 students aged 15-16 using a set of text and questions constructed according to the criteria of the PISA Reading test Level 1. Item analysis was performed following the sampling using Rasch Measurement, deemed essential for determining the ideal index of test items relative to students’ ability in making the correct response. The component of the calculation comprises reliability, separation, dan standard error. The Rasch model was constructed manually using Microsoft Excel to obtain the result of the calculation, and a Wright Map was also made manually to illustrate the result of the calculation. The results of the item analysis indicate that the test and the items the teachers constructed have met good criteria. The results revealed an even distribution of test item difficulty at the targeted level. The samples’ ability to make correct answers, however, was decentralized towards the test items of moderate level of difficulty. Only a limited number of students showed good ability in their response to test items of higher difficulty. These findings have the practical implication of advancing PISA-like reading test teaching and writing models by providing more information on teachers' ability to write PISA-like reading test items and the levels of difficulty of the items written by the teachers, as indicated by the students' responses to the test items. © 2023 Agricultural Research Communication Centre. All rights reserved.",TestAnalysis
"Developing reliable, quantifiable, and accessible metrics for dyslexia diagnosis and tracking represents an important goal, considering the widespread nature of dyslexia and its negative impact on education and quality of life. In this study, we observe eye-tracking data from 15 dyslexic and 15 neurotypical Serbian school-age children who read text segments presented on different color configurations. Two new eye-tracking features were introduced that quantify the amount of spatial complexity of the subject’s gaze through time and inherently provide information regarding the locations in the text in which the subject struggled the most. The features were extracted from the raw eye-tracking data (x, y coordinates), from the original data gathered at 60 Hz, and from the downsampled data at 30 Hz, examining the compatibility of features with low-cost or custom-made eye-trackers. The features were used as inputs to machine learning algorithms, and the best-obtained accuracy was 88.9% for 60 Hz and 87.8% for 30 Hz. The features were also used to analyze the influence of background/overlay color on the quality of reading, and it was shown that the introduced features separate the dyslexic and control groups regardless of the background/overlay color. The colors can, however, influence each subject differently, which implies that an individualistic approach would be necessary to obtain the best therapeutic results. The performed study shows promise in dyslexia detection and evaluation, as the proposed features can be implemented in real time as feedback during reading and show effectiveness at detecting dyslexia with data obtained using a lower sampling rate. © 2023 by the authors.",TestAnalysis
"Introduction: Unicornuate uterus is a rare Müllerian anomaly. Its potential association with a rudimentary uterine horn can cause a diagnostic delay. The most common consequences are pelvic pain, hematometra, and endometriosis. Diagnosis of a unicornuate uterus is usually done by imaging combining ultrasound and magnetic resonance imaging. The aim of this systematic review is to assess the role of laparoscopic approach in the management of this rare condition. Methods: A comprehensive search was performed in PubMed, EMBASE, SCOPUS, and Web of Science databases prior to 1 May 2022 according to Preferred Reporting Items for Systematic Reviews and Meta-Analyses statement (PRISMA). The inclusion criteria were: cases of rudimentary horn managed through laparoscopy only; laparoscopic treatment of communicating or noncommunicating uterine horn. Results: The search strategy identified 45 articles. After this first screening, 37 studies were evaluated. The full text of remaining articles was examined. 35 studies were finally included in this article. All included studies were case reports, due to the rarity of this condition. Rudimentary horns were noncommunicating in all cases. Conclusion: The laparoscopic removal of a rudimentary uterine horn could be considered a feasible therapeutic option. An accurate preoperative evaluation is mandatory to assess anatomic variants and to select the optimal and tailored surgical approach, based also on the symptoms complained by the patient. © 2023 S. Karger AG. All rights reserved.",TestAnalysis
"Knowledge management for high-tech products, based on innovative product architectures and components, is a critical issue for market satisfaction. Scientific research has widely investigated the competitive advantage that product knowledge owned by Original Equipment Manufacturers (OEMs) has on product innovation. Nonetheless, the linkage between OEMs’ accumulated knowledge on single modules and customer satisfaction is less explored. The article aims at identifying what level of knowledge OEMs should have on both the single modules and the whole product architecture to achieve better customer satisfaction. The research method uses text mining techniques on patent documents to detect associations of modules and product knowledge with patented technologies. Regression analyses are thereafter performed to test the linkage of such a knowledge with customer satisfaction using SPSS. The explorative analysis of the smartphone industry demonstrates that an effect on the final market is found for specific modules, such as application processor, camera and touchscreen controller. © 2023 The Author(s)",TestAnalysis
"The withdrawal of US troops from Afghanistan and the sub-sequent collapse of the Afghan government threatens the lives, security, and human right of many people. Twitter and other social media platforms took the lead in opinion and sentiment sharing, allowing researchers to make a real-time assessment that may help authorities develop early response strategies. In this study, 362,566 tweets relating to the exit of the US troops from Afghanistan collected between August 11 and 27, 2021, are analyzed using text mining techniques, including sentiment analysis and word cloud analysis. The analysis shows diverse topics on social media related to the fallout, and the general reaction regarding the crisis was negative. © 2023, Tamkang University. All rights reserved.",TestAnalysis
"Ahmad Shamlū (1925-2000), modern Persian poet, is among those creative writers who showcase their mastery of language in translation as well. Among his translated works, which encompass both verse and prose, his translation of Margot Bickel's Pflücke den Tag (1982) and Geh deinen Weg! (1989) is specifically noteworthy for tremendous success and high reception in the TL context, which is arguably beyond that of the original from a literary and critical perspective. As the analysis of sample poems from the two collections reveals, Shamlū's skilful rendition has actually produced poetry in the TL. Away from marginalizing the pivotal role of translation in cross-cultural literary exchanges, this study reflects on the critique of literature in translation and literary reception as prone to downplaying or magnifying the significance of SL text in TL critical and receptive evaluations. The paper initiates with an overview of the status of literary translation and its interface with comparative literature, and then briefly reviews two world-famous works of poetry translation and their reception in host cultures to set them as the background for the argument to be made about Shamlū's translation of Bickel's works.  © 2023 Walter de Gruyter GmbH, Berlin/Boston.",TestAnalysis
"Background: Osteosarcopenia, a combination of osteopenia/osteoporosis and sarcopenia, is a common condition among older adults. While numerous studies and meta-analyses have been conducted on osteoporosis biomarkers, biomarker utility in osteosarcopenia still lacks evidence. Here, we carried out a systematic review to explore and analyze the potential clinical of circulating microRNAs (miRs) shared between osteoporosis/osteopenia and sarcopenia. Methods: We performed a systematic review on PubMed, Scopus, and Embase for differentially expressed miRs (p-value < 0.05) in (i) osteoporosis and (ii) sarcopenia. Following screening for title and abstract and deduplication, 83 studies on osteoporosis and 11 on sarcopenia were identified for full-text screening. Full-text screening identified 54 studies on osteoporosis, 4 on sarcopenia, and 1 on both osteoporosis and sarcopenia. Results: A total of 69 miRs were identified for osteoporosis and 14 for sarcopenia. There were 9 shared miRs, with evidence of dysregulation (up- or down-regulation), in both osteoporosis and sarcopenia: miR-23a-3p, miR-29a, miR-93, miR-133a and b, miR-155, miR-206, miR-208, miR-222, and miR-328, with functions and targets implicated in the pathogenesis of osteosarcopenia. However, there was little agreement in the results across studies and insufficient data for miRs in sarcopenia, and only three miRs, miR-155, miR-206, and miR-328, showed the same direction of dysregulation (down-regulation) in both osteoporosis and sarcopenia. Additionally, for most identified miRs there has been no replication by more than one study, and this is particularly true for all miRs analyzed in sarcopenia. The study quality was typically rated intermediate/high risk of bias. The large heterogeneity of the studies made it impossible to perform a meta-analysis. Conclusions: The findings of this review are particularly novel, as miRs have not yet been explored in the context of osteosarcopenia. The dysregulation of miRs identified in this review may provide important clues to better understand the pathogenesis of osteosarcopenia, while also laying the foundations for further studies to lead to effective screening, monitoring, or treatment strategies. © 2023 by the authors.",TestAnalysis
"This paper proposed a method for improving the XLNet model to address the shortcomings of segmentation algorithm for processing Chinese language, such as long sub-word lengths, long word lists and incomplete word list coverage. To address these issues, we proposed the CWSXLNet (Chinese Word Segmentation XLNet) model based on Chinese word segmentation information enhancement. The model first pre-processed Chinese pretrained text by Chinese word segmentation tool, and proposed a Chinese word segmentation attention mask mechanism by combining PLM (Permuted Language Model) and two-stream self-attention mechanism of XLNet. While performing natural language processing at word granularity, it can reduce the degree of masking between masked and non-masked words for two words belonging to the same word. For the Chinese sentiment analysis task, proposed the CWSXLNet-BiGRU-Attention model, which introduces bi-directional GRU as well as self-attention mechanism in the downstream task. Experiments show that CWSXLNet has achieved 89.91% precision, 91.53% recall rate and 90.71% F1-score, and CWSXLNet-BiGRU-Attention has achieved 92.61% precision, 93.19% recall rate and 92.90% F1-score on ChnSentiCorp dataset, which indicates that CWSXLNet has better performance than other models in Chinese sentiment analysis. © 2023 by the authors.",TestAnalysis
"In the context of today's green development, it is the core task of the financial sector at all levels to enhance the utilisation of resources and to guide the high-quality development of industries, especially to channel funds originally gathered in high-pollution and energy-intensive industries to sectors with green and high-technology, to achieve the harmonious development of the economy and the resources and environment. This paper proposes a green financial text classification model based on machine learning. The model consists of four modules: the input module, the data analysis module, the data category module, and the classification module. Among them, the data analysis module and the data category module extract the data information of the input information and the green financial category information respectively, and the two types of information are finally fused by the attention mechanism to achieve the classification of green financial data in financial data. Extensive experiments are conducted on financial text datasets collected from the Internet to demonstrate the superiority of the proposed green financial text classification method.  © 2023 Ting Zhang, published by Sciendo.",TestAnalysis
"Although vaccination provides substantial protection against COVID, many people reject the vaccine despite the opportunity to receive it. Recent research on potential causes of such vaccine hesitancy showed that those unvaccinated rejected calls to get vaccinated when they stemmed from a vaccinated source (i.e., a vaccination rift). To mend this vaccination rift, it is key to understand the underlying motivations and psychological processes. To this end, we used the voluntary free-text responses comprised of 49,259 words from the original Austrian large-scale data-set (N = 1170) to conduct in-depth psycho-linguistic analyses. These findings indicate that vaccinated message sources elicited longer responses using more words per sentence and simpler language writing more about things rather than themselves or addressing others directly. Contrary to common assumptions, expressed emotions or indicators of cognitive processing did not differ between message source conditions, but vaccinated sources led to more achievement-related expressions. Participant vaccination did not moderate the observed effects but had differential main effects on psycho-linguistic response parameters. We conclude that public vaccination campaigns need to take the vaccination status of the message source and other societal rifts into account to bolster recipients’ achievement. © 2023 by the authors.",TestAnalysis
"Bathsheba’s story is split by a wide chasm of male-dominated texts, spanning from 2 Sam 11–12 on one end to 1 Kgs 1–2 on the other—a literary rift that has long presented a problem for scholars attempting to discern a coherent development and appraisal of Bathsheba’s character throughout. This study highlights the ways in which the biblical depiction of Bathsheba resists simplistic interpretations and instead evinces a coherent, upward crescendo of character development through a combination of literary analysis and the hermeneutic lens of trauma and recovery, the latter of which highlights the suppression and growth of communicative agency throughout. The first section asserts that the trauma of rape is apparent and so recognized in 2 Sam 11:1–4 through its evocative synthesis of contextual setting, Hebrew terminology, and syntax. The second section analyzes 2 Sam 11:5–12:25, paying special attention to instances in which Bathsheba’s body “speaks” (i.e., nonverbal activity). The final section examines the emergence of Bathsheba’s verbal expression in 1 Kgs 1:1–2:25, elucidating an inverse relationship between David’s waning health and Bathsheba’s ascending voice. Together, these sections attest a consistent and coherent development of dynamic resiliency on the part of Bathsheba within the Hebrew text. © 2023 Society of Biblical Literature. All rights reserved.",TestAnalysis
"Stroke survivors are at increased risk of developing depression and cognitive decline. Thus, it is crucial for both clinicians and stroke survivors to be provided with timely and accurate prognostication of post-stroke depression (PSD) and post-stroke dementia (PSDem). Several biomarkers regarding stroke patients’ propensity to develop PSD and PSDem have been implemented so far, leukoaraiosis (LA) being among them. The purpose of the present study was to review all available work published within the last decade dealing with pre-existing LA as a predictor of depression (PSD) and cognitive dysfunction (cognitive impairment or PSDem) in stroke patients. A literature search of two databases (MEDLINE and Scopus) was conducted to identify all relevant studies published between 1 January 2012 and 25 June 2022 that dealt with the clinical utility of preexisting LA as a prognostic indicator of PSD and PSDem/cognitive impairment. Only full-text articles published in the English language were included. Thirty-four articles were traced and are included in the present review. LA burden, serving as a surrogate marker of “brain frailty” among stroke patients, appears to be able to offer significant information about the possibility of developing PSD or cognitive dysfunction. Determining the extent of pre-existing white matter abnormalities can properly guide decision making in acute stroke settings, as a greater degree of such lesioning is usually coupled with neuropsychiatric aftermaths, such as PSD and PSDem. © 2023 by the authors.",TestAnalysis
"Aims: Currently, virtual reality (VR) constitutes a vital aspect of digital health, necessitating an overview of study trends. We classified type A studies as those in which health care providers utilized VR devices and type B studies as those in which patients employed the devices. This study aimed to analyse the characteristics of each type of studies using natural language processing (NLP) methods. Methods and results: Literature related to VR in cardiovascular research was searched in PubMed between 2010 and 2022. The characteristics of studies were analysed based on their classification as type A or type B. Abstracts of the studies were used as corpus for text mining. A binary logistic regression model was trained to automatically categorize the abstracts into the two study types. Classification performance was evaluated by accuracy, precision, recall, F-1 score, and c-statistics of the receiver operator curve (ROC) analysis. In total, 171 articles met the inclusion criteria, where 120 (70.2%) were type A studies and 51 (29.8%) were type B studies. Type A studies had a higher proportion of case reports than type B studies (18.3% vs. 3.9%, P = 0.01). As for abstract classification, the binary logistic regression model yielded 88% accuracy and an area under the ROC of 0.98. The words 'training', '3d', and 'simulation' were the most powerful determinants of type A studies, while the words 'patients', 'anxiety', and 'rehabilitation' were more indicative for type B studies. Conclusions: NLP methods revealed the characteristics of the two types of VR-related research in cardiology.  © 2023 The Author(s). Published by Oxford University Press on behalf of the European Society of Cardiology.",TestAnalysis
"Background: Aortic stenosis (AS) is the world's most prevalent heart valve disease. Transcatheter aortic valve replacement (TAVR) or Implantation (TAVI) is widely available yet adopting this procedure in Asia has been slow due to high device cost, the need for specific training programs, and the lack of specialized heart teams and dedicated infrastructures. The limited number of randomized controlled trials describing TAVI outcomes among the Asian population hampered the approval for medical reimbursements as well as acceptance among surgeons and operators in some Asian countries. Methods: A comprehensive medical literature search on TAVI and/or TAVR performed in Asian countries published between January 2015 and June 2022 was done through MEDLINE and manual searches of bibliographies. The full text of eligible articles was obtained and evaluated for final analysis. The event rates for key efficacy and safety outcomes were calculated using the data from the registries and randomized controlled trials. Results: A total of 15,297 patients were included from 20 eligible studies. The mean patient age was 82.88 ± 9.94 years, with over half being females (62.01%). All but one study reported Society of Thoracic Surgeons (STS) scores averaging an intermediate risk score of 6.28 ± 1.06%. The mean logistic European Systems for Cardiac Operations Risk Evaluation (EuroSCORE) was 14.85. The mean baseline transaortic gradient and mean aortic valve area were 50.93 ± 3.70 mmHg and 0.64 ± 0.07 cm2, respectively. The mean procedural success rate was 95.28 ± 1.51%. The weighted mean 30-day and 1-year all-cause mortality rate was 1.66 ± 1.21% and 8.79 ± 2.3%, respectively. The mean average for stroke was 1.98 ± 1.49%. The acute kidney injury (AKI) rate was 6.88 ± 5.71%. The overall major vascular complication rate was 2.58 ± 2.54%; the overall major bleeding rate was 3.88 ± 3.74%. Paravalvular aortic regurgitation rate was 15.07 ± 9.58%. The overall rate of pacemaker insertion was 7.76 ± 4.6%. Conclusions: Compared to Americans and Europeans, Asian patients who underwent TAVI had lower all-cause mortality, bleeding, and vascular complications, however, had a higher rate of postprocedural aortic regurgitation. More studies with greater sample sizes are needed among Asian patients for a more robust comparison. © 2023 The Author(s).",TestAnalysis
"Background: Coronavirus disease 2019 (COVID-19) disrupted access to food and adequate nutrition and the types of foods consumed. However, little empiric data exists on the changes in American's food and nutrition habits 2 y into the pandemic. Objectives: To assess current and altered food choices ∼2 y into the COVID-19 pandemic in the months after historic public pandemic relief. Methods: A national sample of 1878 United States adults balanced by age, sex, race/ethnicity, and income completed a one-time, online, semi-quantitative, 44-item questionnaire in Fall 2021 asking about the demographics, COVID-19 food choice changes (including free-text), and consumer priorities. This analysis investigates COVID-19 impacts on food security, healthfulness, and access. Results: More than 35% of respondents reported improved food security and >45% reported improved food healthfulness compared with prepandemic status. Improvement was reported in more than 30% of Black/African-American and Hispanic/Latinx adults, adults with lower annual income, and female sex, despite over 75% reporting reduced choice of where to eat or buy food. The pandemic offered occasion for many to improve diet, but a similar number expressed that the pandemic destabilized healthy habits. Conclusions: Our novel findings suggest that by late 2021, most Americans had improved food security and food choice healthfulness, despite reduced access to food service and retail, although with worsening among a meaningful proportion of Americans as well as heterogeneity in these changes. Vigorous federal, state, city, and community responses to the pandemic may have played a role in improving the food security and food choice healthfulness during the COVID-19 pandemic. Health crises differently impact health behaviors, but when accompanied by vigorous civic and community response, food security, and food healthfulness can be fortified. © 2023 The Authors",TestAnalysis
"The manuscript Yin Shu (The Book of Pulling), excavated from Zhangjiashan Han Tomb No. 247, is the earliest surviving text on therapeutic exercise known as Dao Yin (lit. guiding and pulling). Discovered in 1983, this Dao Yin text, together with the drawings of 44 figures performing ""guiding and pulling"" exercises found in the Mawangdui Han Tomb in 1974, are of great significance to the study of the early history of Dao Yin. Prior to these discoveries, researchers into Dao Yin relied mainly on material found in the Dao Zang (the Daoist Canon), compiled in 1145. This led to their conclusion that Dao Yin was essentially Daoist. The development of Dao Yin reached its zenith during the Sui Dynasty (581-618 CE), when it became one of the three medical departments at the imperial medical education institution. As part of the medical reform of the second Sui Emperor, Yang Di, Dao Yin became the treatment of choice, and the employment of a large number of Dao Yin specialists to the Sui court transformed the state medical service. The compilation of Zhu Bing Yuan Hou Lun (Treatise on the Origins and Manifestations of Various Diseases) under Yang Di's decree, incorporated an abundance of resources on Dao Yin, enabling physicians to potentially ""prescribe"" Dao Yin to their patients. Situating both Yin Shu and Zhu Bing Yuan Hou Lun in their social and historical contexts, this article analyses their editorial treatments, examines their different objectives, styles, and readerships, and compares the various exercises described in the two texts. It emphasizes the fact that over a period of nearly a thousand years, from the late Warring States (475-221 BCE) to the Sui and Tang periods, Dao Yin was an important medical practice, culminating in its institutionalization by the Sui government. © 2023 American Academy of Physician Associates.",TestAnalysis
"Lameness within the dairy industry is a concern because of its associated costs and welfare implications. Visual locomotion scoring has been commonly used for assessing cows’ locomotion quality, but it can have low reliability and is relatively subjective compared to automated methods of assessing locomotion. Kinematic, kinetic, and accelerometric technologies can provide a greater number of more detailed outcome measurements than visual scoring. The objective of this systematic review was to determine outcome measurements, and the relationships between them, that have been recorded using kinematic, kinetic, and accelerometric technologies, as well as other approaches to evaluating cow locomotion. Following PRISMA guidelines, two databases were searched for studies published from January 2000 to June 2022. Thirty-seven articles were retained after undergoing a screening process involving a title and abstract evaluation, followed by a full-text assessment. Locomotion measurements recorded using these technologies often overlapped, but inconsistencies in the types of technology, the arrangement of equipment, the terminology, and the measurement-recording approaches made it difficult to compare locomotion measurements across studies. Additional research would contribute to a better understanding of how factors regarding the health, environment, and management of dairy cows affect aspects of locomotion, as recorded through the detailed, objective outcome measurements provided by these technologies. © 2023 by the authors.",TestAnalysis
"This paper proposes a novel hybrid model for sentiment analysis. The model leverages the strengths of both the Transformer model, represented by the Robustly Optimized BERT Pretraining Approach (RoBERTa), and the Recurrent Neural Network, represented by Gated Recurrent Units (GRU). The RoBERTa model provides the capability to project the texts into a discriminative embedding space through its attention mechanism, while the GRU model captures the long-range dependencies of the embedding and addresses the vanishing gradients problem. To overcome the challenge of imbalanced datasets in sentiment analysis, this paper also proposes the use of data augmentation with word embeddings by over-sampling the minority classes. This enhances the representation capacity of the model, making it more robust and accurate in handling the sentiment classification task. The proposed RoBERTa-GRU model was evaluated on three widely used sentiment analysis datasets: IMDb, Sentiment140, and Twitter US Airline Sentiment. The results show that the model achieved an accuracy of 94.63% on IMDb, 89.59% on Sentiment140, and 91.52% on Twitter US Airline Sentiment. These results demonstrate the effectiveness of the proposed RoBERTa-GRU hybrid model in sentiment analysis. © 2023 by the authors.",TestAnalysis
"There was an error in the original article [1]. Section 8 of the paper uses a simple toy example to illustrate Principal Component Analysis (PCA) of compositional data, using the additive (alr) and centred (clr) logratio transformations. It explains that the clr transformation is preferred because it produces more easily interpretable biplots. However, it failed to mention that, even though the alr- and clr-based PCA configurations of the toy example look similar, they are not the same. This is because the alr transformation is not isometric. Distances in alr-space depend on the choice of denominator, which spells trouble for PCA. As explained in Section 7 of the paper, PCA is a special case of Multidimensional Scaling (MDS). MDS is based on dissimilarity matrices, so if distances are not well defined, then neither are the MDS configuration and, hence, the principal components. The clr transformation fixes this issue. A correction has been made to Section 8 and Figure 5 to clarify this point. It replaces the text from “Consider the following” to “in this context.” with: Consider the following trivariate (a, b and c) dataset of three (1, 2 and 3) compositions that are constrained to a constant sum (ai + bi + ci = 100% for 1 ≤ i ≤ 3, Figure 5): (Formula presented.) It would be wrong to apply conventional PCA to this dataset, because this would ignore the constant sum constraint. As was discussed in Section 6, PCA begins by ‘centering’ the data via the arithmetic mean. Section 3 showed that this yields incorrect results for compositional data. Although the additive logratio transformation (alr) of Equation (1) solves the closure problem, it is not suitable for PCA because it is not isometric. For example, the alr-distance between samples 2 and 3 is 1.74 if b is used as a common denominator, but 2.46 if c is used as a common denominator. The fact that distances are not unequivocally defined in alr-space spells trouble for PCA. Recall the equivalence of PCA and classical MDS, which was discussed in Section 7. MDS is based on dissimilarity matrices, so if distances are not well defined then neither are the MDS configuration and, hence, the principal components. This issue can be solved by the centred logratio transformation (clr): (Formula presented.) where gi is the geometric mean of the ith sample: (Formula presented.) Applying the clr-transformation to the data of Equation (12) yields a new trivariate dataset: (Formula presented.) where g stands for the geometric mean of each row. Note that each of the rows of Xc adds up to zero. Thanks to the symmetry of the clr-coordinates, the distances between the rows (which are also known as Aitchison distances) are well defined. Subjecting Equation (14) to the same matrix decomposition as Equation (8) yields: (Formula presented.) so that (Formula presented.) Note that, even though this yields three principal components instead two, the variance of the third component in matrix V is zero. Therefore, all the information is contained in the first two components. Furthermore, note that the first two principal components of the compositional dataset are identical to those of the PCA example shown in Section 6 (Equation (9)). This is, of course, intentional. A second correction was made to page 6, where “geometric mean” should be replaced with “logratio mean”. The corrected paragraph appears below: “5. Compute the logratio mean composition and add it to the existing ternary diagram as a red square:” “Figure 1. Graphical output of Section 3. Black circles mark 20 synthetic Al2O3, (CaO + Na2O) and K2O compositions, drawn from a logistic normal distribution. The blue square marks the arithmetic mean, which falls outside the data cloud. The blue polygon marks a 2- (Formula presented.) confidence polygon, which plots outside the ternary diagram, in physically impossible negative space. The red square represents the logratio mean, which firmly plots inside the data cloud. The red confidence envelope marks a 95% confidence region calculated using Aitchison’s logratio approach. This confidence envelope neatly fits inside the ternary diagram and tightly hugs the data.” The author states that the scientific conclusions of the remainder of the paper are unaffected. This correction was approved by the Academic Editor. The original publication has also been updated. © 2023 by the author.",TestAnalysis
"Background: Oculocutaneous albinism (OCA) is a genetic disease that causes the impaired conversion of melanin, thus leading to the development of vision impairment and skin/hair-related complications. This disease can also cause extensive psychosocial consequences for patients with this disease. Objectives: This research aimed to provide a deep understanding of the lived experience of people with albinism (PWA) in Iran. Methods: this research has been conducted using a qualitative approach. The sampling was done as purposive and continued until reaching data saturation. The data were collected through deep semi-structured interviews, and then analyzed via thematic analysis, after transcribing the interviews and removing the similar codes, 1077 initial codes were extracted. The categories were coded using open coding indirect process alongside several times of reading the text and allocating relevant codes through constant comparison of codes with each other. Results: The results obtained from data analysis led to extraction of three main themes including: (1) Challenges; (2) perceived sources of support; and (3) psychological mechanisms of coping with challenges. Conclusions: based on the findings of this research, the main challenges of PWA were categorized into two major groups: body-based challenges and psychosocial challenges. The perceived support sources of these people against these challenges were social supports and access to facilitator tools. The psychological mechanisms were divided into adaptive and maladaptive sub-categories. The findings of this research can provide a deeper understanding of the needs of these people for providing optimal care and ultimately promote their psychosocial well-being and also can be employed in developing interpretive theories about the biopsychosocial conditions of PWA. © 2023, Author(s). This is an open-access article distributed under the terms of the Creative Commons Attribution-NonCommercial 4.0 International License (http://creativecommons.org/licenses/by-nc/4.0/) which permits copy and redistribute the material just in noncommercial usages, provided the original work is properly cited.",TestAnalysis
"The Sylloga vocum Atticarum is composed, on the one hand, of the Technologies of the Scholastic Anthology and Manuel Moschopulos' scholia to the poets, on the other, of the Epimerisms of Maximos Planudes.The present essay identifies, in its first part, two important unidentified preliminary stages of the Sylloga, which were formed from Moschopulos's materials, and clarifies the structure of the Planudean Epimerisms. This allows an almost complete analysis of the Sylloga's content. The second part links these results to the life of Moschopulos with the help of the letters of both scholars,. The aim of this paper is to avoid misidentifications of the texts in question and to contribute to the material basis of recent research on intellectual life in the early Paleologan period. © 2023 De Gruyter. All rights reserved.",TestAnalysis
"Background Our aim was to investigate the effectiveness of virtual wards on health outcomes in patients with acute respiratory infection. Methods We searched four electronic databases from January 2000 to March 2021 for randomised controlled trials (RCTs). We included studies in people with acute respiratory illness or an acute exacerbation of a chronic respiratory illness, where a patient or carer measured vital signs (oximetry, blood pressure, pulse) for initial diagnosis and/or asynchronous monitoring, in a person living in private housing or a care home. We performed random-effects meta-analysis for mortality. Results We reviewed 5834 abstracts and 107 full texts. Nine RCTs were judged to be relevant for inclusion, in which sample sizes ranged from 37 to 389 (total n=1627) and mean ages ranged between 61 and 77 years. Five were judged to be at low risk of bias. Five RCTs had fewer hospital admissions in the intervention (monitoring) group, out of which two studies reported a significant difference. Two studies reported more admissions in the intervention group, with one reporting a significant difference. We were unable to perform a meta-analysis on healthcare utilisation and hospitalisation data due to lack of outcome definition in the primary studies and variable outcome measurements. We judged two studies to be at low risk of bias. The pooled summary risk ratio for mortality was 0.90 (95% CI 0.55–1.48). Conclusion The limited literature for remote monitoring of vital signs in acute respiratory illness provides weak evidence that these interventions have a variable impact on hospitalisations and healthcare utilisation, and may reduce mortality. © The authors 2023.",TestAnalysis
"Purpose: As more newborns have received expanded newborn screening (NBS) for metabolic disorders, the overall number of false-positive results has increased. The purpose of this study was to explore the psychological impacts experienced by mothers related to the NBS process. Methods: An online parenting community in Korea was selected, and questions regarding NBS were collected using web crawling for the period from October 2018 to August 2021. In total, 634 posts were analyzed. The collected unstructured text data were preprocessed, and keyword analysis, topic modeling, and visualization were performed. Results: Of 1,057 words extracted from posts, the top keyword based on ‘term frequency-inverse document frequency’ values was “hypothyroidism,” followed by “discharge,” “close examination,” “thyroid-stimulating hormone levels,” and “jaundice.” The top keyword based on the simple frequency of appearance was “XXX hospital,” followed by “close examination,” “discharge,” “breastfeeding,” “hypothyroidism,” and “professor.” As a result of LDA topic modeling, posts related to inborn errors of metabolism (IEMs) were classified into four main themes: “confirmatory tests of IEMs,” “mother and newborn with thyroid function problems,” “retests of IEMs,” and “feeding related to IEMs.” Mothers experienced substantial frustration, stress, and anxiety when they received positive NBS results. Conclusion: The online parenting community played an important role in acquiring and sharing information, as well as psychological support related to NBS in newborn mothers. Nurses can use this study’s findings to develop timely and evidence-based information for parents whose children receive positive NBS results to reduce the negative psychological impact. Copyright © 2023 Korean Society of Women Health Nursing.",TestAnalysis
"Sentiment analysis on social media platforms (i.e., Twitter or Facebook) has become an important tool to learn about users’ opinions and preferences. However, the accuracy of sentiment analysis is disrupted by the challenges of natural language processing (NLP). Recently, deep learning models have proved superior performance over statistical- and lexical-based approaches in NLP-related tasks. Word embedding is an important layer of deep learning models to generate input features. Many word embedding models have been presented for text representation of both classic and context-based word embeddings. In this paper, we present a comparative analysis to evaluate both classic and contextualized word embeddings for sentiment analysis. The four most frequently used word embedding techniques were used in their trained and pre-trained versions. The selected embedding represents classical and contextualized techniques. Classical word embedding includes algorithms such as GloVe, Word2vec, and FastText. By contrast, ARBERT is used as a contextualized embedding model. Since word embedding is more typically employed as the input layer in deep networks, we used deep learning architectures BiLSTM and CNN for sentiment classification. To achieve these goals, the experiments were applied to a series of benchmark datasets: HARD, Khooli, AJGT, ArSAS, and ASTD. Finally, a comparative analysis was conducted on the results obtained for the experimented models. Our outcomes indicate that, generally, generated embedding by one technique achieves higher performance than its pretrained version for the same technique by around 0.28 to 1.8% accuracy, 0.33 to 2.17% precision, and 0.44 to 2% recall. Moreover, the contextualized transformer-based embedding model BERT achieved the highest performance in its pretrained and trained versions. Additionally, the results indicate that BiLSTM outperforms CNN by approximately 2% in 3 datasets, HARD, Khooli, and ArSAS, while CNN achieved around 2% higher performance in the smaller datasets, AJGT and ASTD. © 2023 by the authors.",TestAnalysis
"This article traces the marketing of Scottish brewer Tennent Caledonian’s “Lager Lovelies” beer cans, which featured sexualized photo-graphs of women, from the initial production of the cans in the 1960s to the rebranding of Tennent’s Lager in 1997. The article considers the develop-ment of the cans and situates the marketing in the social and historical con-text. Oral history interviews with former models, industry employees, and people who remember the cans provide insights into people’s attitudes toward the marketing. The images on the cans are examined using visual discourse analysis, which shows that the marketing was derivative of the pervasive sexual objectification of women’s bodies in media and pornogra-phy. The marketing of the cans to White heterosexual men is located within twentieth-century capitalism and patriarchal structures that enabled Ten-nent’s to commodify and objectify women and eroticize an everyday activity like drinking lager. The article considers the end of the Lager Lovelies cans in the early 1990s and the subsequent attempt to reposition Tennent’s Lager in 1997 as a desirable alcoholic drink for younger generations. © 2023 Alcohol and Drugs History Society. All rights reserved. Published by The University of Chicago Press for the Alcohol and Drugs History Society.",TestAnalysis
"Construction companies usually record customer complaints as unstructured texts, resulting in unsuitable information to understand defect occurrences. Moreover, complaint databases are often manually classified, which is time-consuming and error-prone. However, previous studies have not provided guidance on how to improve customer complaint data collection and analysis. This research aims to devise an information management model for customer complaints in residential projects. Using Design Science Research, a study was undertaken at a Brazilian residential building company. Multiple sources of evidence were used, including interviews, participant observations, and analysis of an existing database. Natural language processing (NLP) was used to build a word menu for customers to lodge a complaint. Moreover, a recommendation system was proposed based on machine learning (ML) and hierarchical defect classification. The system was designed to indicate which defects should be investigated during inspections. The main outcome of this investigation is an information management model that provides an effective classification system for customer complaints, supported by artificial intelligence (AI) applications that improve data collection, and introduce some degree of automation to warranty services. The main theoretical contribution of the study is the use of advanced data management approaches for managing complaints in residential building projects, resulting in the combination of inputs from technical and customer perspectives to support decision-making. © 2023 by the authors.",TestAnalysis
"It is commonly thought that Dioscorides’s view on medicine is purely pragmatic, focused entirely on the effectiveness of medicines, and derived from trial and error. One reason for this interpretation is that Dioscorides himself wrote little about his theory of medicine. In this article, however, we argue that he would have arranged De Materia Medica in a way that would have been useful only to a skilled practitioner. This argument implies that Dioscorides had a medical theory, as the arrangement of the content could not have fol-lowed a trial-and-error approach. It is only in the sense of having a theory that he is able to claim that his text is more “complete” than others. This article provides a historical over-view of the text from its genesis to its reception and, ultimately, to its falling out of use. This article concludes with a series of hypotheses on the correspondence between theory and arrangement of the treatise, with the aim of narrowing scholarly conjectures about both. In the final analysis, we argue that an arrangement by family resemblance most closely corresponds to the theory that animates Dioscorides’s text. © 2023 International Society for the History of Philosophy of Science. All rights reserved.",TestAnalysis
"Dental implant is a material used in replacing missing teeth. The osseointegration process of dental implants will be affected by the macrodesign of the fixtures. This study aimed to review the dental implant macrodesign in the past 10 years. This study was conducted in a systematic review method using two electronic databases (PUBMED and Science Direct). Only randomized controlled trials (RCTs) published in the last 10 years were used for this review. All the search results were filtered using Preferred Reporting Items for Systematic Reviews And Meta-Analyses and should fulfill some predefined inclusion criteria. The last step was to assess the methodological quality of the studies using the JBI Checklist for RCT. The search identified 357 studies with only 23 that going through full-text analysis, resulting in 14 articles included in the review. In total, 19 different implant brands were used in 12 different countries. Dental implant macrodesigns were divided into collar design, implant shape, thread geometry, and platform design. The macrodesign features of the implant were mostly developed in the variation of thread geometry and collar design.  © 2023 Indian Society of Periodontology | Published by Wolters Kluwer - Medknow.",TestAnalysis
"Objectives: We aimed to examine the bias for statistical significance using published confidence intervals in sport and exercise medicine research. Design: Observational study. Methods: The abstracts of 48,390 articles, published in 18 sports and exercise medicine journals between 2002 and 2022, were searched using a validated text-mining algorithm that identified and extracted ratio confidence intervals (odds, hazard, and risk ratios). The algorithm identified 1744 abstracts that included ratio confidence intervals, from which 4484 intervals were extracted. After excluding ineligible intervals, the analysis used 3819 intervals, reported as 95 % confidence intervals, from 1599 articles. The cumulative distributions of lower and upper confidence limits were plotted to identify any abnormal patterns, particularly around a ratio of 1 (the null hypothesis). The distributions were compared to those from unbiased reference data, which was not subjected to p-hacking or publication bias. A bias for statistical significance was further investigated using a histogram plot of z-values calculated from the extracted 95 % confidence intervals. Results: There was a marked change in the cumulative distribution of lower and upper bound intervals just over and just under a ratio of 1. The bias for statistical significance was also clear in a stark under-representation of z-values between − 1.96 and + 1.96, corresponding to p-values above 0.05. Conclusions: There was an excess of published research with statistically significant results just below the standard significance threshold of 0.05, which is indicative of publication bias. Transparent research practices, including the use of registered reports, are needed to reduce the bias in published research. © 2023 The Author(s)",TestAnalysis
"This article challenges a common scholarly view regarding Josh 10:1-39, 11:1-15. The first edition of these episodes is commonly attributed to Judean authors. I offer arguments in favor of a northern Israelite provenance of the first edition, assessing the extracts for which there is convincing evidence of such provenance. I also critically examine the arguments in favor of a Judean composition, rejecting some of them, reevaluating others, and determining pieces of text within 10:1-39, 11:1-15 for which there is in fact convincing evidence of Judean authorship. Much of the analysis is focused on the level of familiarity with different regions of Eretz-Israel exhibited in different parts of the text. In addition, any portion within these episodes for which the geographical setting of composition can be determined is placed along the time line of the episodes' textual development. Whenever possible I suggest the approximate date of composition for a text and assess whether the extract under discussion belongs to a relatively early layer or to a late, redactional one. I conclude that the first edition of 10:1-39, 11:1-15 was composed in the northern kingdom of Israel before 722 BCE, and that this edition was later revised and expanded by Judean authors, probably in the seventh century BCE. © 2023 Society of Biblical Literature. All rights reserved.",TestAnalysis
"A theoretical mechanism was analyzed from the micro perspective of the enterprise to explore how information accessibility moderates the effect of accounting manipulation on the sustainable development of digital enterprises. Using data from 1200 listing digital enterprises in China and the DEA-Malmquist index method, the efficiency value of digital enterprises in 2007-2021 was estimated to represent the index of sustainable development of digital enterprises. The accounting manipulation was detected using the panel PSM-DID method based on the Administrative Measures for the Recognition of High-tech Enterprise's policy. The information accessibility value was estimated based on the MDA method. Empirical studies were conducted using text analysis, the panel PSM-DID method, and the double moderating effect model. The results showed that: (1) Accounting manipulation had a negative impact on the sustainable development of ""true""digital enterprises and the ""fake""digital enterprises. (2) Information accessibility directly and positively enhanced the technological progress and scale efficiency of digital enterprises, and its moderating effect was heterogeneous, with a significant moderating effect on the ""true""digital enterprises and a negative effect on the ""fake""ones. © 2023 Wu et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Due to mistakes in tabulating data when preparing the manuscript, the original published version of this article contained errors in the description of the clustering cohort in tables 1 and 3. After reviewing all the data and analysis, the authors concluded that the analysis was performed correctly and that these errors do not change the main message of the published study. The corrected tables are as shown below. The following changes to the text of the paper were also required as a result of these amendments. In the Abstract, Results section, in the following the sentence the p-value has changed from p=0.01 to p=0.02: “Patients from cluster C were more likely to experience an increase in per cent predicted forced expiratory volume in 1 s (FEV1 % pred) ≥5% under lumacaftor–ivacaftor than those in the other clusters (54% of responders versus 32% and 33%; p=0.02).” In the Results, Study population section of the article (second paragraph in that section), the number of “responders” with improvement in FEV1 has changed from 102 to 101: “101 of 283 patients (36%) had an improvement in FEV1 % pred ≥5% in absolute value and were considered as responders.” In the Results, CT morphological phenotype identification section, the sentence that originally read: “The proportion of patients with methicillin-susceptible Staphyloccocus aureus colonisation was significantly higher in cluster C than in the other two clusters (77% for cluster C versus 62% for cluster A and 64% for cluster B, p<0.01).” Has been corrected to: “The proportion of patients with methicillin-resistant Staphyloccocus aureus colonisation was significantly lower in cluster C than in the other two clusters (6% for cluster C versus 26% for cluster A and 21% for cluster B, p=0.01).” In the same section, in the following the sentence the p-value has changed from p=0.01 to p=0.02: “Interestingly, patients from cluster C, who had less morphologically and functionally severe disease, were better responders to treatment than the others (54% of responders in cluster C versus 32% in cluster A and 33% in cluster B, p=0.02).” The article has been corrected and republished online. Copyright © 2023 ERS.",TestAnalysis
"Aims This systematic review aimed to summarize the full range of complications reported following ankle arthroscopy and the frequency at which they occur. Methods A computer-based search was performed in PubMed, Embase, Emcare, and ISI Web of Science. Two-stage title/abstract and full-text screening was performed independently by two reviewers. English-language original research studies reporting perioperative complications in a cohort of at least ten patients undergoing ankle arthroscopy were included. Complications were pooled across included studies in order to derive an overall complication rate. Quality assessment was performed using the Oxford Centre for Evidence-Based Medicine levels of evidence classification. Results A total of 150 studies describing 7,942 cases of ankle arthroscopy in 7,777 patients were included. The overall pooled complication rate was 325/7,942 (4.09%). The most common complication was neurological injury, accounting for 180/325 (55.4%) of all complications. Of these, 59 (32.7%) affected the superficial peroneal nerve. Overall, 36/180 (20%) of all nerve injuries were permanent. The overall complication rate following anterior ankle arthroscopy was 205/4,709 (4.35%) compared to a rate of 35/528 (6.6%) following posterior arthroscopy. Neurological injury occurred in 52/1,998 (2.6%) of anterior cases using distraction, compared to 59/2,711 (2.2%) in cases with no distraction. The overall rate of major complications was 16/7,942 (0.2%), with the most common major complication – deep vein thrombosis – occurring in five cases. Conclusion This comprehensive systematic review demonstrates that ankle arthroscopy is a safe procedure with a low overall complication rate. The majority of complications are minor, with potentially life-threatening complications reported in only 0.2% of patients. © 2023 The British Editorial Society of Bone & Joint Surgery.",TestAnalysis
"Objectives: Pre-pregnancy diet has an important role in preparing for healthy generation. However, evidence on this issue has been scarce. A scoping review synthesising current evidence will support the demand to map ‘what has been researched’ on pre-pregnancy diet and maternal and child health. Methods: Systematic search was performed using PICOS (Population, Intervention, Comparison, Outcomes, and Study design) framework in electronic databases. Articles were screened for eligibility, summarized, and the quality was assessed using the National Institute of Health assessment tool. The review structure complies with Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews guide. Results: Forty-two articles were included after full-text screening. Twenty-five studies were in high-income countries (HICs), six in each upper-middle income, five in lower-middle income countries (LMICs), and one in low-income countries (LIC). Based on the regions: North America (n = 16), Europe (n = 5), South America (n = 4), Australia (n = 4), Asia (n = 5), Middle East (n = 2), and sub-Saharan Africa (n = 1). The two-most observed diet-related exposures were dietary pattern (n = 17) and dietary quality (n = 12). The most assessed outcome was gestational diabetes mellitus (n = 28) and fetal and newborn anthropometry (n = 7). The average quality score±standard deviation was 70±18%. Conclusions: Research related to pre-pregnancy diet is still concentrated in HICs. The context of diet may vary; therefore, future research is encouraged in LMICs and LICs context, and Mediterranean, South-East Asia, Pacific, and African regions. Some maternal and child nutrition-related morbidity, such as anemia and micronutrient deficiencies, have not been discussed. Research on these aspects will benefit to fill in the gaps related to pre-pregnancy diet and maternal and child health. Copyright © 2023 The Korean Society for Preventive Medicine.",TestAnalysis
"Objective: The current systematic review was planned to provide quality assessment of different exercise regimes and their outcomes on the symptoms of polycystic ovary syndrome, and to see if one exercise regime was better than the rest. Methods: Search was conducted on PubMed and Google Scholar databases for studies published between 2001 and 2021 whose full text was available. The search yielded 28 studies that were reviewed. Results: The current evidence suggests that exercise regimes, such as high-intensity interval training, progressive resistance training, aerobic exercises, and yoga may improve polycystic ovary syndrome conditions. This is accomplished through treating associated risk factors, like body morphology, insulin resistance, hyperandrogenism, lipid profile, reproductive hormones, menstrual cycle, and quality of life. Conclusion: Exercise regimes improves several symptoms of polycystic ovary syndrome. However, selecting a specific exercise regime over others as the standardised treatment protocol remained inconclusive. © 2023 Pakistan Medical Association. All rights reserved.",TestAnalysis
"In the original published version of this article, the affiliation for the author Ying Wu was incorrectly listed as School of Management Science and Real Estate, Chongqing University, Chongqing, China. The correct affiliation for Ying Wu is State Grid Zhongxing Co., Ltd. Lvyuan Branch, Beijing, China. The authors apologize for the errors. Both the HTML and PDF versions of the article have been updated to correct the errors. © 2022 The Author(s)",TestAnalysis
"Background: Single herb Ayurvedic lipid-based formulations of Glycyrrhiza glabra are used as oral, nasal and topical applications for reducing radiotherapy induced side effects in oral cavity cancer patients. These formulations are reported to be de-glycyrrhized, thus minimizing adverse effects of glycyrrhizin on longer consumption. Being a proprietary formulation with specific ratio of herb, lipid and liquid media, there is a need of pharmaceutical standardization and stability study to be conducted for quality control and quality assurance. Objective: Standardization of Yashtimadhu Ghrut (YG) and Yashtimadhu Taila (YT) based on pharmaceutical characters, safety tests, chromatographic analysis and stability study. Material and methods: Two formulations viz., YG and YT were prepared using cow's ghee and sesame oil, respectively. Basic physicochemical analysis, Thin Layer Chromatography, High Pressure Liquid Chromatography of glabridin and 18-β glycyrrhetinic acid, microbial load and heavy metal analysis were performed. Long term (0,3,6,9,12 months) as well as accelerated (0,3,6 months) stability study was conducted and extrapolated shelf-life was calculated for both the drugs. Result: Organoleptic and basic physicochemical characters were comparable for both the products while safety parameters were within permissible limits. Extrapolated shelf-life was deduced as 1.74 and 0.67 years for YG and YT, respectively. Conclusion: Single herb- G. glabra based lipid formulations were standardized and monographs were established. Shelf-life, though complying with classical Ayurvedic texts, indicates further research work with respect to pre-treatment of lipids and packaging systems for its enhancement. © 2023 The Authors",TestAnalysis
"Depression is a serious mental health disorder that poses a major public health concern in Thailand and have a profound impact on individuals’ physical and mental health. In addition, the lack of number to mental health services and limited number of psychiatrists in Thailand make depression particularly challenging to diagnose and treat, leaving many individuals with the condition untreated. Recent studies have explored the use of natural language processing to enable access to the classification of depression, particularly with a trend toward transfer learning from pre-trained language model. In this study, we attempted to evaluate the effectiveness of using XLM-RoBERTa, a pre-trained multi-lingual language model supporting the Thai language, for the classification of depression from a limited set of text transcripts from speech responses. Twelve Thai depression assessment questions were developed to collect text transcripts of speech responses to be used with XLM-RoBERTa in transfer learning. The results of transfer learning with text transcription from speech responses of 80 participants (40 with depression and 40 normal control) showed that when only one question (Q1) of “How are you these days?” was used, the recall, precision, specificity, and accuracy were 82.5%, 84.65, 85.00, and 83.75%, respectively. When utilizing the first three questions from Thai depression assessment tasks (Q1 − Q3), the values increased to 87.50%, 92.11%, 92.50%, and 90.00%, respectively. The local interpretable model explanations were analyzed to determine which words contributed the most to the model’s word cloud visualization. Our findings were consistent with previously published literature and provide similar explanation for clinical settings. It was discovered that the classification model for individuals with depression relied heavily on negative terms such as ‘not,’ ‘sad,’, ‘mood’, ‘suicide’, ‘bad’, and ‘bore’ whereas normal control participants used neutral to positive terms such as ‘recently,’ ‘fine,’, ‘normally’, ‘work’, and ‘working’. The findings of the study suggest that screening for depression can be facilitated by eliciting just three questions from patients with depression, making the process more accessible and less time-consuming while reducing the already huge burden on healthcare workers. Copyright: © 2023 Munthuli et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Offline handwritten Chinese recognition is an important research area of pattern recognition, including offline handwritten Chinese character recognition (offline HCCR) and offline handwritten Chinese text recognition (offline HCTR), which are closely related to daily life. With new deep learning techniques and the combination with other domain knowledge, offline handwritten Chinese recognition has gained breakthroughs in methods and performance in recent years. However, there have yet to be articles that provide a technical review of this field since 2016. In light of this, this paper reviews the research progress and challenges of offline handwritten Chinese recognition based on traditional techniques, deep learning methods, methods combining deep learning with traditional techniques, and knowledge from other areas from 2016 to 2022. Firstly, it introduces the research background and status of handwritten Chinese recognition, standard datasets, and evaluation metrics. Secondly, a comprehensive summary and analysis of offline HCCR and offline HCTR approaches during the last seven years is provided, along with an explanation of their concepts, specifics, and performances. Finally, the main research problems in this field over the past few years are presented. The challenges still exist in offline handwritten Chinese recognition are discussed, aiming to inspire future research work. © 2023 by the authors.",TestAnalysis
"Background: Osteosarcopenia, a combination of osteopenia/osteoporosis and sarcopenia, is a common condition among older adults. While numerous studies and meta-analyses have been conducted on the treatment of osteoporosis, the pharmacological treatment of osteosarcopenia still lacks evidence. Denosumab, a human monoclonal antibody, has shown encouraging results for the treatment of osteosarcopenia. Our systematic review and meta-analysis aimed to investi-gate the potential dual role of denosumab as an anti-resorptive agent and for other beneficial muscle-related effects in patients with osteosarcopenia, and to evaluate whether denosumab can be a treatment of choice compared to bisphosphonate. Methods: Relevant literature was collated from the Cochrane Central Register of Controlled Trials (CENTRAL), PubMed, and Google Scholar databases. The primary outcome was denosumab’s effect on lumbar spine bone mineral density (LS BMD), handgrip strength, and gait speed change. The secondary outcome was the effect of denosumab on appendicular lean mass (ALM). The outcomes were presented as mean dif-ference (MD). A random effects model was used in the analysis to represent the population. The risk of bias was assessed using funnel plots. Results: Out of the 3,074 studies found, four full-text studies met the inclusion criteria, including 264 and 244 participants in the intervention and control groups, respectively. Regarding a primary outcome, our meta-analysis showed that deno-sumab showed no significant differences in LS BMD and gait speed changes compared to other agents—MD=0.37, 95% confidence interval (CI),-0.35 to 0.79; p=0.09 and MD=0.11; 95% CI,-0.18 to 0.40; p=0.46, respectively. Denosumab had a significant effect on handgrip strength change compared to standard agents—MD=5.16; 95% CI, 1.38 to 18.94; p=0.007, based on the random effects model. Conclusions: Denosumab was better than bisphosphonate and placebo in improving muscle strength (handgrip strength). Therefore, denosumab may be favored in individuals with osteosarcopenia to improve muscular performance and reduce fall risk. © 2023 by The Korean Geriatrics Society.",TestAnalysis
"A computer vision model known as a generative adversarial network (GAN) creates all the visuals, including images, movies, and sounds. One of the most well-known subfields of deep learning and machine learning is generative adversarial networks. It is employed for text-to-image translations, as well as image-to-image and conceptual image-to-image translations. Different techniques are used in the processing and generation of visual data, which can lead to confusion and uncertainty. With this in mind, we define some solid mathematical concepts to model and solve the aforementioned problem. Complex picture fuzzy soft relations are defined in this study by taking the Cartesian product of two complex picture fuzzy soft sets. Furthermore, the types of complex picture fuzzy soft relations are explained, and their results are also discussed. The complex picture fuzzy soft relation has an extensive structure comprising membership, abstinence, and non-membership degrees with multidimensional variables. Therefore, this paper provides modeling methodologies based on complex picture fuzzy soft relations, which are used for the analysis of generative adversarial networks. In the process, the score functions are also formulated. Finally, a comparative analysis of existing techniques was performed to show the validity of the proposed work. © 2023 by the authors.",TestAnalysis
"Augmented reality (AR) is a significant Fourth Industrial Revolution (IR4.0) technology that employs computer-generated display, sound, text, and effects to enhance the user's real-world experience via wearable devices. Order picking processes have had a substantial influence on overall operational efficiency in warehouse management systems (WMS). The conventional picking process is challenging to handle, which may result in deviations from the intended picking performance. Pick-by-vision, a new technological solution for order picking, is receiving growing attention and is now considered a significant WMS-supporting technology. This article explores the positive implications and prospects of utilizing AR pick-by-vision technology in the warehouse picking processes by performing a narrative review of the previous review articles. To demonstrate the focus of the main area, this study also presents the hierarchical classification structure of AR implementation in WMS and highlights the pick-by-vision method. The analysis provided important key findings by evaluating 23 articles (original articles and case studies) on AR pick-by-vision technology applications, which are significant to the prospective advantages of AR pick-by-vision deployment in warehouse operations. This study gathers knowledge and insight that can be used by both academics and professionals who are interested in optimizing this new advanced technology for future research. © Acta Logistica, www.actalogistica.eu.",TestAnalysis
"Relationship skills coaching is a kind of psychotherapy that helps people to communicate in a healthier way. It helps with personal problems and issues such as, for example: trust, lying, respect, anger-management, communication, conflict, power struggles, abuse, jealousy, romance, intimacy, parenting, in-laws, divorce, loneliness, stress, fear, anxiety, depression, and so on. Currently, relationship skills coaching is becoming a trendy profession in Egypt and many coaches are becoming famous. Many of these coaches communicate with people using their Facebook pages. This paper focuses mainly on a selection of the Facebook posts of two coaches, namely, Howayda Aldemerdash and Waleed Khairy. The study provides a positive discourse analysis (PDA) (Martin, 1995, 2004, 2006) of the selected posts. PDA emphasises the function of discourse construction in motivating change into a better world. The theoretical basis of PDA is Appraisal theory, which focuses on the evaluative resources in discourse and is comprised of three sub-systems: Attitude (people’s feelings and evaluations), Engagement (the voices of the author and texts) and the Graduation system (the different levels and gradability of evaluation). The study provides a significant application of PDA to Arabic discourse and sheds light on the nature of relationship skills coaching in Egypt. The analysis shows that Waleed Khairy deals with issues related to love and trust; whereas Howayda Aldemerdash focuses on the relationship between couples and marital problems. However, both coaches employ the three sub-systems of Appraisal theory to reach out to their followers and construct themselves as authoritative, expert, engaged, and emotional. © 2023 Wesam M. A. Ibrahim.",TestAnalysis
"On June 16, 2018, Beyoncé and Jay-Z released ""Apeshit""-a trap-styled hip hop track featuring a chorus of ""I can't believe we made it / Have you ever seen the crowd going apeshit?""The muchcommented- on music video for the track was framed as a hip hop takeover of the world's most visited museum-Paris's Louvre-featuring pop's reigning power couple, marketed as ""The Carters,""making themselves at home with a collection of dancers in flesh-colored black, brown, and beige bodysuits. While the video was generally received through the split-screen frame of either a cutting decolonial takedown of this monument to Western civilization or the ultimate in money-flaunting bling spectacle, a more subtle and complex set of issues is at play. This article examines the deep historical ambivalences at play in this pop cultural artifact. Employing multi-modal methodologies that combine visual and musical arts perspectives articulated via the frames of postcolonial studies, this analysis theorizes the cultural ""traps""in effect. Ranging from the track's ""trap""sonic production and lyrical rhetoric of escape (""we made it""), to the historical trap of musealized colonial plunder and the Louvre's labyrinthine, oft-subterranean floor plan, to the ""trappings""of consumption, bourgeois self-making, and aesthetic contemplation, we seek to illustrate how this socio-cultural text destabilizes Enlightenment universalism and its public/private split.  © 2023 by the International Association for the Study of Popular Music, U.S. Branch (IASPM-US).",TestAnalysis
"Background: Oropharyngeal squamous cell carcinoma (OPSCC) patients are burdened by the effect of the disease process and treatment toxicities on organs important in everyday activities, such as breathing, speaking, eating, and drinking. There is a rise in OPSCC due to human papilloma virus (HPV)-associated OPSCC, affecting younger and healthier patients and with a better overall prognosis. Emphasis must be shared between oncologic outcomes and the effects on quality of life. While there have been efforts to study global and physical quality of life, the impact on psychosocial quality of life has not yet been specifically reviewed. Methods: A scoping review methodology was employed to explore the emotional, social, and mental quality of life in OPSCC patients and determine the impact of HPV status or treatment modalities. Results: Eighty-seven full-text articles were evaluated for eligibility. Fifteen articles met final inclusion criteria. The majority of the studies were conducted in the United States (n = 10) and study methodology was divided between cross-sectional (n = 6), prospective (n = 5), and retrospective studies (n = 4). Four psychosocial quality of life themes were explored: the impact on mental health and emotional wellbeing, social wellbeing and function, stress, and relationship and sexual behavior. Eighteen different patient-reported outcome measures were used, including both general head and neck oncology questionnaires and symptom-specific surveys. Conclusion: There is a paucity of research regarding the effect of OPSCC on patients’ psychosocial quality of life. Learning more about this component of quality of life can guide outreach programs and multidisciplinary involvement in improving patient care. © 2023 by the authors.",TestAnalysis
"Aim: To provide dental practitioners and researchers with a comprehensive review of the historical development, chemical composition, mechanisms of action, advantages, and drawbacks of different chemomechanical caries removal (CMCR) agents. Methods: An electronic search was performed for all articles published on CMCR agents in various databases, including the Web of Science, PubMed, Cochrane, Scopus, and Google Scholar bibliographic databases, from January 1, 1975, to July 31, 2022. Results: Records were identified using the following search terms: Brix3000, Carie-Care, Caridex, Carisolv, chemomechanical caries removal, conventional surgical method, and Papacárie. A total of 171 articles were screened based on the titles and abstracts, of which 126 were deemed eligible for inclusion after duplicates were removed. Following a manual search of the reference list, eight articles were added. Articles were then excluded for other reasons, such as being written before 1975, being written in a language other than English, and the non-availability of the full text. Overall, 120 articles were included in the analysis (literature reviews [n = 27], systematic reviews [n = 8], research articles [n = 82], case reports [n = 3]). Conclusion: CMCR is a potential method of caries control in the future as an alternative to the conventional surgical approach in standard dentistry applications. It is more widely accepted, less painful, and has comparable efficacy to the conventional surgical method. Clinical significance: A continuous trend among manufacturers has been observed since 1975 to reduce the drawbacks of CMCR agents. Moreover, evidence-based minimally invasive techniques, including CMCR agents that require minimal or no aerosol-generating procedures, are preferred while measures to control the spread of coronavirus disease are in force. © 2023 King Saud University",TestAnalysis
"Information on historical flood levels can be communicated verbally, in documents, or in the form of flood marks. The latter are the most useful from the point of view of public awareness building and mathematical modeling of floods. Information about flood marks can be found in documents, but nowadays, they are starting to appear more often on the Internet. The only problem is finding them. The aim of the presented work is to create a new model for classifying Internet sources using advanced text analysis (including named entity recognition), deep neural networks, and spatial analysis. As a novelty in models of this type, it was proposed to use a matrix of minimum distances between toponyms (rivers and towns/villages) found in the text. The resulting distance matrix for Poland was published as open data. Each of the methods used is well known, but so far, no one has combined them into one ensemble machine learning model in such a way. The proposed SD-NER model achieved an F1 score of 0.920 for the binary classification task, improving the model without this spatial module by 17%. The proposed model can be successfully implemented after minor modifications for other classification tasks where spatial information about toponyms is important. © 2023 by the author.",TestAnalysis
"Mental health and well-being are increasingly important topics in discussions on public health [1]. The COVID-19 pandemic further revealed critical gaps in existing mental health services as factors such as job losses and corresponding financial issues, prolonged physical illness and death, and physical isolation led to a sharp rise in mental health conditions [2]. As such, there is increasing interest in the viability and desirability of digital mental health applications. While these dedicated applications vary widely, from platforms that connect users with healthcare professionals to diagnostic tools to self-assessments, this article specifically explores the implications of digital mental health applications in the form of chatbots [3]. Chatbots can be text based or voice enabled and may be rule based (i.e., linguistics based) or based on machine learning (ML). They can utilize the power of conversational agents well-suited to task-oriented interactions, like Apple's Siri, Amazon's Alexa, or Google Assistant. But increasingly, chatbot developers are leveraging conversational artificial intelligence (AI), which is the suite of tools and techniques that allow a computer program to seemingly carry out a conversational experience with a person or a group.  © 1982-2012 IEEE.",TestAnalysis
"This study aims to analyse the transformation of urban greenery into greenfield housing development from 2019 to 2023 in the medium-sized city of Rzeszow (Poland) by evaluating the validity of references to the greenery in advertising texts on the developers’ websites. Furthermore, to assess the impact of the proposed greenery-related changes on urban green infrastructure. Through web-based research, 13 greenfield housing developments were identified. Changes in land use of areas that were allocated to urban green infrastructure were highlighted by applying GIS spatial analysis. The written and visual content analysis identified references to greenery in advertising campaigns. Finally, status relations analysis was performed to assess whether the specific advertising website presents an added ecological asset that can be considered as a nature-based solution or should be interpreted as greenwashing. The study revealed that the advertising websites for greenfield housing development constructed from 2019 to 2023 in Rzeszow do not represent an additional ecological asset, but committed greenwashing. All analysed housing estates trigger irretrievable environmental damage. The advertising material does not define the environmental indicators of the housing estates, including how the new construction would compensate for the destruction of natural habitats. © 2023 by the authors.",TestAnalysis
"The present study investigated the role of syntactic awareness in reading comprehension among English–French bilinguals learning French as an additional language in Canadian French immersion programs. We examined the direct effect of French syntactic awareness on French reading comprehension as well as the indirect effects mediated through French word reading and French vocabulary. We further examined the extent to which English syntactic awareness contributed to French reading comprehension through cross-language transfer, again considering both the direct effect and the indirect effects through French word reading and French vocabulary. Mediation analyses indicated that, within French, the relationship between French syntactic awareness and French reading comprehension was fully mediated by both French word reading and French vocabulary. In contrast, English syntactic awareness contributed directly to French reading comprehension. Finally, French word reading partially mediated the relationship between English syntactic awareness and French reading comprehension. Our study suggests that children who learn French as an additional language rely on word reading and vocabulary, in addition to French syntactic awareness, to comprehend French texts. Given that English is French immersion children’s stronger language, they use English syntactic awareness to support French reading comprehension both directly and indirectly through French word reading. © 2023 by the authors.",TestAnalysis
"Introduction: Cleft lip and palate (CL/P) are among the most common congenital abnormalities. The purpose of the present study was to review the literature relating to the quality of life (QoL) in young patients with cleft lip and/or palate (CL/P) and to identify the specific aspect of QoL in young patients with CL/P that is mostly affected. Other associated variables within studies that may have an impact on QoL were also identified. Materials and Methods: Systematic searches of PubMed, Scopus and Web of Science databases were conducted. Independent reviewers screened the title, abstract and full texts according to predetermined inclusion and exclusion criteria. Articles published in English from January 2012 to March 2022 reporting the QoL of non-syndromic young patients aged 7–18 years with CL/P were included. Review articles and articles reporting the psychological adjustment of parents or other family members with CL/P were excluded. Results: 975 publications were identified, of which 20 studies met our inclusion criteria. The majority of studies reported that the CL/P condition has a negative impact on the QoL. Psychological health, functional well-being, social-emotional well-being and school environment are domains that are affected. Compared with typically developing young patients, those with CL/P had lower QoL scores even though QoL was assessed using different instruments across studies. The impact of CL/P on overall QoL scores varied by age but not gender or cleft type. Conclusion: Our reviews had shown the presence of CL/P negatively affects the QoL of young patients. Psychological health is the most affected QoL domain. Understanding the impacted domain will help in planning and delivering better health care for individuals with CL/P and reducing the stigma commonly associated with CL/P. Future studies should target intervention on psychological health and consider resilience factors towards positive adjustment. © 2023, Malaysian Medical Association. All rights reserved.",TestAnalysis
"Magnesium, an essential cation for numerous cellular processes, is a major component of bone. However, its relationship with the risk of fractures is still uncertain. The present systematic review and meta-analysis aim to investigate the impact of serum Mg on the risk of incident fractures. A systematic search was conducted using several databases including PubMed/Medline and Scopus from inception to 24 May 2022, including observational studies investigating serum Mg and the incidence of fractures considered as outcomes. Abstract and full-text screenings, data extractions, and risk of bias assessments were conducted by two investigators independently. Any inconsistencies were resolved by consensus with a third author. The Newcastle–Ottawa Scale was used to assess the study quality/risk of bias. Among 1332 records initially screened, 16 were retrieved as full-texts; of them, four papers were included in the systematic review with a total of 119,755 participants. We found that lower serum Mg concentrations were associated with a significantly higher risk of incident fractures (RR = 1.579; 95%CI: 1.216–2.051; p = 0.001; I2 = 46.9%). Our systematic review with meta-analysis suggests a strong association of serum Mg concentrations with incident fractures. Further research is needed to confirm our results among other populations and to assess whether serum Mg is potentially relevant in the prevention of fractures, which continue to increase and represent a significant health burden due to the associated disability. © 2023 by the authors.",TestAnalysis
"Question-asking is a critical aspect of human communications. Yet, little is known about the reasons that lead people to ask questions, which questions are considered better than others, or what cognitive mechanisms allow the ability to ask informative questions. Here, we take a first step towards investigating human question-asking. We do so by an exploratory data-driven analysis of the questions asked by Akinator, a popular online game of a genie who asks questions to guess the character that the user is thinking of. We propose that the Akinator’s question-asking process may be viewed as a reflection of how humans ask questions. We conduct an exploratory data analysis to examine different strategies for the Akinator’s question-asking process, ranging from mathematical algorithms to gamification-based considerations, by analyzing complete games and individual questions. Furthermore, we use topic-modelling techniques to explore the topics of the Akinator’s inquiries and map similar questions into clusters. Overall, we find surprising aspects of the specificity and types of questions generated by the Akinator game, that may be driven by the gamification characteristics of the game. In addition, we find coherent topics that the Akinator retrieves from when generating questions. Our results highlight commonalities in the strategies for question-asking used by people and by the Akinator. © 2023 by the authors.",TestAnalysis
"Background: Perceived injustice (PI) is a multidimensional appraisal cognition comprising the severity of loss consequent to injury, blame, a sense of unfairness, and/or irreparability of loss. PI gained increasing interest in pain research since it potentially contributes to the experience and burden of (chronic) pain. Objectives: This systematic review aimed to determine the prevalence of PI and factors associated with PI in people with pain. Study Design: Systematic review with meta-analysis. Methods: Web of Science, PubMed, and Embase were screened for cross-sectional or cohort studies encompassing human patients who were diagnosed with a condition causing pain and reported prevalence rates for PI and/or associations between a factor and PI. Meta-analyses were carried out, and subgroup analyses were undertaken based on the methodological quality of the studies, the type of pain population, and whether the outcome measure was valid or not in case of heterogeneity (P < 0.05). Results: Fifty-four studies were found eligible. The prevalence of PI ranged from 23% to 77% (I2 = 99%, P < 0.001). Association with PI, assessed using the Injustice Experienced Questionnaire, were found with pain catastrophizing (pooled Pearson’s r [rp ] = 0.66 [0.64, 0.69], P < 0.00001), posttraumatic stress (rp = 0.63 [0.59, 0.67], P < 0.00001), anger (rp = 0.59 [0.49, 0.67], P < 0.00001), anxiety (rp = 0.59 [0.52, 0.64], P < 0.00001), pain acceptance (rp =-0.59 [-0.66,-0.49], P < 0.00001), depressive symptoms (rp = 0.57 [0.52, 0.60], P < 0.00001), kinesiophobia (rp = 0.57 [0.50, 0.64], P < 0.00001), academic functioning (rp =-0.54 [-0.65,-0.41], P < 0.00001), disability (rp = 0.53 [0.47, 0.59], P < 0.00001), emotional functioning (rp =-0.52 [-0.64,-0.39], P < 0.00001), pain interference (rp = 0.49 [0.35, 0.60], P < 0.00001), state anger (rp = 0.48 [0.41, 0.54], P < 0.00001), mental functioning (rp =-0.48 [-0.57,-0.38], P < 0.00001), symptoms of central sensitization (rp = 0.47 [0.39, 0.55], P < 0.00001), social functioning (rp =-0.47 [-0.60,-0.31], P < 0.00001), and physical functioning (rp =-0.43 [-0.53,-0.33], P < 0.00001), pain perceptions (rp = 0.40 [0.40, 0.64], P < 0.00001), trait anger (rp = 0.40 [0.29, 0.49], P < 0.00001), pain intensity (rp = 0.37 [0.33, 0.42], P < 0.00001), and anger inhibition (rp = 0.35 [0.26, 0.43], P < 0.00001). Limitations: Some articles had to be excluded due to the absence of a full-text version. The findings can largely be applied to developed and high-income countries, but further research is needed in developing countries. Also, no validated cutoff values were available for the National Institutes of Health to determine the methodological quality of the included studies. Lastly, high heterogeneity was observed in many of the performed analyses. However, this was addressed by performing subgroup analyses, which could decrease heterogeneity in some cases. Conclusions: The prevalence of PI was ≥ 33% in 75% of the studies indicating that PI is important to consider in people with pain. There is evidence for the association of PI with psychological, pain, and quality of life characteristics in people with pain. The associations of PI with personal, injury, and recovery characteristics were overall not significant or negligible. © 2023, American Society of Interventional Pain Physicians. All rights reserved.",TestAnalysis
"Background HIV testing services (HTS) are the first steps in reaching the UNAIDS 95-95-95 goals to achieve and maintain low HIV incidence. Evaluating the effectiveness of different demand creation interventions to increase uptake of efficient and effective HTS is useful to prioritize limited programmatic resources. This review was undertaken to inform World Health Organization (WHO) 2019 HIV testing guidelines and assessed the research question, “Which demand creation strategies are effective for enhancing uptake of HTS?” focused on populations globally. Methods and findings The following electronic databases were searched through September 28, 2021: PubMed, PsycInfo, Cochrane CENTRAL, CINAHL Complete, Web of Science Core Collection, EMBASE, and Global Health Database; we searched IAS and AIDS conferences. We systematically searched for randomized controlled trials (RCTs) that compared any demand creation intervention (incentives, mobilization, counseling, tailoring, and digital interventions) to either a control or other demand creation intervention and reported HTS uptake. We pooled trials to evaluate categories of demand creation interventions using random-effects models for meta-analysis and assessed study quality with Cochrane’s risk of bias 1 tool. This study was funded by the WHO and registered in Prospero with ID CRD42022296947. We screened 10,583 records and 507 conference abstracts, reviewed 952 full texts, and included 124 RCTs for data extraction. The majority of studies were from the African (N = 53) and Americas (N = 54) regions. We found that mobilization (relative risk [RR]: 2.01, 95% confidence interval [CI]: [1.30, 3.09], p < 0.05; risk difference [RD]: 0.29, 95% CI [0.16, 0.43], p < 0.05, N = 4 RCTs), couple-oriented counseling (RR: 1.98, 95% CI [1.02, 3.86], p < 0.05; RD: 0.12, 95% CI [0.03, 0.21], p < 0.05, N = 4 RCTs), peer-led interventions (RR: 1.57, 95% CI [1.15, 2.15], p < 0.05; RD: 0.18, 95% CI [0.06, 0.31], p < 0.05, N = 10 RCTs), motivation-oriented counseling (RR: 1.53, 95% CI [1.07, 2.20], p < 0.05; RD: 0.17, 95% CI [0.00, 0.34], p < 0.05, N = 4 RCTs), short message service (SMS) (RR: 1.53, 95% CI [1.09, 2.16], p < 0.05; RD: 0.11, 95% CI [0.03, 0.19], p < 0.05, N = 5 RCTs), and conditional fixed value incentives (RR: 1.52, 95% CI [1.21, 1.91], p < 0.05; RD: 0.15, 95% CI [0.07, 0.22], p < 0.05, N = 11 RCTs) all significantly and importantly (≥50% relative increase) increased HTS uptake and had medium risk of bias. Lottery-based incentives and audio-based interventions less importantly (25% to 49% increase) but not significantly increased HTS uptake (medium risk of bias). Personal invitation letters and personalized message content significantly but not importantly (<25% increase) increased HTS uptake (medium risk of bias). Reduced duration counseling had comparable performance to standard duration counseling (low risk of bias) and video-based interventions were comparable or better than in-person counseling (medium risk of bias). Heterogeneity of effect among pooled studies was high. This study was limited in that we restricted to randomized trials, which may be systematically less readily available for key populations; additionally, we compare only pooled estimates for interventions with multiple studies rather than single study estimates, and there was evidence of publication bias for several interventions. Conclusions Mobilization, couple- and motivation-oriented counseling, peer-led interventions, conditional fixed value incentives, and SMS are high-impact demand creation interventions and should be prioritized for programmatic consideration. Reduced duration counseling and video-based interventions are an efficient and effective alternative to address staffing shortages. Investment in demand creation activities should prioritize those with undiagnosed HIV or ongoing HIV exposure. Selection of demand creation interventions must consider risks and benefits, context-specific factors, feasibility and sustainability, country ownership, and universal health coverage across disease areas. This is an open access article, free of all copyright, and may be freely reproduced, distributed, transmitted, modified, built upon, or otherwise used by anyone for any lawful purpose. The work is made available under the Creative Commons CC0 public domain dedication.",TestAnalysis
"The Coronavirus disease 2019 (COVID-19) outbreak impacted health care. We investigated its impact on the time to referral and diagnosis for symptomatic cancer patients in The Netherlands. We performed a national retrospective cohort study utilizing primary care records linked to The Netherlands Cancer Registry. For patients with symptomatic colorectal, lung, breast, or melanoma cancer, we manually explored free and coded texts to determine the durations of the primary care (IPC) and secondary care (ISC) diagnostic intervals during the first COVID-19 wave and pre-COVID-19. We found that the median IPC duration increased for colorectal cancer from 5 days (Interquartile Range (IQR) 1–29 days) pre-COVID-19 to 44 days (IQR 6–230, p < 0.01) during the first COVID-19 wave, and for lung cancer, the duration increased from 15 days (IQR) 3–47) to 41 days (IQR 7–102, p < 0.01). For breast cancer and melanoma, the change in IPC duration was negligible. The median ISC duration only increased for breast cancer, from 3 (IQR 2–7) to 6 days (IQR 3–9, p < 0.01). For colorectal cancer, lung cancer, and melanoma, the median ISC durations were 17.5 (IQR (9–52), 18 (IQR 7–40), and 9 (IQR 3–44) days, respectively, similar to pre-COVID-19 results. In conclusion, for colorectal and lung cancer, the time to primary care referral was substantially prolonged during the first COVID-19 wave. In such crises, targeted primary care support is needed to maintain effective cancer diagnosis. © 2023 by the authors.",TestAnalysis
"were listed incorrectly. The corrected statement is below, and the original article is corrected. EJW and BC conceived of and designed the study with contributions from CR and AEM. EJW and BC coordinated herbarium and field sampling and AEM conducted the DNA sequencing laboratory work. AEM and APR conducted preliminary data analysis and EWH, JW, JCG, and WH refined the dataset and expanded the analyses in the final version. EWH, EJW, BC, and AEM drafted sections of the manuscript text and tables; EWH and WH made all figures; and EWH, JW, JCG, and WH crafted the final narrative. All authors provided critical review and revision of the draft manuscript. © 2023, Canadian Science Publishing. All rights reserved.",TestAnalysis
"Thresholding is a prerequisite for many computer vision algorithms. By suppressing the background in an image, one can remove unnecessary information and shift one’s focus to the object of inspection. We propose a two-stage histogram-based background suppression technique based on the chromaticity of the image pixels. The method is unsupervised, fully automated, and does not need any training or ground-truth data. The performance of the proposed method was evaluated using a printed circuit assembly (PCA) board dataset and the University of Waterloo skin cancer dataset. Accurately performing background suppression in PCA boards facilitates the inspection of digital images with small objects of interest, such as text or microcontrollers on a PCA board. The segmentation of skin cancer lesions will help doctors to automate skin cancer detection. The results showed a clear and robust background–foreground separation across various sample images under different camera or lighting conditions, which the naked implementation of existing state-of-the-art thresholding methods could not achieve. © 2023 by the authors.",TestAnalysis
"This study utilized computational techniques for a reliable analysis of discourse. These techniques were adopted to analyze the progress of Saudi social change in terms of women’s empowerment within the Saudi transformation program. The data from open source 2021–2022 Saudi newspaper archives were automatically crawled using cutting-edge computational techniques and structured according to the sections of the Saudi newspapers: front page, economy, international, sports, society, culture and religion. The analysis was based on computing the minimally uneven distribution of the relative frequencies of the occurrence of the central word (the Arabic forms of woman and women) from the years 2021 to 2022. This produced two samples of text data, each of which represented the respective years. Calculating the normalized and adjusted frequencies of the central word from each section in the data from each year was important to avoid unbalanced absolute frequencies in the qualitative analysis stage. In addition, dispersion measures showed that the amount of variance in terms of the lexical dispersion of the central word was not high. The observable facts from the quantitative analysis produced a more accurate observational sample of citations, which we qualitatively analyzed. The results of the latter showed a considerable ascending change in favor of empowering women as a consequence of Saudi Vision 2030. © 2023 by the authors.",TestAnalysis
"Migration patterns have rapidly changed in Australia and elsewhere, which have contributed to increasingly culturally and linguistically diverse societies. This requires healthcare sectors to provide professional interpreter services for patients with a language barrier to eliminate healthcare disparities. This integrative review aimed to investigate the impact of professional interpreter services on hospital care outcomes and the associated cost of service provision. A systematic search of five databases was conducted for peer-reviewed articles from January 1996 to December 2020. Data were extracted for the hospital setting, intervention, population, study design, outcomes and key findings. Following the PRISMA guidelines, full-text screening identified 37 articles that were analysed and included. Communication quality, hospital care outcomes and hospital costs were the three main themes identified. Closing the language gap should be a primary consideration to prevent adverse events that affect patient safety and the standard of care in hospitals. The findings of this review indicate the provision of professional interpreter services can enhance hospital care for linguistically diverse patients by improving patient–provider communication. To gain insight into the changing patterns on the outcomes of medical care, further research requires efforts by the hospital administrative system to document complete records of service usage. © 2023 by the authors.",TestAnalysis
"Landmark trials (Z0011 and AMAROS) have demonstrated that axillary lymph node dissection (ALND) can be safely omitted in patients with breast cancer and 1–2 positive sentinel nodes. Extrapolating from these and other cardinal studies such as NSABP B-04, guidelines state that patients with 1–2 needle biopsy-proven positive lymph nodes undergoing upfront surgery can have sentinel lymph node biopsy (SLNB) alone. The purpose of this study is to systematically review the literature to identify studies examining the direct application of SLNB in such patients. EMBASE and Ovid MEDLINE were searched from inception to 3 May 2022. Studies including patients with nodal involvement confirmed on pre-operative biopsy and undergoing SLNB were identified. Studies with neoadjuvant chemotherapy were excluded. Search resulted in 2518 records, of which 68 full-text studies were reviewed, ultimately yielding only 2 studies meeting inclusion criteria. Both studies used targeted axillary surgery (TAS) with pre-operative localization of the biopsy-proven positive node in addition to standard SLNB techniques. In a non-randomized single-center prospective study, Lee et al. report no regional recurrences in patients undergoing TAS or ALND, and no difference in distant recurrence or mortality at 5 years. In the prospective multicenter TAXIS trial by Webber et al., the median number of positive nodes retrieved with TAS in patients undergoing upfront surgery was 2 (1, 4 IQR). Within the subset of patients who underwent subsequent ALND, 61 (70.9%) had additional positive nodes, with 26 (30.2%) patients having ≥4 additional positive nodes. Our review demonstrates that there is limited direct evidence for SLNB alone in clinically node-positive patients undergoing upfront surgery. Available data suggest a high proportion of patients with residual disease in this setting. While the totality of the data, mostly indirect evidence, suggests SLNB alone may be safe, we call on clinicians and researchers to prospectively collect data on this patient population to better inform decision-making. © 2023 by the authors.",TestAnalysis
"OBJECTIVE: The objective of this methodological review is to evaluate the adherence of systematic reviews of effectiveness published in JBI Evidence Synthesis to reporting guidelines and methodological quality. INTRODUCTION: Systematic reviews of effectiveness are essential tools for health practitioners and policy-makers. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) 2020 guidelines and the Risk of Bias in Systematic Reviews (ROBIS) tool are used to ensure maintenance of high reporting standards and methodological quality, respectively. This review will utilize these tools to identify strengths and shortfalls in the reporting quality of JBI systematic reviews of effectiveness. INCLUSION CRITERIA: This review will include the 20 most recent systematic reviews of effectiveness published in JBI Evidence Synthesis . METHODS: This review will search MEDLINE (PubMed) for effectiveness reviews published in JBI Evidence Synthesis . Abstract and full-text screening will be performed by 2 independent reviewers, and the most recent 20 studies will be selected for inclusion. Data regarding adherence to PRISMA 2020 and ROBIS will be extracted by 2 independent reviewers. Data will be presented descriptively with tables and synthesized narratively. Copyright © 2023 JBI.",TestAnalysis
"When gender is brought into concerns about older people, the emphasis often lies on stereotypes connected to older women, and few comparative studies have been conducted pertaining to the representation of the intersection between older age and gender in fiction. This article argues that not only children’s literature, traditionally considered to be a carrier of ideology, plays a large part in the target readership’s age socialization, but so do young adult and adult fiction. In a large corpus of 41 Dutch books written for different ages, the representation of older men and women is studied through the verbs, grammatical possessions and adjectives associated with the relevant fictional characters, which were extracted from the texts through the computational method of dependency parsing. Older adult characters featured most frequently in fiction for adults, where, more so than in the books for younger readers, they are depicted as being prone to illness, experiencing the effects of a deteriorating body and having a limited social network. In the books for children, little to no association between older adulthood and mortality was found in the data. Ageist stereotypes pertaining to both genders were found throughout the corpus. In terms of characterization, male older adults are associated more with physicality, including matters of illness and mobility, while character traits and emotions show up in a more varied manner in connection to female older characters. © 2023 by the author.",TestAnalysis
"The Future Design (FD) workshop (FDWS) is a discussion framework based on FD. The aim of FD is to activate a human trait called futurability, considering the preferences of future generations. Previous FD prac-tices with the theme of policy-making in local govern-ments have demonstrated this possibility. However, creating concrete proposals might depend on workshop participants’ abilities and emotions to perceive future society. By comparing two case studies, this study examines the effects of a method for utilizing a causal loop diagram (CLD), a tool for systems think-ing, in FDWS to systematically draw the future society and activate discussions among the participants. CLD is a qualitative system model that helps identify the factors that lead to systemic problems and analyze the guidelines for solving them. Its effects on the performance of the FDWS discussion activity are evalu-ated. They are quantified by text mining analysis using participants’ remark records. Two case studies con-ducted at policy-making workshops in the local gov-ernments of Japan are examined. One is the FDWS in Kyoto City which adopted the proposed CLD utilization method, and the other is the FDWS in Suita City without CLD. The comparative analysis demonstrates that the proposed method makes the discussion live-lier, less divergent, and more developed in the FDWS. © Fuji Technology Press Ltd. the Creative Commons Attribu.",TestAnalysis
"The Investor Sentiment Index (ISI) is widely regarded as a useful measure to gauge the overall mood of the market. Investor panic may result in contagion, causing failure in financial markets. Market participants widely use the ISI indicator to understand price fluctuations and related opportunities. As a result, it is imperative to systematically review the compiled literature on the subject. In addition to reviewing past studies on the ISI, this paper attempts a bibliometric analysis (BA) to understand any related publications. We systematically review over 100 articles and carry out a BA on a set of information based on the publication year, the journal, the countries/territories, the deployed statistical tools and techniques, a citation analysis, and a content analysis. This analysis further strengthens the study by establishing interesting findings. Most articles use the Baker and Wurgler index and text-based sentiment analysis. However, an Internet-search-based ISI was also used in a few of the studies. The results reveal the lack of direct measures or a robust qualitative approach in constructing the ISI. The findings further indicate a vast research gap in emerging economies, such as India’s. This study had no limit on the period for inclusion and exclusion. We believe that our current work is a seminal study, jointly involving a systematic literature review and BA, that will enormously facilitate academicians and practitioners working on the ISI. © 2022 by the authors.",TestAnalysis
"Electronic commerce appeared as a new way of managing businesses in the digital era. However, it has also been accelerated by the recent pandemic situation. Retailers had to find new strategies of reaching customers in the online environment. Thus, concepts such as multi-channel and omni-channel retailing have gained the attention of both retailers and researchers in this field. This paper aims at using a text-mining approach in order to reveal the researchers focus on this theme in a period that also precedes and covers the COVID-19 pandemic. The research methodology follows five steps that are necessary in order to obtain a relevant collection of documents that will further provide the content to be analyzed. These steps refer to: (1) Creating the database of documents for analysis purposes; (2) identifying geographic areas for separating the collection’s documents; (3) framing a thematic dictionary of descriptors; (4) exploring the text using text mining approach; and (5) correspondence analysis. The discussion of the main findings is constructed starting with the geographic and the temporal distribution of documents and the design of a thematic dictionary of descriptors. Then, exploring the content of the documents provides information on the frequency of descriptors and reveals clusters of descriptors along with a link analysis. All of them are presented separately on geographic regions. Finally, the correspondence analysis of descriptors versus years provides the proximity maps and reveals the preferred topics and less approached themes. Among the main findings, one can highlight: (1) The greatest contributor in terms of documents related to the theme of interest is the United States; (2) a higher number of connections (and stronger) among descriptors for America as compared to the other two regions; (3) some categories of descriptors are specific to a particular year, which means that there are different themes under the researchers lens depending on the period; (4) the most frequently used descriptors are included in the following categories from the dictionary: Online retail environment and Consumer behavior, regardless of the region. In the end of this paper, research limitations and guidelines for future research are elaborated. © 2022 by the authors.",TestAnalysis
"Previous studies examining the impact of heritage tourism have focused on specific ecological, economic, political, or cultural impacts. Research focused on the extent to which heritage tourism fosters host communities' participation and enhances their capacity to flourish and support long-term health and wellbeing is lacking. This systematic review assessed the impact of heritage tourism on sustainable community development, as well as the health and wellbeing of local communities. Studies were included if they: (i) were conducted in English; (ii) were published between January 2000 and March 2021; (iii) used qualitative and/or quantitative methods; (iv) analysed the impact of heritage tourism on sustainable community development and/or the health and wellbeing of local host communities; and (v) had a full-text copy available. The search identified 5292 articles, of which 102 articles met the inclusion criteria. The included studies covering six WHO regions (Western Pacific, African, Americas, South-East Asia, European, Eastern Mediterranean, and multiple regions). These studies show that heritage tourism had positive and negative impacts on social determinants of health. Positive impacts included economic gains, rejuvenation of culture, infrastructure development, and improved social services. However, heritage tourism also had deleterious effects on health, such as restrictions placed on local community participation and access to land, loss of livelihood, relocation and/or fragmentation of communities, increased outmigration, increases in crime, and erosion of culture. Thus, while heritage tourism may be a poverty-reducing strategy, its success depends on the inclusion of host communities in heritage tourism governance, decision-making processes, and access to resources and programs. Future policymakers are encouraged to adopt a holistic view of benefits along with detriments to sustainable heritage tourism development. Additional research should consider the health and wellbeing of local community groups engaged in heritage tourism. Protocol PROSPERO registration number: CRD42018114681. © 2023 Brooks et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Background: Opportunities for social connection between generations in the UK have diminished over the last few decades because of changes in the way that we live and work. The decline in communal spaces such as libraries, youth clubs and community centres mean that there are fewer opportunities to meet and mix socially with other generations outside our own families. Increased working hours, improved technology, changes in family patterns, relationship breakdowns within families and migration are also believed to be contributory factors to generation segregation. There are many potential economic, social and political impacts of generations living separate and parallel lives, for example, higher health and social care costs, an undermining of trust between generations reduced social capital, a reliance on the media to form understanding of others’ viewpoints and higher levels of anxiety and loneliness. Intergenerational programmes and activities can take many forms and are delivered in many settings. Evidence suggests that intergenerational activity can have a positive impact on participants, for example, in reducing loneliness and exclusion for both older people and children and young people, improving mental health, increasing mutual understanding and addressing important issues such as ageism, housing and care. There are currently no other EGMs that exist that address this type of intervention; however, it would complement existing EGMs addressing child welfare. Objectives: To identify, appraise and bring together the evidence on the use of intergenerational practice, to answer the following specific research questions:. What is the volume, nature and diversity of research on, and evaluation of, intergenerational practice and learning? What approaches have been used to deliver intergenerational activities and programmes that may be relevant to providing such services during and in the subsequent recovery from the COVID-19 pandemic? What promising intergenerational activities and programmes have been developed and are being used but have not yet been subject to formal evaluation?. Search Methods: We searched MEDLINE (via OvidSp), EMBASE (via OvidSp), PsycINFO (via OvidSp), CINAHL (via EBSCOHost), Social Policy and Practice (via OvidSp), Health Management Information Consortium (via OvidSp), Ageline (via EBSCOhost), ASSIA (via ProQuest), Social Science Citations Index (via Web of Science), ERIC (via EBSCOhost), Community Care Inform Children, Research in Practice for Children, ChildData (via Social Policy and Practice), the Campbell Library, the Cochrane Database of Systematic Reviews and the CENTRAL database between 22 and 30 July 2021. We searched for additional grey literature via the Conference Proceedings Citation Index (via Web of Science) and ProQuest Dissertation & Theses Global and via relevant organisation websites, for example, Age UK, Age International, the Centre for Ageing Better, Barnado's, Children's Commission, UNICEF, Generations Working Together, the Intergenerational Foundation, Linking Generations and The Beth Johnson Foundation) and the Ottawa initiative called Older Adults and Students for Intergenerational support. Selection Criteria: Any intervention that brings older and younger people together with the purpose of interacting to achieve positive health and/or social and/or educational outcomes from any study design including systematic reviews, randomised controlled studies, observational studies, surveys and qualitative studies are included. The titles and abstracts, and later full texts, of records identified by the search methods were screened against inclusion criteria by two independent reviewers. Data Collection and Analysis: Data extraction was undertaken by one reviewer and checked by a second with any inconsistencies identified and resolved through discussion. The data extraction tool was developed on EPPI reviewer and was modified and tested through stakeholder and advisor consultation, and piloting of the process. The tool was informed by the research question and the structure of the map. We did not undertake quality appraisal of the included studies. Main Results: Our searches identified 12,056 references, after screening 500 research articles were included in the evidence gap map conducted across 27 countries. We identified 26 systematic reviews, 236 quantitative comparative studies (of which 38 were randomised controlled trials), 227 were qualitative studies (or had a qualitative element), 105 were observational studies (or had elements of observational methods) and 82 used a mixed methods approach. The outcomes reported in the research cover mental health (n = 73), physical health (n = 62), attainment and knowledge (n = 165), agency (n = 174), mental wellbeing (n = 224), loneliness and social isolation (n = 54), attitudes towards the other generation (n = 283), intergenerational interactions (n = 196), peer interactions (n = 30) and health promotion (n = 23) and including mutual outcomes such as the impact on community (n = 37) and perceptions on the sense of community (n = 43). Gaps in the evidence that were identified include: research that reports on mutual, societal and community outcomes of intergenerational interventions; more research on interventions classified as levels 1–4 and level 7 on the Intergenerational Engagement Scale, mental health, loneliness, social isolation, peer interactions, physical health and health promotion outcomes in children and young people; health promotion in older people; outcomes centred on care giver wellbeing, mental health and attitudes; economic outcomes; process outcomes and adverse or unexpected outcomes. Authors’ Conclusions: Whilst a substantional amount of research on intergenerational interventions has been identified in this EGM, as well as the gaps identified above, there is a need to explore promising interventions not yet formally evaluated. Research on this topic is gradually increasing, and systematic reviews will be important to determine how and why interventions are or are not beneficial. However, the primary research needs to build more cohesively so that the findings can be comparable and avoid research waste. The EGM presented here will nevertheless be a useful resource for decision-makers allowing them to explore the evidence with regard to the different interventions that may be relevant to their population needs and the settings or resources available to them. © 2023 The Authors. Campbell Systematic Reviews published by John Wiley & Sons Ltd on behalf of The Campbell Collaboration.",TestAnalysis
"To describe process knowledge at the watershed scale, hydrologists commonly refer to a ‘perceptual model’, an expert summary of the watershed and its runoff processes often supported by field observations. Perceptual models are often presented as a schematic figure, although such a figure will necessarily simplify the hydrologist's complex mental model. In this paper, our aim was to understand what constitutes a visual expert summary of watershed process knowledge, and to evaluate how perceptual models could be used to share hydrological process information at larger scales. To do so, we conducted a systematic review of the literature and found 63 perceptual model figures. We counted and categorized the stores and fluxes in each figure using a taxonomic classification and quantified a variety of figure attributes including spatial or temporal zonation, inclusion of vegetation, soils, topographical and geological data and consideration of uncertainty. Our analysis showed that a typical figure has 1 surface flux, 4 subsurface fluxes, 3–4 subsurface stores and 0–1 channel stores; 28 out of 63 figures use sub-figures to show temporal dynamics (e.g., wet/dry conditions), and 12 out of 63 show spatial zones. Perceptual model figures, therefore, provide a concise summary of watershed processes with a complexity comparable to that of many conceptual hydrological models. However, only four figures showed any information on uncertainty or knowledge gaps. We recommend that perceptual figure value could be easily increased by consistent captioning of figures to assist automated search, and wider use of standard figure annotations such as legends and scale markings to ensure that information is fully conveyed to the user. If perceptual figures are proposed as a primary method for sharing process information, the hydrological community should consider how to link more detailed text descriptions to figures, and how to represent process uncertainty. © 2023 The Authors. Hydrological Processes published by John Wiley & Sons Ltd.",TestAnalysis
"Antipsychotic-induced akathisia (AIA) is a movement disorder characterized by a subjective feeling of inner restlessness or nervousness with an irresistible urge to move, resulting in repetitive movements of the limbs and torso, while taking antipsychotics (APs). In recent years, there have been some associative genetic studies of the predisposition to the development of AIA. Objective: The goal of our study was to review the results of associative genetic and genome-wide studies and to systematize and update the knowledge on the genetic predictors of AIA in patients with schizophrenia (Sch). Methods: We searched full-text publications in PubMed, Web of Science, Springer, Google Scholar, and e-Library databases from 1977 to 2022. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) quality scale was used for the critical selection of the studies. Results: We identified 37 articles, of which 3 were included in the review. Thus, the C allele of rs1800498 (59414 C>T) and the A allele of rs1800497 (17316 G>A) (TaqIA) from the DRD2 gene as well as the TT genotype rs13212041 (77461407 C>T) from the HTR1B gene were found to be associated with AIA. Conclusions: Uncovering the genetic biomarkers of AIA may provide a key to developing a strategy for the personalized prevention and treatment of this adverse neurological drug reaction of APs in patients with Sch in real clinical practice. © 2023 by the authors.",TestAnalysis
"Present-day, interdisciplinary research is increasing in social network-related applications, and it is a daily routine activity in every human life. So, sentiment analysis (SA) based on opinion mining is the most sophisticated concept in the well-known social network environment. Different machine learning methods were implemented to extract different text label features in SA, and all of those methods can detect whether a given text is positive or negative based on the text features. Analysis of sentiment has been suffering from inaccuracies while using machine learning and sentiment-based lexical methods dependent on domain-specific problems. Multi-class SA is an expensive task where memory, label samples, and other parameters are insufficient. So, we propose and implement a novel hybrid model which is a combination of ResNeXt and recurrent neural framework (NH-ResNeXt-RNF) to explore multi-class sentiment from textual features. This framework investigates the polarity of words connected to a specific domain across the entire dataset and eliminates noisy data in an unsupervised manner using pre-processing. Optimization is required to perform efficient multi-class classification to reduce the effort associated with annotation for multi-class SA via unsupervised learning. The proposed model performance is evaluated on two data sets namely: Amazon and Twitter. We increase the accuracy of the sentiment of polarity on each sentence present in the data set. Experimental results of the proposed approach give better and more efficient multi-class (positive, negative, very positive, neutral and highly negative) domain-specific sentiment than traditional approaches related to supervised, semi-supervised, and unsupervised domains. The proposed hybrid model accuracy is 96.5% and 95.37% for Amazon and Twitter datasets respectively. © 2023 The Author(s). Published by IOP Publishing Ltd",TestAnalysis
"The aim of the study is to show whether it is possible to predict infectious disease outbreaks early, by using machine learning. This study was carried out following the guidelines of the Cochrane Collaboration and the meta-analysis of observational studies in epidemiology and the preferred reporting items for systematic reviews and meta-analyses. The suitable bibliography on PubMed/Medline and Scopus was searched by combining text, words, and titles on medical topics. At the end of the search, this systematic review contained 75 records. The studies analyzed in this systematic review demonstrate that it is possible to predict the incidence and trends of some infectious diseases; by combining several techniques and types of machine learning, it is possible to obtain accurate and plausible results. © 2023 by the authors.",TestAnalysis
"(1) Background: Iron deficiency (ID) is an important adverse prognostic marker in patients with heart failure (HF); however, it is unclear whether intravenous iron replacement reduces cardiovascular mortality in this patient group. Here, we estimate the effect of intravenous iron replacement therapy on hard clinical outcomes following the publication of IRONMAN, the largest trial in this field. (2) Methods: In this systematic review and meta-analysis, prospectively registered with PROSPERO and reported according to PRISMA guidelines, we searched PubMed and Embase for randomized controlled trials investigating intravenous iron replacement in patients with HF and co-existing ID. The primary outcome was cardiovascular mortality and secondary outcomes were all-cause mortality, hospitalizations for HF and a combination of the primary outcome and hospitalizations for HF. (3) Results: A total of 1671 items were identified and after removal of duplicates we screened titles and abstracts of 1202 records. Some 31 studies were identified for full-text review and 12 studies were included in the final review. The odds ratio (OR) for cardiovascular death using a random effects model was 0.85 (95% CI 0.69 to 1.04) and for all-cause mortality it was 0.83 (95% CI 0.59 to 1.15). There was a significant reduction in hospitalizations for HF (OR 0.49, 95% CI 0.35 to 0.69) and the combination of hospitalizations for HF and cardiovascular death (OR 0.65, 95% CI 0.5 to 0.85). (4) Conclusions: This review supports the use of IV iron replacement reducing hospitalization rates for HF, however more research is required to determine the effect on cardiovascular mortality and to identify the patient population most likely to benefit. © 2023 by the authors.",TestAnalysis
"This study set out to better understand virtual consumerism (VC) by applying natural language processing (NLP) methods for sentiment and content analyses. A total of 318 articles related to VC were identified on theguardian.com Web site and analyzed by text mining methodology. A thematic, content analysis using the Leximancer program was performed to explore VC as a concept, and its related concepts and concept associations. For the purposes of ""deep-dive insights,""further content and sentiment analyses were performed with MonkeyLearn and valence aware dictionary for sentiment reasoning. This triangulation in methodology enabled a comprehensive unstructured qualitative data analysis. The study identified key themes that characterize and define VC. It uncovered that, although there is predominantly positive sentiment toward VC reported in The Guardian online articles, negative sentiment also exists, presenting challenges for the industry to maneuver. The findings reveal that in the context of VC, a virtual experience is also a social experience in a virtual space, which is becoming and evolving. There are certain industries and sectors that are embracing VC, such as marketing, advertising and public relations, software development/IT, art/design, and entertainment, as well as science/technology. Some sectors and industries are experiencing challenges, such as security/law enforcement and medical, and hence display negative sentiment toward VC. Overall, this study presents a working definition of VC, a synopsis of the state of VC, and highlights areas for potential research to further our understanding of this phenomenon. It contributes to an improved understanding of VC for the industry and academia, and provides impetus for future studies focused on the emergent VC-relevant conceptual relationships.  Copyright © 2023, Mary Ann Liebert, Inc.",TestAnalysis
"The protection of one’s home and ensuring the safety of one’s family have been deep-rooted concerns throughout time and in all cultures. Ānzhái 安宅 (“pacifying one’s residence”) rituals can be traced to ancient China and are still practiced in contemporary China. In this study, we will focus on the Fóshuō ānzhái shénzhòu jīng 佛說安宅神呪經 (AZSZJ; T.21, No. 1394), one of the extant Buddhist scriptures dealing with home protection. There have been (at least) two lines of transmission of ānzhái scriptures and on the basis of internal and external evidence, we project the compilation of the extant version of this text to include the late 6th century and mid 7th century and show that the scripture—in earlier catalogues labeled as “fake”—entered the Buddhist canon on the basis of a mistake or confusion by Míng Quán when he recorded it in his Dà-Zhōu kāndìng zhòngjīng mùlù 大周刊定眾經目錄. The main part of the study consists of an annotated translation of AZSZJ and a preliminary analysis of the difficult terminology appearing in parts of the text. In the last part, we discuss some aspects of the text’s traditional Chinese and Buddhist elements and how they were skillfully combined in order to make the overall text attractive for the medieval Chinese Buddhist community and to successfully compete with other contemporary ritual practices concerned with the safety of one’s home. © 2023 by the authors.",TestAnalysis
"Preterm birth is associated with weaknesses in reading skills that are usually less severe than those of children with dyslexia. To understand the characteristics of reading processes in preterm children, we adopted a cross-population and multi-modal approach comparing eye movements in reading tasks among three groups: children with preterm birth, children with a diagnosis of dyslexia, and children with typical development. The study involved 78 participants (10.5 years). Eye movements (number and duration of fixations, amplitude and number of saccades, number of regressions) were recorded during the silent reading of two texts; cognitive and reading standardized tasks were also administered. Children with dyslexia had more fixations and more frequent and smaller saccades compared to the preterm group and children with typical development. They also showed more regressions compared to the control group. Preterm children showed shorter fixations compared to the other groups. Cognitive and reading standardized tasks confirmed severe delays in reading in children with dyslexia and some weaknesses in text reading speed and comprehension in preterm children. These results are discussed with reference to candidate mechanisms that underlie reading processes in preterm children and considering possible implications for research. © 2023 by the authors.",TestAnalysis
"The local structure and density of ternary Fe-C-S liquid alloys have been studied using a combination of in situ X-ray diffraction and absorption experiments between 1 and 5 GPa and 1600–1900 K. The addition of up to 12 at% of carbon (C) to Fe-S liquid alloys does not significantly modify the structure, which is largely controlled by the perturbation to the Fe-Fe network induced by S atoms. The liquid density determined from diffraction and/or absorption techniques allows us to build a non-ideal ternary mixing model as a function of pressure, temperature, and composition in terms of the content of alloying light elements. The composition of the Moon's core is addressed based on this thermodynamic model. Under the assumption of a homogeneous liquid core proposed by two recent Moon models, the sulfur content would be 27–36 wt% or 12–23 wt%, respectively, while the carbon content is mainly limited by the Fe-C-S miscibility gap, with an upper bound of 4.3 wt%. On the other hand, if the core is partially molten, the core temperature is necessarily lower than 1850 K estimated in the text, and the composition of both the inner and outer core would be controlled by aspects of the Fe-C-S phase diagram not yet sufficiently constrained. © 2023. The Authors.",TestAnalysis
"Objective: Malnutrition is often underestimated in the context of cancer therapy: the dietary trends initiated by patients after diagnosis are usually neither known to nor evaluated by the medical staff. Here, we propose a combined screening instrument evaluating malnutrition and dietary trends. Methods: The validated screening tool NRS-2002 was combined with a four-item questionnaire assessing whether (1) patients preferred certain foods, (2) avoided certain foods, (3) used dietary supplements or followed a special diet since the time of cancer diagnosis. The screening tool was routinely used by cancer patients in the daily practice of three oncological departments. The presented analysis was performed retrospectively and anonymized. Results: Overall, 102 cancer patients undergoing systemic therapy (CP), 97 undergoing radiation therapy (RP), and 36 head–neck cancer patients (HNP) were screened. The CP cohort showed a higher rate of malnutrition (50.00%) than the HNP (28.13%) or RP (26.80%) cohort. Overall, diet changes were observed in 33.63% of all patients. Avoiding meat, stimulants, or hard and edgy food was often mentioned in free text answers, while patients reported a preference for fruit and vegetables. Nutritional supplements were used by 28.76% of the patients. While dietary changes were common, only 6.64% of the patients mentioned adhering to a specific cancer diet. Conclusion: Malnutrition is still underestimated nowadays. Diet trends, especially avoiding certain foods, are common in cancer patients, while adhering to a specific cancer diet is an exception. Diet trends should be assessed and addressed to avoid or aggravate malnutrition. © 2023 by the authors.",TestAnalysis
"This study explores how natural language processing (NLP) can supplement content analyses of political documents, particularly the manifestos of political parties. NLP is particularly useful for tasks such as: estimating the similarity between documents, identifying the topics discussed in documents (topic modeling), and sentiment analysis. This study applies each of these techniques to the study of political party manifestos. Document similarity may be used to gain some insight into the way parties change over time and which political parties are successful at bringing attention to their policy agenda. Categorizing text into topics may help objectively categorize and visualize the ideas political parties are discussing. Finally, sentiment analysis has the potential to show each political party’s attitude towards a policy area/topic. This study specifically applies these techniques to the manifestos produced by the political parties of New Zealand, from 1987 to 2017 (a period of significant party system change in New Zealand). It finds that NLP techniques provide valuable insights, although there is a need for significant fine-tuning. © 2023 by the authors.",TestAnalysis
"The search for definitions is ubiquitous in Sanskrit philosophy. In many texts across traditions, we find philosophers presenting their theories by laying down definitions of key theoretical categories, by testing those definitions, and by refuting competing definitions of the same theoretical categories. Call this the method of definitions. The aim of this essay is to explore a challenge that arises for this method: the paradox of definitions. It arises from the claim that the method of definitions is either (i) redundant because it does not provide us any knowledge that we did not already possess, or (ii) impossible to successfully pursue because it leads to an infinite regress. Neither of these alternatives should be acceptable to the defender of this method. To focus our discussion, I will show how this challenge arose for—and was arguably resolved by—early Nyāya-Vaiśeṣika thinkers active in the first millennium CE and at the very beginning of the second millennium. In response to the paradox of definitions, these Nyāya-Vaiśeṣika thinkers claimed that the purpose of a definition is to remove either metaphysical ignorance about the distinction between theoretically significant kinds or kind-membership, or metalinguistic ignorance about the meaning or the application-conditions of theoretically significant terms. I will show how this discussion helps us to ward off certain misconceptions about the method of definitions in Nyāya-Vaiśeṣika. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.",TestAnalysis
"Plant-based diets have grown increasingly popular across the globe, mainly for their health and environmental benefits. Several studies have identified a link between plant-based diets and the decreased risk of developing cardiovascular diseases, obesity, and other health issues. We systematically reviewed human interventions to identify the relationship between various plant-based food items and the gut microbiome, alongside the biochemical and anthropometric measurements as secondary findings. The study selection process was completed using the COVIDENCE platform. Overall, 203 studies were identified, of which 101 were chosen for title and abstract screening by two independent authors. Following this process, 78 studies were excluded, and the full texts and the reference lists of the remaining 23 records were reviewed using the review eligibility criteria. A manual search yielded five additional articles. In the end, 12 studies were included in the systematic review. We found evidence for short- to moderate-term beneficial effects of plant-based diets versus conventional diets (duration ≤ 13 months) on gut microbiome composition and biochemical and anthropometric measurements in healthy participants as well as obese, cardiovascular, and rheumatoid arthritis patients. However, contradictory results were observed for Enterobacteriaceae, at the family level, and for Faecalibacterium and Coprococcus, at the genus level, of gut microbiome composition. The relationship between plant-based diets and the gut microbiome, alongside their underlying metabolic and inflammatory effects, remains largely unexplored. Hence more interventional studies are needed to address these questions. © 2023 by the authors.",TestAnalysis
"Disruptive technologies are related to a country’s competitiveness and international status. Accurately identifying and predicting the trends in disruptive technologies through scientific methods can effectively grasp the dynamics of technological development, adjust the national science and technology strategic layout, and better seize the high ground in international competition. Based on patent text data, this paper uses the improved LDA2Vec model combined with relevant indicators to identify the main topics in disruptive technologies, and predicts and analyzes the development trend through the establishment of an ARIMA model. Taking the energy technology field as an example, the main topics and development trends concerning disruptive technologies in this field are obtained. The study found that ten technologies, including energy storage technology, energy internet management technology, and offshore wind energy technology, are disruptive technologies in the energy technology field, and the development speed of energy storage technology is the fastest. To verify the correctness of the conclusion, this paper compares the results with artificial verification methods such as expert interviews and document verification, and finds that the two are basically consistent, thus verifying the effectiveness and feasibility of the proposed method. © 2023 by the authors.",TestAnalysis
"The paper is dedicated to the problematics of the Russian Empire’s military researchers of the Don Host. Within it, it is shown that, due to Don Host’s subordination to the Ministry of War, there were quite a few of such researchers, although in later historiography the attention was drawn predominantly to those of them who were of Cossack descent. Meanwhile, even the most general analysis allows to distinguish 4 groups of Russian Empire’s Don Host military researchers: these are, besides Don Cossacks, the officers who had visited Don before any serious publications on the matter of studying the Don Cossacks, the officers of the General Staff and the officers of the Main Directorate of Cossack Hosts. At the same time, exactly in the case of Cossacks, assigning researchers who had military rank to the category of military researches should be made with outmost caution: a number of Don historians and statisticians (for example, M.Kh. Senyutkin and V.M. Pudavov) did not have military education, did not serve in any combat units and therefore principally had a bad familiarity with military-specific literature, including that about the Don Cossacks. The officers who had visited Don before the publications of any serious researches on the Don Cossacks did try to describe, by their own impressions too, the Cossacks and the Don Host, which were perceived as somewhat of an exotic at the time, filling a lacuna in Russian scientific and publicist prose. The officers of the General Staff had frequently composed their works in preparation of upcoming reformations, or just to inform higher authorities about local statistics, and it is characteristic for their works to be based of statistical science which was taught in Nicholas General Staff Academy. Finally, a number of texts was made by the officers of the Main Directorate of Cossack Hosts, based on presenting materials from the archives, which were also found while performing government assignments. Therefore, somewhat different research methods and themes were characteristic for various categories of Russian Empire’s Don Host military researchers, which were determined by their education and official duties. Copyright © 2023 by Cherkas Global University.",TestAnalysis
"In the original publication [1], a table of “Reference sequences to each variant/lineages” was not included in the “Data Availability Statement”. Now, we would like to include it as Table A2 in Appendix A. The authors state that the scientific conclusions are unaffected. This correction was approved by the Academic Editor. The original publication has also been updated. The sequences included in the reference database. With regard to the insert of Table A2, there are two places that need to be corrected in the text. “Data availability statement section” should be replaced with “Table A2” in Section 2.3. Partial S-Gene Sequencing and Phylogenetic Analysis, paragraph 1, and Section 3.1. In Silico Specificity of the S-Gene 921 BP-Fragment, paragraph 1. © 2023 by the authors.",TestAnalysis
"Twitter location inference methods are developed with the purpose of increasing the percentage of geotagged tweets by inferring locations on a non-geotagged dataset. For validation of proposed approaches, these location inference methods are developed on a fully geotagged dataset on which the attached Global Navigation Satellite System coordinates are used as ground truth data. Whilst a substantial number of location inference methods have been developed to date, questions arise pertaining the generalizability of the developed location inference models on a non-geotagged dataset. This paper proposes a high precision location inference method for inferring tweets’ point of origin based on location mentions within the tweet text. We investigate the influence of data selection by comparing the model performance on two datasets. For the first dataset, we use a proportionate sample of tweet sources of a geotagged dataset. For the second dataset, we use a modelled distribution of tweet sources following a non-geotagged dataset. Our results showed that the distribution of tweet sources influences the performance of location inference models. Using the first dataset we outweighed state-of-the-art location extraction models by inferring 61.9%, 86.1% and 92.1% of the extracted locations within 1 km, 10 km and 50 km radius values, respectively. However, using the second dataset our precision values dropped to 45.3%, 73.1% and 81.0% for the same radius values. Copyright: © 2023 Serere et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"The article provides an encyclopedia source analysis of “Industry and Technology. Encyclopedia of Industrial Knowledge”, published in the Russian Empire period 1901-1904. The encyclopedia was a complete translation of the German edition with significant additions by Russian scientists in certain areas of technical knowledge. It was in the Russian version of the Encyclopedia that the logical order of books collection was determined, which corresponded to the most advanced technologies characteristic of the XX century beginning. The purpose of this article is to analyze the formation history and development of Russian science and technology, as well as to determine the information potential of the encyclopedia as a historical source. The content of each volume has a huge array of information about scientific and technical developments, major discoveries and current scientific knowledge in a specific historical period. Despite the great attention to the science and technology achievements the past, encyclopedic texts record the aspiration of technological progress to the future, where science and technology will be a solid foundation for the social and cultural progress of Russia. Because of the conducted source analysis of the Encyclopedia, including using the qualitative and quantitative content analysis method, the historical continuity of this technology type as an “automaton” in the Russian history of science and technology was established. Special attention to this type of technology was due to the modern development and achievements in the field of technical sciences, the modern significance automated technology. The significance of the publication under study as a historical source lies in the comprehensive and systematic nature of the materials presented on the history of Russian science and technology. Copyright © 2023 by Cherkas Global University.",TestAnalysis
"Over the past few years, word embeddings and bidirectional encoder representations from transformers (BERT) models have brought better solutions to learning text representations for natural language processing (NLP) and other tasks. Many NLP applications rely on pre-trained text representations, leading to the development of a number of neural network language models for various languages. However, this is not the case for Amharic, which is known to be a morphologically complex and under-resourced language. Usable pre-trained models for automatic Amharic text processing are not available. This paper presents an investigation on the essence of learned text representation for information retrieval and NLP tasks using word embeddings and BERT language models. We explored the most commonly used methods for word embeddings, including word2vec, GloVe, and fastText, as well as the BERT model. We investigated the performance of query expansion using word embeddings. We also analyzed the use of a pre-trained Amharic BERT model for masked language modeling, next sentence prediction, and text classification tasks. Amharic ad hoc information retrieval test collections that contain word-based, stem-based, and root-based text representations were used for evaluation. We conducted a detailed empirical analysis on the usability of word embeddings and BERT models on word-based, stem-based, and root-based corpora. Experimental results show that word-based query expansion and language modeling perform better than stem-based and root-based text representations, and fastText outperforms other word embeddings on word-based corpus. © 2023 by the authors.",TestAnalysis
"Feature selection and feature extraction have always been of utmost importance owing to their capability to remove redundant and irrelevant features, reduce the vector space size, control the computational time, and improve performance for more accurate classification tasks, especially in text categorization. These feature engineering techniques can further be optimized using optimization algorithms. This paper proposes a similar framework by implementing one such optimization algorithm, Ant Colony Optimization (ACO), incorporating different feature selection and feature extraction techniques on textual and numerical datasets using four machine learning (ML) models: Logistic Regression (LR), K-Nearest Neighbor (KNN), Stochastic Gradient Descent (SGD), and Random Forest (RF). The aim is to show the difference in the results achieved on both datasets with the help of comparative analysis. The proposed feature selection and feature extraction techniques assist in enhancing the performance of the machine learning model. This research article considers numerical and text-based datasets for stroke prediction and detecting hate speech, respectively. The text dataset is prepared by extracting tweets consisting of positive, negative, and neutral sentiments from Twitter API. A maximum improvement in accuracy of 10.07% is observed for Random Forest with the TF-IDF feature extraction technique on the application of ACO. Besides, this study also highlights the limitations of text data that inhibit the performance of machine learning models, justifying the difference of almost 18.43% in accuracy compared to that of numerical data. © 2023 by the authors.",TestAnalysis
"The authors would like to make the following correction to the published paper (Seip and Zhang 2022). In Figure 2, e and f were duplicates. The correct Figure 2 is presented below: both LOESS(0.1) smoothed (gray) and both raw, unsmoothed (dark gray). Numbers show percentage “pseudo significant” LL relations (see text). Drop-lines show the beginning of recessions. OLR between gray and black bars give R = 0.30, p < 0.001. (c) GDP-LOESS (0.8) residual and UE (%) both series LOESS(0.1) smoothed. (d) LL(GDP LOESS (0.8) residual, UE), both series LOESS(0.1) smoothed and normalized to unit standard deviation. Red horizontal lines show recession periods. Droplines show beginning of recessions. (e) Phase plot for GDP and EM, not detrended, 1989-1993M4, dropline show the beginning of the 1990 recession. (f) Same as (e), but with GDP and UE. The authors confirm that the scientific conclusions are unaffected. The original publication has also been updated. © 2023 by the authors.",TestAnalysis
"Gluten proteins are known as immunological triggers for inflammation resulting in mucosal lesions in patients with coeliac disease (CD). Adherence to a strict gluten-free diet (GFD) is currently known as the only effective treatment for CD. In this study, we performed a systematic review and dose-response meta-analysis on data from previous studies to investigate the association between different gluten doses administered and the risk of CD relapse. Electronic databases were systematically searched to retrieve studies that investigated the response of CD patients to different amounts of gluten intake and evaluated the clinical, serologic, and/or histologic evidence to recognize disease relapse. Study-specific relative risks (RRs) were combined using a random effects model. A total of 440 identified published papers were screened, of which 7 records were selected following full-text reviewing and eligibility assessment for dose-response meta-analysis. According to our analysis, the risk of CD relapse is estimated to be 0.2% (RR: 1.002; 95% CI: 1.001 to 1.004) following the consumption of 6 mg gluten/day, which was increased to 7% (RR: 1.07; 95% CI: 1.03 to 1.10), 50% (RR: 1.50; 95% CI: 1.23 to 1.82), 80% (RR: 1.80; 95% CI: 1.36 to 2.38), and 100% (RR: 2.00; 95% CI: 1.43 to 2.78) by the daily intake of 150, 881, 1276, and 1505 mg gluten, respectively. Although good adherence to a GFD can adequately control CD-related symptoms, disease relapse might happen even with a very low dose of gluten, and the duration of exposure to gluten is also an important matter. The current literature has substantial limitations, such as relying on the data from just a few countries that were different in terms of the amount of gluten administered, the duration of the challenge, etc. Therefore, more randomized clinical trials using a standardized gluten challenge protocol are needed to confirm the findings of the present study. © 2023 by the authors.",TestAnalysis
"Introduction Valid and reliable scores from measurement tools to test competency in basic manual wheelchair-service-provision are needed to promote good practice and support capacity building. The International Society of Wheelchair Professionals’ (ISWP) Basic Test Version 1 in English, launched in 2015, is the most frequently used outcome measure tool to test basic manual wheelchair-service-provision knowledge and is part of an international certification process. Despite the wide acceptance and use of the test, its psychometric properties have not yet been established. The objectives of this study were 1) to evaluate the test’s psychometric properties, 2) to develop the test’s Version 2, and 3) to evaluate the content validity of the new version. Methods For Objective 1, methods from the Classical Test Theory were used to obtain items’ difficulty, item discrimination index and domains’ reliability. For Objective 2, a team of experts in wheelchair service delivery and education conducted a systematic qualitative review of the questions’ text and answers and updated them using evidence-based guidelines. For Objective 3, an external team reviewed the clarity, relevance and domain allocation of the developed items using a 4-point Likert scale. Descriptive statistics were used to describe and characterize the results for each objective. Item-content (I-CVI) and Scale-content (S-CVI) validity indexes were calculated to compute content validity. Results For Objective 1, all domains in the test were below the threshold for acceptable internal consistency reliability; 80% of the total test pool (116 items from the total pool of 145) did not meet the thresholds for item difficulty and index of discrimination suggested in the literature. Of the items in the Test, 78% could be responded to intuitively and 66% did not distinguish between test-takers who were knowledgeable in the content area and those who were not. For Objective 2, experts found concerns such as items being grouped in the wrong domain, being repeated, not using person-first language, and using terms inconsistently. Thirty-four (23.4%) items were dropped and 111 (76.5%) were updated. In addition, 61 new items were developed. Members re-categorized the items and proposed a new classification of subdomains. For Objective 3, good agreement between subject-matter experts was found; the S-CVI calculated using the I-CVIs related to item clarity was 84% while using the I-CVIs related to item relevance was 98%. Only 7 items (4.1%) were deemed to be in the wrong domain and 4 items (2.3%) were considered irrelevant and dropped. Conclusion The psychometric evidence in support of ISWP Basic Test Version 1 in English is suboptimal. A new set of items developed by experts in the field has shown excellent content validity. Ongoing assessments will be needed as ISWP Basic Test Version 2 is implemented and monitored. Copyright: © 2023 Burrola-Mendez et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Hypoplastic or hypomineralized enamel defects represent a recurrent reason for consultation within the pediatric population, causing great discomfort due to their aesthetic appearance, as well as their functional limitations. Current conservative dentistry requires minimally invasive treatments in order to treat such defects and provide successful, definitive solutions. A systematic review of the literature has been carried out in accordance with the PRISMA recommendations. A search was carried out in the PubMed, Scopus, SciELO and Web of Science databases, completed with a manual search. The following variables were extracted from the selected studies: author, year, publication journal, type of study, sample, age of the participants and the materials used for its development. From the initial electronic search of the four databases, 282 articles were identified: 34 from PubMed, 240 from Scopus, 0 from SciELO and 8 from Web of Science. After eliminating duplicate articles, a total of 225 remained. After reading the title and abstract, 158 articles were eliminated, leaving 68. Upon reading the full text, the remaining studies were eliminated for not answering the research question or the inclusion criteria, leaving a total of 13 articles. Finally, 12 articles were used to carry out the systematic review. Treatments performed to date with the ICON™ system in pediatric patients have shown good results after their application. Since the variability of diagnostic methods has been observed, new diagnostic and assessment protocols should be created after treatment to objectify their effect on hypoplastic or hypomineralized enamel defects. In the same way, it has been described that treatment provides better results if combined with other opalustre-type or remineralizing materials. This review is registered in PROSPERO with the number CRD42021288738. © 2023 by the authors.",TestAnalysis
"Pauses act as important acoustic cues to prosodic phrase boundaries. However, the distribution and phonetic characteristics of pauses have not yet been fully described either cross-linguistically or in different genres and speech styles within languages. The current study examines the pausal performance of 24 Czech speakers in two genres of read speech: news reading and poetry reciting. The pause rate and pause duration are related to genre differences, overt and covert text organization, and speech tempo. We found a significant effect of several levels of text organization, including a strong effect of punctuation. This was reflected in both measures of pausal performance. A grammatically informed analysis of a subset of pauses within the smallest units revealed a significant contribution for pause rate only. An effect of tempo was found in poetry reciting at a macro level (speaker averages) but not when pauses were observed individually. Genre differences did not manifest consistently and analogically for the two measures. The findings provide evidence that pausing is used systematically by speakers in read speech to convey not only prosodic phrasing but also text structure, among other things. © 2023 by the authors.",TestAnalysis
"The trend of E-commerce and online shopping is increasing rapidly. However, it is difficult to know about the quality of items from pictures and videos available on the online stores. Therefore, online stores and independent products reviews sites share user reviews about the products for the ease of buyers to find out the best quality products. The proposed work is about measuring and detecting product quality based on consumers’ attitude in product reviews. Predicting the quality of a product from customers’ reviews is a challenging and novel research area. Natural Language Processing and machine learning methods are popularly employed to identify product quality from customer reviews. Most of the existing research for the product review system has been done using traditional sentiment analysis and opinion mining. Going beyond the constraints of opinion and sentiment, such as a deeper description of the input text, is made possible by utilizing appraisal categories. The main focus of this study is exploiting the quality subcategory of the appraisal framework in order to predict the quality of the product. This paper presents a quality of product-based classification model (named QLeBERT) by combining quality of product-related lexicon, N-grams, Bidirectional Encoder Representations from Transformers (BERT), and Bidirectional Long Short Term Memory (BiLSTM). In the proposed model, the quality of the product-related lexicon, N-grams, and BERT are employed to generate vectors of words from part of the customers’ reviews. The main contribution of this work is the preparation of the quality of product-related lexicon dictionary based on an appraisal framework and automatically labelling the data accordingly before using them as the training data in the BiLSTM model. The proposed model is evaluated on an Amazon product reviews dataset. The proposed QLeBERT outperforms the existing state-of-the-art models by achieving an F1macro score of 0.91 in binary classification. © 2023 by the authors.",TestAnalysis
"The growing enthusiasm for STEAM (STEM + Arts) initiatives reflects the rich potential for inquiry and integration between arts and sciences. Biologically informed poetry is an active interdisciplinary area of creation and analysis that requires biologically attuned illustration and translation to retain its STEAM effectiveness across linguistic barriers. Pablo Neruda, Chilean poet and Nobel laureate, was a keen observer and informed scholar who wove his scientific knowledge into his poetry. He was particularly obsessed with the sea and featured marine invertebrates in many of his works. The molluscs in his poem “Mollusca Gongorina” are unusual in being specified by their Latin genera. In this zoopoetic analysis, we first ask whether the 11 specimens can be identified to species and find that eight have ready identifications based on morphology in the poem's text, and three have likely identifications based on the poem's themes. We then examine illustrations and translations of the poem, identify where they are consonant or dissonant with the biology of the original, and propose alternative translations informed by the species' identities. Our zoopoetic approach to what could today be considered a STEAMy poem surfaces the beauty of its imagery and narrative, reflects the biological sophistication of the poet, enhances the coherence of its translations making it accessible to a wider audience, and allows it to enhance the biological literacy of the reader. © 2023 The American Microscopical Society LLC.",TestAnalysis
"The potential applications of blockchain technology across various business functions and industries have generated significant interest. However, its underlying knowledge structure remains unclear. This study aimed to gain a deeper understanding of the technological domain and knowledge structure of blockchain technology by analyzing 4753 USPTO patent data from 2008 to 2019. We used multiple approaches, such as analyzing patent filing volumes, constructing co-citation networks, and examining text (patent abstract) data with a variant of bidirectional encoder representations from transformers (BERT). The results demonstrate the advantages of using an NLP-based BERT text analysis approach for examining technological knowledge and relationships within the blockchain technology field. Our findings reveal that the field of blockchain technology is expanding and diversifying, with increasing patent filings in both cryptocurrency and distributed ledger technologies and growing knowledge similarity between these two subdomains. We also found that patent assignees (companies) engage differently in innovative activities within the blockchain technology domain based on their prior experience in the field. These results hold potential for informing future research in emerging technology studies and guiding industry and policy decisions related to blockchain technology. © 2023 by the authors.",TestAnalysis
"In the field of life sciences there is a growing need for literature analysis tools that help scientists tackle information overload. Europe PubMed Central (Europe PMC), a partner of PubMed Central (PMC; National Library of Medicine, 2022), is an open access database of over 41 million life science publications and preprints, enriched with supporting data, reviews, protocols, and other relevant resources. Europe PMC is a trusted repository of choice for many life science funders (Europe PMC, 2022a), offering a suite of innovative search tools that allow users to search and evaluate the literature, including finding highly cited articles, preprints with community peer reviews, or papers referencing a proteomics dataset in the figure legend. In addition, Europe PMC utilizes text-mining to help researchers identify key terms and find data and evidence in the literature. First-time users often do not utilize the wealth of tools Europe PMC offers and can feel overwhelmed about how to perform the most effective search. This protocol, describing how to search and evaluate publications and preprints using Europe PMC, demonstrates how to carry out more efficient and effective literature searches using the tools provided by Europe PMC. This includes discovering the latest findings on a research topic, following research from a specific author, journal, or preprint server, exploring literature on a new method, expanding your reading list with relevant articles, as well as accessing and evaluating publications and preprints of interest. © 2023 EMBL-EBI. Current Protocols published by Wiley Periodicals LLC. Basic Protocol 1: Finding articles and preprints on a topic of interest. Basic Protocol 2: Accessing an article. Basic Protocol 3: Browsing the article. Basic Protocol 4: Evaluating the article. Basic Protocol 5: Refining search results. Basic Protocol 6: Finding research by author. Basic Protocol 7: Finding a specific article. Basic Protocol 8: Finding information about a methodology. Basic Protocol 9: Finding evidence of biological interactions, relations, and modifications. Basic Protocol 10: Finding data behind a publication. Basic Protocol 11: Expanding a reading list and building a bibliography. Basic Protocol 12: Staying on top of the current literature. © 2023 EMBL-EBI. Current Protocols published by Wiley Periodicals LLC.",TestAnalysis
"With the rapid development of social network platforms, Sina Weibo has become the main carrier for modern netizens to express public views and emotions. How to obtain the tendency of public opinion and analyze the text’s emotion more accurately and reasonably has become one of the main challenges for the government to monitor public opinion in the future. Due to the sparseness of Weibo text data and the complex semantics of Chinese, this paper proposes an emotion analysis model based on the Bidirectional Encoder Representation from Transformers pre-training model (BERT), Fast Gradient Method (FGM) and the bidirectional Gated Recurrent Unit (BiGRU), namely BERT-FGM-BiGRU model. Aiming to solve the problem of text polysemy and improve the extraction effect and classification ability of text features, this paper adopts the BERT pre-training model for word vector representation and BiGRU for text feature extraction. In order to improve the generalization ability of the model, this paper uses the FGM adversarial training algorithm to perturb the data. Therefore, a BERT-FGM-BiGRU model is constructed with the goal of sentiment analysis. This paper takes the Chinese text data from the Sina Weibo platform during COVID-19 as the research object. By comparing the BERT-FGM-BiGRU model with the traditional model, and combining the temporal and spatial characteristics, it further studies the changing trend of user sentiment. Finally, the results show that the BERT-FGM-BiGRU model has the best classification effect and the highest accuracy compared with other models, which provides a scientific method for government departments to supervise public opinion. Based on the classification results of this model and combined with the temporal and spatial characteristics, it can be found that public sentiment is spatially closely related to the severity of the pandemic. Due to the imbalance of information sources, the public showed negative emotions of fear and worry in the early and middle stages, while in the later stage, the public sentiment gradually changed from negative to positive and hopeful with the improvement of the epidemic situation. © 2023 by the authors.",TestAnalysis
"PURPOSE: A range of materials for single-tooth computer-aided design and computer-aided manufacturing (CAD-CAM) restorations have been introduced that may affect CAM accuracy. This study aimed to review articles evaluating marginal and internal fit of lithium disilicate (LD) and zirconia (Z) crowns fabricated by CAD-CAM systems using intraoral optical scanners (IOS). MATERIALS AND METHODS: Under the guidelines of Preferred Reporting Items for Systematic Reviews and Meta-analysis (PRISMA), a systematic review was performed along with an electronic article search in the Medline/Pubmed database. The articles were limited to those in the English language that were published within the past ten years. RESULTS: The initial search resulted in 50 articles and of those, a total of 18 articles were selected for full-text review following abstract evaluation. Eight articles that did not meet the inclusion criteria were excluded and the remaining ten articles, which provided internal and marginal gap values, were used in this review. For LD crowns, marginal gap values ranged between 45µm and 190.2µm. For Z crowns, the values varied between 39µm and 126.4µm. For LD crowns, the internal gap values were between 57.8µm and 475.4µm, and for Z crowns, the values were between 79µm and 205.8µm. CONCLUSION: The outcome of this review suggests that clinically acceptable marginal and internal fit can be attained with LD and Z all-ceramic CAD-CAM crowns using digital impressions. Additionally, it has been found that LD and Z ceramics provide similar marginal gap values, but LD material provides better internal fit than Z.",TestAnalysis
"Aspect-based sentiment analysis is a fine-grained sentiment analysis that focuses on the sentiment polarity of different aspects of text, and most current research methods use a combination of dependent syntactic analysis and graphical neural networks. In this paper, a graph attention network aspect-based sentiment analysis model based on the weighting of dependencies (WGAT) is designed to address the problem in that traditional models do not sufficiently analyse the types of syntactic dependencies; in the proposed model, graph attention networks can be weighted and averaged according to the importance of different nodes when aggregating information. The model first transforms the input text into a low-dimensional word vector through pretraining, while generating a dependency syntax graph by analysing the dependency syntax of the input text and constructing a dependency weighted adjacency matrix according to the importance of different dependencies in the graph. The word vector and the dependency weighted adjacency matrix are then fed into a graph attention network for feature extraction, and sentiment polarity is predicted through the classification layer. The model can focus on syntactic dependencies that are more important for sentiment classification during training, and the results of the comparison experiments on the Semeval-2014 laptop and restaurant datasets and the ACL-14 Twitter social comment dataset show that the WGAT model has significantly improved accuracy and F1 values compared to other baseline models, validating its effectiveness in aspect-level sentiment analysis tasks. © 2023 by the authors.",TestAnalysis
"Background: Artificial intelligence (AI) techniques and methodologies for problem solving are emerging as formal tools essential to assist in nursing care. Given their potential to improve workflows and to guide decision making, several studies have been developed; however, little is known about their impact, particularly on decision making. Objective: The aim of this study was to map the existing research on the use of AI in decision making in nursing. With this review protocol, we aimed to map the existing research on the use of AI in nursing decision making. Methods: A scoping review was conducted following the framework proposed by the Joanna Briggs Institute (JBI). The search strategy was tailored to each database/repository to identify relevant studies. The contained articles were the targets of the data extraction, which was conducted by two independent researchers. In the event of discrepancies, a third researcher was consulted. Results: This review included quantitative, qualitative and mixed method studies. Primary studies, systematic reviews, dissertations, opinion texts and gray literature were considered according to the three steps that the JBI has defined for scoping reviews. Conclusions: This scoping review synthesized knowledge that could help advance new scientific developments and find significant and valuable outcomes for patients, caregivers and leaders in decision making. This review was also intended to encourage the development of research lines that may be useful for the development of AI tools for decision making. © 2023 by the authors.",TestAnalysis
"Purpose: The purpose of this study was twofold: (a) to determine whether there are speech rhythm differences between preschool-age children who stutter that were eventually diagnosed as persisting (CWS-Per) or recovered (CWS-Rec) and children who do not stutter (CWNS), using empirical spectral analysis and empirical mode decomposition of the speech amplitude envelope, and (b) to determine whether speech rhythm characteristics close to onset are predictive of later persistence. Method: Fifty children (3–4 years of age) participated in the study. Approxi-mately 2–2.5 years after the experimental testing took place, children were assigned to the following groups: CWS-Per (nine boys, one girl), CWS-Rec (18 boys, two girls), and CWNS (18 boys, two girls). All children produced a narrative based on a text-free storybook. From the audio recordings of these narra-tives, fluent utterances were selected for each child from which seven envelope-based measures were extracted. Group-based differences on each measure as well as predictive analyses were conducted to identify measures that discriminate CWS-Per versus CWS-Rec. Results: CWS-Per were found to have a relatively higher degree of power in suprasyllabic oscillations and greater variability in the timing of syllabic rhythms especially for longer utterances. A logistic regression model using two speech rhythm measures was able to discriminate the eventual outcome of recovery versus persistence, with 80% sensitivity and 75% specificity. Conclusion: Findings suggest that envelope-based speech rhythm measures are a promising approach to assess speech rhythm differences in developmental stuttering, and its potential for identification of children at risk of developing persistent stuttering should be investigated further. © 2023 American Speech-Language-Hearing Association.",TestAnalysis
"Background: Recent years have seen major advancements in xenotransplantation: the first pig-to-human heart transplant, the development of a brain-dead recipient model for kidney xenotransplantation, and the registration of the first xenokidney clinical trial. The attitudes of patients with kidney disease or transplants on xenotransplantation and an assessment of their reservations and considerations regarding the technology are crucial to successful clinical translation and eventual widespread implementation. Methods: This systematic review was registered through PROSPERO (CRD42022344581) prior to initiation of the study and reported using the Preferred Reporting Items for Systematic Review and Meta-Analyses (PRISMA) guidelines. We included studies that evaluated attitudes towards and willingness to undergo xenotransplantation in patients with end-stage renal disease (ESRD), including those who had already undergone transplantation. MEDLINE (via Ovid), Embase (via Elsevier), and Web of Science (via Clarivate) were searched from database inception to July 15, 2022 by an experienced medical librarian for studies on xenotransplantation and attitudes. Abstracts and full text were screened using Covidence software and data items regarding study methodology, patient demographics, and attitudes regarding xenotransplantation were extracted using Microsoft Excel. Risk of bias assessments were performed using the Critical Appraisal Skills Programmed and National Institute of Health study quality assessment tools. Results: Of 1992 studies identified, 14 studies met the inclusion criteria. These studies were conducted across eight countries, four in the United States, for a total of 3114 patients on the kidney waitlist or with a kidney transplant. All patients were over 17 years old and 58% were male. Acceptance of a xenotransplant was assessed using surveys in 12 studies. Sixty-three percent (n = 1354) of kidney patients reported that they would accept a xenotransplant with function comparable to that of an allotransplant. Acceptance of xenografts with inferior function to allografts (15%) or as bridge organs (35%) to allotransplantation was lower. Specific concerns expressed by patients included graft function, infection, social stigma, and animal rights. Subgroup analyses showed higher acceptance in already transplanted compared to waitlist patients and white compared to Black Americans. Conclusion: An understanding of patient attitudes and reservations is key to the successful execution of the first xenotransplantation clinical trials. This study compiles important factors to consider, such as patient concerns, attitudes regarding practical clinical scenarios for the use of xenotransplantation, and the impact of demographic factors on acceptance of this emerging technology. © 2023 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd.",TestAnalysis
"This paper uses supervised machine learning (sentiment analysis) to analyze the sentiments of social media information in the P2P lending market. After segmentation, filtering, feature word extraction, and model training of the text information captured by Python, the sentiments of media and social media information were calculated to examine the effect of media and social media sentiments on default probability and cost of capital of peer-to-peer (P2P) lending platforms in China (2015–2019). We find that only positive changes in media and social media sentiment have significantly negative effects on the platform’s default probability and cost of capital, while negative changes in sentiment do not have any effects. We conclude the existence of an asymmetric effect of media and social media sentiments in the Chinese peer-to-peer lending market. © 2023 by the authors.",TestAnalysis
"The political debate in social networks, and its derivatives such as hate speech, has surfaced at the top of the social agenda due to its impact on public opinion and, consequently, in the communication strategies of political parties, public institutions, media corporations, and lobbies. The scientific community has been working to respond to the demand for tools that allow studying the political attitude of citizens in these networks, focusing on sentiment analysis methodologies. However, their work has been hampered by several significant challenges, such as the absence of standardized investigation methodologies, the filtering of content created by bots and spammers, or the interpretation of slang and other conventionalisms that are specific to microblogging platforms. In addition to these challenges and the generic problems related to the interpretation of human language, researchers from the Spanish-speaking community have found themselves with the additional problem of developing strategies and methodologies suitable for Spanish text, in a scenario dominated by research aimed at the English language. In this paper, we present a systematic review that describes the state of the art in sentiment analysis methods for politics and hate speech contents in the Spanish language, by systematically reviewing the relevant papers available. © 2003-2012 IEEE.",TestAnalysis
"Gamers’ perceptions of using competitive digital games, especially concerning anxiety and socialization, have raised doubts about the benefits of playing such games. Since different studies highlight different results, this research aims to explore these differences by analyzing the perceptions of adults involved in playing a competitive digital game, in this case, FIFA, considering data that were collected during the COVID-19 pandemic period. The main question is ‘How do adults perceive anxiety, stress, and socialization when playing the FIFA digital game?’. The research comprises two studies involving volunteer participants: In the first part, which adopts a qualitative approach, the participants’ perceptions of what they think and feel when playing FIFA were analyzed and interpreted using text mining analysis. In the second, a quantitative study, FIFA users’ perceptions of the gaming experience were statistically analyzed. The results show that adult users tend to refer to positive perceived stress and socialization. The fact that participants identified manipulations and interference in the game and no longer allowed its use to influence their mood reveals that perceptions of attacks of rage were considered possible reactions to the use of the game, interpreted from the interface, and leading to the creation of knowledge. © 2022 by the authors.",TestAnalysis
"Do extreme events have a significant effect about textual sentiment? The purpose of this article is to highlight the need to correct the estimation of indicators of economic uncertainty. The indicators were constructed from textual data about the perspective of extreme events. For this purpose, based on data extracted from the minutes of mee-tings of the Monetary Policy of eighteen Central Banks, we estimated two variables of perception of economic uncertainty: the first using only a traditional sentiment dictio-nary and the second incorporating terms associated with the extreme event (COVID- 19 Pandemic) in its word list. Initial results show that there is a significant effect of COVID-19 on the estimation of the perception of economic uncertainty; this effect acts as an accelerator that potentiates its impact. It was evident that incorporating conjunctural issues - be it local or global - is indispensable when performing sentiment analysis in texts during extreme events. Moreover, failing to take conjunctural issues into account throughout the estimation process can result in variables with biased in-formation. © 2023 The Authors",TestAnalysis
"PURPOSE:Consent processes are critical for clinical care and research and may benefit from incorporating digital strategies. We compared an electronic informed consent (eIC) option to paper consent across four outcomes: (1) technology burden, (2) protocol comprehension, (3) participant agency (ability to self-advocate), and (4) completion of required document fields. METHODS:We assessed participant experience with eIC processes compared with traditional paper-based consenting using surveys and compared completeness of required fields, over 3 years (2019-2021). Participants who consented to a clinical trial at a large academic cancer center via paper or eIC were invited to either pre-COVID-19 pandemic survey 1 (technology burden) or intrapandemic survey 2 (comprehension and agency). Consent document completeness was assessed via electronic health records.RESULTS:On survey 1, 83% of participants (n = 777) indicated eIC was easy or very easy to use; discomfort with technology overall was not correlated with discomfort using eIC. For survey 2, eIC (n = 262) and paper consenters (n = 193) had similar comprehension scores. All participants responded favorably to at least five of six agency statements; however, eIC generated a higher proportion of positive free-text comments (P <.05), with themes such as thoroughness of the discussion and consenter professionalism. eIC use yielded no completeness errors across 235 consents versus 6.4% for paper (P <.001).CONCLUSION:Our findings suggest that eIC when compared with paper (1) did not increase technology burden, (2) supported comparable comprehension, (3) upheld key elements of participant agency, and (4) increased completion of mandatory consent fields. The results support a broader call for organizations to offer eIC for clinical research discussions to enhance the overall participant experience and increase the completeness of the consent process.  © American Society of Clinical Oncology.",TestAnalysis
"It is important to classify academic papers in a fine-grained manner to uncover deeper implicit themes and semantics in papers for better semantic retrieval, paper recommendation, research trend prediction, topic analysis, and a series of other functions. Based on the ontology of the climate change domain, this study used an unsupervised approach to combine two methods, syntactic structure and semantic modeling, to build a framework of subject-indexing techniques for academic papers in the climate change domain. The framework automatically indexes a set of conceptual terms as research topics from the domain ontology by inputting the titles, abstracts and keywords of the papers using natural language processing techniques such as syntactic dependencies, text similarity calculation, pre-trained language models, semantic similarity calculation, and weighting factors such as word frequency statistics and graph path calculation. Finally, we evaluated the proposed method using the gold standard of manually annotated articles and demonstrated significant improvements over the other five alternative methods in terms of precision, recall and F1-score. Overall, the method proposed in this study is able to identify the research topics of academic papers more accurately, and also provides useful references for the application of domain ontologies and unsupervised data annotation. © 2023 by the authors.",TestAnalysis
"Objective: To assess the influence of systemic sclerosis (SSc) on the survival rate of dental implants in SSc patients receiving implant-supported treatments. Methods: The Preferred Reporting Items for Systematic Reviews and Meta-analysis (PRISMA) Statement and the Cochrane Collaboration's guiding principles were followed during the study's execution. The data from three databases, PubMed, Google Scholar, and Scopus, available until January 2023, were used to compile the material for our research. Only English-language publications were submitted for this research and evaluated based on their titles, abstracts, and full texts. For performing a quality assessment, quality scores were calculated. Results: The total number of patients and implants studied were 37 and 153, respectively, all having had scleroderma. The patients’ ages ranged from 28 to 77 years old, with a mean (SD) age of 58.16 (12.88). All the patients in the case reports and most in the case series study were female. The range of follow-up duration was from 1 to 10 years. In case report studies, the survival rate was 100%; in case series, it was 89.2%. Conclusion: The SSc status had no discernible impact on the implant survival rate. Implant-based treatments in SSc patients should not worsen the overall morbidity and should not conflict with systemic treatments. Before starting implant therapy, a thorough risk assessment is essential, though. © 2023 The Authors. Immunity, Inflammation and Disease published by John Wiley & Sons Ltd.",TestAnalysis
"The Universal Protein Resource (UniProt) is a comprehensive resource for protein sequence and annotation data (UniProt Consortium, 2023). The UniProt website receives about 800,000 unique visitors per month and is the primary means to access UniProt. Along with various datasets that you can search, UniProt provides four main tools. These are the “BLAST” tool for sequence similarity searching, the “Align” tool for multiple sequence alignment, the “Peptide Search” tool for retrieving proteins containing a short peptide sequence, and the “Retrieve/ID Mapping” tool for using a list of identifiers to retrieve UniProt Knowledgebase (UniProtKB) proteins and to convert database identifiers from UniProt to external databases or vice versa. This article provides four basic protocols and seven alternate protocols for using UniProt tools. © 2023 The Authors. Current Protocols published by Wiley Periodicals LLC. Basic Protocol 1: Basic local alignment search tool (BLAST) in UniProt. Alternate Protocol 1: BLAST through UniProt text search results pages. Alternate Protocol 2: BLAST through UniProt basket. Basic Protocol 2: Multiple sequence alignment in UniProt. Alternate Protocol 3: Align tool through UniProt results pages and entry pages. Alternate Protocol 4: Align tool through UniProt basket. Basic Protocol 3: Peptide search in UniProt. Basic Protocol 4: Batch retrieval and ID mapping in UniProt. Alternate Protocol 5: Retrieve/ID Mapping tool through UniProt text search results pages and BLAST and Align results pages. Alternate Protocol 6: Retrieve/ID Mapping tool through UniProt basket. Alternate Protocol 7: Retrieve/ID Mapping tool through UniProt search box. © 2023 The Authors. Current Protocols published by Wiley Periodicals LLC.",TestAnalysis
"The article is carried out within the framework of a scientific project, is devoted to the analysis of book maps of Russian authors of the XIX – early XX centurшуы, cataloging and introduction into scientific circulation of cartographic unique, little-known data in order to study the visual history of Kazakhstan. The source base was the book collections of rare editions with book maps of the National Library named after Alisher Navoi, Tashkent (NBUz) and of the Orenburg Universal Scientific Library named after N.K. Krupskaya (OUSL). During the preparation of the catalog, a single catalog description of the book maps was developed. The methodology of the research is a comprehensive interdisciplinary approach of broad interaction between the humanities and natural sciences, which made it possible to identify, analyze and prepare a bibliography of book maps. A cartographic method is used as a special method, which allows cataloging and description of book maps. The operational and functional advantages of the catalog of cartographic materials are substantiated, where each researcher can get an answer where and under what number the necessary book with a book maps is located. In the description of the book maps using the materials of the book, additional opportunities appear to characterize historical facts more fully and visually show the dynamics of the events taking place. Comparison of the book maps and the text showed that the cartographic material contains information that is not in the text of the book. The historical details of the formation of the border, possible ways of melioration of the Central Asian region unknown pages of military history, the participation of the Kazakhs in the military campaign to Khiva in 1839-1840, the peculiarities of the distribution and nomadic ways of the Kazakhs district were revealed. The authors conclude that Russian scientists, travelers, bureaucrats and the military left a significant book heritage with phenomenal cartographic material for studying the visual history of Kazakhstan. Copyright © 2023 by Cherkas Global University.",TestAnalysis
"This Cord erratum Injury” corrects (J. Haefeli, the article Mabray “Multivariate MC, Whetstone Analysis WD, of et MRI al. AJNR Biomarkers Am J Neuroradiol for Predicting 2017;38:648 Neurologic –55 Impairment 10.3174/ajnr.A5021). in Cervical Spinal In the original publication, there was an error in the Materials and Methods section on page 649 under the Image Analysis heading related to a description of the Brain and Spinal Injury Center (BASIC) score grading, which erroneously included a description of 6 distinct grades. The corrected version of text for this section is below and describes the correct 5 grades (grade 0 through grade 4) composing the BASIC score. A neuroradiology fellow (M.C.M.) and attending physician (J.F.T.) performed consensus MR imaging ratings for all metrics while blinded to clinical outcome. The interrater reliability and BASIC axial MR imaging grading have been previously described as follows:4,30 grade 0, no cord signal abnormality; grade I, T2 hyperintensity confined to GM; grade II, intramedullary T2 hyperintensity extending beyond the expected gray matter margins to involve spinal white matter but not involving the entire transverse extent of the spinal cord; grade III, T2 hyperintensity involving the entire axial plane of the spinal cord; grade IV, grade III injury with the addition of foci of T2 hypointensity consistent with hemorrhage. Sagittal grading was assigned as previously described as follows: grade I, no spinal cord signal abnormality; grade II, single-level T2 hyperintensity; grade III, .1 vertebral-level T2 signal hyperintensity; grade IV, T2 signal hyperintensity with areas of hypointensity representing hemorrhage.1,19 The greatest length (millimeters) of injury on sagittal T2 was measured as described in the National Institutes of Health/National Institute of Neurological Disorders and Stroke SCI Common Data Elements, Version 1.0.3 Maximum canal compromise (MCC) and maximum spinal cord compression (MSCC) assessed midsagittal images by dividing the anterior-posterior diameter of the canal (on sagittal T1 for MCC) and the anterior-posterior diameter of spinal cord (on sagittal T2 for MSCC) by the average of the canal or spinal cord above and below as previously described.8,15,16,22,. © 2023 American Society of Neuroradiology. All rights reserved.",TestAnalysis
"Phrase-final syllable duration and pauses are generally considered to be positively correlated: The stronger the boundary, the longer the duration of phrase-final syllables, and the more likely or longer a pause. Exploring a large sample of complex literary prose texts read aloud, we examined pause likelihood and duration, pre-boundary syllable duration, and the pitch excursion at prosodic boundaries. Comparing these features across six predicted levels of boundary strength (level 0: no break; 1: simple phrase break; 2: short comma phrase break; 3: long comma phrase break; 4: sentence boundary; 5: direct speech boundary), we find that they are not correlated in a simple monotonic fashion. Whereas pause duration monotonically increases with boundary strength, both pre-boundary syllable duration and the pitch excursion on the pre-boundary syllable are largest for level-2 breaks and decrease significantly through levels 3 to 5. Our analysis suggests that pre-boundary syllable duration is partly contingent on the tonal realization, which is subject to f0 declination as the utterance progresses. We also surmise that pre-boundary syllable duration reflects differences in planning complexity for the different prosodic and syntactic boundaries. Overall, this study shows that a simple monotonic correlation between pause duration and pre-boundary syllable duration is not valid. © 2023 The Authors",TestAnalysis
"Aims and objectives Studies have shown that the COVID-19 pandemic has taken a toll on individuals who interact with patients with SARS-CoV-2 but focused largely on clinicians in acute care settings. This qualitative descriptive study aimed to understand the experiences and well-being of essential workers across settings during the pandemic. Background Multiple studies of the well-being of individuals who have cared for patients during the pandemic have included interviews of clinicians from acute care settings and revealed high levels of stress. However, other essential workers have not been included in most of those studies, yet they may also experience stress. Methods Individuals who participated in an online study of anxiety, depression, traumatic distress, and insomnia, were invited to provide a free-text comment if they had anything to add. A total of 2,762 essential workers (e.g., nurses, physicians, chaplains, respiratory therapists, emergency medical technicians, housekeeping, and food service staff, etc.) participated in the study with 1,079 (39%) providing text responses. Thematic analysis was used to analyze those responses. Results Four themes with eight sub-themes were: Facing hopelessness, yet looking for hope; Witnessing frequent death; Experiencing disillusionment and disruption within the healthcare system, and Escalating emotional and physical health problems. Conclusions The study revealed major psychological and physical stress among essential workers. Understanding highly stressful experiences during the pandemic is essential to identify strategies that ameliorate stress and prevent its negative consequences. This study adds to the research on the psychological and physical impact of the pandemic on workers, including non-clinical support personnel often overlooked as experiencing major negative effects. Relevance to clinical practice The magnitude of stress among all levels of essential workers suggests the need to develop strategies to prevent or alleviate stress across disciplines and all categories of workers. © 2023 Copel et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Acoustic emission (AE) was monitored during stress intensity factor (SIF)-controlled high-cycle fatigue (HCF) tests on an aluminum 2024-T3 specimen with a fatigue crack growing at its center. The SIF control was implemented in such a manner that crack growth could be slowed down and even inhibited while the fatigue experiment continued. In the beginning, a specific type of AE signal was observed while the crack was allowed to grow to up to approximately 9.4 mm in length. Subsequently, the load was reduced in order to control the SIF value at the crack tip and to inhibit the crack growth. AE signals were recorded even when the crack stopped growing, although the specific signature of these AE signals was different from those observed when the crack was growing, as discussed in the text. The gist of the phenomenon reported in this article is that strong AE signals could still be observed even when the crack stopped growing. These latter AE signals could be due to rubbing and clapping of the crack faying surfaces. Travel analysis was consistently performed to ensure that these AE signals were originating from the crack, though not necessarily from the crack tip. In addition, absorbing clay wave dams were built around the crack region to inhibit boundary reflections and grip noise. Fast Fourier Transform (FFT) and Choi–Williams Transform (CWT) analysis were performed to classify the AE signals. It was observed that the AE signals related to crack growth were clearly different from the AE signals originating from the crack while the crack was not growing. Strong S0-mode Lamb wave components were observed in the crack-growth AE signals, whereas strong A0-mode Lamb wave components dominated the non-crack-growth AE signals. Pearson correlation clustering analysis was performed to compare the crack-growth and non-crack growth AE signals. We propose that the fatigue-crack faying surfaces may undergo rubbing and/or clapping during fatigue cyclic loading and thus produce strong AE signals that are registered by the AE system as hits, although the crack is not actually growing. The understanding of this phenomenon is very important for the design of the structural health monitoring (SHM) system based on AE-hit signal capture and interpretation. © 2023 by the authors.",TestAnalysis
"Digitization and transcription of historic documents offer new research opportunities for humanists and are the topics of many edition projects. However, manual work is still required for the main phases of layout recognition and the subsequent optical character recognition (OCR) of early printed documents. This paper describes and evaluates how deep learning approaches recognize text lines and can be extended to layout recognition using background knowledge. The evaluation was performed on five corpora of early prints from the 15th and 16th Centuries, representing a variety of layout features. While the main text with standard layouts could be recognized in the correct reading order with a precision and recall of up to 99.9%, also complex layouts were recognized at a rate as high as 90% by using background knowledge, the full potential of which was revealed if many pages of the same source were transcribed. © 2023 by the authors.",TestAnalysis
"Analysing writing development as a function of foreign language competence is important in secondary school children because the developmental patterns are strongest at a young age when successful interventions are needed. Although a number of researchers have explored the degree to which specific textual characteristics in EFL students’ essays are associated with high and low ratings by teachers, the extent to which such characteristics are associated with rater-mediated assessment under standard exam conditions remains relatively unexplored. Motivated by the above void in pertinent literature, the overall aim of the present study was to investigate the relationship between specific discourse features present in the writing scripts of EFL learners sitting for the British Council’s APTIS for TEENS exam and the assigned scores during operational scoring by specially trained raters. A total of 800 international EFL students aged 13 to 15 years old took part in the study, and 800 scored written essays on the same task prompt of the pertinent test produced under standard exam conditions were analysed. The results showed statistically significant differences (p ≤ 0.05) between the linguistic features identified in the essays produced by young EFL learners at different levels of language competence. The main text features that were repeatedly found to make a significant contribution to distinguishing scores assigned to texts both within and across levels were word frequency, word abstractness, lexical diversity, lexical and semantic overlap, all of which could be used to obtain a numerical cut-off point between proficiency levels. These findings support the notion that progress in L2 writing is primarily associated with producing more elaborate texts with more sophisticated words, more complex sentence structure and fewer cohesive features as a function of increased language competence. The findings of the study could provide practical guidance to EFL teachers, material developers and test designers as to the kind of linguistic strategies young EFL learners develop as a function of their level of language competence and suggestions to consider when designing EFL classroom curricula, writing skills textbooks and exam papers on written production. © 2022 by the author.",TestAnalysis
"Background This systematic review evaluates pneumolysin (PLY) as a target for new treatments against pneumococcal infections. Pneumolysin is one of the main virulence factors produced by all types of pneumococci. This toxin (53 kDa) is a highly conserved protein that binds to cholesterol in eukaryotic cells, forming pores that lead to cell destruction. Methods The databases consulted were MEDLINE, Web of Science, and Scopus. Articles were independently screened by title, abstract, and full text by two researchers, and using consensus to resolve any disagreements that occurred. Articles in other languages different from English, patents, cases report, notes, chapter books and reviews were excluded. Searches were restricted to the years 2000 to 2021. Methodological quality was evaluated using OHAT framework. Results Forty-one articles describing the effects of different molecules that inhibit PLY were reviewed. Briefly, the inhibitory molecules found were classified into three main groups: those exerting a direct effect by binding and/or blocking PLY, those acting indirectly by preventing its effects on host cells, and those whose mechanisms are unknown. Although many molecules are proposed as toxin blockers, only some of them, such as antibiotics, peptides, sterols, and statins, have the probability of being implemented as clinical treatment. In contrast, for other molecules, there are limited studies that demonstrate efficacy in animal models with sufficient reliability. Discussion Most of the studies reviewed has a good level of confidence. However, one of the limitations of this systematic review is the lack of homogeneity of the studies, what prevented to carry out a statistical comparison of the results or meta-analysis. Conclusion A panel of molecules blocking PLY activity are associated with the improvement of the inflammatory process triggered by the pneumococcal infection. Some molecules have already been used in humans for other purposes, so they could be safe for use in patients with pneumococcal infections. These patients might benefit from a second line treatment during the initial stages of the infection preventing acute respiratory distress syndrome and invasive pneumococcal diseases. Additional research using the presented set of compounds might further improve the clinical management of these patients. Copyright: © 2023 Cima Cabal et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"This article presents detailed descriptions of procedures and troubleshooting tips for solid-supported membrane (SSM)-based electrophysiology assays (SURFE²R) to measure electrogenic solute carrier transporter proteins (SLCs) and assess the effects of compounds that modulate their activity. SURFE²R allows the use of the standard 96-well format, making it an ideal platform for tertiary assays in a drug-discovery campaign. The assays are performed with cell-line-derived membrane fractions or proteoliposomes containing the transporter of interest. Three main protocols are described for the isolation of membrane fractions from cell culture and the generation of proteoliposomes containing the transporter of interest. Additionally, detailed protocols for SURFE²R single concentration and dose-response experiments are included to measure the potencies of test compounds in stimulating or inhibiting transporter function (EC50 or IC50 values, respectively) and kinetic functional assays to calculate apparent affinity (kM) and maximal velocity (Vmax) of substrate uptake. © 2023 Sanofi. Current Protocols published by Wiley Periodicals LLC. This article was corrected on 23 March 2023. See the end of the full text for details. PROTOCOL GROUP 1: Sample preparation for SSM-based electrophysiology assays. Support Protocol 1: Production of cell batches. Support Protocol 2: Simple isolation of cell membranes. Alternate Protocol 1: Isolation of cell membranes with sucrose gradient pre-purification. Support Protocol 3: Production and isolation of liposomes. Support Protocol 4: Preparation of sensor with isolated cell membranes. Alternate Protocol 2: Preparation of sensor with isolated proteoliposomes. PROTOCOL GROUP 2: Determination of assay parameters for SSM-based electrophysiology assay. Support Protocol 5: Assay with stable buffer. Alternate Protocol 3: Assay with ion gradient. Support Protocol 6: Determination of membrane/liposome concentration. Support Protocol 7: Determination of substrate dependency kM. PROTOCOL GROUP 3: Determination of advanced assay parameters for SSM-based electrophysiology assays. Support Protocol 8: Assessment of ion concentration dependency. Support Protocol 9: Assessment of pH dependency. Support Protocol 10: Assessment of DMSO dependency. Support Protocol 11: Assessment of signal stability with multiple activations. PROTOCOL GROUP 4: Compound testing through SSM-based electrophysiology assays using SURFE²R apparatus. Support Protocol 12: Assessment of signal specificity of a published inhibitor or unknown compound(s). Support Protocol 13: Compound wash-out. Support Protocol 14: Statistical analysis. © 2023 Sanofi. Current Protocols published by Wiley Periodicals LLC.",TestAnalysis
"Using data on Chinese A-share listed firms from 2008 to 2017, we explore how corporate social responsibility (CSR) performance is affected by managerial short-termism and what factors influence the association between the two. First, by employing text analysis in conjunction with machine learning, we construct a new managerial short-termism indicator. Using panel fixed models, we find that managerial short-termism has an adverse impact on CSR performance, and the results are consistent in a series of robustness checks. The heterogeneous test results show that the negative effect is significant only for firms with lower internal corporate governance, for firms in less competitive industries, for firms with less analyst attention, and for state-owned enterprises (SOEs). Additionally, a better institutional environment weakens the negative impact of managerial short-termism on CSR performance. The findings shed light on policy implications for emerging countries. © 2023 The Authors",TestAnalysis
"Background and objectives: Medical notes are narratives that describe the health of the patient in free text format. These notes can be more informative than structured data such as the history of medications or disease conditions. They are routinely collected and can be used to evaluate the patient's risk for developing chronic diseases such as dementia. This study investigates different methodologies for transforming routine care notes into dementia risk classifiers and evaluates the generalizability of these classifiers to new patients and new health care institutions. Methods: The notes collected over the relevant history of the patient are lengthy. In this study, TF-ICF is used to select keywords with the highest discriminative ability between at risk dementia patients and healthy controls. The medical notes are then summarized in the form of occurrences of the selected keywords. Two different encodings of the summary are compared. The first encoding consists of the average of the vector embedding of each keyword occurrence as produced by the BERT or Clinical BERT pre-trained language models. The second encoding aggregates the keywords according to UMLS concepts and uses each concept as an exposure variable. For both encodings, misspellings of the selected keywords are also considered in an effort to improve the predictive performance of the classifiers. A neural network is developed over the first encoding and a gradient boosted trees model is applied to the second encoding. Patients from a single health care institution are used to develop all the classifiers which are then evaluated on held-out patients from the same health care institution as well as test patients from two other health care institutions. Results: The results indicate that it is possible to identify patients at risk for dementia one year ahead of the onset of the disease using medical notes with an AUC of 75% when a gradient boosted trees model is used in conjunction with exposure variables derived from UMLS concepts. However, this performance is not maintained with an embedded feature space and when the classifier is applied to patients from other health care institutions. Moreover, an analysis of the top predictors of the gradient boosted trees model indicates that different features inform the classification depending on whether or not spelling variants of the keywords are included. Conclusion: The present study demonstrates that medical notes can enable risk prediction models for complex chronic diseases such as dementia. However, additional research efforts are needed to improve the generalizability of these models. These efforts should take into consideration the length and localization of the medical notes; the availability of sufficient training data for each disease condition; and the variabilities resulting from different feature engineering techniques. © 2023 The Authors",TestAnalysis
"Background: Good communication is central to effective social work practice, helping to develop constructive working relationships and improve the outcomes of people in receipt of social work services. There is strong consensus that the teaching and learning of communication skills for social work students is an essential component of social work qualifying courses. However, the variation in communication skills training and its components is significant. There is a sizeable body of evidence relating to communication skills training therefore a review of the findings helps to clarify what we know about this important topic in social work education. We conducted this systematic review to determine whether communication skills training for social work students works and which types of communication skills training, if any, were more effective and lead to the most positive outcomes. Objectives: This systematic review aimed to critically evaluate all studies which have investigated the effectiveness of communication skills training programmes for social work students. The research question which the review posed is: ‘What is the effectiveness of communication skills training for improving the communicative abilities of social work students?’ It was intended that the review would provide a robust evaluation of communication skills training for social work students and help explain variations in practice to support educators and policy-makers to make evidence-based decisions in social work education, practice and policy. Search Methods: We conducted a search for published and unpublished studies using a comprehensive search strategy that included multiple electronic databases, research registers, grey literature sources, and reference lists of prior reviews and relevant studies. Selection Criteria: Study selection was based on the following characteristics: Participants were social work students on generic (as opposed to client specific) qualifying courses; Interventions included any form of communication skills training; eligible studies were required to have an appropriate comparator such as no intervention or an alternative intervention; and outcomes included changes in knowledge, attitudes, skills and behaviours. Study selection was not restricted by geography, language, publication date or publication type. Data Collection and Analysis: The search strategy was developed using the terms featuring in existing knowledge and practice reviews and in consultation with social work researchers, academics and the review advisory panel, to ensure that a broad range of terminology was included. One reviewer conducted the database searches, removing duplicates and irrelevant records, after which each record was screened by title and abstract by both reviewers to ensure robustness. Any studies deemed to be potentially eligible were retrieved in full text and screened by both reviewers. Main Results: Fifteen studies met the inclusion criteria. Overall, findings indicate that communication skills training including empathy can be learnt, and that the systematic training of social work students results in some identifiable improvements in their communication skills. However, the evidence is dated, methodological rigour is weak, risk of bias is moderate to high/serious or incomplete, and extreme heterogeneity exists between the primary studies and the interventions they evaluated. As a result, data from the included studies were incomplete, inconsistent, and lacked validity, limiting the findings of this review, whilst identifying that further research is required. Authors’ Conclusions: This review aimed to examine effects of communication skills training on a range of outcomes in social work education. With the exception of skill acquisition, there was insufficient evidence available to offer firm conclusions on other outcomes. For social work educators, our understanding of how communication skills and empathy are taught and learnt remain limited, due to a lack of empirical research and comprehensive discussion. Despite the limitations and variations in educational culture, the findings are still useful, and suggest that communication skills training is likely to be beneficial. One important implication for practice appears to be that the teaching and learning of communication skills in social work education should provide opportunities for students to practice skills in a simulated (or real) environment. For researchers, it is clear that further rigorous research is required. This should include using validated research measures, using research designs which include appropriate counterfactuals, alongside more careful and consistent reporting. The development of the theoretical underpinnings of the interventions used for the teaching and learning of communication skills in social work education is another area that researchers should address. © 2023 The Authors. Campbell Systematic Reviews published by John Wiley & Sons Ltd on behalf of The Campbell Collaboration.",TestAnalysis
"Objective To systematically review the effects of the early childhood physical activity program (ECPAP) on gross motor skill (GMS) in preschool children. Methods We searched Web of Science, PubMed, Cochrane Library, EBSCO SPORTDiscus with Full Text, CNKI, WanFangData and VIP databases to collect randomized controlled trails (RCT) about ECPAP for improving GMS in preschool children from the establishment of the database to August 8, 2022. Two reviewers independently screened the literature, extracted data, and assessed the risk of bias of the included studies. Meta-analysis was then performed using RevMan 5.4.1 and Stata 15.0 software. Results A total of 18 studies including 1 141 children in experimental group and 1 135 children in control group were included. The results of meta-analysis showed that after ECPAP, the GMS (SMD=1.96, 95%CI 1.44 to 2.49), locomotor skills (SMD=1.15, 95%CI 0.83 to 1.46) and manipulative skills (SMD=1.25, 95%CI 0.84 to 1.65) of the experimental group were significantly better than those of the control group (P<0.05). Conclusion ECPAC is considered to significantly promote the GMS of preschool children. Due to the limited quantity and quality of the included studies, more high-quality studies are needed to verify the above conclusion. © 2023 West China University of Medical Science. All rights reserved.",TestAnalysis
"This paper compares the results of a real linear synchronous motor and its digital twin. It differs from other common publications in that it uses only basic mathematical models representing a particular physical principle. In this way, a minimum of input parameters was achieved. At the same time, all model input parameters are normally listed in the motor datasheet or are easily measurable. Nowadays, digital twins are very important for the development of new machines. Achieving accuracy using the finite element method is possible, but the time requirement does not allow real-time simulations. The digital twin in this paper is based on a mathematical model involving temperature dependence. The real motor is loaded at different operating points to better evaluate the quality of the model. The structure of the control loops has a significant effect on the response of the digital twin, so the design is based on the motor driver used. The text focuses on linear synchronous motors, but the methods used can be generalized to the plane of rotary synchronous motors. © 2023, MM publishing Ltd.. All rights reserved.",TestAnalysis
"Considering that the public health sector has been considered as a key stakeholder in climate action, it seems important to understand what interventions are carried out globally by trusted professionals such as nurses engaged in health promotion and environmental health in optimizing the health of individuals, families, and communities toward the dissemination of lifestyle decarbonization and guidance on healthier climate-related choices. The objective of this review was to understand the extent and type of evidence related to the community-based interventions of nurses that are being led or have been implemented thus far with the aim of reducing the health risks from climate change impact in urban areas. The present protocol follows the JBI methodological framework. Databases to be searched include PubMed, MEDLINE complete, CINAHL, Scopus, Embase, Web of Science, SciELO (Scientific Electronic Library Online), and BASE (Bielefeld Academic Search Engine). Hand searched references were also considered for inclusion. This review will include quantitative, qualitative, and mixed methods studies from 2008 onwards. Systematic reviews, text, opinion papers, and the gray literature in English and Portuguese were also considered. Mapping the nurse led interventions or those that have been implemented thus far in urban areas may lead to further reviews that may help identify the best practices and gaps within the field. The results are presented in tabular format alongside a narrative summary. © 2023 by the authors.",TestAnalysis
"Objective The purpose of this study is to evaluate reading time and characteristics of fixations at different distances when looking through different areas of progressive power lenses (PPL) with different power distributions by means of eye-tracking technology. Method A wearable eye tracker system (Tobii-Pro Glasses 3) was used to record the pupil position of 28 PPL subjects when reading at near and distance vision while using 3 different PPL designs: a PPL optimized for distance vision (PPL-Distance), a PPL optimized for near vision (PPL-Near) and one of them balanced for a general use (PPL-Balance). Subjects were asked to read out loud a text displayed on a digital screen located at 5.25m and 0.37m when they were looking through the central and peripheral regions of each PPL. Reading time, total duration of fixations, and the number of fixations were analyzed for each reading condition and PPL. Statistical analysis was carried out using Statgraphics Centurion XVII.II Software. Results The analysis of eye movements at distance-reading vision showed a statistically significant lower reading time (p = 0.004) and lower total duration of fixations (p = 0.01) for PPL-Distance. At near-reading vision, PPL-Near provided statistically significant lower reading time (p<0.001), lower total duration of fixations (p = 0.02), and less fixation count(p<0.001) in comparison with PPL-Balance and PPL-Distance. Conclusions Reading time and fixations characteristics are affected by the power distribution of a PPL. A PPL design with a wider distance region provides better distance-reading performance while a PPL with a wider near area performs better at a near-reading task. The power distribution of PPLs influences the user performance at vision-based tasks. Thus, to provide the user with the best visual experience, PPL selection must consider user needs. © 2023 Concepcion-Grande et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Nowadays, e-learning and web-based learning are the most integrated new learning methods in schools, colleges, and higher educational institutions. The recent web-search-based learning methodological approach has helped online users (learners) to search for the required topics from the available online resources. The learners extracted knowledge from textual, video, and image formats through web searching. This research analyzes the learner’s significant attention to searching for the required information online and develops a new recommendation system using machine learning (ML) to perform the web searching. The learner’s navigation and eye movements are recorded using sensors. The proposed model automatically analyzes the learners’ interests while performing online searches and the origin of the acquired and learned information. The ML model maps the text and video contents and obtains a better recommendation. The proposed model analyzes and tracks online resource usage and comprises the following steps: information logging, information processing, and word mapping operations. The learner’s knowledge of the captured online resources using the sensors is analyzed to enhance the response time, selectivity, and sensitivity. On average, the learners spent more hours accessing the video and the textual information and fewer hours accessing the images. The percentage of participants addressing the two different subject quizzes, Q1 and Q2, increased when the learners attempted the quiz after the web search; 43.67% of the learners addressed the quiz Q1 before completing the web search, and 75.92% addressed the quiz Q2 after the web search. The average word counts analysis corresponding to text, videos, overlapping text or video, and comprehensive resources indicates that the proposed model can also apply for a continuous multi sessions online search learning environment. The experimental analysis indicates that better measures are obtained for the proposed recommender using sensors and ML compared with other methods in terms of recall, ranking score, and precision. The proposed model achieves a precision of 27% when the recommendation size becomes 100. The root mean square error (RMSE) lies between 8% and 16% when the number of learners < 500, and the maximum value of RMSE is 21% when the number of learners reaches 1500. The proposed recommendation model achieves better results than the state-of-the-art methods. © 2023 by the authors. Licensee MDPI, Basel, Switzerland.",TestAnalysis
"Background Appropriate medication use is essential in ensuring optimal pharmacotherapeutic outcomes. It is mistakenly assumed that adults can swallow solid oral dosage forms (SODFs, e.g.Tablets/ capsules colloquially referred to as 'pills'), without difficulty and that children cannot. KidzMed is a 'pill swallowing' training programme designed to teach effective SODF use in patients of all ages. It may be utilised by healthcare professionals to assist patients taking SODFs. E-learning was essential for training during COVID pandemic to reduce viral transmission. The aim of this study was to explore UK student pharmacists views of e-learning to support swallowing solid oral dosage forms. Methods This study used pre-and post-intervention online surveys on Microsoft Forms to evaluate self-directed eLearning about pill swallowing on MPharm programmes at three UK Universities using a 13-item survey. A combination of five-point Likert Scales and free-Text items were used. The eLearning was available via the virtual learning environment at the University and embedded within existing curriculum. Descriptive statistical analysis was used to explore responses. Results In total, 113 of 340 (33%) students completed the survey. Seventy-eight percent (n = 65) reported the eLearning would enable them to teach adults and children to swallow SODFs successfully. Learners either agreed or strongly agreed that they felt comfortable to teach patients (95%, n = 62/113) and parents or carers (94%, n = 60) to swallow medications having completed the e-learning. Student pharmacists generally found eLearning as an acceptable way to reflect on their own experiences of 'pill' swallowing and how to support patients to swallow SODFs. Conclusion The KidzMed eLearning was well received by student pharmacists. Further work is needed to explore whether skills translates into real life application in the clinical settings.  © 2023 McCloskey et al.",TestAnalysis
"Evidence on the effectiveness of melatonin in breast cancer patients suffering from sleep disturbances is contradictory, and there have been no meta-analyses on its use in humans with breast cancer. This study investigated the melatonin supplementation effectiveness in alleviating sleep disturbances in breast cancer patients. We searched Embase, PubMed, MEDLINE, CINAHL, Cochrane Library, Google Scholar, and Clinical trial.org databases for relevant reports by following PRISMA guidelines and collected clinical experimental studies of melatonin supplementation in breast cancer patients. Breast cancer for the population, melatonin supplementation for intervention, including sleep indicator, cancer treatment-related symptoms for outcomes, and clinical trial for humans were the searched keywords. Among the 1917 identified records, duplicates and irrelevant articles were excluded. Among the 48 full-text articles assessed, 10 studies met the criteria for inclusion in a systematic review, and five studies had sleep-related indicators and were included in the meta-analysis after quality assessment. The estimated average effect size (Hedges’ g) was −0.79 (p < 0.001) in a random-effects model, thus indicating that melatonin supplementation had a moderate effect in ameliorating sleep quality in breast cancer patients. Pooled data from studies on melatonin supplementation indicate that melatonin administration may alleviate sleep problems related to treatments in breast cancer patients. © 2023 by the authors.",TestAnalysis
"Volume 199, no. 17, e00359-17, 2017, https://doi.org/10.1128/JB.00359-17. Genomic analysis of the DTTHA0328 deletion strain developed in this study revealed that this strain is a derivative of Thermus thermophilus HB27 and not HB8. However, the amino acid sequence of the product of TTHA0328 in the HB8 strain is a perfect match with the homologue of the HB27 strain (locus tag: TTC1655), and all other genes involved in the NAD1 salvage pathway were also conserved between the two strains. In addition, gene organization and the sequence around the nicotinamidase (NAMase) are similar between the two strains and thus the knockout mutant for TTC1655 was successfully constructed using the primers that were designed based on the HB8 genome sequence. Therefore, the results and conclusions presented in the original paper, including sequence alignment (Fig. 2) and recombinant protein characteristics (Fig. 3), are valid if the strain and gene names are replaced throughout the text and Fig. 2 and 3 as shown in the table in this correction (Table Presented). Copyright © 2023 American Society for Microbiology. All Rights Reserved.",TestAnalysis
"Featured Application: Text Mining, Apriori Algorithm, Association Rules, Rule-based Machine Learning Method, Web Graph Analysis, Content Analysis, Qualitative Projective Technique, Textual Complaints. By looking at complaints made by guests of different star-rated hotels, this study attempts to detect associations between complaint attributions and specific consequences. A multifaceted approach is applied. First, a content analysis is conducted to transform textual complaints into categorically structured data. Furthermore, a web graph analysis and rule-based machine learning method are applied to discover potential relationships among complaint antecedents and consequences. These are validated using a qualitative projective technique. Using an Apriori rule-based machine learning algorithm, optimal priority rules for this study were determined for the respective complaining attributions for both the antecedents and consequences. Based on attribution theory, we found that Customer Service, Room Space, and Miscellaneous Issues received more attention from guests staying at higher star-rated hotels. Conversely, cleanliness was a consideration more prevalent amongst guests staying at lower star-rated hotels. Qualitative research was conducted to corroborate the findings. Other machine learning techniques (i.e., Decision Tree) build rules based on only a single conclusion, while association rules attempt to determine many rules, each of which may lead to a different conclusion. The main contributions of this study lie in the fact that this is one of the first attempts to detect correlations within the online complaining behaviors of guests of different star-rated hotels by utilizing rule-based machine learning. © 2023 by the authors.",TestAnalysis
"Background and Aims: The success of every new technology depends on numerous factors, including specialists' knowledge and perceptions of the concept, acquired attitude skills, and work environments. This systematic review aimed to examine medical students' knowledge, attitudes, and perceptions of telemedicine. Methods: Studies were obtained from the PubMed, Embase, Scopus, and Web of Science databases on June 9, 2022. We followed the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. Cross-sectional studies that examined medical students' knowledge, attitude, and perceptions of telemedicine approaches were considered inclusion criteria. Titles and abstracts were independently screened based on eligibility criteria. Articles that did not meet the inclusion criteria were excluded from this review. After that, the complete texts were retrieved and screened by two separate researchers based on the eligibility criteria. Disputes were resolved by discussion. The same checklist was used for data extraction. To assess the quality of the studies entering this study, the Joanna Briggs Institute Critical Appraisal Checklist for analytical cross-sectional studies was used. Results: In total, 10 eligible articles were found through this review. The sample size of the studies ranged from 60 to 3312 participants, or 6172 participants on the whole. The medical students' attitudes toward telemedicine were evaluated in eight included studies. Many of these studies (seven cases) reported positive and promising perspectives on telemedicine. However, in one study, participants revealed moderate attitudes toward online health information and online health experience sharing (p < 0.05). Students' knowledge of the telemedicine approach was evaluated in eight included studies. Many of these studies (five cases) reported that students possessed an extensively poor knowledge of telemedicine's uses. In three other studies, two reported moderate and one disclosed desirable levels of students' knowledge. All the included studies attributed medical students' poor knowledge to the lack of, and thus failure of, educational courses in this field. Conclusion: The evidence obtained from this review reveals that medical students possess positive and promising attitudes toward telemedicine technology for education, treatment, and care. However, their knowledge levels were extremely insufficient, and many had not passed any educational courses in this respect. Such results can foreground the health and education policymakers' obligations for planning, training, and empowering digital health and telemedicine literacy among medical students as the primary players in social health. © 2023 The Authors. Health Science Reports published by Wiley Periodicals LLC.",TestAnalysis
"The implementation of digitalization has gradually become an important strategy for many enterprises to improve sustainability. The text mining and principal component analysis methods were used to measure enterprise digitalization and the level of enterprise resilience from 2011 to 2019, respectively. This study then explored the impact of digitalization on enterprise resilience. This research comes to three conclusions. (1) Digitalization can improve enterprise resilience significantly, but beyond the threshold, it inhibits enterprise resilience. In other words, there is an inverted U-shaped relationship between digitalization and enterprise resilience, and the steepness of this inverted U-shape shows a marginal increasing trend. (2) Notably, Resource allocation efficiency and information accessibility play a mediating effect in the impact of digitization on enterprise resilience. Further analysis found that the improvement of enterprise resilience is not only conducive to the growth of total factor productivity but also conducive to the high-quality development of the manufacturing industry. (3) The influence of digitization on enterprise resilience in areas with a high level of marketization, labor-and technology-intensive industries, and eastern and coastal areas is more obvious. The impact of digitization on the sustainable development of small and medium-sized enterprises, and private and foreign-funded enterprises is more significant. Finally, corresponding policy suggestions are proposed. © 2023",TestAnalysis
"Background The international collaboration study PRICOV-19 -Primary Health Care in times of COVID-19 aims to assess the impact of the COVID-19 pandemic on the organisation of primary health care. The German part focuses on the subjective perceptions of general practitioners on primary health care and the impact of political measures during the second wave of the COVID-19 pandemic. Within this survey, the “open text field” of the questionnaire was utilised remarkably frequently and extensively by the respondents. It became clear that the content that was named needed to be analysed in an exploratory manner. Accordingly, this paper addresses the following question: What preoccupies general practitioners in Germany during COVID-19 that we have not yet asked them enough? Methods The data collection took place throughout Germany from 01.02.2021 to 28.02.2021with a quantitative online questionnaire consisting of 53 items arranged across six topics as well as an “open text field” for further comments. The questionnaire's open text field was analysed following the premises of the qualitative content analysis. Results The topics discussed by the respondents were: insufficient support from health policies, not being prioritised and involved in the vaccination strategy, feeling insufficient prepared, that infrastructural changes and financial concerns threatened the practice, and perceiving the own role as important, as well as that health policies affected the wellbeing of the respondents. One of the main points was the way general practitioners were not sufficiently acknowledged for their contribution to ensuring high-quality care during the pandemic. Discussion German general practitioners perceived their work and role as highly relevant during the COVID-19 pandemic. In controversy with their perception, they described political conditions in which they were the ones who contributed significantly to the fight against the pandemic but were not given enough recognition. Copyright: © 2023 Stark et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Background: Healthcare providers (HCPs) may be at elevated risk for moral injury due to increased exposure to potentially morally injurious events (PMIEs) throughout the COVID-19 pandemic. Identifying PMIEs experienced during the COVID-19 pandemic is a critical first step for understanding moral injury in HCPs. Accordingly, the purpose of the present study was to gain a deeper understanding of the work-related PMIEs experienced by HCPs in Canada during the pandemic. Methods: Canadian HCPs completed an online survey between February and December 2021 about mental health and functioning, including demographics and the Moral Injury Outcome Scale (MIOS). We conducted a qualitative thematic analysis of PMIEs described extemporaneously by HCPs in the open-text field of the MIOS. Results: One-hundred and twenty-four (N = 124) HCPs were included in analysis. Eight PMIE-related themes were identified, comprising patients dying alone; provision of futile care; professional opinion being ignored; witnessing patient harm; bullying, violence and divided opinions; resources and personal protective equipment; increased workload and decreased staffing; and conflicting values. Conclusions: Understanding broad categories of PMIES experienced by Canadian HCPs during the COVID-19 pandemic provides an opportunity to enhance cultural competency surrounding their experiences which will aid the development of targeted prevention and intervention approaches. © 2023 by the authors.",TestAnalysis
"Objective: Evaluation of the success and/or survival rates of resin-bonded fixed partial dentures (RBFPDs) reported in the scientific literature with a minimum average observation time of five years. Materials and Methods: Search conducted in Pubmed, Web of Science, and Cochrane databases in free-text format and MESH terms, until May 2021. The random-effects model was used for the estimated survival rate, percentage per year of estimated failure, and existing complications for the meta-analysis. Study heterogeneity was assessed by the inconsistency test (I2) and study quality by the Downs and Black scale. Results: Eleven articles were included, with 687 participants and 783 RBFPDs, with a mean observation time of 8.2 years, with success rates mentioned in three articles and survival rates reported in nine articles. A total of 142 failures were reported for 783 prostheses, the most frequent being debonding. The estimated failure rate was between 0.53% and 5.10% per year. The studies were of sufficient quality. In the meta-analysis, the survival rates showed a significant result (p < 0.001), with moderate heterogeneity (I2 = 58.76%). Conclusions: Within the limitations of this research, mainly related to the heterogeneity of the studies and their quality, it seems possible to conclude that RBFPDs are a viable clinical option for the rehabilitation of patients with single edentulous spaces, mainly when using a single retainer and a zirconia-ceramic prosthesis. © 2023 by the authors.",TestAnalysis
"In the energy sector, since the adoption of remote device management for massive advanced metering infrastructure (AMI) devices and Internet of Things (IoT) technology using a representational state transfer (RESTful) architecture, a blurred boundary has been developed between traditional AMI and IoT. With respect to smart meters, the standard-based smart metering protocol, called the device language message specification (DLMS) protocol, still has a predominant role in the AMI industry. Thus, we aim to propose a novel data interworking model in this article that embraces the DLMS protocol in AMI using the most promising IoT protocol, the so-called lightweight machine-to-machine (LwM2M) protocol. We provide a 1:1 conversion model using the correlation of the two protocols with an analysis of the object modeling and resource management methods of both the LwM2M and DLMS protocols. The proposed model utilizes a complete RESTful architecture, which is the most beneficial in the LwM2M protocol. It improves the average packet transmission efficiency and packet delay on the plaintext and encrypted text (session establishment and authenticated encryption) by 52.9%p and 9.9%p, respectively, and by 11.86 ms for both cases, compared to the encapsulation method of the LwM2M protocol, KEPCO’s current approach. This work provides the key idea to unify the protocol for the remote metering and device management of field devices into the LwM2M protocol, and it is expected that this work will improve the efficiency in the operation and management of KEPCO’s AMI system. © 2023 by the authors.",TestAnalysis
"The impact of a chief executive officer s (CEO s) functional experience on firm performance has gained the attention of many scholars. However, the measurement of functional experience is rarely disclosed in the public database. Few studies have been conducted on the comprehensive functional experience of CEOs. This paper used the upper echelons theory and obtained deep-level curricula vitae (CVs) data through the named entity recognition technique. First, we mined 15 consecutive years of CEOs CVs from 2006 to 2020 from Chinese listed companies. Second, we extracted information throughout their careers and automatically classified their functional hierarchy. Finally, we constructed breadth (functional breadth: functional experience richness) and depth (functional depth: Average tenure and the hierarchy of function) for empirical analysis. We found that a CEO s breadth is significantly negatively related to firm performance, and the quadratic term is significantly positive. A CEO s depth is significantly positively related to firm performance, and the quadratic term is significantly negative. The research results indicate a u-shaped relationship between a CEO s breadth and firm performance and an inverted u-shaped relationship between their depth and firm performance. The study s findings extend the literature on factors influencing firm performance and CEOs functional experience. The study expands from the horizontal macro to the vertical micro level, providing new evidence to support the recruitment and selection of high-level corporate talent. © 2023 Public Library of Science. All rights reserved.",TestAnalysis
"It is critical to safeguard confidential data, especially secret and private messages. This study introduces a novel data cryptography approach. The new approach will be capable of encrypting and decrypting any communication size. The suggested approach will use a sophisticated private key with a convoluted structure. The private key will have 5 components with a double data type to prevent guessing or hacking. The confidential data will produce two secret keys, the first of which will be taken from the image key. These keys will be vulnerable to slight changes in private key information. To maximize the approach's efficiency, the suggested method will deal with lengthy messages by splitting them into chunks. On the other hand, the chaotic logistic map model will be used to create the second key. The suggested technique will be implemented, and several sorts of analysis (sensitivity, quality, security, and speed analysis) will be undertaken to demonstrate the benefits of the proposed method. The quality metrics MSE, PSNR, and CC will be com-puted to validate the suggested method's quality. To illustrate the efficiency of the proposed tech-nique, encryption and decryption times will be measured, and cryptography throughputs will be determined. Various PKs will be tried throughout the decryption process to demonstrate how sen-sitive the produced outputs are to changes in the private key. The suggested approach will be tested, and the results will be compared to the results of existing methods to demonstrate the improvement offered by the proposed method. © 2023 by the authors; licensee Growing Science, Canada.",TestAnalysis
"Introduction: As the significance of social workers (SW) in improving healthcare delivery in the emergency department (ED) continues to expand, emergency physicians will increasingly be expected to effectively partner with SWs in both academic and community settings. In this scoping review we sought to provide evidence-based recommendations for effective emergency clinician educational interventions on how to incorporate SWs in the ED to address health-related social needs while also identifying directions for future research. Methods: We conducted a systematic literature review of publications in PubMed, CINAHL, Cochrane Database of Systematic Reviews, Cochrane Central Register of Controlled Trials, and APA PsycINFO. A search strategy was designed in accordance with Peer Review of Electronic Search Strategies (PRESS) guidelines. Using the scoping review framework by Arksey and O’Malley, we applied consensus-based inclusion and exclusion criteria to guide study selection. A Preferred Reporting Items for Systemic Reviews and Meta-Analyses (PRISMA) flow chart delineating the selection process was generated using Covidence. Results: Our search strategy identified nine qualifying articles for further analysis out of an initial sample of 2,119 articles. Of the nine articles that underwent full text review, 89% (8/9) evaluated a short educational didactic with or without a hands-on component to reinforce learning. Barriers to successful implementation of curricula discussed in all articles included time constraints, lack of buy-in from clinical faculty, lack of knowledge of appropriate referral sources once a problem is identified, and perceived distraction of the training from more standard clinical topics. Facilitators of curricula implementation and training success included the presence of a pre-existing and structured weekly conference schedule, ability to complete the training in a relatively short time frame or during intern orientation, presence of simulation resources, and residents’ overall perceived interest in the topics. Conclusion: Ultimately, we found that interdisciplinary learning with SWs is generally well received by participants, and we offer various suggestions on incorporation into student and resident education. Moving forward, we recommend that a standardized curriculum of working with SWs be developed using didactic sessions, simulation, and/or direct observation with feedback. © 2023 Rehman et al.",TestAnalysis
"Introduction: In people living with human immunodeficiency virus (PLHIV), traditional cardiovascular risk factors, exposure to HIV per se and antiretroviral therapy (ART) are assumed to contribute to cardiometabolic diseases. Nevertheless, controversy exists on the relationship of HIV and ART with diabetes. To clarify the relationship between HIV and type 2 diabetes, this review determined, in PLHIV in Africa, diabetes and prediabetes prevalence, and the extent to which their relationship was modified by socio-demographic characteristics, body mass index (BMI), diagnostic definitions used for diabetes and prediabetes, and HIV-related characteristics, including CD4 count, and use and duration of ART. Methods: For this systematic review and meta-analysis (PROSPERO registration CRD42021231547), a comprehensive search of major databases (PubMed-MEDLINE, Scopus, Web of Science, Google Scholar and WHO Global Health Library) was conducted. Original research articles published between 2000 and 2021 in English and French were included, irrespective of study design, data collection techniques and diagnostic definitions used. Observational studies comprising at least 30 PLHIV and reporting on diabetes and/or prediabetes prevalence in Africa were included. Study-specific estimates were pooled using random effects models to generate the overall prevalence for each diagnostic definition. Data analyses used R statistical software and “meta” package. Results: Of the 2614 records initially screened, 366 full-text articles were assessed for eligibility and 61 were selected. In the systematic review, all studies were cross-sectional by design and clinic-based, except for five population-based studies. Across studies included in the meta-analysis, the proportion of men was 16–84%. Mean/median age was 30–62 years. Among 86,412 and 7976 participants, diabetes and prediabetes prevalence rates were 5.1% (95% CI: 4.3–5.9) and 15.1% (9.7–21.5). Self-reported diabetes (3.5%) was lower than when combined with biochemical assessments (6.2%; 7.2%). Discussion: While not statistically significant, diabetes and prediabetes were higher with greater BMI, in older participants, urban residents and more recent publications. Diabetes and prediabetes were not significantly different by HIV-related factors, including CD4 count and ART. Conclusions: Although HIV-related factors did not modify prevalence, the diabetes burden in African PLHIV was considerable with suboptimal detection, and likely influenced by traditional risk factors. Furthermore, high prediabetes prevalence foreshadows substantial increases in future diabetes in African PLHIV. © 2023 The Authors. Journal of the International AIDS Society published by John Wiley & Sons Ltd on behalf of the International AIDS Society.",TestAnalysis
"Background: Frequent use of antibiotics in patients with COVID-19 threatens to exacerbate antimicrobial resistance. We aimed to establish the prevalence and predictors of bacterial infections and antimicrobial resistance in patients with COVID-19. Methods: We did a systematic review and meta-analysis of studies of bacterial co-infections (identified within ≤48 h of presentation) and secondary infections (>48 h after presentation) in outpatients or hospitalised patients with COVID-19. We searched the WHO COVID-19 Research Database to identify cohort studies, case series, case-control trials, and randomised controlled trials with populations of at least 50 patients published in any language between Jan 1, 2019, and Dec 1, 2021. Reviews, editorials, letters, pre-prints, and conference proceedings were excluded, as were studies in which bacterial infection was not microbiologically confirmed (or confirmed via nasopharyngeal swab only). We screened titles and abstracts of papers identified by our search, and then assessed the full text of potentially relevant articles. We reported the pooled prevalence of bacterial infections and antimicrobial resistance by doing a random-effects meta-analysis and meta-regression. Our primary outcomes were the prevalence of bacterial co-infection and secondary infection, and the prevalence of antibiotic-resistant pathogens among patients with laboratory-confirmed COVID-19 and bacterial infections. The study protocol was registered with PROSPERO (CRD42021297344). Findings: We included 148 studies of 362 976 patients, which were done between December, 2019, and May, 2021. The prevalence of bacterial co-infection was 5·3% (95% CI 3·8–7·4), whereas the prevalence of secondary bacterial infection was 18·4% (14·0–23·7). 42 (28%) studies included comprehensive data for the prevalence of antimicrobial resistance among bacterial infections. Among people with bacterial infections, the proportion of infections that were resistant to antimicrobials was 60·8% (95% CI 38·6–79·3), and the proportion of isolates that were resistant was 37·5% (26·9–49·5). Heterogeneity in the reported prevalence of antimicrobial resistance in organisms was substantial (I2=95%). Interpretation: Although infrequently assessed, antimicrobial resistance is highly prevalent in patients with COVID-19 and bacterial infections. Future research and surveillance assessing the effect of COVID-19 on antimicrobial resistance at the patient and population level are urgently needed. Funding: WHO. © 2023 Published by Elsevier Ltd. This is an Open Access article under the CC BY 4.0 license",TestAnalysis
"The paper investigates the multiple representation approach as used in elementary school science learning. A systematic literature review (SLR) method and preferred reporting items for systematic review and meta-analysis (PRISMA) protocol were employed in this research. This included systematic review stages, eligibility and exclusion criteria, review process procedures, and data abstraction and analysis assisted by Publish or Perish 7, VOSviewer, and NVivo 12 Plus applications. The search for publications on Scopus through the Publish or Perish 7 application yielded 605 publications, and for the ERIC database, there were 2018 publications, making 2623 publications. The publications were then filtered according to compatible themes and 50 were selected to be used as material for the SLR. The 50 publications were analyzed according to the assigned topics through the NVivo 12 Plus application, and the results are described in this paper. According to literature, multiple representations is a learning approach that involves using more than one or two representations. This is done by utilizing text, video, tables, audio, animation, diagrams, analogies, cartoons, movements, formulas, and graphs to reflect, interpret, and solve scientific problems in elementary science learning. The multiple representation approach is implemented through task assignment, visualization technology; representation of images, symbols, tables, pictures, and graphs; scientific investigations; engineering design; technological skills; applications; recordings; and written symbols. The impact that the multiple representation approach has in elementary science learning is an increase in reasoning skills, critical thinking skills, communication skills, solving of science problems, concern for nature conservation, and social and visual intelligence. This paper contributes to research examining multiple representations in elementary school science learning. © Authors.",TestAnalysis
"Background and Aims: This systematic review examined healthcare students' attitudes, knowledge, and skill in Artificial Intelligence (AI). Methods: On August 3, 2022, studies were retrieved from the PubMed, Embase, Scopus, and Web of Science databases. Preferred Reporting Items for Systematic Reviews and Meta-Analyses recommendations were followed. We included cross-sectional studies that examined healthcare students' knowledge, attitudes, skills, and perceptions of AI in this review. Using the eligibility requirements as a guide, titles and abstracts were screened. Complete texts were then retrieved and independently reviewed per the eligibility requirements. To collect data, a standardized form was used. Results: Of the 38 included studies, 29 (76%) of healthcare students had a positive and promising attitude towards AI in the clinical profession and its use in he future; however, in nine of the studies (24%), students considered AI a threat to healthcare fields and had a negative attitude towards it. Furthermore, 26 studies evaluated the knowledge of healthcare students about AI. Among these, 18 studies evaluated the level of student knowledge as low (50%). On the other hand, in six of the studies, students' high knowledge of AI was reported, and two of the studies reported average student general knowledge (almost 50%). Of the six studies, four (67%) of the students had very low skills, so they stated that they had never worked with AI. Conclusion: Evidence from this review shows that healthcare students had a positive and promising attitude towards AI in medicine; however, most students had low knowledge and limited skills in working with AI. Face-to-face instruction, training manuals, and detailed instructions are therefore crucial for implementing and comprehending how AI technology works and raising students' knowledge of the advantages of AI. © 2023 The Authors. Health Science Reports published by Wiley Periodicals LLC.",TestAnalysis
"Words are fundamental linguistic units that connect thoughts and things through meaning. However, words do not appear independently in a text sequence. The existence of syntactic rules induces correlations among neighboring words. Using an ordinal pattern approach, we present an analysis of lexical statistical connections for 11 major languages. We find that the diverse manners that languages utilize to express word relations give rise to unique pattern structural distributions. Furthermore, fluctuations of these pattern distributions for a given language can allow us to determine both the historical period when the text was written and its author. Taken together, our results emphasize the relevance of ordinal time series analysis in linguistic typology, historical linguistics, and stylometry.  © 2023 Author(s).",TestAnalysis
"Cypriot Arabic (CyAr) is a severely endangered Semitic variety spoken by Cypriot Maronites. It belongs to the group of “peripheral varieties” of Arabic that were separated from the core Arabic-speaking area and came into contact with non-Semitic languages. Although there has been a renewed interest since the turn of the century for the study of CyAr, some aspects of its structure are still not well known. In this paper, we present and analyze a number of developments in CyAr induced by contact with Cypriot Greek. Our methodology for investigating such phenomena makes a novel contribution to the description of this underrepresented variety, as it was based not only on existing linguistic descriptions and text corpora in the literature, but mainly on a vast corpus of naturalistic oral speech data from the Archive of Oral Tradition of CyAr. Our analysis revealed the complexity of investigated contact phenomena and the differing degrees of integration of borrowings into the lexico-grammatical system of CyAr. © 2022 by the authors.",TestAnalysis
"Current research on knowledge graph construction is focused chiefly on general-purpose fields, whereas constructing knowledge graphs in vertically segmented professional fields faces numerous difficulties. To solve the problems of complex relation types of domain entities, the lack of a large amount of annotated corpus, and the difficulty of extraction, this study proposed a method for constructing domain-annotated datasets based on publicly available texts on the web, which integrates remote supervision and semi-supervision. For the relational triad extraction of a given core entity (an entity lexicon defined semi-automatically by experts), an inflated gate attention network structure for increasing the perceptual field of the model is proposed. In addition, a relational extraction model, Ro-DGANet, was designed based on this structure, incorporating the idea of a probability graph. The Ro-DGANet model was experimentally evaluated on the publicly available Chinese datasets LIC2019 and CHIP2020 and compared with the mainstream relation extraction models, achieving the best results with F1 values of 82.99% and 66.39%, respectively. Finally, the Ro-DGANet model was applied to the relation extraction task of equipment components in industrial scenarios and to the relation extraction task of core knowledge points of programming languages. The analysis results show that the proposed method is applicable to open relation extraction among core entities in different domains with reliable performance and portability. © 2023 by the authors.",TestAnalysis
"Introduction: Complex Regional Pain Syndrome (CRPS) is most common in the upper limb and associated with high disability. The purpose of this review was to critically appraise and synthesise literature exploring non-pharmacological treatment for upper limb CRPS, to guide upper-limb-specific management. Methods: Using an integrative review methodology, 13 databases were searched to identify all published studies on non-pharmacological management of upper limb CRPS. The Crowe Critical Appraisal Tool was used to provide quality ratings for included studies, and analysis employed a qualitative descriptive approach. Results: From 236 abstracts reviewed, 113 full texts were read, and 38 articles selected for data extraction. Designs included single case (n = 14), randomised controlled trial (n = 8), prospective cohort (n = 8), case series (n = 4), retrospective (n = 3), and mixed methods (n = 1). Interventions were categorised as sensory retraining (n = 13), kinesiotherapy (n = 7), manual therapies (n = 7), physical modalities (n = 6), and interdisciplinary treatment programmes (n = 5). All studies measured pain intensity, and most (n = 24) measured physical parameters such as strength, movement, or perceptual abilities. Few measured patient-rated function (n = 13) or psychological factors (n = 4). Quality ratings ranged from 30% to 93%, with a median of 60%. Conclusion: Methodological quality of non-pharmacological treatment approaches for upper limb CRPS is overall poor. Movement, desensitisation, and graded functional activity remain the mainstays of intervention. However, despite the impact of CRPS on wellbeing and function, psychological factors and functional outcomes are infrequently addressed. Further robust research is required to determine which aspects of treatment have the greatest influence on which symptoms, and when and how these should be introduced and progressed. © The Author(s) 2023.",TestAnalysis
"This study aims to provide research results through empirical analysis on how customers’ reactions on social media affect the present and future value of a company. This research selected Korean KOSPI-listed companies that actually own and operate YouTube channels, and collected data through text mining the comments on YouTube videos with high views. In addition, the TF-IDF value was calculated, keywords were extracted, and keywords were classified into three groups through topic modeling. The characteristics of the three groups could be transformed into a “current-oriented topic” as advertising promotion content focused on fun or interest; a “future-oriented topic” as critical content pointing out problems, and a “neutral topic” as content of a neutral attitude toward companies. This study uses a regression analysis model to perform an empirical analysis by setting a company’s YouTube-related variable as an independent variable and setting a company’s current value and future value-related variable as a dependent variable. The results of this research are as follows. First, this paper found that companies that directly operate and manage YouTube accounts currently have lower corporate value than those that do not. Second, this study also found that companies which directly operate and manage YouTube accounts have higher future corporate value than those that do not. Third, the results showed that if a customer simply mentions interesting content or advertising/promotion-related content through corporate YouTube comments, the current corporate value may be improved in the short term, but in the long term, it has a negative effect on future corporate value. Fourth, the results of this research also presented that if a customer criticizes a company or points out a company’s problems through YouTube comments, the current corporate value decreases due to damage to the company’s image, but it was found that the future corporate value increases. Fifth, this paper found that neutral content, not just for fun and interest, nor for constructive criticism or dissatisfaction with the company, was not related to the company’s current and future corporate value. The contributions and expected effects of this paper are as follows. First of all, this paper provides useful information through research results which shows that companies are more advantageous in improving future corporate value from a long-term perspective by strategically operating social media directly. In addition, the research results of this study objectively demonstrated through YouTube channels that it is more helpful for companies in the long run to respond well to customer complaints and negative opinions, and to implement policies that continuously manage customer opinions. Finally, the research method used in this paper, that is, the research methodology that conducted empirical analysis through quantification of unstructured tax data, is expected to provide guidelines for many scholars to expand the scope of data available for empirical research in the future. © 2023 by the authors.",TestAnalysis
"Background Decision impact studies have become increasingly prevalent in cancer prognostic research in recent years. These studies aim to evaluate the impact of a genomic test on decision-making and appear to be a new form of evidence of clinical utility. The objectives of this review were to identify and characterize decision impact studies in genomic medicine in cancer care and categorize the types of clinical utility outcomes reported. Methods We conducted a search of four databases, Medline, Embase, Scopus and Web of Science, from inception to June 2022. Empirical studies that reported a “decision impact” assessment of a genomic assay on treatment decisions or recommendations for cancer patients were included. We followed scoping review methodology and adapted the Fryback and Thornbury Model to collect and analyze data on clinical utility. The database searches identified 1803 unique articles for title/abstract screening; 269 articles moved to full-text review. Results 87 studies met inclusion criteria. All studies were published in the last 12 years with the majority for breast cancer (72%); followed by other cancers (28%) (lung, prostate, colon). Studies reported on the impact of 19 different proprietary (18) and generic (1) assays. Across all four levels of clinical utility, outcomes were reported for 22 discrete measures, including the impact on provider/team decision-making (100%), provider confidence (31%); change in treatment received (46%); patient psychological impacts (17%); and costing or savings impacts (21%). Based on the data synthesis, we created a comprehensive table of outcomes reported for clinical utility. Conclusions This scoping review is a first step in understanding the evolution and uses of decision impact studies and their influence on the integration of emerging genomic technologies in cancer care. The results imply that DIS are positioned to provide evidence of clinical utility and impact clinical practice and reimbursement decision-making in cancer care. Systematic review registration: Open Science Framework osf.io/hm3jr. Copyright: © 2023 Parker et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Background: Pulmonary artery pressure (PAP) monitoring reduces heart failure (HF) hospitalizations (HFHs) and improves quality of life in New York Heart Association (NYHA) class III HF. We evaluated the impact of PAP monitoring on outcomes and health spending in a Canadian ambulatory HF cohort. Methods: Twenty NYHA III HF patients underwent wireless PAP implantation at Foothills Medical Centre, Calgary, Alberta. Baseline, and 3-, 6-, 9-, and 12-month assessments of laboratory parameters, hemodynamics, 6-minute walk text and Kansas City Cardiomyopathy Questionnaire scores were collected. Healthcare costs 1 year pre- and post-implantation were collected from administrative databases. Results: Mean age was 70.6 years; 45% were female. Results were as follows: an 88% reduction in emergency room visits (P = 0.0009); an 87% reduction in HFHs (P < 0.0003); a 29% reduction in heart function clinic visits (P = 0.033), and a 178% increase in nurse calls (P < 0.0002). Questionnaire and 6-minute walk test scores at baseline vs last follow-up were 45.4 vs 48.4 (P = 0.48) and 364.4 vs 402.8 m (P = 0.58), respectively. Mean PAP at baseline vs follow-up was 31.5 vs 24.8 mm Hg (P = 0.005). NYHA class improved by at least one class in 85% of patients. Mean measurable HF-related spending preimplantation was CAD$29,814 per patient per year and postimplantation was CAD$25,642 per patient per year (including device cost). Conclusions: PAP monitoring demonstrated reductions in HFHs, and emergency room and heart function clinic visits, with improvements in NYHA class. Although further economic evaluation is needed, these results support the use of PAP monitoring as an effective and cost-neutral tool in HF management in appropriately selected patients in a publicly funded healthcare system. © 2022 The Authors",TestAnalysis
"Background: ""Spin"" refers to a manipulation of language that implies benefit for an intervention when none may exist. Randomized controlled trials (RCTs) in other fields have been demonstrated to employ spin, which can mislead clinicians to use ineffective or unsafe interventions. This study's objective was to determine the strategies, severity, and extent of spin in plastic surgery RCTs with nonsignificant primary outcomes. Methods: A literature search of the top 15 plastic surgery journals using MEDLINE was performed (2000 through 2020). Parallel 1:1 RCTs with a clearly identified primary outcome showing statistically nonsignificant results (P > 0.05) were included. Screening, data extraction, and spin analysis were performed by two independent reviewers. The spin analysis was then independently assessed in duplicate by two plastic surgery residents with graduate-level training in clinical epidemiology. Results: From 3497 studies identified, 92 RCTs were included in this study. Spin strategies were identified in 78 RCTs (85%), including 64 abstracts (70%) and 77 main texts (84%). Severity of spin was rated moderate or high in 43 abstract conclusions (47%) and 42 main text conclusions (46%). The most identified spin strategy in the abstract was claiming equivalence for statistically nonsignificant results (26%); in the main text, focusing on another objective (24%). Conclusions: This study suggests that 85% of statistically nonsignificant RCTs in plastic surgery employ spin. Readers of plastic surgery research should be aware of strategies, whether intentional or unintentional, used to manipulate language in reports of statistically nonsignificant RCTs when applying research findings to clinical practice. © 2023 Lippincott Williams and Wilkins. All rights reserved.",TestAnalysis
"The most prominent tasks in emotion analysis are to assign emotions to texts and to understand how emotions manifest in language. An important observation for natural language processing is that emotions can be communicated implicitly by referring to events alone, appealing to an empathetic, intersubjective understanding of events, even without explicitly mentioning an emotion name. In psychology, the class of emotion theories known as appraisal theories aims at explaining the link between events and emotions. Appraisals can be formalized as variables that measure a cognitive evaluation by people living through an event that they consider relevant. They include the assessment if an event is novel, if the person considers themselves to be responsible, if it is in line with their own goals, and so forth. Such appraisals explain which emotions are developed based on an event, for example, that a novel situation can induce surprise or one with uncertain consequences could evoke fear. We analyze the suitability of appraisal theories for emotion analysis in text with the goal of understanding if appraisal concepts can reliably be reconstructed by annotators, if they can be predicted by text classifiers, and if appraisal concepts help to identify emotion categories. To achieve that, we compile a corpus by asking people to textually describe events that triggered particular emotions and to disclose their appraisals. Then, we ask readers to reconstruct emotions and appraisals from the text. This set-up allows us to measure if emotions and appraisals can be recovered purely from text and provides a human baseline to judge a model’s performance measures. Our comparison of text classification methods to human annotators shows that both can reliably detect emotions and appraisals with similar performance. Therefore, appraisals constitute an alternative computational emotion analysis paradigm and further improve the categorization of emotions in text with joint models. © 2022 Association for Computational Linguistics.",TestAnalysis
"This paper designed a voice interactive robot system that can conveniently execute assigned service tasks in real-life scenarios. It is equipped without a microphone where users can control the robot with spoken commands; the voice commands are then recognized by a well-trained deep neural network model of automatic speech recognition (ASR), which enables the robot to execute and complete the command based on the navigation of a real-time simultaneous localization and mapping (SLAM) algorithm. The voice interaction recognition model is divided into two parts: (1) speaker separation and (2) ASR. The speaker separation is applied by a deep-learning system consisting of eight convolution layers, one LSTM layer, and two fully connected (FC) layers to separate the speaker’s voice. This model recognizes the speaker’s voice as a referrer that separates and holds the required voiceprint and removes noises from other people’s voiceprints. Its automatic speech recognition uses the novel sandwich-type conformer model with a stack of three layers, and combines convolution and self-attention to capture short-term and long-term interactions. Specifically, it contains a multi-head self-attention module to directly convert the voice data into text for command realization. The RGB-D vision-based camera uses a real-time appearance-based mapping algorithm to create the environment map and replace the localization with a visional odometer to allow the robot to navigate itself. Finally, the proposed ASR model was tested to check if the desired results will be obtained. Performance analysis was applied to determine the robot’s environment isolation and voice recognition abilities. The results showed that the practical robot system successfully completed the interactive service tasks in a real environment. This experiment demonstrates the outstanding performance with other ASR methods and voice control mobile robot systems. It also verified that the designed voice interaction recognition system enables the mobile robot to execute tasks in real-time, showing that it is a convenient way to complete the assigned service applications. © 2023 by the authors.",TestAnalysis
"In the business world, large companies that can achieve continuity in innovation gain a significant competitive advantage. The sensitivity of these companies to follow and monitor news sources in e-commerce, social media, and forums provides important information to businesses in the decision-making process. With the large amount of data shared in these resources, sentiment analysis can be made from people's comments about services and products, users' emotions can be extracted and important feedback can be obtained. All of this is of course possible with accurate sentiment analysis. In this study, new data sets were created for Turkish, English, and Arabic, and for the first time, comparative sentiment analysis was performed from texts in three different languages. In addition, a very comprehensive study was presented to the researchers by comparing the performances of both the pre-trained language models for Turkish, Arabic, and English, as well as the deep learning and machine learning models. Our paper will guide researchers working on sentiment analysis about which methods will be more successful in texts written in different languages, which contain different types and spelling mistakes, which factors will affect the success, and how much these factors will affect the performance. © 2023 The Author(s)",TestAnalysis
"Artificial Neural Networks (ANNs) are machine learning algorithms inspired by the structure and function of the human brain. Their popularity has increased in recent years due to their ability to learn and improve through experience, making them suitable for a wide range of applications. ANNs are often used as part of deep learning, which enables them to learn, transfer knowledge, make predictions, and take action. This paper aims to provide a comprehensive understanding of ANNs and explore potential directions for future research. To achieve this, the paper analyzes 10,661 articles and 35,973 keywords from various journals using a text-mining approach. The results of the analysis show that there is a high level of interest in topics related to machine learning, deep learning, and ANNs and that research in this field is increasingly focusing on areas such as optimization techniques, feature extraction and selection, and clustering. The study presented in this paper is motivated by the need for a framework to guide the continued study and development of ANNs. By providing insights into the current state of research on ANNs, this paper aims to promote a deeper understanding of ANNs and to facilitate the development of new techniques and applications for ANNs in the future. © 2023 by the authors.",TestAnalysis
"Background: The lack of clinical guidelines for the treatment of primary psychodermatologic disorders (PPDs) hinders the delivery of optimal care to patients. The review aimed to identify, appraise, and summarize the currently available evidence about the safety and effectiveness of pharmacological management of PPDs through randomized controlled trials (RCTs). Methods: The Preferred Reporting Items for Systematic Review and Meta-Analyses (PRIMSA) statement and the Global Evidence Mapping Initiative guidance were followed. Medline, Embase, PsycInfo, Cochrane and Scopus were searched, and two reviewers independently completed article review, data extraction, and quality assessment. Results: Among 2618 unique studies, full texts of 83 were reviewed and 21 RCTs were included. Five PDDs were identified: trichotillomania (n = 12), pathologic skin picking (n = 5), nail biting (n = 2), delusional parasitosis (n = 1), and dermatitis from compulsive hand washing (n = 1). Seven different classes of medications were investigated: SSRIs (i.e., fluoxetine, sertraline, and citalopram), tricyclic antidepressants (i.e., clomipramine and desipramine), antipsychotics (i.e., olanzapine and pimozide), anticonvulsant (i.e., lamotrigine), N-acetylcysteine, inositol, and milk thistle. RCT-derived evidence supports the use of antidepressants in trichotillomania (sertraline and clomipramine), pathologic skin picking (fluoxetine), pathologic nail biting and dermatitis from compulsive hand washing (clomipramine or desipramine); antipsychotics in trichotillomania (olanzapine) and delusional parasitosis (pimozide); N-acetyl cysteine in trichotillomania and skin picking. Conclusion: Few pharmacotherapies for primary psychodermatologic disorders are assessed through controlled trials in the literature. This review serves as a roadmap for researchers and clinicians to reach informed decisions with current evidence, and to build on it to establish guidelines in the future. © The Author(s) 2023.",TestAnalysis
"Mutational signature analysis promises to reveal the processes that shape cancer genomes for applications in diagnosis and therapy. However, most current methods are geared toward rich mutation data that has been extracted from whole-genome or whole-exome sequencing. Methods that process sparse mutation data typically found in practice are only in the earliest stages of development. In particular, we previously developed the Mix model that clusters samples to handle data sparsity. However, the Mix model had two hyper-parameters, including the number of signatures and the number of clusters, that were very costly to learn. Therefore, we devised a new method that was several orders-of-magnitude more efficient for handling sparse data, was based on mutation co-occurrences, and imitated word co-occurrence analyses of Twitter texts. We showed that the model produced significantly improved hyper-parameter estimates that led to higher likelihoods of discovering overlooked data and had better correspondence with known signatures. © 2023 by the authors.",TestAnalysis
"Background and Objectives: The digital world offers opportunities for sex and love and also reflects societal stereotypes regarding sex and love among older adults. The aim of the current review is to look at the ways older adults use digital media for sex and love and also at digital media's representations of older adults. Research Design and Methods: We searched for studies published in English that used qualitative and/or quantitative methods, with findings based on empirical data from individuals 55 years of age or older. The following data sets were searched: PubMed, Web of Science, PsycINFO, Cochrane Database of Systematic Reviews, and CINAHL. Bibliographies of all relevant studies were searched. Titles and abstracts were reviewed, and selected articles were extracted independently by 2 reviewers. Results: A total of 1,819 records were retrieved. After removing duplicates, 1,488 records remained. Of these, 70 records remained for full-text screening, and a final count of 15 records was included for synthesis. Discussion and Implications: The present review highlights major research gaps in the field. Although studies have indeed focused on the online dating scene among this cohort, they have ignored older adults' sexuality in favor of other aspects (e.g., love and companionship). Representations of this cohort in terms of love and sex are also lacking, and diversity is hardly addressed. Additional research is needed to examine how older adults use digital media for reasons related to love and sex, and how the media mirrors societal stereotypes regarding sex and love among older adults.  © 2022 The Author(s). Published by Oxford University Press on behalf of The Gerontological Society of America. All rights reserved.",TestAnalysis
"Reading-into-writing tasks are frequently used as an assessment tool in the higher education context. Due to the nature of the task, students strategically process the source texts to successfully select the relevant information and integrate it into their writing. This study addresses the questions of a) how students strategically process the source text in reading-into-writing tasks and b) if there are differences between summary and argumentative tasks with different topics (natural and social sciences) regarding students' strategic processing of the source text. For this purpose, four types of reading-into-writing tasks were developed and completed by 14 students from German universities. While completing the tasks, each participant was asked to verbalize their thoughts (think-aloud), and their screen was video recorded. The audio-visual data were transcribed and analysed using a deductive approach. Our results support previous research about discourse synthesis and metacognitive strategies in reading-into-writing tasks and indicate some differences between the types of tasks and topics in the employment of particular strategies. Moreover, our analyses show that higher-level and lower-level reading processes play a role in the source text strategic processing depending on the reader's goals. This study gives further insights into the reading-into-writing construct, considering task type and topic effects. © 2023 Elsevier Ltd",TestAnalysis
"Individuals with comorbidities (i.e., Diabetes Mellitus, hypertension, heart diseases) are more likely to develop a more severe form of coronavirus disease 2019 (COVID-19), thus, they should take necessary precautions to avoid infection with severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2) and its emerging variants and subvariants by getting COVID-19 vaccination and booster doses. In this regard, we used text analytics techniques, specifically Natural Language Processing (NLP), to understand the perception of Twitter users having comorbidities (diabetes, hypertension, and heart diseases) towards the COVID-19 vaccine booster doses. Understanding and identifying Twitter users' perceptions and perspectives will help the members of medical fraternities, governments, and policymakers to frame and implement a suitable public health policy for promoting the uptake of booster shots by such vulnerable people. A total of 176,540 tweets were identified through the scrapping process to understand the perception of individuals with the mentioned comorbidities regarding the COVID-19 booster dose. From sentiment analysis, it was revealed that 57.6% out of 176,540 tweets expressed negative sentiments about the COVID-19 vaccine booster doses. The reasons for negative expressions have been found using the topic modeling approach (i.e., risk factors, fear of myocardial fibrosis, stroke, or death, and using vaccines as bio-weapons). Of note, enhancing the COVID-19 vaccination drive by administering its booster doses to more and more people is of paramount importance for rendering higher protective immunity under the current threats of recently emerging newer Omicron subvariants which are presently causing a rise in cases in a few countries, such as China and others, and might lead to a feasible new wave of the pandemic with the surge in cases at the global level.  © The Author(s) 2023.",TestAnalysis
"Academic Medical Centres (AMCs) are important organisations for shaping healthcare. The purpose of this scoping review is to understand the scope and type of evidence related to the organisation of European AMCs. We selected the study population intending to obtain a demographic cross-section of European countries: Czech Republic, Germany, Latvia, the Netherlands, Poland, Spain, Sweden and the UK. We focused our search strategy on the relationship between medical schools and AMCs, the organisation of governing bodies, and legal ownership. We searched the bibliographic databases of PubMed and Web of Science (most recent search date 17-06-2022). To enrich the search result, we used Google search engines to conduct targeted searches for relevant websites. Our search strategy yielded 4,672 records for consideration. After screening and reviewing full-text papers, 108 sources were included. Our scoping review provided insight into the scope and type of evidence related to the organisation of European AMCs. Limited literature is available on the organisation of these AMCs. Information from national-level websites complemented the literature and provided a more complete picture of the organisation of European AMCs. We found some meta-level similarities regarding the relationship between universities and AMCs, the role of the dean and the public ownership of the medical school and the AMC. In addition, we found several reasons why a particular organisational and ownership structure was chosen. There is no uniform model for AMC organisations (apart from some meta-level similarities). Based on this study, we cannot explain the diversity in these models. Therefore, further research is needed to explain these variations. For example, by generating a set of hypotheses through in-depth case studies that also focus on the context of AMCs. These hypotheses can then be tested in a larger number of countries. © 2023 Cardinaal et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Purpose. To revise the current literature on FIL SSF (Carlevale) intraocular lens, previously known as Carlevale lens, and to compare their outcomes with those from other secondary IOL implants. Methods. We performed a peer review of the literature regarding FIL SSF IOLs until April 2021 and analyzed the results only of articles with a minimum of 25 cases and a follow-up of at least 6 months. The searches yielded 36 citations, 11 of which were abstracts of meeting presentations that were not included in the analysis because of their limited data. The authors reviewed 25 abstracts and selected six articles of possible clinical relevance to review in full text. Of these, four were considered to be sufficiently clinically relevant. Particularly, we extrapolated data regarding the pre- and postoperative best corrected visual acuities (BCVA) and the complications related to the procedure. The complication rates were then compared with those from a recently published Ophthalmic Technology Assessment by the American Academy of Ophthalmology (AAO) on secondary IOL implants. Results. Four studies with a total of 333 cases were included for results analysis. The BCVA improved in all cases after surgery, as expected. Cystoid macular edema (CME) and increased intraocular pressure were the most common complications, with an incidence of up to 7.4% and 16.5%, respectively. Other IOL types from the AAO report included anterior chamber IOLs, iris fixation IOLs, sutured iris fixation IOLs, sutured scleral fixation IOLs, and sutureless scleral fixation IOLs. There was no statistically significant difference in the rates of postoperative CME (p = 0.20), and vitreous hemorrhage (p = 0.89) between other secondary implants and the FIL SSF IOL, whereas the rate of retinal detachment was significantly less with FIL SSF IOLs (p = 0.04). Conclusion. The results of our study suggest the implantation of FIL SSF IOLs is an effective and safe surgical strategy in cases where there is a lack of capsular support. In fact, their outcomes seem to be comparable to those obtained with the other available secondary IOL implants. According to published literature, the FIL SSF (Carlevale) IOL provides favorable functional results with a low rate of postoperative complications. © 2023 by the authors.",TestAnalysis
"When compared with traditional local shops where the customer has a personalised service, in large retail departments, the client has to make his purchase decisions independently, mostly supported by the information available in the package. Additionally, people are becoming more aware of the importance of the food ingredients and demanding about the type of products they buy and the information provided in the package, despite it often being hard to interpret. Big shops such as supermarkets have also introduced important challenges for the retailer due to the large number of different products in the store, heterogeneous affluence and the daily needs of item repositioning. In this scenario, the automatic detection and recognition of products on the shelves or off the shelves has gained increased interest as the application of these technologies may improve the shopping experience through self-assisted shopping apps and autonomous shopping, or even benefit stock management with real-time inventory, automatic shelf monitoring and product tracking. These solutions can also have an important impact on customers with visual impairments. Despite recent developments in computer vision, automatic grocery product recognition is still very challenging, with most works focusing on the detection or recognition of a small number of products, often under controlled conditions. This paper discusses the challenges related to this problem and presents a review of proposed methods for retail product label processing, with a special focus on assisted analysis for customer support, including for the visually impaired. Moreover, it details the public datasets used in this topic and identifies their limitations, and discusses future research directions of related fields. © 2023 by the authors.",TestAnalysis
"Featured Application: Our work aims to provide a media analytics framework for the Greek language that utilizes subjectivity similarities among the related classification tasks, with potential for application to other low-resource languages. Media analysis (MA) is an evolving area of research in the field of text mining and an important research area for intelligent media analytics. The fundamental purpose of MA is to obtain valuable insights that help to improve many different areas of business, and ultimately customer experience, through the computational treatment of opinions, sentiments, and subjectivity on mostly highly subjective text types. These texts can come from social media, the internet, and news articles with clearly defined and unique targets. Additionally, MA-related fields include emotion, irony, and hate speech detection, which are usually tackled independently from one another without leveraging the contextual similarity between them, mainly attributed to the lack of annotated datasets. In this paper, we present a unified framework to the complete intelligent media analysis, where we propose a shared parameter layer architecture with a joint learning approach that takes advantage of each separate task for the classification of sentiments, emotions, irony, and hate speech in texts. The proposed approach was evaluated on Greek expert-annotated texts from social media posts, news articles, and internet articles such as blog posts and opinion pieces. The results show that this joint classification approach improves the classification effectiveness of each task in terms of the micro-averaged F1-score. © 2023 by the authors.",TestAnalysis
"Using advanced algorithms to conduct a thematic analysis reduces the time taken and increases the efficiency of the analysis. Long short-term memory (LSTM) is effective in the field of text classification and natural language processing (NLP). In this study, we adopt LSTM for text classification in order to perform a thematic analysis using concordance lines that are taken from a corpora of news articles. However, the statistical and quantitative analyses of corpus linguistics are not enough to fully identify the semantic shift of terms and concepts. Therefore, we suggest that a corpus should be classified from a linguistic theoretical perspective, as this would help to determine the level of the linguistic patterns that should be applied in the experiment of the classification process. We suggest investigating the concordance lines of the articles rather than only the relationship between collocates, as this has been a limitation for many studies. The findings of this research work highlight the effectiveness of the proposed methodology for the thematic analysis of media coverage, reaching 84% accuracy. This method provides a deeper thematic analysis than only applying the classification process through the collocational analysis. © 2023 by the authors.",TestAnalysis
"Biomedical image analysis algorithm validation depends on high-quality annotation of reference datasets, for which labelling instructions are key. Despite their importance, their optimization remains largely unexplored. Here we present a systematic study of labelling instructions and their impact on annotation quality in the field. Through comprehensive examination of professional practice and international competitions registered at the Medical Image Computing and Computer Assisted Intervention Society, the largest international society in the biomedical imaging field, we uncovered a discrepancy between annotators’ needs for labelling instructions and their current quality and availability. On the basis of an analysis of 14,040 images annotated by 156 annotators from four professional annotation companies and 708 Amazon Mechanical Turk crowdworkers using instructions with different information density levels, we further found that including exemplary images substantially boosts annotation performance compared with text-only descriptions, while solely extending text descriptions does not. Finally, professional annotators constantly outperform Amazon Mechanical Turk crowdworkers. Our study raises awareness for the need of quality standards in biomedical image analysis labelling instructions. © 2023, The Author(s).",TestAnalysis
"China’s outbreak related to cold-chain aquatic product quality and safety in 2020 caused public panic and further led to a crisis in China’s aquatic industry. This paper uses topic clustering and emotion analysis methods to text-mine the comments of netizens on Sina Weibo to study the main features of the public’s views on the administration’s crisis management measures and to provide experience for future imported food safety management. The findings show that for the imported food safety incident and the risk of virus infection, the public response had four types of characteristics: a higher proportion of negative emotion; a wider range of information demand; attention paid to the whole imported food industry chain; and a differentiated attitude towards control policies. Based on the online public response, countermeasures to further improve the management ability of imported food safety crises are proposed as follows: the government should pay active attention to the development trend of online public opinion; work more on exploring the content of public concern and emotion; strengthen the risk assessment of imported food and establish the classification and management measures of imported food safety events; construct the imported food safety traceability system; build a special recall mechanism for imported food safety; and improve the cooperation between government and media, enhancing the public’s trust in policies. © 2023 by the authors.",TestAnalysis
"Objective: In the past, studies on antimicrobial resistance were carried out on pathogens in the clinical areas. However, since then, this phenomenon has become a general case both in the environment and in the food sector. This systematic review aimed to review the various scientific publications on the resistance of bacteria to antibiotics in foods in West Africa. Methods: An extensive literature search was carried out through an electronic database including PubMed, Google Scholar, Research Gate, and African Journals Online (AJOL). Articles published from fifteen countries of the Economic Community of West African States (ECOWAS) between 2010 and 2020 on antibiotic resistance of foodborne pathogens were included in the study. The titles and abstracts of the retrieved articles and then the full texts of the selected articles were reviewed. Results: Out of the 565 articles found in our initial research, 149 publications (26.55%) were considered suitable for inclusion in this review. Globally, 2018, 2019, and 2020 had more included papers (n = 21 to 25) than the other years. Of the 149 publications analyzed, four types of food commodities were identified as products of high consumption based on the number of publications in the field such as poultry (39/149), read‐to‐eat food (22/149), meat, and animal products (20/149). Most studies have shown that E. coli has the highest prevalence followed by Salmonella and Staphylococcus. Only 33 (22.14%) of the 149 publications were based on further molecular characterization of the isolates. Publications analyzed showed that the most prevalent detected genes were tet(A), tet(B), tet(C), tet(K) blaTEM, catA1, catA2, cmlA, blaCTXM and qnrA, qnrB, qnrS, parC, and qepA4. Conclusion: From these results, antibiotic use in the food areas must be strongly regulated, especially in developing countries, particularly in Africa. This highlights the need to implement suitable and appropriate control strategies to reduce complications and prevent the dissemination of resistant bacteria isolates in foods. One health antimicrobial resistance surveillance system in the region must be a great concern. © 2023 The Author(s).",TestAnalysis
"Type 1 Diabetes (T1D) is a condition requiring 24-hour management. The way in which an individual combines their 24-hour movement behaviours (24-h MBs), which is comprised of physical activity (PA), sedentary behaviour (SB), and sleep, throughout the day can have a significant impact on physical and mental health. This mixed methods systematic review aimed to investigate 24-h MBs’ relationship with glycaemic control and psychosocial outcomes in adolescents (11–18 years) with T1D. Ten databases were searched for quantitative and qualitative English language articles reporting at least one of the behaviours and their relationship with outcomes. There were no restrictions on article publication dates or study design. Articles were subjected to title and abstract screening, full text screening, data extraction and quality assessment. Data were summarised narratively, and a meta-analysis was conducted where possible. From 9922 studies, 84 were included for data extraction (quantitative (n = 76), qualitative (n = 8)). Meta-analyses revealed a significant favourable association between PA and HbA1c (−0.22 [95% CI: −0.35, −0.08; I2 = 92.7%; p = 0.001). SB had an insignificant unfavourable association with HbA1c (0.12 [95% CI: −0.06, 0.28; I2 = 86.1%; p = 0.07]) and sleep had an insignificant favourable association (−0.03 [95% CI: −0.21, 0.15; I2 = 65.9%; p = 0.34]). Importantly, no study investigated how combinations of behaviours collectively interacted and impacted on outcomes. © 2023 by the authors.",TestAnalysis
"BACKGROUND: Evidence of effective early childhood obesity prevention is scarce and mainly derived from face-to-face interventions. However, the COVID-19 pandemic drastically reduced face-to-face health programmes globally. This study assessed effectiveness of a telephone-based intervention in reducing obesity risk of young children. METHODS: We adapted a study protocol (developed before the pandemic) and conducted a pragmatic randomised controlled trial of 662 women with children aged 2 years (mean age 24·06 months [SD 0·69]) during March, 2019, and October, 2021, extending the original planned intervention of 12 months to 24 months. The adapted intervention comprised five telephone-based support sessions plus text messages over a 24-month period (at child ages 24-26 months, 28-30 months, 32-34 months, 36-38 months, and 42-44 months). The intervention group (n=331) received staged telephone plus SMS support regarding healthy eating, physical activity, and information about COVID-19. The control group (n=331) received four staged mail-outs on information not related to the obesity prevention intervention, such as toilet training, language development, and sibling relationships, as a retention strategy. The intervention effects on BMI (primary outcome) and eating habits (secondary outcome), and perceived co-benefits, were evaluated using surveys and qualitative telephone interviews at 12 months and 24 months after baseline (age 2 years). The trial is registered with the Australian Clinical Trial Registry, ACTRN12618001571268. FINDINGS: Of 662 mothers, 537 (81%) completed the follow-up assessments at 3 years, and 491 (74%) completed the follow-up assessment at 4 years. Multiple imputation analysis showed no significant difference in mean BMI between the groups. Among low-income families (ie, annual household income <AU$80 000) at age 3 years, the intervention was significantly associated with a lower mean BMI (16·26 kg/m2 [SD 2·22]) in the intervention group than in the control group (16·84 kg/m2 [2·37]; p=0·040), a difference of -0·59 (95% CI -1·15 to -0·03; p=0·040). Children in the intervention group were more likely not to eat in front of the television than the control group, with an adjusted odds ratio (aOR) of 2·00 (95% CI 1·33 to 2·99) at 3 years and an aOR of 2·50 (1·63 to 3·83) at 4 years. Qualitative interviews with 28 mothers revealed that the intervention increased their awareness, confidence, and motivation to implement healthy feeding practices, particularly for families from culturally diverse backgrounds (ie, speaking a language other than English at home). INTERPRETATION: A telephone-based intervention was well received by the mothers who participated in the study. The intervention could reduce children's BMI from low-income families. Telephone-based support targeted at low-income families and families from culturally diverse backgrounds could reduce current inequalities in childhood obesity. FUNDING: The trial was funded under the NSW Health Translational Research Grant Scheme 2016 (number TRGS 200) and also by a National Health and Medical Research Council Partnership grant (number 1169823). Copyright © 2023 The Author(s). Published by Elsevier Ltd. This is an Open Access article under the CC BY 4.0 license. Published by Elsevier Ltd.. All rights reserved.",TestAnalysis
"At present, websites, such as Amazon and Yelp, permit consumers to submit reviews for different businesses, services, and products. In recent times, the customer’s shopping decision is highly influenced by the online reviews posted by the customers using star ratings, as well as, texts. Generally, customers believe that ratings are consistent with the reviews provided, but it may not be in the case of intermediate ratings. Conversely, the reviews posted by the customers will be in an unstructured format, which makes it highly complicated in understanding and analysis of the review, thereby requiring efficient approaches to estimate ratings considering the sentiment of the customer. In this paper, a novel sentiment rating prediction approach is devised by utilizing a deep learning network with hybrid optimization. Here, Random Multimodel Deep Learning (RMDL) network is used to estimate the sentiment rating, where the RMDL is trained using the devised Honey-based Exponential Poor Rich Optimization (HEPRO) algorithm. Moreover, the presented HEPRO-RMDL is examined for its effectiveness based on various metrics, like True Positive Rate (TPR), True Negative Rate (TNR), and accuracy is observed to have achieved high values of accuracy, TNR, and TPR at 0.935, 0.925, and 0.956, respectively. © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",TestAnalysis
"Food insecurity is prevalent, affecting 1·2 billion people globally in 2021. However, the effects of food insecurity are unequally distributed across populations and climate-related shocks threaten to exacerbate food insecurity and associated health consequences. The mechanisms underlying this exacerbation at the household level are largely unknown. We aimed to synthesise the available evidence on the mechanisms connecting extreme climate events to household-level food insecurity and highlight the research gaps that must be addressed to inform better food security and health policy. For this systematic review, a comprehensive literature search was done by a medical librarian in February, 2021 for articles about food security and climate-related shocks. Relevant publications were identified by searching the following databases with a combination of standardised index terms and keywords: MEDLINE, Embase, CINAHL, GreenFILE, Environment Complete, Web of Science Core Collection, and Global Health. Searches were limited to human studies published in English. Included studies measured food security outcomes using indicators developed by the UN Food and Agricultural Organization (ie, consumption patterns, livelihood change, malnutrition, and mortality) and explained the mechanism behind the household-level or population-level food insecurity. Purely theoretical, modelling, and review studies were excluded. Quality assessment was conducted using the appropriate Joanna Briggs Institute Critical Appraisal Tool. Data were analysed using thematic analysis of the categories of mechanism (interpreted using internationally accepted frameworks), risk and resilience factors, and author policy recommendations. We found a paucity of data with only 18 studies meeting criteria for inclusion out of 337 studies identified for full-text review. All the studies that were included in our analysis showed worse food security outcomes after climate-related shocks. Food availability was the most common mechanism cited (17 studies), although most studies addressed at least one additional mechanism (15 studies). Studies were of mixed methodologies with nuanced discussions of risk and resilience factors, and of policy recommendations. This systematic review shows that there is an incomplete assessment of food security at the household and community level after climate-related shocks in the literature and finds that food availability is the primary mechanism studied. The low number of studies on this topic limits subgroup analysis and generalisability; however, the good quality of the studies allows for important policy recommendations around improving resilience to climate shocks and suggestions for future research including the need for a more granular understanding of mechanisms and feasible adaptation solutions. © 2023 The Author(s). Published by Elsevier Ltd. This is an Open Access article under the CC BY-NC-ND 4.0 license",TestAnalysis
"Introduction The aim of this review was to evaluate the impact of preoperative myosteatosis on long-term outcomes following surgery for gastrointestinal malignancy. Methods We conducted a systematic search of the electronic information sources, including PubMed MEDLINE, Embase, Cochrane Central Register of Controlled Trials (CENTRAL), CINAHL and AMED. Studies were included if they reported the impact of preoperatively defined myosteatosis, or a similar term, on long-term survival outcomes following surgery for gastrointestinal malignancy. A subgroup analysis was performed for those studies reporting outcomes for colorectal cancer patients only. Findings Thirty-nine full-text articles were reviewed for inclusion, with 19 being retained after the inclusion criteria were applied. The total number of included patients across all studies was 14,481. Patients with myosteatosis had significantly poorer overall survival, according to univariate (hazard ratio (HR) 1.82, 95% confidence interval (CI) 1.67–1.99) and multivariable (HR 1.66, 95% CI 1.49–1.86) analysis. This was also demonstrated for cancer-specific survival (univariate HR 1.62, 95% CI 1.18–2.22; multivariable HR 1.73, 95% CI 1.48–2.03) and recurrence-free survival (univariate HR 1.28, 95% CI 1.10–1.48; multivariable HR 1.38, 95% CI 1.07–1.77). Conclusions This meta-analysis demonstrates that patients with preoperative myosteatosis have poorer long-term survival outcomes following surgery for gastrointestinal malignancy. Therefore, myosteatosis should be used for preoperative optimisation and as a prognostic tool before surgery. More standardised definitions of myosteatosis and further cohort studies of patients with non-colorectal malignancies are required. © 2023 Royal College of Surgeons of England. All rights reserved.",TestAnalysis
"Data sources: The authors searched Medline via Pubmed, EMBASE, Cochrane Database of Systematic Reviews and Scielo. Additionally, grey literature was also searched with no restrictions regarding date of publication and journal up to March 2022. The search was conducted by two pre-calibrated independent reviewers using AMSTAR 2 and PRISMA checklists. Both MeSH terms, relevant free text and their combinations were utilised to conduct the search. Study selection: The authors screened the articles on the basis of their titles and abstracts. Duplicates were removed. Full-text publications were evaluated. Any disagreement was resolved by discussion amongst themselves or with a third reviewer. Only the systematic reviews that included RCTs and CCTs were included involving the articles comparing nonsurgical periodontal treatment alone vs no treatment or nonsurgical periodontal treatment with adjunctive therapeutic modality (antibiotics, laser) vs no treatment or nonsurgical periodontal therapy alone. PICO method was used to define the inclusion criteria and changes in glycated haemoglobin post-intervention 3 months was taken as primary outcome. All the articles with the use of adjunctive therapy other than antibiotics (local or systemic) or laser were excluded. The selection was restricted to English only. Data extraction and synthesis: Data extraction was performed by two reviewers. For each systematic review and each study, mean and standard deviation of glycated hemoglobin level at each follow-up, number of patients both in intervention and control group, type of diabetes, design of study, follow-up period, number of comparisons in meta-analysis, quality assessment of systematic review was assessed by 16 items AMSTAR 2 (Assessment of Multiple Systematic Reviews) and 27 itemed PRISMA (Preferred Reporting Items for Systematic Review and Meta-Analysis) checklist. JADAD scale was used to assess the risk of bias for included RCTs. Q test was used to calculate statistical heterogeneity and percentage of variation by I2 Index. Both Fixed (Mantel-Haenszel [Peto] test) and random (Dersimonian-Laird test) models were used to estimate individual study. Funnel plot and Egger’s linear regression methods were used to evaluate publication bias. Results: Following initial electronic and hand search, 1062 articles were screened for title and abstract and 112 articles were considered for full text eligibility. Finally, 16 systematic reviews were considered for qualitative synthesis of results. 16 systematic reviews described 30 unique meta-analyses. Publication bias was assessed in nine out of 16 systematic reviews. Compared to control or non-treatment group, nonsurgical periodontal therapy resulted in statistically significant mean difference of −0.49% HBA1c reduction at 3 months (p = 0.0041), −0.38% (p = 0.0851). The effect of periodontal therapy with antibiotics compared to NSPT alone was not statistically significant (CI −0.32–0.06, 3 months; CI −0.31–0.53, 6 month). The effect of NSPT and laser vs NSPT for HbA1c was not statistically significant (CI −0.73–0.17, 3–4 month). Conclusions: Based on included systematic reviews and limitations within the study, nonsurgical periodontal therapy is an effective treatment modality in glycaemic control in diabetic patients in terms of HbA1c reduction both at 3 months and 6 months follow-up. The adjunctive therapies like antibiotic administration whether local or systemic and use of lasers with NSPT does not show statistically significant differences as compared to NSPT alone. However, these findings are based on analysis of available literature based on systematic reviews on this subject. © 2023, The Author(s), under exclusive licence to British Dental Association.",TestAnalysis
"Background: Digital health interventions have shown promising results for the management of type 2 diabetes, but a comparison of the effectiveness and implementation of the different modes is not currently available. Therefore, this study aimed to compare the effectiveness of SMS, smartphone application, and website-based interventions on improving glycaemia in adults with type 2 diabetes and report on their reach, uptake, and feasibility. Methods: In this systematic review and meta-analysis, we searched CINAHL, Cochrane Central, Embase, MEDLINE, and PsycInfo on May 25, 2022, for randomised controlled trials (RCTs) that examined the effectiveness of digital health interventions in reducing glycated haemoglobin A1c (HbA1c) in adults with type 2 diabetes, published in English from Jan 1, 2009. Screening was carried out using Covidence, and data were extracted following Cochrane's guidelines. The primary endpoint assessed was the change in the mean (and 95% CI) plasma concentration of HbA1c at 3 months or more. Cochrane risk of bias 2 was used to assess risk of bias. Data on reach, uptake, and feasibility were summarised narratively and data on HbA1c reduction were synthesised in a meta-analysis. Grading of Recommendations, Assessment, Development, and Evaluation criteria was used to evaluate the level of evidence. The study was registered with PROSPERO, CRD42021247845. Findings: Of the 3236 records identified, 56 RCTs from 24 regions (n=11 486 participants), were included in the narrative synthesis, and 26 studies (n=4546 participants) in the meta-analysis. 20 studies used SMS as the primary mode of delivery of the digital health intervention, 25 used smartphone applications, and 11 implemented interventions via websites. Smartphone application interventions reported higher reach compared with SMS and website-based interventions, but website-based interventions reported higher uptake compared with SMS and smartphone application interventions. Effective interventions, in general, included people with greater severity of their condition at baseline (ie, higher HbA1c) and administration of a higher dose intensity of the intervention, such as more frequent use of smartphone applications. Overall, digital health intervention group participants had a –0·30 (95% CI –0·42 to –0·19) percentage point greater reduction in HbA1c, compared with control group participants. The difference in HbA1c reduction between groups was statistically significant when interventions were delivered through smartphone applications (–0·42% [–0·63 to –0·20]) and via SMS (–0·37% [–0·57 to –0·17]), but not when delivered via websites (–0·09% [–0·64 to 0·46]). Due to the considerable heterogeneity between included studies, the level of evidence was moderate overall. Interpretation: Smartphone application and SMS interventions, but not website-based interventions, were associated with better glycaemic control. However, the studies' heterogeneity should be recognised. Considering that both smartphone application and SMS interventions are effective for diabetes management, clinicians should consider factors such as reach, uptake, patient preference, and context of the intervention when deciding on the mode of delivery of the intervention. Nine in ten people worldwide own a feature phone and can receive SMS and four in five people have access to a smartphone, with numerous smartphone applications being available for diabetes management. Clinicians should familiarise themselves with this modality of programme delivery and encourage people with type 2 diabetes to use evidence-based applications for improving their self-management of diabetes. Future research needs to describe in detail the mediators and moderators of the effectiveness and implementation of SMS and smartphone application interventions, such as the optimal dose, frequency, timing, user interface, and communication mode to both further improve their effectiveness and to increase their reach, uptake, and feasibility. Funding: EU's Horizon 2020 Research and Innovation Programme. © 2023 The Author(s). Published by Elsevier Ltd. This is an Open Access article under the CC BY 4.0 license",TestAnalysis
"This multiliteracies-framed study is an analysis of how English Language Arts students designed digital portfolios across three digital media platforms: Weebly (a website building platform), blogs, and Instagram (a photo and video sharing app). Analysis centers around an examination of students’ writing (defined broadly), student surveys, focal student interviews, and a reflective interview with the teacher to understand the research question: How did students use each of the platforms and what did this afford that may not have otherwise been possible in this typically formal and text-based class? Findings indicate that the students designed complex, reflective, multimodal compositions that would have otherwise not been possible with the typically formal, prescribed forms of writing typical to this classroom. Implications for this study include embracing alternative communication styles in classrooms beyond traditional forms of text-based writing to allow for students’ out-of-school and in-school literacy practices to be bridged. © 2023 Elsevier Inc.",TestAnalysis
"Information Security Awareness (ISA) is a significant concept that got considerable attention recently and can assist in minimizing the risks associated with information security breaches. Several measurement scales have been developed in this regard, as measuring users’ ISA is paramount. Although ISA specific scales are very important, yet what methodological rigor they use in terms of initial conceptualization of ISA, data collection and analysis during the development, and scale validation of such scales are some unknown aspects. Therefore, we provide a comprehensive review of the existing ISA specific scales to address all the above concerns. A popular method, PRISMA, is utilized, and a total of 24 articles that match with criteria of this research are included for the final in-depth analysis. Also, a holistic evaluation framework is developed containing three phases and 19 criteria. Findings revealed that most studies treat ISA as a multi-dimensional construct, and ISA researchers rarely conduct both pilot testing and pre-text evaluation while validating and refining the initial scales. Additionally, several articles did not report some of the essential elements used for checking the rigor of factor analysis, and evidence for validities of the identified scales is inadequate. Consequently, existing ISA specific scales must be improved both in terms of the methodological thoroughness of the scale development procedure and their validities. Moreover, not only justifying why the development of a new scale is necessary, but also improving the quality of the existing scales by doing multiple iterations is significant in the future. Likewise, the inclusion of all the dimensions of ISA, while generating the initial items pool is an important aspect to be considered. A thorough discussion, recommendations for future research, conclusions, and study limitations are provided. © 2023 The Authors",TestAnalysis
"Transperineal laser ablation (TPLA) of the prostate is a new minimally invasive treatment option in men with lower urinary tract symptoms (LUTS) due to benign prostatic enlargement (BPE). The aim of this systematic review was to investigate the efficacy and safety of TPLA in the management of BPE. The primary outcomes were the improvement in urodynamic parameters (maximum urinary flow (Qmax) and postvoiding residue (PVR)) and LUTS relief, assessed using the IPSS questionnaire. The secondary outcomes were the preservation of sexual and ejaculatory functions, assessed with the IEEF-5 and MSHQ-EjD questionnaires, respectively, and rates of postoperative complications. We reviewed the literature for prospective or retrospective studies evaluating the use of TPLA in the treatment of BPE. A comprehensive search in PubMed, Scopus, Web of Science, and ClinicalTrials.gov was performed for English language articles published between January 2000 and June 2022. Pooled analysis of the included studies with available follow-up data for the outcomes of interest was additionally performed. After screening 49 records, six full-text manuscripts were identified, including two retrospective and four prospective non-comparative studies. Overall, 297 patients were included. All the studies independently reported a statistically significant improvement, from baseline, in Qmax, PVR, and IPSS score at each timepoint. Three studies additionally demonstrated that TPLA did not affect sexual function, reporting no change in the IEEF-5 score, and a statistically significant improvement in MSHQ-EjD score at each timepoint. Low rates of complications were recorded in all the included studies. Pooled analysis showed a clinically meaningful improvement in both micturition and sexual outcomes mean values at 1, 3, 6, and 12 months of follow-up, compared with baseline. Transperineal laser ablation of the prostate for the treatment of BPE showed interesting results in pilot studies. However, higher level and comparative studies are needed to confirm its efficacy in relieving obstructive symptoms and preserving sexual function. © 2023 by the authors.",TestAnalysis
"Data sources: Electronic databases PubMed, Scopus and Embase were systematically searched and restricted to articles published between February 2009 and 2022. Study selection: Studies were categorized using the modified method by the Swedish Council of Technology Assessment in Health Care. 20 studies were included, one of which was categorized as high quality (Grade A) and 19 of which were of moderate quality (Grade B). Exclusion criteria included articles with insufficient descriptions of reliability and reproducibility testing, review articles and case reports, and studies including traumatised teeth. Data extraction and synthesis: Three independent authors examined titles, abstracts and full texts of relevant articles against the inclusion criteria. Disagreements were resolved by discussion. Retrieved studies were assessed in accordance with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Data extracted included tooth movement performed, the appliance and force used, follow-up of subjects, changes in pulpal blood flow (PBF), tooth sensibility, expression of inflammation-related proteins, along with pulpal histology and morphology changes during tooth movement (intrusion, extrusion and tipping). Overall risk of bias was unclear. Results: A reduction in pulpal blood flow and tooth sensibility due to the application of orthodontic forces was reported by studies included in the review. Increases in the activity of proteins and enzymes related to inflammation of the pulp was reported. Two studies reported histological changes of the pulpal tissues related to orthodontic treatment. Conclusions: Orthodontic forces cause multiple temporary detectable changes in the dental pulp. The authors conclude there are no clear signs of permanent pulpal damage to healthy teeth due to the application of orthodontic forces. © 2023, The Author(s), under exclusive licence to British Dental Association.",TestAnalysis
"Objective: Cervical lymphadenopathy is a frequent finding in children that poses diagnostic challenges. We sought to compare the utility of fine needle aspiration (FNA) with ultrasound (US) for evaluating pediatric cervical lymphadenopathy based on published literature. Study design: In October 2019, we performed a comprehensive electronic search of PubMed, OVID (MEDLINE), EMBASE, and Scopus databases. Two authors independently screened and assessed full-text reports of potentially eligible studies. We compared sensitivity, specificity, positive predictive value estimates, and balanced accuracy for determining the underlying etiology of lymphadenopathy. Results: The initial search returned 7736 possible studies, of which 31 met the criteria for inclusion. A total of 25 studies were included in the final analysis, with a total of 4721 patients, of which 52.8% were male. Of these, 9 (36.0%) examined US, and 16 (64%) examined fine needle aspiration. The pooled balanced accuracy for determining etiology was 87.7% for US and 92.9% for FNA. Reactive lymphadenopathy was identified in 47.9%, 9.2% were malignant, 12.6% were granulomatous, and 6.6% were non-diagnostic. Conclusions: In this systematic review, US was identified as an accurate initial diagnostic imaging modality in children. Fine needle aspiration was found to play a significant role in ruling out malignant lesions and potentially avoiding excisional biopsy. © 2023",TestAnalysis
"The use of Saccharomyces cerevisiae (SC) feed additives to improve animal performance are on the increase; however, the results of the action of SC supplementation on goats performance indices are conflicting. Thus, the thrust of this meta-analysis was to examine the influence of dietary SC intervention on the growth performance, haemato-biochemical indices and ruminal fermentation characteristics of growing goats fed total mixed ration (TMR). The search conducted in Google Scholar, PubMed and Scopus databases using several keywords yielded 500 studies of which 16 full-text articles were utilised for study. Response variables were aggregated via a random-effects model. The results showed that goats fed SC experienced higher average daily gain (ADG) than the controls (as standardized mean difference, SMD = 2.14; 95% confidence interval, CI: 1.40 to 2.89). In converse, dietary SC intervention had a small impact on dry matter intake (DMI) and feed conversion ratio (FCR). Subgroup analysis demonstrated that SC type (active vs inactive) improved FCR and ADG in growing goats. Results suggested that SC preparation increased blood glucose, white blood cell (WBC), ruminal propionate and total volatile fatty acid levels. There is heterogeneity among the articles used in the study, and aspects of studied covariates explained the variation. In conclusion, this study indicated that dietary yeast can positively influence growth performance, haemato-biochemical indices, and rumen fermentation parameters of growing goats. © 2023 The Authors",TestAnalysis
"Gambling disorder is a major public health issue in many countries. It has been defined as a persistent, recurrent pattern of gambling and is associated with substantial distress or impairment, lower quality of life, and living with a plurality of psychiatric problems. Many people suffering from gambling disorder seek help in ways other than formal treatment seeking, including self-management strategies. One example of responsible gambling tools that has gained popularity in recent years is self-exclusion programs. Self-exclusion entails individuals barring themselves from a gambling venue or a virtual platform. The aim of this scoping review is to summarize the literature on this topic and to explore participants’ perceptions and experiences with self-exclusion. An electronic literature search was conducted on 16th May 2022 in the following databases: Academic Search Complete, CINAHL Plus with Full Text, Education Source, ERIC, MEDLINE with Full Text, APA PsycArticles, Psychology and Behavioral Sciences Collection, APA PsychInfo, Social Work Abstracts, and SocINDEX. The search yielded a total of 236 articles, of which 109 remained after duplicates were removed. After full-text reading, six articles were included in this review. The available literature shows that although there are many barriers and limitations to the current self-exclusion programs, self-exclusion is generally viewed as an effective responsible gambling strategy. There is a clear need to improve the current programs by increasing awareness, publicity, availability, staff training, off-site venue exclusion, and technology-assisted monitoring, as well as by adopting more holistic management approaches to gambling disorders in general. © 2023 by the authors.",TestAnalysis
"Background: Growing evidence supports exercise for people with lung cancer. This overview aimed to summarise exercise intervention efficacy and safety across the care continuum. Methods: Eight databases (including Cochrane and Medline) were searched (inception—February 2022) for systematic reviews of RCTs/quasi-RCTs. Eligibility: population—adults with lung cancer; intervention: exercise (e.g., aerobic, resistance) +/− non-exercise (e.g., nutrition); comparator: usual care/non-exercise; primary outcomes: exercise capacity, physical function, health-related quality of life (HRQoL) and post-operative complications. Duplicate, independent title/abstract and full-text screening, data extraction and quality ratings (AMSTAR-2) were completed. Results: Thirty systematic reviews involving between 157 and 2109 participants (n = 6440 total) were included. Most reviews (n = 28) involved surgical participants. Twenty-five reviews performed meta-analyses. The review quality was commonly rated critically low (n = 22) or low (n = 7). Reviews commonly included combinations of aerobic, resistance and/or respiratory exercise interventions. Pre-operative meta-analyses demonstrated that exercise reduces post-operative complications (n = 4/7) and improves exercise capacity (n = 6/6), whilst HRQoL findings were non-significant (n = 3/3). Post-operative meta-analyses reported significant improvements in exercise capacity (n = 2/3) and muscle strength (n = 1/1) and non-significant HRQoL changes (n = 8/10). Interventions delivered to mixed surgical and non-surgical populations improved exercise capacity (n = 3/4), muscle strength (n = 2/2) and HRQoL (n = 3). Meta-analyses of interventions in non-surgical populations demonstrated inconsistent findings. Adverse event rates were low, however, few reviews reported on safety. Conclusions: A large body of evidence supports lung cancer exercise interventions to reduce complications and improve exercise capacity in pre- and post-operative populations. Additional higher-quality research is needed, particularly in the non-surgical population, including subgroup analyses of exercise type and setting. © 2023 by the authors.",TestAnalysis
"Background: Self-measured blood pressure monitoring (SMBP) is essential to effective management of hypertension. This study aims to evaluate effectiveness and implementation of SMBP that leverages: cellular-enabled home BP monitors without a need for Wi-Fi or Bluetooth; simple communication modalities such as text messaging to support patient engagement; and integration into existing team-based workflows in safety-net clinics. Methods: This study will be conducted with patients in San Francisco who are treated within a network of safety-net clinics. English and Spanish-speaking patients with diagnosed hypertension will be eligible for the trial if they have recent BP readings ≥140/90 mmHg and do not have co-morbid conditions that make home BP monitoring more complex to manage. This study will implement a three-arm randomized controlled trial to compare varying levels of implementation support: 1) cellular-enabled BP monitors (with minimal implementation support), 2) cellular-enabled BP monitors with protocol-based implementation support (text reminders for patients; aggregated BP summaries sent to primary care providers), and 3) cellular-enabled BP monitors and pharmacist-led support (pharmacist coaching and independent medication adjustments). Results: For the main analysis, we will use mixed effects linear regression to compare the change in primary outcome of systolic BP. Secondary outcomes include BP control (<140/90 mmHg), medication intensification, patient-reported outcomes, and implementation processes (i.e., engagement with the intervention). Discussion: This study will design and test a digital health intervention for use in marginalized populations treated within safety net settings, evaluating both effectiveness and implementation to advance more equitable health outcomes. © 2023 The Authors",TestAnalysis
"Objectives: Socioeconomic status is well established as a key determinant of inequalities in health outcomes. Existing literature examining the impact of socioeconomic status on outcomes in critical care has produced inconsistent findings. Our objective was to synthesize the available evidence on the association between socioeconomic status and outcomes in critical care. Data Sources: A systematic search of CINAHL, Ovid MEDLINE, and EMBASE was undertaken on September 13, 2022. Study Selection: Observational cohort studies of adults assessing the association between socioeconomic status and critical care outcomes including mortality, length of stay, and functional outcomes were included. Two independent reviewers assessed titles, abstracts, and full texts against eligibility and quality criteria. Data Extraction: Details of study methodology, population, exposure measures, and outcomes were extracted. Data Synthesis: Thirty-eight studies met eligibility criteria for systematic review. Twenty-Three studies reporting mortality to less than or equal to 30 days following critical care admission, and eight reporting length of stay, were included in meta-Analysis. Random-effects pooled analysis showed that lower socioeconomic status was associated with higher mortality at less than or equal to 30 days following critical care admission, with pooled odds ratio of 1.13 (95% CIs, 1.05-1.22). Meta-Analysis of ICU length of stay demonstrated no significant difference between socioeconomic groups. Socioeconomic status may also be associated with functional status and discharge destination following ICU admission. Conclusions: Lower socioeconomic status was associated with higher mortality following admission to critical care. © 2023 Lippincott Williams and Wilkins. All rights reserved.",TestAnalysis
"This study examines the impact of environmental information disclosure quality on firm value for Chinese listed companies in heavily polluting industries from 2010 to 2021. By controlling for the level of leverage, growth, and corporate governance, a fixed effects model is constructed to test this relationship. Furthermore, this study analyzes the moderating effects of annual report text features, such as length, similarity, and readability, on the relationship between environmental information disclosure and firm value and the heterogeneous impact of firm ownership on this relationship. The main findings of this study are as follows: There is a positive correlation between the level of environmental information disclosure and firm value for Chinese listed companies in heavily polluting industries. Annual report text length and readability positively moderate the relationship between environmental information disclosure and firm value. Annual report text similarity negatively moderates the relationship between environmental information disclosure and firm value performance. Compared with state-owned enterprises, the impact of environmental information disclosure quality on the firm value of no-state-owned enterprises is more significant. © 2023 by the authors.",TestAnalysis
"Background: Basal metabolic index (BMI) is a unique anthropometric indicator used to define the relative amount of body fat on an individual’s frame. There are many diseases and conditions associated with obesity and underweight. Recent research trials suggest that there is a significant association between oral health indicators and BMI as both are attributed to common risk factors such as dietary, genetic, socioeconomic, and lifestyle issues. Objectives: The main objective of this review paper is to emphasize the association between BMI and oral health with available literature evidence. Methodology: A literature search was conducted using multiple databases comprising of MEDLINE (via PubMed), EMBASE, and Web of Science. The terms used for the search were “body mass index”, “periodontitis”, “dental caries”, and “tooth loss”. Results: In total, 2839 articles were obtained from the analysis of the databases. Unrelated articles from the available full text of 1135 articles were excluded. The main reasons for excluding the articles were: they were dietary guidelines and policy statements. A total of 66 studies were finally included in the review. Conclusion: The presence of dental caries, periodontitis and tooth loss may be associated with a higher BMI or obesity, whereas, improved oral health might be associated with lower BMI. Promoting general and oral health should be a hand in hand feature, as common risk factors can be embattled. © 2023 by the authors.",TestAnalysis
"Sentiment analysis is one of the most important tasks in natural language processing. The goal of sentiment analysis is to classify the text-based sentiment tendencies by extracting text features. The quality of the classification can be assessed by the accuracy, precision and recall of the classification. So it is very important to design efficient tools or models to carry out the classification process. In this paper, we build a novel model, integrating the dealing method of Bidirectional Encoder Representation from Transformers (BERT), Bidirectional Long Short - Term Memory (Bi-LSTM) and the Multi-Head Attention (MHA), building an MHA based, integrating BERT and Bi-LSTM, Sentiment Analysis Model (MHA-BB-SAM). The model concludes two layers, the embedding layer and the Bi-LSTM layer. In the embedding layer, BERT is used to pre-process the text and train the required word vectors. In the Bi-LSTM layer, Bi-LSTM network is utilized to catch the order information of the context. Multi-Head Attention (MHA) is introduced to enhance the ability to capture the long-distance text features. The novel model is tested on two corpuses, SemEval-2020 corpus and College Learners' Spoken English Corpus (COLSEC). The computing results prove the high performance of the model. The approach presented in this paper can provide a reference for the sentiment analysis work. © 2023,IAENG International Journal of Computer Science. All Rights Reserved.",TestAnalysis
"Introduction: This is an original research, the authors having not found in the specialized literature this kind of approach. The authors raise several questions related to the writings, testimonies, and autofictions published by the victims of attacks: Why tell yourself? What are the motivations that push a writer, an essayist, an anonymous person to tell the story of his life or a segment of his life? What triggers this need, this desire? Who are the recipients of these messages? Methodology: Analysis of victims’ texts (written by direct or indirect victims or their relatives) according to several parameters, including chronological succession – sometimes meticulous – events, the narration of personal experiences at distances sometimes very variable of the situations that inspire them. Analysis: This is a network analysis according to the method of comparative clinical epistemology which shows that: the literary structure and construction chosen by the authors are very varied, as are the literary genres mastered or sketched to which they belong. The roles of these texts and the functions to which the construction of such narratives responds differ according to the victims; we often find a remote function, a step back from a moment in his life that affects his future. Compared to the reader, the function of testimony and sharing does not seem a sufficient explanation while the need to make each disappeared live in the collective memory often appears to the victim as a necessity. The Narratology and Ricoeur's studies on identity and self-constitution have emphasized the richness of the notion of narrative unity of life while taking into account the difficulties it raises. Conclusion: The writings of victims account for an individual experience at different moments of the evolution of trauma and sequelae; the moment of transition to writing, near or at a distance of the attack is variable, as is the evolution of posttraumatic stress; as for the sequelae it is often appreciated differently by the victim, his entourage and professionals. © 2023",TestAnalysis
"With the recent expansion of social media in the form of social networks, online portals, and microblogs, users have generated a vast number of opinions, reviews, ratings, and feedback. Businesses, governments, and individuals benefit greatly from this information. While this information is intended to be informative, a large portion of it necessitates the use of text mining and sentiment analysis models. It is a matter of concern that reviews on social media lack text context semantics. A model for sentiment classification for customer reviews based on manifold dimensions and manifold modeling is presented to fully exploit the sentiment data provided in reviews and handle the issue of the absence of text context semantics. This paper uses a deep learning framework to model review texts using two dimensions of language texts and ideogrammatic icons and three levels of documents, sentences, and words for a text context semantic analysis review that enhances the precision of the sentiment categorization process. Observations from the experiments show that the proposed model outperforms the current sentiment categorization techniques by more than 8.86%, with an average accuracy rate of 97.30%. © 2023 by the authors.",TestAnalysis
"In this paper, the as-cast microstructure, microsegregation, and the kinetics of (γ+γ′) eutectic phase and Laves phase dissolution in GH4151 alloy were studied by the optical microscope (OM), scanning electron microscope (SEM), electron probe microanalysis (EPMA), differential scanning calorimetry (DSC), and high-temperature water quenching text. The results show that W and Al elements are segregated into the dendrites arm, while Mo, Nb, and Ti are segregated into the interdendritic region. The initial melting point temperature of the MB2 phase was near 1100 °C, the redissolution temperature range of γ′ phase is 1130–1160 °C, the obvious dissolution temperature of Laves phase was above 1145 °C and the γ + γ′ eutectic phase was redissolved obviously above 1165 °C. Based on the JMAK analysis, the activation energies of dissolution of Laves phase (266.3 kJ/mol) and γ+γ′ phase (279.5 kJ/mol) are close to the activation energy for the diffusion of Mo in Ni (288.15 kJ/mol) and Ti in Ni (288.15 kJ/mol), respectively. The back-diffusion of Mo and Ti into austenite is controlling the micro-mechanism for the dissolution of Laves phase and (γ+γ′) eutectic phase, respectively. © 2023",TestAnalysis
"Digitization, informatization, and Internet penetration have led to a significant rise in cross-border e-commerce (CBEC), attracting considerable interest from academia, government, and industry. This study employed a novel method combining automatic text generation technology and traditional bibliometric analysis to summarize and categorize the research on CBEC evolution from 2000 to 2021. Articles were selected and examined with a focus on four dimensions: customer, risk, supply chain, and platform. Contradictions in these dimensions were found to result in two major obstacles to CBEC development, namely, dataset sharing and platform scalability. These obstacles prevent research on cross-border platforms from moving beyond theory-based studies. Further research needs to examine how soft computing can be used to accelerate and remodel the global trade ecosystem. © 2022 Xi'an Jiaotong University",TestAnalysis
"Background Epidemiological studies of interstitial lung disease (ILD) are limited by small numbers and tertiary care bias. Investigators have leveraged the widespread use of electronic health records (EHRs) to overcome these limitations, but struggle to extract patient-level, longitudinal clinical data needed to address many important research questions. We hypothesized that we could automate longitudinal ILD cohort development using the EHR of a large, community-based healthcare system. Study design and methods We applied a previously validated algorithm to the EHR of a community-based healthcare system to identify ILD cases between 2012–2020. We then extracted disease-specific characteristics and outcomes using fully automated data-extraction algorithms and natural language processing of selected free-text. Results We identified a community cohort of 5,399 ILD patients (prevalence = 118 per 100,000). Pulmonary function tests (71%) and serologies (54%) were commonly used in the diagnostic evaluation, whereas lung biopsy was rare (5%). IPF was the most common ILD diagnosis (n = 972, 18%). Prednisone was the most commonly prescribed medication (911, 17%). Nintedanib and pirfenidone were rarely prescribed (n = 305, 5%). ILD patients were high-utilizers of inpatient (40%/year hospitalized) and outpatient care (80%/year with pulmonary visit), with sustained utilization throughout the post-diagnosis study period. Discussion We demonstrated the feasibility of robustly characterizing a variety of patient-level utilization and health services outcomes in a community-based EHR cohort. This represents a substantial methodological improvement by alleviating traditional constraints on the accuracy and clinical resolution of such ILD cohorts; we believe this approach will make community-based ILD research more efficient, effective, and scalable. Copyright: © 2023 Farrand et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Background: Chronic stress, anxiety, and depression are psychological problems that can hurt young adults, interfering with their everyday function, academic achievement, and interpersonal relationships. This study aimed to assess the impact of Text4Hope, an online mental health service, on the psychological well-being of young adults. Methods: This study adopted both longitudinal and naturalistic controlled trial designs. It examined clinical outcomes in young adult (≤26 years old) subscribers of Text4Hope who completed surveys at baseline and six weeks and compared clinical parameters in two groups of subscribers. The first group comprised the intervention group (IG) (young adult subscribers who received once-daily supportive text messages for six weeks and completed sixth-week evaluation measures between 26 April and 12 July 2020), and the second group was the control group (CG) (young adult subscribers who joined Text4Hope in the same time frame and completed a baseline survey and were yet to receive any text messages). The prevalence of moderate to high stress, anxiety, and depression was measured at baseline and six weeks in the longitudinal study and between the two groups for the naturalistic controlled study using the Perceived Stress Scale (PSS-10), Generalized Anxiety Disorder 7-item (GAD-7), and Patient Health Questionnaire-9 (PHQ-9). Inferential statistics, including the t-test, McNemar test, chi-square, and binary logistic regression analyses, were used to evaluate the differences in the prevalence and severity of the psychological symptoms. Results: In the longitudinal study, of the 9214 subscribers to Text4Hope who completed the baseline survey, 1047 (11.4%) were identified as youth. For the young adult subscribers who completed both the baseline and sixth-week surveys (n = 114), a significant reduction in the prevalence of moderate to high stress (8%) and likely GAD (20%) from baseline to six weeks was reported. Similarly, there was a significant reduction in the mean scores on the PSS-10, GAD-7, and Composite Mental Health score but not the PHQ-9 from baseline to six weeks. The largest reduction in mean scores was for the GAD-7 scale (18.4%), with a small effect size overall. For the naturalistic study, the IG included 173 young adult subscribers of Text4Hope who completed the sixth-week survey compared to 92 subscribers in the CG who completed the baseline survey during the designated period. There was a significantly lower prevalence for likely Moderate Depressive Disorder (MDD) (25.2%) and suicidal thoughts/thoughts of self-harm (48.4%), with a small effect size in the IG compared to the CG. Similarly, lower mean scores were reported for all outcome variables in the IG compared to the CG, with a small to medium effect size. The receipt of daily supportive text messages for six weeks resulted in significantly lower odds of both likely GAD and experiencing thoughts of self-harm or death wish while controlling for sociodemographic characteristics. Conclusions: The Text4Hope service is an effective tool for mental health support for young adult subscribers. Young adults receiving the service exhibited a reduction in psychological symptoms, including thoughts of self-harm or death wish. This population-level intervention program can be used to effectively support young adult mental health and in suicide prevention programs. © 2023 by the authors.",TestAnalysis
[No abstract available],TestAnalysis
"Objectives To explore women's experiences of over-the-counter and prescription medication advice and use during pregnancy. Design A study design consisting of an online survey and nested in-depth interviews with a subsample of participants. We analysed data from survey free-text responses and in-depth interviews using thematic analysis. Quantitative survey data is published elsewhere. Setting The UK. Participants Women were eligible if living in the UK, aged 16-45 years, were pregnant or had been pregnant in the last 5 years regardless of pregnancy outcome. A total of 7090 women completed the survey, and 34 women who collectively had experienced 68 pregnancies were subsequently interviewed. Results Medication prescribing and use during pregnancy was common. The prescribing, dispensing and taking of some advised medications were restricted through women's or prescribers' fear of fetal harm. Lack of adherence to national prescribing guidance, conflicting professional opinion and poor communication resulted in maternal anxiety, avoidable morbidity and women negotiating complex and distressing pathways to obtain recommended medications. In contrast, some women felt overmedicated and that pharmacological treatments were used without exploring other options first. Conclusion Increased translation of national guidance into practice and greater personalisation of antenatal care are needed to improve the safety, efficacy and personalisation of prescribing in pregnancy.  © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY. Published by BMJ.",TestAnalysis
"Background: Natural Language Processing (NLP) is widely used to extract clinical insights from Electronic Health Records (EHRs). However, the lack of annotated data, automated tools, and other challenges hinder the full utilisation of NLP for EHRs. Various Machine Learning (ML), Deep Learning (DL) and NLP techniques are studied and compared to understand the limitations and opportunities in this space comprehensively. Methodology: After screening 261 articles from 11 databases, we included 127 papers for full-text review covering seven categories of articles: (1) medical note classification, (2) clinical entity recognition, (3) text summarisation, (4) deep learning (DL) and transfer learning architecture, (5) information extraction, (6) Medical language translation and (7) other NLP applications. This study follows the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Result and Discussion: EHR was the most commonly used data type among the selected articles, and the datasets were primarily unstructured. Various ML and DL methods were used, with prediction or classification being the most common application of ML or DL. The most common use cases were: the International Classification of Diseases, Ninth Revision (ICD-9) classification, clinical note analysis, and named entity recognition (NER) for clinical descriptions and research on psychiatric disorders. Conclusion: We find that the adopted ML models were not adequately assessed. In addition, the data imbalance problem is quite important, yet we must find techniques to address this underlining problem. Future studies should address key limitations in studies, primarily identifying Lupus Nephritis, Suicide Attempts, perinatal self-harmed and ICD-9 classification. © 2023 Elsevier Ltd",TestAnalysis
"Background: Sustainability is becoming an increasingly important issue in higher education (HE). Leadership statements in university sustainability reports (LSUSR) represent a unique genre for university leaders to communicate sustainability. This study aims to demystify the genre so that future leadership statements might be crafted with a greater degree of reflexivity. Literature review: Sustainability discourse in HE has been regarded as a legitimacy tool and an opportunity for image improvement for universities. Some studies have examined university sustainability reports, whereas there is a lack of studies focusing on the section of leadership statements. Research question: Are there any cross-cultural similarities or differences in terms of rhetorical moves and communicative purposes between the Italian LSUSR genre and the American LSUSR genre? Research methodology: Using cross-cultural genre analysis, this study investigates the rhetorical moves of leadership statements produced by Italian and American universities. A move scheme is established and is used to annotate the sample texts. Results and conclusion: The findings show that although the Italian and American LSUSR genres share the communicative purpose of establishing a sustainable image, the degree of discourse force exerting on this communicative purpose varies. The image-building discourse force appears to be more noticeable in the American leadership statements, which tend to use a wider range and a larger quantity of image-improving moves. The Italian subcorpus, on the other hand, seems to pay more attention to the genre function of report-introducing, which is not explicitly linked to image improvement. This article suggests that practitioners could consider the potentials of the LSUSR genre in developing an institutional culture of sustainability.  © 1988-2012 IEEE.",TestAnalysis
"Artificial intelligence (AI) technologies are used in many dimensions of our lives, including education. Motivated by the increasing use of AI technologies and the current state of the art, this study examines research on AI from the perspective of online distance education. Following a systematic review protocol and using data mining and analytics approaches, the study examines a total of 276 publications. Accordingly, time trend analysis increases steadily with a peak in recent years, and China, India, and the United States are the leading countries in research on AI in online learning and distance education. Computer science and engineering are the research areas that make the most of the contribution, followed by social sciences. t-SNE analysis reveals three dominant clusters showing thematic tendencies, which are as follows: (1) how AI technologies are used in online teaching and learning processes, (2) how algorithms are used for the recognition, identification, and prediction of students’ behaviors, and (3) adaptive and personalized learning empowered through artificial intelligence technologies. Additionally, the text mining and social network analysis identified three broad research themes, which are (1) educational data mining, learning analytics, and artificial intelligence for adaptive and personalized learning; (2) algorithmic online educational spaces, ethics, and human agency; and (3) online learning through detection, identification, recognition, and prediction. © 2023 by the authors.",TestAnalysis
"STUDY QUESTION: What are the chances of achieving a live birth after embryo, oocyte and ovarian tissue cryopreservation (OTC) in female cancer survivors? SUMMARY ANSWER: The live birth rates (LBRs) following embryo and oocyte cryopreservation are 41% and 32%, respectively, while for IVF and spontaneous LBR after tissue cryopreservation and transplantation, these rates are 21% and 33%, respectively. WHAT IS KNOWN ALREADY: Currently, fertility preservation (FP) has become a major public health issue as diagnostic and therapeutic progress has made it possible to achieve an 80% survival rate in children, adolescents and young adults with cancer. In the latest ESHRE guidelines, only oocyte and embryo cryopreservation are considered as established options for FP. OTC is still considered to be an innovative method, while it is an acceptable FP technique in the American Society for Reproductive Medicine guidelines. However, given the lack of studies on long-term outcomes after FP, it is still unclear which technique offers the best chance to achieve a live birth. STUDY DESIGN, SIZE, DURATION: We performed a systematic review and meta-analysis of published controlled studies. Searches were conducted from January 2004 to May 2021 in Medline, Embase and the Cochrane Library using the following search terms: cancer, stem cell transplantation, FP, embryo cryopreservation, oocyte vitrification, OTC and reproductive outcome. PARTICIPANTS/MATERIALS, SETTING, METHODS: A total of 126 full-text articles were preselected from 1436 references based on the title and abstract and assessed via the Newcastle-Ottawa Quality Assessment Scale. The studies were selected, and their data were extracted by two independent reviewers according to the Cochrane methods. A fixed-effect meta-analysis was performed for outcomes with high heterogeneity. MAIN RESULTS AND THE ROLE OF CHANCE: Data from 34 studies were used for this meta-analysis. Regarding cryopreserved embryos, the LBR after IVF was 41% (95% CI: 34-48, I2: 0%, fixed effect). Concerning vitrified oocytes, the LBR was 32% (95% CI: 26-39, I2: 0%, fixed effect). Finally, the LBR after IVF and the spontaneous LBR after ovarian tissue transplantation were 21% (95% CI: 15-26, I2: 0%, fixed-effect) and 33% (95% CI: 25-42, I2: 46.1%, random-effect), respectively. For all outcomes, in the sensitivity analyses, the maximum variation in the estimated percentage was 1%. LIMITATIONS, REASONS FOR CAUTION: The heterogeneity of the literature prevents us from comparing these three techniques. This meta-analysis provides limited data which may help clinicians when counselling patients. WIDER IMPLICATIONS OF THE FINDINGS: This study highlights the need for long-term follow-up registries to assess return rates, as well as spontaneous pregnancy rates and birth rates after FP. STUDY FUNDING/COMPETING INTEREST(S): This work was sponsored by an unrestricted grant from GEDEON RICHTER France. The authors have no competing interests to declare. REGISTRATION NUMBER: CRD42021264042. © The Author(s) 2022. Published by Oxford University Press on behalf of European Society of Human Reproduction and Embryology.",TestAnalysis
"Cell phone use while walking is an ever-increasing traffic hazard, and leads to an augmented risk of accidents. There is a rising number of injuries to pedestrians using a cell phone. Texting on a cell phone while walking is an emerging problem among people of different ages. The aim of this experiment was to investigate whether using a cell phone while walking affects walking velocity, as well as cadence, stride width, and length in young people. Forty-two subjects (20 males, 22 females; mean age: 20.74 ± 1.34 years; mean height: 173.21 ± 8.07 cm; mean weight: 69.05 ± 14.07 kg) participated in the study. The subjects were asked to walk on an FDM−1.5 dynamometer platform four times at a constant comfortable velocity and a fast velocity of their choice. They were asked to continuously type one sentence on a cell phone while walking at the same velocity. The results showed that texting while walking led to a significant reduction in velocity compared to walking without the phone. Width, cadence, and length of right and left single steps were statistically significantly influenced by this task. In conclusion, such changes in gait parameters may result in an increased risk of pedestrian crossing accidents and tripping while walking. Phone use is an activity that should be avoided while walking. © 2023 by the authors.",TestAnalysis
"Little is known about digital health interventions used to support treatment for pregnant and early parenting women (PEPW) with substance use disorders (SUD). Methods: Guided by the Arksey and O’Malley’s Scoping Review Framework, empirical studies were identified within the CINAHL, PsycInfo, PubMed, and ProQuest databases using subject headings and free-text keywords. Studies were selected based on a priori inclusion/exclusion criteria, and data extraction and descriptive analysis were performed. Results: A total of 27 original studies and 30 articles were included. Varying study designs were used, including several feasibility and acceptability studies. However, efficacious findings on abstinence and other clinically important outcomes were reported in several studies. Most studies focused on digital interventions for pregnant women (89.7%), suggesting a dearth of research on how digital technologies may support early parenting women with SUD. No studies included PEPW family members or involved PEPW women in the intervention design. Conclusions: The science of digital interventions to support treatment for PEPW is in an early stage, but feasibility and efficacy results are promising. Future research should explore community-based participatory partnerships with PEPW to develop or tailor digital interventions and include family or external support systems to engage in the intervention alongside PEPW. © 2023 by the authors.",TestAnalysis
"Background: With the advent of the COVID-19 pandemic, pharmacy students and educators experienced an abrupt shift as programmes that were previously taught exclusively in-person were then predominantly taught online. This sudden change provided little time for students to prepare for the new learning environment. Objectives: The study objective was to explore pharmacy students' experiences of technology-enhanced learning during the COVID-19 pandemic. Methods: A cross-sectional survey was developed and distributed by email to all 3rd year (N = 76) and 4th year (N = 68) pharmacy students undertaking an MPharm programme in an Irish university. Results: A total of 32 responses were collected, including 20 third year and 12 fourth year pharmacy students (response rates of 26.3% and 17.6%, respectively). The majority of respondents reported good or very good internet speed (71%) and stability (59%). Almost all were confident or very confident using Canvas (97%) prior to the onset of online learning. Respondents preferred engaging with other students in-person rather than online for coursework (68.8%) and learning new material (56.3%). Students favoured face-to-face delivery, with a recording of the session available online afterwards, for lectures (68.8%), workshops (50%) and tutorials (56.3%). Analysis of free-text comments indicates that respondents used recorded content to support exam revision and that a key drawback of online learning was social isolation. Implications: Pharmacy students favoured a blended learning approach, with in-person learning being recorded to support study and revision. Students' experience of TEL during the pandemic should be considered in the development and ongoing review of pharmacy programmes. © 2022 The Authors",TestAnalysis
"Recent research has shown writing strategies to have a substantial impact on language learners' writing performance but little is known about what strategies EFL learners use and how they use them in writing academic texts such as reports, final assignments, and project papers. The study reported in this paper extends this line of research by investigating the strategies Vietnamese EFL pre-service teachers use in academic writing. Data included document analysis of 17 pre-service teachers' final assignment papers (one paper per teacher) and individual semi-structured interviews with ten teachers. The study adopted a content-based approach to qualitative data analysis with reference to a comprehensive research-based taxonomy for L2 academic writing strategies, including rhetorical, metacognitive, cognitive, and social affective strategies. The results show that rhetorical, metacognitive, and cognitive strategies were most frequently used by the teacher participants. The results further show that self-efficacy and self-regulation determined the teachers' use of strategies during the writing process. Implications for the L2 writing classroom focused on academic writing strategies to enhance pre-service teachers’ writing quality will be discussed. © 2023",TestAnalysis
"The Cholera-Hospital-Based-Intervention-for-7-Days (CHoBI7) mobile health program promotes water, sanitation, and hygiene (WASH) behaviors through interactive voice response (IVR), voice, and text messages to reduce diarrheal diseases in Bangladesh. The objective of this study was to investigate the relationship between responses to CHoBI7 WASH IVR quiz messages and subsequent diarrhea and WASH behaviors. Fourteen CHoBI7 IVR quiz messages on handwashing with soap and treatment of stored water were sent to 517 households with 1,777 participants during the 12-month program period. IVR message responses were classified as correct answer, incorrect answer, no response (did not press 1 or 2), and failed (did not answer the phone). Diarrhea prevalence was assessed through self-reported monthly clinical surveillance visits. Handwashing with soap was assessed by a 5-hour structured observation, and stored water quality was defined by Escherichia coli concentration. Households that responded correctly to a CHoBI7 IVR quiz message had significantly lower odds of diarrhea for all age groups (adults and children) at the subsequent visit 1 month later (odds ratio [OR], 0.73; 95% CI, 0.54–0.98), and significantly greater odds of handwashing with soap after stool-related events (OR, 2.48; 95% CI, 1.12–5.49) and E. coli levels, 100 colony forming units (CFU)/100 mL (World Health Organization high-risk cutoff) in the stored household water (OR, 2.04; 95% CI, 1.25–3.33) compared with households that did not answer CHoBI7 IVR quiz calls. Correct responses to CHoBI7 IVR quizzes were associated with decreased diarrhea prevalence and improved stored drinking water quality and handwashing with soap behaviors at the subsequent visits. These findings suggest engagement in the CHoBI7 mobile health (mHealth) program and awareness of diarrheal disease prevention can reduce diarrhea and facilitate changes in WASH behaviors. Copyright © 2023 The American Society of Tropical Medicine and Hygiene.",TestAnalysis
"Design: Systematic review. Data Sources: The following databases were searched for publications up to May 2022: Medline, EMBASE, Scopus, Web of Science, LILACS, Cochrane and Open Grey. Additionally, four journals were hand searched. Study Selection: Clear inclusion and exclusion criteria were provided. A focused question was outlined using PICO format. A full search protocol was supplied, and all study designs were considered. Data extraction and synthesis: Two reviewers screened 97 articles after de-duplication. Fourteen full-text articles were assessed. Data were collected using a spreadsheet. Results: Four cross-sectional studies were included in the systematic review, all reporting on male participants. Meta-analysis was performed highlighting worse outcomes in electronic cigarette (e- cigarette) user group regarding increased bone loss, probing depth, plaque index and bleeding on probing, as well as increased levels of inflammatory cytokines, when compared to never-smokers. Conclusions: From the limited number of studies available, e-cigarettes appear to have a negative impact on dental implant outcomes in male patients. © 2023, The Author(s), under exclusive licence to British Dental Association.",TestAnalysis
"Designing and delivering useful information for customers are crucial requirements of smart services as they influence the customer perception of the value and appeal of the service. Service information represents the results of data analysis that are delivered to customers. While the importance of transforming data into information has been recognized, the process of information design has been inadequately researched. This study introduces a methodology for transforming data into information to support smart services. The methodology is developed using morphological analysis and text mining. The proposed methodology was applied to a real-world case in smart services for vehicle operations management. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TestAnalysis
"Fine-grained sentiment analysis, known as Aspect-Based Sentiment Analysis (ABSA), establishes the polarity of a section of text concerning a particular aspect. Aspect, sentiment, and emotion categorisation are the three steps that make up the configuration of ABSA, which we looked into for the dataset of English reviews. In this work, due to the fuzzy nature of textual data, we investigated machine learning methods based on fuzzy rough sets, which we believe are more interpretable than complex state-of-the-art models. The novelty of this paper is the use of a pipeline that incorporates all three mentioned steps and applies Fuzzy-Rough Nearest Neighbour classification techniques with their extension based on ordered weighted average operators (FRNN-OWA), combined with text embeddings based on transformers. After some improvements in the pipeline’s stages, such as using two separate models for emotion detection, we obtain the correct results for the majority of test instances (up to 81.4%) for all three classification tasks. We consider three different options for the pipeline. In two of them, all three classification tasks are performed consecutively, reducing data at each step to retain only correct predictions, while the third option performs each step independently. This solution allows us to examine the prediction results after each step and spot certain patterns. We used it for an error analysis that enables us, for each test instance, to identify the neighbouring training samples and demonstrate that our methods can extract useful patterns from the data. Finally, we compare our results with another paper that performed the same ABSA classification for the Dutch version of the dataset and conclude that our results are in line with theirs or even slightly better. © 2023 by the authors.",TestAnalysis
"After the cold war, some countries gradually seek to regional cooperation when they could not handle various transnational challenges alone. Shanghai Cooperation Organization (SCO) is a good example. It brought Central Asian countries together. This paper applies the text-mining method, using co-word analysis, co-occurrence matrix, cluster analysis, and strategic diagram to analyze the selected articles from newspapers quantitatively and visually. In order to investigate the Chinese government’s attitude toward the SCO, this study collected data from the China Core Newspaper Full-text Database, which contains high-impact government newspapers revealing the Chinese government’s perception of the SCO. This study characterizes the changing role of SCO as perceived by the Chinese government from 2001 to 2019. Beijing’s changing expectations in each of the three identified subperiods are described. Copyright: © 2023 Xu, Rogers. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Objectives: Polycystic ovary syndrome (PCOS) is a common endocrine disease in women of childbearing age. Although it is a leading cause of menstrual disorders, infertility, obesity, and other diseases, its molecular mechanism remains unclear. This study aimed to analyze the target genes, pathways, and potential drugs for PCOS through text mining. Methods: First, three different keywords (""polycystic ovary syndrome"", ""obesity/adiposis"", and ""anovulation"") were uploaded to GenCLiP3 to obtain three different gene sets. We then chose the common genes among these gene sets. Second, we performed gene ontology and signal pathway enrichment analyses of these common genes, followed by protein-protein interaction (PPI) network analysis. Third, the most significant gene module clustered in the protein-protein network was selected to identify potential drugs for PCOS via gene-drug analysis. Results: A total of 4291 genes related to three different keywords were obtained through text mining, 72 common genes were filtered among the three gene sets, and 69 genes participated in PPI network construction, of which 23 genes were clustered in the gene modules. Finally, six of the 23 genes were targeted by 30 existing drugs. Conclusions: The discovery of the six genes (CYP19A1, ESR1, IGF1R, PGR, PTGS2, and VEGFA) and 30 targeted drugs, which are associated with ovarian steroidogenesis (P <0.001), may be used in potential therapeutic strategies for PCOS.  Copyright © 2022 Reproductive and Developmental Medicine, Published by Wolters Kluwer Health, Inc.",TestAnalysis
"The Editorial Office would like to draw the reader's attention to the error in the following article. Van Linden L, Stoops K, Dumbá LCCS et al. (2022). Sagittal crest morphology decoupled from relative bite performance in Pleistocene tapirs (Perissodactyla: Tapiridae). Integrative Zoology 00, 1–24. https://doi.org/10.1111/1749-4877.12627 In the original version of this Original Article, absolute bite forces were described for available species of tapirids (Tapiridae: Perissodactyla). Due to author oversights in the bite force calculations, the maximum tension constant for mammalian muscle (300 kPa; Law & Mehta 2019) was not incorporated into the calculation. In this correction, we present the amended text and accurate bite force estimates which account for maximum muscle tension alongside the original versions of both text and tables MATERIALS AND METHODS (paragraph 5, sentence 9) Original: Bilateral bite forces were estimated using the equation: (Formula presented.) where MP is the cross-sectional area for m. masseter + m. pterygoideus, mp is the moment arm for m. masseter + m. pterygoideus, T is the cross-sectional area for m. temporalis, t is the moment arm for m. temporalis, and Oi is the out-lever from the temporomandibular joint to each tooth. Correction: Bilateral bite forces were estimated using the equation: (Formula presented.) where MP is the cross-sectional area for m. masseter + m. pterygoideus, mp is the moment arm for m. masseter + m. pterygoideus, T is the cross-sectional area for m. temporalis, t is the moment arm for m. temporalis, and Oi is the out-lever from the temporomandibular joint to each tooth. Cross-sectional areas were multiplied by a maximum tension constant for mammalian muscle (300 kPa), following previous published works (e.g. Thomason 1991; Christiansen & Wroe 2007; Law & Mehta 2019). RESULTS (Table 2) Original and corrected bite forces (BF) at the first molar in Newtons (N) for tapirid species ± standard deviation (SD) to 3 significant figures, with n the number of specimens per species. (Table presented.) These corrected values were all subjected to the same correction (300 kPa maximum muscle tension; Law & Mehta 2019); as such, the values are altered but the resultant patterns of bite forces remain constant. No changes to the range of values compared to sagittal crest height were observed, and no changes to biogeographical variation are found. Thus, our interpretations regarding the influence of phylogeny and biogeography on the bite force data recovered are unaffected, and we do not present alternative graphs as the original patterns remain constant. A correction was added to Fig. 4 to display the correct bite forces. We have provided the updated bite force calculations as a Supplementary File. The corrected values for bite force do affect our interpretations for interspecific comparison in the Discussion section, so we provide the following amendments to the original text. 4 Figure (Figure presented.) DISCUSSION (paragraph 2, sentence 1) Original: Our study showed that tapirs exhibit variation in bite forces, with some species having higher bite forces relative to their skull size than might be expected (e.g. T. mesopotamicus). Unsurprisingly, tapirs with large skulls (and consequently large muscle masses) had high absolute bite forces. Bite force estimates for large herbivores are rare, particularly for extant ungulates (e.g. DeSantis et al. 2020; bite forces calculated but not reported), hence it is quite difficult to see how these tapir bite forces compare to other extant clades of large herbivores. However, bite force estimates have been calculated for large, extinct herbivores such as the diprotodontid marsupial Diprotodon optatum (Sharp & Rich 2016) and the hystricognath rodent Josephoartigasia monesi (Blanco et al. 2012). When compared to mid-sized tapirids in the present study (e.g. T. bairdii, T. veroensis; body masses ∼250 kg, MacLaren et al. 2018), the estimation of bilateral bite force at the center of the cheek toothrow for D. optatum yields similar bite forces (5000–6000 N) despite D. optatum reputedly reaching body masses of over 2000 kg (Wroe et al. 2004). Bilateral bite forces at the caniniform incisor for mid-sized tapirs (2000–2700 N) fall well within the range of bite forces for the giant rodent J. monesi (1260–6428 N; values from Blanco et al. (2012) scaled up to assume a bilateral bite force). Although these values for herbivores may appear high, especially for tapirs, herbivorous species of bears (Ursus malayanus and Ailuropoda melanoleuca) exhibit higher bite forces than carnivorous species (Christiansen & Wroe 2007); the overall pressure exerted on the apex of sharp, carnivoran teeth will ultimately be greater for a given input force than that of a ridged or lophodont tooth, as are exhibited in tapirs. Thus, the high values calculated for large-bodied herbivores, in general, may not be overly surprising. Correction: Our study showed that tapirs exhibit variation in bite forces, with some species having higher bite forces relative to their skull size than might be expected (e.g. T. mesopotamicus). Unsurprisingly, tapirs with large skulls (and consequently large muscle masses) had high absolute bite forces. Bite force estimates for large herbivores are rare, particularly for extant ungulates (e.g. DeSantis et al. 2020; bite forces calculated but not reported), hence it is quite difficult to see how these tapir bite forces compare to other extant clades of large herbivores. However, bite force estimates have been calculated for large, extinct herbivores such as the diprotodontid marsupial Diprotodon optatum (Sharp & Rich 2016) and the hystricognath rodent Josephoartigasia monesi (Blanco et al. 2012). When compared to the largest tapirids in the present study (T. augustus; BF ≈3200 N, body masses ∼630 kg, MacLaren et al. 2018), the estimation of bilateral bite force at the center of the cheek toothrow for D. optatum yields far higher absolute bite forces (5000–6000 N). Despite this, relative bite forces may have been more comparable, given that D. optatum reputedly reached body masses of over 2000 kg (Wroe et al. 2004), more than 3 times heavier than the largest tapir T. augustus. Bilateral bite forces at the caniniform incisor for T. augustus (∼1300 N) fall well within the range of bite forces for the giant rodent J. monesi (967–1850 N), an animal estimated to weigh up to 1000kg (Cox et al. 2015). Among herbivorous carnivorans with bite force data available, bite forces at the first molar for giant panda (Ailuropoda melanoleuca) approximate those of small-to-mid-sized Tapirus (1100–1800 N; Christiansen & Wroe 2007; Figueirido et al. 2014), never falling lower than the smallest extinct species (Tapirus polkensis ∼950 N). Although these values for herbivores may initially appear high, herbivorous species of bear (Ursus malayanus and Ailuropoda melanoleuca) on the whole exhibit higher bite forces than carnivorous species (Christiansen & Wroe 2007); the overall pressure exerted on the apex of sharp, carnivoran teeth will ultimately be greater for a given input force than that of a ridged or lophodont tooth, as are exhibited in tapirs. Thus, the high values calculated for large-bodied herbivores, in general, may not be overly surprising. All other discussion topics and conclusions remain accurate in the original version of the manuscript. In the Supplementary Information, an amended raw dataset has been provided including edited units, raw values and species averaged values for bite force and sagittal crest height. We add additional acknowledgement to the researcher who notified us of our oversight, and one additional reference as cited in the corrected text: ACKNOWLEDGMENTS (paragraph 1, line 2) The authors wish to thank C. Cartelle (Museu de Ciências Naturais PUC Minas), L. F. B. Flamarion (Coleção de Mastozoologia do Museu Nacional do Rio de Janeiro), F. A. Perini (Coleção de Mastozoologia da Universidade Federal de Minas Gerais), O. Pauwels (Royal Belgian Institute of Natural Sciences), J. Lésur (Museum National d'Histoire Naturelle), L. Tyteca (MuseOs Natuurhistorichmuseum), and R. C. Hulbert Jr. (Florida Museum of Natural History) for the access to tapir collections. The authors also wish to thank M. Green for feedback on the study, and 4 anonymous reviewers. This study was conceived by JAM. Measurements were collected by LVL, KS, and JAM; first-hand images were provided by LCCSD, MAC, and JAM. Statistical analyses were performed by LVL; drafts were written by LVL and KS, with all authors contributing to the final version of the manuscript. This work was facilitated by doctoral and post-doctoral funding awarded to JAM (doctoral by the Fonds Wetenschappelijk Onzerzoek [FWO]; post-doctoral by Fonds de la Recherche Scientifique [FNRS]; travel grant from the Florida Museum of Natural History [FLMNH]), and a doctoral fellowship awarded to LCCSD (by the Coordenação de Aperfeiçoamento de Pessoal de Nível Superior [CAPES]). © 2022 International Society of Zoological Sciences, Institute of Zoology/Chinese Academy of Sciences and John Wiley & Sons Australia, Ltd.",TestAnalysis
"Extreme climate events and renewable energy development challenge the reliability of the power supply, which is an important guarantee for high-quality economic development and the production and operation of firms. In this paper, we analyzed the relationship between power shortage and firm productivity by developing a city-level power shortage index in China using the text analysis method. The results indicate that power shortage reduces the probability, quantity, and quality of R&D investment and has a negative impact on the total factor productivity (TFP) of firms. However, it has a smaller negative impact on the TFP of large- and medium-sized firms, export-oriented firms, and state-owned firms than others. Our results are robust to alternative measures of power shortage. © 2023 Elsevier B.V.",TestAnalysis
"Artificial intelligence (AI) has the potential to revolutionize research by automating data analysis, generating new insights, and supporting the discovery of new knowledge. The top 10 contribution areas of AI towards public health were gathered in this exploratory study. We utilized the “text-davinci-003” model of GPT-3, using OpenAI playground default parameters. The model was trained with the largest training dataset any AI had, limited to a cut-off date in 2021. This study aimed to test the ability of GPT-3 to advance public health and to explore the feasibility of using AI as a scientific co-author. We asked the AI asked for structured input, including scientific quotations, and reviewed responses for plausibility. We found that GPT-3 was able to assemble, summarize, and generate plausible text blocks relevant for public health concerns, elucidating valuable areas of application for itself. However, most quotations were purely invented by GPT-3 and thus invalid. Our research showed that AI can contribute to public health research as a team member. According to authorship guidelines, the AI was ultimately not listed as a co-author, as it would be done with a human researcher. We conclude that good scientific practice also needs to be followed for AI contributions, and a broad scientific discourse on AI contributions is needed. © 2023 by the authors.",TestAnalysis
"Purpose: This study was to analyze the responses of informants about Instagram infographics on Covid-19 prevention for pregnant women. Methods: This was a qualitative study that used Rapid Assessment Procedure (RAP) and used pretesting communication theory. The informant selection technique was purposive sampling that consist of three pregnant women as main informants, a midwifery lecturer and a visual graphic designer as key informants. One-to-one pretesting communication procedure was selected because the research was conducted at the beginning of the Covid-19 pandemic, so it had a difficulty in recruiting informants. The interview guideline was conducted by the research team and was examined in a field trial. Data collection was by semi-structured interview using voice call WhatsApp application. Data were analysed using thematic analysis. Results: In attraction aspect, this was considered quite interesting by the informants. In comprehension aspect, the messages were easily understood because of using brief, concise, and simple sentences. Furthermore, the messages were supported by images and comprehensive. In acceptance aspect, all the informants’ opinions were identified that the messages of this infographic did not have a conflict with the existing norms. In self-involvement aspect, this infographic was in accordance with the current condition of the informants. In persuasion aspect, it had a good persuasive value as the informants were willing to share the infographic with others. Conclusion: The infographic still needed improvements from the attraction aspect such as consider using contrasting colour between the background and text, equalize the font size and change icons to become related to the text. As from the comprehension aspect consider using terms that are more popular in the community. There were no need improvements from acceptance, self-involvement, and persuasion aspects. However, evidence-based research is still needed on how this infographic is developed and implemented to optimize transfer of knowledge. © 2023, Dove Medical Press Ltd. All rights reserved.",TestAnalysis
"Research question: Does dental trauma have impact on the oral health-related quality of life of children and adolescents? Research protocol: Protocol was designed as per the best practices of evidence-based medicine, guidelines for umbrella reviews and registered in PROSPERO. Literature search: PubMed, Scopus, Embase, Web of Sciences and Lilacs were searched for studies meeting the inclusion criteria from start of databases to 15th July 2021. Grey literature and registries of systematic review protocols were also searched. Hand searching of the references of included articles was also performed. The literature search was updated on 15th October 2021. Scrutiny of the titles and abstracts and later full text was done as per the inclusion and exclusion criteria. Data extraction: Self-designed pre-piloted form was used by two reviewers. Quality appraisal: AMSTAR-2 was used to assess the quality of systematic reviews, PRISMA was used to check reporting-characteristics and citation-matrix was used to evaluate study-overlap. Quality of evidence was assessed by using Kohler’s-criteria. Data analysis: Qualitative synthesis was performed for describing the study characteristics, details of sampling and the tool of OHRQoL used. The meta-analytic data was used for evaluating the evidence and its strength for each of the outcomes. Results and interpretation: A significant impact of all types of TDI on OHRQoL in children and adolescents was observed. The effect of uncomplicated TDI on OHRQoL in children and all ages showed no difference from controls. Though the quality of evidence in these interpretations was weak. © 2023, The Author(s), under exclusive licence to British Dental Association.",TestAnalysis
"Background: With an increasing older population, the pressure on home care resources is growing, which makes it important to ensure the maintenance of quality care. It is known that compassion and ethical sensitivity can improve the quality of care, but little is known about care leaders’ perceptions on ethical sensitivity and compassion in home care and how it is associated with staff competence and thus quality of care. Aim: The aim of the study was to explore home care leaders’ perceptions of ethical sensitivity and compassion associated with care quality in home care. Research design, participants, and research context: A hermeneutical approach with a qualitative explorative design was used. The data consists of texts from 10 in-depth interviews with home care leaders. Content analysis was used as a method. Ethical considerations: The study was conducted following the ethical guidelines of the Declaration of Helsinki and the Finnish Advisory Board of Research Ethics. Research ethics permission was applied for from a Research Ethics Board. Findings: One overall theme and four subthemes were found. The overall theme was: “Compassion provides deeper meaning and ethical sensitivity provides means for knowing how to act”. Discussion: If nurses fail to be sensitive and compassionate with patients, good and high qualitative home care cannot be achieved. Ethical sensitivity and compassion can be seen as resources in home care but the organization and the care leaders need to provide the support for these to develop. Conclusion: This study provides an understanding of the meaning of ethical sensitivity and compassion as sources of strength and their link to quality of care in a home care context. Further studies could focus on how to build compassion and ethical sensitivity into home-based care and how to ensure adequate support for healthcare professionals’ compassion and ethical sensitivity. © The Author(s) 2022.",TestAnalysis
"Based on the background of the digital transformation of commercial banks, the advantages and benefits of this study are to study the promotion effect of digital finance on the production efficiency of commercial banks from four aspects: technological innovation, financial innovation, deep integration of technology and finance, and industry advantages. This study verifies that digital finance has a positive impact on the total factor productivity of commercial banks. In order to study the impact of the development of digital finance on the efficiency of commercial banks, this paper puts forward two assumptions. Using the “text mining method” and taking the total factor productivity of commercial banks as the explanatory variable and the digital finance index as the core explanatory variable, this paper empirically studies the impact of digital finance on bank efficiency. Through empirical research, it is believed that through the analysis of total factor productivity, digital finance has strongly promoted the improvement of the total factor productivity of commercial banks through the technology spillover effect. The impact of digital finance on banks is therefore heterogeneous. © 2023 by the authors.",TestAnalysis
"The improvement of health literacy (HL) is a critical issue for college students who are in the transitional period to adulthood and are establishing their subsequent lifestyles. The present study aimed to evaluate the current state of HL among college students and to explore the factors that influence HL. Moreover, it investigated the relationship between HL and health conditions. For this study, the researchers conducted an online survey of college students. The questionnaire consisted of the Japanese version of the 47-item European Health Literacy Survey Questionnaire (HLS-EU-Q47), which is a self-assessment tool for HL that covers the major health issues of college students and health-related quality of life. The study analyzed 1049 valid responses. Based on the HLS-EU-Q47 total score, 85% of the participants exhibited problematic or unsatisfactory HL levels. Participants who reported high levels of healthy lifestyles obtained high HL scores. High levels of HL were associated with high levels of subjective health. Results from quantitative text analysis suggested that specific mindsets were correlated with high levels of competency in appraising health information among male students. In the future, educational intervention programs for college students need to be established to improve HL levels. © 2023 by the authors.",TestAnalysis
"Problem: This tutorial aims to guide readers through key concepts, basic processes, and common decision points that inform computer-assisted corpus-based research in technical, professional, and scientific communication (TPSC). Key concepts: Based on our collaborative experiences and an example developed for this tutorial, key concepts of corpus analysis useful to TPSC researchers and practitioners include the following: corpus location, text preparation, and programming language and software selection. Key lessons: These key concepts can be used to establish basic processes and decision points that, in turn, yield lessons related to the usefulness of lexicogrammatical language models and the significance of multidisciplinarity. Implications: Although corpus research is a growing and important part of the field of TPSC, challenges remain in terms of language model variety and ethical considerations. At least in part, these challenges can be met, respectively, by alignment between corpus and analytic tools and reference to the Common Rule and related international standards.  © 1988-2012 IEEE.",TestAnalysis
"Aim: To document current teaching methods, curriculum, and perceived educational preparation related to the teaching of life-limiting fetal conditions, termination, and perinatal palliative care to Australian student midwives. Background: Australian women receiving a diagnosis of a life-limiting fetal condition are generally offered a choice between termination of pregnancy and perinatal palliative care. Midwives are often involved with caring for these women. What Australian student midwives are being taught about life-limiting fetal conditions, termination of pregnancy, and perinatal palliative care during their entry-to-practice program is unknown. Design: This study utilised a mixed-methods descriptive approach for data collection and analysis. Methods: Academic Leads of all Australian entry-to-practice midwifery programs received a questionnaire exploring topics taught, teaching time, teacher role, and perceived effectiveness of student preparation. Data was analysed statistically and thematically. Results: Twelve of 24 Academic Leads responded (50%); only five stated their programs taught all three areas. More respondents taught about termination of pregnancy (10/12) than perinatal palliative care (7/12). On average 5.8 ( ± 2.8) total hours was spent teaching about life-limiting fetal conditions, termination of pregnancy, and perinatal palliative care during the entire midwifery program, with a range of 1 – 10 h. The free-text data identified three central themes: lack of value within the curriculum; disconnect between the university and the placement hospital; and preparation for practice. Most (10/12) Academic Leads did not believe student midwives are prepared to care for affected families. Conclusions: Entry-to-practice midwifery programs vary considerably in their education surrounding life-limiting fetal conditions, however teaching hours overall were low and most Academic leads did not feel (or know if) their students were adequately prepared. Further research is required to determine if early career midwives find their university education in life-limiting fetal conditions adequate preparation for practice, and to then remediate identified deficiencies. © 2023 The Authors",TestAnalysis
"With the increasing importance of computer intelligence in the new round of the industrial revolution, administrative, regulatory, or design (ARD) green technology contributes to improving national technological competitiveness and promoting the transformation of green technology, which is becoming an important field under sustainable development goals. The U.S. and China ranked top two in terms of paper influence and patent applications in the field of ARD green technology. However, few comparative studies have been conducted in these two countries. This study presents the evolution and landscapes of ARD green technology between China and the U.S., focusing on comparing development priorities and technical layouts in each five-year plan period. According to the “International Patent Classification (IPC) Green Inventory” launched by the World Intellectual Property Organization (WIPO), we retrieved 69,412 patents published between 2001 and 2020 from the PatSnap database. Descriptive, content, and thematic network analyses were conducted using latent dirichlet allocation (LDA) and community detection algorithms. The results show that both China and the U.S. strategically focus on ARD green technology development. The technical topics in this field can be divided into three themes: data processing systems, traffic control systems, and building designs. The emphasis on technology research and development (R&D) differs between China and the U.S. There is also evidence that the U.S. has advantages in terms of technological innovation and capabilities. However, China has an advantage in terms of data volume, and the gap between China and the U.S. is gradually narrowing. We also highlight the contributions and limitations of this study. © 2023 Xi'an Jiaotong University",TestAnalysis
"Microimplant-assisted rapid palatal expansion is increasingly used clinically; however, the effect on the upper airway volume in patients with maxillary transverse deficiency has not been thoroughly evaluated yet. The following electronic databases were searched up to August 2022: Medline via Ovid, Scopus, Embase, Web of Science, Cochrane Library, Google Scholar, and ProQuest. The reference lists of related articles were also reviewed by manual search. The Revised Cochrane Risk of Bias Tool for randomized trials (ROB2) and the Risk of Bias in non-randomized Studies of Interventions (ROBINS-I) tool were used to evaluate the risks of bias of the included studies. The mean differences (MD) and 95% confidence intervals (CI) of changes in nasal cavity and upper airway volume were analyzed using a random-effects model, and subgroup and sensitivity analyses were also performed. Two reviewers independently completed the process of screening studies, extracting data, and assessing the quality of studies. In total, twenty-one studies met the inclusion criteria. After assessing the full texts, only thirteen studies were included, with nine studies selected for quantitative synthesis. Oropharynx volume increased significantly after immediate expansion (WMD: 3156.84; 95% CI: 83.63, 6230.06); however, there was no significant change in nasal volume (WMD: 2527.23; 95% CI: −92.53, 5147.00) and nasopharynx volume (WMD: 1138.29; 95% CI: −52.04, 2328.61). After retention a period, significant increases were found in nasal volume (WMD: 3646.27; 95% CI: 1082.77, 6209.77) and nasopharynx volume (WMD: 1021.10; 95% CI: 597.11, 1445.08). However, there was no significant change after retention in oropharynx volume (WMD: 789.26; 95% CI: −171.25, 1749.76), palatopharynx volume (WMD: 795.13; 95% CI: −583.97, 2174.22), glossopharynx volume (WMD: 184.50; 95% CI: −1745.97, 2114.96), and hypopharynx volume (WMD: 39.85; 95% CI: −809.77, 889.46). MARPE appears to be linked with long-term increases in nasal and nasopharyngeal volume. However, high-quality clinical trials are required to further verify the effects of MARPE treatment on the upper airway. © 2023 by the authors.",TestAnalysis
"This study aimed to assess global trends in research on salt stress in rice and provide new directions for future studies. The subjects in this study are a plain text file with full records and cited references (Web of Science core collection as the database, “rice” and “salt” as the retrieved title with the date range from 1 January 2000 to 31 December 2021). The bibliometric method was used in this study, and the results were visualized using Scimago Graphica, VOSviewer, and CiteSpace. The results showed that China, India, and Japan contributed most of the literature in this field, and the institutes with the largest academic output were the Chinese Academy of Science, the International Rice Research Institute, and Nanjing Agriculture University. This study argues that research on salt stress in rice has been conducted in three main areas: phenotypes, response mechanisms, and remediation strategies. Inoculation of rhizosphere bacteria, ion homeostasis, soil remediation, and gene editing will be popular topics in rice salt stress research in the future. This study aimed to provide a potential theoretical direction for research on salt stress in rice as well as a reference for feasible studies on the exploitation of saline–alkali lands. © 2023 by the authors.",TestAnalysis
"OBJECTIVE: Reduced fetal movement, defined as a decrease in the frequency or strength of fetal movements as perceived by the mother, is a common reason for presentation to maternity care. Observational studies have demonstrated an association between reduced fetal movement and stillbirth and fetal growth restriction related to placental insufficiency. However, individual intervention studies have described varying results. This systematic review and meta-analysis aimed to determine whether interventions aimed at encouraging awareness of reduced fetal movement and/or improving its subsequent clinical management reduce the frequency of stillbirth or other important secondary outcomes. DATA SOURCES: Searches were conducted in MEDLINE, Embase, CINAHL, The Cochrane Library, Web of Science, and Google Scholar. Guidelines, trial registries, and gray literature were also searched. Databases were searched from inception to January 20, 2022. STUDY ELIGIBILITY CRITERIA: Randomized controlled trials and controlled nonrandomized studies were eligible if they assessed interventions aimed at encouraging awareness of fetal movement or fetal movement counting and/or improving the subsequent clinical management of reduced fetal movement. Eligible populations were singleton pregnancies after 24 completed weeks of gestation. The primary review outcome was stillbirth; a number of secondary maternal and neonatal outcomes were specified in the review. METHODS: Risk of bias was assessed using the Cochrane Risk of Bias 2 and Risk of Bias in Non-Randomized Studies I tools for randomized controlled trials and nonrandomized studies, respectively. Variation caused by heterogeneity was assessed using I2. Data from studies employing similar interventions were combined using random effects meta-analysis. RESULTS: A total of 1609 citations were identified; 190 full-text articles were evaluated against the inclusion criteria, 18 studies (16 randomized controlled trials and 2 nonrandomized studies) were included. The evidence is uncertain about the effect of encouraging awareness of fetal movement on stillbirth when compared with standard care (2 studies, n=330,084) with a pooled adjusted odds ratio of 1.19 (95% confidence interval, 0.96–1.47). Interventions for encouraging awareness of fetal movement may be associated with a reduction in neonatal intensive care unit admissions and Apgar scores of <7 at 5 minutes of age and may not be associated with increases in cesarean deliveries or induction of labor. The evidence is uncertain about the effect of encouraging fetal movement counting on stillbirth when compared with standard care with a pooled odds ratio of 0.69 (95% confidence interval, 0.18–2.65) based on data from 3 randomized controlled trials (n=70,584). Counting fetal movements may increase maternal-fetal attachment and decrease anxiety when compared with standard care. When comparing combined interventions of fetal movement awareness and subsequent clinical management with standard care (1 study, n=393,857), the evidence is uncertain about the effect on stillbirth (adjusted odds ratio, 0.86; 95% confidence interval, 0.70–1.05). CONCLUSION: The effect of interventions for encouraging awareness of reduced fetal movement alone or in combination with subsequent clinical management on stillbirth is uncertain. Encouraging awareness of fetal movement may be associated with reduced adverse neonatal outcomes without an increase in interventions in labor. The meta-analysis was hampered by variations in interventions, outcome reporting, and definitions. Individual studies are frequently underpowered to detect a reduction in severe, rare outcomes and no studies were included from high-burden settings. Studies from such settings are needed to determine whether interventions can reduce stillbirth. © 2022 The Authors",TestAnalysis
"Background: Choroid plexus (CP) metastases are an extremely rare condition accounting for less than 1% of brain metastases. Due to its scarcity, little is known about this pathology and its management. Herein, we propose a review of the current literature to help its diagnosis and management. Methods: Through a literature review based on PubMed/MEDLINE database, we reviewed 94 cases of intraventricular metastasis of solid cancer in 28 full-text articles in English from 1980 to 2010. We have reported epidemiological, clinical, radiological, histological data, as well as management strategies and outcomes. A case report of fourth ventricular pulmonary metastasis illustrates this review. Results: Intraventricular metastases are most often reported in patients in their 6th decade. The clinical presentation is marked by acute hydrocephalus, more rarely lesional bleeding. Three-quarters of intraventricular metastases develop in lateral ventricle, then respectively in the fourth and third ventricles. Kidney cancer accounts for 45% of the cases. The treatment modalities are surgical removal in case of a single lesion and adjuvant radiotherapy and chemotherapy depending on the primary cancer. The prognosis remains poor due to dissemination via the cerebrospinal fluid. Conclusion: Multiple choroid plexus metastasis is a rare diagnosis, affecting patients with a specific clinical presentation and a misleading radiological appearance. There is no standard of care for the management of these lesions and surgical approach can be challenging. © 2023",TestAnalysis
"As sustainability becomes fundamental to companies, voluntary and mandatory disclosures or corporate sustainability practices have become a key source of information for various stakeholders, including regulatory bodies, environmental watchdogs, nonprofits and NGOs, investors, shareholders, and the public at large. Understanding sustainability practices by analyzing a large volume of disclosures poses major challenges, given that the information is mostly in the form of text. Applying machine learning and text analytic methods, we analyzed approximately 25,428 disclosure reports for the period of 2011 to 2020, extracted from the Securities and Exchange Commission (SEC) filings and made available at the Ceres website via application programming interfaces (APIs). Our study identified six industry clusters from the K-means and six main topics from the latent Dirichlet allocation (LDA) method that related to the disclosure of climate-change-related environmental concerns. Both methods produced overlapping results that further reinforce and enhance our understanding of climate-change-related disclosure at various levels, such as sector, industry, and topic. Our analysis shows that companies are concerned primarily with the topics of gas emission, carbon risk, climate change, loss and damage, renewable energy, and financial impact when disclosing climate-change-related issues to the government. The study has implications for corporate sustainability practices, the communication and dissemination of such practices to stakeholders at large and furthering our understanding of sustainability in general. © 2023 by the authors.",TestAnalysis
"Purpose: Implantable electronic cardiovascular device such as cardiac pacemakers and implantable defibrillators are common life-saving devices. Device-related complications can arise when undergoing surgical interventions with electrosurgical tools due to electromagnetic interference, based on electrocautery type, implantable electronic cardiovascular device type, electrocautery location, and a number of other factors. The risk of device-related complications due to electrocautery in oculoplastic surgery has not been established. This systematic literature review assesses prevalence, risk factors, and outcomes of electrocautery-related device complications in oculoplastic surgery. Methods: Systematic literature review followed Preferred Reporting Items for Systematic and Meta-Analysis guidelines and used the search terms ""pacemaker,"" ""implantable cardioverter defibrillator,"" ""electrocautery,"" ""cautery,"" and ""electrosurgery"" through June 2022. Inclusion criteria were full-text articles, discussing ocular, oculoplastic, or other facial surgery. Exclusion criteria were non-English language or surgery focused on other parts of the body. Full-text manuscripts of identified articles were reviewed and relevant data were extracted. Results: Twelve studies met inclusion criteria. Two studies were level I and II evidence, while 10 studies were level III or IV. There were no reports of electromagnetic interference with bipolar cautery use. With monopolar cautery use, cases of electromagnetic interference were reported, but without related significant morbidity or mortality. Safety recommendations to minimize electrical flow through the implantable electronic cardiovascular device are described. Conclusions: There were no reports of implantable electronic cardiovascular device-related complications from bipolar or thermocautery use in ophthalmic or oculoplastic surgeries. Monopolar have been associated with electromagnetic interference, but additional preoperative and perioperative measures can be taken to mitigate this risk. © 2023 Lippincott Williams and Wilkins. All rights reserved.",TestAnalysis
"Data sources: Cochrane Oral Health Information specialist searched databases: Cochrane Oral Health’s Trials Register, Cochrane Central Register of Controlled Trials in the Cochrane diary, MEDLINE Ovid, Embase Ovid, CINAHL EBSCO and Open Grey up to 17 November 2021 without language, publication status or year restriction. Additionally, Chinese Bio Medical Literature Database, China National Knowledge Infrastructure and VIP database were searched up to 4 March 2022. For ongoing trials, the US National Institutes of Health Trials Register, the World Health Organization (WHO) Clinical Trials Registry Platform (up to 17 November 2021), and Sciencepaper Online (up to 4 March 2022) were also searched. A reference list of included studies, hand searching for important journals, and Chinese professional journals in the relevant field was performed until March 2022. Study selection: Authors screened the articles on the basis of their titles and abstracts. Duplicates were removed. Full-text publications were evaluated. Any disagreement was resolved by discussion amongst themselves or in consultation with a third reviewer. Only randomised controlled trials assessing the effects of periodontal treatment on participants having chronic periodontitis with cardiovascular disease (CVD) (secondary prevention) or without cardiovascular disease (primary prevention) with minimum follow-up of one year were considered. Patients having known genetic or congenital heart defects, other sources of inflammation, aggressive periodontitis, or were pregnant and/or lactating were excluded. Subgingival scaling and root planning (SRP) with or without combination of systemic antibiotics with or without active remedies were compared with supragingival scaling, mouth rinse, or no periodontal treatment. Data extraction and synthesis: Data extraction was performed by two independent reviewers in duplicate. A formal, customised pilot-based data extraction form was used to capture data. Overall risk of bias for each study was categorised as low, medium, and high. For trials having missing data or unclear data, clarification from the authors were sought by mail. Testing for heterogeneity was planned by I2 test. For dichotomous data, fixed-effect model (Mantel-Haenszel) was used; and for continuous data, mean difference and 95% confidence intervals were used as measures of treatment effect. For time-to-event data, Peto or inverse variance method was used. Sensitivity and subgroup analysis was planned to test the stability of conclusion. Results: Following initial electronic and hand search, 1690 articles were screened for title and abstract and 82 articles were considered for full-text eligibility. Finally, two studies out of the reported six articles were included in this review for qualitative synthesis of results, and no study was included in the quantitative analysis. Publication bias was determined using funnel plots which were further assessed using dichotomous and continuous outcome. For primary prevention of CVD in participants with periodontitis and metabolic syndrome, one study (165 participants) provided very low certainty evidence. Scaling and root planning plus amoxicillin and metronidazole could reduce incidence of all-cause death (Peto odds ratio [OR] 7.48, 95% confidence interval [CI] 0.15 to 376.98), or all CVD-related death (Peto OR 7.48, 95% CI 0.15 to 376.98). The possibility that scaling and root planning plus amoxicillin and metronidazole could increase cardiovascular events (Peto OR 7.77, 95% CI 1.07 to 56.1) compared with supragingival scaling measured at 12-month follow-up was observed. For secondary prevention of CVD, one pilot study randomised 303 participants to receive scaling and root planning plus oral hygiene instruction or oral hygiene instruction plus a copy of radiographs and recommendation to follow-up with a dentist (community care). As cardiovascular events had been measured for different time periods between 6 and 25 months, and only 37 participants were available with at least one-year follow-up, the data was not sufficiently robust for inclusion in the review. The study did not evaluate all-cause death and all CVD-related death. Conclusions about the effects of periodontal therapy on secondary prevention of CVD were not drawn. Conclusions: There is very limited evidence assessing the impact of periodontal therapy on the prevention of cardiovascular disease, and it is insufficient to generate any implications for practice. Further trials are needed before reliable conclusions can be drawn. © 2023, The Author(s), under exclusive licence to British Dental Association.",TestAnalysis
"Determining gender using offline handwriting is an applied research problem in forensics, psychology and security applications. This task becomes challenging and tedious due to interpersonal and intrapersonal differences in handwriting. This work proposes gender classification from offline handwritten text using a machine learning model, trained on features from the proposed novel dataset, extracted using two Novel Local Binary Pattern-based feature extraction approaches, ALBP (AND Local Binary Pattern) and OLBP (OR Local Binary Pattern). The proposed novel features extend the LBP feature to include the details from 24 neighbouring pixels around the centre pixel. These two features utilize logical operations for distinguishing the two-level neighbouring pixel hierarchy, from the centre pixel, based on their intensity within the specified threshold. The proposed approach, assessed with scientific rigour, extracts the complete and helpful information around a centre pixel. Various techniques, including principal component analysis, cross-validation and holdout validation, are tested to generalize the model better. As a result, Both methods, ALBP and OLBP, show better results, outperform LBP, and achieve the best accuracy of 99% with 15-fold cross-validation for predicting gender from the offline handwritten text. © 2023, The Author(s), under exclusive licence to Bharati Vidyapeeth's Institute of Computer Applications and Management.",TestAnalysis
"PURPOSE: To explore the effect of silicone dressings on the prevention of pressure injuries in patients cared for in the acute care setting. Three main comparisons were explored: silicone dressing versus no dressing, all anatomical areas; silicone dressing versus no dressing on the sacrum; and silicone dressing versus no dressing on the heels. METHODS: Using a systematic review methodology, published randomized controlled trials and cluster randomized controlled trials were included. The search was conducted from December 2020 to January 2021 using CINAHL, full text on EBSCOhost, MEDLINE on EBSCOhost, and Cochrane databases. The search returned 130 studies; 10 met inclusion criteria. Data were extracted using a predesigned extraction tool. The Cochrane Collaboration tool was used to assess the risk of bias and the certainty of the evidence was appraised using a software program specifically designed for this purpose. RESULTS: Silicone dressings probably reduce the incidence of pressure injuries compared to no dressings (relative risk [RR]: 0.40, 95% confidence interval [CI]: 0.31-0.53; moderate certainty evidence). Furthermore, silicone dressings probably reduce the incidence of pressure injuries on the sacrum compared to no dressings (RR: 0.44, 95% CI: 0.31-0.62; moderate certainty evidence). Finally, silicone dressings probably reduce the incidence of pressure injuries on the heels compared to no dressings (RR: 0.44, 95% CI: 0.31-0.62; moderate certainty evidence). CONCLUSION: There is moderate certainty evidence of the effect of silicone dressings as a component of a pressure injury prevention strategy. The main limiting factor in the study designs was a high risk of performance and detection bias. Although this is a challenge to achieve in trials such as these, consideration should be given to how the effect of this could be minimized. A further issue is the lack of head-to-head trials that limits clinicians' abilities to determine whether any of the products in this category are more effective than others. © 2023 Authors. All rights reserved.",TestAnalysis
"Importance The associations between endogenous dehydroepiandrosterone (DHEA) and DHEA sulfate (DHEAS), and depression in older women are uncertain. However, DHEA supplements are widely available over the counter in some countries, and some people may be taking DHEA with the hope of positive mood effects. Objective This systematic review aimed to investigate the association between endogenous DHEA/DHEAS blood concentrations and depression/depressive symptoms in community-dwelling postmenopausal women. Evidence Review: Searches were conducted in Ovid MEDLINE, EMBASE, PsycINFO, and Web of Science databases for observational studies with at least 100 community-dwelling participants until March 9, 2022. The bibliographies of retrieved articles were manually searched. The studies published in English and meeting the inclusion criteria were included in the review. The risk of bias was assessed with the modified Hoy tool for cross-sectional designs and the Joanna Briggs Institute modified critical appraisal checklist for cohort studies. Findings Of the 30 articles retrieved for full-text review, 14 met the criteria for inclusion. Seven studies were cross-sectional, six were longitudinal, and one had both cross-sectional and longitudinal data. Five of eight cross-sectional studies found no association between DHEAS and depression, whereas three studies reported an inverse association. Similarly, most of the studies (n = 4) with longitudinal data reported no association, whereas two studies reported either an inverse association or mixed results for DHEAS and depression severity. No association between DHEA and depression was found irrespective of the study design. Heterogeneity of design was a barrier to meta-analysis and between study comparison. The majority of studies were limited by high risk of bias in at least one assessed domain. Conclusion and Relevance This systematic review does not support an association between endogenous DHEA/DHEAS and depression in postmenopausal women.  © Wolters Kluwer Health, Inc. All rights reserved.",TestAnalysis
"BACKGROUND: Increasing childhood cancer survival rates in recent decades have led to an increased focus on fertility as a long-term complication of cancer treatment. Male childhood cancer survivors often face compromised testicular function as a late effect of chemotherapy exposure, with no well-established options to prevent such damage and subsequent infertility. Despite vincristine being considered to be associated with low-gonadotoxic potential, in prepubertal rodents, it was recently shown to result in morphological alterations of the testis and in severely impaired fertility. OBJECTIVE AND RATIONALE: This systematic review aimed to evaluate the effects of vincristine-containing regimens on human prepubertal testis with reference to testicular function and fertility in adulthood. SEARCH METHODS: The systematic search of the literature was conducted according to PRISMA guidelines, and the study was registered with PROSPERO. PubMed and Scopus were searched for articles published in English between 01 January 1900 and 05 March 2021, with the search including chemotherapy, vincristine, prepubertal, testis, spermatogenesis and related terms. Abstracts and full-text articles were screened and selected for, providing they met the inclusion criteria (12 years at treatment, exposure to vincristinecontaining regimens and long-term fertility outcomes). Additional studies were identified via bibliography screening. Bias evaluation across included studies was conducted using the ROBINS-I tool, subdivided into assessment for confounding, participant selection, intervention classification, missing data, outcome measurements and selection of reported results. OUTCOMES: Our initial search identified 288 articles of which 24 (8%; n 7134 males) met all inclusion criteria. Control groups were included for 9/24 (38%) studies and 4/24 (17%) studies provided sub-analysis of the relative gonadotoxicity of vincristine-based agents. Primary outcome measures were: fertility and parenthood; semen analysis (World Health Organization criteria); and hormonal function and testicular volume. For the studies that performed vincristine sub-analysis, none reported negative associations with vincristine for the potential of siring a pregnancy, including the largest (n 6224; hazard ratio 0.56) controlled study. For semen analysis, no significant difference versus healthy controls was illustrated for mitotic inhibitors (including vincristine) following sub-analysis in one study (n 143). For hormone analysis, a single study did not find significant impacts on spermatogenesis attributed to vincristine based on levels of FSH and semen analysis, which meant that its administration was unlikely to be responsible for the diminished testicular reserve; however, most of the studies were based on low numbers of patients receiving vincristine-containing chemotherapy. Analysis of bias demonstrated that studies which included vincristine exposure sub-analysis had a lower risk of bias when compared with cohorts which did not. WIDER IMPLICATIONS: In contrast to recent findings in rodent studies, the limited number of clinical studies do not indicate gonadotoxic effects of vincristine following prepubertal exposure. However, given the relative lack of data from studies with vincristine subanalysis, experimental studies involving vincristine exposure using human testicular tissues are warranted. Results from such studies could better inform paediatric cancer patients about their future fertility and eligibility for fertility preservation before initiation of treatment. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",TestAnalysis
"The burnout rate among physicians is expected to be higher during COVID-19 period due to the additional sources of physical and emotional stressors. Throughout the current COVID-19 pandemic, numerous studies have evaluated the impacts of COVID-19 on physicians’ burnout, but the reported results have been inconsistent. This current systematic review and meta-analysis aims to assess and estimate the epidemiology of burnout and the associated risk factors during the COVID-19 pandemic among physicians. A systematic search for studies targeting physicians’ burnout was conducted using PubMed, Scopus, ProQuest, Cochrane COVID-19 registry, and pre-print services (PsyArXiv and medRχiv) for English language studies published within the time period of 1 January 2020 to 1 September 2021. Search strategies resulted in 446 possible eligible studies. The titles and abstracts of these studies were screened, which resulted in 34 probable studies for inclusion, while 412 studies were excluded based on the predetermined inclusion criteria. These 34 studies went through a full-text screening for eligibility, which resulted in 30 studies being included in the final reviews and subsequent analyses. Among them, the prevalence of physicians’ burnout rate ranged from 6.0–99.8%. This wide variation could be due to the heterogeneity among burnout definitions, different applied assessment tools, and even cultural factors. Further studies may consider other factors when assessing burnout (e.g., the presence of a psychiatric disorders, other work-related and cultural factors). In conclusion, a consistent diagnostic indices for the assessment of burnout is required to enable consistent methods of scoring and interpretation. © 2023 by the authors.",TestAnalysis
"Road safety is increasingly threatened by distracted driving. Studies have shown that there is a significantly increased risk for a driver of being involved in a car crash due to visual distractions (not watching the road), manual distractions (hands are off the wheel for other non-driving activities), and cognitive and acoustic distractions (the driver is not focused on the driving task). Driving simulators (DSs) are powerful tools for identifying drivers’ responses to different distracting factors in a safe manner. This paper aims to systematically review simulator-based studies to investigate what types of distractions are introduced when using the phone for texting while driving (TWD), what hardware and measures are used to analyze distraction, and what the impact of using mobile devices to read and write messages while driving is on driving performance. The review followed the Preferred Reporting Items for Systematic Reviews and Meta-Analysis extension for Scoping Reviews (PRISMA-ScR) guidelines. A total of 7151 studies were identified in the database search, of which 67 were included in the review, and they were analyzed in order to respond to four research questions. The main findings revealed that TWD distraction has negative effects on driving performance, affecting drivers’ divided attention and concentration, which can lead to potentially life-threatening traffic events. We also provide several recommendations for driving simulators that can ensure high reliability and validity for experiments. This review can serve as a basis for regulators and interested parties to propose restrictions related to using mobile phones in a vehicle and improve road safety. © 2023 by the authors.",TestAnalysis
"Clinical trials frequently include multiple end points that mature at different times. The initial report, typically based on the primary end point, may be published when key planned co-primary or secondary analyses are not yet available. Clinical Trial Updates provide an opportunity to disseminate additional results from studies, published in JCO or elsewhere, for which the primary end point has already been reported.The combined analysis of SOFT-TEXT compared outcomes in 4,690 premenopausal women with estrogen/progesterone receptor-positive (ER/PgR+) early breast cancer randomly assigned to 5 years of exemestane + ovarian function suppression (OFS) versus tamoxifen + OFS. After a median follow-up of 9 years, exemestane + OFS significantly improved disease-free survival (DFS) and distant recurrence-free interval (DRFI), but not overall survival, compared with tamoxifen + OFS. We now report DFS, DRFI, and overall survival after a median follow-up of 13 years. In the intention-to-treat (ITT) population, the 12-year DFS (4.6% absolute improvement, hazard ratio [HR], 0.79; 95% CI, 0.70 to 0.90; P <.001) and DRFI (1.8% absolute improvement, HR, 0.83; 95% CI, 0.70 to 0.98; P =.03), but not overall survival (90.1% v 89.1%, HR, 0.93; 95% CI, 0.78 to 1.11), continued to be significantly improved for patients assigned exemestane + OFS over tamoxifen + OFS. Among patients with human epidermal growth factor receptor 2-negative tumors (86.0% of the ITT population), the absolute improvement in 12-year overall survival with exemestane + OFS was 2.0% (HR, 0.85; 95% CI, 0.70 to 1.04) and 3.3% in those who received chemotherapy (45.9% of the ITT population). Overall survival benefit was clinically significant in high-risk patients, eg, women age < 35 years (4.0%) and those with > 2 cm (4.5%) or grade 3 tumors (5.5%). These sustained reductions of the risk of recurrence with adjuvant exemestane + OFS, compared with tamoxifen + OFS, provide guidance for selecting patients for whom exemestane should be preferred over tamoxifen in the setting of OFS.  © American Society of Clinical Oncology.",TestAnalysis
"The emotion analysis of hotel online reviews is discussed by using the neural network model BERT, which proves that this method can not only help hotel network platforms fully understand customer needs but also help customers find suitable hotels according to their needs and affordability and help hotel recommendations be more intelligent. Therefore, using the pretraining BERT model, a number of emotion analytical experiments were carried out through fine-tuning, and a model with high classification accuracy was obtained by frequently adjusting the parameters during the experiment. The BERT layer was taken as a word vector layer, and the input text sequence was used as the input to the BERT layer for vector transformation. The output vectors of BERT passed through the corresponding neural network and were then classified by the softmax activation function. ERNIE is an enhancement of the BERT layer. Both models can lead to good classification results, but the latter performs better. ERNIE exhibits stronger classification and stability than BERT, which provides a promising research direction for the field of tourism and hotels. Copyright: © 2023 Wen et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"This paper looks at the translation of address terms from the perspective of the pragmatics of fiction and interpersonal pragmatics. It aims to offer some insights into how choices made by translators in this respect affect the presentation of relationships among fictional characters. The analysis focuses on the address terms used between the main characters of Henning Mankell's novel The Dogs of Riga, Kurt Wallander and Baiba Liepa, in the original Swedish version and in its English and Polish translations. The study examines how the relational work done by the characters in the source text (selection of address terms, address terms negotiations, shifts in address use) is recreated in the two translations. The identified dissimilarities are shown to result both from the differences between Swedish, English and Polish address systems, particularly concerning ways of expressing the T-V semantics, and from the translators' interpretation of the relational work done by the characters in the source text. Misinterpretations result in the use of unnatural and contextually inappropriate address forms, which disrupt the interactional coherence of the novel and are inconsistent with the characters' non-verbal behaviour. © 2023 Elsevier B.V.",TestAnalysis
"What are the features of high-quality online courses in higher education? In this scoping review, we explore peer-reviewed scholarship related to the features of online learning in postsecondary contexts. We searched ERIC (EBSCO), Education Research Complete, and SocINDEX with Fulltext to retrieve peer-reviewed literature from 2010-2022 pertaining to features of online learning in higher education. Two reviewers independently conducted the initial title and abstract screening (n = 1,574), full text review (n = 483), and data extraction of the included articles (n = 38). Using thematic content analysis to explore the data extracted from each article, we found that the literature predominately included scholarship related to quality online course design, instructor facilitation in online courses, quality assessment of online courses, and student engagement in online courses. The breadth of these themes included a multiplicity of strategies and approaches to consider when designing online learning experiences. We recommend that administrators, faculty members, and instructors responsible for designing online courses and programs for postsecondary contexts continue to incorporate these considerations to promote high-quality and consistent online offerings. We conclude the review by presenting four high-level considerations to guide these discussions. © 2023, The Online Learning Consortium. All rights reserved.",TestAnalysis
"Food safety is closely related to human health. Therefore, named entity recognition technology is used to extract named entities related to food safety, and building a regulatory knowledge graph in the field of food safety can help relevant authorities to regulate food safety issues and mitigate the hazards caused by food safety problems. However, there is no publicly available named entity recognition dataset in the food safety domain. In contrast, the non-standardized Chinese short texts generated from user comments on the web contain rich implicit information that can help identify named entities in specific domains (e.g., food safety domain) where the corpus is scarce. Therefore, in this paper, named entities related to food safety are extracted from these unstandardized texts on the web. However, the existing Chinese named entity identification methods are mainly for standardized texts. Meanwhile, these unstandardized texts have the following problems: (1) their corpus size is small; (2) there are various new and wrong words and noise; (3) and they do not follow strict syntactic rules. These problems make the recognition of Chinese named entities for online texts more challenging. Therefore, this paper proposes the ERNIE-Adv-BiLSTM-Att-CRF model to improve the recognition of food safety domain entities in unstandardized texts. Specifically, adversarial training is added to the model training as a regularization method to alleviate the influence of noise on the model, while self-attention is added to the BiLSTM-CRF model to capture features that significant impact entity classification and improve the accuracy of entity classification. This paper conducts experiments on the public dataset Weibo NER and the self-built food domain dataset Food. The experimental results show that our model achieves a SOTA performance of 72.64% and a good performance of 69.68% for F1 values on the public and self-built datasets, respectively. The validity and reasonableness of our model are verified. In addition, the paper further analyses the impact of various components and settings on the model. The study has practical implications in the field of food safety. © 2023 by the authors.",TestAnalysis
"The authors have proposed a method of reiterating the statistical analysis of the Nationally Determined Contributions (NDCs) of the UNFCCC Parties, which were updated at Conference of the Parties-26. The present analysis confirms the taxonomy developed in 2020, based on 2475 adaptive solutions recorded in 2022 NDCs, and discusses the differences observed. An ex ante adaptation metric is proposed, which allows monitoring of adaptive solutions over time and comparisons between projects in time and space. The fitness coefficient evaluates the ex ante relevance of these adaptive projects in relation to the climate challenges of each country. The authors have proposed a program of continuous improvement instead of a definitive calculation. The authors have developed an algorithm to automate the text analysis and minimize the subjectivity of the analysis. The objective is to assign a level of vulnerability to each project for each hazard in the country. The correspondence analysis was used to derive the most representative dimensions of project category dispersion and vulnerability intensities from a contingency table for each hazard. This coefficient can be made available to experts, project developers, and funders for ex ante evaluation and selection of candidate projects for funding before more in-depth analyses are carried out. © 2023 by the authors.",TestAnalysis
"Background: Non-fatal burns are a major cause of morbidity, with incidents often occuring at home and at work. Almost all burn cases occur in the WHO region, precisely in African and Southeast Asian countries. Yet, the epidemiology of these injuries, especially in the WHO-defined Southeast Asian Region, has yet to be adequately defined. Method: A scoping review of the literature was performed to identify epidemiology of thermal, chemical, and electrical burns in the WHO-defined Southeast Asian Region. The database search screened 1023 articles in total, of which 83 articles were assessed for eligibility at a full-text level, and 58 of these were excluded. Therefore, 25 fulltext articles were included for data extraction and analysis. Results: Data analysed included demographics, injury details, burn mechanism, total body surface area burned, and in-hospital mortality. Conclusion: Despite the steady increase on burns research, the Southeast Asian region is still limited in terms of burns data. This scoping review has shown that the largest set of articles on burns come from Southeast Asia, indicating the importance of reviewing data at a regional or local level, as global studies tend to be dominated by data from high-income countries. © 2023 MA Healthcare Ltd. All rights reserved.",TestAnalysis
"The concept of axiological-semantic density from Legitimation Code Theory (LCT) is extremely helpful in analysing political knowledge-building, as it describes the strength of relations between various people, political stances and moral judgements, enabling these to be positioned in relation to each other. We present a multi-level translation device designed to identify strengths of axiological-semantic density in political news articles from the Daily Sun, South Africa's most popular tabloid newspaper. This translation device was devised through analysis of selected texts from a corpus of 516 articles published between January and June 2015. It was developed through a collaborative process involving the first author and a team of student research assistants. The final translation device has five tools, of which two, the wording and charging tools, are described in this article, and then illustrated using an example analysis of a Daily Sun political news article. Both tools reveal insights into South African political discourses and ways in which axiological-semantic density can be enacted in future research. Making axiological-semantic density visible using such a translation device also has practical applications in assisting readers to understand the ways in which publications such as the Daily Sun position political parties, enabling them to engage more constructively in discussions on the country's future.  © 2022 Walter de Gruyter GmbH, Berlin/Boston.",TestAnalysis
"This essay offers a corpus-based linguistic analysis of the paratexts of the works of John Pechey (1654–1718), a licentiate physician and prolific medical author and popularizer, whose ideas and practice brought him into conflict with the Royal College of Physicians. Following the methodology of corpus-assisted discourse analysis, historical discourse analysis, and historical sociopragmatics, the essay analyses the paratextual material of Pechey's medical publications, with the aims of (a) collecting a corpus of texts published under his name, (b) assessing his role in the popularization of learned medicine, and (c) tracing how he constructed and performed his identity both as a knowledgeable medical practitioner and as a critic of the beliefs and practices of the Royal College of Physicians. © 2023 British Society for Eighteenth-Century Studies.",TestAnalysis
"BACKGROUND: Surgical randomized controlled trials (RCTs) have potential drawbacks, leading some to question their role in filling the information gap in orthopaedic surgery. Pragmatism in study design was introduced to increase the clinical applicability of study results. The purpose of this study was to examine how pragmatism affects the scholarly influence of surgical RCTs. METHODS: A search for surgical hip fracture-related RCTs published between 1995 and 2015 was done. Journal impact factor, citation number, research question, significance and type of outcome, number of centers involved, and the Pragmatic-Explanatory Continuum Indicator Summary-2 level of pragmatism score were recorded for each study. Scholarly influence was estimated by a study's inclusion into orthopaedic literature or guidelines or through the study's average yearly citation rate. RESULTS: One hundred sixty RCTs were included in the final analysis. A multivariate logistic regression identified large study sample size as the only predictor of an RCT being used in clinical guidance texts. Large sample size and multicenter RCTs were predictors of high yearly citation rates. The level of pragmatism in study design did not predict scholarly influence. CONCLUSIONS: Pragmatic design is not independently associated with increased scholarly influence; however, large study sample size was the most important study characteristic affecting scholarly influence. Copyright © 2023 The Authors. Published by Wolters Kluwer Health, Inc. on behalf of the American Academy of Orthopaedic Surgeons.",TestAnalysis
"Inflammatory bowel disease (IBD) is a complex and multifactorial systemic disorder of the gastrointestinal tract and is strongly associated with the development of colorectal cancer. Despite extensive studies of IBD pathogenesis, the molecular mechanism of colitis-driven tumorigenesis is not yet fully understood. In the current animal-based study, we report a comprehensive bioinformatics analysis of multiple transcriptomics datasets from the colon tissue of mice with acute colitis and colitis-associated cancer (CAC). We performed intersection of differentially expressed genes (DEGs), their functional annotation, reconstruction, and topology analysis of gene association networks, which, when combined with the text mining approach, revealed that a set of key overexpressed genes involved in the regulation of colitis (C3, Tyrobp, Mmp3, Mmp9, Timp1) and CAC (Timp1, Adam8, Mmp7, Mmp13) occupied hub positions within explored colitis- and CAC-related regulomes. Further validation of obtained data in murine models of dextran sulfate sodium (DSS)-induced colitis and azoxymethane/DSS-stimulated CAC fully confirmed the association of revealed hub genes with inflammatory and malignant lesions of colon tissue and demonstrated that genes encoding matrix metalloproteinases (acute colitis: Mmp3, Mmp9; CAC: Mmp7, Mmp13) can be used as a novel prognostic signature for colorectal neoplasia in IBD. Finally, using publicly available transcriptomics data, translational bridge interconnecting of listed colitis/CAC-associated core genes with the pathogenesis of ulcerative colitis, Crohn’s disease, and colorectal cancer in humans was identified. Taken together, a set of key genes playing a core function in colon inflammation and CAC was revealed, which can serve both as promising molecular markers and therapeutic targets to control IBD and IBD-associated colorectal neoplasia. © 2023 by the authors.",TestAnalysis
"The role of the parliamentary arena and members of parliament (MPs) therein for both mainstreaming and cross-sectoral policy integration is largely unknown. Studying the case of Switzerland, this paper analyzes the integration of the biodiversity issue into policies of 20 different policy sectors over a period of 19 years to assess how two specific actor attributes—issue and sector specialization—increase the chances of MPs of engaging in both biodiversity mainstreaming and its cross-sectoral integration. The results based on a comprehensive collection of political documents from the parliamentary arena, and multilevel regression models show that an increase in MPs' sector specialization is associated with both a decrease in mainstreaming and a decrease in cross-sectoral integration activities. By contrast, an increase in issue specialization typically translates into biodiversity-related activity in a larger number of sectors. In the parliamentary arena, therefore, it is primarily a small group of “issue specialists” who take responsibility for the integration of crosscutting issues, such as biodiversity, into critical sectoral policies. © 2023, The Author(s).",TestAnalysis
"Shared electric scooters have recently emerged as an alternative mode of transportation in many cities around the globe. However, they can become a nuisance to residents when they are not well regulated. The approaches to prioritizing laws and regulations of shared electric scooters have not been explored extensively. Therefore, this study presented a multi-criteria approach for prioritizing electric scooter ordinances using Bloomington, Indiana's survey data. The study applied a descriptive analysis, text mining, and logistic regression on 1,891 responses. The responses were based on a questionnaire with 13 predefined ordinances and an additional comment section. The three criteria- the frequency of selection of ordinances, the sequence of selection of ordinances, and the ordinances associated with additional comments were used. Results revealed a great variation in the priorities of the ordinances when the three criteria are used. The frequency of selection criteria would highly favor the ordinance related to enforcing scooter riders to follow traffic laws, while both sequence of selection and additional comments would favor prohibiting scooters from the sidewalks. The policy implications of the multi-criteria and individual criteria are also presented. It is expected that jurisdictions would apply the approach presented in this study and the associated proposed alternatives when prioritizing the ordinances for electric scooters. © 2023 World Conference on Transport Research Society",TestAnalysis
"Lithofacies paleogeography is a data-intensive discipline that involves the interpretation and compilation of sedimentary facies. Traditional sedimentary facies analysis is a labor-intensive task with the added complexity of using unstructured knowledge and unstandardized terminology. Therefore, it is very difficult for beginners or non-geology scholars who lack a systematic knowledge and experience in sedimentary facies analysis. These hurdles could be partly alleviated by having a standardized, structured, and systematic knowledge base coupled with an efficient automatic machine-assisted sedimentary facies identification system. To this end, this study constructed a knowledge system for fluvial facies and carried out knowledge representation. Components include a domain knowledge graph for types of fluvial facies (meandering, braided and other fluvial depositional environments) and their characteristic features (bedforms, grain size distribution, etc.) with visualization, a method for query and retrieval on a graph database platform, a hierarchical knowledge tree-structure, a data-mining clustering algorithm for machine-analysis of publication texts, and an algorithm model for this area of sedimentary facies reasoning. The underlying sedimentary facies identification and knowledge reasoning system is based on expert experience and synthesis of publications. For testing, 17 sets literature publications data that included details of sedimentary facies data (bedforms, grain sizes, etc.) were submitted to the artificial intelligence model, then compared and validated. This testing set of automated reasoning results yielded an interpretation accuracy of about 90% relative to the published interpretations in those papers. Therefore, the model and algorithm provide an efficient and automated reasoning technology, which provides a new approach and route for the rapid and intelligent identification of other types of sedimentary facies from literature data or direct use in the field. © 2022 China University of Geosciences (Beijing) and Peking University",TestAnalysis
"Language models have proved to achieve high performances and outperform state of the art results in the Natural Language Processing field. More specifically, Bidirectional Encoder Representations from Transformers (BERT) has become the state of the art model for such tasks. Most of the available language models have been trained on Indo-European languages. These models are known to require huge training datasets. However, only a few studies have focused on under-represented languages and dialects. In this work, we describe the pretraining of a customized Google BERT Tensorflow implementation model (named TunBERT-T) and the pretraining of a PyTorch implementation of BERT language model using NVIDIA implementation (named TunBERT-P) for the Tunisian dialect. We describe the process of creating a training dataset from collecting a Common-Crawl-based dataset, filtering and pre-processing the data. We describe the training setup and we detail fine-tuning TunBERT-T and TunBERT-P models on three NLP downstream tasks. We challenge the assumption that a lot of training data is needed. We explore the effectiveness of training a monolingual Transformer-based language model for low-resourced languages, taking the Tunisian dialect as a use case. Our models results indicate that a proportionately small sized Common-Crawl-based dataset (500K sentences, 67.2MB) leads to comparable performances as those obtained using costly larger datasets (from 24GB to 128GB of text). We demonstrate that with the use of newly created datasets, our proposed TunBERT-P model achieves comparable or higher performances in three downstream tasks: Sentiment Analysis, Language Identification and Reading Comprehension Question-Answering. We release the two pretrained models along with all the datasets used for the fine-tuning. © 2023, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd.",TestAnalysis
"Background: Accident and Emergency Department (AED) is the frontline of providing emergency care in a hospital and research focusing on improving decision-makings and service level around AED has been driving a rising number of attentions in recent years. A retrospective review among the published papers shows that related research can be classified according to six planning modules: demand forecasting, days-off scheduling, shift scheduling, line-of-work construction, task assignment and staff assignment. As patient arrivals demand forecasts enable smooth AED operational planning and help decision-making, this article conducted a systematic review on the statistical modelling approaches aimed at predicting the volume of AED patients’ arrival. Methods: We carried out a systematic review of AED patient arrivals prediction studies from 2004 to 2021. The Medline, ScienceDirect, and Scopus databases were searched. A two-step screening process was carried out based on the title and abstract or full text, and 35 of 1,677 articles were selected. Our methods and results follow the preferred reporting items for systematic reviews and meta-analyses (PRISMA) guidelines. We categorise AED methods for modelling patient arrivals into four main classes: regression, time series, artificial intelligence and time series regression. Choice of prediction model, selection of factors and model performance are compared. Finally, we discuss the advantages and limitations of the models and suggest future research directions. Results: A total of 1,677 papers that fulfilled the initial searching criteria was obtained from the three databases. Based on the first exclusion criteria, 1,603 articles were eliminated. The remaining 74 full text articles were evaluated based on the second exclusion criteria. Finally, 35 articles were selected for full review. We find that the use of artificial intelligence-based model has risen in recent years, from the view of predictive model selection. The calendar-based factors are most commonly used compared with other types of dependent variables, from the view of dependent variable selection. Conclusions: All AEDs are inherently different and different covariables may have different effects on patient arrivals. Certain factors may play a key role in one AED but not others. Based on results of meta-analysis, when modelling patient arrivals, it is essential to understand the actual AED situation and carefully select relevant dominating factors and the most suitable modelling method. Local calibration is also important to ensure good estimates. © Quantitative Imaging in Medicine and Surgery. All rights reserved.",TestAnalysis
"Muslims in the U.K. who maintain their religious culture are often viewed as a suspect community. This pre-registered experimental research examined the mediating role of perceived (dis)loyalty as underlying process and the moderating role of acculturation expectations. A total of 334 non-Muslim White British participants in Study 1 and 810 in Study 2 were asked to indicate their acculturation expectations towards Muslims. They were then randomly assigned to read a text that described Muslims in a fictional town as either (a) maintaining their religious culture or (b) adopting the mainstream British culture, or they read (c) a neutral control text. As expected, in Study 1, when Muslims were presented as maintaining their religious culture, trust decreased compared to the control group. Conversely, when described as adopting the mainstream culture, trust increased while support for surveillance of Muslims decreased. Both effects were mediated by the perception of Muslims being disloyal or loyal to the U.K in both studies, respectively. Perceived loyalty to their religious group did not significantly mediate any effect. We replicated these findings in Study 2. Moreover, we showed that describing Muslims as maintaining their religious culture decreased trust and increased support for surveillance especially among participants who expected Muslims to give up their religious culture. Moderated mediation analysis showed that these effects were partly mediated by perceived loyalty to the U.K. We discuss the societal implications of the findings for policymakers and Muslim leaders along with recommendations for future research. © 2023",TestAnalysis
"Introduction: Dapagliflozin, a new treatment option for heart failure, leads to a significant reduction in the hospitalization of patients with heart failure. We aimed to review studies on the economic evaluation of adding dapagliflozin to standard care compared with standard care alone in heart failure patients with reduced ejection fraction (HFrEF). Methods: For this systematic review, the PubMed, EMBASE, Web of Science, Cochrane, Scopus, and CEA Registry scientific databases were searched from 1 January 2020 to 25 March 2022. Two of the present researchers screened titles and abstracts, extracted data from full-text articles, and evaluated their quality using the Quality of Health Economic Studies (QHES) checklist for the quality assessment of health economic studies. Results: Of the 456 abstracts screened, 19 studies met the inclusion criteria. The mean QHES score for the studies was 0.87 (high quality). Eight studies on cost-effectiveness analysis, ten studies on cost-utility analysis, and one study on cost-minimization analysis were conducted. Based on the available evidence and the present findings, the addition of dapagliflozin to standard care in patients with HFrEF was cost effective in most countries. Conclusions: Based on the results of the present study, the addition of dapagliflozin to standard care in patients with HFrEF was cost effective. More studies investigating the cost effectiveness of dapagliflozin in patients with HFrEF are required in light of the actual epidemiological data of countries in the relevant input parameters. It is also recommended to conduct cost-effectiveness studies of dapagliflozin taking into account costs and benefits from a societal perspective. © 2023, The Author(s), under exclusive licence to Springer Nature Switzerland AG.",TestAnalysis
"The gastronomy of a destination can be a competitive advantage, but there is no study on how the gastronomy of Málaga is perceived. Therefore, the present study has tried to resolve this lack of information in order to contribute to the future development of strategies. A database of 1228 user-generated comments was compiled with the opinions of tourists. After the application of content analysis software, frequent topics and concepts, thematic clusters, text characteristics and positive and negative areas of the text were identified, as well as attributes that have practical implications for companies in the sector. The results show the concepts associated to our gastronomy, highlighting attributes such as the freshness of the food and its flavor and quality. Additionally, it was found that favorable opinions were mainly related to the food, while negative ones were related to the service. © 2023 Elsevier B.V.",TestAnalysis
"Objective: Cognitive measures are an important primary outcome of pediatric, adolescents, and childhood epilepsy surgery. The purpose of this systematic review and meta-analysis is to assess whether there are long-term alterations (≥ 5 years) in the Full-Scale Intelligence Quotient (FSIQ) of pediatric patients undergoing epilepsy surgery. Methods: Electronic databases (EMBASE, MEDLINE, and Scopus) were searched for English articles from inception to October 2022 that examined intelligence outcomes in pediatric epilepsy surgery patients. Inclusion criteria were defined as the patient sample size of ≥ 5, average follow- up of ≥5 years, and surgeries performed on individuals ≤ 18 years old at the time of surgery. Exclusion criteria consisted of palliative surgery, animal studies, and studies not reporting surgical or FSIQ outcomes. Publication bias was assessed using a funnel plot and the Quality in Prognosis Studies (QUIPS) toolset was used for quality appraisal of the selected articles. A random-effects network meta-analysis was performed to compare FSIQ between surgical patients at baseline and follow-up and Mean Difference (MD) was used to calculate the effect size of each study. Point estimates for effects and 95% confidence intervals for moderation analysis were performed on variables putatively associated with the effect size. Results: 21,408 studies were screened for abstract and title. Of these, 797 fit our inclusion and exclusion criteria and proceeded to full-text screening. Overall, seven studies met our requirements and were selected. Quantitative analysis was performed on these studies (N = 330). The mean long-term difference between pre- and post- operative FSIQ scores across all studies was noted at 3.36 [95% CI: (0.14, 6.57), p = 0.04, I2 = 0%] and heterogeneity was low. Conclusion: To our knowledge, this is the first meta-analysis to measure the long-term impacts of FSIQ in pediatric and adolescent epilepsy patients. Our overall results in this meta-analysis indicate that while most studies do not show long-term FSIQ deterioration in pediatric patients who underwent epilepsy surgery, there was an increase of 3.36 FSIQ points, however, the observed changes were not clinically significant. Moreover, at the individual patient level analysis, while most children did not show long-term FSIQ deterioration, few had significant decline. These findings indicate the importance of surgery as a viable option for pediatric patients with medically refractory epilepsy. © 2023",TestAnalysis
"This study examines the Korean translations of a Japanese work Joshi no rongo [/Women's Analects] (Yuki, Ako . 2011. Tokyo: Sunmark Publishing House), a modern interpretation of the Chinese classic The Analects, with a view to identifying how the paratexts of a translated text contributed, or hindered the reception of the work in the target culture. By drawing on Gérard Genette's (1997 [1987]. Paratexts: Threshold of interpretation, Jane E. Lewin (trans.). Cambridge: Cambridge University Press) concept of ""paratexts,""this study both analyses translation shifts in the peritexts (e.g., cover, foreword, table of contents) and the epitexts (reviews) of the Korean translations. The analysis shows that the additions and rearrangements of some paratextual elements in the Korean translation further reinforced the traditional view presented in the source text, which ironically brought about heavy criticisms of the original Japanese text and resulted in the Korean retranslation of the work. The scrutiny of peritexts and epitexts in this article will enhance our understanding of the interactions between the translator, the publisher, and the public readers, which jointly contextualize the production and reception of a translated work in a given culture.  © 2023 Walter de Gruyter GmbH, Berlin/Boston.",TestAnalysis
"In this paper, I try to expatiate on the poetic function of language on the basis of considerations by Jakobson and Waugh. I try to bring in the consideration that pragmatics plays an important role in elucidating the poetic function of language. Contextualism allows us to interpret a poem: referents must be fixed or need not be fixed due to the requirements of the discourse; citations are brought in through pragmatic ways; polyphony is achieved by taking into account the context of previous analyses of a poetic text; the vicinity of a certain word, or concept or line is likely to affect the interpretation of a certain expression; the poetic text can take different forms, from graffiti to discourse at the market place, to discourse between lovers. All these forms of poetic text would not exist if the notion of poetry did not include the idea of semantic/pragmatic compression which is matched, in interpretation, by expansions.  © 2023 Walter de Gruyter GmbH, Berlin/Boston.",TestAnalysis
"The use of transformer-based language models in artificial intelligence (AI) has increased adoption in various industries and led to significant productivity advancements in business operations. This article explores how these models can be used to augment human innovation teams in the new product development process, allowing for larger problem and solution spaces to be explored and ultimately leading to higher innovation performance. The article proposes the use of the AI-augmented double diamond framework to structure the exploration of how these models can assist in new product development (NPD) tasks, such as text summarization, sentiment analysis, and idea generation. It also discusses the limitations of the technology and the potential impact of AI on established practices in NPD. The article establishes a research agenda for exploring the use of language models in this area and the role of humans in hybrid innovation teams. (Note: Following the idea of this article, GPT-3 alone generated this abstract. Only minor formatting edits were performed by humans.). © 2023 The Authors. Journal of Product Innovation Management published by Wiley Periodicals LLC on behalf of Product Development & Management Association.",TestAnalysis
"Context: Execution logs capture the run-time behavior of software systems. To assist developers in their maintenance tasks, many studies have proposed tools to analyze execution information from logs. However, it is as yet unknown how industry developers use logs in embedded software engineering. Objective: In this study, we aim to understand how developers use logs in an embedded software engineering context. Specifically, we would like to gain insights into the type of logs developers analyze, the purposes for which developers analyze logs, the information developers need from logs and their expectation on tool support. Method: In order to achieve the aim, we conducted these interview studies. First, we interviewed 25 software developers from ASML, which is a leading company in developing lithography machines. This exploratory case study provides the preliminary findings. Next, we validated and refined our findings by conducting a replication study. We involved 14 interviewees from four companies who have different software engineering roles in their daily work. Results: As the result of our first study, we compile a preliminary taxonomy which consists of four types of logs used by developers in practice, 18 purposes of using logs, 13 types of information developers search in logs, 13 challenges faced by developers in log analysis and three suggestions for tool support provided by developers. This taxonomy is refined in the replication study with three additional purposes, one additional information need, four additional challenges and three additional suggestions of tool support. In addition, with these two studies, we observed that text-based editors and self-made scripts are commonly used when it comes to tooling in log analysis practice. As indicated by the interviewees, the development of automatic analysis tools is hindered by the quality of the logs, which further suggests several challenges in log instrumentation and management. Conclusions: Based on our study, we provide suggestions for practitioners on logging practices. We provide implications for tool builders on how to further improve tools based on existing techniques. Finally, we suggest some research directions and studies for researchers to further study software logging. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"Recently, social media data have been leveraged for product defect discovery. But the considerable number of defects reflected via social media inhibits manufacturers from solving product defects promptly. Extant studies focus on identifying defect-relevant texts and then deriving defects discussed in texts. They omit to assess the importance of discovered defects and find the defects with high priorities. In this study, we first developed a topic model named Defect Analysis Model (DAM) to discover product defects from defect-related texts, which are identified by the integrated BERT and Random Forest. Then we propose the Two-Phased Quality Function Deployment for Defect (TPQFDD) to prioritize discovered product defects. With the consideration of defect frequencies and defect costs, TPQFDD evaluates the importance of defective components, defects, and defect causes for more inspired managerial insights. We compare our approaches with baseline approaches using an online thread dataset of automobiles. Comparison results prove that our methods effectively detect and prioritize product defects that occurred in the aftersales stage. © 2023 Elsevier Ltd",TestAnalysis
"Objective Temporal bone mucosal melanomas (MMs) are rare, and patients may experience delays in diagnosis and treatment. Our objective was to better characterize the presentation, diagnosis, treatment modalities, and outcomes of this process. Data Sources PubMed/Medline, CINAHL (EBSCOhost), and Web of Science databases were searched in all languages without restriction of publication dates. Study Selection Inclusion criteria included that the article was either a case report or a case series with individual case data. All non-English articles were excluded if the corresponding abstract lacked data on demographics, initial presentation, and clinical management. Data Extraction After full-text analysis, data pertaining to demographics, diagnosis, medical and surgical management modalities, and outcomes were extracted. Data Synthesis Data were qualitatively synthesized, and means and averages were obtained for all continuous variables. Overall survival was measured by the Kaplan-Meier method, and significance was measured through log-rank testing. Conclusions Clinicians should suspect temporal bone MM in the differential diagnosis of patients with bloody otorrhea in the context of a chronic serous otitis media or an associated cranial nerve palsy. If suspected, physicians should not delay the acquisition of a biopsy or imaging studies. Management is highly variable and must be decided on a case-by-case basis. Outcomes remain poor because of the high propensity for MM to metastasize.  © Wolters Kluwer Health, Inc. All rights reserved.",TestAnalysis
"Text classification (TC) is a crucial subject. The number of digital files available on the internet is enormous. The goal of TC is to categorize texts into a series of predetermined groups. The number of studies conducted on the English database is significantly higher than the number of studies conducted on the Arabic database. Therefore, this research analyzes the performance of automatic TC of the Arabic language using Machine Learning (ML) approaches. Further, Single-label Arabic News Articles Datasets (SANAD) are introduced, which contain three different datasets, namely Akhbarona, Khaleej, and Arabiya. Initially, the collected texts are pre-processed in which tokenization and stemming occur. In this research, three kinds of stemming are employed, namely light stemming, Khoja stemming, and nostemming, to evaluate the effect of the pre-processing technique on Arabic TC performance. Moreover, feature extraction and feature weighting are performed; in feature weighting, the term weighting process is completed by the term frequencyinverse document frequency (tf-idf) method. In addition, this research selects C4.5, Support Vector Machine (SVM), and Naïve Bayes (NB) as a classification algorithm. The results indicated that the SVM and NB methods had attained higher accuracy than the C4.5 method. NB achieved the maximum accuracy with a performance of 99.9%. © 2023 NSP Natural Sciences Publishing Cor.",TestAnalysis
"Blockchain and immersive technology are the pioneers in bringing digitalization to tourism, and researchers worldwide are exploring many facets of these techniques. This paper analyzes the various aspects of blockchain technology and its potential use in tourism. We explore high-frequency keywords, perform network analysis of relevant publications to analyze patterns, and introduce machine learning techniques to facilitate systematic reviews. We focused on 94 publications from Web Science that dealt with blockchain implementation in tourism from 2017 to 2022. We used Vosviewer for network analysis and artificial intelligence models with the help of machine learning tools to predict the relevance of the work. Many reviewed articles mainly deal with blockchain in tourism and related terms such as smart tourism and crypto tourism. This study is the first attempt to use text analysis to improve the topic modeling of blockchain in tourism. It comprehensively analyzes the technology’s potential use in the hospitality, accommodation, and booking industry. In this context, the paper provides significant value to researchers by giving an insight into the trends and keyword patterns. Tourism still has many unexplored areas; journal articles should also feature special studies on this topic. © 2023 by the authors. Licensee MDPI, Basel, Switzerland.",TestAnalysis
"High-Dimensional Processing is the idea that mind register illustrations of neural activities which are not immediately related with numbers. The objective of the article is hyper-dimensional computation of data for categorization of text from two distinct speech datasets, namely the Arabic Corpus dataset and the MediaSpeech dataset with four languages (Arabic, Spanish, French, and Turkish). Through the use of an n-gram encoding scheme, hyper dimensional computing is used to conduct the analysis from the prior set of data. Using hyper dimensional computing, the MediaSpeech dataset accomplishes 100% accuracy for all 4-gram to 14-gram encoding schemes, while the Arabic Corpus dataset accomplishes 100% accuracy for 4-gram to 7-gram encoding schemes. © 2023 NSP Natural Sciences Publishing Cor.",TestAnalysis
"Tusher, HM, Nazir, S, Mallam, S, Rusli, R, Botnmark, AK. Learning from accidents: Nontechnical skills deficiency in the European process industry. Process Saf. Prog. 2022;41(S1):S4-S9. doi:10.1002/prs.12344 In the above article, the credits for the corresponding author Salman Nazir were inadvertently missed in the article's Author Contributions section. The correct text should read along with, “Salman Nazir: Conceptualization (equal); formal analysis (equal); funding acquisition (lead); investigation (equal); methodology (equal); project administration (lead); resources (lead); supervision (equal); validation (equal); writing—original draft (supporting); writing—review and editing (equal).” We apologize for this error. © 2023 American Institute of Chemical Engineers.",TestAnalysis
"This paper examines the controversy that followed the 1987 publication of Joseph Greenberg's book, Language in the Americas, attending to the role of language and linguistic research within overlapping disciplinary traditions. With this text, Greenberg presented a macro-level tripartite classification that opposed then dominant fine-grained analyses recognizing anywhere from 150 to 200 distinct language families. His proposal was the subject of a landmark conference, examining strengths and weaknesses, the unpublished proceedings of which are presented here for the first time. For specialists in the anthropological and comparative-historical study of Indigenous American languages, Greenberg's intervention highlighted the tension between language, conceived as an abstract object of study, and languages, understood to be carriers of specific cultural knowledge. For physical anthropologists and archaeologists, his theory was initially fortuitous on programmatic, substantive, and methodological grounds. The essay will show how interdisciplinary appeals were figured by supporters as a virtue, and by critics as a vice. The essay further highlights ethical reasons for integrating historical narratives of science and the humanities. © 2023 Wiley-VCH GmbH.",TestAnalysis
"International regimes contain norm bundles with several distinct norms that jointly define what is expected from parties. As states engage with these regime-inherent norms, they attribute meanings to them. Moreover, they can also translate norms extraneous to the regime. Here we take a theoretical middle ground between full-fledged norm adoption and approaches that emphasize the novelty of each translation. We argue that norm translations may be largely shared among states with similar domestic contexts. This includes individual translations of norms as well as prioritizations between them. Empirically, we focus on the United Nations Framework Convention on Climate Change (UNFCCC) by applying unsupervised quantitative text analysis (topic modeling) to the Nationally Determined Contributions (NDCs) submitted around the 2015 Paris conference. Studying these implementation pledges, we find that states have mostly engaged in regime-inherent norm translations, indicating normative stability of the regime. This occurred in distinct forms, such as by translating mitigation responsibilities in the form of absolute or relative emission reduction targets. We find hints that norm translations indeed vary in line with states’ domestic context factors: Beyond broad differences between industrialized and developing countries, we show the relevance of factors like vulnerability to climate change and emissions levels. © 2023, Springer Nature Limited.",TestAnalysis
"Poor intrinsic thermal conductivity (TC) of beta-phase gallium oxide ( β -Ga2O3) poses challenges to the thermal management of its devices. Various packaging-level cooling strategies have been proposed, demonstrating great thermal benefits. In addition, much attention has been paid to the device-level cooling methods, which have shown remarkable efficiency for the thermal management of many wide and ultrawide bandgap devices. As the device-level thermal management efficiency is highly associated with the device architecture, deep insight into the device architecture effect is highly warranted. Here, we used numerical simulation method to conduct the device-level thermal analysis on β -Ga2O3 MESFETs. The impacts of various device components on channel temperature are comprehensively investigated, such as metal geometry, layout alignment, thickness, and orientation-dependent β -Ga2O3 TCs, and the thermal boundary resistance (TBR) between metal and β -Ga2O3. We show that increasing the gate length from 0.5 to 1.5 μ achieves a 35 K reduction in maximum channel temperature, equivalent to optimizing the device's substrate TC from 100 to 2000 W/mK. Furthermore, properly designing the layout alignment on the 3-D anisotropic β -Ga2O3 substrate could also benefit the thermal dissipation. Particularly, aligning the gate length to the direction at which β -Ga2O3 has the highest and lowest in-plane TC could render ∼ 60 K difference in maximum channel temperature. Overall, we analyzed the efficiency of various device-level cooling strategies for the β -Ga2O3 device, suggesting a thermal design route by designing device architecture.  © 1963-2012 IEEE.",TestAnalysis
"Background and Hypothesis: Disturbances in self-experience are a central feature of schizophrenia and its study can enhance phenomenological understanding and inform mechanisms underlying clinical symptoms. Self-experience involves the sense of self-presence, of being the subject of one's own experiences and agent of one's own actions, and of being distinct from others. Self-experience is traditionally assessed by manual rating of interviews; however, natural language processing (NLP) offers automated approach that can augment manual ratings by rapid and reliable analysis of text. Study Design: We elicited autobiographical narratives from 167 patients with schizophrenia or schizoaffective disorder (SZ) and 90 healthy controls (HC), amounting to 490 000 words and 26 000 sentences. We used NLP techniques to examine transcripts for language related to self-experience, machine learning to validate group differences in language, and canonical correlation analysis to examine the relationship between language and symptoms. Study Results: Topics related to self-experience and agency emerged as significantly more expressed in SZ than HC (P < 10-13) and were decoupled from similarly emerging features such as emotional tone, semantic coherence, and concepts related to burden. Further validation on hold-out data showed that a classifier trained on these features achieved patient-control discrimination with AUC = 0.80 (P < 10-5). Canonical correlation analysis revealed significant relationships between self-experience and agency language features and clinical symptoms. Conclusions: Notably, the self-experience and agency topics emerged without any explicit probing by the interviewer and can be algorithmically detected even though they involve higher-order metacognitive processes. These findings illustrate the utility of NLP methods to examine phenomenological aspects of schizophrenia. © 2022 The Author(s).",TestAnalysis
"This article presents an unprecedented analysis of the Islamic State of Iraq and Syria (ISIS) primary school physical education curriculum focused on calligraphy and illustrations. Indeed, this research concentrated on describing, analyzing and understanding the context and the philosophy of the document, as well as its illustrations (Islamic calligraphy, pictures, among others). Semiotic and iconographic methods were used to conduct analyses of the data. Findings show several attempts to divert the meaning of the Muslim religion, notably through an ultra-rigorist vision and a total absence of girls or women. Our analyses lead us to believe that this curriculum, addressed mainly to the physical education teacher, was developed by ISIS as a preamble to the military preparation of future soldiers. Finally, the Islamic calligraphy used in the curriculum raises questions about the choice of type of calligraphy as well as its relevance within the context of an incomplete and rapidly developed document. This study provides a deeper understanding of the educational system set up by ISIS and its body of disciplinary texts. © 2023 Elsevier Ltd",TestAnalysis
"The recognition of symbols within document images is one of the most relevant steps involved in the Document Analysis field. While current state-of-the-art methods based on Deep Learning are capable of adequately performing this task, they generally require a vast amount of data that has to be manually labeled. In this paper, we propose a self-supervised learning-based method that addresses this task by training a neural-based feature extractor with a set of unlabeled documents and performs the recognition task considering just a few reference samples. Experiments on different corpora comprising music, text, and symbol documents report that the proposal is capable of adequately tackling the task with high accuracy rates of up to 95% in few-shot settings. Moreover, results show that the presented strategy outperforms the base supervised learning approaches trained with the same amount of data that, in some cases, even fail to converge. This approach, hence, stands as a lightweight alternative to deal with symbol classification with few annotated data. © 2023 The Author(s)",TestAnalysis
"The video-centered platform, TikTok, has gained popularity due to its position as an entertainment app, but it is still underexplored as a tool that generates awareness and discussions about mental health. This article explores TikTok's data-point ranking system to analyze how mental health rhetoric is shaped and how public health communities are formed around the term anxiety. Through a multimodal discourse analysis of the top 10 TikTok videos using the hashtag, #anxiety, this article seeks to establish how discussions of anxiety disorders are facilitated through the use of TikTok's socio-technical features and affordances of visibility, editability, persistence, and association in order to build digital communities of support. I identify recurring themes in users’ narrations of anxiety by studying in-frame content that creates meaning and contextual messages about mental health. Ultimately, these multimodal expressions of anxiety allow users to intervene and discuss often serious topics related to mental health through video, text, images, and sounds that other users can relate to and recognize. These features and affordances create networks of community and attract conversation where others can share their experiences and practices. © 2023",TestAnalysis
"Due to the 2019 new coronavirus disease (COVID-19) pandemic, tourism is undergoing fundamental changes that are affecting tourism research. This situation calls for in-depth analyses of tourism research. Scholars have already published review studies on COVID-19-related research within the tourism field; however, these studies do not connect findings, such as the research focus, research methodology and target group, to form a research profile, and the geographical patterns of the findings are not identified. study, COVID-19-related tourism studies were collected and analyzed in depth following the Preferred Reporting Items for systematic reviews and meta-analyses (PRISMA) method. In addition, data-driven methods, such as spatial multilayer networks, frequent patterns and content-based analyses, were applied to identify research profiles and their geographic patterns. This study pointed out the role of geographic patterns in tourism research, going beyond the research of the authors. Moreover, topics, focus destinations, applied methodologies and employed data sources have relevant geographic patterns. Four dominant research profiles that show that a shift can be observed in tourism research toward data sources and research methods were identified. Due to COVID-19, the strengthening of the application of quantitative methods and employment of secondary data sources are needed. © 2023, The Author(s).",TestAnalysis
"Introduction: The objective of this systematic review is to describe polysubstance studies and their prevalence estimates among pregnant people in the US. Methods: This review was not subject to protocol preparation or registration with the International Prospective Register of Systematic Reviews (PROSPERO) because outcome data were not reported. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) Checklist was followed. Four scientific literature databases were used to identify articles published from January 1, 2009 to June 3, 2020 reporting prenatal exposure to two or more substances in the US. A standardized process of title and abstract screening followed by a two-phase full-text review was used to assess study eligibility. Results: A total of 119 studies were included: 7 case–control studies, 7 clinical trials, 76 cohort studies, and 29 cross-sectional studies. Studies varied with respect to study design, time period, region, sampling and participant selection, substances assessed, and method of exposure ascertainment. Commonly reported polysubstance prevalence estimates among studies of pregnant people included combinations with alcohol, marijuana, and/or tobacco/nicotine. The range of prevalence estimates was wide (alcohol 1–99%; marijuana 3–95%; tobacco/nicotine 2–95%). Discussion: Polysubstance use during pregnancy is common, especially with alcohol, marijuana, and/or tobacco/nicotine. Future research to assess polysubstance use during pregnancy could help better describe patterns and ultimately help mitigate its effects on maternal and infant health outcomes. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"Brazil has recently been experiencing a phenomenon of political polarization: a conflict involving political views and social identities. Considering the extent to which this socially constructed conflict has been partially fueled by the media, we propose to use the Social Representations Theory. The present study explores how discourses in the mainstream media construct the political polarization taking place in Brazil. The topics covered in 82 texts published between January 2015 and August 2019 in Brazilian mainstream press, Folha da S. Paulo and Estado de S. Paulo, were examined using content analysis and Reinert's method with IRaMuTeQ software. A descending hierarchical analysis divided the corpus into four classes, and content analysis showed that both daily newspapers strongly criticized the political polarization underway, which was anchored to and objectified through episodes of violence, and they supported the valorization of democracy. © 2022 Walter de Gruyter GmbH, Berlin/Boston.",TestAnalysis
"Translocations are an important conservation tool that enable the restoration of species and their ecological functions. They are particularly important during the current environmental crisis. We used a combination of text-analysis tools to track the history and evolution of the peer-reviewed scientific literature on animal translocation science. We compared this corpus with research showcased in the IUCNs Global Conservation Translocation Perspectives, a curated collection of non-peer-reviewed reintroduction case studies. We show that the peer-reviewed literature, in its infancy, was dominated by charismatic species. It then grew in two classical threads: management of the species of concern and management of the environment of the species. The peer-reviewed literature exhibits a bias towards large charismatic mammals, and while these data are invaluable, expansion to under-represented groups such as insects and reptiles will be critical to combating biodiversity loss across taxonomic groups. These biases were similar in the Translocation Perspectives, but with some subtle differences. To ensure translocation science can address global issues, we need to overcome barriers that restrict this research to a limited number of countries. © 2023 The Authors. Ecography published by John Wiley & Sons Ltd on behalf of Nordic Society Oikos.",TestAnalysis
"Learning and understanding customer needs is one of the business strategies that will help build long-term customer relationships. This research has analyzed customer opinions compared to hotel features, and allowed the hoteliers to use this information to develop and improve their business to meet the needs of their guests. This research proposed: 1) compilation of English comments from the website, 2) word segmentation process consists of labeling the types of words using the Penn Treebank Target and extracting the types of words that are important to the analysis as follows: verbs, adjectives, and adverbs to be processed, 3) the customer feedback analysis process is used to identify the feedback poles of each feature, 4) extracting the hotel description, and 5) feature matching between hotel description and prediction result. It uses to check the consistency between the customer reviews and hotel strengths. The results showed that the efficacy of the analysis of hotel guest reviews with the highest and average F-measure values were 0.83 and 0.56, respectively. ICIC International ©2023.",TestAnalysis
"Objective: Outpatient no-shows have important implications for costs and the quality of care. Predictive models of no-shows could be used to target intervention delivery to reduce no-shows. We reviewed the effectiveness of predictive model-based interventions on outpatient no-shows, intervention costs, acceptability, and equity. Materials and Methods: Rapid systematic review of randomized controlled trials (RCTs) and non-RCTs. We searched Medline, Cochrane CENTRAL, Embase, IEEE Xplore, and Clinical Trial Registries on March 30, 2022 (updated on July 8, 2022). Two reviewers extracted outcome data and assessed the risk of bias using ROB 2, ROBINS-I, and confidence in the evidence using GRADE. We calculated risk ratios (RRs) for the relationship between the intervention and no-show rates (primary outcome), compared with usual appointment scheduling. Meta-Analysis was not possible due to heterogeneity. Results: We included 7 RCTs and 1 non-RCT, in dermatology (n = 2), outpatient primary care (n = 2), endoscopy, oncology, mental health, pneumology, and an magnetic resonance imaging clinic. There was high certainty evidence that predictive model-based text message reminders reduced no-shows (1 RCT, median RR 0.91, interquartile range [IQR] 0.90, 0.92). There was moderate certainty evidence that predictive model-based phone call reminders (3 RCTs, median RR 0.61, IQR 0.49, 0.68) and patient navigators reduced no-shows (1 RCT, RR 0.55, 95% confidence interval 0.46, 0.67). The effect of predictive model-based overbooking was uncertain. Limited information was reported on cost-effectiveness, acceptability, and equity. Discussion and Conclusions: Predictive modeling plus text message reminders, phone call reminders, and patient navigator calls are probably effective at reducing no-shows. Further research is needed on the comparative effectiveness of predictive model-based interventions addressed to patients at high risk of no-shows versus nontargeted interventions addressed to all patients.  © 2022 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association.",TestAnalysis
"Introduction: Optimising clinical education in radiography is crucial to ensure competent graduates provide safe and effective patient care. Radiographers play a vital role in student supervision undertaken in the complex clinical environment. A greater understanding of factors influencing their ability to undertake this role effectively is needed. The study aimed to explore radiographers' attitudes and perceptions of confidence in undertaking clinical supervision and perceived barriers in a ‘real-life’ clinical department. Methods: The lens of Bandura's social-cognitive theory was utilised to assist the exploration of the desired constructs. An anonymous online survey was developed and circulated among qualified radiographers in Ireland. Descriptive (frequencies and percentages) and inferential statistical testing was undertaken. Thematic analysis was conducted on optional free-text comments. Results: 217 responses were received. Although most radiographers reported a positive attitude (73.3%), a significant minority reported not being confident across survey items related to the tasks required (ranging from 20.7%–29.1%). Time pressures from clinical workload, perceived lack of organisational support, and lack of guidance on expectations were highlighted challenges. Conclusion: The survey has enabled first-hand identification of some challenges radiographers encounter in undertaking students' clinical supervision. Radiographers must be supported to optimise the clinical learning environment where both students and educators are valued. Implications for practice: The findings highlight impact on educational support, practice, policy and future research. Effective clinical supervision is dependent on collaborative engagement and support being evident at all levels, including the clinical department, academic and healthcare institutions, and national organisations. © 2023 The College of Radiographers",TestAnalysis
"With the advent of digital transformation, organizations increasingly rely on various information systems to support their business processes (BPs). Recorded data, including textual data and event log, expand exponentially, complicating decision-making and posing new challenges for BP complexity analysis in Business Process Management (BPM). Herein, Process Mining (PM) serves to derive insights based on historic BP execution data, called event log. However, in PM, textual data is often neglected or limited to BP descriptions. Therefore, in this study, we propose a novel approach for analyzing BP execution complexity by combining textual data serving as an input at the BP start and event log. The approach is aimed at studying the connection between complexities obtained from these two data types. For textual data-based complexity, the approach employs a set of linguistic features. In our previous work, we have explored the design of linguistic features favorable for BP execution complexity prediction. Accordingly, we adapt and incorporate them into the proposed approach. Using these features, various machine learning techniques are applied to predict textual data-based complexity. Moreover, in this prediction, we show the adequacy of our linguistic features, which outperformed the linguistic features of a widely-used text analysis technique. To calculate event log-based complexity, the event log and relevant complexity metrics are used. Afterward, a correlation analysis of two complexities and an analysis of the significant differences in correlations are performed. The results serve to derive recommendations and insights for BP improvement. We apply the approach in the IT ticket handling process of the IT department of an academic institution. Our findings show that the suggested approach enables a comprehensive identification of BP redesign and improvement opportunities. © 2023 The Author(s)",TestAnalysis
"Objective: Dysphagia is the most commonly reported complication of annterior cervical discectomy and fusion (ACDF) surgery. However, the incidence of dysphagia post-ACDF varies widely–partly attributable to differing outcome measures used to capture dysphagia. Our objective was to conduct a scoping review of the literature to quantify which dysphagia outcome measures have been employed post-ACDF and examine trends by study design, year, and location. Methods: After removing duplicates, 2396 abstracts were screened for inclusion. A total of 480 studies were eligible for full-text review. After applying exclusion criteria, data was extracted from 280 studies. We extracted the dysphagia outcome measure(s), study design (prospective vs retrospective), year, and location (country). Approximately 10% of studies were repeated for intra-rater agreement. Results: In total, 317 dysphagia outcome measures were reported in 280 studies (primarily retrospective—63%). The largest proportion of outcome measures were categorized as “unvalidated patient-reported outcome measures” (46%), largely driven by use of the popular Bazaz scale. The next most common categories were “insufficient detail” and “validated patient-reported outcome measures” (both 16%) followed by “chart review/database” (13%) and instrumental assessment (7%). Studies examining dysphagia post-ACDF steadily increased over the years and the use of validated measures increased in the past 10 years. Conclusions: This scoping review of the literature highlights that nearly half of the ACDF dysphagia literature relies on unvalidated patient-reported outcome measures. The current understanding of the mechanism, timeline, and presentation of dysphagia post-ACDF are likely limited due to the metrics that are most commonly reported in the literature. © 2023, The Author(s).",TestAnalysis
"Despite the widespread use of interpretive structural modeling (ISM) in business research, little is known about its overall scientific productivity and impact on business research. This study presents a comprehensive review of the published ISM research and its latest editions in business using text mining. A two-tier review (narrative and systematic) is used to examine the methods and provide a comprehensive bibliometric analysis and an application roadmap. We demonstrate the number of ISM publications has been increasing in the past fifteen years, even though ISM was developed half a century ago. The study provides evidence for the increasing impact of ISM research in business. Content analysis shows an increase in the application of an updated edition of ISM, total interpretive structural modeling (TISM). In addition, the overall scientific productivity of ISM and TISM is assessed, and an ISM/TISM method selection roadmap is proposed. We further develop ISM+, a new integrated framework combining ISM and its latest editions to improve its performance and potential applications in business research. © 2023 Elsevier Inc.",TestAnalysis
"Objectives: The purpose of this systematic review and meta-analysis was to evaluate the proportion and risk factors of lymphoceles and symptomatic lymphoceles after PLND in early-stage cervical and early-stage high or high-intermediate risk endometrial cancer. Methods: Studies reporting on the proportion of lymphocele after PLND were conducted in PubMed, Embase and Cochrane Library. Retrieved studies were screened on title/abstract and full text by two reviewers independently. Quality assessment was conducted using the Newcastle Ottowa Scale and the Cochrane risk-of-bias tool. Proportion of lymphocele and possible risk factors were pooled through random-effects meta-analyses. Results: From the 233 studies retrieved, 24 studies were included. The pooled proportion of lymphocele was 14% and of symptomatic lymphocele was 3%. Routinely performing diagnostics was associated with a significantly higher proportion of lymphocele compared to diagnostics performed on indication (21% versus 4%, p < 0.01). Laparotomic surgical approach led to a significantly higher proportion of lymphoceles than laparoscopic surgical approach (18% versus 7%, p = 0.05). The proportion of lymphocele was significantly higher when >15% of the study population underwent additional paraaortic lymph node dissection (PAOLND) opposed to <15% (15% versus 3%, p < 0.01). A mean number of lymph nodes dissected of <21 resulted in a significantly higher pooled proportion of lymphoceles opposed to when the mean number was 21 or higher (19% versus 5%, p = 0.02). Other risk factors analysed were BMI, lymph node metastasis, adjuvant radiotherapy and follow up. There was no sufficient data to detect significant risk factors for the development of symptomatic lymphoceles. Conclusion: The pooled proportion of lymphocele was 14% of which symptomatic lymphoceles occurred in 3%. Significant risk factors for the total proportion of lymphoceles were laparotomic approach, decreased number of lymph nodes dissected and additional PAOLND. © 2023 The Authors",TestAnalysis
"This paper describes the effect of analysis window functions on the performance of Mel Frequency Cepstral Coefficient (MFCC) based speaker recognition (SR). The MFCCs of speech signal are extracted from the fixed length frames using Short Time Fourier Analysis (STFA) technique where an appropriate analysis window function is required to extract frames from the complete speech signal of a speaker prior to STFA. The number of frames are consider as the number of MFCC feature vectors of a speaker which uniquely represents the speaker in feature space (domain). For the recognition purpose Vector Quantization (VQ) and/or Gaussian Mixture Model (GMM) and/or Universal Background Model GMM (UBM-GMM) based classifiers are used and a comparative study is made. Generally in state-of-the-art MFCC feature vector extraction, Hamming (in some places abbreviated as Ham in this paper) window function is used, but here we also examine the effect of other window functions like rectangular window, Hann window, B-spline windows, polynomial windows, adjustable windows, hybrid windows and Lanczos window in SR. In the present paper, we briefly describe the analysis window functions and try to evaluate text-independent speaker identification (SI). We also use voice activity detector (VAD) to discard the silence frames before STFA. Indeed, silence frames removal leads to the better performance of SR because MFCC of silent frames make the MFCC feature space intrinsic (MFCC with impurity). Here IITG MV SR database contains speech signal of speakers recorded by different devices, namely, D01, H01, T01, M01 and M02, in different environment, different language, different session. This is the reason for calling the database multi variability. It is observed that VQ classifier performs better than other GMM based classifiers for this database and the classifiers VQ-GMM, VQ-UGM-GMM and the combination of them suffers from singularity problem of covariance matrix. So we evaluate the performance of device D01 for all the classifiers and the three classifiers namely, GMM, UBM-GMM and VQ are used for the remaining four recording devices, H01, T01, M01, M02 because except these three classifiers, all other classifiers suffer from singularity problem of covariance matrix in SI. It is observed that VQ provide the highest accuracy for all the devices. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"In response to the overuse of prescription opioid analgesics, clinical practice guidelines encourage opioid deprescribing (ie, dose reduction or cessation) in patients with chronic noncancer pain. Therefore, this study evaluated and compared international clinical guideline recommendations on opioid deprescribing in patients with chronic noncancer pain. We searched PubMed, EMBASE, PEDro, National Institute for Health and Care Excellence (United Kingdom), and MAGICapp databases from inception to June 4, 2021, with no language or publication restrictions. In addition, we searched the National Guideline Clearinghouse and International Guideline Network databases from inception to December 2018. Two independent reviewers conducted the initial title and abstract screening. After discrepancies were resolved through discussion, 2 independent reviewers conducted the full-text screening of each potentially eligible reference. Four independent reviewers completed the prepiloted, standardized data extraction forms of each included guideline. Extracted information included bibliographical details; strength of recommendations; and the outcomes, such as when and how to deprescribe, managing withdrawal symptoms, additional support, outcome monitoring, and deprescribing with coprescription of sedatives. A narrative synthesis was used to present the results. This study found that clinical practice guidelines agree on when and how to deprescribe opioid analgesics but lack advice on managing a patient's withdrawal symptoms, outcome monitoring, and deprescribing with coprescription of sedatives. Quality assessment of the guidelines suggests that greater discussion on implementation and dissemination is needed. © 2023 Lippincott Williams and Wilkins. All rights reserved.",TestAnalysis
"Background: Many important clinical decisions require causal knowledge (CK) to take action. Although many causal knowledge bases for medicine have been constructed, a comprehensive evaluation based on real-world data and methods for handling potential knowledge noise are still lacking. Objective: The objectives of our study are threefold: (1) propose a framework for the construction of a large-scale and high-quality causal knowledge graph (CKG); (2) design the methods for knowledge noise reduction to improve the quality of the CKG; (3) evaluate the knowledge completeness and accuracy of the CKG using real-world data. Material and methods: We extracted causal triples from three knowledge sources (SemMedDB, UpToDate and Churchill's Pocketbook of Differential Diagnosis) based on rule methods and language models, performed ontological encoding, and then designed semantic modeling between electronic health record (EHR) data and the CKG to complete knowledge instantiation. We proposed two graph pruning strategies (co-occurrence ratio and causality ratio) to reduce the potential noise introduced by SemMedDB. Finally, the evaluation was carried out by taking the diagnostic decision support (DDS) of diabetic nephropathy (DN) as a real-world case. The data originated from a Chinese hospital EHR system from October 2010 to October 2020. The knowledge completeness and accuracy of the CKG were evaluated based on three state-of-the-art embedding methods (R-GCN, MHGRN and MedPath), the annotated clinical text and the expert review, respectively. Results: This graph included 153,289 concepts and 1,719,968 causal triples. A total of 1427 inpatient data were used for evaluation. Better results were achieved by combining three knowledge sources than using only SemMedDB (three models: area under the receiver operating characteristic curve (AUC): p < 0.01, F1: p < 0.01), and the graph covered 93.9 % of the causal relations between diseases and diagnostic evidence recorded in clinical text. Causal relations played a vital role in all relations related to disease progression for DDS of DN (three models: AUC: p > 0.05, F1: p > 0.05), and after pruning, the knowledge accuracy of the CKG was significantly improved (three models: AUC: p < 0.01, F1: p < 0.01; expert review: average accuracy: + 5.5 %). Conclusions: The results demonstrated that our proposed CKG could completely and accurately capture the abstract CK under the concrete EHR data, and the pruning strategies could improve the knowledge accuracy of our CKG. The CKG has the potential to be applied to the DDS of diseases. © 2023 Elsevier Inc.",TestAnalysis
"Sentiment analysis is one of the effective techniques for mining the opinion from shapeless data contains text like review of the products, review of the movie. Sentiment analysis is used as a key to gather response from consumers, reviews of brands, marketing analyses, and political campaigns. In the subject of natural processing, performing sentiment analysis using the data obtained from Twitter is considered as a new study in these days. The dataset is gathered using the Twitter API and the Twitter package. The analysis of Twitter data is a process which takes place automatically by text data analysis to determine the view of public on the specified topic. Here, an improvised sentimental analysis model is proposed to identify the polarity of the tweets such as positive, neutral and negative. In this paper, stochastic gradient descent (SGD) algorithm uses stochastic gradient neural network (SGNN) to categorize the sentiment analysis on basis of tweets provided by the Twitter users and the proposed stochastic gradient descent optimization Algorithm based on stochastic gradient neural network (SGDOA-SGNN) provides better performance when compared with the existing Forest–Whale Optimization Algorithm based on deep neural network F-WOA-DNN model. © 2023, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd.",TestAnalysis
"Objective: To determine the skills and intentions of health practitioners in New Zealand to provide first trimester abortion care. New Zealand achieved abortion law reform in 2020, changing how abortion could be delivered and experienced by pregnant people. However, little has changed in the way abortion care is provided. Study design: This survey, which was deployed to a range of health practitioners via regulatory bodies and professional groups, used an online free text and tick box survey. Questions included demographics, scope of practice, abortion care experience, philosophical perspective on abortion, and skills transferable to abortion care. Data was analysed using descriptive statistics and deductive and inductive thematic analysis. Results: 128 respondents included doctors, nurses, midwives, counsellors, and social workers from a range of practice settings, the majority from primary health (51%). Most respondents indicated competency or proficiency in clinical skills relevant to provision of early medical abortion. However, practitioners were more likely to indicate “I do not have this skill” or “support required” for: calculating gestational age by bimanual examination (42%), LARC (implant and IUC) insertion (36%), undertake a pregnancy related consultation using tikanga best practice guidelines (19%). Analysis of qualitative data showed three main themes; (1) support for abortion access and for abortion provision in primary care (2) levels of intention to provide abortion (3) critical components for an action plan for abortion in primary care. Conclusion: Abortion care in the community has support from health practitioners. They identified needs including development of clinical skills, funding, and wider sector support. © 2022 Elsevier B.V.",TestAnalysis
"Optical character recognition (OCR) is typically used to extract the textual contents of scanned texts. The output of OCR can be noisy, especially when the quality of the scanned image is poor, which in turn can impact downstream tasks such as information retrieval (IR). Post-processing OCR-ed documents is an alternative to fix digitization errors and, intuitively, improve the results of downstream tasks. This work evaluates the impact of OCR digitization and correction on IR. We compared different digitization and correction methods on real OCR-ed data from an IR test collection with 22k documents and 34 query topics on the geoscientific domain in Portuguese. Our results have shown significant differences in IR metrics for the different digitization methods (up to 5 percentage points in terms of mean average precision). Regarding the impact of error correction, our results showed that on the average for the complete set of query topics, retrieval quality metrics change very little. However, a more detailed analysis revealed it improved 19 out of 34 query topics. Our findings indicate that, contrary to previous work, long documents are impacted by OCR errors. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TestAnalysis
"E-commerce has become a booming market for wildlife trafficking, as online platforms are increasingly more accessible and easier to navigate by sellers, while still lacking adequate supervision. Artificial intelligence models, and specifically deep learning, have been emerging as promising tools for the automated analysis and monitoring of digital online content pertaining to wildlife trade. Here, we used and fine-tuned freely available artificial intelligence models (i.e., convolutional neural networks) to understand the potential of these models to identify instances of wildlife trade. We specifically focused on pangolin species, which are among the most trafficked mammals globally and receiving increasing trade attention since the COVID-19 pandemic. Our convolutional neural networks were trained using online images (available from iNaturalist, Flickr and Google) displaying both traded and non-traded pangolin settings. The trained models showed great performances, being able to identify over 90 % of potential instances of pangolin trade in the considered imagery dataset. These instances included the showcasing of pangolins in popular marketplaces (e.g., wet markets and cages), and the displaying of commonly traded pangolin parts and derivates (e.g., scales) online. Nevertheless, not all instances of pangolin trade could be identified by our models (e.g., in images with dark colours and shaded areas), leaving space for further research developments. The methodological developments and results from this exploratory study represent an advancement in the monitoring of online wildlife trade. Complementing our approach with other forms of online data, such as text, would be a way forward to deliver more robust monitoring tools for online trafficking. © 2023 The Author(s)",TestAnalysis
"Recent multimodal sentiment analysis works focus on establishing sophisticated fusion strategies for better performance. However, a major limitation of these works is that they ignore effective modality representation learning before fusion. In this work, we propose a novel text-audio sentiment analysis framework, named StyleBERT, to enhance the emotional information of unimodal representations by learning distinct modality styles, such that the model already obtains an effective unimodal representation before fusion, which mitigates the reliance on fusion. In particular, we propose a Bi-directional Style Enhancement module, which learns one contextualized style representation and two differentiated style representations for each modality, where the relevant semantic information across modalities and the discriminative characteristics of each modality will be captured. Furthermore, to learn fine-grained acoustic representation, we only use the directly available Log-Mel spectrograms as audio modality inputs and encode it with a multi-head self-attention mechanism. Comprehensive experimental results on three widely-used benchmark datasets demonstrate that the proposed StyleBERT is an effective multimodal framework and significantly outperforms the state-of-the-art multimodal baselines. Our code is available at https://github.com/lsq960124/StyleBERT. © 2022 Elsevier Ltd",TestAnalysis
"Background Within the scope of an educational improvement project, the teaching concept of the course hygiene and microbiology at the Goethe-University in Frankfurt was transferred from an organ system-based teaching concept into a case-based teaching concept. Concomitantly, this transformation was qualitatively reviewed to evaluate self-perceived learning success. Methods 54 participants were included in this qualitative study. 45 students were interviewed in homogeneous focus groups of up to five. Nine physicians were interviewed individually. Following anonymization and transcription, a structured and qualitative text analysis was conducted. Results Both groups, students and physicians, prefer a case-based teaching concept in hygiene and microbiology, especially in combination with a hands-on approach to learn practical skills. Students taught with the case-based approach were more satisfied and reported better knowledge retention. The practical elements of the course hygiene and microbiology were positively remembered by all participants. Regardless of the teaching concept, the individual lecturer is considered most essential in shaping motivation. Conclusions Overall, the implementation of a case-based teaching concept with practical elements in the course hygiene and microbiology increases the ability of medical students to understand the relevance of core knowledge and improves self-perceived learning. The fusion of theoretical and clinical contents elements in the course hygiene and microbiology meets the new national medical licensing regulations in Germany and promises to be a sustainable concept for clinical-theoretical subjects like hygiene and microbiology. © 2023 Georg Thieme Verlag. All rights reserved.",TestAnalysis
"This article is focused on the statistical data and analyses of 187 Chinese character variants found in the book Chư phẩm kinh (諸品經, Various Essential Segments of the Scripture), which was collected and compiled by Zen Master Pháp Loa (1284–1330) and revised then by Zen Master Huyền Quang (1254–1334) to be handed down for posterity. Of those Chinese character variants, we have analysed 96 that are found only in Vietnam, proving that the number of character variants created intra-nationally in Vietnam is greater than that of the international variants introduced from China. © 2022 The Author(s).",TestAnalysis
"Wastewater-based epidemiology (WBE) has contributed significantly to the monitoring of drug use and transmission of viruses that has been published in numerous research papers. In this paper, we used LitStraw, a self-developed text extraction tool, to extract, analyze, and construct knowledge graphs from nearly 900 related papers in PDF format collected in Web of Science from 2000 to 2021 to analyze the research hotspots and development trends of WBE. The results showed a growing number of WBE publications in multidisciplinary cross-collaboration, with more publications and close collaboration between the USA, Australia, China, and European countries. The keywords of illicit drugs and pharmaceuticals still maintain research hotness, but the specific research hotspots change significantly, among which the research hotspots of new psychoactive substances, biomarkers, and stability show an increasing trend. In addition, judging the spread of COVID-19 by the presence of SARS-CoV-2 RNA in sewage has become the focus since 2020. This work can show the development of WBE more clearly by constructing a knowledge graph and also provide new ideas for the paper mining analysis methods in different fields. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TestAnalysis
"Background: The number of days between treatment sessions is often overlooked as a predictor of attrition in psychotherapy. In text-based Internet interventions, days between sessions may be a simple yet powerful predictor of attrition. Objective: We hypothesized that a larger number of days between sessions increased the likelihood of attrition among participants with Binge Eating Disorder (BED) in a 12-session Internet-based cognitive behavioral therapy (iCBT) program. Participants could work on the sessions whenever convenient for them and received written support from a psychologist. Material and methods: We compared 201 adult participants with mild to moderate BED (85 non-completers and 116 completers) on the number of days between sessions to predict attrition rates. Results: Mixed model binomial logistic regression showed that non-completers spent significantly more days between sessions across the first four treatment sessions (1–4) when controlling for age, gender, and intake measures of BMI, BED, overall health status (EQ VAS), and depression symptoms (MDI) (OR = 1.042, p <.001). Age (OR = 0.976, p <.001) and EQ VAS (OR = 0.984, p <.001) were also significant. The risk of attrition increased by 4.2 % for each additional day participants spent completing a session. A receiver operating characteristic (ROC) curve analysis showed that classification accuracy increased across sessions from 61.1 % in session 1 and 65.7 % in session 2 to 68.8 % in session 3 and 73.2 % in session 4. The optimal cut-off point in session 4 was 17.5 days, which detected 60.4 % of non-completers (sensitivity) and 78.4 % of completers (specificity). An exploratory repeated measures of ANOVA of days between sessions showed a significant within-subjects effect, where both non-completers and completers spent more days between sessions as they progressed from sessions 1 through 4 (F = 20.54, df = 3, p <.001). There was no interaction effect, suggesting that the increase in slope did not differ between non-completers and completers. Conclusions: Participants spending more days between sessions are at increased risk of dropping out of treatment. This may have important implications for identifying measures to reduce attrition, e.g., intensifying interventions through automated reminders or therapist messages. Our findings may have important transdiagnostic implications for text-based Internet interventions. Further studies should investigate the predictive value of days between sessions in other diagnoses. © 2023",TestAnalysis
"GaN-based electronics have witnessed an increase in both research and industrial activities, first spurred by the successful demonstration of GaN LEDs, and are now expanding into transistors and photovoltaic cells. In addition, GaN/GaAs heterojunction devices are currently receiving much interest. In this study, we conduct rigorous optoelectronic computational analysis of cubic phase GaN (c-GaN)/GaAs heterojunction solar cells for a comprehensive understanding of the cell. We utilize a compositionally graded GaAs1-xNx buffer layer to reduce defect states at the heterojunction interface caused by a significant lattice mismatch between c-GaN and GaAs. Furthermore, we enhance the performance of the cell by optimizing GaAs absorber layer thickness and c-GaN buffer layer doping concentration. Moreover, we examine the effects of GaAs1-xNx/GaAs interface recombination velocity (IRV) on the cell. Overall, we achieve 23% power conversion efficiency within 1.25- μ thin-film GaAs at low GaAs1-xNx/GaAs IRV. The analyses and results presented in this study demonstrate the vast application potential of c-GaN/GaAs heterojunction in high-efficiency solar cells.  © 1963-2012 IEEE.",TestAnalysis
"Pali Samas words cannot be found in any dictionary. They are created by placing Pali words that contain meaning after one another without changing their morphemes or with changes in morphemes and pronunciation. Thus, Pali Samas words need to be segmented back into their previously original words to obtain their meanings. This research presents a novel approach to Pali Samas segmentation using bidirectional long short-term memory to predict the splitting locations and applies the rules obtained from Samas word segmentation to achieving correct meanings. For the dataset used in this research, a total of 2,757 Thai Pali Samas words are used to further create 4,478 Samas words through text augmentation. The results from the Samas word segmentation indicate that the prediction for splitting locations has a weighted average of F1-score of 99.20%, with 81.91% of the original words derived from reverse segmentation based on the rules. ICIC International © 2023.",TestAnalysis
"Autocommunication, communication with oneself, may become distinct from communication with an ""other""both in form and function. Autocommunication has a special role in the development of thinking in small children, as differentiation of speech for oneself, known as ""private speech,""from communication for social purposes entails the child's organization of her or his own cognition and behavior with the aid of symbols. Recent studies have suggested that speech distinctly for the child him or herself is particularly observable during what is called ""crib speech""and thus it appears to support already early language acquisition. The purpose and functions of crib speech in child development have been topics of interest until recently, but they are still debated. In autocommunication, instead of transfer of signs from one mind to another as when in communication with an ""other,""there is transfer of signs from one state of mind to another, as in the case of recalling something with the help of signs. Next to this mnemonic type autocommunication, Juri Lotman was interested in the type in which textual devices within a text guide the communicative interpretation in relation to the text itself, particularly characteristic to poetry. The paper provides a semiotic analysis of crib speech in terms of Lotman's concept of autocommunication explaining its particular appearance both in form and content, as well as what initiates and inspires it for the small child and why does it bring such joy. From the point of view of semiotics, crib speech presents as an exceptionally rich phenomenon. In addition to being small children's language practice, crib speech appears as language play, if not poetry, serving as a modelling system for enacting and representing the world as it appears for the small child.  © 2023 Walter de Gruyter GmbH, Berlin/Boston.",TestAnalysis
"Artificial intelligence (AI) has become part of our everyday lives, and its presence and influence are expected to grow exponentially. Regardless of its expanding impact, the perplexing algorithms and processes that drive AI's decision and output can lead to decreased trust, and thus impede the adoption of future AI services. Explainable AI (XAI) in recommender systems has surfaced as a solution that can help users understand how and why an AI recommended a specific product or service. However, there is no standardized explanation method that satisfies users' preferences and needs. Therefore, the main objective of this study is to explore a unified explanation method that centers around human perspective. This study examines the preference for AI interfaces by investigating the components of user-centered explainability, including scope (global and local) and format (text and visualization). A mixed logit model is used to analyze data collected by a conjoint survey. Results show that local explanation and visualization are preferred, and users dislike lengthy textual interfaces. Our findings incorporate the extraction of monetary value from each attribute. © 2023 Elsevier Inc.",TestAnalysis
"Assessing health outcomes associated with exposure to polychlorinated biphenyls (PCBs) is important given their persistent and ubiquitous nature. PCBs are classified as a Group 1 carcinogen, but the full range of potential noncancer health effects from exposure to PCBs has not been systematically summarized and evaluated. We used systematic review methods to identify and screen the literature using combined manual review and machine learning approaches. A protocol was developed that describes the literature search strategy and Populations, Exposures, Comparators, and Outcomes (PECO) criteria used to facilitate subsequent screening and categorization of literature into a systematic evidence map of PCB exposure and noncancer health endpoints across 15 organs/systems. A comprehensive literature search yielded 62,599 records. After electronic prioritization steps, 17,037 studies were manually screened at the title and abstract level. An additional 900 studies identified by experts or supplemental searches were also included. After full-text screening of 3889 references, 1586 studies met the PECO criteria. Relevant study details such as the endpoints assessed, exposure duration, and species were extracted into literature summary tables. This review compiles and organizes the human and mammalian studies from these tables into an evidence map for noncancer health endpoints and PCB mixture exposure to identify areas of robust research as well as areas of uncertainty that would benefit from future investigation. Summary data are available online as interactive visuals with downloadable metadata. Sufficient research is available to inform PCB hazard assessments for most organs/systems, but the amount of data to inform associations with specific endpoints differs. Furthermore, despite many years of research, sparse data exist for inhalation and dermal exposures, which are highly relevant human exposure routes. This evidence map provides a foundation for future systematic reviews and noncancer hazard assessments of PCB mixtures and for strategic planning of research to inform areas of greater uncertainty. © 2023",TestAnalysis
"Background: Pleural infection represents a significant clinical challenge worldwide. Although prompt drainage of pleural fluid is thought to play a key role in pleural infection management, the optimal size of intrapleural catheter has yet to be defined. Objectives: The aim of this systematic review and meta-analysis was to summarize data on efficacy and complications of small-bore drain (SBD), defined as ≤14F, in comparison to large-bore drain (LBD) in patients with pleural infection. Method: We searched MEDLINE and Embase for all studies reporting outcomes of interest published up to October 2021. Two authors reviewed selected full text to identify studies according to predefined eligibility criteria. Summary estimates were derived using the random-effects model. Results: Twelve original studies were included for qualitative analysis and 7 of these for quantitative analysis. The surgical referral rate of SBD and LBD were, respectively, 0.16 (95% confidence interval [CI], 0.12-0.21) and 0.20 (95% CI, 0.10-0.32), the pooled mortality were 0.12 (95% CI, 0.05-0.21) and 0.20 (95% CI, 0.10-0.32), and the length of hospital stay was 24 days in both groups. Data on complications suggest similar proportions of tube dislodgement. Intensity of pain was evaluated in one study only, reporting higher scores for LBD. Conclusions: This systematic review and meta-analysis provide the first synthesis of data on performance of SBD and LBD in management of pleural infection, and, overall, clinical outcomes and complications did not substantially differ, although the limited number of studies and the absence of dedicated randomized trials does limit the reliability of results. © 2023 The Author(s). Published by S. Karger AG, Basel. This article is licensed under the Creative Commons Attribution-NonCommercial 4.0 International License (CC BY-NC). Usage and distribution for commercial purposes requires written permission.",TestAnalysis
"Objective: To explore midwives’ thoughts on providing antenatal care to pregnant transmen. Methods: A qualitative study based on semi-structured, individual interviews with 12 midwives during January 2022. Systematic text condensation was used for data analysis. Results: The analysis of the data material resulted in three result categories: 1) Gender transition and the desire to have children - exposure of the phenomenon can help to avoid stigmatisation, 2) A pregnant person is a pregnant person no matter what - the midwife's role in meeting a pregnant man, and 3) Being a man but using the body as a woman - the knowledge is lacking in the textbooks. Conclusion: The study showed that midwives have little knowledge about pregnant transmen. The knowledge gaps will remain unfilled unless more research is done on the topic, and sufficient information provides for good procedures and standards of care. Access to information about pregnant transmen and experiences of their encounters with midwives will contribute with new knowledge and over time, changes in attitudes, both professional and private. © 2023 The Author(s)",TestAnalysis
"Research examining workplace bullying (WB) perpetration from the perspective of perpetrators has remained limited compared to the literature on targets and victims. Until now, no systematic review of the studies from the perpetrators' viewpoints has been published. The present review aimed to synthesize the empirical studies that examine antecedents, mediators, moderators, and outcomes of WB perpetration. It also analyzed the practical suggestions given to curb perpetration and the research methods used. A literature search in Scopus, ProQuest, Science Direct, PubMed, and Web of Science databases for empirical studies published between 2003 and 2023 in peer-reviewed journals in English resulted in 50 full-text articles. Antecedent–perpetration relationships were primarily examined based on social and aggression theories. These relationships were analyzed in the silos of work environment or individual factors without diverse moderators and mediators. Research on WB perpetrators largely lacked causality analysis. Perpetration was associated with task-focused, conflict-prone, poorly organized, and stressful work environments. WB perpetrators had undesirable personality characteristics, and they were also being bullied. The outcomes of their behavior were rarely studied. The suggestions the researchers gave to curb WB perpetration seemed unlikely to be implemented by the same management team that created the toxic environment in the first place. Research on WB perpetrators, which is still in its infancy stage, lacks variety in terms of topics studied, the combination of work environment and individual factors, causality analysis and evidence-based interventions. © 2023 The Authors",TestAnalysis
"Because of the environmental consequences of manufacturing activities, the general public, industry, and academia are becoming more aware of sustainable manufacturing (SM), which incorporates environmentally friendly manufacturing processes while emphasizing overall triple bottom line (TBL) performance in manufacturing. This article employs various text mining techniques and bibliometric analysis including cluster analysis, Pearson coefficient and research landscape to conduct an extensive investigation on SM with a focus on the TBL, in which the research content of SM with the TBL is reviewed and discussed systematically from a wide angle and with reduced bias. In this study, three new indicators about the ratios of the number of scientific papers between social, environmental, and economic dimensions of SM are devised to show the weight and level of importance of dimensions in SM, covering scientific papers from 30 years. The findings from this study indicate that the influential power of SM varies across the three dimensions, with a particular emphasis on the social dimension of SM from various countries, implying a current state of imbalance status in TBL for SM, at the same time, the economic and environmental dimensions share similar research topics and academic emphasis in SM. Based on these findings, recommendations based on sustainable development goals (SDGs) of the United Nations (UN) are made to increase the social influence of SM. This article firstly reveals the individual status of the social dimension and the situation of unbalanced TBL in SM, providing sustainable suggestions for enhancing the effectiveness of SM and achieving balanced TBL regarding the SDGs. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TestAnalysis
"The present work reports a novel methodological and comprehensive bibliometric analysis on past and present research advances carried out on geothermal water–rock interaction experiments from 1963 to 2022. The novel bibliometric analysis enabled the most representative bibliometric indicators on the research subject to be obtained. Published articles, preferred publication journals, research leaderships (authors, networking groups, institutions, and countries), and future research trends were also collected from a comprehensive searching carried out in indexed databases (Web of Science and Scopus). Up to our knowledge, this bibliometric information will benefit the worldwide geothermal community by providing a deeper insight of water/rock interaction lab experiments carried out up to date. The bibliometric analysis suggests relevant research areas such as geochemistry, thermodynamics, enhanced geothermal systems, carbon dioxide capture, and hydrothermal alteration as the main key research findings. These research areas were identified as the main bibliometric hotspots which have a strong potential to be used for the experimental design of new and improved water–rock interaction studies to address some crucial problems present in the geothermal prospection and exploitation. Among these problems stand out the study of hydrothermal, superhot and enhanced geothermal systems, the chemical fractionation of major and trace elements, the hydrothermal alteration, the calibration of solute and gas geothermometers, the scaling and corrosion problems, the carbon capture and storage, the evaluation of environmental issues, among others. Details of this comprehensive bibliometric analysis, including some statistical and text mining and mapping tools are fully outlined. © 2023, The Author(s).",TestAnalysis
"Background: The ability to effectively communicate with patients continues to be a challenge for physician offices. Mobile healthcare applications have enhanced the accessibility of healthcare providers to their patients. However, the efficacy of unrestricted, personalized, bidirectional, freeform texting has not been previously evaluated. Methods: We investigated patient preference and self-reported outcomes using a smartphone HIPAA compliant mobile healthcare texting app, compared to conventional telecommunication, in self-reported quality of care, and impact on preventing unnecessary emergency department visits. A retrospective cohort survey study of a single-surgeon hernia specialist’s practice was utilized. Patients with access to a smartphone who received care between July 2017 and March 2020 were instructed to utilize the healthcare texting app as a replacement to calling/receiving calls from the physician’s office. Messages to and from patients were delivered directly to their surgeon and the surgical team via non-automated, personalized, freeform text messages, and templates, available to patients at all hours of the day. A depersonalized online survey was then distributed to assess patient perceived quality of care using the app, compared to their past experiences calling physician offices, and whether they preferred using text or conventional telecommunication. Additional statistics were reported using the application’s built-in software, including response times, adoption rates, and message volumes. Results: 90 patients successfully completed the entirety of the survey, median age range 50–60 years old. 97% of respondents reported the texting app provided at least non-inferior quality of care compared to conventional telecommunication, with a majority (75%) experiencing a relatively improved quality of care. 9% reported an unnecessary ED visit being avoided after consulting their physician through the application. Conclusions: Unrestricted, freeform, non-automated communication via texting may be preferred by patients over conventional telecommunication. However, further research is warranted to assess the external validity and clinical impact of such results. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"Objective: To evaluate the efficacy of different physical therapy interventions that could validate decisions taken by health care providers in the field of rehabilitation of patients with hemophilia according to the International Classification of Functioning, Disability and Health (ICF), including body functions and structures, activity, and participation. Data Sources: Seven databases—PubMed, Cochrane Library, Scopus, Web of Science, Physiotherapy Evidence Database, Google Scholar, and Clinicaltrials.gov—were systematically searched for randomized controlled trials evaluating any physical therapy modality to manage hemophilia. Study Selection: After abstract and full-text filtration, a methodological quality assessment was performed using the Physiotherapy Evidence Database scale for the studies that met the eligibility criteria. Data Extraction: Relevant data were extracted from eligible studies and outcomes were categorized according to the ICF. Data Synthesis: Using Review Manager and Microsoft Excel, a quantitative analysis using standardized mean differences with the 95% confidence interval was completed. Statistical heterogeneity between studies was explored using the I2 test. A fixed effect model was applied to all data analyses. If heterogeneity was statistically significant, the Der Simonian and Laird random effects models were used instead. Results: 35 randomized controlled trials with 1216 participants were included in this systematic review; 13 of them dealt with pediatric patients. Most of the studies were of good quality; 12 studies were of low quality. Meta-analysis showed a significant difference in favor of manual therapy, laser, and therapeutic exercises on selected outcomes of body function and structure, activity, and participation categories of the ICF model. Conclusion: This systematic review recommends using manual therapy and therapeutic exercise modalities to improve join health status in combination with educational sessions to improve the quality of life of patients with hemophilic arthropathy. For pediatric patients with hemophilic arthropathy, using laser therapy is promising for improving functional capacity. © 2022 American Congress of Rehabilitation Medicine",TestAnalysis
"Objectives: This study aimed to systematically review the literature to determine outcomes following surgical treatment of pediatric vocal fold nodules. Methods: Studies with patients ≤18 years with nodules who underwent surgery were reviewed for dysphonia improvement and recurrence in PubMed, EMBASE, Medline, CINAHL, Cochrane, Scopus, and Web of Science databases, searched from inception to November 1, 2022 using PRISMA guidelines. Non-English studies and case reports were excluded. Two evaluators independently reviewed each abstract and article. Heterogeneity and bias across studies were evaluated and meta-analysis was performed. Results: The literature search yielded 655 articles; 145 underwent full-text screening and eight were selected for systematic review and meta-analysis. There were 311 children with nodules, aged 2–18 years, with male-to-female ratio of 3.6:1. There were no surgical complications. Voice therapy was inconsistently reported. Follow-up time ranged from 1 month to 10 years. One study concluded that neither surgery nor voice therapy was effective, while five studies concluded that dysphonia improved with surgery. Voice grading by GRBAS, objective voice measures, and lesion size were improved following surgery, when reported. Meta-analysis of six studies demonstrated improvement in dysphonia in 90% of children post-operatively (95% CI: 74–99%). Meta-analysis of four studies showed that recurrence occurred in 19% of children (95% CI: 13–23%). Conclusion: This systematic review suggests possible post-operative improvement in dysphonia for pediatric patients with vocal fold nodules; however, study measures, methods, and surgery utilized were heterogeneous and results should be interpreted cautiously. In order to better understand surgical outcomes, future studies should include standardized definition of nodules and objective measures of voice. © 2023 Elsevier B.V.",TestAnalysis
"Background: During the COVID-19 pandemic, there is a global demand for intelligent health surveillance and diagnosis systems for patients with critical conditions, particularly those with severe heart diseases. Sophisticated measurement tools are used in hospitals worldwide to identify serious heart conditions. However, these tools need the face-to-face involvement of healthcare experts to identify cardiac problems. Objective: To design and implement an intelligent health monitoring and diagnosis system for critical cardiac arrhythmia COVID-19 patients. Methodology: We use artificial intelligence tools divided into two parts: (i) IoT-based health monitoring; and (ii) fuzzy logic-based medical diagnosis. The intelligent diagnosis of heart conditions and IoT-based health surveillance by doctors is offered to critical COVID-19 patients or isolated in remote locations. Sensors, cloud storage, as well as a global system for mobile texts and emails for communication with doctors in case of emergency are employed in our proposal. Results: Our implemented system favors remote areas and isolated critical patients. This system utilizes an intelligent algorithm that employs an ECG signal pre-processed by moving through six digital filters. Then, based on the processed results, features are computed and assessed. The intelligent fuzzy system can make an autonomous diagnosis and has enough information to avoid human intervention. The algorithm is trained using ECG data from the MIT-BIH database and achieves high accuracy. In real-time validation, the fuzzy algorithm obtained almost 100% accuracy for all experiments. Conclusion: Our intelligent system can be helpful in many situations, but it is particularly beneficial for isolated COVID-19 patients who have critical heart arrhythmia and must receive intensive care. © 2023 Elsevier Ltd",TestAnalysis
"Objectives: To compare online learning with traditional face-to-face and blended learning, based on randomized controlled trials, to determine the impact of online learning on nursing students' learning outcomes. Design: A systematic review and meta-analysis. Data sources: A systematic search was conducted via English (PubMed, ERIC, Embase, CENTRAL, and CINAHL) and Korean databases (RISS, DBpia, and KISS). Review methods: Studies published up to the first week of April 2022 were reviewed with a focus on the participants, intervention, comparison, outcome, and study design format. Following a primary screening of titles and abstracts, and secondary screening of full texts, 10 randomized controlled trial studies were selected, of which eight were included in the meta-analysis. Two researchers independently reviewed the literature, and the final selection was made in consensus. Results: Online learning had a statistically significant positive effect on nursing students' knowledge, compared with no educational intervention (standardized mean difference (SMD) = 1.63; 95 % confidence interval (CI): 1.31 to 1.95). However, there was no significant difference in the impact of online learning on knowledge compared with blended learning (SMD = −0.14; 95 % CI: −0.70 to 0.41) and face-to-face learning (SMD = 0.37; 95 % CI: −0.32 to 1.06). Furthermore, compared with blended learning (SMD = −0.18; 95 % CI: −0.43 to 0.06) and face-to-face learning (SMD = 0.05; 95 % CI: −0.31 to 0.41), there was no significant difference in the impact of online learning on attitudes toward learning. Conclusions: Online learning in nursing education is not significantly different from blended or face-to-face learning in terms of its impact on knowledge acquisition and attitudes toward learning. The results of this review and meta-analysis highlight the need for selective application of learning methods, taking into account learning environments as well as curricular subjects and topics. © 2023 Elsevier Ltd",TestAnalysis
"Background: Community pharmacists are increasingly recognized as integral members in suicide prevention programs, as part of a multidisciplinary and multifaceted approach. However, further research is required to understand then optimize the whole pharmacy teams’ role across sectors. Objective: To explore pharmacy teams’ experience of, and attitudes towards, suicide prevention in England. Methods: A cross-sectional survey was purposively distributed to pharmacy staff in England before accessing an optional suicide awareness raising video, hosted by Centre for Pharmacy Postgraduate Education (CPPE), in September 2019–March 2021. Questions included demographics and experience of, attitudes towards, and preparedness for, suicide prevention. The 14-item Attitudes to Suicide Prevention (ASP) scale was used (possible range 14–70 with lower scores representing positive attitudes). Descriptive and comparative statistics were reported. Free-text comments were invited to explore respondents’ experience of suicide prevention and reflexive thematic analysis used. Results: Of 403 respondents, 82% were female; most were pharmacists (59%) or pharmacy technicians (21%), with the remainder having other roles. Eighty-five percent worked in community pharmacy. Eleven percent had prior suicide prevention training, and 71% reported interacting with at least one patient about suicide. Most often, suicidality was disclosed by the patient (40%), with 6% of pharmacy staff having directly asked a patient about suicidal behavior or plans. The aggregated ASP score was 31.51 (SD 6.23), and role did not affect experience or attitude. Pharmacy teams’ experiences of suicide prevention can be summarized by three major themes i) Exposure to suicide; ii) Responsibility for action; and iii) Access to means of suicide. Conclusions: Pharmacy teams felt responsibility in caring for those at risk of suicide and had experience of this. Further training should include understanding of medicines means restriction and involve all roles and sectors of pharmacy. Pharmacy teams should be integrated into the ‘circle of care’ to access referral pathways. © 2022 The Authors",TestAnalysis
"Classics has been used for various social, cultural and political purposes on the African sub-continent. Part I highlights some theoretical considerations regarding the traditional models of the classical tradition and the classical reception in Africa. The idea of the classical ‘traception’ embraces the classical tradition through its suggestion of linear descendent and the classical reception through its ‘receptive’ and reconfigurative associations. Part II discusses how and when classical ideas and texts reached and extended into Africa from the time of the sixteenth century and the main areas that constitute the classical ‘traception’ on the subcontinent. Part III presents a case study in the area of drama to illustrate some of the interpretive consequences of using the model of the classical tradition as opposed to that of the classical reception. My proposed model of the ‘classical traception’ seems preferable to either of these models when describing the dynamics of Fugard, Kani, and Ntshona’s The Island (1974) since it spans both the European conception of the original Antigone and its linear descent as well as its reconfiguration by its split collective (hybrid) multi-racial ‘author’ in The Island. Considering the elements of the classical tradition along with those of the classical reception—what I jointly term classical ‘traception’—helps to provide a broader view of the ways in which Classics has helped to shape and been received by different African societies and their cultures from the perspectives of both the European colonizers and indigenous peoples. © 2023, The Author(s).",TestAnalysis
"Rapid urbanization negatively affects the built and biotic environment, necessitating interdisciplinary mitigation strategies. Current nature-based solutions that are integrated into building envelope design have proved to be beneficial. These solutions, however, are primarily anthropocentric and often overlook the potential to support other living organisms, such as animals and microbiota. Thus, a multi-species approach is envisioned to facilitate more holistic envelope-design solutions. While integrating ecological knowledge into architectural design often introduces decision-making complexity, multi-criteria decision-making can support multi-species building envelope design. This paper reviews such decision-making applications in two domains: building envelope design and ecological planning design. Using a systematic literature review methodology to compile relevant publications for full-text analysis, the results show significant disparities between the two domains. This is primarily driven by decision-making applications, the scale of analysis, criteria typology and external decision-maker engagement. However, we identified opportunities to sequentially employ multi-objective optimization and multi-attribute decision-making to mitigate the technical differences and facilitate interdisciplinary collaboration. Finally, we discuss future developments using hybrid multi-criteria decision-making to facilitate better architectural and ecological computer-aided design. © 2023 The Authors",TestAnalysis
"The distraction of road users is one of the leading causes of road crashes. In general, distraction in road crashes is often associated with only driving, not walking, however, several studies have highlighted distracted walking as a major cause for road crashes and have also examined distracted walking behaviour and its causes, but there is a paucity of such kind of literature in the context of developing or low-income countries, such as India. This study sought to fill this gap by examining factors that influence pedestrians' use of cell phones for texting while crossing the roads in the city of Bhopal, India. In the present study analysis of psychological factors and socio-economic factors that contribute to distracted walking/crossing was analysed using an extended version of the theory of planned behaviour (TPB). Using confirmatory factor analysis (CFA) and structural equation modelling (SEM), this study confirmed the validity of items under each factor of the TPB and then employed SEM to investigate the relationship between the latent variables (attitude, subjective norm, and perceived behaviour control), and demographic characteristics (age, income, and gender) of pedestrians with their intention to text while crossing the street. The results obtained from SEM indicated that the intention to use cell phones for texting at crosswalks was negatively impacted by age, and positively impacted by income level. A significant influence of attitudes, subjective norms, and perceived behaviour control was found on the intention to use cell phones. Perceived behaviour control (PBC) was found as the most influential factor for predicting pedestrian intentions to use cell phones, followed by Subjective norms (SN). In addition, perceived behaviour control and the intention to use a cell phone also significantly affected crossing behaviour. The findings from the present study can significantly contribute to enhancing pedestrian safety in transportation research, and a better understanding of the factors contributing to pedestrian fatalities could lead towards safe system approach. © 2023 International Association of Traffic and Safety Sciences",TestAnalysis
"With an increase in complexity and severity, it is becoming harder to identify and mitigate vulnerabilities. Although traditional tools remain useful, machine learning models are being adopted to expand efforts. To help explore methods of vulnerability detection, we present an empirical study on the effectiveness of text-based machine learning models by utilizing 344 open-source projects, 2,182 vulnerabilities and 38 vulnerability types. With the availability of vulnerabilities being presented in forms such as code snippets, we construct a methodology based on extracted source code functions and create equal pairings. We conduct experiments using seven machine learning models, five natural language processing techniques and three data processing methods. First, we present results based on full context function pairings. Next, we introduce condensed functions and conduct a statistical analysis to determine if there is a significant difference between the models, techniques, or methods. Based on these results, we answer research questions regarding model prediction for testing within and across projects and vulnerability types. Our results show that condensed functions with fewer features may achieve greater prediction results when testing within rather than across. Overall, we conclude that text-based machine learning models are not effective in detecting vulnerabilities within or across projects and vulnerability types. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"This paper reports on an automated patent landscaping and legal geography analysis to scrutinize the biopiracy of endemic plants in the island of Hispaniola (Haiti and the Dominican Republic). My analysis relies on shrubs and flowers that may be reaped without a fair and equitable distribution of benefits. My findings highlight that Western pharmaceutical and biotechnology companies' innovations may overlap sovereign states’ intellectual property rights, implying that regulatory gaps must be filled to empower local communities to benefit from biodiversity and ecosystem services. Therefore, I suggest that the island adopt effective and consistent access and benefit-sharing policies, including mechanisms that encourage environmental protection and require prior informed consent and mutually agreed terms for utilizing genetic resources. I also suggest the introduction of disclosure of origin and/or source of genetic resources in their respective patents regime to ensure that Convention on Biological Diversity regulations and other related international frameworks can be followed. © 2023 Elsevier Ltd",TestAnalysis
"The practice of municipal solid waste (MSW) in developing countries like China is changing from mixed treatment to classified treatment, with the need of urban development. This variation calls for assessment of the MSW policies, in particular, whether the MSW policies formulated in the past can well guide the demand of the current MSW system. Quantitative evaluation of MSW policies from the perspective of policy consistency is conducive to systematically identifying common problems existing in policies and providing possible new ways for policy improvement. However, quantitative evaluation of MSW policies is under-represented in the existing literature. This paper employs the Policy Modeling Consistency Index (PMC-Index) approach and text mining technology to quantitatively evaluate the consistency level of China's 26 MSW policies, and comparatively analyze the common problems of 26 policies in the horizontal dimensions. The results indicate that sixteen policies belong to the good consistency level, ten pertain to the acceptable level. In other words, none is able to attain the perfect policy level. This demonstrates that while China's MSW policies are generally reasonable and consistent, there is some room for improvement. Further comparative analysis reveals that policy release agency, policy timeliness and policy instrument are main reasons for the results of policy imperfection. Thus, these three aspects may be the starting points to effectively improve China's MSW policies. © 2023 Elsevier Inc.",TestAnalysis
"Background: Polycystic ovary syndrome (PCOS) is the primary cause of anovulatory infertility, bringing serious harm to women's physical and mental health. Acupuncture may be an effective treatment for PCOS. However, systematic reviews (SRs) on the efficacy and safety of acupuncture for PCOS have reported inconsistent results, and the quality of these studies has not been adequately assessed. Objective: To summarize and evaluate the current evidence on the efficacy and safety of acupuncture for PCOS, as well as to assess the quality and risks of bias of the available SRs. Search strategy: Nine electronic databases (Cochrane Library, MEDLINE, Embase, PsycINFO, CINAHL, Chinese National Knowledge Infrastructure, Wanfang Data, Chongqing VIP Chinese Science and Technology Periodical Database, and China Biology Medicine disc) were searched from their establishment to July 27, 2022. Based on the principle of combining subject words with text words, the search strategy was constructed around search terms for “acupuncture,” “polycystic ovary syndrome,” and “systematic review.” Inclusion criteria: SRs of randomized controlled trials that explored the efficacy and (or) safety of acupuncture for treating patients with PCOS were included. Data extraction and analysis: Two authors independently extracted study data according to a predesigned form. Tools for evaluating the methodological quality, risk of bias, reporting quality, and confidence in study outcomes, including A Measurement Tool to Assess Systematic Reviews 2 (AMSTAR 2), Risk of Bias in Systematic Reviews (ROBIS), Preferred Reporting Items for Systematic Reviews and Meta-analyses for Acupuncture (PRISMA-A), and the Grading of Recommendations Assessment, Development and Evaluation (GRADE), were used to score the included SRs. Results: A total of 885 studies were retrieved, and 11 eligible SRs were finally included in this review. The methodological quality of 2 SRs (18.18%) was low, while the other 9 SRs (81.82%) were scored as extremely low. Four SRs (36.36%) were considered to be of low risk of bias. As for reporting quality, the reporting completeness of 9 SRs (81.82%) was more than 70%. Concerning the confidence in study results, 2 study results were considered to have a high quality of evidence (3.13%), 14 (21.88%) a “moderate” quality, 28 (43.75%) a “low” quality, and 20 (31.24%) considered a “very low” quality. Descriptive analyses suggested that combining acupuncture with other medicines can effectively improve the clinical pregnancy rate (CPR) and ovulation rate, and reduce luteinizing hormone/follicle-stimulating hormone ratio, homeostasis model assessment of insulin resistance, and body mass index (BMI). When compared with medicine alone, acupuncture alone also can improve CPR. Further, when compared with no intervention, acupuncture had a better effect in promoting the recovery of menstrual cycle and reducing BMI. Acupuncture was reported to cause no adverse events or some adverse events without serious harm. Conclusion: The efficacy and safety of acupuncture for PCOS remains uncertain due to the limitations and inconsistencies of current evidence. More high-quality studies are needed to support the use of acupuncture in PCOS. © 2022 Shanghai Yueyang Hospital Affiliated to Shanghai University of Traditional Chinese Medicine.",TestAnalysis
"Objective: Little is known about sex differences in response to lifestyle interventions among pediatric populations. The purpose of this analysis was to evaluate sex differences in adiposity following lifestyle interventions among children and adolescents with overweight or obesity aged 6 to 18 years old. Methods: Searches were conducted in PubMed, Web of Science, and MEDLINE (from inception to March 2021), and references from included articles were examined. Eligibility criteria included children and adolescents aged 6 to 18 years with overweight or obesity, randomization to a lifestyle intervention versus a control group, and assessment of at least one adiposity measure. Corresponding authors were contacted to obtain summary statistics by sex (n = 14/49). Results: Of 89 full-text articles reviewed, 49 (55%) were included, of which 33 (67%) reported statistically significant intervention effects on adiposity. Only two studies (4%) evaluated sex differences in response to lifestyle intervention, reporting conflicting results. The results of the meta-regression models demonstrated no significant differences in the treatment effect between male and female youth for weight (beta = −0.05, SE = 0.18, z = −0.28, p = 0.8), BMI (beta = 0.03, SE = 0.14, z = 0.19, p = 0.85), BMI z score (beta = −0.04, SE = 0.18, z = −0.23, p = 0.82), percentage body fat (beta = −0.11, SE = 0.16, z = −0.67, p = 0.51), and waist circumference (beta = −0.30, SE = 0.25, z = −1.18, p = 0.24). Conclusions: The meta-analysis revealed that youth with overweight or obesity do not demonstrate a differential response to lifestyle intervention in relation to adiposity-related outcomes. © 2023 The Obesity Society.",TestAnalysis
"Aim: Qualitative Phenomenological analysis of nurses' experience working with immigrants, exploring the dimension of work motivation. Background: Nurses' professional motivation and job satisfaction affects quality of care, work performance, burnout and resilience. The challenge of maintaining professional motivation is reinforced when providing care to refugees and new immigrants. In recent years, a large number of refugees sought sanctuary in Europe, resulting in the formation of refugee camps and asylum centers. Medical staff - including nurses - are involved in patient-caregiver encounter treating multicultural immigrant/refugee population. Design and methodology: A qualitative Phenomenological Methodology was employed. In-depth semi structured interviews and archival research were both used. Results: Study population – 93 certified nurses working between the years 1934–2014. Thematic and text analysis was employed. Four main motivation themes emerged from the interviews: duty, mission, perception of devotion and the general responsibility to bridge the cultural gap for the immigrant patients. Conclusion: The findings emphasize the importance of understanding nurses' motivations in working with immigrants. © 2023 Elsevier Ltd",TestAnalysis
"Introduction: More than 25% of American adolescents live in immigrant families. This cohort of adolescents is a minority group with amplified health challenges. The purpose of this study was to provide an integrative review of quantitative research on the access and use of primary and preventive health care by adolescents in immigrant families. Method: Searches yielded 460 reports, 54 of them satisfied criteria for full-text review, and four publications met inclusion criteria. Results: Research, albeit very limited, revealed that adolescents in immigrant families have poor access to and use of preventive health care. Discussion: Lack of primary health care may prevent identification of health risks in immigrant adolescents and lead them to perceive that preventive health care is unnecessary. Researchers are challenged to develop and test health promotion interventions tailored for these adolescents. Study recruitment outside of high schools, the typical setting, is critical to advance knowledge and improve access for this vulnerable population. © The Author(s) 2023.",TestAnalysis
"This article explores the fan-dubbing practice of ‘abridged anime’ on YouTube and considers the implications involving the creators’ cultural distance from their transnational source material. In this case study, I argue that the practice of parody and fan appropriation can be viewed within the context of global media flows and cultural reinterpretation, suggesting a toxic fan culture that either trivializes or distorts the original text. By focusing on numerous abridged anime series and creator interviews, and framing that analysis within the theorization of parodic transgression, I demonstrate that these fan practices can take on either orientalist or sexist perspectives and move us further from a nuanced cultural understanding of the text itself. © The Author(s) 2023.",TestAnalysis
"The creation of an engaging online learning environment where students feel a sense of belonging is a challenge for all educators. With the rise of online courses, discussion forums are commonly used to connect students with course content, peers, and instructors. However, these discussions are often text-based in nature. The purpose of this quantitative study examined preservice teacher perceptions of Flipgrid in an introductory educational technology course. Statistically significant relationships between groups were found related to two of the three components of the Community of Inquiry framework. Specifically, the findings suggest those enrolled in a hybrid course perceived Flipgrid as a more effective platform to create cognitive and teaching presence than those online. Additionally, hybrid learners were significantly more likely to use Flipgrid in their own teaching practices. In this article, an analysis of findings will be discussed and provide suggestions for future research. © 2023, Association for Educational Communications & Technology.",TestAnalysis
"The impact of online social media has aided the users in sharing of knowledge, mood, feelings, and interests to the large volume of audience. The mental health of a person can be easily identified by analysing these expressions consisting of different modalities (text and emojis/emoticons). This research work aims to investigate the mood disorder like depression, low mood and other symptoms using tweets and emoticons. The present work curated the twitter based SentiEmoDD dataset as a benchmark for depression detection, labelled with sentiments analysis, emotions detection and other symptoms important for depression detection. The evolved dataset is equipped with both modalities (text and emojis) of tweets. A novel approach has been proposed based on the multi-view ensemble learning model contemplated to attain the information available in different modalities of a sentence for better depression detection. The proposed approach extracts the results from inter ensemble learning model and intra ensemble learning model. The experimental results clearly indicates that multimodal, multi-view and multitasking proposed framework provides an accuracy of 88.29% for the primary task of depression detection SVM linear kernel function. The stacking technique used here, provides the accuracy of 87.69% to detect depression using the proposed algorithm considering all the expressions of emoji and text combinations. © 2023, The Author(s) under exclusive licence to The Society for Reliability Engineering, Quality and Operations Management (SREQOM), India and The Division of Operation and Maintenance, Lulea University of Technology, Sweden.",TestAnalysis
"A systematic review and Bayesian sequential pair-wise meta-analyses were conducted to assess the efficacy of internal teat sealants (ITS) administered at dry-off in comparison to no treatment for preventing new intramammary infections (IMI) and clinical mastitis (CM) in dairy cattle. This work updated a previous systematic review and network meta-analysis conducted in 2019 but employed a narrowed scope and eligibility. The updated eligibility included studies that used ITS without concurrent therapy compared to a no treatment control (NTC), a study population of dairy cows or prepartum heifers, controlled trial design, and assessed one of the following outcomes: incidence of new IMI at calving or CM during the first 30 days in milk (DIM). Risk of bias was assessed through the Cochrane Risk of Bias 2.0 tool. Evidence quality was assessed using Grading of Recommendations Assessment, Development, and Evaluation (GRADE). There were 141 potentially relevant records identified from the updated search conducted on April 29, 2021, with a publication date restriction of 2018 or later; one study passed full-text screening and was included. Of the 32 studies included in the previous review, 12 studies were relevant after applying the modified eligibility criteria, totaling 13 studies included in this review (12 addressing IMI at calving outcome, 4 addressing CM at 30 DIM outcome). Sequential meta-analysis was conducted for both outcomes in R 3.6.0. Decisions for stopping were assessed at each analysis for intervention effect or futility in finding an effect based on a priori minimum clinically relevant values (ORδ =0.5, 0.75). ITS at dry-off significantly reduced odds of new IMI at calving compared to NTC at the second meta-analysis (OR2 =0.27, 95% CI=0.22–0.34), and onward (OR12 =0.29, 95% CI=0.27–0.32). For CM at 30 DIM, significance was reached at the second meta-analysis (OR2 =0.59, 95% CI=0.47–0.73), and onward (OR3 =0.47, 95% CI=0.42–0.51). Stopping for effect occurred at the second analysis in both outcomes and ORδs, but low-quality evidence and heterogeneity concerns were noted. A continuity-correction to include zero-event CM studies showed significance at the third meta-analysis (OR3 =0.79, 95% CI=0.73–0.86), stopping for effect at the fourth for ORδ = 0.75 (OR4 =0.77, 95% CI=0.72–0.83), and stopping for futility at the second for ORδ = 0.5 (OR2 =0.94, 95% CI=0.75–1.20), but the main CM analysis was considered more appropriate due to the sensitivity analysis’ very low-quality evidence assessment. Based on sequential evidence available, sufficient research currently exists for practical use, and cessation of future research until substantial changes to ITS application occur may be appropriate. © 2023",TestAnalysis
"Background: Peripherally inserted central catheter (PICC) is widely used in clinical practice because of its long retention time and easy maintenance. However, PICC-associated venous thromboembolism (VTE) is the most serious complication of PICC. Guidelines recommend exercise therapy to prevent PICC-associated VTE. However, inconsistent findings have been reported across the literature. This study conducted a meta-analysis to further evaluate the effect of exercise therapy on PICC-associated VTE. Methods: We searched CNKI, Wanfang database, Chinese Science and Technology Journal Full Text Database, PubMed, Embase, Web of Science and Cochrane Library databases and included all randomized controlled trials (RCTs) of exercise therapy for the prevention of PICC-associated VTE. Two investigators independently screened the literature, extracted information, and evaluated the risk of bias for eligible RCTs. Meta-analysis was conducted by RevMan5.4 software. Results: Eleven RCTs were included, including 1919 patients. Meta-analysis showed that the incidence of PICC-associated VTE was lower in the exercise therapy group than in the usual care group (RR = 0.30, 95% CI: 0.22–0.41, p < 0.00001).Exercise therapy increased the axillary vein maximum velocity (SMD = 0.93, 95% CI: 0.58–1.28, p < 0.00001) and the axillary vein time-mean flow velocity (SMD = 0.86, 95% CI: 0.53–1.20, p < 0.00001). Subgroup analysis showed statistically significant differences for the incidence of PICC-associated VTE for intervention times<4 weeks (RR = 0.26, 95% CI: 0.17–0.40, p < 0.00001) and intervention times≥4 weeks (RR = 0.35, 95% CI: 0.22–0.54, p < 0.00001). For axillary vein maximum velocity, the difference was statistically significant for both intervention time <4 weeks (SMD = 0.73, 95% CI: 0.55–0.91, p < 0.00001) and intervention time ≥4 weeks (SMD = 1.18, 95% CI: 0.18–2.19, p = 0.02). For axillary vein time-mean flow velocity, the intervention time <4 weeks (SMD = 0.75, 95% CI: 0.46–1.04, p < 0.00001), and the difference was statistically significant; while ≥4 weeks, the difference was not statistically significant (SMD = 1.14, 95% CI: −0.07 to 2.35, p = 0.06). Conclusions: Exercise therapy improved venous blood flow velocity and effectively reduced the incidence of PICC-associated VTE. However, RCTs with large samples and high quality are needed to further evaluate the effectiveness of exercise therapy in PICC patients. © The Author(s) 2023.",TestAnalysis
"At millimeter waves (MMW), the current state of research in computational dosimetry is mainly relying on flat-surface tissue-equivalent models to simplify the exposure assessment by disregarding geometrical irregularities characteristic of conformal surfaces on realistic models. However, this can lead to errors in estimation of dosimetric quantities on non-planar body parts with local curvature radii comparable to the wavelength of the incident field. In this study, we address this problem by developing an averaging technique for the assessment of the absorbed power density (Sab) on the anatomically-accurate electromagnetic (EM) model of the human ear. The dosimetric analysis is performed for the plane-wave exposure at 26 and 60 GHz, and the accuracy of the proposed method is verified by using two commercial EM software. Furthermore, we compare the two definitions of Sab provided in the international guidelines and standards for limiting exposure to EM fields above 6 GHz. Results show marginal relative differences between the obtained values from the two different definitions (within about 6 %) in all considered scenarios. On the other hand, in comparison to flat models, the spatial maximum Sab on the ear is up to about 20 % larger regardless of definition. These findings demonstrate a promising potential of the proposed method for the assessment of Sab on surfaces of anatomical models at frequencies upcoming for the 5th generation (5G) wireless networks and beyond. © 2016 IEEE.",TestAnalysis
"Purpose: Both women with breast cancer and their minor children were affected by a breast cancer diagnosis. The purpose of this review was to synthesize the evidence from qualitative studies on illness-related communication between mothers with breast cancer and their minor children from mothers’ perspectives. Methods: A thorough systematic review and meta-synthesis of qualitative studies was conducted. English articles published prior to 6 November 2021 were searched from five databases, including PubMed/ MEDLINE, EMBASE, Web of Science, CINAHL, and PsycINFO. After screening the titles, abstracts, and full texts, seven articles were finally included in the quality appraisal and meta-aggregation. Results: Four synthesized findings were derived from seven articles, including disclosure dilemma, factors impacting disclosure, methods of communication, and information needs. Conclusions: This systematic review offered insight into the communication between mothers with breast cancer and their minor children. Various factors influenced the decision-making process on illness-related disclosure, as well as the methods and contents of the communication. Future studies should be undertaken to explore the common model shared by mothers and children who have had comparable experiences, as well as to completely analyze the differences between different cultures in this topic. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TestAnalysis
"This paper explores the connections between the culture and living conditions of Afro-descendants in Colombian society. The specific object of study is Champeta, a Black urban music associated with social resistance. The text analyzes Champeta’s evolution in Colombia’s multicultural frame. It concludes with an analysis of these multicultural premises’ shortcomings, especially regarding the material improvement of Black Colombians’ living conditions. This text contributes to current debates on cultural diversity in Latin America. © 2023, The Author(s), under exclusive licence to Springer Nature B.V.",TestAnalysis
"The authors regret that an error has been made in our article regarding the reporting of results. All results (figures, tables and text) should have been reported as “per 10 °F increase in mean weekly temperature” and not as “per 1 °F increase in mean weekly temperature.” Authors deeply regret making this error. The authors would like to apologise for any inconvenience caused. © 2022 Elsevier Inc.",TestAnalysis
"This paper introduces AutoHTTP, a novel end-to-end trainable framework for detecting malicious HTTP traffic. It can automatically analyze plain-text network traffic data without any manual labor and present an interpretable detection report for better human understanding. The purpose of the framework is to detect malicious HTTP traffic by mining multi-field inexplicit semantic characteristics and correlation. To conquer the problems in reality, we first divide the multi-field plain-texts (e.g. user-agent, URL, method) into two types: R-field and S-field. Then, an elementary feature extraction module is proposed to turn these fields into a compact field representation. Finally, the field interactions and significant parts of different fields are simultaneously extracted by feeding the compact feature vector into a newly proposed attention and cross network, which couples two important components, the attention portion and the cross part. We show that the network offers strong interpretability and reliable results for further analysis. Extensive experiments on CTU-13, CICAndMal, and ISCX-URL datasets demonstrate that our approach outperforms existing methods based on manually-designed features and other auto-designed features. © 2022 Elsevier Ltd",TestAnalysis
"Background: Osteonecrosis of the femoral head (ONFH) is a devastating disease affecting young adults, resulting in significant pain, articular surface collapse, and disabling dysfunction. ONFH can be divided into two broad categories: traumatic and non-traumatic. It has been established that ONFH results from an inadequate blood supply that causes the death of osteocytes and bone marrow cells. Nonetheless, the precise mechanism of ONFH remains to be elucidated. In this regard, preclinical animal and cell models to study ONFH have been established to assess the efficacy of various modalities for preventing and treating ONFH. Nevertheless, it should be borne in mind that many models do not share the same physiologic and metabolic characteristics as humans. Therefore, it is necessary to establish a reproducible model that better mimics human disease. Methods: We systematically reviewed the literatures in regard to ONFH experimental models over the past 30 years. The search was performed in PubMed and Web of Science. Original animal, cell studies with available full-text were included. This review summarizes different methods for developing animal and cell experimental models of ONFH. The advantages, disadvantages and success rates of ONFH models are also discussed. Finally, we provide experimental ONFH model schemes as a reference. Results: According to the recent literatures, animal models of ONFH include traumatic, non-traumatic and traumatic combined with non-traumatic models. Most researchers prefer to use small animals to establish non-traumatic ONFH models. Indeed, small animal-based non-traumatic ONFH modeling can more easily meet ethical requirements with large samples. Otherwise, gradient concentration or a particular concentration of steroids to induce MSCs or EPCs, through which researchers can develop cell models to study ONFH. Conclusions: Glucocorticoids in combination with LPS to induce ONFH animal models, which can guarantee a success rate of more than 60% in large samples. Traumatic vascular deprivation combines with non-traumatic steroids to induce ONFH, obtaining success rates ranging from 80% to 100%. However, animals that undergo vascular deprivation surgery may not survive the glucocorticoid induction process. As for cell models, 10-6mol/L Dexamethasone (Dex) to treat bone marrow stem cells, which is optimal for establishing cell models to study ONFH. The translational potential of this article: This review aims to summarize recent development in experimental models of ONFH and recommended the modeling schemes to verify new models, mechanisms, drugs, surgeries, and biomaterials of ONFH to contribute to the prevention and treatment of ONFH. © 2023 The Authors",TestAnalysis
"Price forecasting is one of the fundamental techniques used in most businesses to improve the competitiveness and decision-making level. Nonetheless, it is a non-trivial task to make a model that provides high accuracy price prediction, especially in modern enterprises with ever longer, and more complex supply chains across the globe. In the classical approach for predictive problem, researchers applied the time series forecasting, but no decent outcome has been developed so far. This work suggests a new way to tackle this problem in the modern complex business world to predict the price of plastic resin by using the integration of textual information and numerical indicators input to deep learning models. Since the traditional methods which are based on historical price itself are not sufficient, external data like economic indicators or textual information gathered from news articles, can improve the performance of the models by catching the overall global economic sentiment. Word semantic is retrieved as a vector representation from pre-trained word embeddings called Global Vectors for Word Representation (GloVe). In addition, deep learning models have gained great attention in the past decade after showing promising performance in various applications including Natural Language Processing (NLP), computer vision, and voice recognition. Hence, deep learning models, Artificial Neural Network (ANN) and Recurrent Neural Network (RNN) are utilized in this research to deal with the complex and fluctuated price of plastic resin. The models’ performances are validated with root mean squared error metric. The training, validation, and test losses of ANN are between 100-200, 15-40, and 15-40, respectively. While the training, validation, and test losses of RNN are between 150-300, 40-70, and 40-70, respectively. Although the results show that RNN models perform a little poorer than ANN, both ANN and RNN show sufficient and satisfying result for plastic resin price prediction. This research also proposed new models designed to handle time series input data with a combination between textual and numerical data and contribute a new alternative strategy in petrochemical industries for more accurate price prediction which is the starting point for developing even more sophisticated and more accurate models in the future. ©2023 ICIC International.",TestAnalysis
"Aims: To provide the overall rate for all types of neurologic iatrogenic injuries during urogynaecologic surgery from textual data. Methods: Systematic research focused on complications of gynaecologic surgery and neurologic injuries in abstracts. Keywords concerning complications (cluster A), unspecific; neurologic issues (cluster B); surgery (generic words) (cluster C); specific gynaecologic operations (cluster D); and specific gynaecologic operations for pelvic organ prolapse and urinary incontinence (cluster E) were extracted. Associations among clusters of keywords were assessed by using multiple runs of text-mining software Semantic Brand Score (SBS, https://semanticbrandscore.com/#primary). Association scores were converted into probabilities. The rate of neurologic complications in urogynaecologic surgery was calculated (“a priori” probability) by applying Bayes' theorem. Textual estimates of neurological injuries in urogynaecologic surgery are 0.035554 (95% confidence intervals 0.019607−0.0515001; no quantitative data were found). To test if the probability calculated on textual information was the same as quantitative data reports (“a posteriori” probability), the rate of neurologic complication of all gynaecologic surgery was calculated using a meta-analytics approach and was compared with the textual analysis value. Results: The rate of neurologic complications in gynaecologic surgery after meta-analytic data synthesis has been 0.016489 (95% confidence intervals 0.012163−0.022320), which is equal to the textual estimate (0.016889, 95% confidence intervals 0.019607−0.051501). Therefore, 0.035554 is a reliable likelihood to observe a neurologic complication in urogynaecologic surgery. Conclusion: Iatrogenic nerve injuries in urogynaecologic surgery are higher than whole gynaecologic surgery. Text-mining software SBS and probability conversion can provide reliable answers from overall scholars' opinions on unsolved clinical questions when better evidence is lacking. © 2023 Wiley Periodicals LLC.",TestAnalysis
"Do Avicenna's extant works preserve any trace of his now-lost early philosophical production? This paper considers a hitherto neglected text, namely the chapter On Hypothetical Propositions from Avicenna's Concise Treatise on the Principles of Logic (Risāla mūÇ aza fī uá ūl al-maná iq, henceforth: RM). The new evidence offered by the RM chapter in question will lead to a different reading of another well-known passage of Avicenna's reworking of Aristotle's Prior Analytics (Qiyās) from the Book of Healing (Kitāb al-šifāÊ ). The clues gathered from an analysis of these two works will finally lead us to ponder the possibility that Avicenna may in fact have composed a (now lost) work on hypothetical propositions and syllogisms. Since Avicenna's RM is to date unedited, an edition, as well as an English translation of the relevant chapter, is also provided in the Appendix of this paper.  Copyright © The Author(s), 2023. Published by Cambridge University Press.",TestAnalysis
"Background and purpose: Peripheral neuropathy is one of the most prevalent and undesirable side effects of taxane-containing chemotherapy regimens. This study aimed to investigate the effect of acetyl-L-carnitine (ALC) on the prevention of taxane-induced neuropathy (TIN). Experimental approach: MEDLINE, PubMed, Cochrane Library, Embase, Web of Science, and Google scholar were systemically applied as electronic databases from 2010 to 2019. The current systematic review was carried out based on the main considerations of PRISMA preferential reporting items for systematic review and meta-analyses. Since there was no significant discrepancy, the random-effect model was used for 12-24 weeks' analysis (I 2 = 0%, P = 0.999). Findings/Results: Twelve related titles and abstracts were found during the search, 6 of them were excluded in the first phase. In the second phase, the full text of the remaining 6 articles was comprehensively evaluated and 3 papers were rejected. Finally, 3 articles complied with the inclusion criteria and pooled analyses. The meta-analysis showed a risk ratio of 0.796 (95% CI between 0.486 and 1.303), so, the effects model was used for 12-24 weeks' analysis (I 2 = 0%, P = 0.999) since no significant discrepancies were observed. There was no evidence of ALC's positive effect on the prevention of TIN during 12 weeks, and it was revealed that ALC significantly increased TIN in 24 weeks. Conclusion and implications: According to our findings, the hypothesis that ALC had a positive effect on preventing TIN in 12 weeks has not been proved; however, ALC led to an increase in the TIN in 24 weeks. © 2023 Wolters Kluwer Medknow Publications. All rights reserved.",TestAnalysis
"Purpose: In people with epilepsy achieving optimal dietary intake may be hampered by psychological and physical comorbidities associated with seizures, medication use, socioeconomic disadvantage and the use of therapeutic diets. This systematic review aimed to evaluate the reported dietary intake and nutritional status of children and adults with epilepsy. Methods: A systematic literature search was completed across Ovid MEDLINE, EMBASE and CINAHL (all from inception to 4 November 2021). We included studies that reported dietary intake in adults and children diagnosed with epilepsy compared with local reference ranges, control groups or general populations. Studies using interventions and therapeutic diets were excluded. Risk of bias was assessed using the Study Quality Assessment Tools by the National Heart, Lung and Blood Institute. A descriptive analysis was performed due to the heterogenous nature of the data. Results: The initial search returned 1214 articles. Full-text screening was completed for 98 studies and 19 studies met eligibility criteria and were included for extraction. These comprised of seven paediatric studies, eight adult studies and four studies that included both adult and paediatric cohorts. Sample size of cases in each study ranged from 17 to 3,220. Vitamin A, C, D and folate were the most frequently reported vitamins. Calcium, iron and zinc were the most commonly reported minerals. Most studies showed that people with epilepsy had poorer dietary intake and nutritional status compared with control groups or reference standards. Conclusion: There were limited studies on dietary intake and nutritional status in people with epilepsy. Most available studies suggested poorer status compared to non-epilepsy controls. The development of a validated dietary assessment tool specifically for epilepsy cohorts would enable comparison of findings across studies, and aid with appropriately tailoring nutrition advice to individuals with epilepsy. © 2023 Elsevier Inc.",TestAnalysis
"OBJECTIVE: Although cell-free DNA screening for sex chromosome abnormalities is increasingly used in clinical practice, its diagnostic accuracy and clinical utility remain unclear. This systematic review and meta-analysis aimed to determine the performance of cell-free DNA in the detection of sex chromosome abnormalities. DATA SOURCES: Medline and PubMed, Embase, and Web of Science were searched from inception to January 2022 for articles relating to cell-free DNA screening for sex chromosome abnormalities. STUDY ELIGIBILITY CRITERIA: Original articles, randomized control trials, conference abstracts, cohort and case-control studies, and case series with more than 10 cases with diagnostic confirmation were considered for inclusion. METHODS: Quality assessment of each included publication was performed using the Quality Assessment of Diagnostic Accuracy Studies 2 tool. The positive predictive value was calculated as the proportion of true positive cases among those who tested positive and underwent diagnostic testing. Sensitivity and specificity were pooled, and a summary receiver operating characteristic curve was produced using bivariate models that included studies that had diagnostic confirmation for high- and low-risk women. RESULTS: The search identified 7553 results. Of these, 380 proceeded to the full-text screening, of which 94 articles were included in the meta-analysis with a total of 1,531,240 women tested. All studies reported a confirmatory genetic test. The pooled positive predictive value was 49.4% (95% confidence interval, 45.8–53.1). The pooled positive predictive value was 32.0% (95% confidence interval, 27.0%–37.3%) for monosomy X, 67.6% (95% confidence interval, 62.5%–72.5%) for XXY, 57.5% (95% confidence interval, 51.7%–63.1%) for XXX, and 70.9% (95% confidence interval, 63.9%–77.1%) for XYY. The pooled sensitivity and specificity of cell-free DNA for sex chromosome abnormalities were 94.1% (95% confidence interval, 90.8%–96.3%) and 99.5% (95% confidence interval, 99.0%–99.7%), respectively, with an area under the summary receiver operating characteristic curve of 0.934 (95% confidence interval, 0.907–0.989). CONCLUSION: Although the sensitivity and specificity of cell-free DNA for sex chromosome abnormalities are high, the positive predictive value was approximately 50%. The positive predictive value was higher for sex chromosome abnormalities with a supernumerary Y chromosome and lower for monosomy X. Clinicians should inform couples about these findings when offering cell-free DNA for sex chromosome abnormalities. © 2022 Elsevier Inc.",TestAnalysis
"Purpose: We generated methods for evaluating clinical outcomes including treatment response in oncology using the unstructured data from electronic health records (EHR) in Japanese language. Methods: This retrospective analysis used medical record database and administrative data of University of Miyazaki Hospital in Japan of patients with lung/breast cancer. Treatment response (objective response [OR], stable disease [SD] or progressive disease [PD]) was adjudicated by two evaluators using clinicians’ progress notes, radiology reports and pathological reports of 15 patients with lung cancer (training data set). For assessing key terms to describe treatment response, natural language processing (NLP) rules were created from the texts identified by the evaluators and broken down by morphological analysis. The NLP rules were applied for assessing data of other 70 lung cancer and 30 breast cancer patients, who were not adjudicated, to examine if any difference in using key terms exist between these patients. Results: A total of 2,039 records in progress notes, 131 in radiology reports and 60 in pathological reports of 15 patients, were adjudicated. Progress notes were the most common primary source data for treatment assessment (60.7%), wherein, the most common key terms with high sensitivity and specificity to describe OR were “reduction/shrink”, for SD were “(no) remarkable change/(no) aggravation)” and for PD were “(limited) effect” and “enlargement/grow”. These key terms were also found in other larger cohorts of 70 patients with lung cancer and 30 patients with breast cancer. Conclusion: This study demonstrated that assessing response to anticancer therapy using Japanese EHRs is feasible by interpreting progress notes, radiology reports and Japanese key terms using NLP. © 2023, The Author(s).",TestAnalysis
"Background: External ventricular drain (EVD) insertion is often a lifesaving procedure frequently used in neurosurgical emergencies. It is routinely done at the bedside in the neurocritical care unit or in the emergency room. However, there are infectious and noninfectious complications associated with this procedure. This meta-analysis sought to evaluate the absolute risk associated with EVD hemorrhages, infections, and revisions. The secondary purpose was to identify and characterize risk factors for EVD complications. Methods: We searched the MEDLINE (PubMed) database for “external ventricular drain,” “external ventricular drain” + “complications” or “Hemorrhage” or “Infection” or “Revision” irrespective of publication year. Estimates from individual studies were combined using a random effects model, and 95% confidence intervals (CIs) were calculated with maximum likelihood specification. To investigate heterogeneity, the t2 and I2 tests were utilized. To evaluate for publication bias, a funnel plot was developed. Results: There were 260 total studies screened from our PubMed literature database search, with 176 studies selected for full-text review, and all of these 176 studies were included in the meta-analysis as they met the inclusion criteria. A total of 132,128 EVD insertions were reported, with a total of 130,609 participants having at least one EVD inserted. The pooled absolute risk (risk difference) and percentage of the total variability due to true heterogeneity (I2) for hemorrhagic complication was 1236/10,203 (risk difference: −0.63; 95% CI: −0.66 to −0.60; I2: 97.8%), infectious complication was 7278/125,909 (risk difference: −0.65; 95% CI: −0.67 to −0.64; I2: 99.7%), and EVD revision was 674/4416 (risk difference: −0.58; 95% CI: −0.65 to −0.51; I2: 98.5%). On funnel plot analysis, we had a variety of symmetrical plots, and asymmetrical plots, suggesting no bias in larger studies, and the lack of positive effects/methodological quality in smaller studies. Conclusions: In conclusion, these findings provide valuable information regarding the safety of one of the most important and most common neurosurgical procedures, EVD insertion. Implementing best-practice standards is recommended in order to reduce EVD-related complications. There is a need for more in-depth research into the independent risk factors associated with these complications, as well as confirmation of these findings by well-structured prospective studies. © 2022 Elsevier Inc.",TestAnalysis
"Purpose:""Spin"" refers to a form of language manipulation that positively reflects negative findings or downplays potential harms. Spin has been reported in randomized controlled trials of other surgical specialties, which can lead to the recommendation of subpar or ineffective treatments. The goal of this study was to characterize spin strategies and severity in statistically nonsignificant urology randomized controlled trials.Materials and Methods:A comprehensive search of MEDLINE and Embase for the top 5 urology journals, major urology subspecialty journals, and high-impact nonurology journals from 2019 to 2021 was conducted. Statistically nonsignificant randomized controlled trials with a defined primary outcome were included. Screening, data extraction, and spin assessment were performed in duplicate by 2 independent reviewers.Results:From the database search of 4,339 studies, 46 trials were included for analysis. Spin was identified in 35 studies (76%), with the majority of abstracts (n = 26, 57%) and main texts (n = 35, 76%) containing some level of spin. ""Obscuring the statistical nonsignificance of the primary outcome and focusing on statistically significant secondary results"" was the most frequently used strategy in abstracts, while ""other"" strategies not previously defined were the most commonly used strategies in main texts. Moderate or high spin severity was identified in 21 (46%) abstract and 22 (48%) main text conclusions.Conclusions:Overall, our results suggest that 76% of statistically nonsignificant urology randomized controlled trials contained some level of spin. Readers and writers should be aware of common spin strategies when interpreting nonsignificant results and critically appraise the significance of results when making decisions for clinical practice. © 2023 Lippincott Williams and Wilkins. All rights reserved.",TestAnalysis
"Objectives: Major observational studies report that the mortality rate of acute respiratory distress syndrome (ARDS) is close to 40%. Different treatment strategies are required for each patient, according to the degree of ARDS. Early prediction of ARDS is helpful to implement targeted drug therapy and mechanical ventilation strategies for patients with different degrees of potential ARDS. In this paper, a new dynamic prediction machine learning model for ARDS incidence and severity is established and evaluated based on 28 parameters from ordinary monitors and ventilators, capable of dynamic prediction of the incidence and severity of ARDS. This new method is expected to meet the clinical practice requirements of user-friendliness and timeliness for wider application. Methods: A total of 4738 hospitalized patients who required ICU care from 159 hospitals are employed in this study. The models are trained by standardized data from electronic medical records. There are 28 structured, continuous non-invasive parameters that are recorded every hour. Seven machine learning models using only continuous, non-invasive parameters are developed for dynamic prediction and compared with methods trained by complete parameters and the traditional risk adjustment method (i.e., oxygenation saturation index method). Results: The optimal prediction performance (area under the curve) of the ARDS incidence and severity prediction models built using continuous noninvasive parameters reached0.8691 and 0.7765, respectively. In terms of mild and severe ARDS prediction, the AUC values are both above 0.85. The performance of the model using only continuous non-invasive parameters have an AUC of 0.0133 lower, in comparison with that employing a complete feature set, including continuous non-invasive parameters, demographic information, laboratory parameters and clinical natural language text. Conclusions: A machine learning method was developed in this study using only continuous non-invasive parameters for ARDS incidence and severity prediction. Because the continuous non-invasive parameters can be easily obtained from ordinary monitors and ventilators, the method presented in this study is friendly and convenient to use. It is expected to be applied in pre-hospital setting for early ARDS warning. © 2022",TestAnalysis
"The celebrated proverb that “speech is silver, silence is golden” has a long multinational history and multiple specific meanings. In written texts punctuation can be considered one of its manifestations. Indeed, the virtue of effectively speaking and writing involves – often decisively – the capacity to apply the properly placed breaks. In the present study, based on a large corpus of world-famous and representative literary texts in seven major Western languages, it is shown that the distribution of intervals between consecutive punctuation marks can almost universally be characterized by only two parameters of the discrete Weibull distribution which can be given an intuitive interpretation in terms of the so-called hazard function. The values of these two parameters tend to be language-specific, however, and even appear to navigate translations. The properties of the computed hazard functions indicate that among the studied languages, English appears the least constrained by the necessity to place a consecutive punctuation mark to partition a sequence of words. Spanish reveals a similar tendency. The above characteristics manifest themselves when all consecutive punctuation marks are considered and not the sentence-ending ones only, and this fact is in accordance with the Detrended Fluctuation Analysis of intervals between the corresponding breaks. © 2023 Elsevier Ltd",TestAnalysis
"This review aimed to update the clinical practice guidelines for managing adults with 22q11.2 deletion syndrome (22q11.2DS). The 22q11.2 Society recruited expert clinicians worldwide to revise the original clinical practice guidelines for adults in a stepwise process according to best practices: (1) a systematic literature search (1992-2021), (2) study selection and synthesis by clinical experts from 8 countries, covering 24 subspecialties, and (3) formulation of consensus recommendations based on the literature and further shaped by patient advocate survey results. Of 2441 22q11.2DS-relevant publications initially identified, 2344 received full-text review, with 2318 meeting inclusion criteria (clinical care relevance to 22q11.2DS) including 894 with potential relevance to adults. The evidence base remains limited. Thus multidisciplinary recommendations represent statements of current best practice for this evolving field, informed by the available literature. These recommendations provide guidance for the recognition, evaluation, surveillance, and management of the many emerging and chronic 22q11.2DS-associated multisystem morbidities relevant to adults. The recommendations also address key genetic counseling and psychosocial considerations for the increasing numbers of adults with this complex condition. © 2023 The Authors",TestAnalysis
"Background: Unnecessary electronic health record (EHRs) documentation burden and usability issues have negatively impacted clinician well-being (e.g., burnout and moral distress). Purpose: This scoping review was conducted by members from three expert panels of the American Academy of Nurses to generate consensus on the evidence of both positive and negative impact of EHRs on clinicians. Methods: The scoping review was conducted based on Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) Extension for Scoping Reviews guidelines. Results: The scoping review captured 1,886 publications screened against title and abstract 1,431 excluded, examined 448 in a full-text review, excluded 347 with 101 studies informing the final review. Discussion: Findings suggest few studies that have explored the positive impact of EHRs and more studies that have explored the clinician's satisfaction and work burden. Significant gaps were identified in associating distress to use of EHRs and minimal studies on EHRs’ impact on nurses. Conclusion: Examined the evidence of HIT's positive and negative impacts on clinician's practice, clinicians work environment, and if psychological impact differed among clinicians. © 2023 The Author(s)",TestAnalysis
"The Himalayan orogeny is among the youngest mountain belts on the earth’s surface. The dynamic landscape of the Himalaya accommodates plentiful eminent geological–geomorphological–heritage sites. The present study assesses a hermit cave system at Lakhamandal valley, located in the Yamuna River basin, Northwest Himalaya. The valley is filled with valley-fill deposits, including a hermit cave complex excavated by sages and local people of the valley. This hermit cave complex is extended between the different terrace levels, one or/and two-story structures carved in the quaternary sediments with a slight opening. Throughout history, the Lakhamandal valley has been located near a pilgrimage route famously known for its cultural and historical significance reflected in many historical texts of the Indian subcontinent. In the last few decades, the growing infrastructure in the valley has drawn local and international tourists leading to multiple unorganised excavations of the hermit caves in the region. To recognise such a remarkable geological and historical feature, we introduce the Lakhamandal valley hermit cave complex geosite with a preliminary assessment with SWOT analysis augmenting with urgent concerns and recommendations further aiming at its validation for a geoheritage site. © 2023, The Author(s), under exclusive licence to International Association for the Conservation of Geological Heritage.",TestAnalysis
"This paper investigates how the reader of prose fiction fills in the blanks regarding a fictional character’s membership category, action, and reason for the action. Aligning with an ethnomethodological approach to texts and appropriating membership categorization analysis (MCA), we analyze how the readers of J. D. Salinger, an author whose works are well known for their ambiguity and ambivalence, would grasp the unwritten identities of characters and the meanings of their actions. Our analysis specifies two types of methods deployed for the reader to understand the fictional texts. First, in an at-a-glance way, the reader can supply the missing categories and sequence of actions by turning to the commonsense knowledge and social norms regarding the association between the category and the activity. Second, the reader can construct various interpretations regarding the recognizably ambiguous scenes of the text by turning to the conceptual knowledge of the relevant social phenomena, the maxims specific to the act of storytelling, and the writer’s techniques peculiar to the fictional texts. The findings demonstrate the vast applicability of an MCA approach to the analysis of the work of reading prose fiction and shed light on the detailed operations of the author’s maxims and techniques in the textual configuration of prose fiction, thereby indicating the possibility of ethnomethodological analysis including the interwoven consideration of the reader’s activity and the textual organization. © 2022, The Author(s).",TestAnalysis
"Introduction: Counseling on the immediate postoperative experience for outpatient procedures is largely based on anecdotal experience. We devised a short messaging service (SMS) survey using mobile phone text messages to evaluate real-time patient recovery following outpatient thyroid or parathyroid surgery. Materials and methods: Daily automated SMS surveys were sent the evening of the operation until postoperative day 10. Pain, opioid use, voice quality, and energy levels were assessed. Impaired voice and energy was defined as a score < 2/3 of normal. Results: One hundred fifty five patients were enrolled with an overall response rate of 81.6%. One hundred thirty three patients had an individual response rate > 50% and were included in the final analysis. Median patient age was 60 y with 102 females (76.7%). Seventy patients (52.6%) underwent parathyroidectomy and 66 (49.6%) thyroidectomy and 10 (7.5%) neck dissection. Forty eight patients (36.1%) did not use any opioids postoperatively. Independent risk factors for higher total pain scores included thyroidectomy and patients with preoperative opioid or tobacco use, while increased opioid use was associated with age < 60 y, body mass index > 30 kg/m2, preoperative opioid or tobacco use, and history of anxiety or depression. Patients with loss of intraoperative recurrent laryngeal nerve signaling had a significantly worse overall voice score (54.65 versus 92.67, P < 0.001). Up to 10% of patients were still using opioids and/or reported impaired voice and energy levels beyond 1 wk postoperatively. Conclusions: Real-time SMS survey is an effective and potentially valuable way to monitor patient recovery following surgery. A subset of patients reported impaired voice and energy and was still using opioids beyond 1 wk after thyroid and parathyroid surgery and these patients may benefit from closer follow-up and earlier intervention. © 2022 Elsevier Inc.",TestAnalysis
"Multimodal sentiment analysis aims to judge the sentiment of multimodal data uploaded by the Internet users on various social media platforms. On one hand, existing studies focus on the fusion mechanism of multimodal data such as text, audio and visual, but ignore the similarity of text and audio, text and visual, and the heterogeneity of audio and visual, resulting in deviation of sentiment analysis. On the other hand, multimodal data brings noise irrelevant to sentiment analysis, which affects the effectness of fusion. In this paper, we propose a Polar-Vector and Strength-Vector mixer model called PS-Mixer, which is based on MLP-Mixer, to achieve better communication between different modal data for multimodal sentiment analysis. Specifically, we design a Polar-Vector (PV) and a Strength-Vector (SV) for judging the polar and strength of sentiment separately. PV is obtained from the communication of text and visual features to decide the sentiment that is positive, negative, or neutral sentiment. SV is gained from the communication between the text and audio features to analyze the sentiment strength in the range of 0 to 3. Furthermore, we devise an MLP-Communication module (MLP-C) composed of several fully connected layers and activation functions to make the different modal features fully interact in both the horizontal and the vertical directions, which is a novel attempt to use MLP for multimodal information communication. Finally, we mix PV and SV to obtain a fusion vector to judge the sentiment state. The proposed PS-Mixer is tested on two publicly available datasets, CMU-MOSEI and CMU-MOSI, which achieves the state-of-the-art (SOTA) performance on CMU-MOSEI compared with baseline methods. The codes are available at: https://github.com/metaphysicser/PS-Mixer. © 2022 Elsevier Ltd",TestAnalysis
"Individuals with an Eating Disorder (ED) are typically reluctant to seek help via traditional means (e.g., psychologists). However, recent evidence suggests that many individuals seek assistance via social media for weight and diet related concerns. Sophisticated approaches are needed to better distinguish those who may be in need of help for an ED from those who are simply commenting on ED in online social environments. In order to facilitate effective communication between individuals with or at-risk of an ED and healthcare professionals, this research exploits a deep learning model to differentiate the users with ED engagement (e.g., ED sufferers, healthcare professionals or communicators) over social media. For this purpose, a collection of Twitter data is compiled using Twitter application programming interface (API) on the Australian Research Data Commons (ARDC) Nectar research cloud. After collecting 1,400,000 Twitter biographies in total, a subset of 4000 biographies are annotated manually. This annotation enables the differentiation of users engaged with ED-focused language on social media into five categories: ED-user, healthcare professional, communicator, healthcare professional-communicator, and other. Based on these annotated categories, a predictive deep learning model based on bidirectional encoder representations from transformers (BERT) and long short-term memory (LSTM) is developed. The model achieves an F1 score of 98.19% and an accuracy of 98.37%. It demonstrates the viability of detecting the individuals with possible ED risk and distinguishes them from other categories using their biography data. We further conducted a network analysis for investigating the communication network between these categories. Our analysis shows that ED-users are more secretive and self-protective, whereas the healthcare professionals and communicators frequently interact with each other and a wide range of other people. To the best of our knowledge, our research is the first of its kind for identifying the different user categories engaged with ED-focused communications on social media. © 2022",TestAnalysis
"Isotope dilution (ID) is a widely used analytical technique to determine elemental abundance to a high degree of accuracy and precision, using a spiked isotope tracer. This technique also enables efficient correction of the inevitable phenomenon of analytical mass fractionation during mass spectrometric analysis. It is also used to determine stable isotope variations of an element in a sample relative to a reference material, using tracers enriched in two isotopes (popularly known as the double spike method). Isotope dilution data reduction can be performed in Microsoft® Excel™ using different algorithmic approaches. Additional software such as iolite and MATLAB® offer algorithm implementations to perform these calculations. These are however limited to use within particular laboratories/research groups, or either require additional cost-bound software or some degree of knowledge in computer programming languages for use, or all of these. To ease this situation, a graphical user interface-based software is proposed (here named Parmanu-Gunak, meaning Atom-Calculator in Sanskrit text) to invert both single and double spiked isotope data, with the aim of making it a standard tool for ID data reduction. Examples of Nd and Mo isotopes are used to demonstrate the robustness of the program. © 2022 The Author. Geostandards and Geoanalytical Research © 2022 International Association of Geoanalysts.",TestAnalysis
"Unfortunately, some of the texts were missed in the online published article. The missing texts are given below. The original article has been corrected. © Geologische Vereinigung e.V. (GV) 2022.",TestAnalysis
"With the miniaturization of printed circuit board (PCB), the distance between the circuit traces or assembled component terminals is becoming smaller and smaller. Under the certain temperature, relative humidity, and bias voltage (THB), it is easier for the insulation performance between circuits to degrade due to electrochemical migration (ECM). The airborne dust deposited on the PCB during a long-term service may change the failure mechanism and time to failure (TTF) of ECM between circuits. In this paper, the mechanism and the characteristics of the combined effects of quartz particles in airborne dust, the temperature, the relative humidity and the bias voltage on the ECM failure of immersion silver finished PCB were studied by THB experiments. Then, the influencing significance of four factors on TTF of ECM were studied by the orthogonal test and range analysis. The results show that the silver cations migrate firstly but the exposed copper substrate on the positive electrode become the main migrated substance finally. The TTF of ECM changes non-monotonously with the increase of particle coverage density due to the bidirectional function of the insoluble particles, which can increase water condensation on PCB by the capillary action, but can extend the migration path of metal cations by physical barriers. The turning point is about the coverage density of $350~\mu \text{g}$ /cm 2. The insoluble particles with high coverage density can significantly shorten the TTF of ECM on the PCB than that with low coverage density under the same THB conditions.  © 2001-2011 IEEE.",TestAnalysis
"Purpose: To review the literature on the efficacy of surgical procedures to improve visual acuity (VA) in patients with infantile nystagmus syndrome (INS). Methods: Literature searches were last conducted in January 2022 in the PubMed database for English-language studies with no date restrictions. The combined searches yielded 354 abstracts, of which 46 were reviewed in full text. Twenty-three of these were considered appropriate for inclusion in this assessment and were assigned a level of evidence rating by the panel methodologist. Results: One included study was a randomized trial; the remaining 22 were case series. The 23 studies included children and adults with INS and a variable proportion with anomalous head position (AHP), strabismus, and sensory diagnoses. The surgical interventions evaluated included large recessions, tenotomy and reattachment (TAR), myectomy with or without pulley fixation, and anterior extirpation of the 4 horizontal rectus muscles, as well as various procedures to correct an AHP in which VA was reported as a secondary outcome. The data were mixed, with improvements in binocular best-corrected visual acuity (BCVA) ranging from no improvement to 0.3 logarithm of the minimum angle of resolution (logMAR), or 3 lines. (Most studies were in the range of 0.05–0.2 logMAR.) Statistically significant improvement in VA was noted in 12 of 16 studies (75%) that performed statistical analyses, with no clear advantage of any single procedure. Complications and reoperations were lowest in patients who underwent TAR and highest in those who underwent myectomy or anterior extirpation. Conclusions: The best available evidence suggests that eye muscle surgery in patients with INS results in a modest improvement in VA. Financial Disclosure(s): Proprietary or commercial disclosure may be found after the references. © 2022 American Academy of Ophthalmology",TestAnalysis
"Using text mining and semantic network analysis, this study analyzed the job descriptions of 34,787 positions about media analytics from Indeed.com to compare how the in-person and remote jobs differ to inform educators about integrating analytics in the media and communications curriculum. We found that the in-person positions emphasized more on the skills of verbal, interpersonal, and organizational communication, whereas the remote positions asked more for written communication. While the in-person positions had higher expectations of using general data management and analysis tools, the remote positions emphasized more on the use of social media analytics and digital marketing tools. © AEJMC 2022.",TestAnalysis
"Background: Virtual Reality (VR) is becoming a popular educational tool in healthcare. This scoping review aimed to (1) determine if VR can be used to reduce the anxiety a patient experiences during an MRI and (2) explore how VR is being used to train MRI technologists. Methods: PubMed, Web of Science, Cochrane Library, CINAHEL, and PsycINFO internet websites of VR in MRI were evaluated. Two authors independently reviewed the titles and abstracts using the inclusion and exclusion criteria. Articles chosen by both reviewers were automatically included for full text review. Articles chosen by one reviewer were audited by a third independent reviewer to determine inclusion for full text review. Descriptive analyses were conducted. Results: The initial search resulted in 357 articles. A large portion of the articles were excluded because they were either based on fMRI or training-based tools for healthcare professionals, which were not our area of focus. Eight articles were included in the final review for assessing if VR can be a useful tool to aid with patient anxiety in MRI. No articles were found that used VR in MRI technologist training. Conclusions: This scoping review suggests there are potentially significant uses for VR in reducing anxiety in adults and children as patients. With further research and development of VR application for use with MRI testing may allow for better patient preparation and reduce scan interruptions, increase MRI operational efficiency, and improve patient outcomes © 2022",TestAnalysis
"Over two million people depend on the Sundarbans for direct or indirect subsistence. Most of the poor and resource-dependent populations rely significantly on fishing for their subsistence in the absence of alternative work and income possibilities. Various global conventions impact national policy, putting pressure on state forest officials to maintain the Sundarbans in order to protect the flagship faunal species, the Royal Bengal tiger, and the pristine ecology. This article examines how the limits imposed on the Sundarbans to protect its biodiversity have affected fishermen's access to forest resources, as well as how the locals have reacted to these constraints in order to maintain their way of life. Given the paucity of research on the subject, we anticipate that the findings of this study will be practical and beneficial to policymakers and practitioners alike. Interviews with key informants, stakeholder input in the form of focus group discussions, documentary research (news reports and government documents), and uncontrolled personal observation were the primary empirical data gathering methods using a semi-structured questionnaire. Inductive contentment analysis was used to examine data with NVivo 12 software. Consequently, the text is organized around four thematic focuses. It begins with a brief history of forest management from the viewpoint of fisheries to demonstrate how the state's intervention to limit local access to fisheries resources exacerbated the socioeconomic vulnerabilities of the local populace. The second piece explores conventional fishing activities in the Sundarbans, while the third section investigates the fishing community's response to the imposed restriction. We discovered that the restrictions imposed to ensure conservation had a severe impact on the livelihood of locals, resulting in unsustainable fishing in the Sundarbans through the adoption of a negotiated system between the forest department and fishermen, i.e., corruption. In Section 4, the article wraps up by discussing a few crucial ideas that can be used to address issues brought on by restrictions. © 2022",TestAnalysis
"Polycystic ovary syndrome (PCOS) is one of the most common endocrine disorders around the world that can endanger reproductive, metabolic, and psychological health in women. Flaxseed is considered as a functional food which provides remarkable amounts of α-linolenic acid (ALA), phytosterogenic lignans, and dietary fibers. This study aimed to investigate the effectiveness of flaxseed or its oil supplementation on PCOS patients. We systematically searched all published randomized clinical trials indexed in PubMed, Scopus, and Google Scholar databases from inception up to May 2022. Intended exposure and outcome were flaxseed or its oil and metabolic, anthropometric, and hormonal status of women with PCOS, respectively. Initial search via related keywords revealed 69 articles. After excluding duplicates, title and abstract of 55 remaining papers were screened. Fourteen papers were obtained for full text screening. Finally, nine clinical trials published between 2011 and 2021 were included in qualitative synthesis. Based on the results of the present systematic review, we suggest that flaxseed supplementation has the potential to improve metabolic, hormonal, and anthropometric parameters in women with PCOS. However, we also deduce that due to the scarcity of high-quality studies, additional studies need to be conducted in order to derive a solid conclusion. © 2022 John Wiley & Sons Ltd.",TestAnalysis
"Objective: To explore the experiences, information and support needs of parents/caregivers of children with cancer and how these changed as the COVID-19 pandemic evolved. Design Online surveys containing closed and free-text questions on experiences, information and support needs were completed at four time points (between April 2020 and October 2021) during the COVID-19 pandemic. Descriptive statistics of closed items and content analysis of qualitative data were conducted. Setting Online. Participants Parents/caregivers of children with cancer. Results: 335 parents/caregivers completed the survey over four time points. Findings revealed that parents'/caregivers' worry about the virus and vigilance about their child's virus symptoms decreased over time. Parents reporting the need for support on how to reduce their worries and/or family members during the virus outbreak were low, however parents reported a slight increase in need for support at T3 when schools reopened. Qualitative findings reported the following themes: (1) Psychological well-being of parents/caregivers, (2) Changing perceptions of risks/priorities, (3) Adjusting to COVID-19: Living with continued caution, (4) Healthcare and treatment provision, (5) Information seeking and needs during COVID-19. Conclusions: The COVID-19 pandemic disrupted people's lives and routines in relation to access to support, finances, education and social lives, leading to psychological distress. Parents highlighted the need for timely, up-to-date and personalised information in relation to COVID-19 and their child with cancer. Further consideration of the development of technology-based health solutions may provide an efficient and safe way to connect with and support parent/caregivers.  © 2023 Author(s) (or their employer(s)).",TestAnalysis
"Over the last 25 years, the BRICs asserted themselves as drivers of globalization. But what does their new-found prominence mean for working conditions at home? Using a novel sub-national database covering outward investment linkages and working conditions in Brazilian municipalities, this study tests whether a direct investment in Europe leads to the introduction of decent working conditions in Brazil. The empirical results provide strong support for the investing-up effect using a mixture of panel data analysis and text analysis. The results suggest that economic integration with high-standard developed countries can act as a powerful mechanism for labor standard improvements in developing countries. © 2022 The Authors. LABOUR published by Fondazione Giacomo Brodolini and John Wiley & Sons Ltd.",TestAnalysis
"Corporate social responsibility, and its other conceptual variants such as corporate sustainability, encourages businesses to act on a range of issues outside what the law and shareholders require. But what are the limits of the concept and its discursive practices in a globalizing world marked by accentuated asymmetrical power relations between businesses, and the communities they operate in and serve (especially corporations working in less powerful global peripheries), and the regulators who are expected to police them? This study uses the discourse-historical approach (DHA) and corporate sustainability framework (CSF) to analyze a British independent oil production firm's—Tullow—communication. It illustrates the utility of the DHA and the CSF for doing critical stakeholder and issues analysis from corporate communication texts. Second, it argues that corporate sustainability illustrates the power asymmetry between the global and local, corporations and community. Specifically, we observe how a petroleum firm uses sustainability discourse, as a form of hegemonic globalization, to perpetuate dominant tropes and conceptions about African local communities as homogeneous and lacking agency, commodifying the lived experiences of the locals in the process while entrenching the superiority of the firm's own position as a ‘benevolent dictator.’ We also illustrate how particular mitigation and intensification discourse techniques are employed to uphold Tullow as a ‘do-good’ actor. The corporation's discursive strategies have a cumulative effect of cementing the power asymmetry that already exists between the firm as an agent of a dominant center of global power and Ghanaian communities as less powerful interests in the globalization process. Suggestions for disrupting the hegemony are provided. © 2022 Elsevier Inc.",TestAnalysis
"Invasion by exotic pests into new geographic areas can cause major disturbances in forest and agricultural systems. Early response can greatly improve containment efforts, underscoring the importance of collecting up-to-date information about the locations where pest species are being observed. However, existing invasive species databases have limitations in both extent and rapidity. The spatial extent is limited by costs and there are delays between species establishment, official recording, and consolidation. Local online news outlets have the potential to provide supplemental spatial coverage worldwide and social media has the potential to provide direct observations and denser historical data for modeling. Gathering data from these online sources presents its own challenges and their potential contribution to historical tracking of pest invasions has not previously been tested. To this end, we examine the practical considerations for using three online aggregators, the Global Database of Events, Language and Tone (GDELT), Google News, and a commercial media listening platform, Brandwatch, to support pest biosurveillance. Using these tools, we investigate the presence and nature of cogent mentions of invasive species in these sources by conducting case studies of online news and Twitter excerpts regarding two invasive plant pests, Spotted Lanternfly and Tuta absoluta. Our results using past data demonstrate that online news and social media may provide valuable data streams to supplement official sources describing pest invasions. © 2022",TestAnalysis
"Released 4 years ago, the Wallace EcoMod application (R package wallace) provided an open-source and interactive platform for modeling species niches and distributions that served as a reproducible toolbox and educational resource. wallace harnesses R package tools documented in the literature and makes them available via a graphical user interface that runs analyses and returns code to document and reproduce them. Since its release, feedback from users and partners helped identify key areas for advancement, leading to the development of wallace 2. Following the vision of growth by community expansion, the core development team engaged with collaborators and undertook a major restructuring of the application to enable: simplified addition of custom modules to expand methodological options, analyses for multiple species in the same session, improved metadata features, new database connections, and saving/loading sessions. wallace 2 features nine new modules and added functionalities that facilitate data acquisition from climate-simulation, botanical and paleontological databases; custom data inputs; model metadata tracking; and citations for R packages used (to promote documentation and give credit to developers). Three of these modules compose a new component for environmental space analyses (e.g., niche overlap). This expansion was paired with outreach to the biogeography and biodiversity communities, including international presentations and workshops that take advantage of the software's extensive guidance text. Additionally, the advances extend accessibility with a cloud-computing implementation and include a suite of comprehensive unit tests. The features in wallace 2 greatly improve its expandability, breadth of analyses, and reproducibility options, including the use of emerging metadata standards. The new architecture serves as an example for other modular software, especially those developed using the rapidly proliferating R package shiny, by showcasing straightforward module ingestion and unit testing. Importantly, wallace 2 sets the stage for future expansions, including those enabling biodiversity estimation and threat assessments for conservation. © 2023 The Authors. Ecography published by John Wiley & Sons Ltd on behalf of Nordic Society Oikos.",TestAnalysis
"The publisher regrets the following conflict of interest text was not published. • The author of this paper is responsible for conception or design of the work; or the acquisition, analysis, or interpretation of data for the work; AND Drafting the work or revising it critically for important intellectual content; AND Final approval of the version to be published. • I also undertake that the article represents valid work. Neither this article nor any part of it has been copied or plagiarized from other works. • That the article has not been published so far OR communicated OR in simultaneous consideration to some other journal. • I also undertake that the authors have disclosed all potential conflict of interests associated with the work. The publisher would like to apologise for any inconvenience caused. © 2022 The Author(s)",TestAnalysis
"The issue of no-shows in radiology is complicated and challenging. Mammography and ultrasound have the highest rate of no-shows among radiologic exams. Screening mammography is one of the most cost-effective ways to reduce breast cancer related deaths. However, the benefit of screening is heavily dependent on patient compliance to routine exams. Enhancing patients’ commitments to their scheduled appointments, thereby improving early detection and decreasing breast cancer related mortality. Retrospective analysis of no-show visits scheduled from August 2017 to December 2017 (before the implementation of combined phone, email and text-based reminders) and from August 2019 to December 2019 (after the implementation of reminder and follow-up phone calls after missed appointments by the coordinator) in an urban academic breast imaging center was conducted. There were 368 no-show patients in 2017 and 238 no-show patients in 2019. Percentage of no-shows, and delay time to the rescheduled missed appointment were calculated. Subgroup analysis of the type of studies that were missed and those who did not reschedule the missed appointment was conducted. Mann Whitney U test was used to analyze differences between group means. No-show visits decreased by 50% in 2019 when compared to 2017. The average wait time between the missed appointment and the rescheduled appointment decreased significantly from 30.7 weeks in 2017 to 12.1 weeks in 2019 (P = 0.047). The percentage of no-show visits was highest among the unemployed, patients scheduled for screening mammograms and patients with a high average of no-show visits. No-show visits adversely impact patient outcome and contribute to increased cost of healthcare. Through a deeper understanding of the factors contributing to no-shows, we can strive to make appropriate interventions to alleviate the consequences of no-shows. © 2022",TestAnalysis
"The publisher regrets the following conflict of interest text was not published. • All the authors listed in this article have made Substantial contributions to the conception or design of the work; or the acquisition, analysis, or interpretation of data for the work; AND Drafting the work or revising it critically for important intellectual content; AND Final approval of the version to be published. • I also undertake that the article represents valid work. Neither this article nor any part of it has been copied or plagiarized from other works. • That the article has not been published so far OR communicated OR in simultaneous consideration to some other journal. • I also undertake that the authors have disclosed all potential conflict of interests associated with the work. The publisher would like to apologise for any inconvenience caused. © 2022",TestAnalysis
"The publisher regrets the following conflict of interest text was not published. • All the authors listed in this article have made Substantial contributions to the conception or design of the work; or the acquisition, analysis, or interpretation of data for the work; AND Drafting the work or revising it critically for important intellectual content; AND Final approval of the version to be published. • I also undertake that the article represents valid work. Neither this article nor any part of it has been copied or plagiarized from other works. • That the article has not been published so far OR communicated OR in simultaneous consideration to some other journal. • I also undertake that the authors have disclosed all potential conflict of interests associated with the work. The publisher would like to apologise for any inconvenience caused. © 2022 The Author(s)",TestAnalysis
"Objective: The aim of this study was to examine women's experience of menopausal transition and their expectations and wishes for support from healthcare. Further, to examine their knowledge about menopause and thoughts about current attitudes in healthcare and in society generally. Methods: Data was collected through three focus group interviews with 14 women experiencing menopausal symptoms. The qualitative analysis was transacted through systematic text condensation, where categories were derived from data. Results: The women in this study told us about being inadequately prepared for menopause through having insufficient knowledge of the menopausal transition. They experienced lack of clarity about where in the health care system they could get help and that knowledge of menopause varied among healthcare staff. The attitudes to menopause experienced by women in this study were both positive and negative, but they often equated menopause with getting old. To be better prepared for the climacteric transition, the women wanted information from health care professionals and they wanted menopausal care to be easily accessible and local. If needed, it should be possible to access clinics providing specialist care. Conclusion: This work indicates that women want more and improved information about menopause in order to be better prepared. Advice and treatment for menopausal healthcare care should be easily accessible for women. Improved education and care guidelines for menopausal problems can be helpful for healthcare staff. © 2022 The Authors",TestAnalysis
"Voice-driven communication assistive systems—speech enhancement (SE), voice conversion (VC), and automatic speech recognition with text-to-speech (ASR-TTS)—are recognized approaches for improving dysarthric speakers’ speech intelligibility. However, which approach performs better for moderate dysarthric patients is unclear. This study compared the benefits of three classic difference-type voice-driven assistive systems for dysarthric patients under identical test conditions. The benefits of the three systems for dysarthric patients’ speech intelligibility were compared; 14 mild-to-severe dysarthric patients and five speakers with normal speech were invited to record the training sets for these systems. Five moderate dysarthric patients were selected to record two additional testing sets, which were used for evaluating the systems’ benefits. Google Automatic Speech Recognition's (Google ASR) evaluation metrics and listening tests verified each system's speech intelligibility and quality. The speech intelligibility results produced by Google ASR were 7.0%, 22.9%, and 93.8% for the SE, VC, and ASR-TTS systems, respectively. Regarding the listening test, the performance of speech intelligibility and quality were 38.7%, 40.5%, 95.5%, and 1.81, 2.18, 4.56 for SE, VC, and ASR-TTS systems, respectively. The ASR-TTS system performed better than SE and VC. Furthermore, t-distributed stochastic neighbor embedding (t-SNE) analysis was used to additionally compare the differences between the systems. The t-SNE analysis results indicated that ASR-TTS’ phonetic posteriorgram features provided stable performance compared with the other speech features (log-power spectrum and spectra) in the SE and VC systems. Results showed that the ASR-TTS is a potential system to improve moderate dysarthric patients’ speech intelligibility and quality in future applications. © 2022 Elsevier Ltd",TestAnalysis
"Understanding customer feedback is becoming a necessity for companies to identify problems and improve their products and services. Text classification and sentiment analysis can play a major role in analyzing this data by using a variety of machine and deep learning approaches. In this work, different transformer-based models are utilized to explore how efficient these models are when working with a German customer feedback dataset. In addition, these pre-trained models are further analyzed to determine if adapting them to a specific domain using unlabeled data can yield better results than off-the-shelf pre-trained models. To evaluate the models, two downstream tasks from the GermEval 2017 are considered. The experimental results show that transformer-based models can reach significant improvements compared to a fastText baseline and outperform the published scores and previous models. For the subtask Relevance Classification, the best models achieve a micro-averaged F1-Score of 96.1 % on the first test set and 95.9 % on the second one, and a score of 85.1 % and 85.3 % for the subtask Polarity Classification. © 2023, The Author(s).",TestAnalysis
"Text mining on a large corpus of data has gained utility and popularity over recent years owing to advancements in information retrieval and machine learning methods. However, popular text mining software packages mainly focus on either sentiment analysis or semantic meaning extraction, requiring pretraining on a large corpus of text data. In comparison, MoreThanSentiments provides computation of newer text attribution measures, including boiler score, specificity, redundancy, and hard info, which have been proposed in accounting analytics literature. Our software package, available in Python, is flexible in terms of parameter setting and is adaptable to different applications. Through this package, we seek to simplify the process of deploying nontrivial information extraction techniques published in domain-specific text analysis research into domain-agnostic analytics applications. © 2022 The Author(s)",TestAnalysis
"This article proposes to start considering the role that citizens play in platform governance as a way of critically reflecting on issues of inclusivity in and effectiveness of current decision-making processes. This article attempts to apply the above suggestion by studying citizens’ discourse in recent European efforts to regulate online content. It does so by employing an experimental methodology, namely, a computationally assisted Critical Discourse Analysis on textual data derived from citizens’ contributions to the European Commission’s Public Consultations on three crucial regulatory texts: the Code of Practice on Disinformation, the Recommendation on Tackling Illegal Content Online and the Digital Services Act. The present analysis suggests that the EU’s strategy to advance participatory governance through public consultations seems to ignore citizens’ qualitative input and, thus, the feedback received can be severely limited. Concluding, the article maintains that scholarship should adopt a more encompassing scope when studying platform governance, especially concerning citizen and user participation, beyond the traditional frame of participation through civil society representation, while critically scrutinising existing ostensibly participatory structures. © The Author(s) 2023.",TestAnalysis
"Background: Emergency healthcare professionals (EHPs) face significant occupational stressors requiring the skilled use of adaptive coping strategies. Some EHP resort to maladaptive coping (MC) strategies that negatively impact their mental health, yet MC strategies are not clearly defined in the literature. Examining factors that predispose EHP to MC can support interventions to improve coping and well-being. Objective: This systematic review examined MC among EHP working in pre-hospital and hospital-based settings. The primary aim was to identify factors associated with MC strategies used by EHP. Methods: Embase, Ovid, CINAHL Plus, PsychInfo, and the Cochrane Library were systematically searched for quantitative studies measuring MC use among EHP. Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) 2020 checklist was used to guide the review. Studies were included if they: (a) targeted licensed healthcare professionals providing patient care, (b) occurred in emergency department or pre-hospital emergency setting, and (c) examined provider coping. Studies were excluded if they: (a) did not include EHPs, (b) did not differentiate results in mixed samples, (c) did not clearly measure coping strategies, (d) failed to include MC strategies in the results, or (e) were not available in full text. Risk of bias and study quality was appraised using Joanna Briggs Institute (JBI) Critical Appraisal Checklist. Bandura's Social Cognitive Theory (SCT) guided the final synthesis, drawing conclusions from the evidence to identify factors associated with MC in EHP. Results: A total of 14 cross-sectional studies, published between 2003 and 2021, were included in the review. Included studies were conducted in either pre-hospital, hospital, or a combination of both settings. Most studies included mixed samples or emergency physicians. A variety of coping strategies were significantly correlated with poor mental health outcomes including venting, denial, disengagement, self-blame, and substance use. Among personal factors, EHPs who were female, older than 50, living alone, with personal trauma history were significantly more likely to use MC strategies. Additionally, EHP with children, work experience, higher life satisfaction, and resilience were negatively associated with MC. Environmental factors positively associated with MC included work stress, workload, and poor benefits. Trauma exposure had a positive, but non-significant relationship. Conclusions: Emergency healthcare professionals use a variety of coping strategies, many of which are maladaptive and significantly related to poor mental health outcomes. Several personal and environmental factors contribute to behavior that reflect the use of MC strategies, but findings are sparse. Researchers should consider current limitations and challenges, particularly mental health stigma, when designing future studies. Clinical Relevance: The evidence in this review suggests that certain factors predispose EHP for use of MC strategies. This review highlights an important research gap necessitating more robust studies to identify MC risk factors among EHP in chronically high-stress environments. © 2022 Sigma Theta Tau International.",TestAnalysis
"Objective: To provide an overview of studies that describe the preferred mode and format of delivery of patient education materials to older adults. Methods: A scoping review was used to identify relevant literature published between January 2010 and June 2021, with specific attention given to studies conducted in high income countries with similar health systems. Results: A total of 3245 titles were identified, and 20 met the inclusion criteria and were included in this scoping review. Older adults preferred written information that could be accessed via health professionals or downloaded online. Other key features were identified including logical layout, signposted information, larger text size, labelled visual aids, and use of images appropriate and relevant to the target group were preferred. Audio visual resources were also considered valuable when well designed. Formats for patient education such as apps, group classes and online courses were less popular with older adults. Conclusions: Patient education materials for older adults should be carefully designed, with attention to layout and content. Older adults indicated a preference for hard copy handouts or in a format that can be downloaded. Practice Implications: Regular engagement with older consumers about their preferences is important as technology for delivery of patient education materials evolve. Key features for specific attention during the design process include a logical layout (tested with consumers), signposted information, text size, labelled visual aids and appropriate images. The perspectives of other key groups of older adults such as those from minority populations or other disadvantaged groups are largely unexplored. © 2022",TestAnalysis
"We investigate the feasibility of machine learning methods for attributional content and framing analysis in corporate reporting. We test the performance of five widely-used supervised machine learning classifiers (naïve Bayes, logistic regression, support vector machines, random forests, decision trees) in a top-down three-level hierarchical setting to (1) identify performance-related statements; (2) detect attributions in these; and (3) classify the content of the attributional statements. The training set comprises manually coded statements from a corpus of management commentary reports of listed companies. The attributions include both intra- and inter-sentential attributional statements. The results show that for both intra- and inter-sentential attributions, F1-scores of our most accurate classifier (i.e., support vector machines) vary in the range of 76% up to 94%, depending on the identification, detection and classification levels and the content characteristics of attributions. Additionally, we assess the hierarchical performance of classifiers, providing insights into a more holistic classification process for attributional statements. Overall, our results show how machine learning methods may facilitate narrative disclosure analysis by providing a more efficient way to detect and classify performance-related attributional statements. Our findings contribute to the accounting and management literature by providing a basis for implementing machine learning methodologies for research investigating attributional behavior and related impression management. © 2022 Elsevier Inc.",TestAnalysis
"How can civil sphere theory contribute to class analysis? In contrast to critics who suggest Jeffrey Alexander’s The Civil Sphere does not take class seriously, this paper argues that class is a central component to both the rhetorical argument and empirical justification of the text. Through a new reading of the book’s discussions and references to class, this paper provides the rudiments for a new civil sphere theory of social class. The paper first demonstrates how Alexander uses social class as a rhetorical foil against instrumentalist, class-centric models of civil society. Second, the paper elaborates on the obscured but rich set of references to historical cases of class formation to push civil sphere theory towards attending to the creative discursive and institutional action of class movements in the civil sphere. Third, the paper develops Alexander’s concept of ‘refraction’ and argues that the ways in which class communities create new cultures better explains the relationship between classes and the civil sphere. In the conclusion, the paper offers two directions for a civil sphere theory of class – a realist one which posits social classes are products of the economy and then become meaningfully civil as they approach the civil sphere; and an interpretivist one which posits that classes are already-meaningful structures in both the economy and the civil sphere, leading to an open-ended transformation of both. © The Author(s) 2022.",TestAnalysis
"Objective: This systematic review and meta-analysis aimed to review and quantify the changes in gait parameters after therapeutic intervention in adults with neurologic disorders. Data Sources: A keyword search was performed in 4 databases: PubMed, CINAHL, Scopus, and Web of Science (01/2000-12/2021). We performed the search algorithm including all possible combinations of keywords. Full-text articles were examined further using forward/backward search methods. Study Selection: Studies were thoroughly screened using the following inclusion criteria: Study design: randomized controlled trial; adults ≥55 years old with a neurologic disorder; therapeutic intervention; spatiotemporal gait characteristics; and language: English. Data Extraction: A standardized data extraction form was used to collect the following methodological outcome variables from each of the included studies: author, year, population, age, sample size, and spatiotemporal gait parameters such as cadence, step length, step width, or double limb support. A meta-analysis was performed among trials presenting with similar characteristics, including study population and outcome measure. If heterogeneity was >50%, a random plot analysis was used; otherwise, a fixed plot analysis was done. Data Synthesis: We included 25 out of 34 studies in our meta-analysis that examined gait in adults with neurologic disorders. All analyses used effect sizes and standard error and a P<.05(denoted by *) threshold was considered statistically significant. Overall, we found that sensory (SS) and electrical stimulation (ES) had the most significant effect on step length (SS: z=5.44*, ES: z=2.42*) and gait speed (SS: z=6.19*, ES: z=7.38*) in adults with Parkinson disease (PD). Although balance or physical activity interventions were not found to be effective in modifying step length in adults with PD, they showed a significant effect on gait speed. Further, physical activity had the most significant effect on cadence in adults with PD (z=2.84*) relative to sensory stimulation effect on cadence (z=2.59*). For stroke, conventional physical therapy had the most significant effect on step length (z=3.12*) and cadence (z=3.57*). Conclusion: Sensory stimulation such as auditory and somatosensory stimulation while walking had the most significant effect on step length in adults with PD. We also found that conventional physical therapy did improve spatial gait parameters relative to other physical activity interventions in adults with PD and stroke. © 2022 American Congress of Rehabilitation Medicine",TestAnalysis
"Vehicle automation, manifested in self-driving cars, promises to provide safe mobility by reducing human errors. While the testing of automated vehicles (AVs) has improved their performance in recent years, automation technologies face challenges such as uncertainty of safety impacts in mixed traffic with human-driven vehicles. This study aims to examine the gaps in AV safety performance and identify what will be required on a preferential basis for AVs to guarantee an acceptable level of safety performance, especially in mixed traffic, by conducting a thorough analysis of crashes involving levels 2–3 AVs. Based on 260 AV collision reports from California from 2019 to 2021, this study extracts crash-related variables from crash records in a standardized form, crash locations, and, notably, crash narratives reported by AV manufacturers. This study untangles the complex interrelationships among pre-crash conditions, AV driving modes, crash types, and crash outcomes by applying a path-analytic framework with the frequentist and Bayesian approaches. Results show that 51.9 percent of crashes were rear-ends. Particularly, AVs become more vulnerable to rear-end collisions in the automated driving mode than in the conventional mode, given a crash. Additionally, the automated driving mode would not significantly affect the chance of a sideswipe collision, injury, or AV damage levels. Another interesting finding is that manual disengagement is more likely to happen when an AV interacts with a transit vehicle right before a crash occurs while having a negative relationship with injury crashes. Moreover, to reduce injury crashes, AVs would need more thorough testing to adapt to the critical roadway and infrastructure features such as intersections, ramps, and slip lanes; and roadway infrastructure would require improvements to support transportation automation. The risk factors identified in this study can be considered in AV safety assessment scenarios and future operations of mixed traffic. This study demonstrates that AV crash narrative data can be leveraged to improve knowledge of AV safety in mixed traffic. © 2022 Elsevier Ltd",TestAnalysis
"Conceptual metaphor detection is a well-researched topic in Natural Language Processing. At the same time, conceptual metaphor use analysis produces unique insight into individual psychological processes and characteristics, as demonstrated by research in cognitive psychology. Despite the fact that state-of-the-art language models allow for highly effective automatic detection of conceptual metaphor in benchmark datasets, the models have never been applied to psychological tasks. The benchmark datasets differ a lot from experimental texts recorded or produced in a psychological setting, in their domain, genre, and the scope of metaphoric expressions covered. We present the first experiment to apply NLP metaphor detection methods to a psychological task, specifically, analyzing individual differences. For that, we annotate MetPersonality, a dataset of Russian texts written in a psychological experiment setting, with conceptual metaphor. With a widely used conceptual metaphor annotation procedure, we obtain low annotation quality, which arises from the dataset characteristics uncommon in typical automatic metaphor detection tasks. We suggest a novel conceptual metaphor annotation procedure to mitigate issues in annotation quality, increasing the inter-annotator agreement to a moderately high level. We leverage the annotated dataset and existing metaphor datasets in Russian to select, train and evaluate state-of-the-art metaphor detection models, obtaining acceptable results in the metaphor detection task. In turn, the most effective model is used to detect conceptual metaphor automatically in RusPersonality, a larger dataset containing meta-information on psychological traits of the participant authors. Finally, we analyze correlations of automatically detected metaphor use with psychological traits encoded in the Freiburg Personality Inventory (FPI). Our pioneering work on automatically-detected metaphor use and individual differences demonstrates the possibility of unprecedented large-scale research on the relation between of metaphor use and personality traits and dispositions, cognitive and emotional processing. © 2022",TestAnalysis
"Background: Nurses’ knowledge of heart failure (HF) is highly variable, ranging from expert to poor, potentially leading to inadequate self-care. Objectives: (1) document the knowledge variation of HF assessment and management among specialist and generalist nurses; (2) determine factors that may be associated with nurses’ knowledge; and (3) describe nurses’ views of knowledge deficits and ways to improve nurses’ knowledge to better meet the needs educational interventions. Method: Members of the American Association of Heart Failure Nurses and Registered Nurses were invited to participate in a cross-sectional survey. Independent samples t-test, chi-square, and linear regression were used for quantitative analysis. Text analysis was applied to analyze the themes of qualitative comments. Results: A total of 918 nurses completed the survey. Specialist nurses had higher scores than generalist nurses with statistically significant F-test for diet, fluid, signs/symptoms, medication, and exercise. Both specialist and generalist nurses were least knowledgeable about dry weight, asymptomatic hypotension, and transient dizziness. Being a specialist nurse was associated with higher level of knowledge scores. Years of experience and race were significant factors associated with knowledge scores in generalist nurses. Confidence level and race were significant predictors for specialist nurses. Three themes emerged regarding the cause of nurses’ insufficient knowledge and several approaches were provided. Conclusions: Specialist nurses are not only knowledgeable, but their knowledge levels are less variable compared to generalist nurses. There is a need to identify additional factors that may potentially influence nurses’ knowledge, contributing to the effectiveness of interventions. © 2022 Elsevier Inc.",TestAnalysis
"Over the past decade, social media applications have significantly increased their market share and garnered a wide user base. However, these applications have also attracted the attention of criminals desiring to exploit the apps to support illicit operations due to the low barrier to entry and ease of usage. A digital forensic investigation of these applications can reveal valuable information about criminal activity and the suspect. Discord is a Voice over Internet Protocol (VoIP) service that enables text, image, video, and audio chats. It has grown in popularity, and as a result, it is subject to increased use by cybercriminals. In this paper, we examine the remnants of the increasingly popular social media application ‘‘Discord” when used on the Google Chrome web browser. We recovered various artifacts such as payment information, sent messages, account settings, conversations, uploaded attachments, and much more, all of which could be utilized in a forensic investigation. © 2022 Elsevier Ltd",TestAnalysis
"Purpose: There is a lack of uniformity in the definition of normal ovary ultrasound parameters. Our aim was to summarize and meta-analyze the evidence on the topic. Full-text English articles published through December 31, 2020 were retrieved via MEDLINE and Embase. Data available for meta-analysis included: ovarian follicular count, ovarian volume, and ovarian Pulsatility Index (PI) assessed by Doppler ultrasound. Methods: Cohort, cross-sectional, prospective studies with a single or double arm were considered eligible. Interventional studies were included when providing baseline data. Both studies on pre- and post-menopausal women were screened; however, data on menopausal women were not sufficient to perform a meta-analysis. Studies on pre-pubertal girls were considered separately. Eighty-one papers were included in the meta-analysis. Results: The mean ovarian volume was 6.11 [5.81–6.42] ml in healthy women in reproductive age (5.81–6.42) and 1.67 ml [1.02–2.32] in pre-pubertal girls. In reproductive age, the mean follicular count was 8.04 [7.26–8.82] when calculated in the whole ovary and 5.88 [5.20–6.56] in an ovarian section, and the mean ovarian PI was 1.86 [1.35–2.37]. Age and the frequency of the transducers partly modulated these values. In particular, the 25–30-year group showed the higher mean follicular count (9.27 [7.71–10.82]), followed by a progressive age-related reduction (5.67 [2.23–9.12] in fertile women > 35 years). A significant difference in follicular count was also found according to the transducer’s upper MHz limit. Conclusion: Our findings provide a significant input to improve the interpretation and diagnostic accuracy of ovarian ultrasound parameters in different physiological and pathological settings. © 2022, The Author(s).",TestAnalysis
"Objective: In this study, we aim to review the current evidence of Food is Medicine interventions on diabetes outcomes among low-income or food-insecure individuals. Methods: Seven databases were searched from January 1, 2000 to October 26, 2021 for full-text articles written in English. The studies included experimental studies of any duration and design which addressed the effect of Food is Medicine interventions on fruit and vegetable (F&V) intake and glycated hemoglobin (A1C) levels among low-income or food-insecure populations with prediabetes or diabetes of any age group. Only direction of effect of interventions on F&V intake were ascertained due to high variability in outcome measurement. A1C results were pooled using generic inverse variance with a fixed-effects model. Heterogeneity was assessed using Cochran's Q and quantified by I2. Results: Sixteen studies were included. Five of the 8 studies reported a significant increase in F&V intake. Seven of the 14 studies reported a significant decrease in A1C levels. A meta-analysis of 5 randomized controlled trials (n=843) resulted in clinically meaningful reductions in A1C compared with control (mean difference, −0.47%; 95% confidence interval, −0.66 to −0.29, I2=88%, p<0.0001). Half (n=8) of the studies have a high risk of bias due to missing data, detection bias, and confounding. Conclusions: Food is Medicine interventions are effective in increasing F&V intake and reducing A1C levels of the target population. More randomized controlled studies are needed to validate the results. © 2022 Canadian Diabetes Association",TestAnalysis
"Admission of a preterm or sick full-term infant to the neonatal intensive care unit (NICU) is a stressful experience for parents. Indeed, the ‘NICU experience’ may constitute a traumatic event for parents, distinct from other birth-related trauma, leading to significant and ongoing posttraumatic stress disorder (PTSD) symptoms. However, the rates at which this outcome occurs are not well understood. This review aimed to identify the prevalence of PTSD in mothers and fathers of high-risk infants admitted to the NICU, specifically focusing on the NICU experience as the index trauma. The PRISMA-P: Preferred Reporting Items for Systematic Review and Meta-Analysis Protocols were used to conduct this review. We searched PsycINFO, PubMed, Scopus, EMBASE, Web of Science, ProQuest Dissertations and Theses databases, and reference lists of included articles (1980–2021). Two independent reviewers screened titles and abstracts and conducted the full-text screening assessment. Of the 707 records identified, seven studies met the inclusion criteria. In this systematic review, PTSD symptomatology was assessed by self-report measures rather than a clinical interview. We identified significant variations in the methodologies and quality between studies, with a wide variation of reported prevalence rates of PTSD of 4.5–30% in mothers and 0–33% in fathers. Overall, the findings indicate that up to one-third of parents experience PTSD symptomatology related to the NICU experience. These results emphasize the importance of universal routine antenatal and postnatal screening for symptoms of PTSD to identify parents at risk of distress during the NICU experience and after discharge. Trial registration: The study protocol was registered with Prospero registration number CRD42020154548 on 28 April 2020. © 2022, Crown.",TestAnalysis
"Although organizational mission is central to social venturing, little is known about the nature and origins of social ventures' missions. In particular, the field lacks a framework for understanding the moral content of nascent ventures' “prosocial” missions that rely on quite different—and potentially conflicting—moral values. We engage in an exploratory study, drawing on moral foundations theory and upper echelons theory to develop framing questions related to the moral discourse in social venture missions and the role of founders' political ideology in relation to this moral discourse. We construct a novel dataset using computer-aided text analysis on the mission statements of over 50,000 nascent nonprofit ventures in the United States, supplemented by voter registration data from 17 states and Washington, D.C. Our findings reveal rich nuance in the moral discourse found in organizations' mission statements. Furthermore, founding teams' political ideologies are strongly associated with the moral discourse in their social ventures' stated missions—and in ways that differ intriguingly from findings in moral psychology at the individual level. We draw on these new insights to develop a roadmap for future research on organizational mission in relation to social venturing, moral markets, mission drift, and political ideology. © 2022 Elsevier Inc.",TestAnalysis
"Aspect-based sentiment analysis aims to determine sentiment polarities toward specific aspect terms within the same sentence or document. Most recent studies adopted attention-based neural network models to implicitly connect aspect terms with context words. However, these studies were limited by insufficient interaction between aspect terms and opinion words, leading to poor performance on robustness test sets. In addition, we have found that robustness test sets create new sentences that interfere with the original information of a sentence, which often makes the text too long and leads to the problem of long-distance dependence. Simultaneously, these new sentences produce more non-target aspect terms, misleading the model because of the lack of relevant knowledge guidance. This study proposes a knowledge guided multi-granularity graph convolutional neural network (KMGCN) to solve these problems. The multi-granularity attention mechanism is designed to enhance the interaction between aspect terms and opinion words. To address the long-distance dependence, KMGCN uses a graph convolutional network that relies on a semantic map based on fine-tuning pre-trained models. In particular, KMGCN uses a mask mechanism guided by conceptual knowledge to encounter more aspect terms (including target and non-target aspect terms). Experiments are conducted on 12 SemEval-2014 variant benchmarking datasets, and the results demonstrated the effectiveness of the proposed framework. © 2022 Elsevier Ltd",TestAnalysis
"The main goal of this study is to develop a virtual reality (VR)-based scenario of bullying that is more effective in investigating the motivational factors (i.e., emotion, self-efficacy) of adolescents' bystander behavior than the traditional text method. The second goal is to examine how emotion and defender self-efficacy relate to adolescent bystander behavior. Eighth graders (N = 229) from Taiwan participated in 2 (presentation mode: VR vs. text) x 2 (participant sex: boys vs. girls) x 2 (actor sex: boys vs. girls) experimental trials. The results of MANCOVAs indicated that boys displayed less outsider and pro-bullying behavior in the VR group than in the text group; however, there were no differences in bystander behavior for girls. The subjects in the VR group experienced more fear and excitement, less empathy, and a lower level of defender self-efficacy than those in the text group. The results of regression analyses showed that higher levels of anger and defender self-efficacy significantly predicted positive bystander behavior. Qualitative data revealed that VR provided the subjects with a vivid and realistic bullying experience and enabled them to experience emotions such as anger, empathy, and fear. The findings demonstrate that VR increases students’ antibullying attitudes, justice emotions, and positive bystander behavior. However, VR does not provoke more empathy and self-efficacy, as expected. VR might capture a different dimension of response to bullying than the traditional text method. Nevertheless, VR has promise as an educational tool for developing bystander intervention in high school. © 2022 Elsevier Ltd",TestAnalysis
"Background: The initial peak incidence of Hodgkin lymphoma (HL) occurs during reproductive years. Objectives: Synthesise published literature on the relationship between HL and maternal and perinatal outcomes. Search strategy: Systematic search of PubMed/Medline, Cochrane Library, Scopus, Embase and Science Direct from inception to June 2022, supplemented by hand-searching reference lists. Selection criteria: Two reviewers independently reviewed titles, abstracts and full-text articles. Published studies containing original data were eligible. Data Collection and Analysis: Two reviewers independently extracted data and appraised study quality. Outcomes for pregnant women with a previous/current diagnosis of HL were compared separately with women never diagnosed with HL. Where data permitted, meta-analyses of odds ratios and proportions were performed. Certainty of evidence was determined using the Grading of Recommendations Assessment, Development and Evaluation (GRADE) framework. Main results: Of the 5527 studies identified, 33 met the inclusion criteria. In the groups with HL before pregnancy and HL during pregnancy, adjusted odds ratios were not statistically significant for congenital malformation (aOR 1.7, 95% CI 0.9–3.1, and aOR 1.84, 95% CI 0.81–4.15, respectively), preterm birth (PTB) (aOR 0.99, 95% CI 0.65–1.51, and aOR 6.74, 95% CI 0.52–88.03, respectively) and miscarriage (aOR 0.78, 95% CI 0.55–1.10, and aOR 0.38, 95% CI 0.05–2.72, respectively). The aORs for all other outcomes were not statistically significant, except for blood transfusion (aOR 1.38, 95% CI 1.05–1.82) and venous thromboembolism (VTE) (aOR 7.93, 95% CI 2.97–21.22) in the group for HL during pregnancy. The proportion of anaemia was also increased in this group (69%, 95% CI 57%–80% vs 4%, 95% CI 4%–5%, respectively). The GRADE certainty of findings ranged from low to very low. Conclusions: Rates of most adverse pregnancy outcomes among women with a previous/current HL diagnosis are not increased significantly compared with the general pregnant population. Women with HL diagnosed during pregnancy may have a higher PTB rate and increased likelihood of VTE, anaemia and blood transfusion; however, small study numbers and the low to very low GRADE certainty of findings preclude firm conclusions. © 2022 The Authors. BJOG: An International Journal of Obstetrics and Gynaecology published by John Wiley & Sons Ltd.",TestAnalysis
"Background: The autopsy protocols in the work of the Greco-Roman physician Galen of Pergamum have so far primarily been examined from a literary and socio-historic point of view. An analysis focused on the medical aspects is still incomplete. Objectives: Which pathologic-anatomic competence do the Galenic section reports convey? Materials: The approximately 400 Galenic case histories were examined for anatomic and pathologic statements obtained during dissections of animals and men. Results: In 29 reports, anatomy and pathology issues are addressed. Most section reports can be found in the work On anatomical procedures (De anatomicis administrationibus). The texts do not follow a fixed structure. Galen is always the leading actor, observer, and analyst. Many interventions were performed in front of an audience. Monkeys were by far the most commonly dissected animals. Galen stayed away from little animals, because in his opinion their anatomy was not sufficiently similar to that of men. The post-mortem examination of human corpses with scientific intent was limited to victims of epidemics, armed conflicts, and accidents. Conclusions: The dissection reports cover only part of Galen’s pathologic expertise. The attractive public opening of animals earned him a large part of his reputation as a scientifically oriented physician. The dissection reports are an essential part of the collection of Galen’s case histories and provide important detailed information on the history of anatomy and pathology in late antiquity. © 2022, The Author(s), under exclusive licence to Springer Medizin Verlag GmbH, ein Teil von Springer Nature.",TestAnalysis
"This work comprehensively investigates the self-heating effects (SHEs) in Tree-FET at 5nm technological nodes. A comparative analysis of Tree-FET with Nanosheet FET (NSFET) shows that the Tree-FET (3-channel+2-bridge) is more or less comparable to the 5-channel NSFET rather than with 3-channel NSFET. An in-depth physics-based study shows that considering only one aspect of increasing ON current is insufficient to judge Tree-FETs for future technological nodes. Targeting these facts, device reliability is demonstrated through numerical simulations showing that Tree-FET outperforms in a self-heating situation, which is a prime concern at a lower technology node. 5-channel NSFET shows $\sim {\textbf {24}}\%$ reduction while Tree-FET ( $\text{H}_{\textbf {IB}}\,\,=$ 25nm) shows only $\sim \textbf {20}\%$ reduction in $I_{\textbf {ON}}$ under self-heating. This is because the bridges create a path to heat removal through electrodes and substrate. The peak temperature difference between channels is $\sim \textbf {23K}$ in Tree-FET, whereas, in the case of other counterparts, it is $\sim \textbf {28K}$. A comparatively smaller variation in the $\text{V}_{\textbf {T}}$ shift due to the self-heating effect is observed in Tree-FET in order to achieve higher $I_{\textbf {ON}}$ , showing a promising candidate for circuitry that requires a high drive current. A comparative lower gate capacitance implies that Tree-FET may perform well in digital switching applications. Though Tree-FET is not comparable to NSFET for analog applications due to lesser intrinsic gain, it shows a lesser degradation in cut-off frequency $(\sim \textbf {3}\%$ ) compared to 5-channel NSFET under a self-heating environment.  © 2001-2011 IEEE.",TestAnalysis
"Basic knowledge of biochemistry underpins oral and dental care. Undergraduate dental students do not always engage well with basic science teaching due to not appreciating its clinical relevance. Co-teaching provides one approach to overcome students' disengagement and involves two lecturers, with complementary expertise, presenting the curriculum together. This study investigated student experiences and engagement using co-teaching to integrate biochemistry with clinical sciences in the students' second-year dental curriculum. Two successive second year dental student cohorts were co-taught. Content was delivered by a biochemist and an oral biologist, either online (during the 2020 COVID lockdown) or in-person (2021). Each cohort was surveyed at the end of the teaching module using an online questionnaire containing both interval scale and free-text questions. Responses were received from 39 (42%) and 64 (85%) of students in 2020 and 2021, respectively. Students from both cohorts preferred the co-teaching approach with a mean of 8.74 on a 10-point interval scale. In 2020 and 2021, 77% and 76% of participants, respectively, preferred a combined biochemistry and clinical dentistry delivery, either in-person (37%), via Zoom (19%) or via video recording (14%). Thematic analysis of responses revealed students experienced enhanced engagement when co-taught and they attributed this to integration of the curriculum making the content more relevant and stimulating. Students preferred co-teaching to individual subjects being taught by a single teacher. Co-teaching established the relevance of theoretical biochemistry to clinical dental sciences and enhanced the students' learning experience. © 2022 The Authors. Biochemistry and Molecular Biology Education published by Wiley Periodicals LLC on behalf of International Union of Biochemistry and Molecular Biology.",TestAnalysis
"Objective: Research has shown that therapists can develop a positive therapeutic relationship in the Internet setting and that the therapeutic relationship plays a role in treatment outcome. However, little is known about how therapists foster a positive therapeutic relationship in the Internet setting. Therefore, the current study assesses the extent to which therapists apply techniques that are recommended in the face-to-face setting when communicating with participants of an Internet-based cognitive behavioural therapy (iCBT) intervention. Method: Qualitative content analysis was conducted to analyse therapists' messages sent to clients during the course of an asynchronous, text-based iCBT intervention for caregivers of people with dementia. A total of 216 written messages from four therapists to 27 participants were analysed. Based on the motivational attunement framework of therapist behaviour, a deductive coding system was developed, and the intercoder reliability was satisfactory. Results: Through qualitative content analysis, a variety of techniques were found in the therapeutic messages: 12 main categories and six subcategories of therapeutic techniques that satisfy the four basic needs according to Grawe were identified. Therapists most frequently addressed the need for attachment (41%), followed by orientation and control (28%), self-esteem (24%) and pleasure (7%). Conclusions: The results indicated that online therapists implemented many of the techniques that are recommended and applied in the face-to-face setting to foster a positive therapeutic relationship. Results can be used to develop training for online therapists and manuals for Internet interventions. © 2022 The Authors. Counselling and Psychotherapy Research published by John Wiley & Sons Ltd on behalf of British Association for Counselling and Psychotherapy.",TestAnalysis
"This study demonstrates a way of bringing an innovative data source, social media information, to the government accounting information systems to support accountability to stakeholders and managerial decision-making. Future accounting and auditing processes will heavily rely on multiple forms of exogenous data. As an example of the techniques that could be used to generate this needed information, the study applies text mining techniques and machine learning algorithms to Twitter data. The information is developed as an alternative performance measure for NYC street cleanliness. It utilizes Naïve Bayes, Random Forest, and XGBoost to classify the tweets, illustrates how to use the sampling method to solve the imbalanced class distribution issue, and uses VADER sentiment to derive the public opinion about street cleanliness. This study also extends the research to another social media platform, Facebook, and finds that the incremental value is different between the two social media platforms. This data can then be linked to government accounting information systems to evaluate costs and provide a better understanding of the efficiency and effectiveness of operations. © 2022 Elsevier Inc.",TestAnalysis
"Recent guidelines have produced a consensus statement for perioperative care in hip and knee replacement. However, there is still a need for reanalysis of the evidence and recommendations. Therefore, we retrieved and reanalyzed the evidence of each recommended components of enhanced recovery after surgery (ERAS) based on the guidelines of total joint arthroplasty. For each one, we included for the highest levels of evidence and those systematic reviews and meta-analyses were preferred. The full texts were analyzed and the evidence of all components were summarized. We found that most of the recommended components of ERAS are supported by evidence, however, the implementation details of each recommended components need to be further optimized. Therefore, implementation of a full ERAS program may maximize the benefits of our clinical practice but this combined effect still needs to be further determined. © 2023 The Authors. Orthopaedic Surgery published by Tianjin Hospital and John Wiley & Sons Australia, Ltd.",TestAnalysis
"In recent decades, many researchers set out to draw links between Western anarchism and ancient Chinese Daoism. The present work aims at adding to this ongoing debate by answering the question of whether the Guodian Laozi’s 郭店老子 sayings can be labelled as “anarchism.” It defends the claim that the text endorses a unique kind of anarchist theory based on a distinctive theory of political authority grounded in Daoist moral commitments. To do so, this essay first offers an overview of the scholarly debate surrounding this topic. Second, it provides an account of the necessary and sufficient feature any theory must secure in order to be argued to be anarchist, as well as a framework that underlines potential differences between various anarchist theories. Third, a rigorous textual analysis of the Guodian Laozi is conducted to extrapolate its political advice, before analyzing it in light of the anarchist framework mentioned above. This essay concludes with an assessment of several objections that may be raised against its claims. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.",TestAnalysis
"Exploring the factors that affect the market performance of paid knowledge products is of great importance for knowledge payment platforms. Drawing on the sensations-familiarity framework and social capital theory, this study investigates how knowledge differentiation between paid and free knowledge impacts market performance, along with the moderating effect of knowledge providers’ social capital. Technically, a neural network-based text mining model is utilized to transform free and paid knowledge to semantic vectors, whose dissimilarity is calculated as knowledge differentiation. Empirical analysis on a real dataset reveals the positive (or negative) effect of knowledge differentiation on sales (or eWOM, electronic word of mouth), which will be more prominent with the increase of social capital. The results are reinforced with robustness checks regarding alternative knowledge-differentiation measures, more control variables and alternative regression methods. The present study extends our understanding of knowledge payment and free-to-paid consumption, and offers practical implications for content design and product management. © 2022 Elsevier Ltd",TestAnalysis
"Objective: To evaluate the diagnostic accuracy of different ultrasound signs for diagnosing adnexal torsion, using surgery as the reference standard. Methods: This was a systematic review and meta-analysis of studies published between January 1990 and November 2021 evaluating ovarian edema, adnexal mass, ovarian Doppler flow findings, the whirlpool sign and pelvic fluid as ultrasound signs (index tests) for detecting adnexal torsion, using surgical findings as the reference standard. The search for studies was performed in PubMed/MEDLINE, CINAHL, Scopus, The Cochrane Library, ClinicalTrials.gov and Web of Science databases. The Quality Assessment of Diagnostic Accuracy Studies-2 (QUADAS-2) tool was used to evaluate the quality of the studies. Pooled sensitivity, specificity, and positive and negative likelihood ratios were calculated separately, and the post-test probability of adnexal torsion following a positive or negative test was also determined. Results: The search identified 1267 citations after excluding duplicates. Eighteen studies were ultimately included in the qualitative and quantitative syntheses. Eight studies (809 patients) analyzed the presence of ovarian edema, eight studies (1044 patients) analyzed the presence of an adnexal mass, 14 studies (1742 patients) analyzed ovarian Doppler flow, six studies (545 patients) analyzed the whirlpool sign and seven studies (981 patients) analyzed the presence of pelvic fluid as ultrasound signs of adnexal torsion. Overall, the quality of most studies was considered to be moderate or good. However, there was a high risk of bias in the patient-selection and index-text domains (with the exception of the whirlpool sign) in a significant proportion of studies. Pooled sensitivity, specificity, and positive and negative likelihood ratios of each ultrasound sign were 58%, 86%, 4.0 and 0.49 for ovarian edema, 69%, 46%, 1.3 and 0.67 for adnexal mass, 65%, 91%, 7.6 and 0.38 for the whirlpool sign, 53%, 95%, 11.0 and 0.49 for ovarian Doppler findings and 55%, 69%, 1.7 and 0.66 for pelvic fluid. Heterogeneity was high for all analyses. Conclusions: The presence of an adnexal mass or pelvic fluid have poor diagnostic accuracy as ultrasound signs of adnexal torsion, while the presence of ovarian edema, the whirlpool sign and decreased or absent ovarian Doppler flow have good specificity but moderate sensitivity for detecting adnexal torsion. © 2022 The Authors. Ultrasound in Obstetrics & Gynecology published by John Wiley & Sons Ltd on behalf of International Society of Ultrasound in Obstetrics and Gynecology. © 2022 The Authors. Ultrasound in Obstetrics & Gynecology published by John Wiley & Sons Ltd on behalf of International Society of Ultrasound in Obstetrics and Gynecology.",TestAnalysis
"Not all hope is equal. For the Christian religion, hope is a theological virtue, and refers to the expectation of future life, beyond death. With the transformation of European society in a secular sense and the rise of individualism between the 17th and 18th centuries, hope becomes a program of political and social transformation, aimed at this world. In my contribution I trace the emergence of the concept of hope in social thought and, then, in sociology. My analysis begins with the Philosophie sociale (Paris, 1793) by Moses Dobruska (1753–1794), a pioneering and largely overlooked text that founds a new vision of social science. After Dobruska, I then devote my attention to the great thinkers of the early nineteenth century, Henri de Saint-Simon (1760–1825) and Auguste Comte (1798–1857), and then I move on to the work of Émile Durkheim (1858–1917). It is a historical perspective that has been neglected until now, and that allows us to appreciate the construction of an idea of hope that frees itself from religious determinants and is oriented toward society and the individuals who live in it, and that anticipates the utopias and failures of the social ideologies of the 20th century. © 2022, The Author(s).",TestAnalysis
"Project construction on-site is known to be very dangerous workplace environments due to large numbers of safety hazards. Analysis of construction safety hazards is essential to formulate rational safety management plans and prevent accidents. Construction documents contain large volumes of safety hazard information available for analysis. However, such analyses are challenging because the safety hazard information in the construction documents is presented in an unstructured or semi-structured format. This study proposes a method for intelligent mining of safety hazard information, which comprises safety hazard technical term recognition and safety hazard information analysis. The safety hazard technical term recognition model is developed based on semantic similarity and information correlation to build a safety hazard technical term library. The safety hazard information based on the technical term library is mined and analyzed using the term frequency-inverse document frequency method (TF-IDF). Finally, the proposed method is applied to build the safety hazard technical term library, which contains 2697 technical terms, and develop a hydraulic project construction safety hazard analysis system, which can realize the intelligent recognition and application of technical terms. Meanwhile, this system can automatically extract safety hazard information and provide a visualization interface to intuitively show the safety hazard analysis results, which improves the extraction efficiency of safety hazard information. The study provides a new approach for recognizing technical terms and mining safety hazard information, which can lead to enhancing management efficiency and practical knowledge discovery for safety management. © 2022 Elsevier Ltd",TestAnalysis
"Aims: The NHS England Radiotherapy Service Specification calls for routine use of patient-reported outcome measures (PROMs). However, barriers exist at patient, healthcare professional and service levels. The aim of the present study was to determine the current use of PROMs within radiotherapy services in England. The current attitudes, barriers and enablers to the implementation of PROMs in radiotherapy practice were evaluated and practical recommendations to inform future implementation were developed. Materials and methods: A mixed-methods approach was adopted to obtain quantitative and qualitative data. An online questionnaire was developed and disseminated to all radiotherapy operational delivery network managers across England. The questionnaire consisted of 12 open and closed questions relating to PROMs use, with the option to provide free-text responses. Inductive thematic analysis was conducted on free-text comments, whereas descriptive statistics were used to analyse quantitative data. Results: In total, 182 responses were received from 40 of the 50 radiotherapy providers, resulting in a response rate of 84%. The current use of PROMs was analysed, including rationale for use, tools used, format of PROMs collection and timing within the radiotherapy pathway. Most respondents indicated that PROMs were used in the context of clinical trials only. Through thematic analysis, four identical key themes were identified relating to both barriers and enablers to PROMs use; these included IT infrastructure, time, human/financial resources and training/education. A fifth theme, standardisation, was identified as a key enabler to PROMs use. Conclusions: Our findings show that outside of clinical trials, PROMs are not routinely used in radiotherapy services due to barriers identified at professional and service levels. Here we provide recommendations to mitigate the barriers identified and implement PROMs in radiotherapy, including training for healthcare professionals and standardisation of PROMs tools and storage. This study provides a key first step in driving PROMs implementation within radiotherapy services across England. © 2022 The Author(s)",TestAnalysis
"Value-at-risk (VAR) is an indispensable part of a disaster risk assessment of historical buildings. Indicator-based value framework can provide a consistent and comparative method to assess the VAR of historical buildings. However, the existing value frameworks and their indicators are diverse, greatly due to the multidimensional characteristic of the value of historical buildings. Besides, there are various value indicators that existing frameworks do not encompass. As such, a holistic framework to assess the VAR of historical buildings is still needed. Establishing a holistic VAR framework requires a detailed review of existing value frameworks and indicators to understand their similarities and differences. Therefore, a review of existing value frameworks and indicators is presented, covering frameworks and indicators applicable to three categories of built cultural heritage (historical buildings, monuments, and archaeological sites) reported in literature, as well as guidelines and reports. The review summarizes 53 value indicators and 12 frameworks, and after integration, reorganization, and optimization, a novel holistic VAR framework, with 6 first-level indicators and 42 second-level indicators, has been proposed for VAR assessment of historical buildings using the analytic hierarchy process based on expert elicitation. Further, the proposed VAR framework has been verified by performing a text mining analysis of the definitions/descriptions of the value indicators. Two historical buildings in China were analyzed to demonstrate the universality and comprehensiveness of the proposed VAR framework. The VAR assessment results can provide reference on safety measures allocation for risk reduction of historical buildings.  © 2022 American Society of Civil Engineers.",TestAnalysis
"The ways in which news media communicate about heatwaves can influence how society conceptualises and addresses heatwave risks. We examined visual news coverage of the 2019 heatwaves in France, Germany, the Netherlands and the UK, using content and visual critical discourse analyses. Many visuals were positively valenced (in contrast to article texts), framing heatwaves as ‘fun in the sun’. The most prevalent type of images in all countries were photographs of people having fun in or by water. When images did depict the danger of heat extremes, people were largely absent. We conclude that this visual framing of heatwaves is problematic: first, by displacing concerns of vulnerability, it marginalises the experiences of those vulnerable to heatwaves; and second, it excludes opportunities for imagining a more resilient future. We conclude with suggestions to diversify the visual discourse on climate change and heatwaves in the news media. The information, practices and views in this article are those of the author(s) and do not necessarily reflect the opinion of the Royal Geographical Society (with IBG). © 2022 The Authors. The Geographical Journal published by John Wiley & Sons Ltd on behalf of Royal Geographical Society (with the Institute of British Geographers).",TestAnalysis
"Unlike the central banks of most developed economies, the People's Bank of China (PBC) does not release its macroeconomic forecasts to the public but instead carries out narrative communication. We apply a hurdle distributed multinomial regression to PBC communication texts in real time, addressing the ultrahigh dimensionality, sparsity, and look-ahead biases. In addition, we embed text-based indices into mixed-data sampling (MIDAS)-type models and conduct forecast combinations for prediction. Our results argue that the predictive information from communication texts improves the real-time out-of-sample prediction performance. We connect textual analysis and real-time macroeconomic projection, providing new insights into the value of central bank communication. © 2022 John Wiley & Sons Ltd.",TestAnalysis
"Text simplification (TS) is the process of generating easy-to-understand sentences from a given sentence or piece of text. The aim of TS is to reduce both the lexical (which refers to vocabulary complexity and meaning) and syntactic (which refers to the sentence structure) complexity of a given text or sentence without the loss of meaning or nuance. In this paper, we present SimpLex, a novel simplification architecture for generating simplified English sentences. To generate a simplified sentence, the proposed architecture uses either word embeddings (i.e., Word2Vec) and perplexity, or sentence transformers (i.e., BERT, RoBERTa, and GPT2) and cosine similarity. The solution is incorporated into a user-friendly and simple-to-use software. We evaluate our system using two metrics, i.e., SARI and Perplexity Decrease. Experimentally, we observe that the transformer models outperform the other models in terms of the SARI score. However, in terms of perplexity, the word embedding-based models achieve the biggest decrease. Thus, the main contributions of this paper are: (1) We propose a new word embedding and transformer-based algorithm for text simplification; (2) we design SimpLex—a modular novel text simplification system—that can provide a baseline for further research; and (3) we perform an in-depth analysis of our solution and compare our results with two state-of-the-art models, i.e., LightLS as reported by Glavaš and Štajner (in: Proceedings of the 53rd annual meeting of the association for computational linguistics and the 7th international joint conference on natural language processing, 2015) and NTS-w2v as reported by Nisioi et al. (in: Proceedings of the 55th annual meeting of the association for computational linguistics, 2017). We also make the code publicly available online. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",TestAnalysis
"The graphene-based materials are promising for applications in supercapacitors and other energy storage devices due to the intriguing properties, i.e., highly tunable surface area, outstanding electrical conductivity, good chemical stability, and excellent mechanical behavior. This review summarizes recent development on graphene-based materials for supercapacitor electrodes, based on their macrostructural complexity, i.e., zero-dimensional (0D) (e.g., free-standing graphene dots and particles), one-dimensional (1D) (e.g., fiber-type and yarn-type structures), two-dimensional (2D) (e.g., graphenes and graphene-based nanocomposite films), and three-dimensional (3D) (e.g., graphene foam and hydrogel-based nanocomposites). There are extensive and on-going researches on the rationalization of their structures at varying scales and dimensions, development of effective and low-cost synthesis techniques, design and architecturing of graphene-based materials, as well as clarification of their electrochemical performance. There are several methods for producing graphene, each with its own advantages and disadvantages. Graphene-based materials have great potential to be employed in supercapacitors due to their unique two-dimensional structure and inherent physical properties like excellent electrical conductivity and large area. This text summarizes recent developments within the sector of supercapacitors, including double-layer capacitors and quasi-capacitors. The pros and cons of using them in supercapacitors are discussed. Compared to traditional electrodes, graphene-based materials show some new properties and mechanisms within the method of energy storage and release. During this paper, we briefly describe carbon structures, particularly graphene, and also the history of graphene discovery, and briefly describe the synthesis methods, properties, characterization methods, and applications of graphene. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"With the flare-up of the COVID-19 infection since 2020, COVID-19 has been one of the hottest topics on Twitter. Topic modeling is one of the most popular analyses, which extracts the topics from the text. This paper proposes a method to extract the most-discussed topics for 32 countries of the world. In this regard, more than five million related tweets have been studied, and a method based on content analysis is proposed to identify the exact location of each tweet. Then, by using the statistical algorithm of Latent Dirichlet Allocation, the main topics of the tweets are identified. By leveraging sentiment analysis, the topics are afterward divided into positive and negative groups, and their trends in a quarterly period are investigated for the countries under study. The outcome of the analysis of time trends shows that for most countries, the trend of negative topics is highly correlated with the number of confirmed cases of COVID-19. © 2022 Elsevier Ltd",TestAnalysis
"The purpose of this paper is to study how people use texts and languages to interpret or make sense of the COVID-19 pandemic. We draw on the theoretical literature of framing perspectives to formulate our arguments that consider the virus a socially constructed reality. We use Taiwan as an empirical case study, using topic modeling analysis of newspaper articles. Our findings show that the language of the COVID-19 coverage combines the four frames of political evaluation, economic impact, biomedical science and social life in varying proportions. These frames are subject to changes in pandemic conditions. Implications for theory and practice are presented. © 2022 Elsevier Inc.",TestAnalysis
"Purpose: Literature reports of adverse drug events can be replicated across multiple companies, resulting in extreme duplication (defined as a majority of reports being duplicates) in the FDA Adverse Event Reporting System (FAERS) database because they can escape legacy duplicate detection algorithms routinely deployed on that data source. Literature reference field, added to in 2014, could potentially be utilized to identify replicated reports. FAERS does not enforce adherence to the Vancouver referencing convention, thus the same article may be referenced differently leading to duplication. The objective of this analysis is to determine if variations of the same literature references observed in FAERS can be resolved with text normalization and fuzzy string matching. Methods: We normalized the literature references recorded in the FAERS database through the first quarter of 2021 with a rule-based algorithm so that they better conform to the Vancouver convention. Levenshtein distance was then utilized to merge sufficiently similar normalized literature references together. Results: Normalization of literature references increases the percentage that can be parsed into author, title, and journal from 61.74% to 93.93%. We observe that about 98% of pairs within groups do have a Levenshtein similarity of the title above the threshold. The extreme duplication ranged from 66% to 87% with a median of 72% of reports being duplicates and often involved addictovigilance scenarios. Conclusions: We have shown that these normalized references can be merged via fuzzy string matching to improve enumeration of all the individual case safety reports that refer to the same article. Inclusion of the PubMed ID and adherence to the Vancouver convention could facilitate identification of duplicates in the FAERS dataset. Awareness of this phenomenon may improve disproportionality analysis, especially in areas such as addictovigilance. © 2022 John Wiley & Sons Ltd.",TestAnalysis
"Social media users are increasingly turning to express opinions with both images and text, while the visual content and text description may cover some conflicting information diverse from each other. Information relevance refers to the matching degree between cross-modal features at the emotional semantic level, which is not systematically studied. In order to exploit the discriminative features and the internal correlation among different modalities, the mid-level representation extracted by a visual sentiment concept classifier is used to determine information relevance, with the integration of other features, including attended textual and visual features. Then grid search is applied to tune weighting coefficients of the decision fusion scheme, followed by a multimodal adaptive method for joint sentiment analysis based on image-text relevance. The superiority of our architecture approach is demonstrated experimentally by comparing it with several state-of-the-art baselines, such as the vision-aware language modeling approach and contrastive learning-based model. The results indicate that fused multiple features lead to more precise classification than unimodal ones, while the contributions of each single modality differ obviously in emotional expression. Besides, the performance of every involved model varies markedly per dataset of different content correlation, which proves that it is of extensive theoretical significance and application prospect to introduce the image-text relevance classifier into a multimodal task. © 2022 Elsevier Ltd",TestAnalysis
"Occupational incidents are a major concern in steel industries due to the complex nature of job activities. Forecasting incidents caused by various activities and determining the root cause might aid in implementing appropriate interventions. Thus, the purpose of this study is to investigate the future trend and identify the pattern of contributing factors of incident occurrences. The study focuses on an integrated steel plant where different steel-making-related operations are carried out in separate units. The incident data of 45 months is used. Initially, a unit-wise trend of incidents (e.g., injury, near-miss and property damage) is forecasted using the autoregressive integrated moving average (ARIMA) model to determine the near-future incident trends and to identify the most incident-prone unit of the plant. The model is validated using six-month holdout data, and the predicted number of incidents is compared with the actual counts. The ARIMA model indicates that the safety performance of the iron making unit is found to be underperforming. In the second phase, meaningful association rules are extracted from text data using the apriori algorithm for the underperforming unit to discover the incident-causing factors. Results from text mining-based association mining suggest that bike and car-related incidents are the leading causes of injury. Similarly, gas leakage, slag spillage, and coke-oven door malfunctioning are causing near-miss incidents. The majority of property damage incidents are reported due to derailment, loading/ unloading and dashing of the dumper vehicle. Effective implementation of the study's specified rules can aid plant administration in formulating policies to improve safety performance by designing focused interventions. © 2022 Elsevier Ltd",TestAnalysis
"The carbon market relies on market-oriented financial means to solve the problem of carbon emissions. An effective carbon pricing mechanism can improve market efficiency and better serve the implementation of carbon emission reduction. The limited attention of investors increases the uncertainty of carbon market volatility and is an important exogenous factor affecting the price of carbon assets. This study innovatively mines keywords of investor attention on the carbon market through online news texts and eliminates those that have no causal link to carbon price forecasting in order to reduce noise. The results show that the keyword extraction method based on news text mining is better than that of nontext mining. Meanwhile, a carbon price forecasting model based on a particle-swarm-optimization LSTM model structure is constructed, and the forecasting accuracy is improved. The results show that carbon market investors pay more attention to carbon quota supply and demand, carbon prices, environmental change, and the energy market. The results have important implications for the development of effective carbon market policies and risk management. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TestAnalysis
"The increasing interest around emotions in online texts creates the demand for financial sentiment analysis. Previous studies mainly focus on coarse-grained document-/sentence-level sentiment analysis, which ignores different sentiment polarities of various targets (e.g., company entities) in a sentence. To fill the gap, from a fine-grained target-level perspective, we propose a novel Lexicon Enhanced Collaborative Network (LECN) for targeted sentiment analysis (TSA) in financial texts. In general, the model designs a unified and collaborative framework that can capture the associations of targets and sentiment cues to enhance the overall performance of TSA. Moreover, the model dynamically incorporates sentiment lexicons to guide the sentiment classification, which cultivates the model faculty of understanding financial expressions. In addition, the model introduces a message selective-passing mechanism to adaptively control the information flow between two tasks, thereby improving the collaborative effects. To verify the effectiveness of LECN, we conduct experiments on four financial datasets, including SemEVAL2017 Task5 subset1, SemEVAL2017 Task5 subset2, FiQA 2018 Task1, and Financial PhraseBank. Results show that LECN achieves improvements over the state-of-art baseline by 1.66 p.p., 1.47 p.p., 1.94 p.p., and 1.88 p.p. in terms of F1-score. A series of further analyses also indicate that LECN has a better capacity for comprehending domain-specific expressions and can achieve the mutually beneficial effect between tasks. © 2022 Elsevier Ltd",TestAnalysis
"Nowadays, fake news has turned into a major problem because of the negative impact that it creates on society. Social media allows people to spread information on the internet with slight investigations and to add fewer filters than the actual content. Nowadays, the false news in the internet community is unsure, and it creates a wrong impression among the users. Detecting false news has become a critical task based on shared content. To tackle the false news growth in social media, various automatic detection schemes were evaluated. The “Natural Language Processing (NLP)” method also gives a prominent solution for false news detection. The main intention of this paper is to design and introduce an innovative false news recognition method using Meta-heuristic Searched-Ensemble Learning (MS-EL). Further, the selected features are extracted by the “Term Frequency-Inverse Document Frequency (TF-IDF)” and also Word2vec features. Here, the extracted selected features are integrated with the Hybrid Squirrel–Dragonfly Search Optimization (HS-DSO) is used to optimize the weighted feature selection approach with the fitness function of solving data variance and correlation. The proposed MS-EL is adopted in the classification part, having three sets of classifiers, Long Short-Term Memory (LSTM), Support Vector Machine (SVM), and Deep Neural Network (DNN). Here, the ensemble classifier is enhanced by the same HS-DSO that shows the parameter tuning with a high convergence rate. From the experimental outcomes, the accuracy of HS-DSO-MS-EL is 22% higher than BMO-MS-EL, 24% higher than SP-BMO-MS-EL, 30% higher than SSA-MS-EL, and 29% higher than DA-MS-EL. Thus, the experimental analysis with standard datasets establishes that the introduced fake news detection method has gained higher accuracy than the existing models. © 2022 Elsevier B.V.",TestAnalysis
"Digitalization has affected working practices in the field of public relations over the past two decades. Consequently, the skills and competences that are expected from public relations professionals are theorized to have undergone stark changes, with obvious implications for educators, role perceptions, and the professionals themselves. Job postings provide information about these changes by describing the skills employers expect and desire from applicants. To date, only a few studies have used this source of information, and these mostly concern the U.S. market using small samples of job postings. The purpose of this study is to enrich our understanding of how digitalization has impacted the skillsets required of public relations practitioners through the longitudinal automated semantic analysis of 62,391 public relations job postings published in Austria and Germany between 2015 and 2020. The analysis shows an increase in the number of hard skills demanded in PR in this region over the past five years. This change is particularly pronounced with respect to digital skills, thus underlining the importance of digitalization in public relations. The detailed and up-to-date findings describing what the job market is currently looking for and how it is changing will be useful for educators in developing and aligning PR curricula and advanced training programmes. © 2022 Elsevier Inc.",TestAnalysis
"Introduction: Melanoma is the fifth most common cancer diagnosed in the United States, representing 5.6% of all new cancer cases. There are conflicting reports correlating a relationship between primarily outdoor occupations, associated with increased exposure to direct sunlight, and the incidence of cutaneous melanoma. Our objective was to outline and critically evaluate the relevant literature related to chronic occupational exposure to sunlight and risk of developing cutaneous melanoma. Methods: The study protocol for this systematic review was submitted to the International Prospective Register of Systematic Reviews and the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines were followed. For each relevant study included, the following information was extracted: author names, publication year, study name, study design, age, exposure assessment, outcome, comparison, number of cases, case ascertainment, and descriptive and adjusted statistics. Study quality and evidence certainty was assessed using the Grading of Recommendations, Assessment, Development and Evaluations model. Results: The initial database search yielded 1629 articles for review and following full-text screening, a total of 14 articles were included for final analysis. Of the studies included, seven articles were retrospective case control and seven were cohort studies. The studies did not report any differences in the likelihood of cutaneous melanoma development based upon membership in the outdoor versus indoor occupation groups included in each study. Conclusions: Overall, the articles included in this systematic review did not report an increased risk of developing cutaneous melanoma among individuals with outdoor occupations. Further investigation is required to determine if other occupational or life-style–related risk factors exist, to help support the development of individualized skin screening recommendations and improve the early detection of melanoma in all populations. © 2022",TestAnalysis
"Researchers have been aware that emotion is not one-hot encoded in emotion-relevant classification tasks, and multiple emotions can coexist in a given sentence. Recently, several works have focused on leveraging a distribution label or a grayscale label of emotions in the classification model, which can enhance the one-hot label with additional information, such as the intensity of other emotions and the correlation between emotions. Such an approach has been proven effective in alleviating the overfitting problem and improving the model robustness by introducing a distribution learning component in the objective function. However, the effect of distribution learning cannot be fully unfolded as it can reduce the model's discriminative ability within similar emotion categories. For example, “Sad” and “Fear” are both negative emotions. To address such a problem, we proposed a novel emotion extension scheme in the prior work (Li, Chen, Xie, Li, and Tao, 2021). The prior work incorporated fine-grained emotion concepts to build an extended label space, where a mapping function between coarse-grained emotion categories and fine-grained emotion concepts was identified. For example, sentences labeled “Joy” can convey various emotions such as enjoy, free, and leisure. The model can further benefit from the extended space by extracting dependency within fine-grained emotions when yielding predictions in the original label space. The prior work has shown that it is more apt to apply distribution learning in the extended label space than in the original space. A novel sparse connection method, i.e., Leaky Dropout, is proposed in this paper to refine the dependency-extraction step, which further improves the classification performance. In addition to the multiclass emotion classification task, we extensively experimented on sentiment analysis and multilabel emotion prediction tasks to investigate the effectiveness and generality of the label extension schema. © 2022 The Author(s)",TestAnalysis
"Urban underground 3D geological modeling can accurately express various geological phenomena and provide a decision-making basis for urban planning and geological analysis. The construction of smart cities has put forward new requirements for the automation and intelligence of urban geological 3D modeling. Geological survey reports are important reference data for urban geological 3D modeling. However, a large number of geological maps, geophysical data, and other geographic quantitative data of geological science surveys have been buried in geological survey literature and have not been effectively used. Currently, the development of data mining and information extraction technology provides the possibility to integrate these data into 3D geological modeling. Therefore, this study designed the workflow of 3D geological modeling using a geological survey report. First, after the geological survey report was deconstructed, the geological text information was recognized and extracted using geological dictionary matching and pattern rule matching, and the integration of knowledge was provided in the form of a knowledge graph. Then, the drilling information and table data in the drilling histogram are automatically extracted. Through these methods, the unstructured geological survey report can be transformed into structured data and integrated into the 3D geological modeling process. Finally, the 3D geological modeling of the Bridge Group in Jinan based on the Jinan urban geological survey report was taken as an example to verify the feasibility of the proposed method and demonstrate the potential of text mining and information extraction of geological survey reports for 3D geological modeling, which provides geological data support for the transformation of old and new kinetic energy and the construction of major projects of government departments. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TestAnalysis
"This article is concerned with ""abstract rhetors"", i.e. inanimate nouns used as subjects of active verbs, in Polish and English academic texts. The few existing studies that deal with abstract rhetors in Polish indicate that their use is limited in comparison with English in both quantitative and qualitative terms. However, no suggestions have been offered so far as to the potential factors that may underlie these limitations, especially with regard to the qualitative differences. Focusing on a special type of abstract rhetors, namely active verbs used with text-denoting subjects, the article offers a comparable corpus-based analysis of Polish and English abstracts of research articles in linguistics with a view to determining their frequencies and shedding some light on the possible causes of the limited use of the structure in Polish. The results show that the use of active verbs with nouns referring to the abstracted article or its part is more than twice less frequent in Polish than in English, with considerable differences between the types of verbs employed in such contexts in the two languages. Three factors are proposed as potentially affecting the compatibility of the Polish verb with an inanimate, text-denoting noun: the type of agency, the supported metaphor/metonymy for the research article, and verb aspect/telicity.  © 2022 Walter de Gruyter GmbH, Berlin/Boston.",TestAnalysis
"The online depression community (ODC) has become a popular resource for people with depression to manage their mental health during the COVID-19 pandemic. This study proposed a novel perspective based on response style theory to investigate whether depression individuals’ distractive and ruminative behaviors in ODC were related to social support received and co-rumination. Furthermore, we explored the influences of social support and co-rumination on suicidal behaviors using panel data set. We collected text data from 22,286 depressed users of a large ODC in China from March 2020 to July 2021, and conducted text mining and econometrics analyses to test our research questions. The results showed that depression users’ online ruminative behaviors had a positive relationship with the co-rumination and had a negative relationship with social support received. Besides, constructive distractive behaviors (i.e., providing social support to others) increased the support users received from others but had a negative relationship with co-rumination. Depression users' future suicidal behaviors are influenced by past received social support and co-rumination. The received social supports and co-rumination have a negative and positive influence on depression users' future suicidal behaviors, respectively. Our results enrich the application of response style theory in online medicine. They provide meaningful insights into behaviors that influence the acquisition of online social support and the incidence of online co-rumination in ODCs. This study helps relevant institutions to conduct more targeted online suicide interventions for depression patients. © 2022 Elsevier Ltd",TestAnalysis
"Progression in the popularity of social media activities had provided huge amount of data in the form of text that can immeasurably augment its specialty. This textual data offers a platform for the reviewers to share their comments about any product, service or event on social media. These types of discussions among the reviewers boost the demand and supply in business and industry field. Furthermore, for every passing day the textual data is also increasing in amount which makes data mining especially sentiment analysis or opinion mining, a research hungry area. This is mainly because of data is represented in the form of calculations about reviewers’ comments, assessment, attitudes, behavior and emotions to individual issues, events, topics, services and attributes. Previously, researchers focus on systems to recognize and categorize sentiments from the written material where opinions are extremely unstructured, assorted and classified. In this paper, authors try to presents a meticulous survey on sentiment analysis with classification, in which one hundred and forty three articles were reviewed regarding important activities, approaches, applications with multilingual and cross domain jobs. This systematic survey considers published literature during 2010-2021, organized based on machine learning, lexicon and hybrid approaches with multilingual and cross domain knowledge. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"The publisher regrets the following conflict of interest text was not published. • All the authors listed in this article have made Substantial contributions to the conception or design of the work; or the acquisition, analysis, or interpretation of data for the work; AND Drafting the work or revising it critically for important intellectual content; AND Final approval of the version to be published. • I also undertake that the article represents valid work. Neither this article nor any part of it has been copied or plagiarized from other works. • That the article has not been published so far OR communicated OR in simultaneous consideration to some other journal. • I also undertake that the authors have disclosed all potential conflict of interests associated with the work. The publisher would like to apologise for any inconvenience caused. © 2022 The Author(s)",TestAnalysis
"Background: Gastric adenocarcinoma (GAC) is the fifth most common cancer in the world, and the presence of germline pathogenic variants has been linked with approximately 5% of gastric cancer diagnoses. Multiple GAC susceptibility genes have been identified, but information regarding the risk associated with pathogenic variants in these genes remains obscure. We conducted a systematic review of existing studies reporting the penetrance of GAC susceptibility genes. Methods: A structured search query was devised to identify GAC-related papers indexed in MEDLINE/PubMed. A semi-automated natural language processing algorithm was applied to identify penetrance papers for inclusion. Original studies reporting the penetrance of GAC were included and the full-text articles were independently reviewed. Summary statistics, effect estimates, and precision parameters from these studies were compiled into a table using a predetermined format to ensure consistency. Results: Forty-five studies were identified reporting the penetrance of GAC among patients harboring mutations in 13 different genes: APC, ATM, BRCA1, BRCA2, CDH1, CHEK2, MLH1, MSH2, MSH6, PMS2, MUTYH-Monoallelic, NBN, and STK11. Conclusion: Our systematic review highlights the importance of testing for germline pathogenic variants in patients before the development of GAC. Management of patients who harbor a pathogenic mutation is multifactorial, and clinicians should consider cancer risk for each applicable gene–cancer association throughout the screening and management process. The scarcity of studies we found investigating the risk of GAC among patients with pathogenic variants in GAC susceptibility genes highlights the need for more investigations that focus on producing robust risk estimates for gene–cancer associations. © 2022, Society of Surgical Oncology.",TestAnalysis
"Objective: To determine if lung sonography is accurate in assessing and confirming pulmonary compromise and thereby reduce the risk of x-ray exposure, for pediatric patients. Materials and Methods: This study was a systematic review of individual published studies. PubMed was the only database used for the article search. A review by a committee of contributors determined whether studies met the specific inclusion criteria. Studies reviewed had participants between the ages 0 and 18 years, with lung compromise of varying pathophysiological diagnoses. Each intervention was coded by levels of evidence; grading of recommendations, assessment, development, and evaluation (GRADE); the evidence alert traffic light grading system; and risk of bias in nonrandomized studies of interventions. Each article was evaluated using the Cochrane assessment of bias and GRADE evidence tables. Results: Thirty-seven articles were retrieved. Of those, 21 articles were removed following title and abstract screening. With 16 articles remaining, only one duplicate was removed. Based on the 15 articles extracted, in full-text versions, only two articles were noted to be irrelevant, and one article was not provided in English. Only 12 articles met the eligibility criteria, but two articles had to be removed because they were systematic reviews and not individual studies. The final analysis was based on 10 articles that met the inclusion criteria. Conclusion: Once reviewed, all 10 articles indicated that lung sonography had high accuracy and confirmation of lung compromise, which spanned multiple pulmonary diagnoses, in pediatric patients. When used by a trained clinician, lung sonography was as highly effective in comparison to other diagnostic tools, such as a chest radiograph and computed tomography. © The Author(s) 2022.",TestAnalysis
"Background: Mainstream economic evaluations methods may not be appropriate to capture the range of effects triggered by interventions for people with intellectual disabilities. In this systematic review, we aimed to identify, assess and synthesise the arguments in the literature on how the effects of interventions for people with intellectual disabilities could be measured in economic evaluations. Method: We searched for studies providing relevant arguments by running multi-database, backward, forward citation and grey literature searches. Following title/abstract and full-text screening, the arguments extracted from the included studies were summarised and qualitatively assessed in a narrative synthesis. Results: Our final analysis included three studies, with their arguments summarised in different methodological areas. Conclusions: Based on the evidence, we suggest the use of techniques more attuned to the population with intellectual disabilities, such sensitive preference-based instruments to collect health states data, and mapping algorithms to obtain utility values. © 2022 The Authors. Journal of Applied Research in Intellectual Disabilities published by John Wiley & Sons Ltd.",TestAnalysis
"The replies of people seeking support in online mental health communities can be analyzed to discover if they feel better after receiving support; feeling better indicates a cognitive change. Most research uses key phrase matching and word frequency statistics to identify psychological cognitive change, methods that result in omissions and inaccuracy. This study constructs an intelligent method for identifying psychological cognitive change based on natural language processing technology. It incorporates information related to emotions that appears in reply text to help identify whether psychological cognitive change has occurred. The model first encodes the emotion information based on rule matching and manual annotation, then adds the encoded emotion lexicon and a cognitive change lexicon to a word2vec high-dimensional semantic word vector training, converts the annotated cognitive change recognition text into a vector matrix using the trained model, and train in the annotated text using TextCNN. To compare the results with those of the traditional methods (key phrase matching and sentiment word frequency statistics), this study uses a semi-automated approach to construct a lexicon of psychological cognitive change, as well as a keyword lexicon without cognitive change, based on word vectors and similarity. We compare the performance of the classifier before and after the fusion of the graphical emotion information, compare the LSTM and Transformer as baselines, and compare traditional word frequency statistics methods. The experimental results show that our proposed classification model performs better than the others; it achieves 84.38% precision, an 84.09% recall rate, and an 84.17% F1 value. Our work bears methodological implications for online mental health platforms. © 2022",TestAnalysis
"Industry 4.0 is an important contributor to industrial innovation and sustainability. Nevertheless, few studies empirically analyse how it acts as a binding force of both business practices. This study examines 1501 sustainability reports using a mixed human-artificial intelligence method based on Python's text mining libraries. This method takes advantage of AI's capabilities to extract information from large samples of data and of human critical thinking to find patterns in those data. Specifically, the method is used to evaluate the adoption of Industry 4.0 technologies, analyse how they are deployed worldwide, and investigate their sustainability outcomes. In terms of overall frequency, robots and cybersecurity are the most often reported technologies. Broken down by the firm's region, Asian firms have the highest rate of adoption, while African firms are lagging. Regarding the themes, Industry 4.0 is mainly adopted to improve production processes and customer experience. A small percentage of firms, particularly in Europe and North America, utilize Industry 4.0 to reduce the environmental footprint of their operations. Furthermore, results indicate that Industry 4.0 and sustainability are following two routes. Some firms have massively adopted Industry 4.0 to increase operational efficiency and reaped environmental gains as an indirect consequence of improved operations. Others have chosen to balance the adoption of technologies aimed to increase productivity with innovations whose explicit aim is the reduction of their operations' environmental footprint, such as additive manufacturing. Eastern firms tend to follow the first route while western firms the second. African and South American firms are still at a very early stage in their Industry 4.0 and sustainability journey. At the global level, Industry 4.0 is still far from being utilized as a catalyst to develop sustainability-driven business models. © 2023 Elsevier Inc.",TestAnalysis
"In this paper, we compare different methods to extract skill demand from the text of job descriptions. We propose the fraction of wage variation explained by the extracted skills as a novel performance metric for the comparison of methods. Using this, we compare the performance of the word-counting method with three different dictionaries and that of three unsupervised topic-modeling techniques, the LDA, the PLSA and the BERTopic. We apply these methods to a U.K. job board dataset of 1,158,926 job advertisements from 35 industries collected in 2018. We find that each of the dictionary-based methods explain about 20% of the wage variation across jobs. The topic modeling techniques perform better as the PLSA is able to explain 36.5% of the wage variation, while BERTopic 32.6%. The best performing method is the LDA with 48.3% of the wage variation explained. Its disadvantage, however, is in the difficulty of interpretation of the skills extracted. © 2022 Elsevier Ltd",TestAnalysis
"Objective: The aim of the present study was to assess the current strategies of endovascular and laparoscopic extravascular stenting for symptomatic compression of the left renal vein (LRV), most frequently between the aorta and superior mesenteric artery (nutcracker syndrome [NCS]). Methods: We performed a systematic review of all studies of endovascular and laparoscopic extravascular LRV stenting for NCS using the PubMed/MEDLINE, Scopus, Embase, Cochrane, Science Citation Index Expanded, Emerging Sources Citation Index, and Epistemonikos databases. Data were collected in accordance with the PRISMA (preferred reporting items for systematic reviews and meta-analysis) guidelines. The English, Spanish, and German language literature was searched from January 1, 1946 to February 9, 2022. The outcomes assessed included symptom resolution, hematuria resolution, and reintervention at follow-up. Results: The search yielded 3498 reports. After removing the duplicates and those without the full text available, 1724 studies were screened. Of these, 11 studies were included in the present review. Of the 11 studies, 7 were on endovascular stenting and 4 on laparoscopic extravascular stenting; all 11 studies were retrospective, single-center case series. Of the 233 patients, 170 (80 women) had undergone endovascular stenting and 63 (9 women) had undergone extravascular stenting. The follow-up period varied from 1 to 60 months after endovascular stenting and 3 to 55 months after extravascular stenting. The symptoms had resolved in 76% (range, 50%-100%) after endovascular stenting and 83% (range, 71%-100%) after extravascular stenting. Hematuria had resolved in 86% (range, 60%-100%) after endovascular stenting and 89% (range, 77%-100%) after extravascular stenting. Of 185 patients, 9 had required reintervention after endovascular stenting and none after extravascular stenting. Conclusions: Endovascular and laparoscopic extravascular stenting are less invasive and, thus, more attractive treatment options that have been more recently developed for the management of NCS. The results from the present study have shown that symptom and hematuria resolution must be provided before they can be considered preferred management options for patients affected by NCS. Given the limited number of patients involved, no definitive conclusion could be drawn regarding the superiority of one technique compared with the other. © 2022 Society for Vascular Surgery",TestAnalysis
"Automatically assessing academic papers has enormous potential to reduce peer-review burden and individual bias. Existing studies strive for building sophisticated deep neural networks to identify academic value based on comprehensive data, e.g., academic graphs and full papers. However, these data are not always easy to access. And the content of the paper rather than other features outside the paper should matter in a fair assessment. Furthermore, while BERT models can maintain general semantics by pre-training on large-scale corpora, they tend to be over-smoothing due to stacked self-attention layers among unfiltered input tokens. Therefore, it is nontrivial to figure out distinguishable value of an academic paper from its limited content. In this study, we propose a novel deep neural network, namely Dual-view Graph Convolutions Enhanced BERT (DGC-BERT), for academic paper acceptance estimation. We combine the title and abstract of the paper as input. Then, a pre-trained BERT model is employed to extract the paper's general representations. Apart from hidden representations of the final layer, we highlight the first and last few layers as lexical and semantic views. In particular, we re-examine the dual-view filtered self-attention matrices via constructing two graphs, respectively. After that, two multi-hop Graph Convolutional Networks (GCNs) are separately employed to capture pivotal and distant dependencies between the tokens. Moreover, the dual-view representations are facilitated by each other with biaffine attention modules. And a re-weighting gate is proposed to further streamline the dual-view representations with the help of the original BERT representation. Finally, whether the submitted paper could be acceptable is predicted based on the original language model features cooperated with the dual-view dependencies. Extensive data analyses and the full paper based MHCNN studies provide insights into the task and structural functions. Comparison experiments on two benchmark datasets demonstrate that the proposed DGC-BERT significantly outperforms alternative approaches, especially the state-of-the-art models like MHCNN and BERT variants. Additional analyses reveal significance and explainability of the proposed modules in the DGC-BERT. Our codes and settings have been released on Github (https://github.com/ECNU-Text-Computing/DGC-BERT). © 2022 Elsevier Ltd",TestAnalysis
"Along with the proliferation of big data technology, organizations are involved in an overwhelming data ocean, the huge volume of data makes them at a loss in the face of frequent data breaches due to their failure of efficient data security management. Data classification has become a hot topic as a cornerstone of data protection especially in China in recent years, by categorizing information types and distinguishing protective measures at different classification levels. Both the text and tables of the promulgated data classification-related regulations (for simplicity, laws, regulations, policies, and standards are collectively referred to as “regulations”) contain a wealth of valuable information which can guide the work of data classification. To best assist data practitioners, in this paper, we automatically “grasp” expert experience on how to classify data from the analysis of such regulations. We design a framework, GENONTO, that automatically extracts data classification practices (DCPs), such as information types and their corresponding sensitive levels to construct an information type lexicon as well as to encode a generic ontology on top of 38 real-world regulations promulgated in China. GENONTO employs machine learning techniques and natural language processing (NLP) to parse unstructured text and tables. To our knowledge, GENONTO is the first work that explores critical information like the category and the sensitivity of information types from regulations, and organizes them in a structured form of ontology, characterizing the subsumptive relations between different information types. Our research helps provide a well-defined integrated view across regulations and bridges the gap between what experts say and how data practitioners do. © 2022 Elsevier Ltd",TestAnalysis
"Small things loom large as a distinct category in social and cultural analysis. However, the social construction and effects of this idiom of scale commonly remain vague and underexplored. Bringing the literature on quantification in conversation with the literature on scale-making, this article offers a theoretically-informed analysis of how smallness consolidates as a publicly salient social attribute, and how it feeds collective narratives. The empirical focus is on American Jewry – an ethnoreligious minority group whose leaders and experts have invested in its quantification, including its representation as a small population. Drawing on a variety of texts and images, as well as on interviews and fieldwork, I show that American Jewish research bodies and public figures engage in a myriad of comparative arithmetic exercises and spectacles of scale to assert the smallness of the population. Deploying smallness as a generative narrative tool allows them to engage with the ambivalences implicated in the American-Jewish post-Holocaust, minority, and diasporic experience. In particular, exercises around notions of numerical negligibility, disproportional success, and numerical inferiority elicit protean narratives around endangerment, power, and a questioned diasporic future. The broader theoretical intervention of this article is to offer scalemaking as a valuable prism for understanding the narrative potency and poignancy of arithmetically-based constructs such as smallness. Instead of emphasizing the assumed epistemological strengths of numbers, this article considers the narrative work that statistics do when they lend themselves to multimodal scaling. It argues that through scaling, statistics are infused with perspective, relevance and meaning, descriptively and prescriptively. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.",TestAnalysis
"Purpose: To evaluate outcomes of anterior cruciate ligament (ACL) rupture in patients ≥40 years treated nonoperatively or with ACL reconstruction (ACLR). Methods: A review of MEDLINE, CINAHL, SportDiscus, Embase, Web of Science, and Cochrane databases from inception to June 1, 2021, was performed to identify randomized controlled trials, prospective or retrospective cohorts, case controls, or case series that met the following criteria: English-language studies reporting at least one subjective and/or objective outcome measure in ACL rupture patients ≥40 years treated nonoperatively or by ACLR. No limits were placed on graft type, time-to-surgery/follow-up, or concomitant procedures. Variability in patient-reported outcome scores, including subjective IKDC score, Lysholm score, Tegner activity score, and Knee Injury and Osteoarthritis Outcome Score, was assessed to evaluate the utility of applying previously established clinically meaningful thresholds to pooled outcome data. Results: 12,605 citations were identified using screening criteria. Sixty studies satisfied criteria following full-text review. As previous systematic reviews reported on earlier literature evaluating ACLR outcomes in patients ≥40 years, studies in this review were limited to include only those published in the last 10 years (40 studies). An additional 16 studies were excluded based on aims of the review not identified during initial screen. Although preoperative to postoperative population-based improvements in Lysholm score, Tegner score, and IKDC score surpassed minimal clinically important differences (MCID) in at least 50% of studies, the variability present in the pooled data may limit its application. No studies evaluated nonoperative outcomes. Conclusions: Evidence supports operative management in patients ≥40 years, as studies generally demonstrated preoperative to postoperative improvements in clinical outcomes based on population-level changes. However, application of patient-level clinically relevant thresholds to pooled outcome data should be undertaken with caution as reporting of population-based outcome scores may not accurately reflect changes in individual patients. Level of Evidence: Systematic review, IV. © 2022 Arthroscopy Association of North America",TestAnalysis
"This article aims to interpret and theorise non-Indigenous health students’ emotional learning experiences within a cultural safety course from an Australian First Peoples’ perspective. All undergraduate health students enrolled in a First Peoples’ health and cultural safety course were invited to complete a post-course online survey. The survey included quantitative items along with six free-text responses about students’ emotional learning experiences. The free-text comments provided by 72 health students are the focus of this article. Drawing upon Kamilaroi Country and the metaphor of the river in drought, flood and when waters become clear, this research provides a synthesis of non-Indigenous health students’ emotions in the cultural safety classroom. Students acknowledged the powerful impact of work undertaken by First Peoples educators in sharing their narratives, creating safe spaces and bearing witness to students’ emotions. The analysis informs an understanding of student learning and recommendations for teaching practice. © The Author(s) 2022.",TestAnalysis
"An imbalance in the population gender ratio is a real-world problem that China faces. A related issue is how the ratio imbalance will affect FinTech innovation. Based on a theoretical analysis, this paper uses text mining and CRITIC methods to construct a provincial FinTech innovation index from 2008 to 2018 and studies the impact of the gender ratio on FinTech innovation. The results show that the gender imbalance can promote FinTech innovation by increasing the social risk-taking level. It is also found that an imbalanced gender ratio also increases FinTech risk exposure. This paper provides insights into the demographic reasons behind the rise and development of China's FinTech industry. © 2022",TestAnalysis
"Sentiment analysis on views and opinions expressed in Indian regional languages has become the current focus of research. But, compared to a globally accepted language like English, research on sentiment analysis in Indian regional languages like Malayalam are very low. One of the major hindrances is the lack of publicly available Malayalam datasets. This work focuses on building a Malayalam dataset for facilitating sentiment analysis on Malayalam texts and studying the efficiency of a pre-trained deep learning model in analyzing the sentiments latent in Malayalam texts. In this work, a Malayalam dataset has been created by extracting 2,000 tweets from Twitter. The bidirectional encoder representations from transformers (BERT) is a pre-trained model that has been used for various natural language processing tasks. This work employs a transformer-based BERT model for Malayalam sentiment analysis. The efficacy of BERT in analyzing the sentiments latent in Malayalam texts has been studied by comparing the performance of BERT with various machine learning models as well as deep learning models. By analyzing the results, it is found that a substantial increase in accuracy of 5% for BERT when compared with that of Bi-GRU, which is the next best-performing model. © 2023 Institute of Advanced Engineering and Science. All rights reserved.",TestAnalysis
"Aims: This paper aims to conduct a Systematic Literature Review (SLR) of the relative applications of text mining in cybersecurity. Objectives: The amount of data generated worldwide has been attributed to a change in different activities associated with cyber security, and demands a high automation level. Methods: In the cyber security domain, text mining is an alternative for improving the usefulness of various activities that entail unstructured data. This study searched databases of 516 papers from 2015 to 2021. Out of which, 75 papers are selected for analysis. A detailed evaluation of the selected studies employs sources, techniques, and information extraction on cyber security applications. Results: This study extends gaps for future studies, such as text processing, availability of datasets, innovative methods, and intelligent text mining. Conclusion: This study concludes with interesting findings of employing text mining in cybersecurity applications; the researchers need to exploit all related techniques and algorithms in text mining to detect and protect the organization from Cybersecurity applications. © 2023 Bentham Science Publishers.",TestAnalysis
"Background and purpose: Approximately 30% of epilepsy patients develop a drug-refractory epilepsy, that is, seizures cannot be controlled with antiepileptic drugs. Surgery has been evaluated as an effective but costly form of treatment. The aim of this systematic review is to synthesize the available evidence on the cost-effectiveness of surgical treatment compared to medical treatment for these patients. Method: A systematic literature search was performed in MEDLINE, Embase, PsycINFO, Cochrane Library and the National Health Service Economic Evaluation Database until September 2022. Title, abstract and full-text screening were conducted by two researchers. Original studies published in English or German analyzing the cost-effectiveness of surgical compared to medical treatment were included. Study characteristics, effectiveness measures, costs and incremental cost-effectiveness ratios (ICERs) were extracted. The quality of studies was assessed using the Drummond checklist. Results: Fourteen studies were included. Most studies evaluated surgery as cost-effective. The ICER per patient seizure free ranged from dominant to purchasing power parity US dollars (PPP-USD) 479,275. The ICER per 1% seizure reduction ranged from PPP-USD 227 to PPP-USD 342. The ICER per year without seizures was PPP-USD 4202 and the ICER per quality-adjusted life-year ranged from dominant to PPP-USD 90,874. The studies varied greatly in their methodology and time horizon. Conclusion: Surgical treatment is cost-effective compared to medical treatment, especially when a lifetime horizon is adopted. It is concluded that all disease-specific costs should be considered over a long period when assessing the cost-effectiveness of epilepsy treatment. From an economic perspective, efforts should be made to improve access to surgical treatment for patients with drug-refractory epilepsy. © 2022 European Academy of Neurology.",TestAnalysis
"This paper utilizes recent advances in automated text analysis to investigate whether and how the shifting inflation focus in the monetary policy strategy of the Federal Reserve (Fed) is reflected in the transcripts of the Federal Open Market Committee (FOMC) meetings over the course of the last quarter century. We ascertain that inflation references have surged in the FOMC's communication long before the implementation of the Fed's explicit inflation targeting framework in 2012. We go on to assess whether the FOMC's inflation communication had a direct impact on the monetary policy decisions of the Fed by estimating Taylor-type rules augmented by the FOMC's tone-measured inflation references. We find these to induce quantitatively small but positive effects on the policy rate and the inflation reaction coefficient. In this sense, the FOMC communication on inflation reflects the Fed's monetary policy stance quite closely. However, all these effects already occur prior to 2012, whereas the actual implementation of the inflation targeting framework itself elicits no further monetary tightening. Our evidence is in line with the FOMC's communication at the time framing the implementation of inflation targeting as a continuation of the pursuit of the price stability objective rather than as a genuine change in the Fed's monetary policy regime. © 2023 Elsevier Inc.",TestAnalysis
"This study examines the influence of digital finance on green growth using China's city-level data from 2008 to 2019. Web crawler technology and a super-efficiency SBM model are employed to measure inclusive digital finance and green growth. For mechanism analysis, it innovatively quantifies the enterprise digital transformation using Big Data text and factor analysis techniques from the unique perspective of disclosing textual information about “enterprise digital transformation”. The results exhibit that inclusive digital finance significantly promotes green growth, and these results are consistent using robust standard error estimation, bootstrap sampling, endogenous estimators, and alternative proxies. The regional samples demonstrate heterogeneous outcomes, suggesting that the influence of digital finance is more pronounced in eastern and central regions than in the western region. Moreover, the asymmetric effect of digital finance is documented through panel quantile regression. It displays that the influence of digital finance turns stronger from the 3rd to 7th quantile and decreases hereafter. Manifestly, the mechanism analysis discovers that digital finance encourages green growth by supporting the digital transformation of enterprises and addressing energy poverty. These findings offer valuable policy recommendations for legislators. © 2022 Elsevier Inc.",TestAnalysis
"The proposed hybrid fifth Generation-based approaches are employed to analyze and investigate the feedback of 37,855 patients from 65 hospitals worldwide and gathered through various online modes. The collected data was analyzed with various cloud-computing technologies such as Artificial Intelligence (AI) based algorithms like natural language pre-processing (NLP), text mining (TM), and sentiment analysis (SA). This work discusses the new opportunities in the healthcare sector and the capabilities that 5G influences can bring to the healthcare industry. According to a recent investigation, the overall assessment ranking agrees with the personal view (sentiment) rating analysis for the title and full element of the web-based feedback obtained from the patients of different hospitals worldwide through an online survey. There are five main categories in the healthcare sector for which patients give priority and expect good services. They are treatment, physical facilities, dependability, timely committed service, and responsiveness. This research makes theoretical and practical contributions to the interdisciplinary areas comprising computer science, data management, and healthcare services by utilizing recent analytic techniques to attain optimized results. © 2022",TestAnalysis
"Existing personality detection methods based on user-generated text have two major limitations. First, they rely too much on pre-trained language models to ignore the sentiment information in psycholinguistic features. Secondly, they have no consensus on the psycholinguistic feature selection, resulting in the insufficient analysis of sentiment information. To tackle these issues, we propose a novel personality detection method based on high-dimensional psycholinguistic features and improved distributed Gray Wolf Optimizer (GWO) for feature selection (IDGWOFS). Specifically, we introduced the Gaussian Chaos Map-based initialization and neighbor search strategy into the original GWO to improve the performance of feature selection. To eliminate the bias generated when using mutual information to select features, we adopt symmetric uncertainty (SU) instead of mutual information as the evaluation for correlation and redundancy to construct the fitness function, which can balance the correlation between features–labels and the redundancy between features–features. Finally, we improve the common Spark-based parallelization design of GWO by parallelizing only the fitness computation steps to improve the efficiency of IDGWOFS. The experiments indicate that our proposed method obtains average accuracy improvements of 3.81% and 2.19%, and average F1 improvements of 5.17% and 5.8% on Essays and Kaggle MBTI dataset, respectively. Furthermore, IDGWOFS has good convergence and scalability. © 2022 Elsevier Ltd",TestAnalysis
"Studies investigating L2 English receptive and productive vocabulary knowledge in young learners have shown that English can be picked up through exposure outside the classroom. In this study I looked into lexical characteristics of young learners’ writing at the start of formal English lessons in the first year of secondary school (n = 3168). The texts were given a holistic score and several lexical measures were calculated. The results showed large individual differences between learners’ writing. Regression analysis was used to investigate which lexical characteristics predicted proficiency scores. The final model explained 50% of the variance. Similar to what was found in previous research investigating young L2 English learners’ writing I found that a number of broad predictors impacted the proficiency score. These were lexical diversity, word count, total number of spelling errors and percentage of English words used. Additionally, four fine-grained variables predicted the proficiency score: word frequency, trigram frequency, age of acquisition and imageability. The results show the added value of investigating a wide range of variables to shed light on the lexical factors that might impact writing scores, even in beginner and pre-intermediate level L2 writing. © 2022 Elsevier Inc.",TestAnalysis
"Several research studies have been conducted on multi-label classification algorithms for text and images, but few have been conducted on multi-label classification for users. Moreover, the existing multi-label user classification algorithm does not provide an effective representation of users, and it is difficult to use directly in social media scenarios. By analyzing complex social networks, this paper aims to achieve multi-label classification of users based on research in single-label classification. Considering the limitations of existing research, this paper proposes a user topic classification method based on heterogeneous networks as well as a user multi-label classification method based on community detection. The model is trained using the ML-KNN multi-label classification algorithm. In actual scenarios, the algorithm is more effective than existing multi-label classification methods when applied to multi-label classification tasks for social media users. According to the results of the analysis, the algorithm has a high level of accuracy in classifying different theme users into a variety of different scenarios using different theme users. Furthermore, this study contributes to the advancement of classification research by expanding its perspective. © 2022",TestAnalysis
"This article explores the elaboration and application of the Old Testament idea of ‘covenant’ among Zambian church leaders who are Christian nationalist activists. In this framework, Zambia serves as an analogue of biblical Israel, while contemporary government and church leaders are the analogues of Old Testament kings, priests, and prophets. This covenantal approach presents challenges. On the one hand, government support for Christian nationalism encourages the compliance of church leaders with state-led religious projects; on the other hand, however, the analogical reading of the biblical text on which this support depends casts the church in a prophetic role, which in turn opens the door for criticism of the government. Christian nationalist activists in Zambia therefore find themselves caught in a double-bind that simultaneously encourages submission and critique. An analysis of this process contributes an important non-Western perspective to contemporary discussions of Christian nationalism. It also complicates easy interpretations of Christian nationalism as abetting state power by demonstrating its critical possibilities. © 2022 The Authors. Journal of the Royal Anthropological Institute published by John Wiley & Sons Ltd on behalf of Royal Anthropological Institute.",TestAnalysis
"The aim of the present study was to examine barriers to reporting sexual offenses as reflected in texts by victims who participated in the #WhyIDidntReport protest that revolved around the reasons for not reporting sexual offenses. Content analysis was used to analyze 95 public posts of Israeli victims published on social media. The findings revealed two main barrier dimensions—personal and social—each comprising several main themes. The most common barrier in the personal dimension was difficulty naming or labeling the experience as a sexual offense to begin with. The most prominent barriers in the social dimension were the power gap between offender and victim, and concern with others' reactions. We discuss the theoretical and practical implications of our findings from the perspectives of alternative dispute resolution, with focus on restorative justice as an optional platform for victims. © 2022 The Authors. Conflict Resolution Quarterly published by Wiley Periodicals LLC.",TestAnalysis
"Background: This conceptual paper is an invitation to reflection and action, and is especially targeted to social marketing researchers and professionals to sensitize and engage in recent efforts to break with the limited and low coverage of investigations and interventions in the field on the topics of racism and anti-racism. Filling this gap is a challenge to be faced by academics and social marketers so that the area can properly connect, understand and contribute to contemporary movements that are challenging society for change. Focus of the Article: This study aims to explicate and delineate conceptual approximations between the thinking and practices of social marketing and anti-racism to explore the observation of points of dialogue and potential, while the articulation of these approaches can accelerate and strengthen positive social changes. Research Questions: What is anti-racism? What aspects and actions circumscribe and contribute to integrating anti-racism and social marketing knowledge? How can this articulation support the analysis and development of anti-racist social marketing strategies and interventions? Importance to the Social Marketing Field: This paper contributes to encourage an expansion of mentality, knowledge and behavior related to racial issues and social marketing, and to stimulate ideas that, supported by anti-racism studies and interventions, provide paths that can be continuously adopted in the research, design and implementation of social marketing initiatives. Methods: This conceptual article is organized by a literature survey, from sources such as recent meta-analyses, reviews and experimental studies from marketing, communication, education, and social and cognitive psychology, in order to understand the conceptual aspects of racism and anti-racism and their expressions in the contemporary world. Also, there are some case and practice suggestions on how anti-racism and social marketing can be aligned to address racism. The literature explored in this article is published in English and Portuguese. Results: The anti-racism aspects presented in this text cover and provide paths that can be useful and explored in different directions in social marketing research and practice. From this perspective, the shared conceptual organization can also support academics and professionals in the area, unfamiliar with studies on racism and anti-racism expressions, to integrate these concepts in their research, plans and programs of intervention or review in these activities. Recommendations for Research or Practice: The reported case and practice suggestions are not analyzed in depth. However, this is a task that should be developed critically and with more attention in future works, considering the developments, metrics, sustainability, backlash effects, and effectiveness or not of recent initiatives. More broadly, it is also pointed out that anti-racist commitments and initiatives of companies’ diversity and inclusion programs, such as those reviewed in the text, should be considered as relevant sources of analysis for social marketing studies. © The Author(s) 2022.",TestAnalysis
"This partially longitudinal study focussed on the ability of pupils to write descriptive texts in English and French as foreign languages and German as language of schooling. The teaching of two foreign languages from primary school onwards is compulsory in Switzerland, where this study is situated. The study responds to the urgent need for empirical research on cross-linguistic and cross-level development as a foundation for the improvement of language teaching. Current curricula do provide for the coherent fostering of the plurilingual repertoires of learners, across languages and school levels. But this still stands in sharp contrast to the multiple compartmentalisations and discontinuities induced by the educational system. Letters with spatial descriptions were collected in a quasi-experimental design in the canton of St. Gallen at the end of primary school (Year 6, N=185) and in the first year of secondary school (Year 7, N=218). The texts were analysed in terms of spatial organisation and text length. Moderate but statistically significant correlations between languages were found for both variables. The analysis revealed continuity of the development in the foreign languages, but stagnation in the language of schooling. The benefits of fostering transversally accessible textual patterns through a genre-based approach, in particular for the second foreign language (L3), are discussed.  © 2023 Walter de Gruyter GmbH, Berlin/Boston.",TestAnalysis
"Objectives: Real-world evidence (RWE) studies are increasingly being used to support healthcare decisions. Various frameworks, tools, and checklists exist for ensuring quality of real-world data, designing robust studies, and assessing potential for bias. In January 2021, Structured Template and Reporting Tool for RWE (STaRT-RWE) was released to further reduce ambiguity, assumptions, and misinterpretation while planning, implementing, and reporting RWE studies of the safety and effectiveness of treatments. The objective of this study was to identify gaps in the reporting quality of published RWE studies by using this template for critical appraisal. Methods: Two reviewers conducted a keyword search on PubMed for free-full-text research articles using real-world data, RWE design, and safety with or without effectiveness outcomes of a medicinal product or intervention in humans of any age or gender, published in English between January 13, 2021, and January 13, 2022. Assessment of risk of bias was done using Assessment of Real-World Observational Studies critical appraisal tool. Deficiencies in methods and findings as per STaRT-RWE template were reported as frequencies. Results: A total of 54 of 2374 retrieved studies were included in the review. Based on the STaRT-RWE template, the studies inadequately reported empirically defined covariates, power and sample size calculation, attrition, sensitivity analyses, index date (day 0) defining criterion, predefined covariates, outcome, metadata about data source and software, objective, inclusion and exclusion criteria, analysis specifications, and follow-up. Conclusions: The use of STaRT-RWE template along with its tables, design diagram, and library of published studies has a potential of improving robustness of RWE studies. © 2022",TestAnalysis
"Sentiment analysis has become one of the most active research areas in natural language processing, and the Arabic language retains its importance in this field. It is so because of the increased use of Arabic on the internet that pushes many users to share their views or thoughts about certain products and services. Despite its crucial importance, most of the existing Arabic sentiment analysis studies have been performed on document or sentence levels with little attention to the aspect level. However, the aspect level’s main objective, also known as aspect-based sentiment analysis, is to extract the discussed aspects and identify their related sentiment polarities from a given review or text. The result is to provide more detailed information than general sentiment analysis. Therefore, this paper seeks to provide a comprehensive review of the Arabic aspect-based sentiment analysis studies and highlights the main challenges that face the different proposed approaches. The relevant gaps in the current literature and the future research directions in this area are also discussed. This survey can guide future researchers who want to contribute to the improvement of this domain. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.",TestAnalysis
"This study investigated the preparedness and experience of students for the fast-paced convergence of ICT and higher education. Overall, 366 distance students with a history of self-directed learning through correspondence courses were profiled using structured text-based online interviews. Twelve students’ attributes on ICT material possession and competencies and experience of Open Distance and Open Learning (ODeL) were collected and analysed. The findings show that the majority of students (72%) who had prior knowledge about the basic concepts of ODeL modalities indicated satisfaction with the e-learning environment while the learning mode is challenging for traditional students (28%). Statistically significant positive correlations (ρ = 0.00) were observed between ICT competencies or preparedness: the level of prior academic qualifications (HAQ: r2 = 0.35); key challenge faced (KC: r2 = 0.26); and the convenience of ODeL (C.ODeL: r2 = 0.18). To ensure that students are not left behind with the proliferation of ICT in distance education, principal component analysis revealed that having prior knowledge about the ODeL modalities is an important attribute that contributes to students’ preparedness for the e-learning environment, thus bridging the variance between the expected expectations and the actual expectations. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"The Brazilian Supreme Court receives tens of thousands of cases each semester. Court employees spend thousands of hours to execute the initial analysis and classification of those cases—which takes effort away from posterior, more complex stages of the case management workflow. In this paper, we explore multimodal classification of documents from Brazil’s Supreme Court. We train and evaluate our methods on a novel multimodal dataset of 6510 lawsuits (339,478 pages) with manual annotation assigning each page to one of six classes. Each lawsuit is an ordered sequence of pages, which are stored both as an image and as a corresponding text extracted through optical character recognition. We first train two unimodal classifiers: A ResNet pre-trained on ImageNet is fine-tuned on the images, and a convolutional network with filters of multiple kernel sizes is trained from scratch on document texts. We use them as extractors of visual and textual features, which are then combined through our proposed fusion module. Our fusion module can handle missing textual or visual input by using learned embeddings for missing data. Moreover, we experiment with bidirectional long short-term memory (biLSTM) networks and linear-chain conditional random fields to model the sequential nature of the pages. The multimodal approaches outperform both textual and visual classifiers, especially when leveraging the sequential nature of the pages. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TestAnalysis
"Proper attention to the theme of corporeality is crucial for understanding Derrida’s analysis of Hegel in “The Pit and the Pyramid.” This article argues that Derrida’s essay compels us to face the impossibility of giving a wholly coherent account of embodiment. The Aufhebung supposedly unites the exteriority of the corporeal with interiority in a higher unity that cancels and preserves them both; Hegel’s own text reveals, however, that meaning is primordially absent from the body that was thought to incarnate it. And it is this absence of ideal meaning that is originary: Differance conditions the body as it conditions speech, rendering the body other than itself such that it is not categorizable as flesh that is the self or as an object that is not the self. I am and am not my body because the dichotomy between interiority and exteriority breaks down even at the level of the body. Indeed, I am and am not my self; the embodied self is disrupted from the start, never self-contained. Thus embodiment always already testifies to the other. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.",TestAnalysis
"Background: Low back pain is a musculoskeletal disorder (MSD), and Kegel exercise is considered as one of the non-surgical management methods. Therefore, the present systematic review and meta-analysis aimed to estimate the results of randomized clinical trials (RCT) about the effect of pelvic floor muscle-strengthening exercises on reducing low back pain‏.‏ Methods: The present study was conducted according to the Preferred Reporting Items for Systematic Reviews and Meta-analyses (PRISMA) guideline (2020) to January 2022. The relevant studies were searched in the MagIran, SID, PubMed, Embase, Web of Science (WoS), Scopus, ClinicalTrials.gov databases and Google Scholar motor engine using related MeSH/Emtree terms, which were combined with free text word. The heterogeneity of the studies was checked using I2 statistic. Results: Finally, 19 RCTs with a sample size of 456 subjects in the intervention group and 470 in the control group were included in the meta-analysis. The low back pain intensity in the intervention group decreased up to 1.261 ± 0.213 (SMD ± 95% CI) with I2 = 87.60 more than that in the control group (P <0.001). The low back pain intensity in postpartum women decreased up to 1.614 ± 0.312 (95% CI) followed by pregnant women as 1.282 ± 0.479 (SMD ± 95% CI) more than that in other populations. But due to high the heterogeneity in all sub-groups (I2 > 80%) this result should be considered with caution. Meta-regression analysis showed the effect of pelvic floor muscle-strengthening exercises increased by increasing the year of publication, quality assessment score of the article, and the number of weeks of intervention (P<0.05). Conclusion: Based on the results of the present meta-analysis, pelvic floor muscle-strengthening exercises significantly reduce the low back pain intensity. Therefore, these exercises can be regarded as a part of a low back pain management plan. © 2022, Fondazione Società Italiana di Neurologia.",TestAnalysis
"Social media is more and more dominant in everyday life for people around the world. YouTube content is a resource that may be useful, in social computational science, for understanding key questions about society. Using this resource, we performed web scraping to create a dataset of 644,575 video transcriptions concerning net activism and whistleblowing. We automatically performed linguistic feature extraction to capture a representation of each video using its title, description and transcription (downloaded metadata). The next step was to clean the dataset using automatic clustering with linguistic representation to identify unmatched videos and noisy keywords. Using these keywords to exclude videos, we finally obtained a dataset that was reduced by 95%, i.e., it contained 35,730 video transcriptions. Then, we again automatically clustered the videos using a lexical representation and split the dataset into subsets, leading to hundreds of clusters that we interpreted manually to identify a hierarchy of topics of interest concerning whistleblowing. We used the dataset to learn a lexical representation for a specific topic and to detect unknown whistleblowing videos for this topic; the accuracy of this detection is 57.4%. We also used the dataset to identify interesting context linguistic markers around the names of whistleblowers. From a given list of names, we automatically extracted all 5-g word sequences from the dataset and identified interesting markers in the left and right contexts for each name by manual interpretation. The results of our study are the following: a dataset (raw and cleaned collections) concerning whistleblowing, a hierarchy of topics about whistleblowing, the automatic prediction of whistleblowing and the semi-automatic semantic analysis of markers around whistleblower names. This text mining analysis can be exploited for digital sociology and e-democracy studies. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"This brief describes a Ku-band passive time-varying phase shifter (TVPS). The time variable is introduced into the conventional vector-sum phase shifter (VSPS) architecture, and the time-varying vector-sum method is proposed for the first time to realize continuous phase shifting. The proof-of-concept passive TVPS consisting of a quadrature coupler, two 0/180° bi-phase modulators and an output combiner is implemented in 0.13- $\mathbf {\mathrm {\mu }}\text{m}$ CMOS technology with a core area of 2.2 $\mathbf {\times }$ 0.8 mm2, and a field-programmable gate array (FPGA) is used to provide gain-control timing sequences with the modulation frequency of 100 kHz for its four control bits. The timing sequences are optimized to eliminate unwanted sidebands, and the measured sideband suppression ratio (SSR) is -17.2 dBc. For both forward and backward phase shifting modes, measured results show that the proposed TVPS can achieve the phase resolution of 10-bits, RMS phase error of 0.20.5°, RMS gain error of less than 0.2 dB over the 1218 GHz frequency band.  © 2004-2012 IEEE.",TestAnalysis
"With more than one billion active users, Instagram is one of the most widely utilized social media platforms. Although recent research has begun to analyze brand-related images, Instagram remains largely neglected within halal food research. In this study, we aim to fill this research gap by collecting, labeling, aggregating, clustering, analyzing, and mapping halal food images, text, and social tagging on Instagram. In total, approximately 95,000 photos related to #halalfood tag were extracted from Instagram along with data related to photo captions, social tags, and comments on the posted photos. Google’s Cloud Vision Application Programming Interface (API) was employed for image labeling to represent context of the photos. The photos were categorized, based on their label, into food, place, advertisement, event, and unhealthy food. The captions and comments in each category were analyzed using the associate network and sentiment analysis approaches. The study found the most frequent tags in Instagram posts, besides the obvious halal food related tags, were #halalfoodexpo, #halalfoodkorea, #halalfoodfestival, and #burger. Furthermore, the most influential tags, besides the halal food related tags, were #halalfoodexpo, #chicken, #halalfoodkorea, #halaltourism, and #repost. In addition, it was found that most of the Instagram data contain positive sentiments towards halal food. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"Microplastics are considered the major pollutant of the Anthropocene. This study presents a retrospective examination of the literature to characterize microplastic research in marine and freshwater habitats and to explore the interconnections among the topics uncovered. After automated text mining, topic modeling was carried out to track the evolution of research topics in peer-reviewed articles on microplastics published from January 2010 to May 2021. The literature analysis suggested a total of 15 topics. The most representative terms in topics related exclusively to marine habitats were similar and differed from those in the topics related to both marine and freshwater habitats. The observed patterns in the popularity of the topics uncovered suggest that several topics have tended to increase in prevalence over time. However, no topic had high popularity, and only two topics were considered “cold,” i.e., there was a drop in prevalence over time. The topics that had the largest research gaps on average across all topics were also among the most specific, those describing the key themes of certain manuscripts. This type of literature analysis is increasingly necessary so that the scientific knowledge available can be useful in the search for solutions to the environmental problems of today’s society. © 2022, The Author(s), under exclusive licence to Springer Nature Switzerland AG.",TestAnalysis
"Objective: Carpal tunnel syndrome (CTS) is the most common peripheral entrapment mononeuropathy. The purpose of this systematic review is to evaluate the reported clinical effectiveness and safety of ultrasound-guided percutaneous carpal tunnel release (USCTR) for the treatment of CTS. Literature Survey: PubMed, EMBASE, and ScienceDirect databases were queried from database inception to February 20, 2021, to identify clinical studies on USCTR. Methodology: Two reviewers independently completed title, abstract, and full-text screening, and they extracted data in duplicate for analysis. Procedure techniques, outcome measures, and complications were descriptively analyzed. Synthesis: Eighty-seven studies were eligible for screening. Twenty studies (three randomized controlled trials, three prospective cohort studies, and 14 case series) met inclusion criteria, with a total of 1772 USCTR cases. The overall level of evidence was very low, with seven studies with at least moderate risk of bias. Thirteen studies exceeded the minimal clinically important difference (MCID) for the Boston Carpal Tunnel Questionnaire Symptom Severity Scale (BCTQ-SS) and Boston Carpal Tunnel Questionnaire Functional Status Scale (BCTQ-FS), and six studies exceeded the MCID for the Quick Disabilities of Arm, Shoulder & Hand (QDASH). Five studies reported statistically significant improvement in these functional outcome measures as early as the first week post-procedure. A major complication occurred in one patient who developed suspected compartment syndrome, and minor complications were reported in 24 patients. Conclusions: Based on very low level of evidence, early studies suggest that USCTR may be an effective treatment for CTS, with potential for short post-procedure recovery times. © 2022 American Academy of Physical Medicine and Rehabilitation.",TestAnalysis
"Open-world classification requires a classifier not only to classify samples of the observed classes but also to detect samples which are not suitable to be classified as the known classes. State-of-the-art methods train a feature extractor to extract features for separating known classes with limited training data. Then some strategies, such as outlier detector, are used to reject samples from unknown classes based on the feature space. However, they are prone to extract the discriminative features among known classes and cannot model comprehensive features of known classes, which causes the classification errors when detecting the samples from the unknown classes in an open world scenario. Motivated by the theory of psychology and cognitive science, we utilize both class descriptions and commonsense knowledge summarized by human to refine the discriminant features and propose a regularization strategy. The regularization is incorporated into the feature extractor, which is enabled to further improve the performance of our model in an open-world environment. Extensive experiments and visualization analysis are conducted to evaluate the effectiveness of our proposed model. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"Basic emotion classification is one of the main tasks of Sentiment Analysis usually performed by using several machine learning techniques. One of the main issues in Sentiment Analysis is the availability of tagged resources to properly train supervised classification algorithms. This is of particular concern in languages other than English, such as Spanish, where scarcity of these resources is the norm. In addition, most basic emotion datasets available in Spanish are rather small, containing a few hundred (or thousand) samples. Usually, the samples only contain a short text (frequently a comment) and a tag (the basic emotion), omitting crucial contextual information that may help to improve the classification task results. In this paper, the impact of using contextual information is measured on a recently published Spanish basic emotion dataset and the baseline architecture proposed in the Semantic Evaluation 2019 competition. This particular dataset has two main advantages for this paper. First, it was compiled using Distant Supervision and as a result it contains several hundred thousand samples. Secondly, the authors included valuable contextual information for each comment. The results show that contextual information, such as news headlines or summaries, helps improve the classification accuracy over a dataset of distantly supervised basic emotion labelled comments. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"Objective: The diagnostic accuracy of cell-free fetal DNA in screening for rare autosomal trisomies is uncertain. We conducted a systematic review and meta-analysis aiming to determine the predictive value of cell-free DNA in screening for rare autosomal trisomies. Data Sources: PubMed, Embase, and Web of Science were searched from inception to January 2022. Study Eligibility Criteria: All studies that reported on the diagnostic accuracy of cell-free DNA in the detection of rare autosomal trisomies were included. Case series were included if they contained at least 10 cases with diagnostic test results or postnatal genetic testing. Methods: Study appraisal was completed using the Quality Assessment of Diagnostic Accuracy Studies 2 (QUADAS-2) tool. Statistical analysis was performed using random-effects meta-analysis of double-arcsine transformed proportions of confirmed results in the fetus out of the positive tests to obtain a pooled estimate of the positive predictive value. Results: The search identified 7553 studies, of which 1852 were duplicates. After screening 5701 titles and abstracts, 380 studies proceeded to the full-text screen; 206 articles were retrieved for data extraction, of which another 175 articles were excluded. A total of 31 studies, with a total of 1703 women were included for analysis. The pooled positive predictive value of cell-free DNA for the diagnosis of rare autosomal trisomies was 11.46% (95% confidence interval, 7.80–15.65). Statistical heterogeneity was high (I2=82%). Sensitivity analysis restricted to 5 studies at low risk of bias demonstrated a pooled positive predictive value of 9.13% (95% confidence interval, 2.49–18.76). There were insufficient data to provide accurate ascertainment of sensitivity and specificity because most studies only offered confirmatory tests to women with high-risk results. Conclusion: The positive predictive value of cell-free DNA in diagnosing rare autosomal trisomies is approximately 11%. Clinicians should provide this information when offering cell-free DNA for screening of conditions outside of common autosomal trisomies. © 2022 Elsevier Inc.",TestAnalysis
"This paper investigates the soybean futures price prediction problem from a new perspective and proposes an effective prediction model named Two-Stage Hybrid Long Short-Term Memory (TSH-LSTM) by using text data from social media. First, the unstructured text is transformed into structured data by sentiment analysis and text classification methods. The improved sentiment score is computed by combining the degree centrality of sentiment words based on the sentiment dictionary method, and the characteristics of price fluctuations in texts are learned through the text Recurrent Convolutional Neural Networks. Second, the significant relationship between social media features and soybean futures price is assessed through stepwise regression, and the results of such an assessment are used as a basis for the identification of significant factors as input variables of the prediction model. Finally, the TSH-LSTM prediction model is designed, and the final prediction result is acquired through the combination of prediction results of each stage using the error reciprocal method. The empirical results indicate that the incorporation of the social media text feature helps improve forecasting performances. Specifically, the proposed TSH-LSTM is more accurate than univariate LSTM, multivariate LSTM, and eXtreme Gradient Boosting. © 2022 John Wiley & Sons Ltd.",TestAnalysis
"Clustering of multivariate count data has widespread applications in areas such as text analysis and microbiome studies. The need to account for overdispersion generally results in a nonconvex loss function, which does not fit into the existing convex clustering framework. Moreover, prior knowledge of a network over the samples, often available from citation or similarity relationships, is not taken into account. We introduce Dirichlet-multinomial network fusion (DMNet) for clustering multivariate count data, which models the samples via Dirichlet-multinomial distributions with individual parameters and employs a weighted group L1 fusion penalty to pursue homogeneity over a prespecified network. To circumvent the nonconvexity issue, we present two exponential family approximations to the Dirichlet-multinomial distribution, which are amenable to efficient optimization and theoretical analysis. We derive an ADMM algorithm and establish nonasymptotic error bounds for the proposed methods. Our bounds involve a trade-off between the connectivity of the network and its fidelity to the true parameter. The usefulness of our methods is illustrated through simulation studies and two text clustering applications. © 2022 Elsevier B.V.",TestAnalysis
"Sustainability is a major issue in the automotive sector and players are at different points in their transition. Adopting a multi-method approach, we identify the positioning of automotive manufacturers in relation to sustainability, highlighting the main foci of their sustainability strategies. This is achieved using a topic model based on automated language processing. Subsequently, we use a Seemingly Unrelated Regression model, applied to manufacturers' operational data, to establish the degree of alignment between sustainability strategies and operations. Results show that sustainability in the automotive sector is highly differentiated and manufacturers emphasize diverging topics in their communication strategy and have different production practices. In relation to sustainability reporting, we identify certain operational variables, which are significantly related with certain dominant sustainability narratives. © 2022 The Authors. Corporate Social Responsibility and Environmental Management published by ERP Environment and John Wiley & Sons Ltd.",TestAnalysis
"Objective: The most commonly employed diagnostic criteria for identifying thyroid nodules include Thyroid Imaging and Reporting Data System (TI-RADS) and American Thyroid Association (ATA) guidelines. The purpose of this systematic review and meta-analysis is to determine the inter-rater reliability of thyroid ultrasound criteria. Methods: We performed a library search of MEDLINE (Ovid), EMBASE (Ovid), and Web of Science for full-text articles published from January 2005 to June 2022. We included full-text primary research articles that used TI-RADS and/or ATA guidelines to evaluate thyroid nodules in adults. These included studies must have calculated inter-rater reliability using any validated metric. The Quality Appraisal for Reliability Studies (QAREL) was used to assess study quality. We planned for a random-effects meta-analysis, in addition to covariate and publication bias analyses. This study was performed in accordance with Preferred Reporting Items for a Systematic Review and Meta-analysis guidelines and registered prior to conduction (International prospective register of systematic reviews—PROSPERO: CRD42021275072). Results: Of the 951 articles identified via the database search, 35 met eligibility criteria. All studies were observational. The most commonly utilized criteria were ACR Thyroid Imaging and Reporting Data System (TI-RADS) and/or ATA criteria, while the majority of studies employed Κ statistics. For ACR TI-RADS, the pooled Κ was 0.51 (95% confidence interval [CI]: 0.42, 0.57; n = 7) while for ATA, the pooled Κ was 0.52 (95% CI: 0.37, 0.67; n = 3). Due to the small number of studies, covariate or publication bias analyses were not performed. Conclusion: Ultrasound criteria demonstrate moderate inter-rater reliability, but these findings are impacted by poor study quality and a lack of standardization. Laryngoscope, 133:485–493, 2023. © 2022 The American Laryngological, Rhinological and Otological Society, Inc.",TestAnalysis
"This paper introduces the concept of deceptive (de)humanization, the internal belief that an outgroup is less-than-human while dishonestly acknowledging aspects of their humanity for impression management purposes. In a large online experiment (N = 1,169), participants wrote about their false or truthful opinions on an outgroup they perceived as more evolved or less evolved. Following several automated text analyses, the data indicated psychological differences in attention through word patterns. Consistent with prior work, deceptive texts contained fewer self-references and more negative emotion terms than truthful texts, and dehumanizers used more negative emotions than humanizers. New evidence suggests those who wrote deceptively about evolved groups focused the most on negative emotions compared to other participants. This work extends deception and dehumanization theory by investigating how such psychological constructs interact, and how they are reflected linguistically as communicators attempt to manage impressions and maintain a positive self-image. © The Author(s) 2022.",TestAnalysis
"Background: The expressiveness during reading is essential for a fluent reading. Reading prosody has been scarcely studied in an experimental manner, owing to the difficulties in taking objective and direct measures of this reading skill. However, new technologies development has made it possible to analyse reading prosody in an experimental way. Prosodic patterns may vary, not being the same at the beginning of the reading learning process as in adulthood. They may also be altered in disorders such as dyslexia, but little is known about the prosodic characteristics and reading fluency of people with neurodegenerative diseases that cause language impairment, such as Parkinson's disease (PD). Aims: The aim of this work was to study reading fluency in PD considering the prosodic characteristics of its reading. Methods & Procedures: The participants were 31 Spanish adults with PD and 31 healthy controls, aged 59–88 years. Two experimental texts were designed that included declarative, interrogative, and exclamatory sentences and experimental verbs and nouns. The manipulability level of the nouns and the motor content of the verbs were considered. The reading of the participants was recorded and analysed with Praat software. Outcomes & Results: A longer reading duration and a greater number of pauses, especially in verbs, were found in the PD group, which also showed less pitch variation than the control group in the experimental sentences. The control group showed a big initial rise in declarative and interrogative sentences, as well as a stronger final declination in declarative and exclamatory ones, when compared to the PD group. Conclusions & Implications: The use of experimental methodologies for the analysis of reading fluency allows learning more about the prosodic characteristics of people with different pathologies, such as PD. Scarce pitch variability found in the analysis, together with the great number of pauses and the longer reading duration, leads to poorly expressive reading, which compromises fluency in PD. The exhaustive evaluation of the reading fluency of PD patients will make it possible to design more complete assessment methods that will favour the diagnosis and early detection of this pathology. What this study adds: What is already known on this subject • The speech of people with Parkinson's disease (PD) is often impaired by the appearance of hypokinetic dysarthria. The language of people with PD is usually affected with the progression of the disease, with lexico-semantic impairment which mainly affects verbs. Previous literature on reading fluency in PD usually considers reading speed and accuracy, neglecting prosody. Other neurodegenerative diseases with language impairment, such as Alzheimer's disease, commonly cause reading fluency problems. What this paper adds to existing knowledge • This study provides direct and objective measures of the reading fluency (speed, accuracy and prosody) in patients with PD, by the design of experimental texts. Reading fluency characteristics were found to be altered in these patients, especially in pitch variations and reading duration. The reading of Parkinson's patients showed a more flattened pitch. In addition, a greater number of pauses and longer reading durations were also found in the reading of verbs compared to the control group. What are the potential or actual clinical implications of this work? • The use of experimentally created texts makes it possible to analyse the influence of different psycholinguistic variables (frequency, length, motor content, manipulability) on reading fluency, and how the processing of these stimuli could be affected in PD. The objective analysis of the reading fluency characteristics in PD allows the design of more specific evaluation and diagnostic tasks. More complete assessment methods may allow the early detection of the disease. In the same way, it may favour a differential diagnosis with other neurodegenerative diseases. © 2022 Royal College of Speech and Language Therapists.",TestAnalysis
"Computational methods, in particular text-as-data or Natural Language Processing (NLP) approaches, have become popular to study climate change communication as a global and large-scale phenomenon. Scholars have discussed opportunities and challenges of these methods for climate change communication, with some proponents and critics taking strong positions, either embracing the potential of computational methods or critically questioning their value. Mirroring developments in the broader social scientific debate, we aim to bring both sides together by proposing a reflexive, integrative approach for computational research on climate change communication: We reflect on strengths (e.g., making data big and small, nowcasting observations) and weaknesses (e.g., introducing empiricist epistemologies, ignoring biases) of computational approaches. Moreover, we also provide concrete and constructive guidance on when and how to integrate (or not integrate) these methods based on theoretical considerations. We thereby understand computational methods as part of an ever-increasing, diverse toolbox for analyzing climate change communication. This article is categorized under: The Social Status of Climate Change Knowledge > Knowledge and Practice The Social Status of Climate Change Knowledge > Sociology/Anthropology of Climate Knowledge. © 2022 The Authors. WIREs Climate Change published by Wiley Periodicals LLC.",TestAnalysis
"Background aims: Evidence regarding the extent that mesenchymal stromal cells (MSCs) may improve clinical outcomes in patients with coronavirus disease 2019 (COVID-19) has been limited by marked inter-study heterogeneity, inconsistent product characterization and appreciable risk of bias (RoB). Given the evolution of treatment options and trajectory of the pandemic, an updated analysis of high-quality evidence from randomized controlled trials is needed for a timely and conclusive understanding of the effectiveness of MSCs. Methods: A systematic literature search through March 30, 2022, identified all English language, full-text randomized controlled trials examining the use of MSCs in the treatment of COVID-19. Results: Eight studies were identified (316 patients, 165 administered MSCs and 151 controls). Controls evolved significantly over time with a broad range of comparison treatments. All studies reported mortality at study endpoint. Random effects meta-analysis revealed that MSCs decreased relative risk of death (risk ratio, 0.63, 95% confidence interval, 0.42–0.94, P = 0.02, I2 = 14%) with no significant difference in absolute risk of death. MSCs decreased length of hospital stay and C-reactive protein levels and increased odds of clinical improvement at study endpoint compared with controls. Rates of adverse events and severe adverse events were similar between MSC and control groups. Only two (25%) studies reported all four International Society for Cell & Gene Therapy criteria for MSC characterization. Included studies had low (n = 7) or some (n = 1) concerns regarding RoB. Conclusions: MSCs may reduce risk of death in patients with severe or critical COVID-19 and improve secondary clinical outcomes. Variable outcome reporting, inconsistent product characterization and variable control group treatments remain barriers to higher-quality evidence and may constrain clinical usage. A master protocol is proposed and appears necessary for accelerated translation of higher-quality evidence for future applications of MSC therapy. © 2022 International Society for Cell & Gene Therapy",TestAnalysis
"Zero-shot Learning (ZSL) aims to recognize novel classes through seen knowledge. The canonical approach to ZSL leverages a visual-to-semantic embedding to map the global features of an image sample to its semantic representation. These global features usually overlook the fine-grained information which is vital for knowledge transfer between seen and unseen classes, rendering these features sub-optimal for ZSL task, especially the more realistic Generalized Zero-shot Learning (GZSL) task where global features of similar classes could hardly be separated. To provide a remedy to this problem, we propose Language-Augmented Pixel Embedding (LAPE) that directly bridges the visual and semantic spaces in a pixel-based manner. To this end, we map the local features of each pixel to different attributes and then extract each semantic attribute from the corresponding pixel. However, the lack of pixel-level annotation conduces to an inefficient pixel-based knowledge transfer. To mitigate this dilemma, we adopt the text information of each attribute to augment the local features of image pixels which are related to the semantic attributes. Experiments on four ZSL benchmarks demonstrate that LAPE outperforms current state-of-the-art methods. Comprehensive ablation studies and analyses are provided to dissect what factors lead to this success.  © 1991-2012 IEEE.",TestAnalysis
"The assignment of codes to free-text clinical narratives have long been recognised to be beneficial for secondary uses such as funding, insurance claim processing and research. The current scenario of assigning clinical codes is a manual process which is very expensive, time-consuming and error prone. In recent years, many researchers have studied the use of Natural Language Processing (NLP), related machine learning and deep learning methods and techniques to resolve the problem of manual coding of clinical narratives and to assist human coders to assign clinical codes more accurately and efficiently. The main objective of this systematic literature review is to provide a comprehensive overview of automated clinical coding systems that utilise appropriate NLP, machine learning and deep learning methods and techniques to assign the International Classification of Diseases (ICD) codes to discharge summaries. We have followed the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines and conducted a comprehensive search of publications from January, 2010 to December 2021 in four high quality academic databases: PubMed, ScienceDirect, Association for Computing Machinery (ACM) Digital Library, and the Association for Computational Linguistics (ACL) Anthology. We reviewed 6128 publications; 42 met the inclusion criteria. This review identified: 6 datasets having discharge summaries (2 publicly available, 4 acquired from hospitals); 14 NLP techniques along with some other data extraction processes, different feature extraction and embedding techniques. The review also shows that there is a significant increase in the use of deep learning models compared to machine learning. To measure the performance of classification methods, different evaluation metrics are used. Efforts are still required to improve ICD code prediction accuracy, availability of large-scale de-identified clinical corpora with the latest version of the classification system. This can be a platform to guide and share knowledge with the less experienced coders and researchers. © 2022 Elsevier Ltd",TestAnalysis
"Sentiment is fundamental to human communication. Countless marketing applications mine opinions from social media communication, news articles, customer feedback, or corporate communication. Various sentiment analysis methods are available and new ones have recently been proposed. Lexicons can relate individual words and expressions to sentiment scores. In contrast, machine learning methods are more complex to interpret, but promise higher accuracy, i.e., fewer false classifications. We propose an empirical framework and quantify these trade-offs for different types of research questions, data characteristics, and analytical resources to enable informed method decisions contingent on the application context. Based on a meta-analysis of 272 datasets and 12 million sentiment-labeled text documents, we find that the recently proposed transfer learning models indeed perform best, but can perform worse than popular leaderboard benchmarks suggest. We quantify the accuracy-interpretability trade-off, showing that, compared to widely established lexicons, transfer learning models on average classify more than 20 percentage points more documents correctly. To form realistic performance expectations, additional context variables, most importantly the desired number of sentiment classes and the text length, should be taken into account. We provide a pre-trained sentiment analysis model (called SiEBERT) with open-source scripts that can be applied as easily as an off-the-shelf lexicon. © 2022 The Authors",TestAnalysis
"Purpose: To evaluate if nudges delivered by text message prior to an upcoming primary care visit can increase influenza vaccination rates. Design: Randomized, controlled trial. Setting: Two health systems in the Northeastern US between September 2020 and March 2021. Subjects: 74,811 adults. Interventions: Patients in the 19 intervention arms received 1-2 text messages in the 3 days preceding their appointment that varied in their format, interactivity, and content. Measures: Influenza vaccination. Analysis: Intention-to-treat. Results: Participants had a mean (SD) age of 50.7 (16.2) years; 55.8% (41,771) were female, 70.6% (52,826) were White, and 19.0% (14,222) were Black. Among the interventions, 5 of 19 (26.3%) had a significantly greater vaccination rate than control. On average, the 19 interventions increased vaccination relative to control by 1.8 percentage points or 6.1% (P =.005). The top performing text message described the vaccine to the patient as “reserved for you” and led to a 3.1 percentage point increase (95% CI, 1.3 to 4.9; P <.001) in vaccination relative to control. Three of the top five performing messages described the vaccine as “reserved for you.” None of the interventions performed worse than control. Conclusions: Text messages encouraging vaccination and delivered prior to an upcoming appointment significantly increased influenza vaccination rates and could be a scalable approach to increase vaccination more broadly. © The Author(s) 2022.",TestAnalysis
"Background: The side effects of the FIFA 11+ program on performance have not been generally reviewed. The objective of this study was to synthesize the literature on the effects of the 11+ on players’ performance. Methods: Five online databases (PubMed, Scopus, ScienceDirect, Springer, and Google Scholar) were searched (from April 2006 to March 2022) using predefined keywords and sub-keywords. The potential references were primarily recorded through Endnote and imported to Covidence. Out of the 123 references screened by 2 blinded researchers through the software, 59 full texts were assessed for eligibility, 33 of which were ultimately included. The quality of the studies and the risk of bias were then assessed. Study ID, title, place, aim, design, start/end dates, population description, study criteria, statistical analysis, and outcomes were extracted. Results: Studies were conducted on male and female players aged 10–32 years old. The quality of the studies was moderate to high, and except for unclear bias for blinding outcome assessment, the risk of bias for all domains was low. Long-term application of the 11+ improved most biomechanical measures and physiological responses except for lower extremity stability, ankle evertors time latency, ankle dorsiflexion, and proprioception. Conversely, the 11+ showed acute negative effects on physical performance compared to dynamic warm-ups and non-significant effects on technical abilities. Conclusion: Mid-to-long-term implementation of the 11+ improved the majority of biomechanical and a couple of physical measures but showed no effects on technical skills. Precaution must be observed for using the 11+ before competitions, as it could acutely decrease physical/technical performance. Given the contradictory nature of the literature, further studies should evaluate the short-to-mid-term effects of the 11+. Further studies are required to address ankle responses to the 11+ intervention. © 2022",TestAnalysis
"Purpose: Corporate social responsibility (CSR) is an increasingly important issue for service brands in fast fashion retailing, as consumers' negative impressions about retailers' CSR activities influence brand experience. Consumers' impressions of CSR efforts arise based on agendas communicated through many channels from different sources. The paper unravels the ‘wrinkles’, i.e. possible mismatches in CSR communication around service brands by studying differences between the three main sources of fast fashion brand-related CSR agendas: Autonomous company communication, news media and social media postings by consumers. Design/methodology/approach: The authors use structural topic modeling (STM) to analyze a corpus of texts focusing on the CSR efforts of three major fast fashion service brands over three years. The texts included 89 items of company communication (CSR reports and press releases), 5,351 news media articles about the brands' CSR efforts and 57,377 consumer generated tweets about the brands. Findings: The STM analysis extracted 26 different CRS-related topics from the texts. Results showed differences in how much the three sources emphasized topics. The brands' own communication puts emphasis on environmental responsibility. News media tended to report on economic issues, treatment of employees and specific CSR-related events. Twitter showed more activity in discussing incident-based and emotionally charged topics. Research limitations/implications: The results feed into the ongoing discussion about how companies' CSR communication relates to communication in the press and among consumers. The authors highlight themes in the individual topics that are emphasized by the three sources, and discuss how CSR themes emerge in the overall transformative agenda. Practical implications: The paper highlights how fast fashion service brands can identify and understand different CSR agendas arising around their brand. Insight into such agendas can be used to tailor the brands' communication strategies. Originality/value: The paper contributes to the understanding of the factors behind fashion service brands' CSR reputation, highlighting how the three main sources of CSR reputation (company reports, news and social media) emphasize different types of agendas. © 2022, Jacob Mickelsson, Joep J.G.M. van Haren and Jos G.A.M. Lemmink.",TestAnalysis
"Food is significant to human daily life. In this paper, we are interested in learning structural representations for lengthy recipes, that can benefit the recipe generation and food cross-modal retrieval tasks. Different from the common vision-language data, here the food images contain mixed ingredients and target recipes are lengthy paragraphs, where we do not have annotations on structure information. To address the above limitations, we propose a novel method to unsupervisedly learn the sentence-level tree structures for the cooking recipes. Our approach brings together several novel ideas in a systematic framework: (1) exploiting an unsupervised learning approach to obtain the sentence-level tree structure labels before training; (2) generating trees of target recipes from images with the supervision of tree structure labels learned from (1); and (3) integrating the learned tree structures into the recipe generation and food cross-modal retrieval procedure. Our proposed model can produce good-quality sentence-level tree structures and coherent recipes. We achieve the state-of-the-art recipe generation and food cross-modal retrieval performance on the benchmark Recipe1M dataset. © 1979-2012 IEEE.",TestAnalysis
"This study explored adolescents' experiences of being under pressure to sext (sending nude images), offering insights into what situations adolescents view as pressuring, how adolescents react to the pressure, and what counter-strategies they use. Written statements from 225 adolescents (age 13–16 years, M = 14.4 years, SD = 0.93) were analyzed using thematic analysis. Results indicated a range of situations including both explicit and implicit pressure. The pressure elicited different emotional responses, including severe physical and psychological reactions, becoming distressed, and being seemingly unconcerned. A majority of the adolescents reported successful strategies on how to ward off the unwanted sexual requests. This study provides insight into how young people cope with potentially harmful situations online. © 2022 The Authors. Journal of Research on Adolescence published by Wiley Periodicals LLC on behalf of Society for Research on Adolescence.",TestAnalysis
"With the rapid development of the Internet and the World Wide Web, and the increasing amounts and variety of information on the Internet, people can now use search engines to obtain a diverse rich range of information. This paper proposes a user intent prediction search engine system (UIPSES) based on query history, using machine learning and deep learning image recognition technologies. Two different search methods are developed, based on a user keyword search and an upload image file search. The upload image file search uses deep learning image recognition technology to obtain multiple intent features for the image. Both the keyword and image searches use machine learning technology to extract multiple search intent feature information from the search logs, which is used as a basis for creating a user intent prediction for the keyword information search and the image file search. UIPSES provides highly correlated website index information between user browsing and predicted intent behaviour and uses machine learning to periodically train each user search process to update the user search intent recognition model to adapt to changes in the user intent, to improve the overall inference performance and analyse the accuracy of UIPSES, and to realise a search engine system with personalisation and a high-quality user experience. The UIPSES is a novel image search system that compares the relevance of search engine results for image and text information by using mean average precision with the well-known advanced web image search engines (Google, Bing, and Yandex). When the user uploads an image file for a search, the highest mean average precision value achieved by these three web image search engines was 2.28% for image information and text information feedback. In contrast, UIPSES can adapt to different conditions for single-object or multi-object images searches by obtaining multiple features from images and making inferences based on search logs, and therefore achieves high mean average precision values of 82.57 and 98.28%. UIPSES can also accurately find preset image and text information with higher relevance to allow users to search for images. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"The increasing integration of distributed energy resources (DERs) into the distribution system has caused interference with the signals stimulated by high impedance faults (HIFs). Many existing HIF detection or location methods that are only based on the superficial nonlinearity features of signals rather than the deep laws, will become invalid. This paper proposes a detection and location scheme for HIFs by theoretically analyzing the relationships between signals and systems. By establishing the equivalent circuit of a resonant distribution system, an online method to calculate the kernel system parameters is proposed, based on which an adaptive criterion for HIF detection is provided. In this way, the ability to detect HIF is adequately exploited and independent of DER influences. The method is able to detect HIF over 8.5 $\text{k}{\Omega }$ under common operating conditions. Furthermore, the nonlinearity of HIF is analyzed by deriving laws about how wideband signals distribute in the system. The $3^{\mathrm{ rd}}$ harmonic component of zero-sequence signals is proved to be superior in HIF location in terms of signal content and discrimination, which is also demonstrated to be valid under the influence of DER harmonic injection. On this basis, a HIF location method utilizing the $3^{\mathrm{ rd}}$ harmonic zero-sequence signals is proposed. The effectiveness of the method and its robustness to the DER interference are validated by simulated and field HIFs in 10kV systems.  © 2010-2012 IEEE.",TestAnalysis
"In this paper, we present a review of studies that have collected and annotated errors produced by people with dyslexia from corpora of written texts (six studies involving English, Spanish, German and French). Such resources are useful for studying the spelling difficulties of people with dyslexia. Results can be used for the design and development of assistive technologies. This paper also presents our contribution: a new study of errors from two corpora of typed texts written by French-speaking people with dyslexia. It details the methodology used to annotate the spelling errors extracted from these corpora and the analysis of these errors. The results of our study are compared to the results of the previous studies. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.",TestAnalysis
"Data preprocessing is among the principal stages in virtually all text-based tasks. In this light, recent approaches have employed word embeddings in the majority of text-based tasks, wherein word co-occurrences are used as the basis of word vector generation processes in the approaches thereof. Word embedding techniques are primarily trained on large corpora. The preprocessing of said corpora is quite crucial in that it can alter the co-occurrence counts of words, and hence the quality of generated word vectors. This highlights the significance of selecting the right preprocessing approach when working with word embeddings. The present study proceeds to scrutinize the effects of preprocessing on the quality of word embeddings on Persian and English corpora, with a focus on preprocessing approaches capable of altering the co-occurrence counts of words by virtue of procedures such as the elimination of stopwords. The quality of the word vectors generated employing different types of preprocessing are intrinsically evaluated by word similarity and word analogy. Text classification and sentiment analysis are also used as extrinsic evaluations. The study also presents four word similarity datasets for Persian, namely PER-RG-65, PER-RC-30, PER-simlex-999, and PER-Mturk-287. Results obtained using GloVe, Word2vec (CBOW), and Fasttext word embeddings show that in certain tasks, such as in the case of text classification or solving semantic questions in word analogy, the removal of punctuations and stopwords will lead to higher performance, as in the case of sentiment analysis and syntactic questions regarding word analogy, where withholding stopwords increases overall performance. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.",TestAnalysis
"Effective mining of social media, which consists of a large number of users is a challenging task. Traditional approaches rely on the analysis of text data related to users to accomplish this task. However, text data lacks significant information about the social users and their associated groups. In this paper, we propose CommuNety, a deep learning system for the prediction of cohesive networks using face images from photo albums. The proposed deep learning model consists of hierarchical CNN architecture to learn descriptive features related to each cohesive network. The paper also proposes a novel Face Co-occurrence Frequency algorithm to quantify existence of people in images, and a novel photo ranking method to analyze the strength of relationship between different individuals in a predicted social network. We extensively evaluate the proposed technique on PIPA dataset and compare with state-of-the-art methods. Our experimental results demonstrate the superior performance of the proposed technique for the prediction of relationship between different individuals and the cohesiveness of communities. © 2022, The Author(s).",TestAnalysis
"Offensive content or hate speech is defined as any form of communication that aims to annoy, harass, disturb, or anger an individual or community based on factors such as faith, ethnicity, appearance, or sexuality. Nowadays, offensive content posted in regional languages increased due to the popularity of social networks and other apps usage by common people. This work proposes a method to detect and identify hate speech or offensive content in Tamil. We have used the HASOC 2021 data set that contains YouTube comments in Tamil language and written in Tamil script. In this research work, an attempt is made to find suitable embedding techniques for Tamil text representation by applying TF-IDF and pre-trained transformer models like BERT, XLM-RoBERTa, IndicBERT, mBERT, TaMillion, and MuRIL. As Tamil is a morphologically rich language, a detailed analysis is made to study the performance of hate speech detection in Tamil by applying enhanced stemming algorithms. An extensive experimental study was performed with different classifiers such as logistic regression, SVM, stochastic Gradient Descent, decision tree, and ensemble learning models in combination with the above techniques. The results of this detailed experimental study show that stop word removal produces mixed results and does not guarantee improvement in the performance of the classifier to detect offensive content for Tamil data. However, the performance on stemmed data shows a significant improvement over un-stemmed data in Tamil texts. As the data is highly imbalanced, we also combined an oversampling/downsampling technique to analyze its role in designing the best offensive classifier for Tamil text. The highest performance was achieved by a combination of stemming the text data, embedding it with the multi-lingual model MuRIL and using a majority voting ensemble as the downstream classifier. We have achieved the F1-score of 84% and accuracy of 86% for detecting offensive content in Tamil YouTube comments. © 2022 Elsevier Ltd",TestAnalysis
"The delay-causing text data contain valuable information such as the specific reasons for the delay, location and time of the disturbance, which can provide an efficient support for the prediction of train delays and improve the guidance of train control efficiency. Based on the train operation data and delay-causing data of the Wuhan–Guangzhou high-speed railway, the relevant algorithms in the natural language processing field are used to process the delay-causing text data. It also integrates the train operating-environment information and delay-causing text information so as to develop a cause-based train delay propagation prediction model. The Word2vec model is first used to vectorize the delay-causing text description after word segmentation. The mean model or the term frequency-inverse document frequency-weighted model is then used to generate the delay-causing sentence vector based on the original word vector. Afterward, the train operating-environment features and delay-causing sentence vector are input into the extreme gradient boosting (XGBoost) regression algorithm to develop a delay propagation prediction model. In this work, 4 text feature processing methods and 8 regression algorithms are considered. The results demonstrate that the XGBoost regression algorithm has the highest prediction accuracy using the test features processed by the continuous bag of words and the mean models. Compared with the prediction model that only considers the train-operating-environment features, the results show that the prediction accuracy of the model is significantly improved with multiple regression algorithms after integrating the delay-causing feature. © 2022, The Author(s).",TestAnalysis
"Objective: To map the existing evidence regarding the masking ability of resin composites. Overview: The literature search was conducted electronically, based on the PRISMA Extension for Scoping Reviews—online protocol at https://osf.io/m2h67/ with no language or time restrictions. Two independent reviewers conducted the screening, and a third reviewer was consulted in case of disagreement. Studies that evaluated resin composite masking ability regardless of background, application technique, thickness, or number of layers were selected. The search found 2995 potentially eligible studies. After removal of duplicates (657), irrelevant articles (2323), 15 citations met the eligibility criteria based on title and abstract, and eight studies were included based on full text analysis (seven in vitro, and one case report). Acceptable masking ability is obtained by one layer of opaque shade resin composite or by the layering technique. A black background is masked with 1.0- to 2.0 mm-thick layers of opaque shade resin composites. Masking of the C4 background is achieved with one layer of 0.5- to 1.5 mm-thick opaque shade resin composite or by the layering technique using different combinations of enamel body and dentin shades with a final thickness of 1.5 mm. Conclusions: Acceptable masking of C4 shade background is achieved with one layer of opaque shade composite at least 0.5 mm-thick or by different combinations of the layering technique, with a final thickness of 1.5 mm. Acceptable masking of the black background of the oral cavity is achieved with a resin composite of at least 1.0 mm opaque shade. Clinical Significance: The thickness of the resin composite layer required to achieve adequate masking is variable and depends on the translucency/opacity of the tested resin composites and the background shade. © 2022 Wiley Periodicals LLC.",TestAnalysis
"Attention towards veg*nism is increasing as the impact of food choices on health and sustainability as well as ethical concerns regarding animal welfare emerge. Although online user analysis is an effective tool to obtain practical insights without geographical constraints, implementation on a large veg*n population has been carried out within a limited scope. This study investigated two veg*n subreddits, r/Vegan and r/Vegetarian, using multiple text mining techniques to classify users' interests and preferences. Based on K-means and term frequency-inverse document frequency, six clusters were identified: Food, Perception, Health, Altruism, Emotion, and Situation. The proportion of each cluster and keywords representing the clusters were obtained. Being a major sector, further assessment of the Food cluster was conducted using Latent Dirichlet Allocation topic modeling technique. Confusion was observed in relation to being pressured with sudden changes in dietary patterns, including meal composition, preparation, and shopping routines. The results also revealed barriers to transition for individuals who have recently started veg*n diets, and those wishing to switch to stricter dietary patterns. In addition to difficulties relating to economic and social aspects, our findings suggest that the establishment of detailed guidelines may help accommodate the various dietary compositions across the veg*n spectrum, and clear information relating to veg*n food products is needed from manufacturers. © 2022 Elsevier Ltd",TestAnalysis
"Background: Enhanced uptake of systematic reviews that use qualitative comparative analyses (QCA) requires knowing how end-users interpret such findings. The study purpose was to identify effective approaches to communicating results from a QCA within a systematic review. Methods: Sequential exploratory mixed methods design; thematic analysis of interviews with 11 end-users followed by a randomized experiment with 254 participants that provided QCA results for a hypothetical review presented through three formats (text, table, and figure). A survey administered after the experiment assessed subjective and objective comprehension of QCA results. Results: Interview themes included use of jargon; appropriate use of appendices, tables, figures; and integration of QCA results within the systematic review. In the experiment, we observed a significant difference (p = 0.035) in subjective comprehension across the three presentation formats. Participants randomized to the figure and text formats scored higher compared to the table. No significant differences were observed for objective comprehension overall (p = 0.11). However, for parameter interpretation (a unique component of QCA results), scores among participants that received the figure format were significantly higher than scores for participants who received the text (p = 0.001) or table (p = 0.004). No significant differences (p = 0.09) were observed in objective comprehension for configuration interpretation. Conclusions: End-users of systematic reviews saw value in the use of QCA, but unfamiliar methods and terminology were barriers to full understanding of the findings. When presenting results, a figure format appears to be superior to text or table formats based on measures of subjective comprehension and some measures of objective comprehension. © 2022 The Authors. Research Synthesis Methods published by John Wiley & Sons Ltd.",TestAnalysis
"The onset of the COVID-19 pandemic has changed consumer usage behavior towards mobile payment (m-payment) services. Consumer usage behavior towards m-payment services continues to increase due to access to usage experiences shared through online consumer reviews (OCRs). The proliferation of massive OCRs, coupled with quick and effective decisions concerning the evaluation and selection of m-payment services, is a practical issue for research. This paper develops a novel decision evaluation model that integrates OCRs and multi-attribute decision-making (MADM) with probabilistic linguistic information to identify m-payment usage attributes and utilize these attributes to evaluate and rank m-payment services. First and foremost, the attributes of m-payment usage discussed by consumers in OCRs are extracted using the Latent Dirichlet Allocation (LDA) topic modeling approach. These key attributes are used as the evaluation scales in the MADM. Based on an unsupervised sentiment algorithm, the sentiment scores of the text reviews regarding the attributes are calculated. We convert the sentiment scores into probabilistic linguistic elements based on the probabilistic linguistic term set (PLTS) theory and statistical analysis. Furthermore, we construct a novel technique known as probabilistic linguistic indifference threshold-based attribute ratio analysis (PL-ITARA) to discover the weight importance of the usage attributes. Subsequently, the positive and negative ideal-based PL-ELECTRE I methodology is proposed to evaluate and rank m-payment services. Finally, a case study on selecting appropriate m-payment services in Ghana is examined to authenticate the validity and applicability of our proposed decision evaluation methodology. © 2022 Elsevier Ltd",TestAnalysis
"Automated sentiment analysis is considered an area in natural language processing research that seeks to understand a text author's mood, thoughts, and feelings. New opportunities and challenges have arisen in this field due to the popularity and accessibility of a variety of resources of ideas, such as online review websites, personal blogs, and social media. Feature selection, which can be conducted using metaheuristic algorithms, is one of the steps of sentiment analysis. It is crucial to use high-performing algorithms for feature selection. This paper applies the Horse herd Optimisation Algorithm (HOA) for feature selection in text sentiment analysis. HOA is a metaheuristic algorithm and uses six key behaviours to simulate the social performance of horses of various ages, to solve high-dimensional optimisation problems. In order to improve HOA, this paper adds another behaviour of horses to the basic algorithm; thus, the new algorithm uses seven key behaviours of horses of different ages to imitate their social performance. It is then discretised and converted to a multi-objective algorithm. The improved algorithm's performance is evaluated using 15 CEC benchmark functions, and the results are compared to the Binary Social Spider Algorithm, the Binary Grey Wolf Optimizer, and the Binary Butterfly Optimization Algorithm. The new algorithm, the Multi-objective Binary Horse herd Optimisation Algorithm (MBHOA), excels at solving high-dimensional complex problems. To evaluate the algorithm's performance in feature selection, as a practical example, it is employed in text sentiment analysis and examined on various data sets. The simulation results indicate that MBHOA has a better performance in analysing sentiment compared to similar approaches. © 2022, The Author(s).",TestAnalysis
"The publisher regrets the following conflict of interest text was not published. • All the authors listed in this article have made Substantial contributions to the conception or design of the work; or the acquisition, analysis, or interpretation of data for the work; AND Drafting the work or revising it critically for important intellectual content; AND Final approval of the version to be published. • I also undertake that the article represents valid work. Neither this article nor any part of it has been copied or plagiarized from other works. • That the article has not been published so far OR communicated OR in simultaneous consideration to some other journal. • I also undertake that the authors have disclosed all potential conflict of interests associated with the work. The publisher would like to apologise for any inconvenience caused. © 2022 Elsevier B.V.",TestAnalysis
"In terms of thought disorder, the language of patients with schizophrenia itself could be a valuable resource. Some valuable studies on the language of patients with schizophrenia have been performed. However, most such studies have been confined to English-speaking countries, or at least those where Indo-European languages are spoken. Therefore, we investigated linguistic anomalies in the language of Korean patients with schizophrenia. Short texts written by 69 patients with schizophrenia from a single mental hospital and matched normal control participants were analyzed. We evaluated these texts in terms of semantic and syntactic errors. Then, we compared the error rates adjusted for text length between patients and normal control participants. We also divided the patients with schizophrenia into two groups by their duration of illness and compared these two groups to investigate the relationship between the duration of illness and linguistic anomalies. The patients with schizophrenia committed a total of 1.86 (2.52) semantic errors and 1.37 (1.79) syntactic errors per 100 characters, which were significantly more frequent than errors committed by normal control participants. Furthermore, there was a notably high number of semantic errors relative to syntactic errors in the language of patients with schizophrenia. Our study results are consistent with previous studies from English-speaking countries, implying that the linguistic anomalies of patients with schizophrenia are not confined to a single language. Because language is essential in mental function, further research on linguistic anomalies in patients with schizophrenia is recommended. © 2022",TestAnalysis
"Background: Australian Aboriginal and Torres Strait Islander (hereafter referred to as Aboriginal) women breastfeed at lower rates than non-Aboriginal women. Little is known about factors associated with breastfeeding specific to Aboriginal women and infants. Aim: Determine the protective and risk factors associated with breastfeeding for Aboriginal women in Australia. Methods: CINAHL, Medline, EMBASE, SCOPUS, PsycINFO, and the Cochrane library were searched for peer-reviewed literature published between 1995 and 2021. Quantitative studies written in English reporting protective and risk factors associated with breastfeeding for Aboriginal women or women having an Aboriginal infant were included. Ten percent of papers were co-screened, and two reviewers completed data extraction. Narrative data synthesis was used. Findings: The initial search identified 12,091 records, with 31 full text studies retrieved, and 17 reports from 14 studies met inclusion criteria. Protective factors included living in a remote area, attending an Aboriginal-specific service, attending a regional service, higher levels of education attainment, increased maternal age, living in larger households, being partnered, and having a higher reported number of stressful events and social health issues. The identified risk factors were smoking in pregnancy, admission to SCN or NICU, and being multiparous. Conclusion: This review identified factors associated with breastfeeding for Aboriginal women. Government focus, support, and consistent funding are required to plan and implement evidence-based interventions and services for Aboriginal women and infants in urban, rural, remote, and very remote locations. Rigorous research is required to understand the Aboriginal-specific factors associated with breastfeeding to improve rates and health outcomes for Aboriginal women and infants. © 2022 Australian College of Midwives",TestAnalysis
"The fast evolution of Information and Digital technology had given way for internet to be an effective medium for communication. This has also paved way for data exploitation. Therefore, users must protect their data from misuse. This led to the emergence of security framework like Information Hiding. Steganography and Steganalysis are of the two primary techniques in the field of Information Hiding. Steganography is the science of concealing confidential information, while steganalysis is the art of detecting the existence of that information. The primary goal of this research is to address the general concept of steganalysis, and various breaches associated with it. It involves a blind statistical steganalysis technique that is led in Joint Photographic Experts Group (JPEG) text embedded images by extracting features that illustrate an alteration during an embedding. The images used as embedding medium are uncalibrated and the percentage of the embedding used in this study is 50%. The text embedding is done using various steganographic schemes in the spatial and transform domain. The steganographic schemes considered are Least Significant Bit (LSB) Matching, Least Significant Bit (LSB) Replacement, Pixel Value Differencing and F5. After steganographic embedding of the data, the first order, second order, extended Discrete Cosine Transform (DCT) and Markov features are extracted. Then, Principal Component Analysis (PCA) is used as a system for feature dimensionality reduction. Furthermore, the technique of machine learning is incorporated by means of a classifier to identify the stego image and cover image. Support Vector Machine (SVM) and Support Vector Machine with Particle Swarm Optimization (SVM-PSO) are the classifiers examined in this paper for a comparative study. Moreover, the concept of cross-validation is also incorporated in this work. Six dissimilar kernel functions and four diverse samplings are used during classification to check on the effectiveness of the kernels and sampling in classification. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"National identity is the cognition of citizens regarding to which political community they belong, and the tendency to accept the political, cultural and ethnic values of the state. Previous studies have found that national identity is heterogeneous at the subnational levels. Why do people hold different degrees of nationalism and patriotism in the subnational units? In this paper, we offer a political economic explanation of national identity, which links the state capacity with political attitudes. We employ a nationalism-patriotism framework to decompose the concept of national identity, then use the supervised learning approach to measure nationalism and patriotism based on a massive number of Weibo posts dating from 2011 to 2017. Automated text analysis shows that the state capacity plays an important role preventing the national identity from being weakened by globalization and the diversity of social information. Specifically, with the progress of China’s globalization, multiculturalism and various information have crossed the national boundaries, which undermines China’s national identity. In order to maintain this identity, the Chinese government utilizes its redistribution capacity to reinforce both nationalism and patriotism, and also its information capacity to strengthen nationalism. © 2022, Journal of Chinese Political Science/Association of Chinese Political Studies.",TestAnalysis
"Fighting medical disinformation in the era of the pandemic is an increasingly important problem. Today, automatic systems for assessing the credibility of medical information do not offer sufficient precision, so human supervision and the involvement of medical expert annotators are required. Our work aims to optimize the utilization of medical experts’ time. We also equip them with tools for semi-automatic initial verification of the credibility of the annotated content. We introduce a general framework for filtering medical statements that do not require manual evaluation by medical experts, thus focusing annotation efforts on non-credible medical statements. Our framework is based on the construction of filtering classifiers adapted to narrow thematic categories. This allows medical experts to fact-check and identify over two times more non-credible medical statements in a given time interval without applying any changes to the annotation flow. We verify our results across a broad spectrum of medical topic areas. We perform quantitative, as well as exploratory analysis on our output data. We also point out how those filtering classifiers can be modified to provide experts with different types of feedback without any loss of performance. © 2022, The Author(s).",TestAnalysis
"Jokes are indispensable to Slavoj Žižek’s commentaries and theoretical reflexions on politics and culture. However, contrary, or in addition, to their putative radical meaning and their capacity to render clear certain ideological practices, some of these jokes seem to raise serious questions in relation to their politics. The current article will focus on three texts by Žižek, all of which contain a joke or pun, in order to examine the function of these jokes on a microsociological level, that is, in relation to speaker/audience dynamics, as well as exploring the broader politics they advocate and they invite us to embrace. A Lacanian discourse analysis is employed in order to open up these texts and jokes and discuss what is understood as their ideological character and disciplinary function. © 2022, The Author(s) under exclusive licence to Springer Nature Limited.",TestAnalysis
"This study grows out of the absence of literature on an in-depth understanding of dissertation-writing challenges, facilitating strategies, and causes to develop a more profound understanding of Pakistani doctoral students. This is primarily qualitative research. One of the largest private universities was selected as a case to collect the data. The data were based on 12 Pakistani doctoral dissertations, 49 evaluation reports from 13 countries, mainly from the state-run universities, and a survey questionnaire responded to by 12 PhD graduates. The data were codified for commonly emerging categories and themes based on the methodological approach of Clarke and Braun (2017). The data revealed that the doctoral students faced challenges concerning mechanics of writing, developing an argument in a coherent whole, and structural organization of the dissertation. The examiners recommended the doctoral students to copyedit/proofread the dissertation to overcome mechanics of writing problems, build the argument logically, use formal language, write transition sentences to knit the texts coherently, embed citations to support the claims, and uniform the structure of the dissertation. Five causes of writing difficulties emerged from the survey questions. Despite a mismatch between the academic resources and research support provided to Pakistani doctoral students, their research work is deemed par with foreign universities, which encourage native-like English. It is hoped that this study will help doctoral students improve their dissertation-writing quality. © 2022 John Wiley & Sons Ltd.",TestAnalysis
"Background and objective: Decreased skeletal muscle mass and quality are one of the several markers used for sarcopenia diagnosis and are generally associated with increased rates of post-operative infections, poorer recovery and increased mortality. The aim of this review was to evaluate methods applied to detect markers of sarcopenia and the associated outcomes for patients undergoing emergency laparotomy. Methods: This review was conducted with reference to Preferred Reporting Items for Systematic Review and Meta-Analysis (PRISMA) guidelines. MEDLINE, Embase and Google Scholar databases were searched. Studies detecting patients with sarcopenia or skeletal muscle decline markers and the associated outcomes after emergency laparotomy surgery were considered. The Newcastle–Ottawa Scale was used to evaluate publication quality. Results: Out of 103 studies, which were screened, 19 full-text records were reviewed and 7 studies were ultimately analyzed. The study cohort sizes ranged from n = 46 to n = 967. The age range was 36–95 years. There were 1107 females (53%) and 973 males (47%) across all 7 studies. All studies measured psoas muscle mass and three studies assessed psoas muscle quality using computerized tomography (CT) imaging. No study assessed muscle strength or function, while five studies showed an association between low muscle mass and increased mortality rates after emergency laparotomy. Among the three studies, which assessed muscle quality, two of three studies showed poorer 30-day survival rates. Conclusions: The existing literature is limited, however it indicates that low psoas muscle mass and quality markers are associated with increased 30-day mortality rates after emergency laparotomy. Therefore, muscle markers can be used as a new feasible tool to identify most at risk patients requiring further interventions. © The Finnish Surgical Society 2022.",TestAnalysis
"Sentiment analysis (SA) has gained much traction In the field of artificial intelligence (AI) and natural language processing (NLP). There is growing demand to automate analysis of user sentiment towards products or services. Opinions are increasingly being shared online in the form of videos rather than text alone. This has led to SA using multiple modalities, termed Multimodal Sentiment Analysis (MSA), becoming an important research area. MSA utilises latest advancements in machine learning and deep learning at various stages including for multimodal feature extraction and fusion and sentiment polarity detection, with aims to minimize error rate and improve performance. This survey paper examines primary taxonomy and newly released multimodal fusion architectures. Recent developments in MSA architectures are divided into ten categories, namely early fusion, late fusion, hybrid fusion, model-level fusion, tensor fusion, hierarchical fusion, bi-modal fusion, attention-based fusion, quantum-based fusion and word-level fusion. A comparison of several architectural evolutions in terms of MSA fusion categories and their relative strengths and limitations are presented. Finally, a number of interdisciplinary applications and future research directions are proposed. © 2022",TestAnalysis
"Impact investing is gaining momentum as an investment practice that optimizes both financial and social outcomes. However, the market is still in its emerging stage, and there is ambiguity regarding the definition of players and practices. In this paper, we adopt an investor identity perspective and use a linguistic approach to explore how social impact venture capitalists (SIVCs) communicate their identities and actions to their external stakeholders. Through a text mining analysis of the websites of 195 investors worldwide, our results reveal four types of investors who differ in terms of their social linguistic positioning and linguistic distinctiveness. Finally, by training a tree boosting machine learning model, we assess the extent to which the use of different linguistic styles is associated with website traffic. © 2022, The Author(s).",TestAnalysis
"In the latest social networks, more and more people prefer to express their emotions in videos through text, speech, and rich facial expressions. Multimodal video emotion analysis techniques can help understand users' inner world automatically based on human expressions and gestures in images, tones in voices, and recognized natural language. However, in the existing research, the acoustic modality has long been in a marginal position as compared to visual and textual modalities. That is, it tends to be more difficult to improve the contribution of the acoustic modality for the whole multimodal emotion recognition task. Besides, although better performance can be obtained by introducing common deep learning methods, the complex structures of these training models always result in low inference efficiency, especially when exposed to high-resolution and long-length videos. Moreover, the lack of a fully end-to-end multimodal video emotion recognition system hinders its application. In this paper, we designed a fully multimodal video-to-emotion system (named FV2ES) for fast yet effective recognition inference, whose benefits are threefold: (1) The adoption of the hierarchical attention method upon the sound spectra breaks through the limited contribution of the acoustic modality, and outperforms the existing models' performance on both IEMOCAP and CMU-MOSEI datasets; (2) the introduction of the idea of multi-scale for visual extraction while single-branch for inference brings higher efficiency and maintains the prediction accuracy at the same time; (3) the further integration of data pre-processing into the aligned multimodal learning model allows the significant reduction of computational costs and storage space.  © 1963-12012 IEEE.",TestAnalysis
"Fake news is information that does not represent reality but is commonly shared on the internet as if it were true, mainly because of its dramatic, appealing, and controversial content. Therefore, a relevant issue is to find characteristics that can assist in identifying Fake News, mainly nowadays, where an increasing number of fake news is spread all over the internet every day. This work aims to extract knowledge from Brazilian fake news data based on statistical learning. Initially, an exploratory data analysis is performed for the available variables to extract insights from the differences between fake and true news. Then, the prediction and modelling are carried out. The learning phase aims to build a model and measure the features that best explain the behaviour of misleading texts, which leads to a parsimonious model. Finally, the test phase estimates the fitted model accuracy based on 10-fold cross-validation in the Monte Carlo framework. The results show that four variables are significant to explain fake news. Moreover, our model achieved comparable results with state-of-the-art, 0.941 F-measure, for a single classifier while having the advantage of being a parsimonious model. This work's details and code can be found at https://github.com/limagbz/fake-news-ptBR. © 2022 John Wiley & Sons Ltd.",TestAnalysis
"As a popular means of nonverbal communication in social media, emojis provide quick predictions about public sentiments towards social events. Previous analyses of emojis reported that people use positive emojis more frequently than negative emojis. However, psychological research reveals a negativity bias in sentiment, as seen in the phenomenon of loss-aversion, where negative sentiment due to a loss possesses a greater psychological valence than positive sentiment due to a gain of an equal amount. We propose that the frequency and intensity of emojis are dissociable. Whereas the frequency of emojis reflects social norms in public communication, the intensity reflects hedonic values and loss-aversion. We first developed a text-free emoji sentiment lexicon based on a survey with more than 900 users of Weibo (a Chinese version of Twitter). Using the sentiment lexicon, we then analyzed 8822 Weibo comments containing the indexed emojis in reaction to three controversial events (i.e., a murder case in which public opinion largely opposed the final verdict, a manslaughter case in which public opinion was supportive of the final verdict, and a public debate on an award-winning subject). The results showed that positive or negative emoji frequency was consistent with the majority sentiment (social norm) towards a controversial event. In contrast, the average intensity of negative emojis was stronger than positive emojis across all three samples, revealing a public sentiment version of loss-aversion. In all three samples, emoji polarity analysis served as a proxy for text sentiment analysis to capture public attitudes towards a social event. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.",TestAnalysis
"Current lexica and machine learning based sentiment analysis approaches still suffer from a two-fold limitation. First, manual lexicon construction and machine training is time consuming and error-prone. Second, the prediction’s accuracy entails sentences and their corresponding training text should fall under the same domain. In this article, we experimentally evaluate four sentiment classifiers, namely support vector machines (SVMs), Naive Bayes (NB), logistic regression (LR) and random forest (RF). We quantify the quality of each of these models using three real-world datasets that comprise 50,000 movie reviews, 10,662 sentences, and 300 generic movie reviews. Specifically, we study the impact of a variety of natural language processing (NLP) pipelines on the quality of the predicted sentiment orientations. Additionally, we measure the impact of incorporating lexical semantic knowledge captured by WordNet on expanding original words in sentences. Findings demonstrate that the utilizing different NLP pipelines and semantic relationships impacts the quality of the sentiment analyzers. In particular, results indicate that coupling lemmatization and knowledge-based n-gram features proved to produce higher accuracy results. With this coupling, the accuracy of the SVM classifier has improved to 90.43%, while it was 86.83%, 90.11%, 86.20%, respectively using the three other classifiers. © 2023, Institute of Advanced Engineering and Science. All rights reserved.",TestAnalysis
"With growing attention on the importance of values, beliefs and worldviews in shaping environmental outcomes, there remains little research on religion and sustainability transformations. We explored the impact of the Archbishop of Canterbury’s environmentally themed Lent Book 2020 “Saying Yes to Life” on environmental values, attitudes and behaviours of lay Christians. An online survey administered before and after reading the book assessed environmental values, New Ecological Paradigm (NEP), connectedness to nature and environmental behaviours, and collected open responses to questions about participants’ perceptions. Follow-up focus groups were also held to understand experiences of cognitive and behavioural change. Analysis of paired data revealed significant increases in environmental behavioural intentions after completing the book, especially for energy use, food and recycling. Some evidence for strengthening of NEP scores and connectedness to nature was also found. Open text responses corroborated with quantitative measures of behaviour change. Additionally, the majority of participants reported some form of reinforcement, confirmation, or further development or change in their beliefs and attitudes. This included a reduction in anthropocentric beliefs and greater appreciation of and obligation towards the natural world. Focus group discussions revealed diverse participant experiences, including having pre-existing theological beliefs affirmed, responding with new practical actions, connecting with spiritual experiences, and discovering systemic origins of unsustainability. Findings suggest potential for environmental interventions within religious contexts to shape mindsets, integrate theological views with environmental concerns, activate latent beliefs, and initiate and sustain pro-environmental behaviour. More intentional engagement with religion may facilitate transformative change for sustainability internally and externally, and across individual, organisational and societal domains. © 2022, The Author(s).",TestAnalysis
"Background: The reproductive and perinatal health of sexual and gender-diverse (SGD) individuals is a research priority area for the National Institutes of Health. Over the past decade, this childbearing population has been the focus of several qualitative studies providing the opportunity to evaluate and synthesize the qualitative literature on SGD childbearing experiences in a metasynthesis. Methods: We conducted a literature search of four databases to identify original research published from January 2011 through June 2021. These results were augmented by forward and backward searching strategies. Two authors independently screened studies. All qualitative studies of the childbearing experience were eligible. Data were extracted and inductively coded using conventional content analysis, and studies underwent a quality appraisal by two authors. Results: From 2396 articles, 127 full-text articles were screened, and 25 were included in this synthesis. Three overarching themes were identified: (a) Systematic Invisibility; (b) Creating Personhood Through Parenthood; and (c) Resilient Narratives of Childbearing. Conclusions: Relative to heterosexual and cisgender parents, SGD childbearing parents experience unique structural and interpersonal challenges and employ critically important resilience strategies and coping techniques to manage an overwhelming heterocisnormative experience. These findings provide an important target for health care organizations and professionals to improve SGD perinatal health. In addition, this metasynthesis identified persistent gaps in our understanding of this marginalized childbearing population, which have important implications for reducing health disparities that SGD parents experience. © 2022 Wiley Periodicals LLC.",TestAnalysis
"Background: Health care-associated infection (HAI) is a common adverse event affecting patient safety. This review aims to (1) establish evidence for the impact of certified infection prevention and control (CIC) specialists on infection prevention and patient safety in acute care settings and (2) summarize study design and statistical modeling used for impact assessment to inform future studies. Methods: We searched and reviewed full-text, quantitative studies assessing the impact of CIC. The studies used empirical data published in English between January 2000 and April 2021 in PubMed, PsycINFO, and EMBASE. We identified 8 articles for data extraction and analysis. All eight studies used a cross-sectional design and had a quality rating of good to high based on the Johns Hopkins Nursing Evidence-Based Practice rating scales. Results: CIC infection preventionists (IPs) may have a stronger understanding than other practitioners of the evidence for certain infection prevention practices and are more likely to recommend implementing them in the hospitals where they work, especially when the lead IP is certified. The association between CIC and HAI rates was inconsistent in our results. Discussion and Conclusions: Further studies are needed to explore the impact of CIC IPs on HAI rates. © 2022 Association for Professionals in Infection Control and Epidemiology, Inc.",TestAnalysis
"Aspect-level sentiment analysis (ALSA) is the process of collecting, processing, analyzing, inferring, and synthesizing subjective sentiments of entities contained in texts at the aspect level. The development of social networks has been driven by the on-going appearance of vast numbers of short documents, such as those in which opinions are expressed and comments are made. The text in these documents reflects users’ emotions related to entities. The ALSA of these short texts plays an important role in solving various problems in life. Particularly in e-commerce, manufacturers can use sentiment analysis to determine users’ orientations, adapt their products to perfection, identify potential users, and pinpoint users that influence other users. Therefore, improving the performance of ALSA methods has recently attracted the interest of researchers. Currently, four main types of ALSA methods are available: knowledge-based, machine learning-based, hybrid-based, and most recently, graph convolutional network (GCN)-based. This study is the first survey to focus on reviewing the proposed methods for ALSA using GCN methods. In this paper, we propose a novel taxonomy to divide GCN-based ALSA models into three categories based on the types of knowledge extraction. We present and compare GCN-based ALSA methods following our taxonomy comprehensively. Common benchmark datasets and text representations that are often used in GCN-based methods are also discussed. In addition, we discuss five challenges and suggest seven future research directions for GCN-based ALSA methods. The findings of our survey are expected to provide the necessary guidelines for beginners, practitioners, and new researchers to improve the performance of ALSA methods. © 2022 Elsevier B.V.",TestAnalysis
"Relapse in antineutrophil cytoplasmic antibodies (ANCA)-associated vasculitis (AAV) is associated with significant morbidity and mortality. Utility of ANCA for prediction of relapses is still controversial. PubMed/MEDLINE, Scopus, and WebOfScience were searched, screened and confirmed for inclusion [PROSPERO No: CRD42020220308]. Studies measuring serial ANCA by ELISA or indirect immunofluorescence (IF), reporting relapses with sufficient data to calculate sensitivity and specificity were included. Diagnostic odds ratio (OR), sensitivity, specificity and likelihood ratios (LR) were synthesized using a bivariate mixed-effect regression model. Sub-group analysis included a comparison between ELISA and IIF, anti-myeloperoxidase (MPO) and -proteinase 3(PR3), and type of rise in ANCA. For meta-analysis of survival outcomes, hazard ratios were synthesized using a random-effect model. QUADAS-2 was used for assessing quality of studies, I2 statistic for heterogeneity Begg’s test for publication bias. 2946 abstracts and 43 full-texts were reviewed to identify 26 eligible studies that included 2623 patients with AAV and 848 relapses. Overall heterogeneity was high [I2 = 99%] and the overall risk of bias was low to moderate. ANCA positivity by either ELISA or immunofluorescence for predicting relapse of AAV had a sensitivity of 0.70(95% CI 0.58–0.81), specificity of 0.66(0.55–0.76), positive LR of 2.1(1.6–42.7) and negative LR of 0.44(0.30–0.60). ELISA performed marginally better [OR: 5(3–7)] than IIF [OR: 4(2–9)] with similar sensitivity, specificity, PLR and NLR. The area under the curve for PR3 was 0.74(0.7–0.77), while that for MPO was not computed as the number of eligible studies was only three. In the survival analysis, the hazard ratio for relapse was 3.11(1.7–5.65). The meta-analysis shows modest accuracy of ANCA in predicting relapses of ANCA vasculitis and supports the use of serial ANCA monitoring as a biomarker for relapse. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TestAnalysis
"Objective: To accelerate the use of outcome measures in rheumatology, we developed and evaluated a natural language processing (NLP) pipeline for extracting these measures from free-text outpatient rheumatology notes within the American College of Rheumatology's Rheumatology Informatics System for Effectiveness (RISE) registry. Methods: We included all patients in RISE (2015–2018). The NLP pipeline extracted scores corresponding to 8 measures of rheumatoid arthritis (RA) disease activity (DA) and functional status (FS) documented in outpatient rheumatology notes. Score extraction performance was evaluated by chart review, and we assessed agreement with scores documented in structured data. We conducted an external validation of our NLP pipeline using data from rheumatology notes from an academic medical center that is not included in the RISE registry. Results: We processed over 34 million notes from 854,628 patients, 158 practices, and 24 electronic health record (EHR) systems from RISE. Manual chart review revealed a sensitivity, positive predictive value (PPV), and F1 score of 95%, 87%, and 91%, respectively. Substantial agreement was observed between scores extracted from RISE notes and scores derived from structured data (κ = 0.43–0.68 among DA and 0.86–0.98 among FS measures). In the external validation, we found a sensitivity, PPV, and F1 score of 92%, 69%, and 79%, respectively. Conclusion: We developed an NLP pipeline to extract RA outcome measures from a national registry of notes from multiple EHR systems and found it to have good internal and external validity. This pipeline can facilitate measurement of clinical- and patient-reported outcomes for use in research and quality measurement. © 2022 American College of Rheumatology.",TestAnalysis
"The smart speaker market, which is considered an early-stage market, is expected to grow rapidly as smart speakers become a part of daily life. Consequently, manufacturers are trying to dominate the market. To achieve this, they must analyze users' reactions to their products and find insights for product improvement through comparison with competitors. We propose a four-step methodological framework for identifying meaningful opinions from a large number of online user reviews. First, network analysis is conducted to compare differences between brands. Next, through topic modeling, the attributes of speakers that users consider the most crucial are extracted for each brand. Third, sentiment analysis is conducted to examine how users' emotional polarities differ for each attribute. Through this, product improvement and product sales plans can be derived. Finally, in order to clarify the strengths and weaknesses of each brand, brand positioning is conducted and user opinions that have changed along with the evolution of the speaker's generation are analyzed. Our study identified the factors that positively or negatively affect the experience of smart speaker users. In addition, the proposed method is highly useful because it can be used to derive insights from a large amount of user opinion data regardless of the search term. © 2022 Elsevier Ltd",TestAnalysis
"Text highlighting is a new method for online sensory-consumer research where participants read a text while making use of highlighting functions to indicate content that they, respectively, ‘like’ and ‘dislike.’ In a recent series of papers, consumers have been found to approach the text highlighting task in a logical and systematic manner, and the results have been shown to deliver attitudinal insights about the focal topic that fit expectations. Building on the early successes of text highlighting, it was an obvious step to try to extend it to applications in product research which occupies a central role in sensory-consumer research. A case study with kiwifruit was performed with consumers in Singapore and Malaysia (n = 1140). Participants read a text (288 words, 19 sentences) which primarily described sensory, nutrition and health characteristics of green and gold kiwifruit. Focusing on 43 specific fruit characteristics, sentiment (difference between the frequency of ‘like’ and ‘dislike’ highlights) was higher for nutrition and health characteristics than for those describing sensory characteristics. Only the Chinese origin of kiwifruit and the hairy skin of green kiwifruit were negatively perceived overall. A novel use of penalty/lift analysis to identify the specific fruit characteristics that significantly influenced expected liking of kiwifruit confirmed the results based on sentiment scores. Moreover, a difference between the drivers of liking for gold and green kiwifruit was identified; the use of ‘like’ highlighting for sensory properties positively contributed to expected liking for gold kiwifruit only. The case study also demonstrated the potential to meaningfully segment consumers based on their highlighting responses to product specific characteristics. The results are discussed in the context of future applications of text highlighting in product research. © 2022 Elsevier Ltd",TestAnalysis
"Purpose: Organoids are three-dimensional cultures of stem cells in an environment similar to the body’s extracellular matrix. This is also a novel development in the realm of regenerative medicine. Stem cells can begin to develop into 3D structures by modifying signaling pathways. To form organoids, stem cells are transplanted into the extracellular matrix. Organoids have provided the required technologies to reproduce human tissues. As a result, it might be used in place of animal models in scientific study. The key goals of these investigations are research into viral and genetic illnesses, malignancies, and extracellular vesicles, pharmaceutical discovery, and organ transplantation. Organoids can help pave the road for precision medicine through genetic editing, pharmaceutical development, and cell therapy. Methods: PubMed, Google Scholar, and Scopus were used to search for all relevant papers written in English (1907–2021). The study abstracts were scrutinized. Studies on the use of stem-cell-derived organoids in regenerative medicine, organoids as 3D culture models for EVs analysis, and organoids for precision medicine were included. Articles with other irrelevant aims, meetings, letters, commentaries, congress and conference abstracts, and articles with no available full texts were excluded. Results: According to the included studies, organoids have various origins, types, and applications in regenerative and precision medicine, as well as an important role in studying extracellular vesicles. Conclusion: Organoids are considered a bridge that connects preclinical studies to clinical ones. However, the lack of a standardized protocol and other barriers addressed in this review, hinder the vast use of this technology. Lay Summary: Organoids are 3D stem cell propagations in biological or synthetic scaffolds that mimic ECM to allow intercellular or matrix-cellular crosstalk. Because these structures are similar to organs in the body, they can be used as research models. Organoids are medicine’s future hope for organ transplantation, tumor biobank formation, and the development of precision medicine. Organoid models can be used to study cell-to-cell interactions as well as effective factors like inflammation and aging. Bioengineering technologies are also used to define the size, shape, and composition of organoids before transforming them into precise structures. Finally, the importance of organoid applications in regenerative medicine has opened a new window for a better understanding of biological research, as discussed in this study. © 2022, The Author(s), under exclusive licence to The Regenerative Engineering Society.",TestAnalysis
"Sentiment classification aims to predict the sentiment label for a given text. Recently, several research efforts have been devoted to incorporate matching clues between text words and class labels into the learning process of text representation. However, these methods heavily rely on the availability of label content. Moreover, they simply capture the label-specific signals to measure each word's contribution by either implicitly employing a learnable label representation or explicitly leveraging the interaction between text words and labels via the interaction mechanism. To deal with these issues, in this paper, we propose a novel framework called Label-Guided Dual-view Sentiment Classifier (LGDSC). We first introduce a new strategy for generating an effective label description and then design a novel Dual-Channel Label-guided Attention Network (DLAN) to learn a text representation via two different channels. DLAN will be further leveraged to learn label-guided text representations from two different views. Extensive experimental results on four real-world datasets demonstrate that LGDSC consistently outperforms the state-of-the-art baseline methods. © 2022 Elsevier Ltd",TestAnalysis
"The purpose of this research is to synthesize the fragmented extant knowledge on flexible and green supply chain management (FGSCM) in the context of emerging economies and to unearth research gaps to motivate future research. We adopted a novel structured systematic literature review by triangulating a systematic literature review, text mining, and network analysis. Institutional theory and contingency theory were employed to analyze the results of the review. The results show that, firstly, research on FGSCM in emerging economies, despite its importance, is immature compared to general FGSCM literature. Second, the specificities of strategies and practices that distinguish this topic in emerging economies are discussed and the drivers and barriers are identified with respect to sources of institutional pressure. Third, a research framework for FGSCM in emerging economies is developed and 12 gaps for future research are identified. This study has exclusively developed a research framework for FGSCM in an emerging economy which has received the least consideration in the literature and practice. The framework was developed to synthesize the existing literature and to identify the research gaps to inspire future research. © 2022, Crown.",TestAnalysis
"Central bank independence has raised questions of accountability ever since its global diffusion in the 1990s, and especially since the financial crisis. Yet, whilst the literature on central banks’ legislative oversight has expanded, the role of the media as account holders has been left largely unexplored. We assess media scrutiny by using an original dataset of news articles about the Bank of England published between 1997 and 2020, and by analysing the relationship between central banking outcomes and scrutiny in the form of evaluative and negative coverage of the Bank. We find that the variation in such coverage can be traced back to policy outcomes, but the association is largely confined to the post-crisis period. The findings support a view of the media as instrumental in central bank oversight, but also show the limits of this form of accountability. © 2022 The Author(s)",TestAnalysis
"In Shannon theory, semantic aspects of communication were identified but considered irrelevant to the technical communication problems. Semantic communication (SC) techniques have recently attracted renewed research interests in 6 generation (6G) wireless, because they have the capability to support an efficient interpretation of the significance and meaning intended by a sender (or accomplishment of the goal) when dealing with multi-modal data such as videos, images, audio, text messages, and so on, which would be the case for various applications such as intelligent transportation systems where each autonomous vehicle needs to deal with real-Time videos and data from a number of sensors including radars. To this end, most of the emerging SC works focus on specific data types and employ sophisticated machine learning models including deep learning and neural networks. However, they could be impractical for multi-modal data possibly within a real-Time constraint, relative to the purpose of the communication. A notable difficulty of existing SC frameworks lies in handling the discrete constraints imposed on the pursued semantic coding and its interaction with the independent knowledge-base, which makes reliable semantic extraction extremely challenging. Therefore, we develop a new hashing-based semantic extraction approach to SC framework, where our learning objective is to generate one time signatures (hash codes) using supervised learning for low latency, secure and efficient management of the SC dynamics. We first evaluate the proposed semantic extraction framework over large image data sets, extend it with domain adaptive hashing and then demonstrate the effectiveness of 'semantics signature' in bulk transmission and multi-modal data.  © 1967-2012 IEEE.",TestAnalysis
"Objective: To systematically investigate the efficacy and safety of dextrose prolotherapy for treating chronic plantar fasciitis. Literature survey: EMBASE, PubMed, Scopus, and Google Scholar (from inception to December 9, 2021). Methodology: Comprehensive review of randomized controlled trials investigating dextrose prolotherapy for chronic plantar fasciitis was done. Two investigators independently screened the titles, abstracts, and full texts and extracted data from eligible studies. The changes in visual analog scale (VAS) pain score, foot function index (FFI), American Orthopaedic Foot and Ankle Society (AOFAS) score, and plantar fascia thickness were analyzed. Reports of complications of the procedure were collected. Synthesis: Eight randomized controlled trials (RCTs) were included in the meta-analysis, analyzing 444 patients in total. The subgroup analysis showed that at short-term follow-up (<6 months) dextrose prolotherapy was more effective in reducing VAS pain score compared to the non-active treatment control group including exercise and normal saline solution (NSS) injection. However, there was no difference in the change of VAS pain score between dextrose prolotherapy and active treatment control group, which included extracorporeal shock wave therapy (ESWT), steroid injection, and platelet-rich plasma (PRP) injection. Dextrose prolotherapy was more effective in reducing FFI, increasing AOFAS score, and reducing plantar fascia thickness at short-term (<6 months) follow-up compared to other comparators. For long-term (≥6 months) follow-up, there was no significant difference in the change in VAS pain score and FFI between the dextrose prolotherapy group and other comparators. No serious complication was reported. Conclusions: Dextrose prolotherapy is an effective treatment of chronic plantar fasciitis to reduce pain, improve foot functional score, and decrease plantar fascia thickness at short-term follow-up. Further studies in larger populations are needed to identify the optimal treatment regimen including dextrose concentration, volume, injection site, injection technique, and the number of injections required. The long-term effects of these treatments also require further examination. © 2022 American Academy of Physical Medicine and Rehabilitation.",TestAnalysis
"Nowadays, cloud computing plays an important role in the process of storing both structured and unstructured data. This contributed to a very large data growth on web servers, which has come to be called Big Data. Cloud computing technology is adopted in many applications, perhaps the most important of which are social networking applications, e-mail messages, and others, which represent an important source of data through the process of communication between web users. Thus, these data represent views and opinions on various topics, which can help businesses and other decision makers in making decisions based on future predictions. To achieve this goal, several methods have been proposed. Recently, it relies on the use of deep learning as a tool for processing large volumes of data due to its high performance in extracting predictions from the opinions of web users. This paper presents a new prediction approach based on Big Data analysis and deep learning for large-scale data, called PABIDDL. The infrastructure of the proposed approach is focused on three important stages, starting with the reduction of Big Data based on MapReduce using the Hadoop framework. In the second stage, we performed the initialization of these data using the GloVe technique. Finally, the text data were classified into advantages and disadvantages poles depending on CNN deep learning approach. Also, we conducted an empirical study of our proposed approach PABIDDL and related works models on two standard datasets IMDB and MR datasets. The results obtained showed that the best performance is given by our approach. We recorded 0.93%, 0.90%, and 0.92% as an accuracy, a recall, and an F1-score, respectively. Furthermore, our approach reached the fastest response time. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",TestAnalysis
"E-commerce strongly relies on marketing strategies that utilize user given feedback on services provided. Hotels and other hospitabilty outlets such as restaurants enlist user feedback about their services in their online reservation systems, thereby helping thier prospective customers in the decision making process. The credibility of such reviews is of paramount significance and any compromise of the process can lead to unwanted consequences both for customers and businesses. As such, the need for a method by which deceptive reviews are identified is evident to protect community and businesses alike. Deceptive reviews typically exhibit distinctive linguistic clues which can be detected, raising a flag about the credibilty of the user who posted them. Specifically, discursive features that show in such texts can be a useful tool in checking the credibility of reviews. Manually analysing the discourse and different rhetorical structures can be a tedious and timeconsuming process allowing some deceptive reviews to remain publically available. However, coupled with artificial intelligence tools such as deep learning approaches, discourse analysis could be performed in a manner that is both efficient and timely. The proposed study used a balanced publically available deceptive and truthful reviews dataset to design a discourse analysis based credibility check scheme with high accuracy. The multi-context of text is extracted via multi-n-gram windows (named as Discourse markers) applied in a proposed deep multi-channel convolutional neural network (MC-CNN). The hold-out approach is applied with 6 various splits of data on the proposed method MC-CNN to validate the performance. From various experiments, we report the best F1-score 87% has been achieved that not only defended the deep learning based discourse analysis but also defended the hypothesis made on deceptive and truthful reviews by proposed study. © 2022 Elsevier Ltd",TestAnalysis
"Textline segmentation in ancient handwritten documents is still considered as a challenging task in document analysis and recognition field even though various rule-based methods exist. These methods succeed under constraint such as a roughly uniform background. They do not contribute well in case of variable inter-line spacing and overlapping characters. This article proposes faster region-convolution neural network (R-CNN) based robust method to segment the textlines in the ancient handwritten document in Devanagari script for the first time in literature. The feature matrix has been generated by residual network and proposals have been predicted through the region proposal network (RPN). A pooling layer has been used to extract regions of interest, known as region of interest pooling layer, to locate the textlines. The performance of the proposed textline segmentation system has been evaluated on self generated dataset of ancient handwritten documents in Devanagari script and it has achieved the f-measure of 99.98%. Experimental results demonstrate that the proposed system outperforms the existing state-of-the-art methods of textline segmentation. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"The learning rate (LR) is one of the most important hyperparameters in stochastic gradient descent (SGD) algorithm for training deep neural networks (DNN). However, current hand-designed LR schedules need to manually pre-specify a fixed form, which limits their ability to adapt to practical non-convex optimization problems due to the significant diversification of training dynamics. Meanwhile, it always needs to search proper LR schedules from scratch for new tasks, which, however, are often largely different with task variations, like data modalities, network architectures, or training data capacities. To address this learning-rate-schedule setting issue, we propose to parameterize LR schedules with an explicit mapping formulation, called MLR-SNet. The learnable parameterized structure brings more flexibility for MLR-SNet to learn a proper LR schedule to comply with the training dynamics of DNN. Image and text classification benchmark experiments substantiate the capability of our method for achieving proper LR schedules. Moreover, the explicit parameterized structure makes the meta-learned LR schedules capable of being transferable and plug-and-play, which can be easily generalized to new heterogeneous tasks. We transfer our meta-learned MLR-SNet to query tasks like different training epochs, network architectures, data modalities, dataset sizes from the training ones, and achieve comparable or even better performance compared with hand-designed LR schedules specifically designed for the query tasks. The robustness of MLR-SNet is also substantiated when the training data are biased with corrupted noise. We further prove the convergence of the SGD algorithm equipped with LR schedule produced by our MLR-SNet, with the convergence rate comparable to the best-known ones of the algorithm for solving the problem. The source code of our method is released at https://github.com/xjtushujun/MLR-SNet.  © 1979-2012 IEEE.",TestAnalysis
"Video Surveillance (VS) systems are popular. For enhancing the safety of public lives as well as assets, it is utilized in public places like marketplaces, hospitals, streets, education institutions, banks, shopping malls, city administrative offices, together with smart cities. The main purpose of security applications is the well-timed and also accurate detection of video anomalies. Anomalous activities along with anomalous entities are the video anomalies, which are stated as the irregular or abnormal patterns on the video that doesn’t match the normal trained patterns. Automatic detection of Anomalous activities, say traffic rule infringements, riots, fighting, and stampede in addition to anomalous entities, say, weapons at the sensitive place together with deserted luggage ought to be done. The Anomaly Detection (AD) in VS is reviewed in the paper. This survey concentrates on the Deep Learning (DL) application in finding the exact count, involved individuals and the occurred activity on a larger crowd at every climate condition. The fundamental DL implementation technology concerned in disparate crowd Video Analysis (VA) is discussed. Moreover, it presented the available datasets as well as metrics for performance evaluation and also described the examples of prevailing VS systems utilized in the real life. Lastly, the challenges together with propitious directions for additional research are outlined. Pattern recognition has been the subject of a great deal of study during the previous half-century. There isn’t a single technique that can be utilised for all kinds of applications, whether in bioinformatics or data mining or speech recognition or remote sensing or multimedia or text detection or localization or any other area. Methodologies for object recognition are the primary focus of this paper. All aspects of object recognition, including local and global feature-based algorithms, as well as various pattern-recognition approaches, are examined here. Please note that we have attempted to describe the findings of many technologies and the future extent of this paper’s particular technique. We used the datasets’ properties and other evaluation parameters found in an easily accessible web database. Research in pattern recognition and object recognition can greatly benefit from this study, which identifies the research gaps and limits in this subject. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"Keyword extraction is an important topic applicable to a wide range of areas such as span detection, information classification, sentiment analysis, and so on. There are hundreds of algorithms which can extract keywords from text documents. Many of these algorithms also use the functionality of the keywords, which is important, especially if we need to limit to a specific area of knowledge. This research work focuses on extracting keywords from educational texts. In an educational context, the keywords are the most important parts of the lesson and may answer the professor's questions. Classic keyword extraction algorithms have a very low success rate extracting keywords from educational texts, as the words extracted by these algorithms are very different from those selected by the teachers. Normally, the most important words from an educational point of view would not match with the most repeated words in that text. This research work attempts to improve automatic keyword extraction in educative texts, avoiding professors from having to do this tedious task. The possibility of detecting keywords automatically could be a starting point for the creation of applications capable of generating questions and exercises automatically. We tested whether the most popular word extraction algorithms were able to extract the keywords selected by professors efficiently. The result obtained by current algorithms were no good at all, as they showed a low true positive rate or very high rates of false positive. Due to these reasons, we designed a novel algorithm based on linguistic approaches and evolutive graphs. The research method to obtain the new algorithm was the design of a complex graph which operates with numerous characteristics related to the relationships between words and their linguistic properties. The graph was trained with a set of texts and keywords to establish the optimal weights for each of the characteristics. The proposal achieves a rate of true positives (TP) and F1 score significantly better than other algorithms. © 2022",TestAnalysis
"This study investigates the possibilities offered by the development of graphene environment technology that can contribute to new and effective approaches for the transition to an ecologically benign ecosystem. To analyze the research and development progress in graphene environment technology, graphene environment technology research trends of South Korea for the years 2009–2020 are investigated by acquiring information pertaining to national research and development projects related to graphene environment technology from the National Science and Technology Information Service. Both structured and unstructured data are analyzed using diverse text-mining methods, such as keyword frequency analysis, association rule mining, and topic modelling. The results indicate that graphene research in South Korea is focused primarily on graphene use in batteries and energy-storage devices, such as solar cells, fuel cells, and secondary batteries. This study can help understand the manner by which the South Korean government has been investing in the research and development of graphene environment technology; additionally, it discusses the future applications and prospects of graphene for the next decade. © 2022 China Ordnance Society",TestAnalysis
"Context: Several tertiary studies have criticized the reporting of software engineering secondary studies. Objective: Our objective is to identify guidelines for reporting software engineering (SE) secondary studies which would address problems observed in the reporting of software engineering systematic reviews (SRs). Method: We review the criticisms of SE secondary studies and identify the major areas of concern. We assess the PRISMA 2020 (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) statement as a possible solution to the need for SR reporting guidelines, based on its status as the reporting guideline recommended by the Cochrane Collaboration whose SR guidelines were a major input to the guidelines developed for SE. We report its advantages and limitations in the context of SE secondary studies. We also assess reporting guidelines for mapping studies and qualitative reviews, and compare their structure and content with that of PRISMA 2020. Results: Previous tertiary studies confirm that reports of secondary studies are of variable quality. However, ad hoc recommendations that amend reporting standards may result in unnecessary duplication of text. We confirm that the PRISMA 2020 statement addresses SE reporting problems, but is mainly oriented to quantitative reviews, mixed-methods reviews and meta-analyses. However, we show that the PRISMA 2020 item definitions can be extended to cover the information needed to report mapping studies and qualitative reviews. Conclusions: In this paper and its Supplementary Material, we present and illustrate an integrated set of guidelines called SEGRESS (Software Engineering Guidelines for REporting Secondary Studies), suitable for quantitative systematic reviews (building upon PRISMA 2020), mapping studies (PRISMA-ScR), and qualitative reviews (ENTREQ and RAMESES), that addresses reporting problems found in current SE SRs.  © 2022 IEEE.",TestAnalysis
"Existing image aesthetics assessment methods mainly rely on the visual features of images but ignore their rich semantics. Nowadays, with the widespread application of social media, the comments corresponding to images in the form of texts can be easily accessed and provide rich semantic information, which can be utilized to effectively complement image features. This paper proposes a comment-guided semantics-aware image aesthetics assessment method, which is built upon a multi-task learning framework for image aesthetics prediction and comment-guided semantics classification. To assist image aesthetics assessment, we first model the semantics of an image as the topic features of its corresponding comments using Latent Dirichlet Allocation. We then propose a two-stream multitask learning framework for both topic feature prediction and aesthetic score distribution prediction. Topic feature prediction task enables to infer the semantics from images, since the comments are usually unavailable during inference and comment-guided semantics can only serve as supervision during training. We further propose to deeply fuse aesthetics and semantic features using a layerwise feature fusion method. Experimental results demonstrate that the proposed method outperforms state-of-the-art image aesthetics assessment methods.  © 1991-2012 IEEE.",TestAnalysis
"Nutrient deficiency during growth is a major cause of reduced yield for wide variety of plants. Yield can be improved if nutrient levels are regularly checked, and maintained using proper fertilization & pest control. In order to perform this task, a wide variety of image processing systems models have been developed, which aim at analysing plant imagery to look for visually apparent nutrient deficient patterns. But these systems are able to identify nutrient deficiencies after the plant is affected by them. In contrast to this, intrusive systems are developed which perform chemical analysis on leaf samples in order to estimate these deficiencies. Performing such chemical analysis limits their testing capabilities because random leaf samples are taken for evaluation, thereby limiting their accuracy. In order to remove these drawbacks, this text proposes a nonintrusive multifrequency visible light analysis framework, that can be used for identification of multiple nutrient deficiencies for a wide variety of plants. In order to map spatial & temporal light properties with nutrient shortages with high accuracy, this framework leverages extensive learning. In order to authenticate the readings, the framework also processes nonintrusive microscopic photos of the same plant leaf using a deep learning technique. This is accomplished by an incremental learning technique that combines the high-efficiency classification capabilities of the VGGNet19 and XceptionNet models. The model can be used for proactive nutrient monitoring and to conduct corrective actions to improve yield quality because it is nonintrusive. The proposed model was evaluated for potassium, nitrogen, copper, zinc, and phosphorus deficit in orange, cotton, apple, banana, mango, litchi, henna, gooseberry, and okra leaf. It was observed that the proposed approach is able to achieve 99.7% accuracy for detection of potassium, 97.2% for nitrogen, 98.5% for copper, 96.8% for zinc, and 95.9% for detection of phosphorus. This accuracy was evaluated by finding average performance of the model for different leaf types, and was compared with various state-of-the-art models. It was observed that the proposed approach has 8% better accuracy than previously described models, and showcases better precision, recall, and fMeasure performance. Due to intensive learning, the model requires large initial delay of training, but evaluation speed is at par with recent state-of-the-art models. © 2022, The Author(s) under exclusive licence to The Korean Institute of Electrical Engineers.",TestAnalysis
"Background: Men with Klinefelter Syndrome develop some degree of seminiferous tubule degeneration, hyalinization, and fibrosis by adulthood. However, the pathophysiology surrounding testicular fibrosis in Klinefelter Syndrome patients remains incompletely understood. Objectives: To perform a systematic review of literature studying the mechanisms of fibrosis initiation or propagation in Klinefelter Syndrome testes. Materials/methods: PubMed was searched systematically for articles specific to Klinefelter Syndrome and the process of fibrosis. Articles that did not contain original data or specifically addressed the target material were excluded. Additional references were extracted when pertinent from the reference lists of included studies. Results: Primary search yielded 139 articles for abstract review, which was narrowed to 16 for full-text review. Following full-text review, eight contained original data and met topic criteria, with one paper added from reference review for a total of nine papers. Discussion: The date range for included papers was 1992–2022. The proposed mechanisms of fibrosis mainly were centered around the impact of altered Sertoli cells on germ cells, the hormonal impact on Leydig cells, the inflammation mediated by mast cells, or the fibrous extracellular matrix deposition by peritubular myoid cells. Additionally, discussions of the role of the altered microvasculature and the specific proteins involved in the blood-testis barrier or the seminiferous tubule architecture are reviewed. Recent papers have incorporated advanced sequencing and offer future directions for targeted gene expression analysis. Still, much of the published data consists solely of immunohistological assessment by age range, creating difficulties in extrapolating causality. Conclusion: The specific initiating factors of fibrosis of the seminiferous tubules and the propagation mechanisms unique to Klinefelter Syndrome remain incompletely understood with a relative paucity of data. Nonetheless, academic interest is increasing in this field as it may further elucidate the pathophysiology behind Klinefelter syndrome. © 2022 The Authors. Andrology published by Wiley Periodicals LLC on behalf of American Society of Andrology and European Academy of Andrology.",TestAnalysis
"Study objective: Patients undergoing diagnostic imaging studies in the emergency department (ED) commonly have incidental findings, which may represent unrecognized serious medical conditions, including cancer. Recognition of incidental findings frequently relies on manual review of textual radiology reports and can be overlooked in a busy clinical environment. Our study aimed to develop and validate a supervised machine learning model using natural language processing to automate the recognition of incidental findings in radiology reports of patients discharged from the ED. Methods: We performed a retrospective analysis of computed tomography (CT) reports from trauma patients discharged home across an integrated health system in 2019. Two independent annotators manually labeled CT reports for the presence of an incidental finding as a reference standard. We used regular expressions to derive and validate a random forest model using open-source and machine learning software. Final model performance was assessed across different ED types. Results: The study CT reports were divided into derivation (690 reports) and validation (282 reports) sets, with a prevalence of incidental findings of 22.3%, and 22.7%, respectively. The random forest model had an area under the curve of 0.88 (95% confidence interval [CI], 0.84 to 0.92) on the derivation set and 0.92 (95% CI, 0.88 to 0.96) on the validation set. The final model was found to have a sensitivity of 92.2%, a specificity of 79.4%, and a negative predictive value of 97.2%. Similarly, strong model performance was found when stratified to a dedicated trauma center, high-volume, and low-volume community EDs. Conclusion: Machine learning and natural language processing can classify incidental findings in CT reports of ED patients with high sensitivity and high negative predictive value across a broad range of ED settings. These findings suggest the utility of natural language processing in automating the review of free-text reports to identify incidental findings and may facilitate interventions to improve timely follow-up. © 2022 American College of Emergency Physicians",TestAnalysis
"This paper aims to investigate the impact of different parameters on promoting the role of cycling as a daily mode of transport. In the first step of the analyses, binary logistic regression was used to examine the impact of different parameters on using or not using the bicycle as a transportation mode in weekly trips. Then by text mining, the main reasons for not using a bicycle in weekly trips are outlined. Finally, for those who use bicycles for at least one utilitarian trip a week, the effect of different factors on the popularity of this mode is investigated by structural equation modeling. Tehran, as a big city in the Middle East and North Africa (MENA) region, was considered as the case study. The results suggest that it is necessary to work on social norms about cycling, especially among those with higher education levels and income. Women use bicycles less than men and it is also necessary to rethink attitudes and regulations in relation to women cycling in Islamic countries. Bicycle promotion should aim to facilitate more positive attitudes among women. Providing more facilities such as safe bicycle paths, bicycle parking, and bike-sharing facilities have significant impacts on using this mode and its popularity. In highly congested cities, alongside facilitating cycling, it is important to set restrictions on private car use. © 2022 American Society of Civil Engineers.",TestAnalysis
"Video-text retrieval is a crucial task that has been a powerful application for multi-media data analysis and attracted tremendous interest in the research area. The core steps are feature representations and alignment to overcome the heterogeneous gap between videos and texts. Existing methods not only take advantage of multi-modal information in videos but also explore local alignment to enhance retrieval accuracy. Although performing well, these methods seem deficient at three perspectives: a) The semantic correlations between different modal features are not considered, which introduces irrelevant noise in feature representations. b) The cross-modal relations and temporal associations are ambiguously learned by a single self-attention manipulation. c) The training signal to optimize the semantic topic assignment for local alignment is missing. In this paper, we proposed a novel Temporal Multi-modal Graph Transformer with Global-Local Alignment (TMMGT-GLA) for video-text retrieval. We model the input video as a sequence of semantic correlation graphs to exploit the structural information between multi-modal features. Graph and temporal self-attention layers are leveraged on the semantic correlation graphs to effectively learn cross-modal relations and temporal associations respectively. For local alignment, the encoded video and text features are assigned to a set of shared semantic topics, and the distances between residuals from the same ones are minimized. To optimize the assignments, a minimum entropy-based regularization term is proposed for training the overall framework. Experimental results are carried out on the MSR-VTT, LSMDC, and ActivityNet Captions datasets. Our method outperforms previous approaches by a large margin and achieves state-of-the-art performance.  © 1991-2012 IEEE.",TestAnalysis
"Young adults (ages 18 to 25) in the U.S. suffer from the highest rates of past-year major depressive episode and are the least likely to receive treatment compared to other age groups. As such, we examined the feasibility, acceptability, and efficacy of a text-message delivered cognitive behavioral therapy: CBT-txt with young adults. The study was a 2-month pilot RCT to test a 4-week intervention for depression that contained 197 text messages (average 12 texts every other day). The sample, recruited via Facebook and Instagram, was 102 U.S. young adults who presented with at least moderate depressive symptomatology. Assessments occurred at baseline prior to randomization and at 1 and 2 months post enrollment. The primary outcome, severity of depressive symptoms, was assessed using the Beck Depression Inventory II. Feasibility benchmarks were met and participants reported high levels of engagement with and acceptability of the intervention. Logistic regression indicated that treatment participants were three times as likely to have minimal or mild depression symptoms at 2 months compared to waitlist control participants. Latent change score modeling found that the strongest significant treatment effect appeared at the 1-month follow-up period, particularly for participants who began with severe depressive symptoms. Mediation analysis revealed significant indirect treatment effects of increases in behavioral activation on reducing depressive symptoms, suggesting a mechanism of change. Limitations were that the sample was relatively small and consisted of primarily women. These results provide initial evidence for the feasibility, acceptability, and efficacy of a text-delivered treatment for young adult depression. © 2023",TestAnalysis
"Internet applications such as Online Social Networking and Electronic commerce are becoming incredibly common, resulting in more content being available. Recommender systems (RS) assist users in identifying appropriate information out of a large pool of options. In today’s internet applications, RS are extremely important. To increase user satisfaction, this type of system supports personalized recommendations based on a massive volume of data. These suggestions assist clients in selecting products, while concerns can increase product utilization. We discovered that much research work is going on in the field of recommendation and that there are some effective systems out there. In the context of social information, sentimental analysis (SA) can aid in increasing the knowledge of a user’s behaviour, views, and reactions, which is helpful for incorporating into RS to improve recommendation accuracy. RS has been found to resolve information overload challenges in information retrieval, but they still have issues with cold-start and data sparsity. SA, on the other hand, is well-known for interpreting text and conveying user choices. It’s frequently used to assist E-Commerce in tracking customer feedback on their products and attempting to comprehend customer needs and preferences. To improve the accuracy and correctness of any RS, this paper proposes a recommendation model based on a Hybrid Recommendation Model (HRM) and hybrid SA. In the proposed method, we first generate a preliminary recommendation list using a HRM. To generate the final recommendation list, the HRM with SA is used. In terms of various evaluation criteria, the HRM with SA outperforms traditional models. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"The registration statement, the inquiry letter, and the reply letter are the main application materials for companies wanting to list on the Science and Technology Innovation Board (STAR) need to submit to regulatory agencies In this paper, we aim to study the impact of these three kinds of application materials on the successful listing of companies on STAR market in China through six text characteristics, including Words, Boilerplate, Fog Index, HardInfoMix, Redundancy, and Specificity for the first time. In the empirical analysis, we collect the registration statements and the inquiry-reply letters of 220 listed companies and 64 unlisted companies from June 13, 2019 to January 31, 2021 to perform the regression analysis. The empirical results show that, for registration statements, higher Words and Boilerplate will improve the success rate for listing, but higher Redundancy will lead to the failed listing. For the inquiry-reply letter, only the number of questions contained in the inquiry letter is negatively significantly associated with the initial public offering (IPO) success rate, while the text characteristics of the reply letter have little to do with the IPO success rate. © 2022 Elsevier B.V.",TestAnalysis
"The aim of this paper is to develop a model to classify the stance expressed in social media texts. More specifically, the work presented focuses on tweets. In stance detection (SD) tasks, the objective is to identify the stance of a person towards a target of interest. In this paper, a model for SD is established and its variations are evaluated using different classifiers. The single models differ based on the pre-processing and the combination of features. To reduce the dimensionality of the feature space, analysis of variance (ANOVA) test is used. Then, two classifiers are employed as base learners including Random Forests (RF) and Support Vector Machines (SVM). Experimental analyses are conducted on SemEval dataset that is used as a benchmark for SD. Finally, the base learners that resulted from different design alternatives, are combined into three ensemble models. Experimental results show the significance of the used features and the effectiveness of a manually built dictionary that is used in the pre-processing stage. Moreover, the proposed ensembles outperform the state-of-the-art models in the overall test score, which suggests that ensemble learning is the best tool for effective SD in tweets.  © 2023 World Scientific Publishing Company.",TestAnalysis
"Science, Technology, and Innovation (STI) have been considered as critical tools in development processes, gaining growing importance in the public policy agenda. We assert that an intersubjective agreement about STI policy has emerged in Latin America from the beginning of the twenty-first century. This operates as a developmental convention which is based on a hybrid theoretical rationale from neoclassical economics and the innovation systems approach. This process has been analyzed from different perspectives of innovation and political economy studies. However, as far as we know, the role of political parties in the construction and reproduction of STI conventions has not been studied. After illustrating the general assertion with stylized facts from the whole Latin American region, we study the platforms that Uruguayan political parties presented in the national elections between 2004 and 2019. Text analysis techniques show that platforms of both left- and right-wing political parties were embedded in the current STI policy convention. However, critical discrepancies emerge in relation to policy implementation—the positive and negative agendas—which show that there has been political competition regarding the role of the state and of markets. This leads us to conclude that even though one can observe a shared set of building blocks on STI policy and development, there is competition within the current convention, suggesting that any agreement is illusory. © 2022 Policy Studies Organization.",TestAnalysis
"This article describes the research design and findings from a use-inspired study of online text-based mathematics resources. We sought to understand whether and how existing mathematics interest, together with the learner characteristics of prior coursework in mathematics and proof scheme, influenced comprehension of mathematical argumentation and triggered interest in two types of mathematics text: (1) text featuring concrete, real-world applications (public domain) and (2) text with abstract and generalized modes of expression and content (abstract domain). Using an online assessment and person-centered analyses, we studied 64 (32 M, 32 F) undergraduate students who were and were not pursuing advanced mathematics coursework. Cluster analysis revealed two participant groups. Less mathematically immersed (LMI) participants improved comprehension of mathematical argumentation when working with public domain text, performing comparably to the more mathematically immersed (MMI) cluster in this domain; those in the MMI cluster performed comparably across text domains. In addition, LMI participants were more likely to identify public domain text as more interesting than abstract text, and they also were more likely than those in the MMI group to explain this by citing public rather than abstract domain reasons. Taken together, study findings suggest that interest in coordination with other learner characteristics scaffolds comprehension of mathematical argumentation. This study makes contributions to interest theory, understanding the role of interest in comprehension of mathematical argumentation, and ways in which practitioners might leverage student interest to promote comprehension. © 2022, The Author(s).",TestAnalysis
"The analytic connectivity (AC), defined via solving a series of constrained polynomial optimization problems, serves as a measure of connectivity in hypergraphs. How to compute such a quantity efficiently is important in practice and of theoretical challenge as well due to the non-convex and combinatorial features in its definition. In this article, we first perform a careful analysis of several widely used structured hypergraphs in terms of their properties and heuristic upper bounds of ACs. We then present an affine-scaling method to compute some upper bounds of ACs for uniform hypergraphs. To testify the tightness of the obtained upper bounds, two possible approaches via the Pólya theorem and semidefinite programming respectively are also proposed to verify the lower bounds generated by the obtained upper bounds minus a small gap. Numerical experiments on synthetic datasets are reported to demonstrate the efficiency of our proposed method. Further, we apply our method in hypergraphs constructed from social networks and text analysis to detect the network connectivity and rank the keywords, respectively. © 2022 John Wiley & Sons, Ltd.",TestAnalysis
"We aimed to evaluate the performance of supervised machine learning algorithms in predicting articles relevant for full-text review in a systematic review. Overall, 16,430 manually screened titles/abstracts, including 861 references identified relevant for full-text review were used for the analysis. Of these, 40% (n = 6573) were sub-divided for training (70%) and testing (30%) the algorithms. The remaining 60% (n = 9857) were used as a validation set. We evaluated down- and up-sampling methods and compared unigram, bigram, and singular value decomposition (SVD) approaches. For each approach, Naïve Bayes, Support Vector Machines (SVM), regularized logistic regressions, neural networks, random forest, Logit boost, and XGBoost were implemented using simple term frequency or Tf-Idf feature representations. Performance was evaluated using sensitivity, specificity, precision and area under the Curve. We combined predictions of the best-performing algorithms (Youden Index ≥0.3 with sensitivity/specificity≥70/60%). In a down-sample unigram approach, Naïve Bayes, SVM/quanteda text models with Tf-Idf, and linear SVM e1071 package with Tf-Idf achieved >90% sensitivity at specificity >65%. Combining the predictions of the 10 best-performing algorithms improved the performance to reach 95% sensitivity and 64% specificity in the validation set. Crude screening burden was reduced by 61% (5979) (adjusted: 80.3%) with 5% (27) false negativity rate. All the other approaches yielded relatively poorer performances. The down-sampling unigram approach achieved good performance in our data. Combining the predictions of algorithms improved sensitivity while screening burden was reduced by almost two-third. Implementing machine learning approaches in title/abstract screening should be investigated further toward refining these tools and automating their implementation. © 2022 The Authors. Research Synthesis Methods published by John Wiley & Sons Ltd.",TestAnalysis
"Pedagogical content knowledge (PCK) is an important target of science teacher knowledge assessment. Most studies that have assessed the PCK across a large sample of science teachers used a text-based approach to elicit and assess the more declarative and static form of teachers' PCK. Recently, small-scale qualitative studies have adopted a novel video-based approach to characterize the more situated and dynamic form of PCK underpinning a teacher's in-the-moment pedagogical reasoning. In this relatively large-scale mixed-methods study, these two approaches to assessing PCK were compared. Specifically, a counterbalanced design was adopted to compare the test scores of 147 Grade 7 biology teachers in a video-based PCK test with those of the same teachers in a text-based PCK test with the same content. A subgroup of teachers (N = 30) with different levels of PCK was interviewed to further understand their reactions to the test and how these might have affected their test performance. The results of paired-samples t tests showed that the teachers' PCK scores in the two types of test were significantly correlated, but their scores were significantly lower in the video-based test. In terms of teacher reactions, although the teachers considered both types of test to be fair, they regarded the video-based test as more authentic and more closely related to their job demands. The teachers reported putting more effort into the video-based test and feeling more immersed and engaged, but also experiencing greater cognitive demand and a higher level of anxiety. A multiple regression analysis revealed that the cognitive demand perceived by the teachers significantly predicted their PCK scores in the video-based test. The findings have implications for the valid design of video-based PCK tests. © 2022 National Association for Research in Science Teaching.",TestAnalysis
"Recent advances in interactive recommender systems (IRS) have received wide attention due to its flexible recommendation strategy and optimization for users’ long-term utility. Considering this interaction paradigm of IRS, researchers have made some attempts to incorporate reinforcement learning (RL) models into IRS, because of the excellent ability of RL in long-term optimizing and decision making. However, data sparsity is an intractable problem most IRS urgently need to address. Although a small amount of work has exploited reviews to address data sparsity, they ignored the varying importance of items for modeling the user. In addition, most existing RL-based approaches suffer from decision-making difficulties when the action space becomes large. To solve above problems, in this work, we present a Review-enhanced Deep Reinforcement Learning model (REDRL) for interactive recommendation. Specifically, we utilize text reviews, combined with a pretrained review representation model to acquire item review-enhanced embedding representations. Then we formalize the recommendation problem as a Markov Decision Process (MDP), and exploit deep reinforcement learning (DRL) to model the interactive recommendation. Notably, we introduce a multi-head self-attention technique to capture distinct importance of various items in the sequence behavior, which is overlooked by existing work when modeling the user preference. In this way, we can model long-term dynamic preferences of users accurately and discriminately for comprehensive interactive recommendation. Moreover, we subtly combine the semantic structure information in the user–item bipartite graph with meta-paths in heterogeneous information networks (HIN), to filter some irrelevant items and obtain candidate items dynamically. By this means, the size of the discrete action space is effectively reduced from a new anger. The experimental results based on three benchmark datasets demonstrate the efficiency of our method with significant improvement over state-of-the-art. © 2022 Elsevier Ltd",TestAnalysis
"Background: Stroke compromises the quality of life and wellbeing of stroke survivors and families as a whole. The unexpected caregiving responsibilities often cause psychological distress, overwhelming emotions, living losses and grief, and relational conflicts with stroke survivors. Despite the increasing research to better understand their needs, empirically sound and holistic psychosocial interventions for stroke caregivers are lacking. Aims: This study aims to consolidate psycho-socio-emotional needs and challenges in the existing systematic reviews and offer potential directions for psychosocial interventions to better support caregivers at a psycho-socio-emotional level. Methods: This systematic review adhered to the PRISMA guideline and employed the PICo (population, phenomena of interest, context) framework to screen for relevant systematic reviews for analysis. Six major databases were searched, including Academic Search Premier, CINAHL, Global Health, Medline, PsycArticles, and PsycInfo between 2010 and 2020. Ten systematic reviews were selected for full-text analysis using thematic synthesis. Summary of review: Data synthesis revealed eight themes with sixteen sub-themes, all together organized into two main theme categories. The psycho-socio-emotional challenges included disruptions to (1) psychological homeostasis, (2) role equilibrium, (3) familial connection, and (4) caregiving empowerment. The psycho-socio-emotional coping mechanisms, which could be adopted to buffer against the identified challenges, involved (1) recalibration of normality and balance, (2) psychosocial support and caregiver relief, (3) relational reorientation and dyadic coping, and (4) institutional holistic care and support. Conclusion: The findings accentuate the importance of addressing living losses and grief emerging from the caregiving journey, as well as facilitating meaning reconstruction to safeguard caregivers’ wellbeing. Clinical implications and future research directions are discussed. © 2022 World Stroke Organization.",TestAnalysis
"Deep neural networks have achieved good performance in recent years for aspect-level sentiment classification (ASC), whereas most neural ASC models neglect the commonsense knowledge absent from text but essential for aspect affective understanding, which largely limits the performance of neural ASC. In this paper, we propose a Weakly Supervised Knowledge Attentive Network, which resolves the above problems via knowledge attention and weakly supervised learning. Specifically, we first present a Knowledge Attentive Network (KAN) to capture more aspect-related information by incorporating external commonsense knowledge into the attention mechanism. Then, we propose a weakly supervised learning method, which allows our KAN model to learn more knowledge from the pseudo-samples generated upon the rich-resource document-level sentiment classification datasets. Extensive experiments on four benchmark datasets show the significant advantages of our proposed approach. In particular, we obtain state-of-the-art performance in terms of accuracy on all the datasets. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"Aspect-based sentiment analysis (ABSA) is a granular-level sentiment analysis task that aims to detect the sentiment polarities of a specified aspect in the text. This research shows excessive curiosity in modelling target and context through attention networks to attain effective feature representations for sentiment detection works. We have proposed a synthetic attention in bidirectional encoder representations from transformers (SA-BERT) with an extreme gradient boosting (XGBoost) classifier to classify sentiment polarity in the review dataset. The proposed model generates dynamic word vector encoding of the aspect and corresponding context of the reviews. Then, the aspect and context of the reviews are meaningfully represented by a transformer that can input the vector word in parallel. After that, the model uses the synthetic attention mechanism to learn essential parts of context and aspects in reviews. Finally, the model places overall representation in the sentiment classification layer to predict sentiment polarity. Both proposed SA-BERT and SA-BERT-XGBoost models achieved the highest accuracy (92.02 and 93.71%) on the restaurant16 and highest F-1 scores (81.19 and 81.64%) on the restaurant14 dataset, respectively. The average accuracy and F1 scores are approximately 2 and 3.04% higher than the baseline models (DLCF-DCA-CDM, R-GAT+BERT, ASGCN-DG, AEN-BERT and BERT-PT). Therefore, proposed models outperform in comparison with baseline models. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"In this brief, a 2-10 GHz reconfigurable power amplifier (PA) with power-added efficiency (PAE) of 30% and output power of 2W is proposed using commercial $0.25~\mathbf {\mu }\text{m}$ GaN technology. It consists of two-stage amplifier transistors with reconfigurable input, inter-stage and output matching networks. By utilizing the reconfigurable matching networks, the proposed PA circuit divides the frequency band of 2-10 GHz into three continuous sub-frequency bands, and achieves high power added efficiency and gain in each sub-frequency band. As a result, the proposed PA can simultaneously maintain high efficiency and high gain and cover multioctave bandwidth. Moreover, in order to further improve the efficiency, harmonic suppression is used in low-band with open circuit impedance at third harmonic. With these techniques, the proposed PA covers frequency band of 2-10 GHz, delivers an average PAE of 38% at 2-5 GHz, 31% at 5-7 GHz, and 31.5% at 7-10 GHz. Good agreement between simulation and measurement is obtained.  © 2004-2012 IEEE.",TestAnalysis
"Background The US Food and Drug Administration requires six text-only warnings for cigar products, including cigarillos. Research has demonstrated the superiority of pictorial over text-only cigarette warnings, yet the relative effectiveness of pictorial warnings for cigarillos has not been examined. We examined the impact of pictorial cigarillo warnings compared with text-only warnings. Methods Data were collected from a nationally representative sample of US young adult (18-29) cigarillo users and susceptible non-users. Participants were randomised to one of three experimental conditions: text-only or one of two pictorial conditions (combined for analyses). For each warning, we assessed negative emotional reactions, cognitive elaboration (ie, thinking about cigarillo risks) and perceived message effectiveness (PME). Results Participants (N=661) were 46.5% female, 64.7% white and 21.9% Hispanic; 34.1% reported past 30-day cigarillo use; 41.4% were lifetime users (excluding past 30-day use); and 24.4% were susceptible non-users. Pictorial warnings elicited more negative emotional reactions and higher PME than text-only warnings (p values<0.01), with interactions showing the largest effects for past 30-day users (emotional reactions: d=0.99, PME: d=0.63). For cognitive elaboration, there was no main effect of warning type, but an interaction revealed effects for past 30-day users (p<0.05, d=0.46). Conclusions Pictorial cigarillo warnings elicited greater negative emotional reactions and PME compared with text-only warnings. These effects and the effects on cognitive elaboration were strongest for past 30-day users. Our findings extend research on cigarette warnings to cigarillos, demonstrating that pictorial warnings are superior to text-only warnings for cigarillos in eliciting beneficial responses.  © Author(s) (or their employer(s)) 2023. No commercial re-use. See rights and permissions. Published by BMJ.",TestAnalysis
"Amongst the most treated questions in Western research on the works of Svetlana Aleksievich is the question of the genre of Aleksievich’s prose works, followed closely by the question of the historical authenticity of her method of collecting oral information about the Soviet period of history from witnesses of that history. The questions treated, such as the problem of genre, aesthetic authenticity and the relationship of history and fiction, can be distilled into the question of the authority of the literary text. If the Nobel Prize for literature is awarded on the assumption that Aleksievich’s work is literature—and no one, including the author, has questioned that assumption—then it is justifiable to pose the question of the authority of the literary text as an aesthetic message—as literary truth—using the tools of literary analysis, not of historiography or sociology. In this essay, the claim that Secondhand Time [Vremia second hend] is a novel will be examined in the context of the narratological model of the literary text of Russian Formalism and Prague Structuralism and by applying the test of “artistic quality” (khudozhestvennost’), which validates the aesthetic value of texts of the literary canon. This examination will allow us to answer the question about what kind of text has been created using oral testimonies as material for a work of fiction. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.",TestAnalysis
"Discourse structure annotation aims at analysing how discourse units (e.g. sentences or clauses) relate to each other and what roles they play in the overall discourse. Several annotation tools for discourse structure have been developed. However, they often only support specific annotation schemes, making their usage limited to new schemes. This article presents TIARA 2.0, an annotation tool for discourse structure and text improvement. Departing from our specific needs, we extend an existing tool to accommodate four levels of annotation: discourse structure, argumentative structure, sentence rearrangement and content alteration. The latter two are particularly unique compared to existing tools. TIARA is implemented on standard web technologies and can be easily customised. It deals with the visual complexity during the annotation process by systematically simplifying the layout and by offering interactive visualisation, including clutter-reducing features and dual-view display. TIARA’s text-view allows annotators to focus on the analysis of logical sequencing between sentences. The tree-view allows them to review their analysis in terms of the overall discourse structure. Apart from being an annotation tool, it is also designed to be useful for educational purposes in the teaching of argumentation; this gives it an edge over other existing tools. © 2021, The Author(s).",TestAnalysis
"Commercially sold electrical or gas products must comply with the safety standards imposed within a country and get registered and certified by a regulated body. However, with the increasing transition of businesses to e-commerce platforms, it becomes challenging to govern the compliance status of online products. This can increase the risk of purchasing non-compliant products which may be unsafe to use. Additionally, examining the compliance status before purchasing can be strenuous because the relevant compliance information can be ambiguous and not always directly available. Therefore, we collaborated with a regulated body from Australia, Energy Safe Victoria, and conducted compliance analyses for household appliances sold on multiple online platforms. A fully autonomous method shown in this public repository is also introduced to check the compliance status of any online product. In this talk, we discuss the compliance check process, which incorporates fuzzy logic for textual matching and a Convolutional Neural Network (CNN) model to classify the product listing based on the images listed. Subsequently, we studied the results with the business users and found that many online listings are non-compliant, signifying that online-shopping consumers are highly susceptible to buying unsafe products. We hope this talk can inspire more follow-up works that collaborate with regulated bodies to introduce a user-friendly compliance check platform that assists in educating consumers to purchase compliant products. © 2023 Owner/Author.",TestAnalysis
"The narrative approach has developed in various directions—philosophy, qualitative analysis, therapy, pedagogy, and research methodology—but these various directions are often isolated from each other. This article weaves together these five threads of narrative in order to suggest a novel way for how narrative can be used in the classroom. This is done through narratively expressed action research (Jean Clandinin) on the experiences of the author, a university teacher in Japan, and his attempts to incorporate narrative elements into career education classes. This article begins with its theoretical foundations, the narrative philosophy of education of Mori Akira, and how it was applied to pedagogically support the growth of self-awareness S1 (social identity) in a university orientation class. It then explores the design principles of this class, drawing from Dan P. McAdams’s narrative analysis and modified using narrative therapy (Michael White & David Epston). Next, it narrates the teacher’s experience of reading and responding to students’ narratives in two parts: the first five sessions where students write autobiographical exercises (looking at the “authored self”) and the last two sessions where students reflect on the texts they have written (highlighting the “authoring self”). I conclude with several design principles that seek to weave together narrative pedagogy, analysis, and therapy. © 2021, The Author(s), under exclusive licence to Springer Nature Switzerland AG part of Springer Nature.",TestAnalysis
"Purpose: Nowadays, the breakout of the COVID-19 pandemic has caused an important change in teaching models. The emotional experience of this change has an important impact on online teaching. This paper aims to explore its time evolution characteristics and provide reference for the development of online teaching in the post epidemic era. Design/methodology/approach: The article firstly crawls the online teaching-related comment text data on Zhihu platform and performs emotional calculation to obtain a one-dimensional time series of daily average emotional values. Then, by using non-linear time-series analysis, this paper reconstructs the daily average emotion value time series in high-dimensional phase space, calculates the maximum Lyapunov exponent and correlation dimension and finally, explores the feature patterns through recurrence plot and recurrence quantification analysis. Findings: It was found that the sequence has typical non-linear chaotic characteristics; its correlation dimension indicates that it contains obvious fractal characteristics; the public emotional evolution shows a cyclical rise and fall. By text mining and temporal evolution analysis, this paper explores the evolution law over chronically of the daily average emotion value time series, provides feasible strategies to improve students' online learning experience and quality and continuously optimizes this new teaching model in the era of pandemic. Originality/value: Based on social knowledge sharing platform of Q&A, this paper models and analyzes users interaction data under online teaching-related topics. This paper explores the evolution law over a long time period of the daily average emotion value time series using text mining and temporal evolution analysis. It then offers workable solutions to enhance the quality and experience of students' online learning, and it continuously improves this new teaching model in the age of pandemics. © 2022, Emerald Publishing Limited.",TestAnalysis
"Video captioning aims at automatically generating a natural language caption to describe the content of a video. However, most of the existing methods in the video captioning task ignore the relationship between objects in the video and the correlation between multimodal features, and they also ignore the effect of caption length on the task. This study proposes a novel video captioning framework (ORMF) based on the object relation graph and multimodal feature fusion. ORMF uses the similarity and Spatio-temporal relationship of objects in video to construct object relation features graph and introduce graph convolution network (GCN) to encode the object relation. At the same time, ORMF also constructs a multimodal features fusion network to learn the relationship between different modal features. The multimodal feature fusion network is used to fuse the features of different modals. Furthermore, the proposed model calculates the length loss of the caption, making the caption get richer information. The experimental results on two public datasets (Microsoft video captioning corpus [MSVD] and Microsoft research-video to text [MSR-VTT]) demonstrate the effectiveness of our method. © 2022 The Authors. CAAI Transactions on Intelligence Technology published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology and Chongqing University of Technology.",TestAnalysis
"Fatal Fetal Anomaly (FFA) has generated international media attention as termination of pregnancy (TOP) for FFA was legislated for, for the first time in Ireland. Media offers an insight into what health-related information is available to the public and how it is presented to them. The aim of this study was to examine how information related to FFA, TOP for FFA and perinatal palliative care (PPC) were framed in Irish published media. A critical discourse analysis, which examines the relations between discourse and social and cultural phenomena was implemented. Habermasian’s framework facilitated an objective analysis of the text, to facilitate interpretation and understanding of socially produced meanings. A broadsheet and journal were chosen. Dated from 2012 to 2017, 129 articles were identified. Themes of personification of the unborn, human rights and power and politics were embedded in the discourse, creating political influence to sway perceptions and views. Terminology were chosen by different ideological perspectives to create varying contexts and support arguments. PPC was suppressed within the published media. This study highlights misrepresentations in the information delivered to the public and suggests the need for healthcare professionals to expand their media literacy and develop these skills with their patients. © The Author(s) 2021.",TestAnalysis
"Objectives: To explore the characteristics of functional dysphonia (FD) using multimodal methods. Methods: A total of 47 FD patients and a group of 22 normal controls were enrolled. Subjective auditory-perceptual assessment of the voice, Voice Handicap Index (VHI) 30, acoustic analysis, psychological scales assessment, surface electromyography (sEMG), nasal airflow and thoracoabdominal studies were performed. Results: FD was mostly triggered by mood changes. Patient self-evaluation was more serious than auditory-perceptual evaluation and objective acoustic analysis. There was no obvious organic disorder observed under laryngoscope in patients with FD, but there were cases of glottic insufficiency and supraglottic compensation. With regards to sEMG, nasal airflow, chest, and abdomen examination results: (1) sEMG in the normal control group was symmetrical and stable on both sides during rest and phonation, and nasal airflow as well as the chest and abdomen were symmetrical and regular; (2) sEMG in the FD group showed increased recruitment of the sternocleidomastoid muscles, the infra- and suprahyoid muscles, and the cricothyroid muscle, accompanied by prephonation recruitment and postphonation persistence, mainly involving the infra- and suprahyoid muscles; (3) In the FD group, there was shortened inspiratory time, increased chest breathing amplitude, and reduced abdominal breathing, with predominantly chest breathing, and a “breath-holding” phenomenon was observed in some patients, with a significant increase in the number of breaths during the short text task. Conclusions: FD occurs mainly in middle-aged women, and there are many triggers. The Hamilton Anxiety/Depression Rating Scale scores were higher, and subjective symptoms were more serious than objective evaluation. No obvious organic changes were seen under laryngoscope, and features such as supraglottic compensation and glottic insufficiency were observed; muscle tension was significantly higher than that of the normal control group, and prephonation recruitment and postphonatory persistence were seen in some patients; the breathing pattern was mainly chest breathing, and the times of breaths during the short text task significantly increased. With identification of the characteristics of FD, the therapy could be focused them. © 2020 The Voice Foundation",TestAnalysis
"Western European politics has experienced considerable change since the 1980s, with the emergence of new parties and immigration’s politicisation. However, no studies have examined Green party discussions of immigration, or their interaction with radical right parties. We hypothesise that increases in the radical right’s vote share, and the saliency they attach to immigration, will incentivise Greens to discuss immigration more. We also examine an alternative explanation that how salient immigration is for left- and right-wing parties will affect immigration’s saliency for Greens. We test this by applying structural topic models to parliamentary speeches in the Dutch Tweede Kamer for 2002–2019. We find that Greens react to the radical right, as the latter’s vote share is positively associated with immigration’s saliency for Greens, although radical right immigration saliency’s effect is not robust. Furthermore, we do not find evidence that Greens react to immigration’s saliency in left- or right-wing party speeches. © The Author(s) 2022.",TestAnalysis
"Consumers tend to attribute human-like traits to a country. Applying theories of country personality and integrated marketing communications, this study examines country personalities as reflected in the website content of government agencies across functions. Specifically, this study used LIWC-based textual analysis to explore the Big Five personality dimensions in the text of government websites. Four ministries of China and South Korea's government with public diplomacy responsibilities were identified: ministries of agriculture, education, tourism & culture, and foreign affairs. Text data on 24 government websites were collected for this study in 2018. Our findings show that countries are different in presenting personalities via the website content of government branches. South Korean government focuses on the branches of foreign affairs and tourism & culture in presenting personalities of agreeableness, extraversion, and conscientiousness. In contrast, the Chinese government focuses on the branches of education and tourism & culture in presenting an openness personality. The findings suggest that a consistent presentation of country personality across websites of different government branches may depend upon structural and cultural characteristics of governing. Homepages and inside pages serve different strategic purposes to create positive presentation of country personality. © 2021, The Author(s), under exclusive licence to Springer Nature Limited.",TestAnalysis
"Nowadays, there is an increasing interest in non-verbal means of written forms of interpersonal communication. It is explained by the fact that the informational component and the pragmatic potential of non-verbal means of communication are often much higher than those of verbal means. As a result, the researchers focus their studies on texts which structural organization contains, in addition to verbal code units, the means of other semiotic codes. Such texts are called creolized or polycode. Polycode texts are a distinctive feature of academic texts, and their interpretation poses certain difficulties for students. The purpose of this study is to analyze the structural components of academic polycode texts; to study the ways of organizing verbal and iconic components; to describe the functional characteristics of iconic elements; to establish the mechanisms of interaction between linguistic and paralinguistic means when creating a single semantic unity of a polycode text. The main research methods are analysis, synthesis, comparison and observation. The textbook for the training of professional engineers Cambridge English for Engineering written by M. Ibbotson is used as the empirical material. The authors come to the following conclusions: there are four types of academic polycode texts; each type has a different pragmatic potential of verbal and iconic parts; in some types, the information function is more prominent in the iconic component; the use of photographs as iconic means facilitates the process of text interpretation and scientific and technical data exchange.  © 2023 EDP Sciences. All rights reserved.",TestAnalysis
"With the deepening of the research of artificial intelligence theory, the research of pattern recognition has made further development, and the applicable fields have also been continuously expanded. Pattern recognition can be used in text and speech recognition, remote sensing nuclear medicine diagnosis. This article optimizes and analyzes intelligent manufacturing based on pattern recognition, and uses improved association rule data mining algorithms to improve it from many aspects, Association rules are not limited by the number of dependent variables and can discover associations between data in large databases. Data analysis is carried out based on factors in different production stages of intelligent manufacturing to demonstrate the feasibility of the improved algorithm of association rule data mining. The experimental simulation results show that the application of the improved pattern recognition model in this research has made the estimated value of the remanufactured product remanufactured to a maximum of 4.05, and the production effect has also been greatly improved, the floating range is between 6.13 and 7.90, and the overall evaluation can reach 9.06. The experimental results show that the effect of the improved pattern recognition model is greatly improved.  © 2012 IEEE.",TestAnalysis
"The authors regret to inform that there were some areas of textual overlap between the original article and another article published by the same author's group. Particularly, text from the Sections 3.1. XPS analysis, 3.4. Electrochemical corrosion behaviour and 4. Conclusions was reused from the article “Structural and electrochemical impedance spectroscopic studies on reactive magnetron sputtered titanium oxynitride (TiON) thin films” previously published by P. Padmavathy, R. Ananthakumar, B. Subramanian, C. Ravidhas and M. Jayachandran in the Journal of Applied Electrochemistry 41 (2011) 751–756 https://doi.org/10.1007/s10800-011-0294-z. In page 5015 of the article, Fig. 1 must be replaced by the following Fig. 1. The results and inferences of the original paper are in no way altered due to this inclusion. The authors would like to apologise for any inconvenience caused. © 2022 Elsevier B.V.",TestAnalysis
"Investment in human capital, along with natural resource management, is an important indicator of sustainable development. One of the areas of such investments is the creation of artificial intelligence systems that allow for the classification of texts. This paper analyzes the use of artificial intelligence systems for stylometric text analysis. On the basis of the algorithm of the convolutional artificial immune system, a system for stylometric analysis of texts was developed and implemented in software. In order to determine the possibility of using this system to determine the authorship of literary works, it was trained and tested. For this, the works of two authors were chosen: Leo Tolstoy and Fyodor Kryukov. This system demonstrated a high quality of text classification and a good speed of work and learning. So, to test the performance of the system, 11 works by Leo Tolstoy and 12 works by Fedor Kryukov were taken that were not used to train the system. All works of these authors were classified correctly. It should be noted that the artificial immune system algorithm can also be successfully used in other tasks requiring text classification.  © 2023 EDP Sciences. All rights reserved.",TestAnalysis
"Background In February 2020, Canada implemented plain packaging without any changes to the size and content of health warning labels (HWLs), which were last updated in 2012 (pictorial HWLs on 75% of the pack front and back). This pre-post evaluation study assessed the impact of plain packaging in Canada on: (1) pack appeal; (2) HWL effectiveness; and (3) support for plain packaging. Additionally, a quasi–experimental design was used to assess the Canadian results relative to two comparator countries: Australia, where plain packaging (with new larger HWLs) was implemented in 2012, and the United States (USA), where plain packaging has not been implemented and the same text warnings have appeared on cigarette packs since 1985. Methods Data are from adult smokers who participated in the 2018 and/or 2020 International Tobacco Control Smoking and Vaping Surveys in Canada (n=4600), Australia (n=1834) and the USA (n=3046). Online surveys were conducted before (February to July 2018) and after (February to June 2020) the implementation of plain packaging in Canada. Adjusted regression analyses were conducted on weighted data. Results Plain packaging was associated with a significant increase in the percentage of Canadian smokers who did not like the look of their cigarette pack (2018: 28.6% vs 2020: 44.7%, p<0.001), whereas no change in pack appeal was observed among smokers in Australia and the USA over the same period. Plain packaging was not associated with changes in HWL effectiveness in Canada. Support for plain packaging increased significantly among Canadian smokers (2018: 25.6% vs 2020: 33.7%, p<0.001). Conclusions Plain packaging in Canada substantially reduced pack appeal and increased support for the policy among adult smokers; however, there was no increase in the effectiveness of Canada’s 8-year-old HWLs. The impact of plain packaging on health warning effectiveness may depend on the design of the warnings and length of time since implementation. © Author(s) (or their employer(s)) 2023.",TestAnalysis
"The transition from visual programming to textual programming reveals a considerable increase in the overall complexity of programming, including a number of challenging issues. To support this transition and alleviate some of these challenges, so-called hybrid programming may be applied. This programming usually refers to the use of a single programming language in block- and text-based modalities within one computing environment. Research shows that the application of hybrid programming for a certain age group may positively contribute to the development of students' programming knowledge and skills as they proceed towards the exclusive use of text-based programming. However, teachers of programming may not be willing to do this, because of limited teaching hours, a demanding syllabus, lack of resources or for other reasons. By using a sample of 38 high school teachers of programming, this study examined teachers' opinions about applying hybrid programming in their teaching and analysed their preference for hybrid programming usage in terms of a number of background variables, such as type of school, teacher's experience and programming language used. The examination of these teachers' opinions revealed that although visual programming may be used as a scaffolding support for textual programming, the opponents of hybrid programming usage did not (realize and) acknowledge this aspect of visual programming. On the other hand, the proponents of hybrid programming usage did mention several affordances related to this aspect, but they had rarely examined them in terms of the particular challenges of the transition in question. The analysis showed that hybrid programming usage was influenced by hybrid programming experience, the text-based programming languages applied and the country region. Suggestions for practice and research are included. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023. All rights reseverd.",TestAnalysis
"The original version of the article unfortunately contained mistakes. After further analysis of the data used in this article, the following items were found to have errors: 1) In body text, the appearance of ""p."" should be changed to ""pp."". 2) In Sect. 3, ""Problem 1"" should be changed to ""Problem I"". 3) In Sect. 3, there should be a space between (T) and x, on the first principle of Problem I. Lastly, 4) On page 4, the arrows for the formula (P ∨ ← ¬P, x⊨ ← ¬P, x⊨P∨ ← ¬P, ← ¬P) should be removed. The original article has been corrected. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.",TestAnalysis
"Objective: To evaluate scientific production on disabled persons with dental care needs over a 20-year period. Material and Methods: The search was conducted in the PubMed database using the MeSH terms “Disabled Persons” AND “Dentistry”. Three researchers selected articles based on readings of the title, abstract and full text. The articles were categorized according to periodical, country, study design, subject and classification of comorbidities and associated disorders. Three hundred ninety-seven articles published in 140 periodicals were included. Results: The periodicals Special Care in Dentistry (54), Dental Clinics of North America (14) and British Dental Journal (14) accounted for 21% of the publications. The studies were conducted in 50 countries, with the United States accounting for 33%. More than half (52%) of the studies had a cross-sectional design. The main subject addressed was oral diagnosis and most of the comorbidities were generalized disabilities. Conclusion: Although a large number of the periodicals have contributed to knowledge building on disabled persons with dental care needs, the number of articles is small compared to other fields of dentistry. Moreover, important gaps in knowledge persist and projects with better methodological designs are needed to offer a more substantial contribution to clinical practice. © 2023, Association of Support to Oral Health Research (APESB). All rights reserved.",TestAnalysis
"Biomedical argument mining aims to automatically identify and extract the argumentative structure in biomedical text. It helps to determine not only what positions people adopt, but also why they hold such opinions, which provides valuable insights into medical decision making. Generally, biomedical argument mining consists of three subtasks: argument component identification, argument component classification and relation identification. Current approaches employ conventional multi-task learning framework for jointly addressing the latter two subtasks, and achieve some success. However, explicit sequential dependency between these two subtasks is ignored, which is crucial for accurate biomedical argument mining. Moreover, relation identification is conducted solely based on the argument component pair without considering its potentially valuable context. Therefore, in this paper, a novel sequential multi-task learning approach is proposed for biomedical argument mining. Specifically, to model explicit sequential dependency between argument component classification and relation identification, an information transfer strategy is employed to capture the information of argument component type that is transferred to relation identification. Furthermore, graph convolutional network is employed to model dependency relation among the related argument component pairs. The proposed method has been evaluated on a benchmark dataset and the experimental results show that the proposed method outperforms the state-of-the-art methods.  © 2004-2012 IEEE.",TestAnalysis
"How do writers from regions with a historical experience of colonialism depict Western Orientalists in their work? What exactly does it mean to “reverse the gaze” and include the Orientalist within the frame of representation? The article considers the non-Western representation of Orientalists and Orientalism in literary texts from three different regions (Turkey, Mexico, and Bengal), concentrating in particular on Oguz Atay’s Tutunamayanlar (The Disconnected), Ignacio Padilla’s Antipodes, and Amitav Ghosh’s In an Antique Land, but also referring to a wide selection of other texts in the process. It suggests three categories of such representation — parodic, empathetic, and authoritative, in ascending order of sympathy — and proposes, in the analysis of the various fictitious representations of Orientalists examined, a central link between Orientalism and the sacred. Finally, the question of the ironic representation of Orientalists — the extent to which a redemptive irony is adopted by structures of power as a tool of self-preservation — is also considered. © The Author(s) 2020.",TestAnalysis
"The Editor-in-Chief and the publisher have retracted this article. The article was submitted to be part of a guest-edited issue. An investigation by the publisher found a number of articles, including this one, with a number of concerns, including but not limited to compromised editorial handling and peer review process, inappropriate or irrelevant references or not being in scope of the journal or guest-edited issue. Based on the investigation's findings the Editorin- Chief therefore no longer has confidence in the results and conclusions of this article. The author has not responded to correspondence regarding this retraction. The online version of this article contains the full text of the retracted article as Supplementary Information. © 2019 Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"For several years machine learning methods have been proposed for risk classification. While machine learning methods have also been used for failure diagnosis and condition monitoring, to the best of our knowledge, these methods have not been used for probabilistic risk assessment. Probabilistic risk assessment is a subjective process. The problem of how well machine learning methods can emulate expert judgments is challenging. Expert judgments are based on mental shortcuts, heuristics, which are susceptible to biases. This paper presents a process for developing natural language-based probabilistic risk assessment models, applying deep learning algorithms to emulate experts’ quantified risk estimates. This allows the risk analyst to obtain an a priori risk assessment when there is limited information in the form of text and numeric data. Universal sentence embedding (USE) with gradient boosting regression (GBR) trees trained over limited structured data presented the most promising results. When we apply these models’ outputs to generate survival distributions for autonomous systems’ likelihood of loss with distance, we observe that for open water and ice shelf operating environments, the differences between the survival distributions generated by the machine learning algorithm and those generated by the experts are not statistically significant. © 2022 The Authors. Risk Analysis published by Wiley Periodicals LLC on behalf of Society for Risk Analysis.",TestAnalysis
"Background: Delivered globally to promote adolescents’ sexual and reproductive health, comprehensive sex education (CSE) is rights-based, holistic, and seeks to enhance young people’s skills to foster respectful and healthy relationships. Previous research has demonstrated that CSE programmes that incorporate critical content on gender and power in relationships are more effective in achieving positive sexual and reproductive health outcomes than programmes without this content. However, it is not well understood how these programmes ultimately affect behavioural and biological outcomes. We therefore sought to investigate underlying mechanisms of impact and factors affecting implementation and undertook a systematic review of process evaluation studies reporting on school-based sex education programmes with a gender and power component. Methods: We searched six scientific databases in June 2019 and screened 9375 titles and abstracts and 261 full-text articles. Two distinct analyses and syntheses were conducted: a narrative review of implementation studies and a thematic synthesis of qualitative studies that examined programme characteristics and mechanisms of impact. Results: Nineteen articles met the inclusion criteria of which eleven were implementation studies. These studies highlighted the critical role of the skill and training of the facilitator, flexibility to adapt programmes to students’ needs, and a supportive school/community environment in which to deliver CSE to aid successful implementation. In the second set of studies (n = 8), student participation, student-facilitator relationship-building, and open discussions integrating student reflection and experience-sharing with critical content on gender and power were identified as important programme characteristics. These were linked to empowerment, transformation of gender norms, and meaningful contextualisation of students’ experiences as underlying mechanisms of impact. Conclusion and policy implications: Our findings emphasise the need for CSE programming addressing gender and power that engages students in a meaningful, relatable manner. Our findings can inform theories of change and intervention development for such programmes. © 2021, The Author(s).",TestAnalysis
"Background: The COVID-19 pandemic has affected the care of many cancer patients in a variety of ways. This study was conducted to understand the experience cancer patients have had during the pandemic. Method: Cancer patients who were under the care of the Trust between September 2020 – January 2021 were invited to take part in a survey sent through as a text message. Results: A total of 600 patients were sent a text message with a link to an online survey. There were 82 patients who responded. The data has been divided into three themes of information provision and safety around COVID-19, impact on cancer care and feeling supported by staff. Conclusion: It was encouraging to see that patients felt safe coming into the hospitals if it was required and they received appropriate information about changes to their care and how to protect themselves against COVID-19. Most patients stated that the pandemic had not influenced their cancer care. Of those that did experience delays most were understanding of this. There was a mixture of responses in terms of patients feeling supported by staff, most inpatients did feel supported and 75% of patients were able to contact their specialist nurse. © The Author(s) 2021.",TestAnalysis
"The cross-section area is a crucial parameter to assess peripheral neuropathy. The ultrasonographic evaluation of cross-section area of median nerve is a low-cost and readily available tool for diagnosis and assessment. However, the intra-nerve dimensional variability and its normative reference value in a healthy subject are missing. The current meta-analysis aims to capture the median nerve cross-section area for healthy subjects and generate a comprehensive ultrasonographic reference data set for each population. Methods: The full text of manuscripts were collected after short-listing the abstracts collected from search strategy. A quality assurance tool was used to capture the risk of bias of each study after reviewing the included manuscripts. The pooled estimate of cross-section area was stratified according to anatomical landmarks, sex, and ancestry. Results: A total of 97 observational studies dealt with 6679 wrists of healthy subjects were included. The pooled estimate of the cross-section area of median nerve at carpal tunnel inlet was 8.54 mm2 [95% CI: 8.34–8.74 mm2]. The same pooled estimate at carpal tunnel outlet was 8.03 mm2 [95% CI: 7.46–8.60 mm2]. Both these pooled estimates have significant correlation with mean age of population. Age and sex were two primary predictors of the cross-section of median nerve. The flattening ratio, circularity, and wrist-forearm ratio of median nerve were also computed. Conclusion: These normative data could serve as a reference for assessing median nerve pathologies, including carpal tunnel syndrome. The ethnic variation of pooled estimate and heterogeneity will guide clinician set up the reference value for diagnostic criteria. © 2022 Elsevier Masson SAS",TestAnalysis
"The Editor-in-Chief and the publisher have retracted this article. The article was submitted to be part of a guest-edited issue. An investigation by the publisher found a number of articles, including this one, with a number of concerns, including but not limited to compromised editorial handling and peer review process, inappropriate or irrelevant references or not being in scope of the journal or guest-edited issue. Based on the investigation's findings the Editorin- Chief therefore no longer has confidence in the results and conclusions of this article. The authors have not responded to correspondence regarding this retraction The online version of this article contains the full text of the retracted article as Supplementary Information. © Springer Science+Business Media, LLC, part of Springer Nature 2019.",TestAnalysis
"Owing to the rising needs of English language for communication at a global level, experts have stressed the significance of teaching English supported by materials based on communicative language teaching (CLT) principles to facilitate the development of communicative competence. This study, therefore, aims to evaluate ESL teaching materials to check their suitability to develop learners' communicative competence. The study, for this purpose, employs content analysis approach for the analysis of text of English designed for class two in the light of a checklist devised on CLT principles. The results reveal that the content of the said textbook does not conform to the CLT principles. Therefore, it is not suitable to facilitate the development of communicative competence in the learners. The study suggests either to improve/revise the textbook or to replace it by another suitable one. © 2023 by IGI Global. All rights reserved.",TestAnalysis
"Natural language processing (NLP) models are known vulnerable to adversarial examples, similar to image processing models. Studying adversarial texts is an essential step to improve the robustness of NLP models. However, existing studies mainly focus on generating adversarial texts for English, with no prior knowledge that whether those attacks could be applied to Chinese. After analyzing the differences between Chinese and English, we propose a novel adversarial Chinese text generation solution Argot, by utilizing the method for adversarial English examples and several novel methods developed on Chinese characteristics. Argot could effectively and efficiently generate adversarial Chinese texts with good readability in both white-box and black-box settings. Argot could also automatically generate targeted Chinese adversarial texts, achieving a high success rate and ensuring the readability of the generated texts. Furthermore, we apply Argot to the spam detection task in both local detection models and a public toxic content detection system from a well-known security company. Argot achieves a relatively high bypass success rate with fluent readability, which proves that the real-world toxic content detection system is vulnerable to adversarial example attacks. We also evaluate some available defense strategies, and the results indicate that Argot can still achieve high attack success rates.  © 2004-2012 IEEE.",TestAnalysis
"With the surge of COVID-19 pandemic, the world is moving towards digitization and automation more than it was presumed. The Internet is becoming one of the popular mediums for communication, and multimedia (image, audio, and video) combined with data compression techniques play a pivotal role in handling a huge volume of data that is being generated on a daily basis. Developing novel algorithms for automatic analysis of compressed data without decompression is the need of the present hour. JPEG is a popular compression algorithm supported in the digital electronics world that achieves compression by dividing the whole image into non-overlapping blocks of 8 × 8 pixels, and subsequently transforming each block using Discrete Cosine Transform (DCT). This research paper proposes to carry out Fast and Smooth Segmentation (FastSS) directly in JPEG compressed printed text document images at text-line and word-level using DC and AC signals. From each 8 × 8 block, DC and AC signals are analyzed for accomplishing Fast and Smooth segmentation, and subsequently, two Faster segmentation (MFastSS) algorithms are also devised using low resolution-images generated by mapping the DC signal (DC Reduced Image) and encoded DCT (ECM Image) coefficients separately. Proposed models are tested on various JPEG compressed printed text document images created with varied space and fonts. The experimental results have demonstrated that the direct analysis of compressed streams is computationally efficient, and has achieved speed gain more than 90% when compared to uncompressed domains. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"Objective This study, conducted in China, evaluated the effectiveness of four different themes of health warning labels (HWLs) that used both text and pictures: (1) self-harm from using cigarettes, (2) harming family or children with secondhand smoke, (3) reinforcing compliance with existing smoke-free policies and (4) anticigarette gift giving practices. Methods A cross-sectional randomised experimental survey was conducted among 3247 adult (aged 18+ years) participants in Beijing, Shanghai and Shenzhen in 2017, using quotas for age group, gender and smoking status. Participants were randomly assigned to one of the four HWL themes. Each participant viewed eight HWLs and rated how effective these themed-labels were in terms of credibility, raising awareness of health harms of smoking on family and children, improving compliance with public smoking bans, stopping the practice of gifting cigarettes, thinking about quitting and preventing smoking using a 10-point scale, with 10 being most effective. Analysis of variance and independent t-tests were used to analyse these data. Findings All four HWL themes performed well for each outcome with average ratings >6.5. Harming family or children with secondhand smoke was the theme that received the highest ratings for each outcome, with credibility (8.0, 95% CI 7.86 to 8.09) and prevention of smoking (8.8, 95% CI 8.63 to 8.91) outcomes being significantly higher (p<0.05). Overall, analysis of ratings by gender, income and education did not impact outcomes. Conclusion All four HWL themes tested could be effective in China; the theme of secondhand smoke harming family or children may be a particularly credible/ effective theme. © Author(s) (or their employer(s)) 2023.",TestAnalysis
"Purpose: Digital media has brought a revolution, making the world a global village. For people who are visually impaired and people with visual and hearing impairment, navigating through the digital world can be as precarious as moving through the real world. To enable them to connect with the digital world, we propose a solution, Haptic Encoded Language Framework (HELF), that uses haptic technology to enable them to write digital text using swiping gestures and understand the text through vibrations. Method: We developed an Android application to present the concept of HELF and evaluate its performance. We tested the application on 13 users (five visually impaired and eight sighted individuals). Results: The preliminary exploratory analysis of the proposed framework using the Android application developed reveals encouraging results. Overall, the reading accuracy has been found to be approximately 91%, and the average CPM is found to be 25.7. Conclusion: The volunteering users of the HELF Android application found it useful as a means of using the digital media and recommended its usage as an assistive technology for the visually challenged. The results of their performance of using the application motivate further research and development in the proposed work to make HELF more usable by people who are visually impaired and people with visual and hearing impairment. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TestAnalysis
"Thousands of new publications appear every day in bibliometric databases, so the demand for document retrieval technology is growing. Bibliometrics makes it possible to perform a quantitative analysis of text publications; however, the problem of classifying complex videos with a high level of semantics remains unsolved. Meanwhile, short-form videos gain popularity and attract more researchers. Knowledge Graph seems to be a promising technology in this area. This technology makes it possible to modernize the information search infrastructure. The experiment involved 461 short-video studies. The material for the experiment was collected from the Chinese Social Sciences Citation Index (CSSCI) database. The bibliometric method was recognized as expedient for the analysis. The keyword mapping and clustering operations were performed using the CiteSpace software. The results demonstrate that short-form video research has been popular among Chinese scientists since 2017. Short-form video research focuses on five major topics, that is, development trends, modern media convergence, video production, visual content management, and short-form videos in the public sector. The present findings may be employed in future research to collect relevant samples with exact semantic relationships. The technology is not limited to specific applications and, therefore, may be useful in any field of research. © The Author(s) 2021.",TestAnalysis
"Purpose: Most educational assessments tend to be constructed in a close-ended format, which is easier to score consistently and more affordable. However, recent work has leveraged computation text methods from the information sciences to make open-ended measurement more effective and reliable for older students. The purpose of this study is to determine whether models used by computational text mining applications need to be adapted when used with samples of elementary-aged children. Design/methodology/approach: This study introduces domain-adapted semantic models for child-specific text analysis, to allow better elementary-aged educational assessment. A corpus compiled from a multimodal mix of spoken and written child-directed sources is presented, used to train a children’s language model and evaluated against standard non-age-specific semantic models. Findings: Child-oriented language is found to differ in vocabulary and word sense use from general English, while exhibiting lower gender and race biases. The model is evaluated in an educational application of divergent thinking measurement and shown to improve on generalized English models. Research limitations/implications: The findings demonstrate the need for age-specific language models in the growing domain of automated divergent thinking and strongly encourage the same for other educational uses of computation text analysis by showing a measurable difference in the language of children. Social implications: Understanding children’s language more representatively in automated educational assessment allows for more fair and equitable testing. Furthermore, child-specific language models have fewer gender and race biases. Originality/value: Research in computational measurement of open-ended responses has thus far used models of language trained on general English sources or domain-specific sources such as textbooks. To the best of the authors’ knowledge, this paper is the first to study age-specific language models for educational assessment. In addition, while there have been several targeted, high-quality corpora of child-created or child-directed speech, the corpus presented here is the first developed with the breadth and scale required for large-scale text modeling. © 2022, Emerald Publishing Limited.",TestAnalysis
"This article analyses the parallel representations of enemy warrior women as sexually profligate and inappropriately martial in selected Latin and Arabic texts from the period of the first three crusades (late eleventh to late twelfth centuries). Cross-cultural comparison of depictions of fighting women demonstrates that both cultures portrayed the other side as dominated, and thus undermined, by women who were unnaturally assertive in both sexual and military affairs. Both Muslim and Christian authors sexualised and militarised the bodies of enemy women in order to define which men were the strongest, best and most deserving of battlefield victory in the holy wars of crusade and jihad. © 2021 John Wiley & Sons Ltd.",TestAnalysis
"Objective To describe and synthesise studies of SARS-CoV-2 seroprevalence by occupation prior to the widespread vaccine roll-out. Methods We identified studies of occupational seroprevalence from a living systematic review (PROSPERO CRD42020183634). Electronic databases, grey literature and news media were searched for studies published during January-December 2020. Seroprevalence estimates and a free-text description of the occupation were extracted and classified according to the Standard Occupational Classification (SOC) 2010 system using a machine-learning algorithm. Due to heterogeneity, results were synthesised narratively. Results We identified 196 studies including 591 940 participants from 38 countries. Most studies (n=162; 83%) were conducted locally versus regionally or nationally. Sample sizes were generally small (median=220 participants per occupation) and 135 studies (69%) were at a high risk of bias. One or more estimates were available for 21/23 major SOC occupation groups, but over half of the estimates identified (n=359/600) were for healthcare-related occupations. â € Personal Care and Service Occupations' (median 22% (IQR 9-28%); n=14) had the highest median seroprevalence. Conclusions Many seroprevalence studies covering a broad range of occupations were published in the first year of the pandemic. Results suggest considerable differences in seroprevalence between occupations, although few large, high-quality studies were done. Well-designed studies are required to improve our understanding of the occupational risk of SARS-CoV-2 and should be considered as an element of pandemic preparedness for future respiratory pathogens.  © World Health Organization 2023. Licensee BMJ.",TestAnalysis
"Objective: Depression and anxiety cause a high burden of disease and have high relapse rates (39%-72%). This meta-analysis systematically examined effectiveness of relapse prevention strategies on risk of and time to relapse in youth who remitted. Method: PubMed, PsycInfo, Embase, Cochrane, and ERIC databases were searched up to June 15, 2021. Eligible studies compared relapse prevention strategies to control conditions among youth (mean age 13-25 years) who were previously depressed or anxious or with ≥30% improvement in symptoms. Two reviewers independently assessed titles, abstracts, and full texts; extracted study data; and assessed risk of bias and overall strength of evidence. Random-effects models were used to pool results, and mixed-effects models were used for subgroup analyses. Main outcome was relapse rate at last follow-up (PROSPERO ID: CRD42020149326). Results: Of 10 randomized controlled trials (RCTs) that examined depression, 9 were eligible for analysis: 4 included psychological interventions (n = 370), 3 included antidepressants (n = 80), and 2 included combinations (n = 132). No RCTs for anxiety were identified. Over 6 to 75 months, relapse was half as likely following psychological treatment compared with care as usual conditions (k = 6; odds ratio 0.56, 95% CI 0.31 to 1.00). Sensitivity analyses including only studies with ≥50 participants (k = 3), showed similar results. Over 6 to 12 months, relapse was less likely in youth receiving antidepressants compared with youth receiving pill placebo (k = 3; OR 0.29, 95% CI 0.10 to 0.82). Quality of studies was suboptimal. Conclusion: Relapse prevention strategies for youth depression reduce risk of relapse, although adequately powered, high-quality RCTs are needed. This finding, together with the lack of RCTs on anxiety, underscores the need to examine relapse prevention in youth facing these common mental health conditions. © 2022 American Academy of Child and Adolescent Psychiatry",TestAnalysis
"This book explores the response to a new scientific advance in medicine three hundred years ago to understand how this discourse revealed religious, racial, anti-intellectual, and other ideologies the first time documented vaccinations were introduced in America. This text serves as a case study that examines the historic discourses surrounding the implementation of a new prevention technique, smallpox inoculation, to prevent the devastating epidemics of smallpox that had visited the new colonies since their start on the American continent. Using this detailed analysis of the arguments surrounding the project in early America, the author examines the various arguments that circulated in the 1720s regarding the project. When compared to today's pandemic, this study argues that Americans over-react and complicate scientific applications not with logical scientific perspectives or even with ethical views, but instead bring exaggerated claims founded on uniquely American historical, religious, racial, territorial, and political ideologies. America's First Vaccination will be of interest to anyone interested in American history, the history of medicine, cultural studies, and a comparison to current pandemic events. © 2023 Barbara Heifferon. All rights reserved.",TestAnalysis
"Statement of problem: Evidence for the efficacy and safety of natural products for the treatment of denture stomatitis is lacking. Purpose: The purpose of this systematic review was to answer the question “Are topical natural substances effective and safe compared with conventional antifungals in the treatment of denture stomatitis?” Material and methods: A structured search in 11 databases, including non-peer-reviewed, was undertaken. Two authors independently selected the studies, extracted the data, assessed the study quality, and graded the evidence, with disagreement resolved with a third reviewer. Data were evaluated descriptively by following Synthesis Without Meta-analysis (SWiM) reporting items. This study was registered at the International Prospective Register of Systematic Reviews (PROSPERO), number CRD42020216213. Results: After the removal of duplicates, 1925 records remained, and after a 2-phase reading of abstracts and full texts, 17 studies were included. Propolis, green tea, ginger, Zataria multiflora, chitosan, garlic, Artemisia, Schinus terebinthifolius Raddi, Uncaria tomentosa, Punica granatum, and Ricinus communis appeared to have similar efficacy and safety when compared with nystatin or miconazole. Most of the studies presented a high risk of bias. Conclusions: Certainty in the body of evidence that natural products might be appropriately used in the treatment of denture stomatitis is low. Well-designed randomized controlled trials are still needed to evaluate the topic better because there is high heterogeneity among the studies. © 2021 Editorial Council for the Journal of Prosthetic Dentistry",TestAnalysis
"Objective: The main objective of this review was to map the literature on the characteristics of patient navigation programs for people with dementia, their caregivers, and members of the care team across all settings. The secondary objective was to map the literature on the barriers and facilitators for implementing and delivering such patient navigation programs. Introduction: People with dementia have individualized needs that change according to the stage of their condition. They often face fragmented and uncoordinated care when seeking support to address these needs. Patient navigation may be one way to help people with dementia access better care. Patient navigation is a model of care that aims to guide people through the health care system, matching their unmet needs to appropriate resources, services, and programs. Organizing the available information on this topic will present a clearer picture of how patient navigation programs work. Inclusion criteria: This review focused on the characteristics of patient navigation programs for people living with dementia, their caregivers, and the members of the care team. It excluded programs not explicitly focused on dementia. It included patient navigation across all settings, delivered in all formats, and administered by all types of navigators if the programs aligned with this review's definition of patient navigation. This review excluded case management programs. Methods: This review was conducted in accordance with JBI methodology for scoping reviews. MEDLINE, CINAHL, APA PsycINFO, Embase, and ProQuest Nursing and Allied Health databases were searched for published full-text articles. A gray literature search was also conducted. Two independent reviewers screened articles for relevance against the inclusion criteria. The results are presented in a Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) flow diagram, and the extracted data are presented narratively and in tabular format. Results: Thirty-nine articles describing 20 programs were included in this review. The majority of these articles were published between 2015 and 2020, and based out of the United States. The types of sources included randomized controlled trials, quasi-experimental studies, and qualitative exploratory studies, among others. All programs provided some form of referral or linkage to other services or resources. Most dementia navigation programs included an interdisciplinary team, and most programs were community-based. There was no consistent patient navigator title or standard delivery method. Commonly reported barriers to implementing and delivering these programs were navigator burnout and a lack of coordination between stakeholders. Commonly reported facilitators were collaboration, communication, and formal partnerships between key stakeholders, as well as accessible and flexible program delivery models. Conclusions: This review demonstrates variety and flexibility in the types of services patient navigation programs provided, as well as in the modes of service delivery and in navigator title. This information may be useful for individuals and organizations looking to implement their own programs in the future. It also provides a framework for future systematic reviews that seek to evaluate the effectiveness or efficacy of dementia navigation programs. © 2023 The Author(s).",TestAnalysis
"Unsupervised domain adaptation (UDA) enables knowledge transfer from a labeled source domain to an unlabeled target domain by reducing the cross-domain distribution discrepancy, and the adversarial learning based paradigm has achieved remarkable success. On top of the derived domain-invariant feature representations, a promising stream of recent works seeks to further regularize the classification decision boundary via self-training to learn target adaptive classifier with pseudo-labeled target samples. However, since the pseudo labels are inevitably noisy, most of prior methods focus on manually designing elaborate target selection algorithms or optimization objectives to combat the negative effect caused by the incorrect pseudo labels. Different from them, in this paper, we propose a simple and powerful meta-learning based target-reweighting regularization algorithm, called MetaReg, which regularizes the model training by learning to reweight the noisy pseudo-labeled target samples. Specifically, MetaReg is motivated by the intuition that an ideal target classifier trained on correct target pseudo labels should make small classification errors on target-like source samples. Therefore, we explicitly define a meta reweighting problem that aims to find the optimal weights for different target pseudo labels by minimizing the classification loss on a designed validation set, a class-balanced set consisting of source samples that are most similar to target ones. Note that the optimization problem can be solved efficiently with a simplified approximation technique. As a result, the automatically learned optimal weights are utilized to reweight pseudo-labeled target samples, and regularize the model learning by target supervision with the learned different importance. Comprehensive experiments on several cross-domain image and text datasets verify that MetaReg could outperform the non-regularized UDA counterparts with state-of-the-art performance. Code is available at https://github.com/BIT-DA/MetaReg.  © 1989-2012 IEEE.",TestAnalysis
"The degree of Shakespeare's concern for a ""living theatre,"" capable of perpetually diversifying in order to maintain its appeal, is immediately apparent in the imaginative opening strategies employed in his plays. In an effort to illuminate them, this book studies the early printed texts for evidence of the opening lines of composition, as well as information supplied by Shakespeare for the actor to translate written word into stage action. This book contains a detailed introduction to its subject. Part One presents relevant ideas about openings in rhetorical and poetic theory from Aristotle to Julius Caesar Scaliger. In drawing on these ideas-and without making too strong a claim about direct or indirect influence-author Joel Benabu constructs a theoretical framework for Shakespeare's opening strategies. Part Two, comprising the main section of the book, explores different strategies for constructing an opening in the Shakespearean plays selected for analysis. The conclusion takes a broader perspective on the theory of Shakespeare's construction of openings explored throughout the book. © 2023 Joel Benabu. All rights reserved.",TestAnalysis
"This work is devoted to the processes of organizing internal information security at the enterprise. The scheme of a software tool for monitoring employee communication and detecting malicious messages using artificial neural network analysis and full-text dictionary search is proposed. A software package designed according to the described scheme has been developed. The scheme of interaction of the program components is considered: a keylogger, a keyboard input analyzer, a user interface, a server coordinating interaction. The schemes of interaction with the analyzer by means of the WebSocket protocol were shown. The interaction of the neural network and the dictionary helped to increase the percentage of accuracy of detecting a dangerous or suspicious message, for example, when the neural network does not consider the text dangerous, and the dictionary considers the opposite, then such text is considered dangerous and is shown to the administrator. Thus, the combination of neural network analysis and dictionary analysis makes it possible to detect more suspicious messages. The work of the software product and its advantages in comparison with other similar systems are demonstrated.  © 2023 EDP Sciences. All rights reserved.",TestAnalysis
"After more than 25 years of scholarship, the deliberative turn in international relations (IR) theory is ready to be revisited with a fresh perspective. Using new methods from automated text analyses, this explorative article investigates how rhetoric may bind action. It does so by building upon Schimmelfennig’s original account of rhetorical entrapment. To begin, I theorize the opposite of entrapment, which I call rhetorical hollowing. Rhetorical hollowing describes a situation in which actors use normative rhetoric, but instead of advancing their interests, such rhetoric fails to increase their chances of obtaining the desired outcome because the normative force of their rhetoric has eroded over time. To provide plausibility to both entrapment and hollowing, I present two mechanisms by which language is connected with action in the United Nations Security Council. Finally, I run a series of time-series-cross-section models on selected dictionary terms conducive to entrapment or hollowing on all speeches and an original Security Council resolution corpus from 1995 to 2017. The research shows that while mentioning ‘human rights’ is consistently associated with increased odds of authorization of force; the word ‘terrorism’ is associated with a decrease of odds for intervention. This finding suggests that some terms may not only entrap or hollow but also normatively backfire. © The Author(s) 2022.",TestAnalysis
"Swearing plays an ubiquitous role in everyday conversations among humans, both in oral and textual communication, and occurs frequently in social media texts, typically featured by informal language and spontaneous writing. Such occurrences can be linked to an abusive context, when they contribute to the expression of hatred and to the abusive effect, causing harm and offense. However, swearing is multifaceted and is often used in casual contexts, also with positive social functions. In this study, we explore the phenomenon of swearing in Twitter conversations, by automatically predicting the abusiveness of a swear word in a tweet as the main investigation perspective. We developed the Twitter English corpus SWAD (Swear Words Abusiveness Dataset), where abusive swearing is manually annotated at the word level. Our collection consists of 2577 instances in total from two phases of manual annotation. We developed models to automatically predict abusive swearing, to provide an intrinsic evaluation of SWAD and confirm the robustness of the resource. We model this prediction task as three different tasks, namely sequence labeling, text classification, and target-based swear word abusiveness prediction. We experimentally found that our intention to model the task similarly to aspect-based sentiment analysis leads to promising results. Subsequently, we employ the classifier to improve the prediction of abusive language in several standard benchmarks. The results of our experiments show that additional abusiveness feature of the swear words is able to improve the performance of abusive language detection models in several benchmark datasets. © 2022, The Author(s).",TestAnalysis
"Deep neural networks (DNNs) have achieved remarkable success in various tasks (e.g., image classification, speech recognition, and natural language processing (NLP)). However, researchers have demonstrated that DNN-based models are vulnerable to adversarial examples, which cause erroneous predictions by adding imperceptible perturbations into legitimate inputs. Recently, studies have revealed adversarial examples in the text domain, which could effectively evade various DNN-based text analyzers and further bring the threats of the proliferation of disinformation. In this paper, we give a comprehensive survey on the existing studies of adversarial techniques for generating adversarial texts written by both English and Chinese characters and the corresponding defense methods. More importantly, we hope that our work could inspire future studies to develop more robust DNN-based text analyzers against known and unknown adversarial techniques. We classify the existing adversarial techniques for crafting adversarial texts based on the perturbation units, helping to better understand the generation of adversarial texts and build robust models for defense. In presenting the taxonomy of adversarial attacks and defenses in the text domain, we introduce the adversarial techniques from the perspective of different NLP tasks. Finally, we discuss the existing challenges of adversarial attacks and defenses in texts and present the future research directions in this emerging and challenging field.  © 1989-2012 IEEE.",TestAnalysis
"The identity and institutional image of universities are presented to the world through their websites. On their websites, universities publish their academic offerings, their mission, their vision, their academic objectives, their achievements, their regulations, their news and all their university work. Hence, the importance of university websites is accessible. The accessibility of university websites has been evaluated several times in the past, but there is no work that has summarized all the evaluations performed to provide a general overview of the situation. Therefore, in this research we have performed a systematic literature review (SLR) to consolidate, analyze, synthesize and interpret the accessibility results of university websites published in 42 papers that have been selected for this study. The methodology used in this SLR was that proposed in Kitchenham’s guidelines, which includes three stages: planning the review, conducting the review and reporting the review. The results present the analysis and synthesis of the evaluations of 9,140 universities in 67 countries. Of these, 38,416 web pages, 91,421 YouTube videos and 28,395 PDF documents were evaluated. Manual methods, methods with automatic tools and the combination of both methods were used for the evaluation. Most websites were evaluated using the ISO/IEC 40500:2012 and Section 508 standards. The accessibility guidelines most commonly violated in the evaluations were: adaptable, compatible, distinguishable, input assistance, keyboard accessible, navigable, predictable, readable and text alternatives. In conclusion, the university websites, YouTube videos and PDF documents analyzed in the 42 papers present important accessibility problems. The main contribution of this SLR is the consolidation of the results of the 42 studies selected to determine the findings and trends in the accessibility of university websites around the world. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TestAnalysis
"Business closure is a critical stage in the lifecycle of any business. Despite a body of literature on the factors influencing business failure and/or success, studies on business closure prediction are next to none. Additionally, the identification of those factors has focused primarily on the managerial and economic dimensions rather than the consumer dimension. This research investigates the prediction of business closure from online consumer reviews, and validates the predictive models in the restaurant industry, which is subject to a relatively high attrition rate. Our proposed method for predicting business closure includes several novel artifacts, including integrating deep learning and time-series analysis techniques, extracting information embedded in online reviews using a hybrid classification method, and incorporating a novel triple word embedding model for text representation. The evaluation results of the proposed method using Yelp online reviews demonstrate its superior performance in business closure prediction, which indicate that online reviews provide strong signals for predicting business closure. We conduct another experiment with review data collected from TripAdvisors.com, and the experiment results are consistent, which provide evidence for the generalizability of the proposed method. The findings of this research have important managerial implications for business and investment decision making. © 1988-2012 IEEE.",TestAnalysis
"In patients with existing ovarian function, there are some special aspects to adjuvant endocrine therapy in premenopausal patients with hormone receptor-positive, HER2-negative (HR pos./HER2 neg.) breast cancer. Treatment options include tamoxifen with or without a GnRH analog, and aromatase inhibitors with a GnRH analog. Furthermore, ovarian function is affected by previous chemotherapy. Both aromatase inhibitors (+GnRH analogs) and GnRH analogs in combination with tamoxifen are supposed to be indicated for patients at increased risk of recurrence. However, national and international guidelines and therapy recommendations do not provide a clear definition of intermediate or high risk; as a result, therapy decisions are often made for each patient on an individual basis. This is also reflected in the considerable variability at national and international levels, e.g., with regard to the use of aromatase inhibitors + GnRH analogs. This review summarizes the data on completed studies (e.g., SOFT, TEXT, EBCTCG meta-analyses) and the current multigene testing studies (TailorX, RxPonder, ADAPT), discusses the rationale for current studies (e.g., CLEAR-B), and looks ahead to future questions. © 2023 Georg Thieme Verlag. All rights reserved.",TestAnalysis
"This article highlights the interpictorality in two YA books by the Swedish writer and illustrator Anna Höglund, Om detta talar man endast med kaniner [This Is Something You Only Talk About with Rabbits] (2013) and Att vara jag [To Be Me] (2015). The analysis of the visual intertextuality between pieces of artwork by Peter Tillberg, Frida Kahlo, Lena Cronqvist, Richard Bergh and René Magritte and five pictures from Höglund’s books thematises school, body and identity. The discursive positioning in the artworks and in Höglund’s pictures directs the readers in their decoding of Höglund’s text, offers possibilities in their interpretations and challenges the adolescent readers to make connections across different formats, such as text and image, and between different images. © 2021, The Author(s).",TestAnalysis
"Much of Cracking India’s scholarship focuses on how the text provides a representation of gendered trauma during Partition. These analyses, however, overlook the reader’s role, which minimizes literary works to analyzable objects rather than interactive opportunities. Following the work of postcolonial trauma scholars such as Steph Craps, Abigail Ward, and Jay Rajiva, I argue that postcolonial trauma narratives are crucial spaces of testimony in which the ongoing traumatic effects of colonialism intersect with reader engagement. Using Dori Laub’s trauma interview model, I examine how Bapsi Sidhwa uses the narrative techniques of perspective, time, and presence in Cracking India to implicate the reader as a witness in gendered postcolonial trauma affecting women. In pairing the examination of how narrative technique engages the reader as a witness with current scholarship on gender in Sidhwa’s novel, I show how such consideration of the reader speaks to how gendered violence contributes to postcolonial identity formation over time. © The Author(s) 2020.",TestAnalysis
"Objective: To assess for differences in surgical site infection (SSI) rates and bacterial load after major mucosal head and neck surgery between patients who received topical antimicrobial prophylaxis and those who did not. Data Sources: Ovid Medline, Embase, SCOPUS, Cochrane Library, and ClinicalTrials.gov from inception to May 20, 2021, with cross-referencing of retrieved studies per PRISMA guidelines. Review Methods: Inclusion criteria captured clinical trials, cohort studies, and case-control studies with infectious outcomes of adults who underwent major mucosal head and neck surgery and received perioperative topical antimicrobial therapy to the oral cavity and/or pharynx. Studies of dental procedures were excluded. The primary outcome was SSI rate, and the secondary outcome was bacterial load. Two blinded investigators screened each text. Results: Of 265 unique citations, 9 studies of 470 total patients were included. Topical treatments included numerous antibiotics and antiseptics directly applied over mucosa. Pooled SSI rates of 252 patients in the intervention cohort and 218 in the control cohort were 8% (95% CI, 3%-14%; I 2 = 61.2%) and 29% (95% CI, 16%-43%; I 2 = 79.5%), respectively. A meta-analysis of 7 comparative studies totaling 192 patients receiving topical therapy and 218 control patients revealed a pooled relative risk of 0.44 (95% CI, 0.28-0.68; I 2 = 0.0%) in favor of the treatment group. The studies demonstrated a short-term decrease in bacterial counts after topical antimicrobial prophylaxis. Conclusion: Patients who underwent prophylactic topical antimicrobial therapy had less than half the risk of developing SSI after mucosal head and neck surgery when compared with those who received no topical prophylaxis. © 2022 American Academy of Otolaryngology–Head and Neck Surgery Foundation.",TestAnalysis
"This study aimed to understand the role that parents play in sharing or limiting their child’s access to information about coronavirus disease 2019 (COVID-19). A subset of data from an international mixed methods online survey study was analysed to elucidate the findings from Brazil. An online survey, conducted between April and June 2020, gathered closed and open text views from parents of children aged 7–12 years old. Quantitative data were analysed using descriptive statistics. Qualitative open text data were analysed using the three stages of the Bardin content analysis framework: pre-analysis (data organisation and initial full-content reading); exploration of the material (thematic coding to identify major motifs and develop thematic categories) and interpretation (treating the data as significant and valid). The sample consisted of 112 (89%) mothers and 14 (11%) fathers. The analysis of the parents open text resulted in two categories: ‘How parents share information with their children about COVID-19’ and ‘How parents limit information to their children about COVID-19’. Some parents reported adopting an honest and open approach on how they shared information with their children, whilst some parents chose to minimise their child’s access to information about the pandemic over concerns of the mortality related to COVID-19. © The Author(s) 2021.",TestAnalysis
"The adoption and sustainability of evidence-based Tier 1 literacy practices in secondary content-area classes is important to improve reading success for students with learning disabilities. We conducted an exploratory multiple-case study investigating teachers’ adoption and sustained use of evidence-based Tier 1 literacy practices that benefit students with learning disabilities. The study was conducted within the context of an adolescent literacy model demonstration project funded by the U.S. Office of Special Education Programs (i.e., Promoting Adolescents’ Comprehension of Text [PACT] Plus). Interviews were conducted with two administrators and seven teachers who sustained implementation of the PACT practices beyond 1 year of researcher support. Analyses revealed practice and school-level factors that influenced teachers’ sustained use of the practices. We used findings from this study to propose a model of sustainability of Tier 1 evidence-based literacy practices used to improve outcomes for students with learning disabilities. Limitations and implications for future research are provided. © Hammill Institute on Disabilities 2022.",TestAnalysis
"The paper explores ways of increasing environmental awareness of students through incorporation of sustainability-related issues into a general English language course. We view language as a living system promoting life-sustaining relationships of humans with each other and with their natural environments. We hold the view that learning English as a foreign language holds powerful potential to promote the values of sustainable development, which should not be overlooked by English language teaching staff. The results of the study show that sustainability concerns are treated as discrete problems in textbooks and are often narrowed down to environmental issues, while social justice issues are left out of consideration. The percentage of units covering sustainability-related topics is considered unsatisfactory. According to the sentiment analysis conducted for textual material, the neutral sentiment is dominant, which can reduce the desired educational effect of sustainability-related texts. The author arrives at the conclusion that reconceptualization of the course framework is needed and presents practical suggestions aimed at developing a more holistic worldview and raising ecological awareness without fundamentally restructuring the whole textbook.  © 2023 EDP Sciences. All rights reserved.",TestAnalysis
"The paper develops a research approach that combines digital ethnography with text mining to explore consumers’ perception of a brand and the degree of alignment between brand identity and image. In particular, the paper investigates the alignment between the art museum’s brand identity and the brand image emerging from visitors’ narratives of their experience. The study adopts a mixed methodology based on netnography and text mining techniques. The analysis concerns an art museum’s brand, with the case of the “Opera del Duomo Museum” in Florence. The methodological approach enables a combined investigation of user-generated content in online communities and the company’s online brand communication, contributing to identifying branding actions that can be taken to increase the brand alignment. It also enables the measurement of the degree of alignment between museums and visitors among common brand themes. Specific indicators of alignment are provided. A key point is the replicability of the model in other contexts of analysis in which the content produced by consumers in online contexts are relevant and readily available, such as fashion or food. © 2022, The Author(s).",TestAnalysis
"With the rapid development of natural language processing techniques, the use of language models in text classification and sentiment analysis has been increasing. However, language models are susceptible to piracy and redistribution by adversaries, posing a serious threat to the intellectual property of model owners. Therefore, re-searchers have been working on designing protection mechanisms to identify the copyright information of language models. However, existing watermarking of language models for text classification tasks cannot be associated with the owner’s identity, and they are not robust enough and cannot regenerate trigger sets. To solve these problems, a new model, namely black-box watermarking scheme for text classification tasks, was proposed. It was a scheme that can remotely and quickly verify model ownership. The copyright message and the key of the model owner were obtained through the Hash-based Message Authentication Code (HMAC), and the message digest obtained by HMAC can prevent forgery and had high security. A certain amount of text data was randomly selected from each category of the original training set and the digest was combined with the text data to construct the trigger set, then the watermark was embedded on the language model during the training process. To evaluate the performance of the proposed scheme, watermarks were embedded on three common language models on the IMDB’s movie reviews and CNews text classification datasets. The experimental results show that the accuracy of the proposed watermarking verification scheme can reach 100% without affecting the original model. Even under common attacks such as model fine-tuning and prun-ing, the proposed watermarking scheme shows strong robustness and resistance to forgery attacks. Meanwhile, the embedding of the watermark does not affect the convergence time of the model and has high embedding efficiency. © 2023, Beijing Xintong Media Co., Ltd.. All rights reserved.",TestAnalysis
"Background: First metacarpal extension osteotomy (FMEO) aims to correct the adduction deformity associated with thumb arthritis, as well as improve the congruity at the first carpometacarpal (FCMC) joint. However, the benefits of this procedure are currently unclear. The purpose of this study is to investigate the outcomes of FMEO in the treatment of FCMC joint arthritis. Methods: Electronic databases were searched systematically for original data studies in the English language reporting outcomes following FMEO for base of thumb arthritis. Data were extracted from the text, tables, and figures of publications and meta-analyzed where possible. Results: Ten publications comprising 211 thumbs were included. FMEO was associated with an improvement in pain relief and patient-reported functional outcomes, however meta-analysis showed no significant long-term improvement in grip strength or lateral pinch grip. Although there was disease progression in one third of patients after FMEO, most did not require further procedures. Outcomes following secondary procedures was not analyzed in the literature. FMEO produced a range of minor complications, however, major complications were rare. Conclusions: The available evidence suggests FMEO does not improve grip or pinch strength. However, it may have a role in analgesia and improvement in functional outcomes. Further studies should compare outcomes of FMEO to continued nonoperative treatment, or other surgical options including arthroscopy or ligamentous reconstruction. © The Author(s) 2022.",TestAnalysis
"Relation classification (RC) task is one of fundamental tasks of information extraction, aiming to detect the relation information between entity pairs in unstructured natural language text and generate structured data in the form of entity-relation triple. Although distant supervision methods can effectively alleviate the problem of lack of training data in supervised learning, they also introduce noise into the data and still cannot fundamentally solve the long-tail distribution problem of the training instances. In order to enable the neural network to learn new knowledge through few instances such as humans, this work focuses on few-shot relation classification (FSRC), where a classifier should generalize to new classes that have not been seen in the training set, given only a number of samples for each class. To make full use of the existing information and get a better feature representation for each instance, we propose to encode each class prototype in an adaptive way from two aspects. First, based on the prototypical networks, we propose an adaptive mixture mechanism to add label words to the representation of the class prototype, which, to the best of our knowledge, is the first attempt to integrate the label information into features of the support samples of each class so as to get more interactive class prototypes. Second, to more reasonably measure the distances between samples of each category, we introduce a loss function for joint representation learning (JRL) to encode each support instance in an adaptive manner. Extensive experiments have been conducted on FewRel under different few-shot (FS) settings, and the results show that the proposed adaptive prototypical networks with label words and JRL has not only achieved significant improvements in accuracy but also increased the generalization ability of FSRC. © 2012 IEEE.",TestAnalysis
"How has the sentiment around the “responsibility to protect” (R2P) changed over time? Scholars have debated far and wide whether the political norm enjoys widespread discursive acceptance or is on the brink of decline. This article contends that we can use sentiment analysis as an important indicator for norm validity. My analysis provides three crucial insights. First, despite the well-known fear of some scholars, R2P is still frequently invoked in Security Council deliberations on issues of international peace and security. Second, overall levels of affirmative language have remained remarkably stable over time. This finding indicates that R2P is far from being obliterated. Out of 130 states, 4 international organizations (IOs), and 2 non-governmental organizations (NGOs) invoking the norm, 65% maintain a positive net-sentiment. Third, zooming into Libya as a case illustration of a critical juncture, we see some minor tonal shifts from some pivotal member states. Adding the fact that interest constellations within the Permanent Five are heterogeneous concerning the third pillar of R2P, future military interventions, sanctioned under the norm, seem unlikely. © The Author(s) 2022.",TestAnalysis
"To monitor students progress and adapt instruction to students needs, teachers increasingly use repeated assessments of equivalent tests. The present study investigates whether equivalent reading tests can be successfully developed via rule-based item design. Based on theoretical considerations, we identified 3-item features for reading comprehension at the word, sentence, and text levels, respectively, which should influence the difficulty and time intensity of reading processes. Using optimal design algorithms, a design matrix was calculated, and four equivalent test forms of the German reading test series for second graders (quop-L2) were developed. A total of N = 7,751 students completed the tests. We estimated item difficulty and time intensity parameters as well as person ability and speed parameters using bivariate item response theory (IRT) models, and we investigated the influence of item features on item parameters. Results indicate that all item properties significantly affected either item difficulty or response time. Moreover, as indicated by the IRT-based test information functions and analyses of variance, the four different test forms showed similar levels of difficulty and time-intensity at the word, sentence, and text levels (all n2 > .002). Results were successfully cross-validated using a sample of N = 5,654 students. © 2023 Hogrefe Publishing GmbH. All rights reserved.",TestAnalysis
"Background: The coronavirus disease 2019 (COVID-19) pandemic has led us to use virtual solutions and emerging technologies such as artificial intelligence (AI). Recent studies have clearly demonstrated the role of AI in health care and medical practice; however, a comprehensive review can identify potential yet not fulfilled functionalities of such technologies in pandemics. Therefore, this scoping review study aims at assessing AI functionalities in the COVID-19 pandemic in 2022. Methods: A systematic search was carried out in PubMed, Cochran Library, Scopus, Science Direct, ProQuest, and Web of Science from 2019 to May 9, 2022. Researchers selected the articles according to the search keywords. Finally, the articles mentioning the functionalities of AI in the COVID-19 pandemic were evaluated. Two investigators performed this process. Results: Initial search resulted in 9123 articles. After reviewing the title, abstract, and full text of these articles, and applying the inclusion and exclusion criteria, 4 articles were selectd for the final analysis. All 4 were cross-sectional studies. Two studies (50%) were performed in the United States, 1 (25%) in Israel, and 1 (25%) in Saudi Arabia. They covered the functionalities of AI in the prediction, detection, and diagnosis of COVID-19. Conclusions: To the extent of the researchers' knowledge, this study is the first scoping review that assesses the AI functionalities in the COVID-19 pandemic. Health-care organizations need decision support technologies and evidence-based apparatuses that can perceive, think, and reason not dissimilar to human beings. Potential functionalities of such technologies can be used to predict mortality, detect, screen, and trace current and former patients, analyze health data, prioritize high-risk patients, and better allocate hospital resources in pandemics, and generally in health-care settings.  © 2023 The Author(s). Published by Cambridge University Press on behalf of Society for Disaster Medicine and Public Health, Inc.",TestAnalysis
"Entity linking (EL) is the process of linking entity mentions appearing in web text with their corresponding entities in a knowledge base. EL plays an important role in the fields of knowledge engineering and data mining, underlying a variety of downstream applications such as knowledge base population, content analysis, relation extraction, and question answering. In recent years, deep learning (DL), which has achieved tremendous success in various domains, has also been leveraged in EL methods to surpass traditional machine learning based methods and yield the state-of-the-art performance. In this survey, we present a comprehensive review and analysis of existing DL based EL methods. First of all, we propose a new taxonomy, which organizes existing DL based EL methods using three axes: embedding, feature, and algorithm. Then we systematically survey the representative EL methods along the three axes of the taxonomy. Later, we introduce ten commonly used EL data sets and give a quantitative performance analysis of DL based EL methods over these data sets. Finally, we discuss the remaining limitations of existing methods and highlight some promising future directions.  © 1989-2012 IEEE.",TestAnalysis
"Introduction: Same-Sex Intimate Partner Violence (SSIPV) is a complex issue that can be severely damaging. When involved in SSIPV, victims and perpetrators sometimes choose to seek help. The help-seeking process, however, can be difficult. Experiences of help-seeking seem to vary and may be positive or negative depending on several factors, some of which appear to be specific to lesbian, gay, and bisexual (LGB) people involved in a same-sex relationship. Methods: A systematic review of the literature has been conducted across four databases following the PRISMA statement guidelines. Out of 410 screened abstracts, 78 articles were selected for full-text review. Following the inclusion and exclusion criteria, 21 studies were included in the current review. Thematic analysis was conducted on these studies and results were discussed by three reviewers. Results: Help-seekers tended to use informal sources of help, perceived to be ambivalently helpful. Formal sources tended to be utilized sparingly, except for counselors. Many formal sources were perceived to be unhelpful, and most of the studies identified several barriers to services that prevented effective help. Formal and helpful sources were perceived as knowledgeable and sensitive about LGB themes. Conclusions: While existing research is limited, formal services that can provide effective care for SSIPV appear scarce. Barriers to services seem widespread, limiting accessibility. Policy Implications: Existing services would benefit from increasing their knowledge and sensitivity on SSIPV-specific themes. The development of policies, programs, and interventions that aim to provide effective help is needed, as well as more research. © 2021, The Author(s).",TestAnalysis
"The study attempts to examine the complex universo of the global debate about environmental issues applying the models of linguistic analysis in order to extract semantic contents represented in the digital conversations of the Internet users. Computational linguistics allows recreating the semantic framework and contents of the online debate on the climate change applying the advances statistical mod-els. Therefore, we have chosen the timeline of the digital discourse of Twitter users referring to climate change in the context of Australia fires, Greta Thunberg and COP25 summit. © GKA Ediciones, authors.",TestAnalysis
"Automated recognition of Human Phenotype Ontology (HPO) terms from clinical texts is of significant interest to the field of clinical data mining. In this study, we develop a combined deep learning method named PhenoBERT for this purpose. PhenoBERT uses BERT, currently the state-of-The-Art NLP model, as its core model for evaluating whether a clinically relevant text segment (CTS) could be represented by an HPO term. However, to avoid unnecessary comparison of a CTS with each of ∼14,000 HPO terms using BERT, we introduce a two-levels CNN module consisting of a series of CNN models organized at two levels in PhenoBERT. For a given CTS, the CNN module produces only a short list of candidate HPO terms for BERT to evaluate, significantly improving the computational efficiency. In addition, BERT is able to assign an ancestor HPO term to a CTS when recognition of the direct HPO term is not successful, mimicking the process of HPO term assignment by human. In two benchmarks, PhenoBERT outperforms four traditional dictionary-based methods and two recently developed deep learning-based methods in two benchmark tests, and its advantage is more obvious when the recognition task is more challenging. As such, PhenoBERT is of great use for assisting in the mining of clinical text data.  © 2004-2012 IEEE.",TestAnalysis
"Although Hegel is increasingly recognized as an important figure in the history of political economy, his economic views are never strictly economic. In contrast to other modern thinkers, his primary concern is not the economic efficacy of different practices or institutions but the extent to which they enable and promote the development of human freedom. In this article, I argue that Hegel's pioneering critique of modern liberal economy plays out simultaneously at a more empirical level, corresponding to the properly economic dimension of his analysis, and at a deeper, logical level, which grounds and guides his position. Moreover, I argue that the tendency to favour the first of these levels, found in most of the literature on Hegel's economic thought, reduces the Philosophy of Right's main argument to a more or less vigorous plea for economic interventionism. Against this kind of reading, I show that a renewed focus on the text's logical structure reveals a different and more radical philosophical proposition, which has yet to be fully acknowledged. In particular, I argue that Hegel's dialectical logic leads him beyond the liberalism-interventionism debate, towards a qualitatively different conception of social and economic relations. © 2022 The Author. European Journal of Philosophy published by John Wiley & Sons Ltd.",TestAnalysis
"In this article, we address the questions: How is the purpose of higher education constructed within policy texts from the European Higher Education Area (EHEA), England and Sweden? How does this position students in making the transition from Bachelor to Masters? We do this through analysis of two recent policy documents from each of the EHEA, England and Sweden, identifying key discourses including the meanings, oppositions, contradictions and logics that structure the texts. We look at what aspects of ‘global policyspeak’ are common across them, what are their particularities and how these are shaped by distinct histories. We argue that all the texts represent neoliberal policies in sharing an economic rationale for higher education and in individualising the benefits of university education. Students are, in their transition from Bachelor to Masters, expected to maximise their employability and their ability to contribute to the national and global knowledge economy. However, there are also differences between the policy documents, tensions within them and alternative discourses, such as a focus on dialogue and academic freedom that challenge the reduction of higher education to the economic. © The Author(s) 2022.",TestAnalysis
"Compressed self-indexes are used widely in string processing applications, such as information retrieval, genome analysis, data mining, and web searching. The index not only indexes the data, but also encodes the data, and it is in compressed form. Moreover, the index and the data it encodes can be operated upon directly, without need to uncompress the entire index, thus saving time while maintaining small storage space. In some applications, such as in genome analysis, existing methods do not exploit the full possibilities of compressed self-indexes, and thus we seek faster and more space-efficient indexes. In this paper, we propose a practical high-order entropy-compressed self-index for efficient pattern matching in a text. We give practical implementations of compressed suffix arrays using a hybrid encoding in the representation of the neighbor function Φ. We analyze the performance in theory and practice of our recommended indexing method, called GeCSA. We can improve retrieval time further using an iterated version of the neighbor function. Experimental results on the tested data demonstrate that the proposed index GeCSA has good overall advantages in space usage and retrieval time over the state-of-the-art indexing methods, especially on the repetitive data.  © 1989-2012 IEEE.",TestAnalysis
"With the development of COVID-19 and technology, interest in metaverse has increased. Also, the market for metaverse, especially regarding children as major service users, is growing. However, related studies are lacking comparing the perceptions among major stakeholders, and there is also a lack of metaverse research on parents. The purpose of this study is to examine the comprehensive perception of child-related metaverse by text mining of news articles that could understand the discussions of service providers and parent communities that could understand the discussions of service users. Each of the nine topics were derived, and common and distinct issues were examined. This study provides policy and strategic implications for the child-related metaverse industry. © 2023 ACM.",TestAnalysis
"The current router security issues focus on the mining and utilization of memory-type vulnerabilities, but there is low interest in detecting backdoors. Hard-coded backdoor is one of the most common backdoors, which is simple and convenient to set up and can be implemented with only a small amount of code. However, it is difficult to be discovered and often causes serious safety hazard and economic loss. The triggering process of hard-coded backdoor is inseparable from string comparison functions. Therefore, the detection of hard-coded backdoors relies on string comparison functions, which are mainly divided into static analysis method and symbolic execution method. The former has a high degree of automation, but has a high false positive rate and poor detection results. The latter has a high accuracy rate, but cannot automate large-scale detection of firmware, and faces the problem of path explosion or even unable to constrain solution. Aiming at the above problems, a hard-coded backdoor detection algorithm based on string text semantic conflict (Stect) was proposed since static analysis and the think of stain analysis. Stect started from the commonly used string comparison functions, combined with the characteristics of MIPS and ARM architectures, and extracted a set of paths with the same start and end nodes using function call relationships, control flow graphs, and branching selection dependent strings. If the strings in the successfully verified set of paths have semantic conflict, it means that there is a hard-coded backdoor in the router firmware. In order to evaluate the detection effect of Stect, 1 074 collected device images were tested and compared with other backdoor detection methods. Experimental results show that Stect has a better detection effect compared with existing backdoor detection methods including Costin and Stringer: 8 hard-coded backdoor images detected from image data set, and the recall rate reached 88.89%. © 2023, Beijing Xintong Media Co., Ltd.. All rights reserved.",TestAnalysis
"The work of the French illustrator and writer Gilles Bachelet has been recognised through numerous awards, but he is not yet sufficiently well known in the critical community. In this article, the multilevel humour that constructs his work is studied, both from an iconic and a textual perspective, as well as the situational humour and the humour of characters that emerge through metafiction, self-referentiality and heteroreferentiality. For this purpose, the theories of humour in children’s literature and the classifications of types of humour offered by different researchers are used as a starting point, and a mixed model of analysis applicable to Bachelet’s work as a whole is proposed. In addition, the analysis of each of the picturebooks is based on the most recent studies on the components of the current picturebook, such as its narrative construction, type of reading, characteristics and organisation of text and image. In this way, the postmodern features of Gilles Bachelet's works, which make him a crossover author, are revealed. © 2021, The Author(s).",TestAnalysis
"Introduction: Spinal infusions of either fentanyl or sufentanil have been reported in international reports, articles, and scientific events worldwide. This study aimed to determine whether intrathecal fentanyl or sufentanil offers safety in mortality and perioperative adverse events. Methods: MEDLINE (via PubMed), EMBASE, CENTRAL (Cochrane library databases), gray literature, hand-searching, and clinicaltrials.gov were systematically searched. Randomized controlled trials with no language, data, or status restrictions were included, comparing the effectiveness and safety of adding spinal lipophilic opioid to local anesthetics (LAs). Data were pooled using the random-effects models or fixed-effect models based on heterogeneity. Results: The initial search retrieved 4469 records; 3241 records were eligible, and 3152 articles were excluded after reading titles and abstracts, with a high agreement rate (98.6%). After reading the full texts, 76 articles remained. Spinal fentanyl and sufentanil significantly reduced postoperative pain and opioid consumption, increased analgesia and pruritus. Fentanyl, but not sufentanil, significantly reduced both postoperative nausea and vomiting, and postoperative shivering; compared to LAs alone. The analyzed studies did not report any case of in-hospital mortality related to spinal lipophilic opioids. The rate of respiratory depression was 0.7% and 0.8% when spinal fentanyl or sufentanil was added and when it was not, respectively. Episodes of respiratory depression were rare, uneventful, occurred intraoperatively, and were easily manageable. Conclusion: There is moderate to high quality certainty that there is evidence regarding the safety and effectiveness of adding lipophilic opioids to LAs in spinal anesthesia. © 2021 Sociedade Brasileira de Anestesiologia",TestAnalysis
"Recent research has produced efficient algorithms based on deep learning for text-based analytics. Such architectures could be readily applied to text-based social media content analysis. The deep learning techniques, which require comparatively fewer resources for language modeling, can be effectively used to process social media content data that change regularly. Convolutional Neural networks and recurrent neural networks based approaches have reported prominent performance in this domain, yet their limitations make them sub-optimal. Capsule networks sufficiently warrant their applicability in language modelling tasks as a promising technique beyond their initial usage of image classification. This study proposes an approach based on capsule networks for social media content analysis, especially for Twitter. We empirically show that our approach is optimal even without the use of any linguistic resources. The proposed architectures produced an accuracy of 86.87% for the Twitter Sentiment Gold dataset and an accuracy of 82.04% for the CrowdFlower US Airline dataset, indicating state-of-the-art performance. Hence, the research findings indicate noteworthy accuracy enhancement for text processing within social media content analysis. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"To understand the audience's subjective perception of quality of service (QoS), it is important to analyze the data acquired from the logistics service logs and online evaluation system reasonably and effectively. Based on the analysis, rational improvement measures and decision suggestions can be developed to enhance the QoS. However, modern logistics service departments often face various business needs and service objects at the same time. If the evaluation subjects and their relationships are unclear in the service evaluation data, the sentiment analysis result of the text is a coarse-grained evaluation of the service as a whole. The lack of fine-grained pertinent evaluation results will hinder the improvement of specific management measures. To solve the problem, this paper designs an attention-based long short-term memory network (AT-LSTM) to divide the service reviews into ten topic relations, and then builds a deeper attention LSTM with aspect embedding (AE-DATT-LSTM). The weight-sharing bidirectional LSTM (BiLSTM) trains the topic word vectors and the text word vectors, and fuses the resulting topic features and text features. After the processing of the deep attention mechanism, the sentiment class of each evaluation topic is obtained by the classifier. Finally, several experiments were carried out on different public datasets. The results show that our approach surpasses the previous attention-based sentiment analysis models in accuracy and stability of service quality sentiment analysis. The introduction of topic features and deep attention mechanism is of great significance for the QoS-based sentiment classification b, and provides a feasible method for other fields like public opinion analysis, question answering system, and text reasoning. © 2023, Strojarski Facultet. All rights reserved.",TestAnalysis
"The true crime genre has become synonymous with the serial killer. As such, other narratives dealing with different types of violent criminal subjects have been overlooked in academic and media analyses. The following article explores a subgenre of true crime which has been overlooked—the life story of the violent criminal or “hardman biography.” However, in acknowledging the hardman, the discussion also reveals his presence across fact/fiction boundaries and a range of cultural terrain. Following a discussion of the cultural space this figure occupies, I turn my attention to hardman stories which exist predominantly in the local imaginary and focus on one such text which tells the story of a violent protagonist and cultures of crime and violence in the North of England in the late 1980s and early 1990s. In so doing, I focus on how this text animates cultures of violence and marginality left in the wake of deindustrialization and economic decline, combining this with relevant theoretical and ethnographic work. I conclude by arguing that the text is a further example of the way in which popular criminology can complement and advance academic criminological understandings of crime and violence. © The Author(s) 2021.",TestAnalysis
"Purpose: This study aims to investigate the drivers of successful equity crowdfunding campaigns in Malaysia. Design/methodology/approach: Data for this study are collected manually from 5 different equity crowdfunding platforms in Malaysia. A total of 101 campaigns are analyzed, out of which the final sample used for this study is 97. The relationships are analyzed via ordinary least squares multiple regression analysis. Findings: The results of the analysis show that minimum funding target, minimum investment required, pre-money valuation and length of pitch video are highly significant in influencing the success of the campaign. Percentage of equity retained is only significant at the 10% level. The size of the project team and the text length of the pitch are found to be insignificant. In addition, all the variables, except for equity retained and the minimum investment required, are found to have a positive impact on the success of an equity crowdfunding campaign in Malaysia. Originality/value: To the best of the authors’ knowledge, this is the first study that investigates the success factors of equity crowdfunding campaigns in a developing country such as Malaysia. In addition, this study contributes to the literature on equity crowdfunding success via the inclusion of less-studied variables such as pre-money valuation and minimum investment required. © 2021, Emerald Publishing Limited.",TestAnalysis
"Purpose: The ongoing impact of COVID-19 and the subsequent perception of threat have shifted consumer perceptions and evaluations of service experiences. This paper aims to investigate how customers’ service evaluation is shared as customer reviews following the pandemic and the heightened perception of threat. In doing so, this research particularly investigates the shifts in the textual contents of online reviews. Design/methodology/approach: This study used the textual contents in the online reviews posted on Hotels.com for 1,497 hotels in New York City for empirical analysis. In total, 109,190 observations were used for the analysis. Findings: By analyzing actual online review data from an online review platform for hotel services, this study finds that the text reviews generated after the pandemic outbreak tend to contain words with stronger negative emotions. In terms of the pronoun choice, this study further finds that the use of “I” increases while the use of “we” decreases. Originality/value: This research adds to the existing literature on service evaluation and online customer reviews by showing that there are shifts in the expressions used to communicate service evaluation through online text reviews, including the degree of emotionality and pronoun usage. Because potential customers are likely to rely on online reviews for their own decisions, the findings suggest that it is important for practitioners to be aware of such shifts and respond accordingly. © 2022, Emerald Publishing Limited.",TestAnalysis
"Introduction Asymmetric mandibular hypoplasia, microtia, tongue and laryngeal anomalies, and soft palate and facial nerve dysfunction are clinical features observed in children with craniofacial microsomia (CFM). Despite involvement of all these structures in hearing and speech, there is limited evidence reporting speech outcomes in this population. Systematic reviews of clinical and surgical interventions related to CFM have been published, but no methodological review of speech outcomes exists. This scoping review will summarise what is known about speech production in individuals with CFM as well as illustrate gaps in the existing body of literature that will guide future research. Methods/analysis This review will follow the methodological framework for scoping reviews first reported by Arksey & O'Malley and revised by Levac and others. Databases searched will include Ovid MEDLINE, EMBASE, CINAHL, PsycINFO and grey literature. Articles reporting any parameter of speech production in individuals with CFM will be considered for inclusion. Articles published in a language other than English will be excluded. Articles will be screened in three stages: (1) title review, (2) abstract review and (3) full text review. Ten per cent of articles will be rescreened by a second reviewer. Reference lists will be hand reviewed to identify additional relevant articles. Data charting will capture article metadata, study population and design, CFM diagnostic criteria, speech outcome measurement and key findings. The Preferred Reporting Systems for Systematic Reviews and Meta-Analyses Protocols-Extension for Scoping Reviews checklist will guide reporting of results. Descriptive analysis and data visualisation strategies will be used. Ethics and dissemination Institutional review board approval is not required for a scoping review, as it does not directly involve human subjects. Results will be disseminated through peer-reviewed publication as well as conference presentation.  © 2023 Author(s) (or their employer(s)). Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.",TestAnalysis
"The core difficulty of text-based person search is how to achieve fine-grained alignment of visual and linguistic modal data, so as to bridge the gap of modal heterogeneity. Most existing works on this task focus on global and local features extraction and matching, ignoring the importance of relational information. This paper proposes a new text-based person search model, named CM-LRGNet, which extracts Cross-Modal Local-Relational-Global features in an end-to-end manner, and performs fine-grained cross-modal alignment on the above three feature levels. Concretely, we first split the convolutional feature maps to obtain local features of images, and adaptively extract textual local features. Then a relation encoding module is proposed to implicitly learn the relational information implied in the images and texts. Finally, a relation-aware graph attention network is designed to fuse the local and relational features to generate global representations for both images and text queries. Extensive experimental results on benchmark dataset (CUHK-PEDES) show that our approach can achieve state-of-the-art performance (64.18%, 82.97%, 89.85% in terms of Top-1, Top-5, and Top-10 accuracies), by learning and aligning local-relational-global representations from different modalities. Our code has been released in https://github.com/zhangweifeng1218/Text-based-Person-Search. © 2023 Elsevier B.V.",TestAnalysis
"Introduction: Due to conflicts of national identity and religion, human rights legislation has been integral to Northern Ireland’s post-war journey. As a result of this, the post-conflict generation of girls, female adolescents, and non-heterosexual, queer-identifying peoples have more rights, opportunities, and recognition in educational policy than generations prior. However, government reports show issues within the country’s Relationships and Sexuality Education (RSE) curricula, including that only one in five Northern Irish schools have touched upon lesbian, gay, bisexual, and transgender (LGBT) topics. Methods: This paper presents the first feminist post-structuralist analysis focusing on gender and sexual inequalities within the current national policy framework (as of September 2021) informing school-based RSE. Applying feminist critical discourse and content analysis to examine official government circulars, legislative text, and RSE policy guidance distributed to schools, feminist lenses are drawn on to examine four main sets of issues: bodies, sexual agency and pleasure, the inclusion of gender and sexual diversity, and heteronormativity. Results: Findings show that despite human rights legislation and having statutory RSE with legislated content, central discourses within the national RSE policy framework impose a story of female victimization, problematize binary constructions of gender, participate in the erasure of non-binary identifying persons, and prioritize compulsory heteronormativity. Conclusions: Until inclusive, non-binary language and standardized content is prescribed within the minimum content found in legislation and deemed statutory by the Department of Education, young people will not receive uniform RSE, undermining the importance of gender and sexual inclusivity and diversity. Policy Implications: Discourses illuminated within this paper may be drawn on by international policy actors and researchers to elucidate taken-for-granted or problematic language found within their own policies so that the rights of marginalized bodies and sexual identities are instilled and those who have been victimized may find empowerment. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"Genetics is the clinical review of congenital mutation, where the principal advantage of analyzing genetic mutation of humans is the exploration, analysis, interpretation and description of the genetic transmitted and inherited effect of several diseases such as cancer, diabetes and heart diseases. Cancer is the most troublesome and disordered affliction as the proportion of cancer sufferers is growing massively. Identification and discrimination of the mutations that impart to the enlargement of tumor from the unbiased mutations is difficult, as majority tumors of cancer are able to exercise genetic mutations. The genetic mutations are systematized and categorized to sort the cancer by way of medical observations and considering clinical studies. At the present time, genetic mutations are being annotated and these interpretations are being accomplished either manually or using the existing primary algorithms. Evaluation and classification of each and every individual genetic mutation was basically predicated on evidence from documented content built on medical literature. Consequently, as a means to build genetic mutations, basically, depending on the clinical evidences persists a challenging task. There exist various algorithms such as one hot encoding technique is used to derive features from genes and their variations, TF-IDF is used to extract features from the clinical text data. In order to increase the accuracy of the classification, machine learning algorithms such as support vector machine, logistic regression, Naive Bayes, etc., are experimented. A stacking model classifier has been developed to increase the accuracy. The proposed stacking model classifier has obtained the log loss 0.8436 and 0.8572 for cross-validation data set and test data set, respectively. By the experimentation, it has been proved that the proposed stacking model classifier outperforms the existing algorithms in terms of log loss. Basically, minimum log loss refers to the efficient model. Here the log loss has been reduced to less than 1 by using the proposed stacking model classifier. The performance of these algorithms can be gauged on the basis of the various measures like multi-class log loss.  © 2023 World Scientific Publishing Company.",TestAnalysis
"This paper proposes a multi-modal approach for speech emotion recognition (SER) using both text and audio inputs. The audio embedding is extracted by using a vision-based architecture, namely VGGish, while the text embedding is extracted by using a transformer-based architecture, namely BERT. Then, these embeddings are fused using concatenation to recognize emotional states. To evaluate the effectiveness of the proposed method, the benchmark dataset, namely IEMOCAP, is employed in this study. Experimental results indicate that the proposed method is very competitive and better than most of the latest and state-of-the-art methods using multi-modal analysis for SER. The proposed method achieves 63.00% unweighted accuracy (UA) and 63.10% weighted accuracy (WA) on the IEMOCAP dataset. In the future, an extension of multi-task learning and multi-lingual approaches will be investigated to improve the performance and robustness of multi-modal SER. For reproducibility purposes, our code is publicly available. © 2023 ACM.",TestAnalysis
"Can International Monetary Fund (IMF) lending improve natural resource governance in borrowing countries? While most IMF agreements mandate policy reforms in exchange for financial support, compliance with these reforms is mixed at best. The natural resource sector should be no exception. After all, resource windfalls enable short-term increases in discretionary spending, and office-seeking politicians are often unwilling to forgo this discretion by reforming the oil, gas, or mining sector. I investigate how and when borrowers go against their political interests and establish natural resource funds—a tool often promoted by the IMF—in the wake of a loan agreement. Using text analysis, statistical models, and qualitative evidence from natural resource policy and IMF conditionality for 74 countries between 1980 and 2019, I show that borrowers under an IMF agreement are more likely to create or regulate a resource fund, particularly if the agreement includes binding conditions that highlight the salience of natural resource reforms. This study contributes to extant research by proposing a new method to extract information from IMF conditions, by introducing a novel dataset on country-level natural resource policy, and by identifying under what circumstances international reform efforts can help combat the resource curse. © 2022 The Authors. Economics & Politics published by John Wiley & Sons Ltd.",TestAnalysis
"Are conservatives more simple-minded and happier than liberals? To revisit this question, 1,518 demographically diverse participants (52% females) were recruited from an online participant-sourcing platform and asked to write a narrative about the upcoming 2020 U.S. Presidential Election as well as complete self and candidates’ ratings of personality. The narratives were analyzed using three well-validated text analysis programs. As expected, extremely enthusiastic Trump supporters used less cognitively complex and more confident language than both their less enthusiastic counterparts and Biden supporters. Trump supporters also used more positive affective language than Biden supporters. More simplistic and categorical modes of thinking as well as positive emotional tone were also associated with positive perceptions of Trump’s, but not Biden’s personality. Dialectical complexity and positive emotional tone accounted for significant unique variance in predicting appraisals of Trump’s trustworthiness/integrity even after controlling for demographic variables, self-ratings of conscientiousness and openness, and political affiliation. © The Author(s) 2022.",TestAnalysis
"In modern theoretical and applied mechanics, tensors and differential geometry are two almost essential tools. Unfortunately, in university courses for engineering and mechanics students, these topics are often poorly treated or even completely ignored. At the same time, many existing, very complete texts on tensors or differential geometry are so advanced and written in abstract language that discourage young readers looking for an introduction to these topics specifically oriented to engineering applications. This textbook, mainly addressed to graduate students and young researchers in mechanics, is an attempt to fill the gap. Its aim is to introduce the reader to the modern mathematical tools and language of tensors, with special applications to the differential geometry of curves and surfaces in the Euclidean space. The exposition of the matter is sober, directly oriented to problems that are ordinarily found in mechanics and engineering. Also, the language and symbols are tailored to those usually employed in modern texts of continuum mechanics. Though not exhaustive, as any primer textbook, this volume constitutes a coherent, self-contained introduction to the mathematical tools and results necessary in modern continuum mechanics, concerning vectors, 2nd- and 4th-rank tensors, curves, fields, curvilinear coordinates, and surfaces in the Euclidean space. More than 100 exercises are proposed to the reader, many of them complete the theoretical part through additional results and proofs. To accompany the reader in learning, all the exercises are entirely developed and solved at the end of the book. © 2023 by World Scientific Publishing Co. Pte. Ltd. All rights reserved.",TestAnalysis
"Scholars interested in substantive representation for women have primarily focused on whether women vote for and prioritize “women’s issue” legislation. It is now well established that female lawmakers do vote for and introduce bills on issues like reproductive rights, childcare, and women’s health at rates higher than men. With this finding widely accepted, scholars have more recently investigated levels of female involvement on a wider range of topics and find that women are just as active as men—sometimes even more active—on an array of policy topics other than “women’s issues.” Several studies show women are more active sponsors of defense-related bills than are their male colleagues. We provide a case study that investigates whether female lawmakers offer distinct perspectives on these topics. We use structural topic modeling to explore sex and party differences in floor speeches delivered in the House of Representatives. Our analysis of these floor speeches given in the 109th Congress reveals that women and men do focus their attention on distinct facets of defense issues—focusing on the implications of war for women, civilians, and communities—and that these differences are conditioned by party. © The Author(s) 2022.",TestAnalysis
"Objective: To evaluate the existing evidence of a machine learning-based classification system that stratifies patients with stroke. Methods: The authors carried out a systematic review following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) recommendations for a review article. PubMed, MEDLINE, Web of Science, and CINAHL Plus Full Text were searched from January 2015 to February 2021. Results: There are twelve studies included in this systematic review. Fifteen algorithms were used in the included studies. The most common forms of machine learning (ML) used to classify stroke patients were the support vector machine (SVM) (n = 8 studies), followed by random forest (RF) (n = 7 studies), decision tree (DT) (n = 4 studies), gradient boosting (GB) (n = 4 studies), neural networks (NNs) (n = 3 studies), deep learning (n = 2 studies), and k-nearest neighbor (k-NN) (n = 2 studies), respectively. Forty-four features of inputs were used in the included studies, and age and gender are the most common features in the ML model. Discussion: There is no single algorithm that performed better or worse than all others at classifying patients with stroke, in part because different input data require different algorithms to achieve optimal outcomes. © The Author(s) 2021.",TestAnalysis
"Efficient recognition of emotions has attracted extensive research interest, which makes new applications in many fields possible, such as human-computer interaction, disease diagnosis, service robots, and so forth. Although existing work on sentiment analysis relying on sensors or unimodal methods performs well for simple contexts like business recommendation and facial expression recognition, it does far below expectations for complex scenes, such as sarcasm, disdain, and metaphors. In this article, we propose a novel two-stage multimodal learning framework, called AMSA, to adaptively learn correlation and complementarity between modalities for dynamic fusion, achieving more stable and precise sentiment analysis results. Specifically, a multiscale attention model with a slice positioning scheme is proposed to get stable quintuplets of sentiment in images, texts, and speeches in the first stage. Then a Transformer-based self-adaptive network is proposed to assign weights flexibly for multimodal fusion in the second stage and update the parameters of the loss function through compensation iteration. To quickly locate key areas for efficient affective computing, a patch-based selection scheme is proposed to iteratively remove redundant information through a novel loss function before fusion. Extensive experiments have been conducted on both machine weakly labeled and manually annotated datasets of self-made Video-SA, CMU-MOSEI, and CMU-MOSI. The results demonstrate the superiority of our approach through comparison with baselines. © 2023 Association for Computing Machinery.",TestAnalysis
"The main objective of this research paper is to overcome the issue of imbalances in data and achieve an improved outcome for grouping by using synthetic minority over-sampling (SMOTE). The imbalanced issue with the dataset causes classification efficiency loss in many applications of data mining comprising of pattern detection, document categorization, and knowledge filtering activities. A sampling-based algorithm SMOTE is used herein to boost the efficiency of emotion classification that over-samples minority class instances to amount of majority class instances. YouTube © dataset was optimized using the SMOTE methodology and evaluated by the use of 3 machine learning algorithms, including decision tree (DT), multinomial Naïve Bayes (MNB), and support vector machines (SVM). As a consequence, SVM reaches full specificity with 92.20 percent filtering function and 88.33 percent filtering process classification. The oversampling solution, however, might not be successful because it merely replicates minority class instances without any additional details. A way to create a set of instances comparable to those in the minority class with high potential to identify with the minority class was proposed in order to address this issue, and use them instead in the oversampling phase. ",TestAnalysis
"The analysis of data provided by tourism platforms through Web 2.0 opens new ways to investigate how to improve trip experiences from a destination management organization's (DMO) perspective. This case study builds on Tripadvisor users' generated content to analyse the lodging experience and overall rating by around 70,000 hotel visitors in the city of Barcelona. The online reviews are processed using text mining and depuration techniques. The overall rating of the hotel stay is then explained by a set of covariates, mostly including locational and services rates' perception (room quality, cleanliness, room service, etc.) by means of a regression analysis using an ordered probit model. Through the case, we will learn to: (i) prepare the data set for the experiment; and (ii) run the model and discuss the main findings. © CAB International 2023. All rights reserved.",TestAnalysis
"Recommendation system can provide recommendations to consumers on which restaurants might be liked by these consumers. This method plays the major role in food industries. The approach taken is to use collaborative filtering for the final touch in providing restaurant recommendations, but before this stage, it will go through several stages, including Natural Language Processing (NLP) aiming to create a new scoring which is the result of sentiment analysis combined with previous ratings (review text content). Then, clustering will be carried out on customers, to accelerate and optimize the recommendation process. From these two approaches, collaborative filtering is then carried out, so that it can provide some recommendations that are most suitable for consumers. However, in the recommendation system, there is a problem called the Cold Start Problem, this is a condition where the consumer is new so we cannot give recommendations. To overcome this problem, Location Based Filtering will be used, in this method, the consumer must fill in the location where he is located, so that we can provide recommendations for the best restaurant close to the location where the consumer is located. To measure model performance Root Mean Squared Error (RMSE) is used, the results obtained for the RMSE of the proposed method are 0.55, better than the baseline RMSE at 0.62. The time needed to provide recommendations on the proposed method is 247 ms, faster than the baseline model with a speed of 1.83 s. To overcome the Cold-Start Problem, Location Based Filtering is used, in this method the consumer must fill in the location where he is, so that he can provide the best restaurant recommendations that are close to the location where the consumer is. © 2023 Little Lion Scientific. All rights reserved.",TestAnalysis
"Objectives: The purpose of this study was to review literature concerning voice disorders in school-aged children. Study Design: Integrative review. Materials and Methods: A database search was conducted using PubMed, Web of Science, Academic Search Complete, CINAHL Complete, and Medline. All records included in this review were peer-reviewed journal articles that discussed voice disorders in children, conducted in the United States or Canada, written in English, and published between 2009 and 2019. Results: Database searching identified 1,771 records and 551 duplicates were removed. A total of 1,220 records were screened and 949 records were excluded. Two hundred and seventy-one full-text records were screened and 12 records met inclusion criteria. Vocal fold nodules were the most commonly reported vocal fold pathology. The Consensus Auditory Perceptual Evaluation of Voice and endoscopy were the most commonly reported assessments. However, variations in practice patterns and access to voice services may exist. Conclusions: The findings highlight that school-aged children may face barriers in accessing voice services. As a result, continued analyses of the potential barriers that hinder identification and treatment of voice disorders in this population appear warranted. © 2020 The Voice Foundation",TestAnalysis
"The author of the article presents the methodology of discourse analysis, studies the structural elements of discourse, and analyses the possibilities of using discourse analysis in confessional studies. It has been determined that discourse analysis is a qualitative tool based on an interdisciplinary strategy that allows revealing the hidden meaning embedded in narrative sources and its manifestation in the process of implementing social relations. The article presents different approaches and methods of discourse analysis, which depend on the approach of the researcher, while noting that, within the framework of a specific historical study, discourse analysis always includes the main provisions of the critical discourse analysis methodology and it is aimed at studying the integral components of discourse: subject – activity – text – environment. As methodological principles of discourse analysis, the article highlights the problematisation and evaluation of discourse as a dialogic communicative act, involving the complex interaction of actors in a specific historical, political, socio-economic and cultural context, implemented in a specific narrative. Discourse analysis is built on an interdisciplinary strategy, which involves the use of theory, techniques and methods of various sciences (culturology, rhetoric, philosophy, psychology, political science, sociology, etc.) to identify the relationship between social, cultural, political and social processes, affecting the essence of discourse. Features of the practical application of discourse analysis in the study of confessional history are illus-trated by the author on the example of the analysis of the discourse of state policy in relation to the Еvangelical movements of Western Belarus in 1921–1939. The main constituent elements of the discourse were subjected to discourse analysis using the methods of formal logic, the historical-genetic method, legal, sociological and other methods, which made it possible to draw conclusions about the external and internal factors of the state confessional policy, to determine its characteristic features and to reveal the latent meaning of the discourse of the state policy regarding the Еvangelical movements of Western Belarus. As a result of testing, the effectiveness of using discourse analysis for the comprehensive study of the subject of confessional history research was confirmed. © 2023, The Belarusian State University. All rights reserved.",TestAnalysis
"Software testing is still a manual process in many industries, despite the recent improvements in automated testing techniques. As a result, test cases (which consist of one or more test steps that need to be executed manually by the tester) are often specified in natural language by different employees and many redundant test cases might exist in the test suite. This increases the (already high) cost of test execution. Manually identifying similar test cases is a time-consuming and error-prone task. Therefore, in this paper, we propose an unsupervised approach to identify similar test cases. Our approach uses a combination of text embedding, text similarity and clustering techniques to identify similar test cases. We evaluate five different text embedding techniques, two text similarity metrics, and two clustering techniques to cluster similar test steps and three techniques to identify similar test cases from the test step clusters. Through an evaluation in an industrial setting, we showed that our approach achieves a high performance to cluster test steps (an F-score of 87.39%) and identify similar test cases (an F-score of 86.13%). Furthermore, a validation with developers indicates several different practical usages of our approach (such as identifying redundant test cases), which help to reduce the testing manual effort and time.  © 2022 IEEE.",TestAnalysis
"Background: The school-based food and nutrition guidelines approach has the potential to combat undernutrition, overnutrition and micronutrient deficiencies among children and adolescents and set the foundation for a healthy adult lifestyle. Aim: To critically compare the Nutrition Friendly School Initiative (NFSI) of the World Health Organization (WHO) with the Food Safety and Standards Authority of India (FSSAI) and the Indian Academy of Pediatrics (IAP) guidelines to gauge the strengths and limitations. Additionally, to summarize the existing studies on implementing school food and nutrition guidelines. Methods: Policy documents of the above guidelines were critically evaluated, and narrative analysis was conducted. An electronic search was conducted for full-text research articles published in the English language between January 2007 to September 2021 in Science Direct, PubMed, Web of Science, and SCOPUS databases. Results: Upon critical comparison of the three guidelines, it was found that the NFSI and FSSAI guidelines shared similarities in many components and the FSSAI guidelines, if implemented adequately, could improve the school food environment and combat the triple malnutrition burden in India. After screening the articles based on the eligibility criteria, 11 studies were included in the preparation of the review. Studies reported partial or inadequate implementation and poor compliance with the guidelines or approach. A few studies identified barriers to guideline implementation. Conclusion: Implementation of school food and nutrition guidelines could improve the nutritional outcomes in children and adolescents. To sustain the effective implementation, adequate resources and preparedness are essential in low-and middle-income countries, including India. © The Author(s) 2022.",TestAnalysis
"In the past couple of years, location-sensitive information retrieval has gained significant attention in terms of extracting and utilizing location information present in the unstructured text. It requires analysis of documents both geographically and thematically that makes it a challenging task. The semantics of text needs to be associated with location features present in the text. Such information association is beneficial in conducting fine-grained analysis of events reported in the text, e.g., Tourist location recommendation, Disaster surveillance, Political activeness and Happiness index, etc. Recently, context-based vector space models have attained much importance in text mining as they intelligently preserve semantics of the text while representing text in vector space of desired dimension. In this paper, a framework for multiclass supervised classification of location-sensitive events, namely, LDoc2Vec is proposed that integrates context-based vector space models with geographic scope resolution of events reported in the text documents. Variants of the Doc2Vec model have been integrated with location features and their performance for multiclass supervised event classification is analysed. Experimental results with various machine learning classifiers indicate that the proposed framework outperforms baseline Doc2Vec models for multiclass classification of location-sensitive events as expressed by renowned performance measurement metrics viz. precision, recall and F1-score. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"Background: The copper intrauterine device (Cu-IUD) is a highly effective method of contraception that can also be used for emergency contraception (EC). It is the most effective form of EC, and is more effective than other existing oral regimens also used for EC. The Cu-IUD provides the unique benefit of providing ongoing contraception after it is inserted for EC; however, uptake of this intervention has been limited. Progestin IUDs are a popular method of long-acting, reversible contraception. If these devices were also found to be effective for EC, they would provide a critical additional option for women. These IUDs could not only provide EC and ongoing contraception, but additional non-contraceptive benefits, including a reduction in menstrual bleeding, cancer prevention, and pain management. Objectives: To examine the safety and effectiveness of progestin-containing IUDs for emergency contraception, compared with copper-containing IUDs, or compared with dedicated oral hormonal methods. Search methods: We considered all randomized controlled trials and non-randomized studies of interventions that compared outcomes for individuals seeking a levonorgestrel IUD (LNG-IUD) for EC to a Cu-IUD or dedicated oral EC method. We considered full-text studies, conference abstracts, and unpublished data. We considered studies irrespective of their publication status and language of publication. Selection criteria: We included studies comparing progestin IUDs with copper-containing IUDs, or oral EC methods for emergency contraception. Data collection and analysis: We systematically searched nine medical databases, two trials registries, and one gray literature site. We downloaded all titles and abstracts retrieved by electronic searching to a reference management database, and removed duplicates. Three review authors independently screened titles, abstracts, and full-text reports to determine studies eligible for inclusion. We followed standard Cochrane methodology to assess risk of bias, and analyze and interpret the data. We used GRADE methodology to assess the certainty of the evidence. Main results: We included only one relevant study (711 women); a randomized, controlled, non-inferiority trial comparing LNG-IUDs to Cu-IUDs for EC, with a one-month follow-up. With one study, the evidence was very uncertain for the difference in pregnancy rates, failed insertion rates, expulsion rates, removal rates and the difference in the acceptability of the IUDs. There was also uncertain evidence suggesting the Cu-IUD may slightly increase rates of cramping and the LNG-IUD may slightly increase bleeding and spotting days. Authors' conclusions: This review is limited in its ability to provide definitive evidence regarding the LNG-IUD’s equivalence, superiority, or inferiority to the Cu-IUD for EC. Only one study was identified in the review, which had possible risks of bias related to randomization and rare outcomes. Additional studies are needed to provide definitive evidence related to the effectiveness of the LNG-IUD for EC. Copyright © 2023 The Cochrane Collaboration. Published by John Wiley & Sons, Ltd.",TestAnalysis
"Study Design: Systematic Review. Objective: To collect and group definitions of segmental instability, reported in surgical studies of patients with lumbar spinal stenosis (LSS) and/or lumbar degenerative spondylolisthesis (LDS). To report the frequencies of these definitions. To report on imaging measurement thresholds for instability in patients and compare these to those reported in biomechanical studies and studies of spine healthy individuals.To report on studies that include a reliability study. Methods: This review was conducted according to Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) guidelines. Studies eligible for inclusion were clinical and biomechanical studies on adult patients with LDS and/or LSS who underwent surgical treatment and had data on diagnostic imaging. A systematic literature search was conducted in relevant literature databases. Full text screening inclusion criteria was definition of segmental instability or any synonym. Two reviewers independently screened articles in a two-step process. Data synthesis presented by tabulate form and narrative synthesis. Results: We included 118 studies for data extraction, 69% were surgical studies with decompression or fusion as interventions, 31% non-interventional studies. Grouping the definitions of segmental instability according similarities showed that 24% defined instability by dynamic sagittal translation, 26% dynamic translation and dynamic angulation, 8% used a narrative definition. Comparison showed that non-interventional studies with a healthy population more often had a narrative definition. Conclusion: Despite a reputation of non-consensus, segmental instability in the degenerative lumbar spine can radiologically be defined as > 3 mm dynamic sagittal translation. © The Author(s) 2022.",TestAnalysis
"The aim of this scoping review is to provide an overview of the existing qualitative research concerning the lived experiences of children and young people currently in foster care. Introduction Lived experience of foster care is an area of limited research. Studies tend to focus on foster caregiver retention rates, education performance outcomes, evaluations and policy development. Although these studies are important, they provide little insight into the everyday lives of those currently in foster care, which is likely to influence these previous areas of research. Methods and analysis The scoping review will be guided by Arksey and O'Malley's approach to scoping studies. A systematic database search of PubMed, CINAHL and PsycINFO will be conducted followed by a systematic chain search of referenced and referencing literature. English-language peer-reviewed qualitative studies of children and young people currently in foster care will be included. We will exclude studies linked to transitioning out of foster care and studies with samples mixed with other types of out-of-home care. Mixed-methods studies will be excluded in addition to programme, treatment or policy evaluations. Following removal of duplicates, titles and abstracts will be screened, followed by a full-text review. Two researchers will independently screen references against inclusion and exclusion criteria using Covidence software. The quality of the included studies will be assessed by two independent reviewers using the appropriate Critical Appraisal Skills Programme checklist. Ethics and dissemination Information gathered in this research will be published in peer-reviewed journals and presented at national and international conferences relevant to foster care services and quality improvement. Reports will be disseminated to relevant foster care agencies, where relevant. Ethical approval and informed consent are not required as this protocol is a review of existing literature. Findings from the included studies will be charted and summarised thematically in a separate manuscript.  © 2023 Author(s) (or their employer(s)). Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.",TestAnalysis
"In this work we analyze the lyrics of one of the most famous and influential Arab artists in the twentieth century, namely, (Abdel ElHalim Hafez). Lyrics analysis provides a deep insight into the artist's career evolution and his interactions with the surrounding environment including the social, political, and economic conditions. In order to perform such analysis we had to collect and compile the lyrics of Abdel ElHalim accompanied with the necessary metadata into an organized and structured form. The data are preprocessed by removing stop words and doing some normalization operations over the songs' prose. We did not perform any lemmatization or stemming as the original form of the tokens convey much more information than the source words. We performed a lexical analysis in order to study both the lexical density and diversity over the course of Abdel ElHalim's career life. We have as well studied the most significant words, idioms, and terms played in the songs using tools such as word clouds and more quantitative measures such as term frequency-inverse document frequency. We have divided the career life of Abdel ElHalim into sub-decades of length 5 years and all analyses are done both in a yearly fashion and more coarsely over such sub-decades. We have found a strong correlation between our statistical analysis and the socio-political status in Egypt and the Arab world during that time. This is especially relevant knowing that Abdel ElHalim is very much truly considered the son of the generation of the 1952 revolution in Egypt. The significance of Abdel ElHalim and his lyrics stem essentially from being contemporaneous to radical changes in Egypt across all sectors including political (support of liberation movements across the world, and the conflict with Israel), and socio-economic (especially changing the social class structure in Egypt). We also investigated the potential effectiveness of PoS (Part of Speech) tagging in genre analysis and classification.  © 2023 Association for Computing Machinery.",TestAnalysis
"Background: Caregivers of elderly people need the right education and empowering skills to manage their own health needs and the elderly people they care for. Objective: The study aimed to explore youth perceptions of the My-Elderly-Care-Skills Module intervention and its perceived feasibility. Methods: This study involved youth respondents (18–30 years old) from low-income households who are accountable to providing care for independent older people (60 years or above) living in the same house. A qualitative study using a case study design was used to assess youth perceptions based on the content of the My-Elderly-Care-Skills module, by focusing on its implementation usage and usefulness for the care of the elderly. A total of 30 youths voluntarily participated in the online training workshop during the COVID-19 pandemic movement restriction order period. There were multiple sources of data, such as video recorded on reflection of care given at home, text messages in a WhatsApp group, and in-depth interviews during small group online meetings. Data were recorded and transcribed verbatim for common themes before a theme analysis was conducted. Inductive content analysis was performed after the saturation point was met. Results: Thematic analysis derived two domains of feasibility: operational and technical feasibility. There were three themes under operational practicality (improving awareness, addressing the caregiving skills needs, and seeking resources for knowledge) and three themes for technical practicality (easily used and informative, skill in effective communication, and program fulfillment). Conclusion: It was verified that it is feasible for young caregivers of the elderly to participate in the My-Elderly-Care-Skills training intervention as it helps in improving knowledge and skills performance in managing and caring for the elderly. Copyright © 2023 Mokhzan, Sutan, Yasin and Yamat.",TestAnalysis
"Objectives This study aims to assess whether the characteristics, management and outcomes of women varied between Syrian and Palestinian refugees, migrant women of other nationalities and Lebanese women giving birth at a public tertiary centre in Beirut, Lebanon. Methods This was a secondary data analysis of routinely collected data from the public Rafik Hariri University Hospital (RHUH) between January 2011 and July 2018. Data were extracted from medical notes using text mining machine learning methods. Nationality was categorised into Lebanese, Syrian, Palestinian and migrant women of other nationalities. The main outcomes were diabetes, pre-eclampsia, placenta accreta spectrum, hysterectomy, uterine rupture, blood transfusion, preterm birth and intrauterine fetal death. Logistic regression models estimated the association between nationality and maternal and infant outcomes, and these were presented using ORs and 95% CIs. Results 17 624 women gave birth at RHUH of whom 54.3% were Syrian, 39% Lebanese, 2.5% Palestinian and 4.2% migrant women of other nationalities. The majority of women had a caesarean section (73%) and 11% had a serious obstetric complication. Between 2011 and 2018, there was a decline in the use of primary caesarean section (caesarean section performed for the first time) from 7% to 4% of births (p<0.001). The odds of preeclampsia, placenta abruption and serious complications were significantly higher for Palestinian and migrant women of other nationalities compared to Lebanese women, but not for Syrian women. Very preterm birth was higher for Syrians (OR: 1.23, 95% CI: 1.08 to 1.40) and migrant women of other nationalities (OR: 1.51, 95% CI: 1.13 to 2.03) compared to Lebanese women. Conclusion Syrian refugees in Lebanon had similar obstetric outcomes compared to the host population, except for very preterm birth. However, Palestinian women and migrant women of other nationalities appeared to have worse pregnancy complications than the Lebanese women. There should be better healthcare access and support for migrant populations to avoid severe complications of pregnancy.  © 2023 BMJ Publishing Group. All rights reserved.",TestAnalysis
"Introduction: In recent years, research has used psycholinguistic features in public discourse, networking behaviors on social media and profile information to train models for depression detection. However, the most widely adopted approach for the extraction of psycholinguistic features is to use the Linguistic Inquiry Word Count (LIWC) dictionary and various affective lexicons. Other features related to cultural factors and suicide risk have not been explored. Moreover, the use of social networking behavioral features and profile features would limit the generalizability of the model. Therefore, our study aimed at building a prediction model of depression for text-only social media data through a wider range of possible linguistic features related to depression, and illuminate the relationship between linguistic expression and depression. Methods: We collected 789 users’ depression scores as well as their past posts on Weibo, and extracted a total of 117 lexical features via Simplified Chinese Linguistic Inquiry Word Count, Chinese Suicide Dictionary, Chinese Version of Moral Foundations Dictionary, Chinese Version of Moral Motivation Dictionary, and Chinese Individualism/Collectivism Dictionary. Results: Results showed that all the dictionaries contributed to the prediction. The best performing model occurred with linear regression, with the Pearson correlation coefficient between predicted values and self-reported values was 0.33, the R-squared was 0.10, and the split-half reliability was 0.75. Discussion: This study did not only develop a predictive model applicable to text-only social media data, but also demonstrated the importance taking cultural psychological factors and suicide related expressions into consideration in the calculation of word frequency. Our research provided a more comprehensive understanding of how lexicons related to cultural psychology and suicide risk were associated with depression, and could contribute to the recognition of depression. Copyright © 2023 Lyu, Ren, Du and Zhao.",TestAnalysis
"Background: A steep increase in new drug applications has increased the overhead of writing technical documents such as medication guides. Natural language processing can contribute to reducing this burden. Objective: To generate medication guides from texts that relate to prescription drug labeling information. Materials and Methods: We collected official drug label information from the DailyMed website. We focused on drug labels containing medication guide sections to train and test our model. To construct our training dataset, we aligned “source” text from the document with similar “target” text from the medication guide using three families of alignment techniques: global, manual, and heuristic alignment. The resulting source-target pairs were provided as input to a Pointer Generator Network, an abstractive text summarization model. Results: Global alignment produced the lowest ROUGE scores and relatively poor qualitative results, as running the model frequently resulted in mode collapse. Manual alignment also resulted in mode collapse, albeit higher ROUGE scores than global alignment. Within the family of heuristic alignment approaches, we compared different methods and found BM25-based alignments to produce significantly better summaries (at least 6.8 ROUGE points above the other techniques). This alignment surpassed both the global and manual alignments in terms of ROUGE and qualitative scoring. Conclusion: The results of this study indicate that a heuristic approach to generating inputs for an abstractive summarization model increased ROUGE scores, compared to a global or manual approach when automatically generating biomedical text. Such methods hold the potential to significantly reduce the manual labor burden in medical writing and related disciplines. Copyright © 2023 Meyer, Adkins, Pal, Galici, Garcia-Agundez and Eickhoff.",TestAnalysis
"Importance: Ipsilateral neck radiotherapy (RT) is controversial in some patients with tonsil cancer due to concern for nodal failure within the contralateral nonirradiated neck (hereinafter referred to as contralateral neck failure [CNF]). Objective: To determine the rate of CNF following ipsilateral neck RT in patients with tonsil cancer. Data Sources: Databases including PubMed, Embase, Web of Science, and Cochrane Library were queried for peer-reviewed, English language articles published between January 1, 1980, and December 31, 2021. Study Selection: Studies reporting rates of CNF from at least 20 patients treated with ipsilateral neck RT. Studies were excluded if they lacked full text, reported results from databases or systematic reviews, or did not provide RT details. Data Extraction and Synthesis: Data were extracted following the PRISMA reporting guideline. Study quality was assessed using criteria from a methodological index for nonrandomized studies. Pooled outcomes were estimated using random-effects models. Main Outcomes and Measures: Primary outcome was the pooled rate of CNF following ipsilateral neck RT. Secondary outcomes were the pooled rates of CNF by tumor and nodal staging categories from the 7th edition of the AJCC Cancer Staging Manual and rates of toxic effects. Results: A total of 17 studies (16 retrospective and 1 prospective) including 1487 unique patients were identified. The pooled risk of CNF was 1.9% (95% CI, 1.2%-2.6%). The rate of CNF by tumor (T) category was as follows: 1.3% (95% CI, 0.3%-2.3%) for T1; 3.0% (95% CI, 1.6%-4.4%) for T2; 11.3% (95% CI, 3.3%-19.2%) for T3; and 16.0% (95% CI, -7.8% to 39.8%) for T4. Patients with T3 to T4 tumors had a significantly higher rate of CNF than those with T1 to T2 tumors (11.5% [95% CI, 3.9%-19.1%] vs 1.8% [95% CI, 1.0%-2.6%]; P <.001). The rate of CNF by nodal (N) category was 1.2% (95% CI, 0.1%-2.2%) for N0; 4.8% (95% CI, 2.4%-7.2%) for N1; 3.1% (95% CI, 0.4%-5.8%) for N2a; 3.1% (95% CI, 1.2%-4.9%) for N2b; and 0 (95% CI, not applicable) for N3. Rates of CNF were similar for patients with N2b to N3 and N0 to N2a disease (3.0% [95% CI, 1.2%-4.7%] vs 1.7% [95% CI, 0.6%-2.8%], respectively; P =.07). Compared with bilateral RT, ipsilateral RT was associated with increased risk of CNF (log odds ratio, 1.29 [95% CI, 0.09-2.48]; P =.04). The crude rates of xerostomia of grade 3 or greater and feeding tube use were 0.9% (95% CI, -0.2% to 1.9%) and 13.3% (95% CI, 8.3%-18.3%), respectively. Conclusions and Relevance: In this systematic review and meta-analysis, ipsilateral neck RT was associated with a low rate of CNF in patients with small, lateralized tonsil cancers. Bilateral neck RT was associated with lower risk of CNF compared with ipsilateral neck RT. Patients with tumors of a higher T category were at increased risk for CNF following ipsilateral neck RT, and advanced nodal stage was not associated with CNF. Rates of toxic effects appeared favorable in patients treated with ipsilateral neck RT.. © 2022 American Medical Association. All rights reserved.",TestAnalysis
"In recent years, Recommendation Systems (RSs) have become a vital component of numerous websites and online applications in a variety of domains. Consider, for instance, the e-commerce websites where RSs predominate. In part, the problem of information overload is mitigated by these RSs. However, RSs still have a few issues, such as data sparsity, which leads to another issue known as cold-start. The cold-start problem occurs when the user-item matrix is incredibly sparse. Additionally, RSs has a problem known as the long-tail problem, in which the system is incapable of providing suggestions due to insufficient or invalid ratings for often purchased products. The cold-start problem can be solved by providing recommendations based on captured user preferences and user feedback. User attitudes can be gleaned from the analysis of textual user reviews of purchased products. Sentiment analysis(SA), also known as opinion mining, is the study of people's opinions, feelings, judgments, feedbacks, and emotions conveyed through written language regarding entities and their features. Usually these sentiments are derived and based out of various contexts. A context in sentiment analysis is a mood-based natural attribute. Collaborative filtering (CF) method is by far and away the most popular and widely used algorithm for RSs to date. Collaborative filtering is a way for generating automatic predictions (filtering) about a user's interests by collecting preferences or taste data from a large number of users. In this study, we combine the functionality of a CF algorithm with contextual information extracted from user input. The varied situations are then assessed for sentiment using distinct attributes. Our model is known as FusionSCF. This study utilises two e-commerce datasets: Amazon.com and Flipkart.com. We predict and recommend products to users based on a combined weighted rating and sentiment score. We execute a lexicon-based sentiment analysis utilising several text classification methods for Natural Language Processing. The results reveal that the proposed contextual information sentiment-based model outperforms the conventional collaborative filtering technique. In the final phase of our work, we also explore the consequences of fake reviews on our filtering system. Also using a metric ""genuinity index"", we convey how reviews can be classified to genuine ones. © 2023 ACM.",TestAnalysis
"Plastic pollution control, involving the whole life cycle management of plastic production, consumption, sorting, recycling, and disposal, has become necessary for global sustainable development. Research on public attitudes is vital to understanding whether plastic pollution control policies are being successfully implemented and the degree to which the public is involved. However, few studies have assessed public attitudes toward plastic pollution control from the whole life cycle perspective, especially using big data. Based on China's whole life cycle management policy of plastics, this study collected more than 200,000 relevant comments and user information from Sina Weibo to analyze and evaluate public attitudes and opinions toward plastic pollution control. Spatial-temporal analysis was conducted to discover the regional and temporal differences in public attention. Using a sentiment classification method based on semantic analysis, the emotional tendencies of the public attitudes toward ten subdivided plastic pollution control links were studied. It was found that more people held a positive attitude and paid more attention to reusing and sorting links, while the negative emotions were concentrated on the collection and sorting links. Using a topic modeling method, the negative opinions in various links were revealed, such as lack of supervision and industry standards; over packaging or insufficient packaging; food safety problems caused by the reuse; high costs, poor use and possibly greater waste of substitutes; unclear sorting rules and insufficient supporting measures. Graph theory was applied to display these opinions. Finally, some policy implications derived from the discussions are given. © 2022 Elsevier B.V.",TestAnalysis
"Introduction Institutionally based intensive treatment modalities (inpatient, day patient and residential treatments) for eating disorders (EDs) are associated with high treatment costs and significant challenges for patients and carers, including access difficulties and disruption to daily routines. Intensive community and home-based treatments have been suggested as alternatives to institutionally based intensive treatments for other severe mental illnesses, with promising clinical, social and health economic outcomes. The possible advantages of these treatments have been proposed for EDs, but this emerging area of research has not yet been systematically investigated. This scoping review aims to map the available literature on intensive community and home treatments for EDs, focusing on their conceptualisation, implementation and clinical outcomes. Methods This proposed scoping review will follow the Preferred Reporting Items for Systematic Reviews and Meta-Analyses Protocol extension for Scoping Reviews checklist and the Joanna Briggs Institute Reviewer's Manual. This review will include any peer-reviewed study concerning intensive community and home-based treatments for any EDs, with no restrictions on geographical context or study design. Grey literature will also be considered. The literature search will be conducted in four databases: PubMed, PsycInfo, MEDLINE and Web of Science. Two researchers will independently screen the titles, abstracts and text of the returned articles for eligibility. Data charting and analysis will consist of a narrative description of the included studies, quantitative and qualitative findings relative to the aims of this scoping review. Gaps in the literature will be highlighted to inform future research, clinical practice, and policy. Ethics and dissemination Ethical approval is not required as all data are available from public sources. The results of this scoping review will be disseminated through peer-reviewed publication, conference presentation, and social media. © 2023 BMJ Publishing Group. All rights reserved.",TestAnalysis
"In the article “Duration Selectivity in Right Parietal Cortex Reflects the Subjective Experience of Time,” by Masamichi J. Hayashi and Richard B. Ivry, which appeared on pages 7749-7758 of the September 30, 2020 issue, the description of the original analysis procedure included an error. The authors note: “For normalization of the fMRI data to the MNI stereotactic space, we used a unified segmentation and normalization procedure, the standard normalization procedure in SPM12. However, the text erroneously stated that we used the diffeomorphic anatomic registration through exponentiated lie algebra (DARTEL) algorithms, an optional procedure for spatial normalization in SPM12.” On page 7751 of the article, in the Materials and Methods subsection on MRI data acquisition and preprocessing, the second to last sentence should have read: “The fMRI data were normalized in MNI space using the unified segmentation and normalization procedure provided in SPM12.” The authors regret the error. © 2023 Society for Neuroscience. All rights reserved.",TestAnalysis
"In the paragraph beginning ""The patient performed"" (page 1354), the penultimate sentence should have ended, ""⋯ with a ratio of minute ventilation to maximum voluntary ventilation of 1.00 (reference value, <0.8),"" rather than ""⋯ 0.67 (reference value, >0.8)."" Figure 2 (page 1355) erroneously provided histopathological images from the surgical lung biopsy and has been replaced by an image showing constrictive bronchiolitis. The legend should have read, ""Hematoxylin and eosin staining of a section of lung shows constrictive bronchiolitis characterized by subepithelial fibrosis that widens (arrows) the normally narrow space between the airway epithelium and smooth muscle. Image and histologic description provided by Dr. Teri Franks, Division of Pulmonary and Mediastinal Pathology, the Joint Pathology Center,"" rather than, ""Biopsy specimens of the right lung show features of constrictive bronchiolitis. In Panel A, hematoxylin and eosin staining shows focal segmental luminal obliteration (yellow arrow) and smooth-muscle hypertrophy (black arrows) of the airways and adjacent vasculature (V). In Panel B, trichrome staining shows airway-wall thickening due to subepithelial collagen deposition (blue staining; arrows), which indicates fibrosis of the membranous bronchiole."" In the paragraph beginning ""The patient underwent"" (page 1355), the text beginning with the third sentence should have read, ""Histopathological analysis identified a small airway size relative to the paired pulmonary artery, airway distortion, focal segmental obliteration, peribronchiolar metaplasia, and subepithelial fibrosis (Fig. 2) associated with secondary mild airspace enlargement. The findings were classified as constrictive bronchiolitis,"" rather than ""⋯ identified airway distortion and narrowing, focal segmental obliteration, peribronchiolar metaplasia, and subepithelial thickening due to smooth-muscle hypertrophy and collagen deposition (Fig. 2). There was minimal pigment deposition adjacent to bronchovascular structures, and there was no evidence of emphysema or pleural inf lammation. The findings were classified as constrictive bronchiolitis."" The article is correct at NEJM.org. © 2023 Massachussetts Medical Society. All rights reserved.",TestAnalysis
"Details of correction: addition to acknowledgments Existing text: The authors would like to acknowledge the guidance of biostatistician Doctor Alison Bowling with the data analysis for this project; the Australian Longitudinal Study of Women’s Health for access to their data sets; the support of Professor Gita Mishra the ALSWH liaison person for our study and Doctor David Giles from the Victorian Cancer Council who constructed the DQESv2 FFQ used in this study. This work was supported by an Australian Government Research Training Programme (RTP) stipend grant for PhD candidate Megan Lee. RTP funding is an Australian support grant for domestic or international students conducting PhD or Master of Research degrees. The project received no other grants from funding agencies, commercial or not-for-profit sectors. This manuscript came from a PhD project. M. L. formulated the research question, designed the study, requested data through an EOI from the ALSWH, cleaned and analysed the data with contribution from A. B. and J. B., interpreted the findings and wrote the article under the supervision of S. S., J. Y. and J. B. The authors acknowledge no conflicts of interest for this research project. Corrected text should read: The research on which this paper is based was conducted as part of the Australian Longitudinal Study on Women’s Health by the University of Queensland and the University of Newcastle. We are grateful to the Australian Government Department of Health and Aged Care for funding and to the women who provided the survey data. The authors would like to acknowledge the guidance of biostatistician Doctor Alison Bowling with the data analysis for this project; the Australian Longitudinal Study of Women’s Health for access to their data sets; the support of Professor Gita Mishra the ALSWH liaison person for our study and Professor Graham Giles and Professor Roger Milne of the Cancer Epidemiology Centre of Cancer Council Victoria, for permission to use the Dietary Questionnaire for Epidemiological Studies (Version 2), Melbourne: Cancer Council Victoria, 1996 This work was supported by an Australian Government Research Training Programme (RTP) stipend grant for PhD candidate Megan Lee. RTP funding is an Australian support grant for domestic or international students conducting PhD or Master of Research degrees. The project received no other grants from funding agencies, commercial or not-for-profit sectors. This manuscript came from a PhD project. M. L. formulated the research question, designed the study, requested data through an EOI from the ALSWH, cleaned and analysed the data with contribution from A. B. and J. B., interpreted the findings and wrote the article under the supervision of S. S., J. Y. and J. B. The authors acknowledge no conflicts of interest for this research project. Details of correction: changes to paper title Existing text: Is dietary quality associated with depression? An analysis of the Australian longitudinal study of women’s health data Corrected text should read: Is dietary quality associated with depression? An analysis of the Australian Longitudinal Study on Women’s Health data. © 2023 Cambridge University Press. All rights reserved.",TestAnalysis
"Objective To analyze the hotspots and frontiers of diabetic peripheral neuropathy nursing research in the past decade in China, and to provide nursing staff with a reference basis for understanding and grasping the direction of research. Methods The literature related to diabetic peripheral neuropathy nursing from January 1, 2012 to December 31, 2021 was searched through China Journal Full Text Database, China Biomedical Literature Database, CQVIP, and Wanfang, and visualized and analyzed by using CiteSpace software. Results A total of 763 articles were included in the literature, and the number of articles was analyzed to show a significant upward trend in 2018-2021, with the most articles by authors being 4 each by Liu Dan and An Caixia, and the most articles by institutions being 6 and 5 by Nanjing Chinese Medicine Hospital and Shanghai Jiading District Chinese Medicine Hospital, respectively, with research hotspots being complications related to diabetic peripheral neuropathy, rehabilitation care, and special Chinese medicine care techniques, and research frontiers being quality of life and neurological function. Conclusions The research base of diabetic peripheral neuropathy is weak, and researchers should focus on the frontiers of international research hotspots in diabetic peripheral neuropathy care to help nursing research produce prospective, high-impact research results and improve patient clinical outcomes. © The Author(s) 2023.",TestAnalysis
"Objectives Increasing access to mental health support is a key factor for treating mental disorders, however, important barriers complicate help-seeking, among them, mental health related stigma being most prominent. We aimed to systematically review the current evidence for interventions focusing on reducing stigma related to mental health problems in small and medium enterprises (SMEs). Design Systematic review with a focus on interventions targeting mental health related stigma in the workplace in accordance with PRISMA guidelines. The methodological quality of included articles was assessed using the Quality Assessment Tool for Quantitative Studies Scale. Data sources PubMed, Ovid Medline, PsycINFO, Scopus, and Cochrane databases and Google Scholar were searched from January 2010 until November 2022. Eligibility criteria for selecting studies We included experimental or quasi-experimental studies about workplace interventions aiming to reduce stigma, where the outcomes were measured in terms of stigmatisation against depression, anxiety and/or other mental health problems. Data extraction and synthesis Records were screened by two independent reviewers after inspecting titles and abstracts and a full-text read of the articles to assess whether they meet inclusion criteria. The results were synthesised narratively. Results We identified 22 intervention studies, 3 with high quality, 13 with moderate quality and 6 with weak quality. Only 2 studies included SMEs, but no study focused on SMEs exclusively. The mode of delivery of the intervention was face to face in 15 studies, online in 4 studies and mixed in 3 studies. We found a significant reduction in stigmatising attitudes in almost all studies (20/22), using 10 different instruments/scales. Effects seemed to be independent of company size. Online interventions were found to be shorter, but seemed to be as effective as face-to-face interventions. Conclusions Although we did not find interventions focusing exclusively on SMEs, it is likely that antistigma interventions also will work in smaller workplaces. Trial registration PROSPERO: ID: CRD42020191307  © 2023 BMJ Publishing Group. All rights reserved.",TestAnalysis
"In the Original Investigation, “Complication Rates of Total Thyroidectomy vs Hemithyroidectomy for Treatment of Papillary Thyroid Microcarcinoma: A Systematic Review and Meta-analysis,”1 published online May 5, 2022, and in the June issue ofJAMA Otolaryngology–Head & Neck Surgery, the authors reported several errors for the studies included in the meta-analysis. The authors have published a Letter2 to explain the errors and corrections, which affect the text, Table, Figures, and Supplement, and indicate that none of the direction of the statistical findings, interpretations, or conclusions are affected. The article has been corrected. © 2022 American Medical Association. All rights reserved.",TestAnalysis
"Background. Caring for chronic psychiatric patients places a complex burden on patients' caregivers. Paying attention to the needs of caregivers based on the cultural conditions of the country in which they live is of particular importance to improve the quality of care. Methods. In this study, 30 caregivers of patients with schizophrenia who were treated for at least two months by a regular psychiatrist joined the study over six months. They contacted the psychiatrist via SMS when their patient was in remission. In total, 1581 text messages were sent during 3 years. All messages were evaluated by three faculty members through the qualitative content analysis method. Results. The results of this study were categorized into training, reporting, and the expression of feelings themes and several codes. Conclusion. Addressing the caregivers needs to take steps forward to improve the effective two-way treatment relationship and prevent the gap between patients, caregivers, and the health care staff. Practical Implications. Paying attention to different dimensions of caregivers' concerns while caring for patients with chronic psychiatric disorders such as schizophrenia can have a significant impact on controlling the disease and improving the quality of life of patients and their family members. © 2022, Tabriz University of Medical Sciences. All rights reserved.",TestAnalysis
"Using Chinese listed companies as the research setting, this study investigates the impact of climate risk on corporate precautionary cash holdings and further explores possible underlying channels. We first apply the text mining technique to construct the climate risk indicator. The regression results then show that climate risk has a significant and positive impact on corporate precautionary cash holdings. Such positive relationship is stronger for firms with small size and those located in central and eastern China. Further mechanism analysis indicates that risk taking and external financing play a mediating effect between climate risk and corporate precautionary cash holdings. Our findings have important practical implications for companies to make sustainability strategies against potential climate risks. Copyright © 2023 Zhang, Yang and Li.",TestAnalysis
"In the modern era, the quantity of data, specifically the text data, has increased rapidly. Recently, fake news has gained a lot of attention worldwide. Generally, fake news is propagated through different social media. The effects of fake news may be economic, political, organizational, or personal. To save the life of community from fake news propagation, identification of fake news at an initial point is crucial. The fake news propagators target innocent people for spreading the fake news and they become a part of fake news propagation unknowingly. To prevent this kind of activity, fake news detection and its blueprint of propagation becomes crucial to community and government. This chapter makes an analysis related to the prediction of fake news through the help of supervised ML algorithms. The ML algorithms are adopted for the categorization of fake news as true or false with the help of NLP textual analysis and feature extraction. However, during the testing phase, the XGB algorithm gives the best result over other ML algorithms with an accuracy of 99%. © 2023, IGI Global. All rights reserved.",TestAnalysis
"At the beginning of 2020 the world was shocked by the COVID-19 pandemic which paralyzed all aspects of activity for some time. However, over time and with the discovery of a vaccine, the cases caused by COVID-19 began to subside. In 2022, the Indonesian government make a policy that people are allowed to take off their masks when active but are encouraged to maintain health protocols. However, the approach reaped the pros and cons of the Indonesian people. One challenge is to build technology to detect and summarize an overall those pros and cons. So that, we look at Twitter and build models for classifying ‘tweets’ into positive, negative and neutral sentiment using top two approaches for sentiment analysis, the lexicon-based method and the naive Bayes classifier. This study aimed to analyze public opinion about removing masks through Twitter by comparing the lexicon-based method and the naive Bayes classifier method to find out how the community responded to taking off masks. A total of 639 tweets with the keyword ""Lepas Masker"" was analyzed include data crawling, text preprocessing, feature extractions and the classification process. The comparison of the results obtained shows the accuracy of 82% for the lexicon-based method and 70% for the naive Bayes classifier method. To the results, the accuracy value of the lexicon-based method is higher than the naive Bayes classifier method. © 2023 Little Lion Scientific. All rights reserved.",TestAnalysis
"Objective: To investigate the effects of orthodontic tooth movement on clinical attachment level (CAL) changes in treated periodontitis in adult patients with malocclusion. Material and Methods: Present study is based on PRISMA guidelines; all articles published in international databases such as PubMed, Scopus, Science Direct, and Embase between 2012 to May 2022 are included. 95% confidence interval (CI) for mean difference with fixed effect modal and inverse-variance were calculated. Data analysis was performed using STATA.V16 software. Results: In the initial review, duplicate studies were eliminated, abstracts of 175 studies were reviewed, two authors reviewed the full text of 21 studies, and finally, eleven studies were selected. The mean of CAL gain was 2.29 mm (MD, 95% CI-2.47 mm,-2.12 mm; p=0.00) (I2=91.81%; p=0.00; high heterogeneity). The mean difference of PPD changes was –1.93 mm (MD, 95% CI-2.07 mm,-1.80 mm; p=0.00) (I2=98.52%; p=0.00; high heterogeneity). Conclusion: Due to the limitations of the study and based on the meta-analysis, it is observed that orthodontic treatment is performed with higher success after reconstructive surgery with periodontal improvement. © 2023, Association of Support to Oral Health Research (APESB). All rights reserved.",TestAnalysis
"Objective This paper provides a systematic review of evidence of government purchase of health services from private providers through stand-alone contracting-out (CO) initiatives and CO insurance schemes (CO-I) on health service utilisation in Eastern Mediterranean Region (EMR) to inform universal health coverage 2030 strategies. Design Systematic review. Data sources Electronic search of published and grey literature on Cochrane Central Register of Controlled Trials, PubMed, CINHAL, Google Scholar and web, including websites of ministries of health from January 2010 to November 2021. Eligibility criteria Randomised controlled trials, quasi-experimental studies, time series, before-after and endline with comparison group reporting quantitative utilisation of data across 16 low-income and middle-income states of EMR. Search was limited to publications in English or English translation. Data extraction and synthesis We planned for meta-analysis, but due to limited data and heterogeneous outcomes, descriptive analysis was performed. Results Several initiatives were identified but only 128 studies were eligible for full-text screening and 17 met the inclusion criteria. These included CO (n=9), CO-I (n=3) and a combination of both (n=5) across seven countries. Eight studies assessed interventions at national level and nine at subnational level. Seven studies reported on purchasing arrangements with non-governmental organisations, 10 on private hospitals and clinics. Impact on outpatient curative care utilisation was seen in both CO and CO-I, positive evidence of improved maternity care service volumes was seen mainly from CO interventions and less reported from CO-I, whereas data on child health service volume was only available for CO and indicated negative impact on service volumes. The studies also suggest pro-poor effect for CO initiatives, whereas there was scarce data for CO-I. Conclusion Purchasing involving stand-alone CO and CO-I interventions in EMR positively impact general curative care utilisation, but lacks conclusive evidence for other services. Policy attention is needed for embedded evaluations within programmes, standardised outcome metrics and disaggregated utilisation data.  © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.",TestAnalysis
"Nineteenth-century European narrative literature repeatedly refers to the deliberate destruction (or intentions, attempts to destroy) of artificial images. The old artist in Honoré de Balzac's novella The Unknown Masterpiece burns his collection of art; the hero of Alexander Pushkin's poem The Bronze Horseman threatens the monument to the Emperor Peter the Great in St Petersburg; the inhabitants of a French village in Prosper Mérimée's novella The Venus of Ille re-melt the 'evil' antique statue found in the soil; the painter in Nikolai Gogol's novel The Portrait compulsively buys and destroys masterpieces of painting; another picture, in Emile Zola's novel L'Œuvre, is burned after the suicide of its author; the hero of Oscar Wilde's novel The Picture of Dorian Gray attempts to stab his own portrait, which is displaying his sins; in The Adventure of the Six Napoleons, a short story by Arthur Conan Doyle, six busts of the French emperor are broken, in turn first by a thief, and finally by a detective. Being destroyed or disappearing seems to be the recurrent destiny of intradiegetic images (material images included into a narrative text as its actors), and the attempts of their obliteration always constitute a highlighted, spectacular moment in the narrative, and not just an outward sign of someone's inner feelings; they are typically presented as a sacrifice of 'excessive' (magical, demonic) objects. In some cases, they are explained by a deviant behaviour of the character (madness, delinquency), but the literary text is organized in order to make the reader sympathize with the experiences of that 'iconoclast', and mentally reproduce his acts. An analysis of texts should disclose the mechanism of this self-identification and put the stories about the attempts on the image into the general framework of nineteenth-century visual and literary culture.  © The Author(s), 2023. Published by Cambridge University Press on behalf of Academia Europaea.",TestAnalysis
"Background: Little is known about the impact of the coronavirus disease 2019 (COVID-19) pandemic on community health serVICe staff. The aim of this study was to assess the immediate and longer-term psychosocial impacts of COVID-19 on community health serVICe staff in Australia. Methods: A prospective cohort design with an anonymous cross-sectional online survey that was administered at two time points (March-April 2021; n = 681 and September-October 2021; n = 479). Staff (clinical and non-clinical) were recruited from eight community health services in Victoria, Australia. Study-specific questions evaluated the impact of COVID-19 on respondents' work and personal lives. Space was provided at the end of the surveys for free-text comments. Results: There were no significant differences in respondent characteristics between the two surveys. At both survey time points, respondents were mostly concerned about their family's health. Compared to the first survey, survey two respondents were significantly more likely to report concerns about infecting family members (48.8% vs 41.6%, P = 0.029), clients having COVID-19 (43.2% vs 36.2%, P = 0.035), getting COVID-19 at work (53.7% vs 45.6%, P = 0.014), not being prepared to care for clients with COVID-19 (27.5% vs 18.8%, P = 0.006) and feeling more stress at work (63.7% vs 50.8%, P < 0.001). A significantly greater proportion of respondents indicated they were considering transitioning into another sector at the time of the second survey compared to the first (24.8% vs 18.7%, P = 0.026). Conclusions: The COVID-19 pandemic has had a considerable impact on the work and personal lives of community health serVICe staff. Staff would benefit from continued and targeted initiatives that address their wellbeing and concerns. © 2023 CSIRO. All rights reserved.",TestAnalysis
"Ice and snow are natural phenomena as well as valuable tourism resources. Originating in the European mountains in the late 19th century, ice-snow tourism has become an increasingly significant sector of the tourism industry. Despite sustained growth, international ice-snow tourism has faced unprecedented threats in recent years. The ice-snow tourism in China has developed in recent years. However, ice-snow tourism industry in China has proliferated in the past few years, especially after China won the 2022 Winter Olympics bid in 2015. The purpose of this study is to summarize international studies on ice-snow tourism and then provide references for future studies in China. Articles associated with ice-snow tourism, published before the year 2021, were retrieved from the Web of Science core collection with the topics “ice tourism”, “ski tourism”, “snow tourism”, “winter tourism” and “ski resort”. Based on a systematic review of the literature, Citespace was also used to perform text mining and visual analysis. The results show that: (1) Research of international ice-snow tourism increased continuously from the year of 1988, with developed countries in Europe and America contributing most of the research, while China showed its great potential in this field. (2) Tourism injuries dominated the initial phase of international ice-snow tourism studies, whereas climate change attracted attention afterward due to the consensus on global warming. In recent studies, studies have focused on ice-snow tourism industry sustainability, diversity of products and services in ski resorts, and other micro-level topics. (3) Knowledge structure of international ice-snow tourism studies was visualized as co-citation clusters, with 7 clusters identified. As a result of comparing labels and reading associated articles, these clusters could be grouped into three main categories: Impact on the natural environment, tourists' experience, and industry development. Additionally, this study suggests that Chinese research on ice-snow tourism has generally focused on discourse at the macro level, and used similar perspectives, conventional data sources and research methods compared to international studies. Therefore, this study concludes that future research on ice-snow tourism in China should pay more attention to in-depth case studies, multiple perspectives, new data and methods, and the practical value of research. © 2023, Science Press. All rights reserved.",TestAnalysis
"The problem of Region of Interest (RoI) in document layout analysis and document recognition has recently become an essential topic in OCRing systems. Arabic manuscript layout analysis and OCRing recognition using language detection, document category, and RoI with Keras and TensorFlow are terms of the state-of-The-Art that should be investigated. This article investigates the problem of Arabic manuscript recognition problems with respect to in OCRing-based recognition. A new framework architecture, which integrates Fast Gradient Sign Method (FGSM) using Keras and TensorFlow with adversarial image generation during training procedure is proposed. Also, the article tries to improve the OCRing accuracy of the image enhancement, alignment, layout analysis, and recognition using deep learning in multilingual system. RoIs detections will be performed using a custom trained deep learning model using bounding box regression with Keras and TensorFlow. This topic investigates an extension of Page Segmentation Method (PSM) to enhance OCRing parameter modes and enhances Arabic OCRing system accuracy from reinforcement strategy. Therefore, the article achieves a significant improvement of OCRing results due to the three parameters: language identification, document category, and RoI types (Table, Title, Paragraph, figure, and list). This model is based on ""region proposal algorithm""as a basis of CNN object detectors to find the number of the RoIs. Therefore, the proposed framework performs three distinctive tasks: (1) CNN architecture for adversarial training, (2) an implementation of the FGSM with Keras and TensorFlow, and (3) an adversarial training script implementation with the CNN and the FGSM method. The experiments on Arabic manuscript dataset including Arabic text, English/Arabic documents, and Latin digits' datasets, demonstrate the accuracy of the proposed method. Moreover, the proposed framework performs well and succeeded in defending against adversarial attacks or adversarial images. The experimental results on our collected dataset illustrate the novelty of our proposed framework over the other existing PSM methods to be extended and updated to improve the quality of the OCRing system. The results show that the influence of PSM after expanding using the RoI types, language ID, and document/manuscript category can improve the OCRing accuracy. Also, the experimental results show significant performance by the new framework model with accuracy reached to 99% compared to relative methods. © 2023 Association for Computing Machinery.",TestAnalysis
"OBJECTIVE: The aim of the study is to assess the distinguishing features of pregnancy-related hypophysitis (PR-Hy) compared to non-pregnancy autoimmune hypophysitis and to evaluate the changing therapeutic approaches and outcomes in PR-Hy over time. DESIGN: Retrospective analysis of all published cases with PR-Hy and 6 own cases. METHODS: A PubMed search was performed and abstracts screened for publications with information on cases with PR-Hy from which full-text review was performed. Clinical features, diagnostic findings, and outcome in relation to treatment modalities in PR-Hy were assessed. RESULTS: One hundred and forty-eight cases with PR-Hy were identified. PR-Hy was significantly delimited from non-PR-Hy by the frequent occurrence of the chiasmal syndrome (50% vs 13%, P < .0001), higher rate of intrasellar origin (94% vs 74%, P = .0005), lower rate of pituitary stalk involvement (39% vs 86%, P < .0001), and low rate of diabetes insipidus (12% vs 54%, P < .0001). The role of surgery in PR-Hy decreased over time while noninvasive treatment modalities increased. The recurrence rate after high-dose glucocorticoid therapy (33%) was high and exceeded that of surgery (2%) and conservative management (2%). In contrast to initial reports on PR-Hy, recent literature regarding outcome of mother's and child's health was positive. The frequency of spontaneous preterm delivery was not increased. Recurrent PR-Hy in a subsequent pregnancy was reported in only two females. CONCLUSION: PR-Hy has distinct features that delineate the disorder from non-PR-Hy. With increasing experience in diagnosis, availability of adequate replacement therapy, and improved treatment modalities, PR-Hy has lost its threat and the outcome is encouraging. © The Author(s) 2023. Published by Oxford University Press on behalf of (ESE) European Society of Endocrinology. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com.",TestAnalysis
"Background: Single-session mental health interventions are frequently attended by children and young people (CYP) in both web-based and face-to-face therapy settings. The Session “Wants” and “Needs” Outcome Measure (SWAN-OM) is an instrument developed in a web-based therapy service to overcome the challenges of collecting outcomes and experiences of single-session therapies (SSTs). It provides pre-defined goals for the session, selected by the young person prior to the intervention, on which progress toward achievement is scored at the end of the session. Objective: The objective of this study was to evaluate the instrument's psychometric properties, including concurrent validity against three other frequently used outcome and experience measures, at a web-based and text-based mental health service. Methods: The SWAN-OM was administered for a period of 6 months to 1,401 CYP (aged 10–32 years; 79.3% white; 77.59% female) accessing SST on a web-based service. Item correlations with comparator measures and hierarchical logistic regressions to predict item selection were calculated for concurrent validity and psychometric exploration. Results: The most frequently selected items were “Feel better” (N = 431; 11.61%) and “Find ways I can help myself” (N = 411; 11.07%); unpopular items were “Feel safe in my relationships” (N = 53; 1.43%) and “Learn the steps to achieve something I want” (N = 58; 1.56%). The SWAN-OM was significantly correlated with the Experience of Service Questionnaire, particularly the item “Feel better” [rs(109) = 0.48, p < 0.001], the Youth Counseling Impact Scale, particularly the item “Learn the steps to achieve something I want” [rs(22) = 0.76, p < 0.001], and the Positive and Negative Affect Schedule, particularly the items “Learn how to feel better” [rs(22) = 0.72, p < 0.001] and “Explore how I feel” [rs(70) = −0.44, p < 0.001]. Conclusion: The SWAN-OM demonstrates good concurrent validity with common measures of outcome and experience. Analysis suggests that lesser-endorsed items may be removed in future iterations of the measure to improve functionality. Future research is required to explore SWAN-OM's potential to measure meaningful change in a range of therapeutic settings. Copyright © 2023 De Ossorno Garcia, Edbrooke-Childs, Salhi, Ruby, Sefi and Jacob.",TestAnalysis
"The quality of development documents written in natural language is basically ensured by developer’s review with quite a few man-hours. Natural language processing (NLP) tools can partially automate the time-consuming review. The authors have developed morpheme level pattern matching and processing tools morfgrep and morfawk for Japanese texts for this purpose; moreover, in this paper, extends them to perform pattern matching on dependency among phrases. Example applications of the tools, proofreading of development documents and domain-specific term extraction, are also presented. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",TestAnalysis
"The ability of the ancient Egyptians to preserve the human body through embalming has not only fascinated people since antiquity, but also has always raised the question of how this outstanding chemical and ritual process was practically achieved. Here we integrate archaeological, philological and organic residue analyses, shedding new light on the practice and economy of embalming in ancient Egypt. We analysed the organic contents of 31 ceramic vessels recovered from a 26th Dynasty embalming workshop at Saqqara1,2. These vessels were labelled according to their content and/or use, enabling us to correlate organic substances with their Egyptian names and specific embalming practices. We identified specific mixtures of fragrant or antiseptic oils, tars and resins that were used to embalm the head and treat the wrappings using gas chromatography–mass spectrometry analyses. Our study of the Saqqara workshop extends interpretations from a micro-level analysis highlighting the socio-economic status of a tomb owner3–7 to macro-level interpretations of the society. The identification of non-local organic substances enables the reconstruction of trade networks that provided ancient Egyptian embalmers with the substances required for mummification. This extensive demand for foreign products promoted trade both within the Mediterranean8–10 (for example, Pistacia and conifer by-products) and with tropical forest regions (for example, dammar and elemi). Additionally, we show that at Saqqara, antiu and sefet—well known from ancient texts and usually translated as ‘myrrh’ or ‘incense’11–13 and ‘a sacred oil’13,14—refer to a coniferous oils-or-tars-based mixture and an unguent with plant additives, respectively. © 2023, The Author(s).",TestAnalysis
"Introduction People often experience significant difficulties in receiving mental healthcare due to insufficient resources, stigma and lack of access to care. Remote care technology has the potential to overcome these barriers by reducing travel time and increasing frequency of contact with patients. However, the safe delivery of remote mental healthcare requires evidence on which aspects of care are suitable for remote delivery and which are better served by in-person care. We aim to investigate clinical and demographic associations with remote mental healthcare in a large electronic health record (EHR) dataset and the degree to which remote care is associated with differences in clinical outcomes using natural language processing (NLP) derived EHR data. Methods and analysis Deidentified EHR data, derived from the South London and Maudsley (SLaM) National Health Service Foundation Trust Biomedical Research Centre (BRC) Case Register, will be extracted using the Clinical Record Interactive Search tool for all patients receiving mental healthcare between 1 January 2019 and 31 March 2022. First, data on a retrospective, longitudinal cohort of around 80 000 patients will be analysed using descriptive statistics to investigate clinical and demographic associations with remote mental healthcare and multivariable Cox regression to compare clinical outcomes of remote versus in-person assessments. Second, NLP models that have been previously developed to extract mental health symptom data will be applied to around 5 million documents to analyse the variation in content of remote versus in-person assessments. Ethics and dissemination The SLaM BRC Case Register and Clinical Record Interactive Search (CRIS) tool have received ethical approval as a deidentified dataset (including NLP-derived data from unstructured free text documents) for secondary mental health research from Oxfordshire REC C (Ref: 18/SC/0372). The study has received approval from the SLaM CRIS Oversight Committee. Study findings will be disseminated through peer-reviewed, open access journal articles and service user and carer advisory groups. © 2023 BMJ Publishing Group. All rights reserved.",TestAnalysis
"Objectives. We recently studied the association between various human leukocyte antigen (HLA) alleles and end-stage renal disease (ESRD). According to our analysis, HLA-B*50 and HLA-DQA1*3 alleles were positively associated with ESRD, while B*40, DRB1*12, DRB1*13, and DQA1*6 alleles were negatively associated with ESRD. However, a single case-control study does not have enough statistical power to evaluate the possible impact of genetic polymorphism on any disease. Hence, the main objective of this meta-analysis is to determine the association between these abovementioned HLA alleles and ESRD. Design. MEDLINE/PubMed, EMBASE, Web of Science, and Cochrane databases were searched through December 2020 for case-control studies on the associations between HLA polymorphisms and ESRD. Independent reviewers screened the texts of potentially eligible studies and assessed the risk of bias. The meta-analysis was conducted based on the checklists and guidelines based on PRISMA. Results. We identified 26 case-control studies comprising 1,312 ESRD and 3,842 healthy subjects. A non-significant positive association was observed between HLA-B*50 (OR = 1.02, 95% CI [0.90, 1.24]), HLA-B*40 (OR = 1.75, 95% CI [0.98, 3.2]), HLA-DQA1*3, (OR = 1.17, 95% CI [0.74, 1.84]), DRB1*12 (OR = 1.05, 95% CI [0.94, 1.18]) alleles and ESRD. In addition, a non-significant negative association was observed between HLA-DRB1*13 (OR = 0.90, CI [0.81, 1.01]), HLA-DQB1*6 (OR = 0.79, 95% CI [0.58, 1.07]) alleles and ESRD. Conclusions. Our meta-analysis indicates no significant association between HLAB*50, HLA-DQA1*3, B*40, DRB1*12, DRB1*13, and DQA1*6 alleles and ESRD. Further studies with larger sample sizes and adjustments for confounders are required to confirm these conclusions. Copyright 2023 Noureen and Zaidi.",TestAnalysis
"Introduction: The present systematic review and meta-analysis explores the impacts of cognitive processing therapy (CPT), eye movement desensitization and reprocessing (EMDR), and prolonged exposure (PE) therapy on neural activity underlying the phenomenon of post-traumatic growth for adult trauma survivors. Methods: We utilized the following databases to conduct our systematic search: Boston College Libraries, PubMed, MEDLINE, and PsycINFO. Our initial search yielded 834 studies for initial screening. We implemented seven eligibility criteria to vet articles for full-text review. Twenty-nine studies remained for full-text review after our systematic review process was completed. Studies were subjected to several levels of analysis. First, pre-and post- test post-traumatic growth inventory (PTGI) scores were collected from all studies and analyzed through a forest plot using Hedges’ g. Next, Montreal Neurological Institute (MNI) coordinates and t-scores were collected and analyzed using an Activation Likelihood Estimation (ALE) to measure brain function. T-scores and Hedges’ g values were then analyzed using Pearson correlations to determine if there were any relationships between brain function and post-traumatic growth for each modality. Lastly, all studies were subjected to a bubble plot and Egger’s test to assess risk of publication bias across the review sample. Results: Forest plot results indicated that all three interventions had a robust effect on PTGI scores. ALE meta-analysis results indicated that EMDR exhibited the largest effect on brain function, with the R thalamus (t = 4.23, p < 0.001) showing robust activation, followed closely by the R precuneus (t = 4.19, p < 0.001). Pearson correlation results showed that EMDR demonstrated the strongest correlation between increased brain function and PTGI scores (r = 0.910, p < 0.001). Qualitative review of the bubble plot indicated no obvious traces of publication bias, which was corroborated by the results of the Egger’s test (p = 0.127). Discussion: Our systematic review and meta-analysis showed that CPT, EMDR, and PE each exhibited a robust effect on PTG impacts across the course of treatment. However, when looking closer at comparative analyses of neural activity (ALE) and PTGI scores (Pearson correlation), EMDR exhibited a more robust effect on PTG impacts and brain function than CPT and PE. Copyright © 2023 Pierce, Johnson, Kim, Lear, Mast and Black.",TestAnalysis
"Data charts are very prevalent in everyday life in different contexts, from economics to politics. However, people with blindness and low vision do not have easy access to this information since they use screen reader software. This software does not extract the information available graphically, but only the chart legend and the text. Among the solutions proposed in the literature, there are crowdsourcing techniques when a person is responsible for interpreting the chart, which can cause bias in the chart’s interpretation. To solve this problem, we proposed textual description templates for simple and grouped bar charts to inform the chart data in a standardized way to users, excluding the interpretation bias. The methodology of this work was divided into three stages: a definition of templates for textual description and testing with 30 participants; the application of textual description templates in an assistive technology tool and testing with 45 participants; the validation of the results found through interviews and tests with 3 specialists. We have iteratively refined templates generated at each stage with users tests, and we carried out quantitative and qualitative analyses. An assistive technology tool, ChartVision, was developed to consume the templates. Finally, we interviewed a specialist about how he would explain chart materials to blind students at university, and we carried out a validation of the final templates with two other professionals from the health and education areas who deal with people with blind people in their daily lives. The main contributions are three textual description bar charts templates: simple bar for applications with sequential reading or reading on-demand, grouped bar for applications with sequential reading, and grouped bar for applications on-demand. The secondary contribution is ChartVision. Other findings include considerations about the synthetic voice used in the tests, expected characteristics for a better understanding of the chart, and interaction ways to access the information. © 2023, Brazilian Computing Society. All rights reserved.",TestAnalysis
"Nowadays, the application of machine learning for developing prediction models is one of the most critical research areas. Early prediction of anti-patterns using machine learning can help developers, and testers fix the design issues and utilize the resources effectively. This work analyzes four different sets of metrics, i.e., source code, WSDL, text, and sequence metrics, to develop web service anti-pattern prediction models. These sets of metrics are treated as an input for models trained using thirty-eight classification techniques to build a model. The experimental finding shows that the models trained using sequence metrics produce better results. The experimental finding also confirmed that the models trained on balanced data achieved better performance than the original data. Further, it is also found that the models trained using CNN and LSTM deep learning approach achieve better results compared to other techniques. © 2023 ACM.",TestAnalysis
"Introduction Health inequities are differences in health between groups of people that are avoidable, unfair and unjust. Achieving equitable health outcomes requires approaches that recognise and account for the differences in levels of advantage between groups. Implementation science, which studies how to translate evidence-based interventions into routine practice, is increasingly recognised as an approach to address health inequities by identifying factors and processes that enable equitable implementation of interventions. This article describes the protocol for a scoping review of the literature relating to the equitable implementation of interventions, focusing on ethnicity-related health inequities. The scoping review aims to identify equity-focused implementation science theories, models and frameworks (TMFs) and to synthesise and analyse the evidence relating to the factors that aid or inhibit equitable implementation of health interventions. Methods and analysis The scoping review is guided by the methodology developed by Arksey and O'Malley and enhanced by Levac and colleagues. Relevant literature will be identified by searching electronic databases, grey literature, hand-searching key journals and searching the reference lists and citations of studies that meet the inclusion criteria. We will focus on literature published from 2011 to the present. Titles, abstracts and full-text articles will be screened independently by two researchers; any disagreements will be resolved through discussion with another researcher. Extracted data will be summarised and analysed to address the scoping review aims. Ethics and dissemination The scoping review will map the available literature on equity-focused implementation science TMFs and the facilitators and barriers to equitable implementation of interventions. Ethical approval is not required. Dissemination of the results of the review will include publications in peer-review journals and conference and stakeholder presentations. Findings from the review will support those implementing interventions to ensure that the implementation pathway and processes are equitable, thereby improving health outcomes and reducing existing inequities. © Author(s) (or their employer(s)) 2023.",TestAnalysis
"Objectives To chart the global literature on gender equity in academic health research. Design Scoping review. Participants Quantitative studies were eligible if they examined gender equity within academic institutions including health researchers. Primary and secondary outcome measures Outcomes related to equity across gender and other social identities in academia: (1) faculty workforce: representation of all genders in university/faculty departments, academic rank or position and salary; (2) service: teaching obligations and administrative/non-teaching activities; (3) recruitment and hiring data: number of applicants by gender, interviews and new hires for various rank; (4) promotion: opportunities for promotion and time to progress through academic ranks; (5) academic leadership: type of leadership positions, opportunities for leadership promotion or training, opportunities to supervise/mentor and support for leadership bids; (6) scholarly output or productivity: number/type of publications and presentations, position of authorship, number/value of grants or awards and intellectual property ownership; (7) contextual factors of universities; (8) infrastructure; (9) knowledge and technology translation activities; (10) availability of maternity/paternity/parental/family leave; (11) collaboration activities/opportunities for collaboration; (12) qualitative considerations: perceptions around promotion, finances and support. Results Literature search yielded 94 798 citations; 4753 full-text articles were screened, and 562 studies were included. Most studies originated from North America (462/562, 82.2%). Few studies (27/562, 4.8%) reported race and fewer reported sex/gender (which were used interchangeably in most studies) other than male/female (11/562, 2.0%). Only one study provided data on religion. No other PROGRESS-PLUS variables were reported. A total of 2996 outcomes were reported, with most studies examining academic output (371/562, 66.0%). Conclusions Reviewed literature suggest a lack in analytic approaches that consider genders beyond the binary categories of man and woman, additional social identities (race, religion, social capital and disability) and an intersectionality lens examining the interconnection of multiple social identities in understanding discrimination and disadvantage. All of these are necessary to tailor strategies that promote gender equity. Trial registration number Open Science Framework: https://osf.io/8wk7e/. © 2023 BMJ Publishing Group. All rights reserved.",TestAnalysis
"The paper presents an analysis of standard Belarusian modals of necessity, based on the Belacorpus, a corpus of contemporary written Belarusian I built in 2010. I investigate the modals’ semantics (which types of modality they express), their frequency in the corpus and their distribution across textual genres. My study confirms what was already observed in previous accounts of Belarusian modals. Namely, only two of them, music’ and pavinen, are polyfunctional (that is, they can express more than one type of modality – dynamic, deontic and epistemic) and thus prototypical (core) members of the modal category. All other modal expressions are dedicated to one type of modality and are thus peripheral. The corpus analysis has also revealed a number of previously unnoticed properties of Belarusian modals, such as: the extreme rarity of the epistemic use of polyfunctional music’ and pavinen; the uneven distribution of peripheral modals across different types of texts; and the fact that the two standards in which Belarusian is codified, taraškevica and narkamaŭka, present no significant difference as far as the use of modals is concerned, with the notable exception of modal mec’ ‘have’, which is much more frequent in taraškevica texts. © 2022 Author(s).",TestAnalysis
"BACKGROUND: Patient decision aids (PDAs) are tools designed to facilitate decision-making. In this systematic review, we summarized existing studies on the development and evaluation of PDAs for patients with hematologic malignancies. PATIENTS AND METHODS: We followed the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. We searched for articles in PubMed, Embase, Web of Science, Cochrane Central Register of Controlled Trials, and ClinicalTrials.gov. We included studies, abstracts, and clinical trial protocols available in English involving PDAs for patients age ≥18 diagnosed with a hematologic malignancy and/or their caregivers. Data were summarized using descriptive statistics. RESULTS: Of the 5281 titles/abstracts screened, 15 were included: 1 protocol, 7 abstracts, and 7 full-texts. Six were PDA developmental studies, 6 were pilot studies, and 3 were randomized trials. PDA formats included electronic with web content, videos, and/or audio, questionnaires, bedside instruments, and a combination of various formats. Average participant age ranged from 36.0 to 62.4 years. Patients and caregivers identified efficacy, adverse effects, cost, and quality of life as important decision-making factors. PDAs were associated with increased knowledge and patient satisfaction as well as decreased decisional conflict and attitudinal barriers. Research on PDAs for adult patients with hematologic malignancies and their caregivers is limited. Among the studies, PDAs appear to support patients in shared decision-making. CONCLUSION: While current literature examining the use of PDAs for adults with hematologic malignancies is limited, the positive impact of PDAs on shared decision-making and patient outcomes warrants additional research in this field. © The Author(s) 2022. Published by Oxford University Press.",TestAnalysis
"Remote simultaneous interpreting (RSI) draws on Information and Communication Technologies (ICTs) to facilitate multilingual communication by connecting conference interpreters to in-presence, virtual or hybrid events. Early solutions for RSI involved interpreters working in interpreting booths with physical hardware. However, in recent years, cloud-based solutions for RSI have emerged, with innovative Simultaneous Interpreting Delivery Platforms (SIDPs) at their core, enabling RSI delivery from anywhere. Initial explorations of the cloud-based solutions suggest that there is room for improving many of the widely used SIDPs. This chapter outlines an ongoing experimental study that investigates two aspects of SIDPs: the design of the interpreter interface and the integration of automatic speech recognition (ASR) in the interface to aid/augment the interpreter's source-text comprehension. Preliminary pilot study data suggests that interpreters have a preference towards cleaner interfaces with a better view of the speaker's hand gestures and body language. Performance analysis of a subsample of three participants indicates that while the most experienced interpreter had a similar performance across different experimental conditions (i.e., presentation of source speech with/without ASR-generated transcript), differences were apparent for the other two interpreters. © Peter Lang GmbH. International Academic Publishers Berlin 2023. All rights reserved.",TestAnalysis
"Background: The number of psychological studies on conspiracy beliefs has been systematically growing for about a dozen years, but in recent years, the trend has intensified. We provided a review covering the psychological literature on conspiracy beliefs from 2018 to 2021. Halfway through this period, the COVID-19 pandemic broke out, accompanied by an explosion of movements based on conspiracy theories, intensifying researchers’ interest in this issue. Methods: Adhering to PRISMA guidelines, the review systematically searched for relevant journal articles published between 2018 and 2021. A search was done on Scopus and Web of Science (only peer-reviewed journals). A study was included if it contained primary empirical data, if specific or general conspiracy belief(s) were measured and if its correlation with at least one other psychological variable was reported. All the studies were grouped for the descriptive analysis according to the methodology used, the participants’ characteristics, the continent of origin, the sample size, and the conspiracy beliefs measurement tools. Due to substantial methodological heterogeneity of the studies, narrative synthesis was performed. The five researchers were assigned specific roles at each stage of the analysis to ensure the highest quality of the research. Results: Following the proposed methodology, 308 full-text articles were assessed for eligibility and 274 articles (417 studies) meeting the inclusion criteria were identified and included in the review. Almost half of the studies (49.6%) were conducted in European countries. The vast majority of the studies (85.7%) were carried out on samples of adult respondents. The research presents antecedents as well as (potential) consequences of conspiracy beliefs. We grouped the antecedents of conspiracy beliefs into six categories: cognitive (e.g., thinking style) motivational (e.g., uncertainty avoidance), personality (e.g., collective narcissism), psychopathology (e.g., Dark Triad traits), political (e.g., ideological orientation), and sociocultural factors (e.g., collectivism). Conclusion and limitations: The research presents evidence on the links between conspiracy beliefs and a range of attitudes and behaviors considered unfavorable from the point of view of individuals and of the society at large. It turned out that different constructs of conspiracy thinking interact with each other. The limitations of the study are discussed in the last part of the article. Copyright © 2023 Pilch, Turska-Kawa, Wardawy, Olszanecka-Marmola and Smołkowska-Jędo.",TestAnalysis
"Many countries have governmental fisheries science organizations, each of which should play a critical role in achieving ocean sustainability by leading the fisheries science in each country’s specific contexts and beyond. In the context of the UN Decade of Ocean Science (UNDOS), understanding the interface of science, policy, and public interest around fisheries is increasingly recognized as critically important for realizing effective knowledge exchange and co-creating desired futures. This study aims to illuminate the interface of the above three facets as a guide to have better outcomes in the UNDOS timeframe. We used a case study of Japan – a country with extensive seafood production and consumption, and analyzed 1) the scientific performance of the Japan Fisheries Research and Education Agency (JFRA), a national fisheries research organization in the country through peer-reviewed papers published by JFRA researchers from 2004–2018, 2) policy needs through annual white papers published by Fisheries Agency from 1989–2018, and 3) public interest around fisheries through public inquiry logs accumulated at JFRA from 2004–2018. The results indicated the following: 1) JFRA was originally a part of fisheries policies, and both science and policy were inherently based on the fisheries practices in the “real world” in Japan. However, over the last fifteen years, the scientific performance has heavily focused on bio-physical dimensions of fisheries such areas as “Stock assessment,” “Fisheries Oceanography,” and “Stock enhancement.” 2) Japanese fisheries policy priority has shifted from relatively simple, straightforward keywords focusing on primary fisheries production (from 1989 to 1998) to more complex, multidimensional fisheries systems, including marine resources, producers, processors, and consumers in/outside of the country (from 2009–2018) over the last three decades. 3) Public fisheries/ocean literacy seems limited, despite the rich history of seafood consumption, cultural bond with fisheries, and inherent close relationship among fisheries science, policy, and resource users. Based on the results, we discuss that JFRA sciences, fisheries policy, and the public are contemporary pursuing different interests. To overcome this situation, one important area that JFRA (and any other marine/fisheries research organizations) needs is to reconnect science and public interest through strengthening human dimension works and science communication. For the public side, literacy development among wider stakeholders is one of the most emergent works to be addressed. This is one of the first case studies of science-policy-public interface through empirical data, particularly with the public inquiry log, and the “non-Western” country case study on this topic. This will encourage other empirical studies from countries with various social/cultural/political backgrounds to enrich the perspective of fisheries science-policy-public interface studies globally. Copyright © 2023 Sugimoto, Tajima, Sugaya and Watari.",TestAnalysis
"The article presents the results of research on the absolute chronology of the NiŽná Myšľa cemetery. Due to its scale and location in a key region of the Carpathian Basin, it should be considered one of the most important Early Bronze Age sites in Central Europe. Many years of archaeological research have so far failed to provide adequate data on absolute chronology. This text presents the results of statistical and spatial analyses on a series of newly acquired 14C dates. They allowed us to present a model of the spatial and chronological development of the funerary space and to capture the stage of significant cultural change associated with the adoption of a new raw material - bronze.  © The Author(s), 2022. Published by Cambridge University Press for the Arizona Board of Regents on behalf of the University of Arizona.",TestAnalysis
"Critical thinking skills are increasingly imperative skills in the nursing profession. Both the Socratic method and nursing theorist philosophy can lead to enhance critical skills. The Socratic method has been rooted in ancient Greek Philosophy, whereas nursing theorist philosophy in the 21st century. This paper discusses critical thinking in the nursing profession and compares the critical thinking concept with the Socratic Method and nurse theorist philosophy. The prime aim of this study is to compare which method is effectively utilized in the nursing profession. The literature pertinent to the topic was searched using the database library, including PubMed, BioMed, Google Scholar, PakMediNet, and Cumulative Index to Nursing and Allied Health Literature CINAHL. Literature was searched using keywords including Socratic method, nurse theorist philosophy, critical thinking skills, nursing education, and nursing clinical practice. The full-text article was included in the study. Relevant original articles, systemic reviews, quasi-experimental design, philosophical papers, and cross-sectional studies focusing on nurses' critical thinking skills, the Socratic Method, and nurse theorist philosophy were included. The study analysis portrayed Socratic questioning as primarily embedded in critical thinking concepts which nurses utilized in theoretical knowledge. The Socratic Method is explicitly known as the student-centered method that probes critical thinking in classroom teachings. Critical thinking has become vital in professional accountability and excellent nursing care. Nurse theorists have generally employed critical thinking skills to obtain the maximum patient care outcome. In conclusion, the Socratic method increases critical thinking in academia while nursing’s theorist philosophy in nursing clinical practice. © 2023, University of Faisalabad. All rights reserved.",TestAnalysis
"The chapter proposes to investigate online reputation of hospitality brands and its measurements. Brand reputation is generally defined as an overall appraisal of a company by its stakeholders, which is the result of the company's past actions and predictions about the company's future (Ferguson, Deephouse, & Ferguson, 2000). Being viewed as the opinion shared among a group of stakeholders (Dowling, 2008), it plays an important role in the tourism industry. With the progress of Information Communication Technologies (ICTs), reviews and user-generated contents of destinations and of hospitality companies together with the related emerging brand reputation can influence consumers' behaviors and choices. Brand reputation analysis could be more useful in the hospitality brand management when integrated with brand image and brand identity analysis, mainly because in tourism businesses and destinations, brands are typically affected by an inherent fragility determined by the service nature of products (Casarin, 1996). According to Biel (1991), the meanings that consumers assign to a brand are synthesized into brand associations formed by the components perceived to underlie the brand's image. As well as brand reputation, strong, positive and unique associations reinforce a brand and increase its equity that requires significant internal brand identity efforts, which should create a corresponding brand image through integration in overall marketing programmes (Keller, 2003). It makes sense to develop an analytical research approach that compares online brand reputation (OBR) with brand association matching as a measure of the alignment between brand identity and brand image in hospitality companies. This comparative analysis emerging from brand reputation, brand image and brand identity analysis can reveal divergent situations (i.e., high brand reputation and low brand association matching) and orient brand managers in reviewing online brand communication. Brand reputation and brand image analysis will be contextualized in an online community as a social setting that is considered to be a new type of market (Muniz & O'Guinn, 2001). We focus on hospitality online communities populated by consumers and other actors such as influencers and bloggers: their brand perception could be separately compared with brand identity that we will extract from company communications including presentational information and brand-related press releases found on websites, nonfinancial narrative from annual reports, and interviews with managers published in mainstream media sources. In our analysis we will focalize on a cluster of luxury hospitality companies integrating a netnographic and text-mining techniques. We will use both the techniques in order to (1) extract and study brand associations in terms of brand reputation, brand image, and brand identity; (2) develop indicators of brand reputation and brand association matching; and (3) discuss their utility in the management of the hospitality company brands. © 2023 Silvia Ranfagni and Massimo Rosati. All rights reserved.",TestAnalysis
"Importance: Counseling prior to thyroid cancer (TC) treatment is an essential component of informed consent. An informed patient affects treatment-related expectations and patient engagement, factors that contribute significantly to patient-reported quality-of-life outcomes. Objective: To describe experiences with pretreatment counseling among survivors of TC and to test factors associated with self-reported treatment meeting expectations. Design, Setting, and Participants: A cross-sectional survey was administered between October 18, 2019, and February 8, 2020, to members of ThyCa: Thyroid Cancer Survivors' Association Inc, and to individuals accessing the public-facing ThyCa website. Survey respondents were asked 55 questions, including 4 free-text questions and 2 multiple-choice questions about pretreatment counseling. Main Outcomes and Measures: Respondents self-reported (1) their unmet information needs, (2) rates of treatment meeting expectations, and (3) rates of treatment understanding. A mixed-methods analysis was performed, including qualitative content analysis of free-text responses and multivariable logistic regression of factors associated with self-reported levels of treatment meeting expectations. Results: Of the 1412 survey respondents, 1249 were women (88.4%). The median age at diagnosis was 48 years (range, 18-85 years), and the median age at the time of survey completion was 60 years (range, 18-87 years). A total of 1259 respondents (89.2%) provided free-text responses to the question, ""What would you tell someone newly diagnosed with your same condition?""Of these individuals, 526 (37.2%) reported inadequate pretreatment plan understanding and 578 (40.9%) reported that their treatment experience did not meet their expectations. Treatment met expectations for only 95 respondents (18.1%) reporting an inadequate pretreatment plan understanding. Of the 526 survivors of TC reporting a lack of understanding, 473 (90.0%) provided additional textual comments, most commonly in the categories of postoperative treatment, surveillance, and treatment effects. On multivariable logistic regression, self-reported failure to have an understanding of TC treatment was independently associated with failure of treatment to meet expectations (odds ratio, 5.1 [95% CI, 3.7-6.9]). Patients reporting a full understanding of their treatment plan were 5-fold more likely to indicate that their initial treatment experience was on par with expectations, independent of reported postoperative complications, age, sex, and other potential confounders. Conclusions and Relevance: In this survey study, a substantial proportion of survivors of TC reported inadequate pretreatment understanding. This gap in understanding was associated with high levels of self-reported failure of treatment to meet expectations, which in turn is associated in other studies with poorer patient-reported quality-of-life outcomes. These outcomes may be improved by addressing gaps in patient understanding so expectations more closely match TC diagnosis and treatment pathways..  © 2022 American Medical Association. All rights reserved.",TestAnalysis
"The main problem of translation lies in the method used by the translator. Newmark suggests in theory eight translation methods commonly used by ""human"" translators in translating texts. However, whether this theory also applies to machine translators is a question that this study attempts to answer. More specifically, this study aims to analyze the translation method used by Facebook Auto Translation (FAT) in translating Arabic-Indonesian based on Newmark's V diagram theory. This research is a combination of quantitative and qualitative research. Data mapping was carried out quantitatively, then data analysis was carried out qualitatively, in which the collection, analysis and presentation of data was carried out descriptively.The results showed that by the 58 posts and their translated results analyzed, the researchers found that FAT only applied two of the eight methods proposed by Newmark. The two methods are word-for-word translation and literal translation. A total of 6 translation results (10.34%) are classified as word-for-word translations and 52 translation results (89.66%) are classified as literal translations. The translation method applied by FAT is dominated by literal translation because basically Arabic grammar and Indonesian grammar are different. Arabic has a predicate + subject sentence pattern, although there are also some that have a subject + predicate pattern. Besides that, Arabic also has additional letters or words to verbs which do not have to be translated into Indonesian but must still be in the text because their role is very important in determining meaning. The difference in grammatical structure causes the order of translation to also change so that FAT applies more literal translation methods. © 2023, Ismail Saritas. All rights reserved.",TestAnalysis
"Objective Recent deaths of Indigenous patients in the Canadian healthcare system have been attributed to structural and interpersonal racism. Experiences of interpersonal racism by Indigenous physicians and patients have been well characterised, but the source of this interpersonal bias has not been as well studied. The aim of this study was to describe the prevalence of explicit and implicit interpersonal anti-Indigenous biases among Albertan physicians. Design and setting This cross-sectional survey measuring demographic information and explicit and implicit anti-Indigenous biases was distributed in September 2020 to all practising physicians in Alberta, Canada. Participants 375 practising physicians with an active medical licence. Outcomes Explicit anti-Indigenous bias, measured by two feeling thermometer methods: participants slid an indicator on a thermometer to indicate their preference for white people (full preference is scored 100) or Indigenous people (full preference, 0), and then participants indicated how favourably they felt toward Indigenous people (100, maximally favourable; 0, maximally unfavourable). Implicit bias was measured using an Indigenous-European implicit association test (negative scores suggest preference for European (white) faces). Kruskal-Wallis and Wilcoxon rank-sum tests were used to compare bias across physician demographics, including intersectional identities of race and gender identity. Main results Most of the 375 participants were white cisgender women (40.3%; n=151). The median age of participants was 46-50 years. 8.3% of participants felt unfavourably toward Indigenous people (n=32 of 375) and 25.0% preferred white people to Indigenous people (n=32 of 128). Median scores did not differ by gender identity, race or intersectional identities. White cisgender men physicians had the greatest implicit preferences compared with other groups (-0.59 (IQR-0.86 to-0.25); n=53; p<0.001). Free-text responses discussed â € reverse racism' and expressed discomfort with survey questions addressing bias and racism. Conclusions Explicit anti-Indigenous bias was present among Albertan physicians. Concerns about â € reverse racism' targeting white people and discomfort discussing racism may act as barriers to addressing these biases. About two-thirds of respondents had implicit anti-Indigenous bias. These results corroborate the validity of patient reports of anti-Indigenous bias in healthcare and emphasise the need for effective intervention.  © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.",TestAnalysis
"Insufficient knowledge of chemical hazards can cause unsafe behaviors, diseases, and accidents in the laboratory, hence educational interventions are significant. Due to its unique qualities, distance learning via educational applications has grown dramatically. This study aimed to determine the efficacy of a safety training intervention via social media applications on the safety knowledge of staff and students at Shahid Beheshti University of Medical Sciences. A total of 166 staff and students at the laboratories of schools and research centers affiliated with Shahid Beheshti University of Medical Sciences were randomized to an experimental group and a control group. A training package was prepared including text, GIF, and video messages on the Globally Harmonized System of classification and labeling of Chemicals (GHS), and the experimental group received a one month training via a common messenger platform in Iran (Telegram). Participants' chemical safety knowledge was assessed before and after the intervention. A validated questionnaire including 24 multiple-choice items in text format and 13 multiple-choice items in image format as well as demographic items was employed to collect data. Shapiro-Wilk, independent t test, and analysis of covariance were used to analyze the data. In the textual section of the questionnaire, the most frequently answered item concerned the ""reason for choosing a respirator"", and the least frequently answered ones were ""meaning of warning""and ""meaning of hazard"". Environmental hazard and oxidation risk received the most frequent correct answers in the visual section. After the intervention, the control and experimental groups' knowledge scores were 64.7 ± 10.1 and 79.2 ± 8.4, respectively. According to the covariance test, the training intervention improved participants' knowledge significantly (p < 0.001). Training interventions through social media can improve GHS knowledge. Moreover, visual messages are easier to understand and transfer than textual ones.  © 2023 American Chemical Society.",TestAnalysis
"Text summarization is a process of generating a concise summary of a given text. It is a popular research topic, and many studies have used sequence-to-sequence deep neural network models such as Long Short Term Memory (LSTM) or Gated Recurrent Unit (GRU) to tackle it. These models consist of two phases: encoding the input text and generating the summary. However, these models may lose information during the encoding phase, particularly when using deep layers, leading to inaccurate summaries. In this paper, we propose a bi-directional LSTM model with a Recurrent Residual Attention mechanism to address this issue. We tested our model on the Amazon Reviews dataset from the Stanford Network Analysis Project and found that it performed better than standard LSTM models and outperformed previous studies.  © 2023 ACM.",TestAnalysis
"Importance: Rights and access for transgender individuals, including the participation of transgender athletes in sports, have long been debated. These discussions often center around fairness and mental health impacts on youths associated with identity-based inclusion in sports. Objective: To assess the experiences and perspectives of adolescents and young adults on the inclusion of transgender individuals in competitive sports. Design, Setting, and Participants: In this qualitative study, 5 open-ended survey questions were sent to the MyVoice cohort from December 10 to 17, 2021. MyVoice is a nationwide text-message polling platform of US youths aged 14 to 24 years. All coding and subsequent analysis was completed between January 10 and December 11, 2022. Main Outcomes and Measures: Qualitative perspectives of youths regarding transgender athlete participation in sports as measured by survey responses. Responses were reviewed using an inductive approach to qualitative thematic analysis to develop a codebook. The codes were independently applied to all responses by 2 investigators; discrepancies were resolved with discussion. Summary statistics were calculated for demographic characteristics and code frequencies, and χ2 tests (α =.05, 2-tailed) were used to evaluate differences in opinion based on gender identity and participation in competitive sports. Results: A total of 905 of 1199 youths (75%) responded to the survey. Respondents had a mean (SD) age of 20 (2) years; 482 (53%) identified as male, 29 (3%) identified as transgender, and 306 (34%) reported having participated in high school and/or collegiate athletics. Three themes emerged: (1) youths differed regarding the inclusion of transgender athletes based on gender identity vs sex assigned at birth, (2) many youths did not have personal experience related to the inclusion of transgender athletes, and (3) youths were uncertain about the impacts of gender identity-based participation on cisgender individuals but perceived positive impacts for transgender individuals. Nearly half of respondents (327 of 691 [47%]) thought that transgender athletes should participate based on their gender identity or personal preference, whereas 240 (35%) favored participation based on sex assigned at birth or in a transgender-only category. Respondents mentioned concern about the fairness of identity-based participation, specifically for cisgender women, but many (410 of 697 [59%]) also reported that it would be affirming for transgender athletes to participate based on gender identity. Conclusions and Relevance: The youths in our study differed in their opinions regarding sports participation of transgender youths, but many felt that inclusive policies would affirm and support the mental health of transgender individuals. Negative impacts on fairness were noted by some respondents. These findings suggest that nuanced policies are needed to address the participation of transgender athletes in competitive sports and should consider the impacts on and perspectives of youths most affected..  © 2022 American Medical Association. All rights reserved.",TestAnalysis
"The impact of mega-events on the tourism destinations image (TDI) has a time-series dynamic feature, and the analysis of the inner mechanism is conducive to promoting destination marketing and competitiveness. This paper adopted Python data mining technology and natural language processing technology (NLP) to crawl the travel reviews of well-known domestic travel websites and established a dataset based on long time series and large sample data. The analysis framework is constructed from the “cognitive-emotional-overall” dimensions to explore the temporal change of Zhangjiakou's TDI during the bidding period, preparation period and warm-up period of the 2022 Winter Olympic Games. In this way, the potential impact and mechanism of the Winter Olympics on the TDI in a special period and in a specific way can be analyzed. The results show that: (1) The composition elements of Zhangjiakou's TDI are becoming increasingly diversified and the effect of the Winter Olympics is becoming more and more significant. The key degree of ice and snow tourism image under the influence of the Winter Olympics is increasing, and it has experienced the refinement process of changing from vague to concrete image. Positive emotions are becoming more prevalent. (2) The Winter Olympic Games have a progressive influence on the TDI of Zhangjiakou City, which exerts its effect through the construction of tourism experience, the projection of image and the halo effect of brand perception. The Winter Olympics promote product innovation, infrastructure upgrade and service level improvement in Zhangjiakou, which will have a positive impact on the TDI by improving the visitor experience. This paper explores the dynamic impact path of the Games on the changing image of city tourism, which is a guide for host cities to change the TDI through festivals and post-event marketing. © 2023, Science Press. All rights reserved.",TestAnalysis
"Digital literature can become an interesting tool to arouse interest in literary texts among students of Secondary, Baccalaureate and Vocational Training. This article analyses some characteristics of electronic literature that make it attractive to digital natives and that can be of great help in developing reading comprehension skills. Several examples are presented that constitute transpositions of canonical works. This fact favours that they can be used in the classroom as an entrance to the original works. At the end, we suggest the possibility of developing a teaching practice based on the concept of transposition and rewriting for future courses. © GKA Ediciones, authors.",TestAnalysis
"This study examined published articles concerning sports leadership within the sport psychology domain over the last 30 years using bibliometric analysis that centered on the written content of the publications as unit of analysis in order to explore the intellectual base, particularly the structural relationships among relevant research components about coach leadership. Leximancer version 5.0 (Leximancer Pty Ltd.) was used to extract data from 100 sports leadership-related articles from four sport psychology journals. Overall, the most relevant concepts generated were coaches (100%) and athletes (59%), followed by study, sport, support, and motivation, and behaviors. Also, relevant concepts produced for each journal were quite similar which included coaches, athletes, behaviors, study, support and team. Further, publications related to coach leadership have shown a steady growth rate since 1990 with 76% of all published articles were conducted via quantitative research method. Finally, United States, Canada, the United Kingdom, and Belgium were the top countries involved in the area of coach leadership. Coach leadership studies generally focus on behaviors and perceptions related to the coach and relationships between leadership and psychological outcomes. Each journal has a similar but distinct rationale when publishing papers about coach leadership. Bibliometric analysis can be applied as an alternative methodology to summarize large volumes of relevant data in order to map the current knowledge as well as identify potential future research directions. Copyright © 2023 Cruz and Kim.",TestAnalysis
"Background: 'Neurodisability' refers to a group of conditions that result primarily from a neurological problem (e.g. cerebral palsy), neuromuscular problem (e.g. a muscular dystrophy) or developmental problems (e.g. developmental impairment, Down syndrome). Children and young people with these conditions may have similar problems with mobility, feeding and airway clearance. Chest and breathing problems (including pulmonary infections) are commonly experienced by children and young people with neurodisabilities and are often a cause for them requiring hospital care. For those who are unable to completely clear their airway of secretions, or have frequent infections, pulmonary infections may not be able to be completely eradicated and therefore become chronic. It is unclear what treatment is best for children and young people in this position. Objectives: To assess the effectiveness and adverse effects of antibiotic treatment for chronic pulmonary infection in children and young people living with a neurodisability, including quality-of-life measures, effects on hospitalisation and healthcare contacts. Search methods: We searched the Cochrane Airways Trials Register, Cochrane Acute Respiratory Infections Group Register of Trials (CARIGRT), Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE (Ovid), Embase (Ovid), Cumulative Index to Nursing and Allied Health Literature (CINAHL), OpenGrey (www.opengrey.eu) and three trials registries up to 8 February 2022. Additionally, we identified related systematic reviews through Epistemonikos.org (8 February 2022) and searched reference lists of these. Selection criteria: All randomised controlled trials of antibiotic therapy for chronic pulmonary infection in children and young people up to the age of 18 living with a neurodisability were eligible. Data collection and analysis: Two independent review authors screened results of the searches against predetermined inclusion criteria, resolving any discrepancies by discussion. Main results: We identified a total of 1968 independent records through our searches, of which we assessed six full-text articles for eligibility. We identified one ongoing study as well as one related substudy but did not identify any completed studies eligible for inclusion in this systematic review. Authors' conclusions: The findings of this systematic review highlight a lack of evidence in the antibiotic treatment of chronic pulmonary infection in children and young people up to the age of 18 living with a neurodisability. Further research examining this topic is therefore required. Copyright © 2023 The Cochrane Collaboration. Published by John Wiley & Sons, Ltd.",TestAnalysis
"Background: Cognitive impairment is one of the common sequelae after stroke, which not only hinders the recovery of patients but also increases the financial burden on families. In the absence of effective therapeutic measures, acupuncture treatment has been widely used in China to treat post-stroke cognitive impairment (PSCI), but the specific efficacy is unclear. Therefore, this review aimed to evaluate the true efficacy of acupuncture treatment in patients with PSCI. Methods: We searched eight databases [PubMed, Embase, Web of Science, Cochrane Central Register of Controlled Trials, China Biomedical Literature Database (CBM), China Science and Technology Journal (VIP) database, the China National Knowledge Infrastructure (CNKI) database, and Wan fang database] from the inception to May 2022 for randomized controlled trials (RCTs) related to acupuncture treatment combined with cognitive rehabilitation (CR) for PSCI. Two investigators independently used a pre-designed form to extract valid data from eligible RCTs. The risk of bias was assessed through tools provided by the Cochrane Collaboration. The meta-analysis was implemented through Rev Man software (version 5.4). The strength of the evidence obtained was evaluated using GRADE profiler software. Adverse events (AEs) were collected by reading the full text and used to evaluate the safety of acupuncture treatment. Results: Thirty-eight studies involving a total of 2,971 participants were included in this meta-analysis. Overall, the RCTs included in this meta-analysis were poor in methodological quality. The combined results showed that acupuncture treatment combined with CR showed significant superiority compared to CR alone in terms of improving cognitive function [Mean Difference (MD) = 3.94, 95% confidence intervals (CI): 3.16–4.72, P < 0.00001 (MMSE); MD = 3.30, 95%CI: 2.53–4.07, P < 0.00001 (MoCA); MD = 9.53, 95%CI: 5.61–13.45, P < 0.00001 (LOTCA)]. Furthermore, the combination of acupuncture treatment and CR significantly improved patients' self-care ability compared to CR alone [MD = 8.66, 95%CI: 5.85–11.47, P < 0.00001 (MBI); MD = 5.24, 95%CI: 3.90–6.57, P < 0.00001 (FIM)]. Meanwhile, subgroup analysis showed that MMSE scores were not sufficiently improved in the comparison of electro-acupuncture combined with CR versus CR alone (MD = 4.07, 95%CI: −0.45–8.60, P = 0.08). However, we also observed that electro-acupuncture combined with CR was superior to the use of CR alone in improving MoCA and MBI scores in patients with PSCI [MD = 2.17, 95%CI: 0.65–3.70, P = 0.005 (MoCA); MD = 1.74, 95%CI: 0.13–3.35, P = 0.03 (MBI)]. There was no significant difference in the occurrence of adverse events (AE) between acupuncture treatment combined with CR and CR alone (P > 0.05). The certainty of the evidence was rated low level because of flaws in the study design and considerable heterogeneity among the included studies. Conclusion: This review found that acupuncture treatment combined with CR may have a positive effect on improving cognitive function and self-care ability in PSCI patients. However, our findings should be treated with caution owing to the existence of methodological quality issues. High-quality studies are urgently required to validate our results in the future. Systematic review registration: https://www.crd.york.ac.uk/prospero/display_record.php?ID=CRD42022338905, identifier: CRD42022338905. Copyright © 2023 Liu, Chen, Qin, Zhao, Li, Han, Ke, Zhu and Wu.",TestAnalysis
"The sentiment analysis task is more complex considering the lack of relevant information in brief texts. Deep neural networks, like as convolutional neural networks (CNNs) and recurrent neural networks (RNNs), have been widely employed to extract information from data sentiment in recent years, with surprisingly good results. Though CNN can efficiently retrieve comparatively high features employing convolution and max-pooling layers, it cannot understand relationships' sequences. Parallelly bidirectional RNN models can extract contextual information and fail to extract local features. In this paper, integrated CNN and RNN models for sentiment analysis are examined to have the advantages of CNN's coarse grain local feature extraction and long-distance dependencies of RNNs. Particularly bidirectional LSTM and GRU networks associated with the convolution and max-pooling layer are used for sentiment analysis in SST-2 and movie review datasets. Two pre-trained word embedding techniques glove and word2vec are used. Experimental findings show that max performance is achieved at 93.44% for SST-2 and 95.42% for the movie review dataset using CNN BiGRU word2vec and CNN BiGRU glove, respectively. © 2023, Ismail Saritas. All rights reserved.",TestAnalysis
"This research aimed to know cadets' speaking abilities through retelling a recount text of shipping project experiences and knowing the importance of recount text of shipping project experiences in cadets' speaking abilities and learning process. This thesis's research design was descriptive qualitative, investigating the recount text of shipping project experiences used by cadets of PIP Makassar. The research site of this research was at PIP Makassar, which is undergone by the ministry of transportation of Indonesia. There were two data resources. The primary resource was 7th-semester cadets of PIP Makassar and four Maritime English lecturers as respondents of the research. The secondary resource was some literature related to speaking abilities and recounting text. The technique of data analyzes was data collection of recording using Miles and Hubberman data analysis, data collected from field notes, data collected from the interview, and data gathered from the questionnaire. The results of this research showed that the cadets' speaking abilities of recount text of shipping project experiences were categorized as average means accepted but not bad learners based on Brown's (2004) theory of speaking abilities. It was shown in the findings and the discussion. It was also shown from the result of the interview with the Maritime English teachers that it was essential to teach recount text of shipping project experiences in the learning process. It was also stated from the questionnaire distributed through google form to the cadets that 75% of cadets chose retelling shipping project experiences was important. It showed that 10% of cadets chose retelling shipping project experiences was very important, and 15% of cadets chose retelling shipping project experiences was not that important.  © 2023 Author(s).",TestAnalysis
"Gas hydrates represent one of the main flow assurance challenges in the oil and gas industry as they can lead to plugging of pipelines and process equipment. In this paper we present a literature study performed to evaluate the current state of the use of machine learning methods within the field of gas hydrates with specific focus on the oil chemistry. A common analysis technique for crude oils is Fourier Transform Ion Cyclotron Resonance Mass Spectrometry (FT-ICR MS) which could be a good approach to achieving a better understanding of the chemical composition of hydrates, and the use of machine learning in the field of FT-ICR MS was therefore also examined. Several machine learning methods were identified as promising, their use in the literature was reviewed and a text analysis study was performed to identify the main topics within the publications. The literature search revealed that the publications on the combination of FT-ICR MS, machine learning and gas hydrates is limited to one. Most of the work on gas hydrates is related to thermodynamics, while FT-ICR MS is mostly used for chemical analysis of oils. However, with the combination of FT-ICR MS and machine learning to evaluate samples related to gas hydrates, it could be possible to improve the understanding of the composition of hydrates and thereby identify hydrate active compounds responsible for the differences between oils forming plugging hydrates and oils forming transportable hydrates. © 2022 The Authors",TestAnalysis
"Density functional theory was used to elucidate the reaction mechanism of Cp*IrIII-catalyzed intermolecular regioselective C(sp3)-H amidation of alkenes with methyl dioxazolones. All substrates, intermediates, and transition states were fully optimized at the ωB97XD/6-31G(d,p) level (LANL2DZ(f) for Ir). The computational results revealed that this amidation occurred through the IrIII/IrV catalytic cycle, involving four important elementary steps: C-H bond activation, oxidative addition of methyl dioxazolone, reductive elimination, and proto-demetalation, and the first was the rate-determining step. The C-H bond activation showed good α- and branch-regioselectivity, decided by the distortion energy of 2-pentene and the interaction energy of the transition state, respectively. The oxidative addition of dioxazolone occurred in one elementary step with CO2 disassociation. The reductive elimination showed good branch-regioselectivity determined by the distorted energy of the allyl group. In the proto-demetalation, hydrogen directly transferred from the oxygen atom to the nitrogen atom. Moreover, to clarify the effect of the substituted groups, selected 12 substrates were also discussed in this text. © 2023 American Chemical Society.",TestAnalysis
"A destination's ability to attract tourists is associated with the visitor experience and, in recent years, visitors have increasingly used virtual environments and digital innovation, such as social media platforms, to communicate their experience of tourist destinations. A positive well-communicated tourist experience improves the reputation of the destination and has relevant consequences for both the destination's attractiveness and its competitive advantage. On the contrary, when the destination's reputation is negatively affected by visitors' experiences, comments and reviews, such destination might compromise its ability to attract new visitors. Studies in this field agree alike that the tourist experience is negatively affected by overcrowding and overflows phenomena occurring around the visited city attractions. The present research, merging the aforementioned observations, investigates whether visitor density affects the online reputation of the Uffizi Gallery, estimated by extracting visitors' opinions and feedbacks on the city's main attractions from TripAdvisor ratings and from Twitter posts, by applying sentiment analysis to evaluate whether the text is positive, negative, or neutral. The city of Florence is an ideal case study, as the city records almost 16 million tourist overnight stays per year hence highly exposed to the risk of tourist overcrowding and overflows. The research findings reveal that Uffizi Gallery experiences and mood are influenced by the number of visitors insisting and if tourists live a negative experience, this is further exacerbated by the growing density of visitors themselves. We find that, if tourists have a negative experience, this is exacerbated by the density of visitors to the Uffizi Gallery. The results reveal also that tourists' experiences are even more influenced by any general dissatisfaction they experience in the city of Florence in a broader way. Practical implications and theoretical contributions are discussed. © 2023 Camilla Ciappei, Giovanni Liberatore, Paolo Nesi, Gianni Pantaleo, Alessandro Monti and Micaela Surchi. All rights reserved.",TestAnalysis
"Introduction Discharging older adults with frailty home from the emergency department (ED) poses unique challenges due to multiple interacting physical and social problems. Paramedic supportive discharge services help overcome these challenges by adding in-home assessment and/or interventions. Our objective is to describe existing paramedic programmes designed to support discharge from the ED or hospital to avoid unnecessary hospital admissions. A comprehensive description of paramedic supportive discharge services will be conducted by mapping the literature to describe: (1) why such programmes are needed; (2) who is being targeted, making referrals and delivering the services and (3) what assessments and interventions are offered. Methods and analysis We will include studies that focus on expanded paramedic roles (community paramedicine) and extended scope postdischarge from the ED or hospital. All study designs will be included with no limit by language. We will include peer-reviewed articles and preprints and a targeted search of grey literature from January 2000 to June 2022. The proposed scoping review will be conducted in accordance with the Joanna Briggs Institute methodology. We will use a search strategy designed by a health science librarian to search MEDLINE All (Ovid), CINAHL Full Text (EBSCO), Embase (Elsevier) and Scopus (Elsevier) for eligible studies from 2000 to present. Two independent reviewers will conduct screening and full-text review. Data extraction will be conducted by one reviewer and verified by another. We will report our findings descriptively by charting trends in the research. Ethics and dissemination Research ethics review is not required as this is a scoping review comprised published studies. The results of this research will be published in a manuscript and presented at national and international geriatric and emergency medicine conferences. This research will inform future implementation studies on community paramedic supportive discharge services. Registration This scoping review protocol was registered in Open Science Framework and can be found here: https://doi.org/10.17605/OSF.IO/X52P7.  © 2023 BMJ Publishing Group. All rights reserved.",TestAnalysis
"Background: Vascular surgery may be followed by internal bleeding due to inadequate surgical haemostasis, abnormal clotting, or surgical complications. Bleeding ranges from minor, with no transfusion requirement, to massive, requiring multiple blood product transfusions. There are a number of drugs, given systemically or applied locally, which may reduce the need for blood transfusion. Objectives: To assess the effectiveness and safety of anti-fibrinolytic and haemostatic drugs and agents in reducing bleeding and the need for blood transfusion in people undergoing major vascular surgery or vascular procedures with a risk of moderate or severe (> 500 mL) blood loss. Search methods: We searched: Cochrane Central Register of Controlled Trials; MEDLINE; Embase; CINAHL, and Transfusion Evidence Library. We also searched the WHO ICTRP and ClinicalTrials.gov trial registries for ongoing and unpublished trials. Searches used a combination of MeSH and free text terms from database inception to 31 March 2022, without restriction on language or publication status. Selection criteria: We included randomised controlled trials (RCTs) in adults of drug treatments to reduce bleeding due to major vascular surgery or vascular procedures with a risk of moderate or severe blood loss, which used placebo, usual care or another drug regimen as control. Data collection and analysis: We used standard Cochrane methods. Our primary outcomes were units of red cells transfused and all-cause mortality. Our secondary outcomes included risk of receiving an allogeneic blood product, risk of reoperation or repeat procedure due to bleeding, risk of a thromboembolic event, risk of a serious adverse event and length of hospital stay. We used GRADE to assess certainty of evidence. Main results: We included 22 RCTs with 3393 participants analysed, of which one RCT with 69 participants was reported only in abstract form, with no usable data. Seven RCTs evaluated systemic drug treatments (three aprotinin, two desmopressin, two tranexamic acid) and 15 RCTs evaluated topical drug treatments (drug-containing bioabsorbable dressings or glues), including fibrin, thrombin, collagen, gelatin, synthetic sealants and one investigational new agent. Most trials were conducted in high-income countries and the majority of the trials only included participants undergoing elective surgery. We also identified two ongoing RCTs. We were unable to perform the planned network meta-analysis due to the sparse reporting of outcomes relevant to this review. Systemic drug treatments. We identified seven trials of three systemic drugs: aprotinin, desmopressin and tranexamic acid, all with placebo controls. The trials of aprotinin and desmopressin were small with very low-certainty evidence for all of our outcomes. Tranexamic acid versus placebo was the systemic drug comparison with the largest number of participants (2 trials; 1460 participants), both at low risk of bias. The largest of these included a total of 9535 individuals undergoing a number of different higher risk surgeries and reported limited information on the vascular subgroup (1399 participants). Neither trial reported the number of units of red cells transfused per participant up to 30 days. Three outcomes were associated with very low-certainty evidence due to the very wide confidence intervals (CIs) resulting from small study sizes and low number of events. These were: all-cause mortality up to 30 days; number of participants requiring an allogeneic blood transfusion up to 30 days; and risk of requiring a repeat procedure or operation due to bleeding. Tranexamic acid may have no effect on the risk of thromboembolic events up to 30 days (risk ratio (RR) 1.10, 95% CI 0.88 to 1.36; 1 trial, 1360 participants; low-certainty evidence due to imprecision). There is one large ongoing trial (8320 participants) comparing tranexamic acid versus placebo in people undergoing non-cardiac surgery who are at high risk of requiring a red cell transfusion. This aims to complete recruitment in April 2023. This trial has primary outcomes of proportion of participants transfused with red blood cells and incidence of venous thromboembolism (DVT or PE). Topical drug treatments. Most trials of topical drug treatments were at high risk of bias due to their open-label design (compared with usual care, or liquids were compared with sponges). All of the trials were small, most were very small, and few reported clinically relevant outcomes in the postoperative period. Fibrin sealant versus usual care was the topical drug comparison with the largest number of participants (5 trials, 784 participants). The five trials that compared fibrin sealant with usual care were all at high risk of bias, due to the open-label trial design with no measures put in place to minimise reporting bias. All of the trials were funded by pharmaceutical companies. None of the five trials reported the number of red cells transfused per participant up to 30 days or the number of participants requiring an allogeneic blood transfusion up to 30 days. The other three outcomes were associated with very low-certainty evidence with wide confidence intervals due to small sample sizes and the low number of events, these were: all-cause mortality up to 30 days; risk of requiring a repeat procedure due to bleeding; and risk of thromboembolic disease up to 30 days. We identified one large trial (500 participants) comparing fibrin sealant versus usual care in participants undergoing abdominal aortic aneurysm repair, which has not yet started recruitment. This trial lists death due to arterial disease and reintervention rates as primary outcomes. Authors' conclusions: Because of a lack of data, we are uncertain whether any systemic or topical treatments used to reduce bleeding due to major vascular surgery have an effect on: all-cause mortality up to 30 days; risk of requiring a repeat procedure or operation due to bleeding; number of red cells transfused per participant up to 30 days or the number of participants requiring an allogeneic blood transfusion up to 30 days. There may be no effect of tranexamic acid on the risk of thromboembolic events up to 30 days, this is important as there has been concern that this risk may be increased. Trials with sample size targets of thousands of participants and clinically relevant outcomes are needed, and we look forward to seeing the results of the ongoing trials in the future. Copyright © 2023 The Authors. Cochrane Database of Systematic Reviews published by John Wiley & Sons, Ltd. on behalf of The Cochrane Collaboration.",TestAnalysis
"The World Health Organization (WHO) has declared Covid-19 as a pandemic since March 11, 2020. The emergence of the Covid-19 pandemic has caused a lot of discussion around the world. Sentiment Analysis and Topic Modeling using Latent Dirichlet Allocation (LDA) can be used to extract patterns or information from a set of texts. This study uses a Systematic Literature Review (SLR) to see what the most dominant topics are discussed during the Covid-19 pandemic and find out research gaps for further research about Sentiment Analysis and Topic Modeling using Latent Dirichlet Allocation (LDA). The articles used are limited to the article publication period, February 2020 to July 2021. The results of the review show that case handling (lockdown, international airports closure), conspiracy issues and fake news, number of daily case reports, the importance of covid prevention, Covid-19 vaccination policy, economic downturn, transportation systems, learning systems, and new policies for each country were the most discussed topics from March 2020 to January 2021.  © 2023 Author(s).",TestAnalysis
"Currently, malware attacks pose a high risk to compromise the security of Android-IoT apps. These threats have the potential to steal critical information, causing economic, social, and financial harm. Because of their constant availability on the network, Android apps are easily attacked by URL-based traffic. In this paper, an Android malware classification and detection approach using deep and broad URL feature mining is proposed. This study entails the development of a novel traffic data preprocessing and transformation method that can detect malicious apps using network traffic analysis. The encrypted URL-based traffic is mined to decrypt the transmitted data. To extract the sequenced features, the N-gram analysis method is used, and afterward, the singular value decomposition (SVD) method is utilized to reduce the features while preserving the actual semantics. The latent features are extracted using the latent semantic analysis tool. Finally, CNN-LSTM, a multi-view deep learning approach, is designed for effective malware classification and detection. Copyright © 2023, IGI Global.",TestAnalysis
"Introduction In 2019, there were 2.5 million reported cases of chlamydia, gonorrhoea and syphilis. The Centers for Disease Control and Prevention reported in the USA, young people aged 15-24 made up 61% and 42% of chlamydia and gonorrhoea cases, respectively. Moreover, the highest rates of sexually transmitted infections (STIs) were reported among college-aged students. In this paper, we outline our protocol to systematically review the published literature on, the use of STI/HIV self-test kits, increasing STI/HIV testing uptake, and stigma, access and confidentiality issues, among young adult college students in the USA. Methods and analysis This scoping review will be conducted and reported according to the guidelines of the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews. We will search electronic databases, OVID Medline, OVID Embase, Web of Science, Cochrane Library, PubMed and CINAHL, for articles published in English from inception to the present. We will search other alternative sources such as ProQuest, Google Scholar and Google to identify grey literature. A two-step process will be used to identify eligible studies based on the defined inclusion criteria. First, the title and abstract of identified articles will be screened for possible inclusion. Second, full-text articles of relevant studies will be retrieved and screened for inclusion. Both screening steps will be done by two people independently. Finally, data will be extracted by two researchers working independently. Any arising disagreements will be resolved by consensus or by a third author. Ethics and dissemination This study is a scoping review of the literature. Therefore, ethics approval is not required. Our plan for the dissemination of findings includes peer-reviewed manuscripts, conferences and webinars.  © 2023 BMJ Publishing Group. All rights reserved.",TestAnalysis
"Importance: Erythropoietic protoporphyria (EPP) is a rare and underdiagnosed genetic disease characterized by painful sensitivity to light. A better understanding and characterization of its light-induced cutaneous symptoms may aid in the identification of EPP in patients. Objectives: To describe the cutaneous symptoms of erythropoietic protoporphyria (EPP) and to determine if these symptoms are associated with the degree of light sensitivity. Design, Setting, and Participants: This was a cross-sectional study of adolescent and adult (≥15 years) patients with EPP across the US conducted by a single academic hospital via a remotely administered survey, measurements of light sensitivity by light dosimetry and by text message symptom assessments. Data analyses were conducted from November 2020 to April 2022. Exposures: Sunlight exposure. Main Outcomes and Measures: Self-reported symptoms and association with measured light sensitivity. Results: The study sample consisted of 35 patients with EPP (mean [SD] age, 39.1 (15.5) years; 21 [60%] female; 14 [40%] male; 35 [100%] White individuals). The patients' median [range] skin tone was 3.0 (1.0-8.0), based on self-reporting from 1 (lightest) to 12 (darkest). A total of 24 participants completed the light dosimeter measurements. Phototoxic reactions were characterized by pain (97%; 34 patients), burning (97%; 34), tingling (97%; 34), pruritus (83%; 29), allodynia (89%; 31), improvement of symptoms with cold (89%; 31), achiness (24%; 12), fatigue (46%; 16), mild swelling (83%; 29), severe swelling (63%; 22), erythema (51%; 18), petechiae (40%; 14), skin cracking (43%; 15), scabbing (46%; 16), scarring (66%; 23), and other chronic skin changes (40%; 14). Patients with EPP reported that their hands, feet, and face were most sensitive to light and that their shoulders and legs were least sensitive; 25.7% (9 patient) reported no chronic skin changes, and 5.7% (2 patients) reported never having had any visible symptoms. None of these findings varied with the degree of light sensitivity except that lower overall light sensitivity was associated with lower ranked sensitivity of the neck and arms. Conclusions and Relevance: The findings of this cross-sectional study suggest that patients with EPP have distinctive cutaneous symptoms that may aid in identification of this underdiagnosed disease. Characteristic EPP symptoms include light-induced cutaneous burning pain and occasional swelling, particularly over the hands, with a prodrome of pruritus and paresthesias. Minimal skin changes or the absence of visible skin changes during reactions to light, including lack of erythema, do not exclude an EPP diagnosis nor suggest low EPP disease burden.. © 2023 American Medical Association. All rights reserved.",TestAnalysis
"The article analyzes the works of authors who served exile in Vologda in 1902. The research material is text fragments in which the language, speech, and style of a person are comprehended. We have attracted texts published after 1902. In our opinion, it is in works remote in time that the manifestation of reflection on communication is a trace of existentially saturated direct contact. The article deals with the works of former exiles who were once in Vologda at the same time. Therefore, the fragments involved in the study acquire the status of reference points for describing the experience of a “forced conversation” that occurred in their lives. The methods of Russian linguistics (description, continuous sampling, contextual analysis, comparison) and philosophy (reconstruction) are used in the work. The leading methodological strategy is the interpretation of the text. We were able to establish that eleven people (P.E. Shchegolev, N.A. Berdyaev, I.E. Ermolaev, V.A. Rusanov, P.L. Tuchapsky, A.M. Remizov, O.A. Kvitkin, S.A. Suvorov, B.V. Savinkov, A.V. Lunacharsky, A.A. Bogdanov) comprehended their communication in the works published after the “Vologda exile”. This fact can be explained neither by the education received, nor by the unity of scientific interests, nor by the commonality of philosophical grounds. This is not a coincidence, not an accident, it is the experience of a “forced conversation” experienced simultaneously in 1902. © 2023, Institute of Philosophy, Russian Academy of Sciences. All rights reserved.",TestAnalysis
"The usage of social media, forums, and e-commerce websites have been widely increased. Feedback from customers has a big impact on the final product. A service provider, merchant, or manufacturer need all the information, even if it is just a comment or a review about a service or a product. So, it is vital to look at input from users, and therefore sentiment analysis has received a lot of interest. Sentiment analysis is a method for identifying and analyzing text in order to determine the features, qualities, and viewpoints of particular user. Extracting user aspects is the main part of this process, and it is used to group the user aspects. In recent years, convolutional neural network (CNN) models have gained popularity in natural language processing. Thus, this research proposes a novel hybrid CNN model by concatenating the bidirectional long short-term memory and CNN models to process the data sequentially by learning their high-level features. The concatenated method minimizes the loss of critical information. Benchmark product reviews and hotel review datasets are employed in the experiments, and accuracies of 93.6% for the product review dataset and 92.7% for the hotel review dataset are achieved by the proposed hybrid model when compared to state-of-the-art techniques. © 2022 John Wiley & Sons, Ltd.",TestAnalysis
"Error in Text: The Original Investigation “Severity and Etiology of Incident Stroke in Patients Screened for Atrial Fibrillation vs Usual Care and the Impact of Prior Stroke: A Post Hoc Analysis of the LOOP Randomized Clinical Trial,”1 published online August 29, 2022, had an error in the Statistical Analysis section of the text. The cutoff for statistical significance should read P < .05 rather than P > .05. This error has been corrected online. © 2023 American Medical Association. All rights reserved.",TestAnalysis
"Background: Diabetic retinopathy (DR) is characterised by neurovascular degeneration as a result of chronic hyperglycaemia. Proliferative diabetic retinopathy (PDR) is the most serious complication of DR and can lead to total (central and peripheral) visual loss. PDR is characterised by the presence of abnormal new blood vessels, so-called “new vessels,” at the optic disc (NVD) or elsewhere in the retina (NVE). PDR can progress to high-risk characteristics (HRC) PDR (HRC-PDR), which is defined by the presence of NVD more than one-fourth to one-third disc area in size plus vitreous haemorrhage or pre-retinal haemorrhage, or vitreous haemorrhage or pre-retinal haemorrhage obscuring more than one disc area. In severe cases, fibrovascular membranes grow over the retinal surface and tractional retinal detachment with sight loss can occur, despite treatment. Although most, if not all, individuals with diabetes will develop DR if they live long enough, only some progress to the sight-threatening PDR stage. Objectives: To determine risk factors for the development of PDR and HRC-PDR in people with diabetes and DR. Search methods: We searched the Cochrane Central Register of Controlled Trials (CENTRAL; which contains the Cochrane Eyes and Vision Trials Register; 2022, Issue 5), Ovid MEDLINE, and Ovid Embase. The date of the search was 27 May 2022. Additionally, the search was supplemented by screening reference lists of eligible articles. There were no restrictions to language or year of publication. Selection criteria: We included prospective or retrospective cohort studies and case-control longitudinal studies evaluating prognostic factors for the development and progression of PDR, in people who have not had previous treatment for DR. The target population consisted of adults (≥18 years of age) of any gender, sexual orientation, ethnicity, socioeconomic status, and geographical location, with non-proliferative diabetic retinopathy (NPDR) or PDR with less than HRC-PDR, diagnosed as per standard clinical practice. Two review authors independently screened titles and abstracts, and full-text articles, to determine eligibility; discrepancies were resolved through discussion. We considered prognostic factors measured at baseline and any other time points during the study and in any clinical setting. Outcomes were evaluated at three and eight years (± two years) or lifelong. Data collection and analysis: Two review authors independently extracted data from included studies using a data extraction form that we developed and piloted prior to the data collection stage. We resolved any discrepancies through discussion. We used the Quality in Prognosis Studies (QUIPS) tool to assess risk of bias. We conducted meta-analyses in clinically relevant groups using a random-effects approach. We reported hazard ratios (HR), odds ratios (OR), and risk ratios (RR) separately for each available prognostic factor and outcome, stratified by different time points. Where possible, we meta-analysed adjusted prognostic factors. We evaluated the certainty of the evidence with an adapted version of the GRADE framework. Main results: We screened 6391 records. From these, we identified 59 studies (87 articles) as eligible for inclusion. Thirty-five were prospective cohort studies, 22 were retrospective studies, 18 of which were cohort and six were based on data from electronic registers, and two were retrospective case-control studies. Twenty-three studies evaluated participants with type 1 diabetes (T1D), 19 with type 2 diabetes (T2D), and 17 included mixed populations (T1D and T2D). Studies on T1D included between 39 and 3250 participants at baseline, followed up for one to 45 years. Studies on T2D included between 100 and 71,817 participants at baseline, followed up for one to 20 years. The studies on mixed populations of T1D and T2D ranged from 76 to 32,553 participants at baseline, followed up for four to 25 years. We found evidence indicating that higher glycated haemoglobin (haemoglobin A1c (HbA1c)) levels (adjusted OR ranged from 1.11 (95% confidence interval (CI) 0.93 to 1.32) to 2.10 (95% CI 1.64 to 2.69) and more advanced stages of retinopathy (adjusted OR ranged from 1.38 (95% CI 1.29 to 1.48) to 12.40 (95% CI 5.31 to 28.98) are independent risk factors for the development of PDR in people with T1D and T2D. We rated the evidence for these factors as of moderate certainty because of moderate to high risk of bias in the studies. There was also some evidence suggesting several markers for renal disease (for example, nephropathy (adjusted OR ranged from 1.58 (95% CI not reported) to 2.68 (2.09 to 3.42), and creatinine (adjusted meta-analysis HR 1.61 (95% CI 0.77 to 3.36)), and, in people with T1D, age at diagnosis of diabetes (< 12 years of age) (standardised regression estimate 1.62, 95% CI 1.06 to 2.48), increased triglyceride levels (adjusted RR 1.55, 95% CI 1.06 to 1.95), and larger retinal venular diameters (RR 4.28, 95% CI 1.50 to 12.19) may increase the risk of progression to PDR. The certainty of evidence for these factors, however, was low to very low, due to risk of bias in the included studies, inconsistency (lack of studies preventing the grading of consistency or variable outcomes), and imprecision (wide CIs). There was no substantial and consistent evidence to support duration of diabetes, systolic or diastolic blood pressure, total cholesterol, low- (LDL) and high- (HDL) density lipoproteins, gender, ethnicity, body mass index (BMI), socioeconomic status, or tobacco and alcohol consumption as being associated with incidence of PDR. There was insufficient evidence to evaluate prognostic factors associated with progression of PDR to HRC-PDR. Authors' conclusions: Increased HbA1c is likely to be associated with progression to PDR; therefore, maintaining adequate glucose control throughout life, irrespective of stage of DR severity, may help to prevent progression to PDR and risk of its sight-threatening complications. Renal impairment in people with T1D or T2D, as well as younger age at diagnosis of diabetes mellitus (DM), increased triglyceride levels, and increased retinal venular diameters in people with T1D may also be associated with increased risk of progression to PDR. Given that more advanced DR severity is associated with higher risk of progression to PDR, the earlier the disease is identified, and the above systemic risk factors are controlled, the greater the chance of reducing the risk of PDR and saving sight. Copyright © 2023 The Authors. Cochrane Database of Systematic Reviews published by John Wiley & Sons, Ltd. on behalf of The Cochrane Collaboration.",TestAnalysis
"Background: Increasing depression patients puts great pressure on clinical diagnosis. Audio-based diagnosis is a helpful auxiliary tool for early mass screening. However, current methods consider only speech perception features, ignoring patients' vocal tract changes, which may partly result in the poor recognition. Methods: This work proposes a novel machine speech chain model for depression recognition (MSCDR) that can capture text-independent depressive speech representation from the speaker's mouth to the listener's ear to improve recognition performance. In the proposed MSCDR, linear predictive coding (LPC) and Mel-frequency cepstral coefficients (MFCC) features are extracted to describe the processes of speech generation and of speech perception, respectively. Then, a one-dimensional convolutional neural network and a long short-term memory network sequentially capture intra- and inter-segment dynamic depressive features for classification. Results: We tested the MSCDR on two public datasets with different languages and paradigms, namely, the Distress Analysis Interview Corpus-Wizard of Oz and the Multi-modal Open Dataset for Mental-disorder Analysis. The accuracy of the MSCDR on the two datasets was 0.77 and 0.86, and the average F1 score was 0.75 and 0.86, which were better than the other existing methods. This improvement reveals the complementarity of speech production and perception features in carrying depressive information. Limitations: The sample size was relatively small, which may limit the application in clinical translation to some extent. Conclusion: This experiment proves the good generalization ability and superiority of the proposed MSCDR and suggests that the vocal tract changes in patients with depression deserve attention for audio-based depression diagnosis. © 2022",TestAnalysis
"This book is a pragma-stylistic study of Ian McEwan's fiction, providing a qualitative analysis of his selected novels using (im)politeness theory. (Im)politeness is investigated on two levels of analysis: the level of the plot and the story world (intradiegetic level) and the level of the communication between the implied author and implied reader in fiction (extradiegetic level). The pragmatic theory of (im)politeness serves the aim of internal characterisation and helps readers to better understand and explain the characters' motivations and actions, based on the stylistic analysis of their speech and thoughts and point of view. More importantly, the book introduces the notion of ""the impoliteness of the literary fiction"" - a state of affairs where the implied author (or narrator) expresses their impolite beliefs to the reader through the text, which has face-threatening consequences for the audience, e.g. moral shock or disgust, dissociation from the protagonist, feeling hurt or 'put out'. Extradiegetic impoliteness, one of the key characteristics of McEwan's fiction, offers an alternative to the literary concept of ""a secret communion of the author and reader"" (Booth 1961), describing an ideal connection, or good rapport, between these two participants of fictional communication. This book aims to unite literary scholars and linguists in the debate on the benefits of combining pragmatics and stylistics in literary analysis, and it will be of interest to a wide audience in both fields. © The Editor(s) (if applicable) and The Author(s), under exclusive licence to Springer Nature Switzerland AG 2023. All rights reserved.",TestAnalysis
"This chapter examines the reactions of Italian, Spanish, French and German citizens through the comments left on Twitter. Italy, Spain, France and Germany were the first four European nations to be affected by the virus and to implement measures to contain the contagion such as the lockdown. Through the merged method of Emotional text mining, citizens' reactions are clustered and sentiment analysis is carried out on them. The tweets reveal a concern for the crisis that is not only health, but also economic, political and social. © Springer Nature Switzerland AG 2023. All rights reserved.",TestAnalysis
"Target sentiment analysis aims to analyze the sentiment tendency corresponding to different targets in the review text. At present, graph neural network based methods use the dependency syntactic tree to incorporate dependency syntactic relations. On the one hand, these methods mostly ignore the fact that dependency relations lack distinction. On the other hand, without considering the dependency relations provided by the dependency syntactic tree, there is a lack of relations between target and sentiment words. Therefore, a dual graph attention network(DGAT) model is proposed. First, the model uses a bidirectional long short-term memory network to obtain word node representation with semantic information, and then constructs a syntactic graph attention network based on the word node representation according to the dependency syntactic tree, so as to distinguish the importance of dependency syntactic relations, more effectively establish the relation between target and sentiment words, and obtain a more accurate representation of target sentiment features. At the same time, according to the undirected complete graph of sentences,a global graph attention network is used to mine lacking relations between target and sentiment words,50 as to further improve the performance of the model. Experimental resul show that compared with existing models, the DGAT model has a better accuracy and macro-average F1 value on different datasets. © 2023 Science Press. All rights reserved.",TestAnalysis
"Importance: Primary cutaneous squamous cell carcinoma is usually curable; however, a subset of patients develops poor outcomes, including local recurrence, nodal metastasis, distant metastasis, and disease-specific death. Objectives: To evaluate all evidence-based reports of patient risk factors and tumor characteristics associated with poor outcomes in primary cutaneous squamous cell carcinoma and to identify treatment modalities that minimize poor outcomes. Data Sources: PubMed, Embase, and SCOPUS databases were searched for studies of the topic in humans, published in the English language, from database inception through February 8, 2022. Study Selection: Two authors independently screened the identified articles and included those that were original research with a sample size of 10 patients or more and that assessed risk factors and/or treatment modalities associated with poor outcomes among patients with primary cutaneous squamous cell carcinoma. Data Extraction and Synthesis: Data extraction was performed by a single author, per international guidelines. The search terms, study objectives, and protocol methods were defined before study initiation. A total of 310 studies were included for full-text assessment. Owing to heterogeneity of the included studies, a random-effects model was used. Data analyses were performed from May 25 to September 15, 2022. Main Outcomes and Measures: For studies of risk factors, risk ratios and incidence proportions; and for treatment studies, incidence proportions. Results: In all, 129 studies and a total of 137449 patients with primary cutaneous squamous cell carcinoma and 126553 tumors were included in the meta-analysis. Several patient risk factors and tumor characteristics were associated with local recurrence, nodal metastasis, distant metastasis, disease-specific death, and all-cause death were identified. Among all factors reported by more than 1 study, the highest risks for local recurrence and disease-specific death were associated with tumor invasion beyond subcutaneous fat (risk ratio, 9.1 [95% CI, 2.8-29.2] and 10.4 [95% CI, 3.0- 36.3], respectively), and the highest risk of any metastasis was associated with perineural invasion (risk ratio, 5.0; 95% CI, 2.3-11.1). Patients who received Mohs micrographic surgery had the lowest incidence of nearly all poor outcomes; however, in some results, the 95% CIs overlapped with those of other treatment modalities. Conclusions and Relevance: This meta-analysis identified the prognostic value of several risk factors and the effectiveness of the available treatment modalities. These findings carry important implications for the prognostication, workup, treatment, and follow-up of patients with primary cutaneous squamous cell carcinoma. Trial Registration: PROSPERO Identifier: CRD42022311250. © 2023 American Medical Association. All rights reserved.",TestAnalysis
"Situated within the field of women 's photographic practice, this chapter investigates the relationship between trauma, memory, and the embodied trace. Using practice examples, the text explores how self-performed modes of self-representation might offer insights into the complex-psychological and physiological-inscriptions left by trauma. Evaluating this relationship, the text draws on analyses by Griselda Pollock, Jill Bennett, and Margaret Iversen. The argument supports post-qualitative research methods that unfold subjective material through the 'doing-thinking-making' process. Approached through posthuman and new materialist frameworks referencing Karen Barad and Rosi Braidotti, the chapter examines how a diffractive-rather than purely reflective-methodology can synthesise praxis and theory through affective photographic outcomes. The chapter concludes by evaluating how a diffractive approach to photographic self-representation can be productive for re-thinking the self, re-interpreting narratives of trauma, and re-imagining the way we see ourselves in our 'becoming-with' others. © 2023 by IGI Global. All rights reserved.",TestAnalysis
"Sentiment Analysis (SA) has recently gained great interest in Natural Language Processing (NLP). In fact, NLP consists in extracting data from texts and categorizing certain tweets as Positive, Negative, or Neutral. In this paper, we also present our participation in the Arabic Sentiment Analysis Challenge organized by King Abdullah University of Science and Technology (KAUST). Data of interest are tweets written in Arabic language, which becomes more challengeable. In this manuscript, we present the introduced system and the bi-LSTM model. Also, detail the less efficient explored solutions. Our main objective is to extract the crucial semantic data in Arabic tweets. The obtained findings about Arabic twitter corpus reveal that the performance of the developed technique is better than that proposed in the literature. Official test accuracy scores are 0.7605 with Macro-F1 score. © 2023 Little Lion Scientific. All rights reserved.",TestAnalysis
"This article investigates how translators choose between multiple competing onomasiological variants to express (verbal) inchoativity in English-to-Dutch translations. Using a corpus-based multifactorial research design, we measure the impact of three well-known socio-cognitive mechanisms on the actual choice, namely the complexity principle, risk aversion, and cognate exposure. We apply the behavioural profile method, which allows us to operationalise these three explanatory mechanisms via ID-tags, and we then use conditional random forest modelling to determine the impact of each mechanism on the choice between four competing verbs of inchoativity. The results of our analyses show that the complexity principle plays a clear role in translated texts, as there is a significant preference for the active construction and for prototypical verbs in passive constructions. Genre-specific risk-averse behaviour as well as cognate avoidance were not observed. © John Benjamins Publishing Company.",TestAnalysis
"One of the important indicators of increasing the capacity of the health system and the chances of survival of patients and injured immediately after chemical, biological, radiation and nuclear (CBRN) accidents is rapid access to medical services. Establishing prehospital health response teams is one of the main strategies to improve the capacity and ability to respond to unusual events. The aim of this study was to investigate the factors influencing the formation of rapid response teams in the field of health in response to chemical, biological, radiation and nuclear accidents (CBRN EDMRT). In this study, the comparative review method was used. The study period was from November 1, 2021 to March 2022. Forming and deploying rapid health response teams based on an extensive multi-step search and keywords in multiple databases such as PubMed, CINHAL, Blackwell, Iranmedex, SID, Cochrane Database of Systematic Reviews, Google Scholar, Scopus Also, the websites of the Ministry of Health and the responsible organizations in different countries and the proposed structure were done by international institutions and sites. After accessing the resources and documents, the process of analysis and comparison of different team structures was performed. After the initial search, the structure and required elements of their teams were extracted. According to published articles and texts, 10 teams from the International Atomic Energy Agency (IAEA), the US Centers for Disease Control and Prevention (CDC), the US Department of Homeland Security, and the North Atlantic Treaty Organization (NATO), Australia, the British Public Health Organization, and the Japanese Red Cross were compared. Team requirements, population distribution, type of accident, level of team activity and training, equipment required by the team after the accident, according to which, each country/organization should consider the above factors to design and establish the structure of CBRN EDMRT to take. A study should be conducted to design a comprehensive and evidence-based structure.  © The Author(s), 2023. Published by Cambridge University Press on behalf of Society for Disaster Medicine and Public Health, Inc.",TestAnalysis
"This case note analyses an appeal decision (Khoin v Jenkins in Re: Observatory Civic Association v Trustees for the Time Being of the Liesbeek Leisure Properties Trust [2023] 1 All SA 110 (WCC)) handed down in 2022 by the Western Cape High Court, its purpose being to identify the strengths and weaknesses of the decision and to comment on possible future developments. The text of the judgment is interpreted in the light of judicial precedent, literature and domestic (South African) and international law. One of the key findings is that ""intangible heritage"" is an integral part of both domestic and international law, and the Khoin-case gives judicial recognition to the concept as a part of South African heritage law. One of the main criticisms levelled against the judgment is that it does not adhere to judicial precedent in failing to find that the right to consultation of First Nations Peoples before administrative action is taken that allegedly violates their constitutional rights to intangible heritage is sufficient to satisfy the test for the existence of a prima facie right for the purposes of obtaining an interim interdict. © 2023, North-West Unversity. All rights reserved.",TestAnalysis
"This chapter provides a self-reflexive evaluation of the Sermon photographs from Waste Land (2005-2010), that was produced by the author for her practice-based PhD. T.S. Eliot's poem ""The Waste Land"" (1922) was used to examine her adaptation methodologies and self-representational strategies. Waterman visually translates her own experience of parental divorce through a close analysis of the text and literary criticism (Brooker and Bentley, Ellman, Miller, Parsons), acknowledging her biographical connections to Eliot's marriage to Vivienne Haigh Wood, to produce cathartic re-enactments, informed by phototherapy (Martin, Spence), memory and trauma studies (Barthes, Freud, Kaplan), feminine metaphors (Gilbert and Gubar, Horner and Zlosnik), and photographic self-portraiture (Chadwick, Lingwood). By interweaving these cross-disciplinary strands and reflecting on the actual process of making each photograph through a unique auto-criticism, Waterman demonstrates how her autobiographical literary interpretations offer a means of restaging memory through the creation of photographic narratives. © 2023 by IGI Global. All rights reserved.",TestAnalysis
"Purpose: The purpose of this study is to determine the satisfaction of the guests who stay at hotels offering technology-supported products and services related to the services and products they receive by using the opinion mining technique. Design/methodology/approach: In this research, 12,396 customer reviews on booking.com related to ten hotels belonging to a hotel chain using technology-supported products were evaluated with aspect-based sentiment analysis techniques. Findings: As a result of this study, it has been determined that using technology in hotel businesses creates a positive impression on customer satisfaction. It has been determined that the enrichment of standard hotel business products such as beds and room lighting with technology, in a way that will not be very costly, affects the guests. In addition, it is interesting that technological features such as robots and room service robots, which are called “High & Technology” in this study, are evaluated by customers in the service process. Practical implications: The hotel managements have the opportunity to evaluate the services we offer by analyzing their online comments and to see their own image from the eyes of the guests. Hotel businesses must learn about customer expectations for technologies with high investment costs. This study, which analyzes online customer reviews, enables tourism businesses that offer technology-supported products and services and invest in technology in service delivery, to understand how customers evaluate the service. Originality/value: In this study, customer reviews of a hotel group operating in many countries belonging to a hotel group that enriches its standard products with technology and provides service with the concept of a “smart hotel” were examined. This study contributes to the understanding of customers' experience of using technological products in hotel businesses. This study contributes to the literature on customers' satisfaction with technological hotel products and services and the decision of hotels to invest in technology. © 2022, Emerald Publishing Limited.",TestAnalysis
"Objectives: To summarize reports describing implementation and evaluation of Web-based psychosocial interventions for disaster-related distress with suggestions for future intervention and research, and to determine whether a systematic literature review on the topic is warranted. Methods: Systematic searches of Embase, PsycINFO, and MEDLINE were conducted. Duplicate entries were removed. Two rounds of inclusion/exclusion were conducted (abstract and full-text review). Relevant data were systematically charted by 2 reviewers. Results: The initial search identified 112 reports. Six reports, describing and evaluating 5 interventions, were included in a data analysis. Four of the 5 interventions were asynchronous and self-guided modular programs, with interactive components. The fifth was a short-term, online supportive group intervention. Studies utilized a variety of evaluation methods, and only 1 of 14 outcome measures used across the studies was utilized in more than 1 project. Conclusions: Several Web-based psychosocial interventions have been developed to target disaster-related distress, but few programs have been formally evaluated. A systematic review of the topic would not be recommended at this time due to heterogeneity in reported studies. Further research on factors impacting participation, generalizability, and methods of program delivery with consistent outcome measures is needed.  © The Author(s), 2023. Published by Cambridge University Press on behalf of Society for Disaster Medicine and Public Health, Inc.",TestAnalysis
"Summarizing a document has become a necessity as, because so much information is produced every day. Document summary makes it simpler to understand the text document than it would be to read through a collection of documents. A foundation for creating an condensed version of one or more text documents is provided by text summary. It is a crucial method for finding pertinent information on the Internet or in sizable text libraries. Additionally, it is essential to extract data in a way that the user would find the information interesting. Extractive summarization and abstract summarization are the two basic approaches used for text summarizing. In order to create the summary, the extractive summarization method chooses the sentences from a Word document and arranges them according to their weight. Abstractive summarizing is a technique that takes the key ideas from a document's content and expresses them abstractly in plain English. Numerous summary methods have been created on the foundation of these two approaches. There are numerous techniques that are language-specific exclusively. In this paper, we used extractive summarization methods and got good results. © 2023, Ismail Saritas. All rights reserved.",TestAnalysis
"The present chapter discusses the ascending number of Internally Displaced Persons in the African Union. The emergence of this category links with the rising concerns for climate refugees. Environmental Internally Displaced People have become one of the most challenging issues of the modern world. The current chapter critically evaluates the Kampala convention for Internally Displaced People (IDPs, henceforth) due to climatic change. It is examined from the point of property relations (in the form of land or housing or relocation) based on the right to return for IDPs. The method imparts a qualitative engagement with the text concerned. It falls in the terrain of discourse analysis where we trace how the sense of return or restitution or repatriation can be raised in the Kampala Convention as well as other relevant documents. The chapter provides critical insight into the claim for Rights than Guidelines for Internally Displaced Persons. It maps the basic rights under the Kampala Convention, the 1998 Guiding Principles, Inter-Agency Standing Committee (IASC), and the Pinheiro Principles. The conventions addressing their concerns prescribe principles that are not legally binding among the States to follow. It becomes important to politically assert a Right based measure than posing an economic argument for a particular social group. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023. All rights reserved.",TestAnalysis
"The increasing number of internet user influence the rise of internet data. One of the increasing internet data takes the form of online forum postings. These forum postings could be accessed from numerous postings portals on the internet. Some portals show only the posting title to let the readers decide whether they want to read it or not by reading the title only. In this study, the author study whether an online postings headline or title could influence reading interest in the community by using the Naïve Bayes and decision tree methods as a comparison. Based on analysis using Naïve Bayes and Decision Tree algorithm, the result shows that title of postings can influence as high as 73% popularity of the postings.  © 2023 Author(s).",TestAnalysis
"The study focused on the texts of high-quality accreditation resolutions of Higher Education Institutions in Colombia. The methodological approach led to a descriptive overview and allowed the construction of qualitative categories that enabled the analysis of the strengths and weaknesses. The results show the gap between the urban and rural contexts; a tendency of official institutions to receive more years of accreditation than private ones and the non-incidence of the academic nature in the number of years of accreditation granted. Improving professors’ working conditions and attending rural areas are some of the priorities that national policies must undertake. © GKA Ediciones, authors.",TestAnalysis
"Objective: To evaluate the influence of non-invasive treatment associated with the use of infiltrating resin for managing caries lesions in primary teeth. Material and Methods: A systematic review was performed by selecting articles from 6 online databases, using a search algorithm and eligibility criteria for data extraction and data synthesis for the papers included. Clinical trials involving primary teeth with incipient caries lesions (1/2 of the enamel or 1/3 of the outer dentin) were included, presenting full text and answering the study's guiding question. This study used the RoB 2 tool for the risk of bias assessment and GRADE for certainty of evidence. Random effects meta-analyses were implemented, and lesion progression treatment effects were estimated through relative risk (RR) and associated 95% confidence intervals. Results: A total of 440 studies were found. After analyzing the inclusion criteria and removal of duplicates, eight studies were analyzed for quality evidence. Five of the eight studies included in this review contributed to the meta-analysis, all with some reflections regarding the risk of bias. Overall, the results of the meta-analysis showed that non-invasive treatment, when associated with the use of infiltrating resins, significantly reduced the risk of caries progression in relation to the treatment without this addition for follow-up periods ranging from 12 months to 2 years (RR 0.51 [0.40-0.65]). Conclusion: There is moderate certainty of evidence that the use of infiltrating resins associated with non-invasive treatments decreases the risk of caries progression in primary teeth with incipient caries lesions (1/2 of the enamel or 1/3 of the dentin outer) when combined with non-invasive control methods alone. © 2023, Association of Support to Oral Health Research (APESB). All rights reserved.",TestAnalysis
"Purpose: The objective of this study was to look closely at how domestic violence is represented in Pakistani drama serials to see if portrayals are reinforcing stereotypical and/or patriarchal values, or breaking the rigid norms. Design/methodology/approach: With the help of dispositive analysis within the critical discourse approach, the prominent and non-dominant discourses about domestic violence were identified and discussed. Episodes from two popular drama serials, Kaisa Yeh Naseeban and Khaas, released in 2019, were watched with special focus on texts on domestic violence alongside objects and actions. Findings: Analysis showed that both drama serials gave importance to socio-systemic and liberal humanist instrumentalism discourses, which describe domestic violence as a result of social structures and that abuse is used to assert control, respectively. However, some instances were noted where patriarchal values were encouraged. Originality/value: As media has become a powerful tool of influence and awareness in the recent times, it is imperative that the content watched on it by millions of people be studied and analyzed. It is claimed that Pakistani drama serials with wide following and that are made on social issues around women aim to raise awareness and empower them. Domestic violence is a prevalent issue in Pakistan, and no research till date has examined representation of domestic violence on Pakistani popular media, which may influence response to domestic violence, which this paper aims to do. © 2022, Emerald Publishing Limited.",TestAnalysis
"Objectives Individuals with fetal alcohol spectrum disorder (FASD) are over-represented within the justice system and have significant employment challenges. The primary aim of this scoping review was to ascertain available employment resources for FASD individuals particularly those involved in the justice system. Secondary aims were to determine available evidence-based interventions for the justice workforce and employment providers. Methods Eligibility criteria: That the resource was (a) published between 1990 and 2021, (b) in English, (c) available electronically in full text, (d) focused on strategies for improving employment outcomes of individuals with FASD and (f) developed for those aged over 15. Sources of evidence: Electronic searches of the following databases were conducted: EMBASE, MEDLINE, PsycINFO, Scopus, Web of Science and Google Scholar. Grey literature was collected via the databases ProQuest Dissertations & Theses Global, OpenGrey, GreyNet International and Grey Matters. Charting methods: Using Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews reporting guidelines, a five-stage methodological framework was employed. A quality appraisal of identified resources was conducted. Data were summarised qualitatively using a content analysis method that allowed for analysis of specific terms/themes/concepts/resource elements that resources covered, as well as a quantitative analysis of their frequency. Results An initial search identified 850 articles, 512 of which were obtained through online database searches, 321 through Google Scholar searches and 17 through google searches. Sixteen resources were identified as meeting inclusion criteria, including four peer-reviewed papers and 12 grey literature resources. Six of the resources extracted were deemed 'good' or 'strong' quality, with the remainder - all grey literature resources - being 'adequate' or 'limited'. None of the resources identified were empirically evaluated or could be implemented synergistically. Content analysis revealed common themes addressing FASD-related employment challenges and required supports. Conclusions This review highlights the need for developing evidence-based employment-related resources for justice-involved people with FASD. Most of the 16 identified resources had a psychoeducational and advocacy component and described typical employment challenges with specific supports and accommodations to maximise workforce participation. However, none had been empirically evaluated, underscoring the importance of future research in this area to better inform more responsive and evidence-based employment-related programmes. Trial registration number doi:10.17605/OSF.IO/J5VMB. © 2023 BMJ Publishing Group. All rights reserved.",TestAnalysis
"Objective: Theoretical models of addictive behavior suggest that subjective effects serve as a mechanism through which substance use disorders develop. However, little is known about the subjective effects of simultaneous alcohol and cannabis use, particularly whether simultaneous use (a) heightens specific subjective effects or (b) is related to unique subjective effects relative to single-substance effects. The present study used formative, qualitative data analysis to examine patterns of responses within open-answer text response data on subjective effects of simultaneous use. Method: College students who simultaneously use alcohol and cannabis (N = 443; 68.2% female) were asked to describe how alcohol effects differ on simultaneous alcohol and cannabis use versus alcohol-only use days. Results: Conventional content analysis revealed nine concepts related to simultaneous (vs. alcohol-only) use subjective effects including as follows: (a) increased/decreased impairment, (b) low arousal/relaxation, (c) balancing/replacement effects, (d) “cross-faded” effects, (e) little-to no differences, (f) altered sensation and perception, (g) increased negative affective states, (h) increased appetite, and (i) increased/decreased negative consequences. Increased impairment (N = 191) and increased relaxation (N = 110) were the most often endorsed subjective effects, followed by decreased impairment (N = 55), balancing/replacement effects (N = 50) and cross-faded/enhancement effects (N = 44). Conclusions: Subjective effects from simultaneous use largely map onto domains of single-substance alcohol and cannabis effects (e.g., relaxation, sociability, cognitive/behavioral impairment), but also include distinct domains related to simultaneous use (e.g., balancing/replacement effects, altered sensation and perception). Future quantitative research is needed to validate measures of subjective effects from simultaneous use and their relations with use behavior. © 2023 American Psychological Association",TestAnalysis
"Objective Ideal cardiovascular health (CVH) was developed to promote CVH as a key component of primordial prevention. Mobile short message service (SMS) is useful for improving health behaviours. We aim to test the effectiveness of SMS intervention in women to improve CVH. Methods In a single-blinded, randomised, controlled study, 620 women, aged 35-70 years, without cardiovascular disease, were enrolled in SMS intervention versus no SMS. CVH metrics by self-report, and biochemical laboratory, anthropometric and blood pressure measurements were collected during home visits at baseline and 9 months. Women were categorised as having poor (0-2), intermediate (3-4) or ideal (5-7) CVH according to the number of ideal CVH metrics. Participants were randomised 1:1 to SMS intervention versus control. SMS was sent every 5-6 days for 9 months. The primary outcome was the difference in the proportion of women with ideal CVH between SMS and control groups at 9 months. Rates of intermediate CVH, poor CVH and each of the seven ideal CV health metrics at 9 months were key secondary endpoints. Results At 9 months, there was no significant difference between groups for the primary outcome (16.3% at baseline and 13.3% at 9 months, and 10.1% and 11.1%, in SMS and control groups, respectively, adjusted RR 1.0; 95% CI 0.6 to 1.6). Similarly, there were no significant differences between groups for the key secondary endpoints. SMS had an acceptance rate of 94.9%. Conclusions Behavioural SMS intervention did not improve rates of ideal CVH in women, despite being feasible and well received. Trial registration number 6377.  © 2023 BMJ Publishing Group. All rights reserved.",TestAnalysis
"This update covers publications from the second half of 2021 to the middle of 2022. Advances in the application of atomic spectrometry techniques to clinical and biological materials, foods and beverages are reviewed in the text, highlighting their key features. Technical details of sample collection and preparation, as well as progresses with analytical techniques are considered and three tables complement the text, summarising details of a larger spectrum of publications. During this period, the trend toward the application of multi-element techniques, such as EDXRFS, ICP-MS and LIBS continued, in particular for food authenticity studies. Triple quadrupole ICP-MS is becoming increasing popular, as it is less affected by interferences, as well as LIBS and XRF, that require minimal sample preparation. However, AAS is still considered a valid alternative for single or a limited number of elements: as in previous years, numerous pre-concentration techniques were presented, some of which explored “greener” reagents. The interest in NPs continued, both as a potential exposure risk and for their application as tags of biological materials, and led to a wider application of spICP-MS. Chromium speciation in food received more attention than usual during this period, providing evidence that the carcinogenic species CrVI was not present. A number of studies covered the application of atomic spectrometry techniques for the indirect determination of biological macromolecules, including an interesting application of LIBS for the rapid detection of the immune response to SARS-CoV-2. © 2023 The Royal Society of Chemistry.",TestAnalysis
"Objective: The objective of this review is to evaluate the effectiveness of perioperative prophylactic tranexamic acid for reducing blood loss in orthognathic surgery in healthy patients. Introduction: Orthognathic surgery can cause significant hemorrhage, which requires postoperative blood transfusions. The most widely studied pharmaceutical adjunct for reducing blood loss is tranexamic acid, a synthetic amino acid that reversibly inhibits plasminogen activation. It is widely used and validated in other surgical procedures to limit blood loss; however, it is not a gold standard in orthognathic surgery. Inclusion criteria: We will include clinical trials comparing tranexamic acid to appropriate controls. The primary outcomes are intraoperative blood loss, change in hematocrit/hemoglobin level, and need for blood transfusion. Secondary outcomes include operating time, length of hospital stay, and adverse reactions. Studies of patients with pre-existing coagulopathies and those undergoing only minor orthognathic surgery (eg, genioplasty) will be excluded. Methods: We will search 3 electronic databases (PubMed, Embase, and Cochrane Library) from database inception. Titles, abstracts, and full-text papers will be assessed against the inclusion criteria by 2 independent reviewers. Risk of bias will be assessed using the Cochrane Risk of Bias 2.0 tool. Data will be extracted by 2 independent reviewers. Meta-analysis will be conducted for all outcomes where appropriate, with weighted mean differences used for intraoperative blood loss, changes in hematocrit/hemoglobin levels, operation time, and length of stay; and risk ratio for transfusion rates and adverse outcomes. Certainty of the evidence will be presented using the Grading of Recommendations, Assessment, Development and Evaluation (GRADE) approach. Systematic review registration number: PROSPERO CRD42022314403. © Lippincott Williams & Wilkins.",TestAnalysis
"In order to standardize the development of supplementary testing methods for cosmetics, in April 2021, National Medical Products Administration issued the “Technical Guidelines for the Development and Drafting of Supplementary Testing Methods for Cosmetics”. In this paper, regulations and requirements of the technical guide are analyzed in detail, the legal basis, development scope, main development direction, requirements for method text editing and method validation are arranged, and the project application and technical requirements for method development are focused on in combination with the “Guidelines for the Development of Supplementary Test Methods for Drugs”. In the end, it provides reference for the relevant personnel of drug inspection institutions to develop supplementary testing methods for cosmetics, and some targeted suggestions are put forward. © 2023 China Surfactant Detergent & Cosmetics. All rights reserved.",TestAnalysis
"Background and ObjectivesTo describe neurologist practice patterns, challenges, and decision support needs pertaining to withdrawal of antiseizure medications (ASMs) in patients with well-controlled epilepsy.MethodsWe sent an electronic survey to (1) US and (2) European physician members of the American Academy of Neurology and (3) members of EpiCARE, a European Reference Network for rare and complex epilepsies. Analyses included frequencies and percentages, and we showed distributions through histograms and violin plots.ResultsWe sent the survey to 4,923 individuals; 463 consented, 411 passed eligibility questions, and 287 responded to at least 1 of these questions. Most respondents indicated that they might ever consider ASM withdrawal, with respondents treating mostly children being more likely ever to consider withdrawal (e.g., medical monotherapy: children 96% vs adults 81%; p < 0.05). The most important factors when making decisions included seizure probability (83%), consequences of seizures (73%), and driving (74%). The top challenges when making decisions included unclear seizure probability (81%), inadequate guidelines (50%), and difficulty communicating probabilities (45%). Respondents would consider withdrawal after a median of 2-year seizure freedom, but also responded that they would begin withdrawal on average only when the postwithdrawal seizure relapse risk in the coming 2 years was less than 15%-30%. Wide variation existed in the use of words or numbers in respondents' counsel methods, for example, percentages vs frequencies or probability of seizure freedom vs seizure. The most highly rated point-of-care methods to inform providers of calculated risk were Kaplan-Meier curves and showing percentages only, rather than pictographs or text recommendations alone.DiscussionMost surveyed neurologists would consider withdrawing ASMs in seizure-free individuals. Seizure probability was the largest factor driving decisions, yet estimating seizure probabilities was the greatest challenge. Respondents on average indicated that they may withdraw ASM after a minimum seizure-free duration of 2 years, yet also on average were willing to withdraw when seizure risk decreased below 15%-30%, which is lower than most patients' postwithdrawal risk at 2-year seizure freedom and lower than the equivalent even of a first seizure of life. These findings will inform future efforts at developing decision support tools aimed at optimizing ASM withdrawal decisions.  © American Academy of Neurology.",TestAnalysis
"Background: Recruitment and retention of farm veterinarians have been the focus of recent research. Previous work suggests that a feeling of ‘fit’ is important for students to consider a farm career. The aim of this study was to identify whether students feel that they ‘fit’ in farm practice and reasons for their answer. Methods: An online survey was distributed to students at all British and Irish veterinary schools. A mixed methods approach was considered, with thematic analysis on free text answers and regression analysis on demographic variables. Results: Thematic analysis identified six themes: career opportunities, nature of farm veterinary work, relationships and interactions, individual experiences, expectations and perceptions, and no perceived barriers. Females, marginalised ethnic groups and those from an urban/suburban background were all identified as having significantly (p < 0.05) less agreement with the statement ‘I feel able to pursue a career in farm practice’. Limitations: Survey limitations include those with a clear bias being likely to respond. However, alignment of the qualitative and quantitative results increased confidence in the findings of this mixed methods approach. Conclusion: This study confirms that biases that exist within wider society do have an influence on veterinary undergraduates' intentions to pursue a farm animal career. This is vital to consider both at a university level and when considering students' experiences on placements. Urgent action is required to improve inclusivity in the farm animal veterinary sector. © 2022 The Authors. Veterinary Record published by John Wiley & Sons Ltd on behalf of British Veterinary Association.",TestAnalysis
"Municipal wastewater collection and treatment systems are critical infrastructures, and they are also identified as major sources of anthropogenic CH4 emissions that contribute to climate change. The actual CH4 emissions at the plant- or regional level vary greatly due to site-specific conditions as well as high seasonal and diurnal variations. Here, we conducted the first quantitative analysis of CH4 emissions from different types of sewers and water resource recovery facilities (WRRFs). We examined variations in CH4 emissions associated with methods applied in different monitoring campaigns, and identified main CH4 sources and sinks to facilitate carbon emission reduction efforts in the wastewater sector. We found plant-wide CH4 emissions vary by orders of magnitude, from 0.01 to 110 g CH4/m3 with high emissions associated with plants equipped with anaerobic digestion or stabilization ponds. Rising mains show higher dissolved CH4 concentrations than gravity sewers when transporting similar raw sewage under similar environmental conditions, but the latter dominates most collection systems around the world. Using the updated data sets, we estimated annual CH4 emission from the U.S. centralized, municipal wastewater treatment to be approximately 10.9 ± 7.0 MMT CO2-eq/year, which is about twice as the IPCC (2019) Tier 2 estimates (4.3-6.1 MMT CO2-eq/year). Given CH4 emission control will play a crucial role in achieving net zero carbon goals by the midcentury, more studies are needed to profile and mitigate CH4 emissions from the wastewater sector. © 2023 American Chemical Society.",TestAnalysis
"In recent years, voice-interaction-based control systems have attracted considerable attention for industrial control systems implementing Industrial Internet of Things (IIoT) technologies. The development of automated semantic understanding relates to the industrial Internet equipment used to realize remote voice control as well as to its intelligent management and control. In these emerging voice-interaction-enabled industrial central control systems, sorting technologies are considered critical. For complex user questions, the level of satisfaction regarding the answers given by such systems tends to be low. Driven by these challenges and opportunities, the optimization of conventional retrieval-based question answering through deep learning methods has become popular. In this study, we propose three deep semantic sorting models based on deep learning, including a multilayer convolutional matching sorting model for single documents and two interactive pairwise bidirectional encoder representations from transformers (BERT) sorting models for document pairs. Two main network architectures are proposed to model document pairs, named Pairwise-Twin-BERT and Pairwise-Triple-BERT. Experimental results indicate that proposed models performed better than state-of-the-art methods based on text matching in a candidate document sorting task.  © 2014 IEEE.",TestAnalysis
"This paper mainly studies the global exponential stability in Lagrange sense (GESLS) of quaternion memristive neural networks (QMNNs) with leakage delays, unbounded distributed delays and time-varying discrete time delays. In the process of research, instead of traditional decomposition into real-valued memristive neural networks (RMNNs) or complex-valued memristive neural networks (CMNNs), we consider the QMNN as a whole, and then give a sufficient condition related to time delays to ensure that the considered QMNN is GESLS. An example is provided to illustrate validity of theoretical results obtained in the end. The method proposed in the present text has two merits: (1) According to the definition of GESLS directly, no Lyapunov–Krasovskii functional (LKF) is required, which avoids massive calculations and solutions of high-dimensional matrix inequalities; (2) It is available not only to QMNNs, but also to RMNNs and CMNNs. © 2022 Elsevier Inc.",TestAnalysis
"BACKGROUND: Prior research suggests an association between clinical outcomes in heart failure (HF) and social determinants of health (SDoH). Because providers should identify and address SDoH in care delivery, we evaluated how SDoH have been defined, measured, and evaluated in studies that examine HF outcomes. METHODS AND RESULTS: Following Preferred Reporting Items for Systematic Reviews and Meta-Analysis guidelines, databases were searched for observational or interventional studies published between 2009 and 2021 that assessed the influence of SDoH on outcomes. Selected articles were assessed for quality using a validated rating scheme. We identified 1373 unique articles for screening; 104 were selected for full-text review, and 59 met the inclusion criteria, including retrospective and prospective cohort, cross-sectional, and intervention studies. The majority examined readmissions and hospitalizations (k=33), mortality or survival (k=29), and success of medical devices and transplantation (k=8). SDoH examined most commonly included race, ethnicity, age, sex, socioeconomic status, and education or health literacy. Studies used a range of 1 to 9 SDoH as primary independent variables and 0 to 7 SDoH as controls. Multiple data sources were employed and frequently were electronic medical records linked with national surveys and disease registries. The effects of SDoH on HF outcomes were inconsistent because of the heterogeneity of data sources and SDoH constructs. CONCLUSIONS: Our systematic review reveals shortcomings in measurement and deployment of SDoH variables in HF care. Validated measures need to be prospectively and intentionally collected to facilitate appropriate analysis, reporting, and replication of data across studies and inform the design of appropriate, evidence-based interventions that can ameliorate significant HF morbidity and societal costs. © 2023 The Authors. Published on behalf of the American Heart Association, Inc., by Wiley.",TestAnalysis
"Purpose: Privacy considerations have become a topic with increasing interest from academics, industry leaders and regulators. In response to consumers’ privacy concerns, Google announced in 2020 that Chrome would stop supporting third-party cookies in the near future. At the same time, advertising technology companies are developing alternative solutions for online targeting and consumer privacy controls. This paper aims to explore privacy considerations related to online tracking and targeting methods used for programmatic advertising (i.e. third-party cookies, Privacy Sandbox, Unified ID 2.0) for a variety of stakeholders: consumers, AdTech platforms, advertisers and publishers. Design/methodology/approach: This study analyzes the topic of internet user privacy concerns, through a multi-pronged approach: industry conversations to collect information, a comprehensive review of trade publications and extensive empirical analysis. This study uses two methods to collect data on consumer preferences for privacy controls: a survey of a representative sample of US consumers and field data from conversations on web-forums created by tech professionals. Findings: The results suggest that there are four main segments in the US internet user population. The first segment, consisting of 26% of internet users, is driven by a strong preference for relevant ads and includes consumers who accept the premises of both Privacy Sandbox and Unified ID (UID) 2.0. The second segment (26%) includes consumers who are ambivalent about both sets of premises. The third segment (34%) is driven by a need for relevant ads and a strong desire to prevent advertisers from aggressively collecting data, with consumers who accept the premises of Privacy Sandbox but reject the premises of UID 2.0. The fourth segment (15% of consumers) rejected both sets of premises about privacy control. Text analysis results suggest that the conversation around UID 2.0 is still nascent. Google Sandbox associations seem nominally positive, with sarcasm being an important factor in the sentiment analysis results. Originality/value: The value of this paper lies in its multi-method examination of online privacy concerns in light of the recent regulatory legislation (i.e. General Data Protection Regulation and California Consumer Privacy Act) and changes for third-party cookies in browsers such as Firefox, Safari and Chrome. Two alternatives proposed to replace third-party cookies (Privacy Sandbox and Unified ID 2.0) are in the proposal and prototype stage. The elimination of third-party cookies will affect stakeholders, including different types of players in the AdTech industry and internet users. This paper analyzes how two alternative proposals for privacy control align with the interests of several stakeholders. © 2022, Emerald Publishing Limited.",TestAnalysis
"Predictive legal analytics is a technology used to predict the chances of successful and unsuccessful outcomes in a particular case. Predictive legal analytics is performed through automated document classification for facilitating legal experts in their classification of court documents to retrieve and understand the details of specific legal factors from legal judgments for accurate document analysis. However, extracting these factors from legal texts document is a time-consuming process. In order to facilitate the task of classifying documents, a robust method namely Distributed Stochastic Keyword Extraction based Ensemble Theil-Sen Regressive Deep Belief Reweight Boost Classification (DSKE-TRDBRBC) is proposed. The DSKE-TRDBRBC technique consists of two major processes namely Keyword Extraction and Classification. At first, the t-distributed stochastic neighbor embedding technique is applied to DSKETRDBRBC for keyword extraction. This in turn minimizes the time consumption for document classification. After that, the Ensemble Theil-Sen Regressive Deep Belief Reweight Boosting technique is applied for document classification. The Ensemble boosting algorithm initially constructs’ set of Theil-Sen Regressive Deep Belief neural networks to classify the input legal documents. Then the results of the Deep Belief neural network are combined to built a strong classifier by reducing the error. This aids in improving the classification accuracy. The proposed method is experimentally evaluated with various metrics such as F-measure, recall, accuracy, precision,, and computational time. The experimental results quantitatively confirm that the proposed DSKE-TRDBRBC technique achieves better accuracy with lowest computation time as compared to the conventional approaches. © 2023 International Journal on Recent and Innovation Trends in Computing and Communication. All rights reserved.",TestAnalysis
"With the continuous advancement of urban renewal, innovative and creative spaces in the urban village have attracted much attention as a new model of space restoration. In the process of material space transformation, the emotional identity and place identity of innovative and creative spaces in urban villages are reconstructed. However, communities and residents in the urban village remain often been neglected in previous studies, most of which focused on the material and economic perspectives. In other words, the emotional mechanisms and spatial influences of relevant subjects in innovative and creative spaces have not received sufficient attention. By focusing on the innovative and creative spaces of Huangpu village in Guangzhou as an example, this study employed in-depth interviews, network text analysis, and other methods to explore the impact of innovative and creative spaces on residents' sense of place and their role in creating a local emotional identity within the context of urban renewal from the perspective of emotional geography. The innovative and creative spaces of the urban villages exerted a different impact on the local emotion and space identity of multiple subjects through the reshaping of the material environment, culture, and social relations. The improvement of the material environment of the innovative and creative spaces in the urban villages enhanced the emotional identity and local attachment of residents. The cultural values of modern industrial forms were not able to shape the local and cultural identities of residents but increased the level of makers. The local identity of the tenant group was based on creativity and cultural atmosphere. The innovative and creative spaces of the urban villages formed a social network relationship with industry as the link by strengthening the interaction and connection between the subjects, establishing a common emotional attachment and local identity, and transforming the original traditional living space into a multi-dimensional space with consumption, production, and leisure attributes. The emotion and atmosphere of the innovative and creative spaces were displayed during the interaction between makers and residents and during the production of creative products and made different subjects participate in the process of space-remodeling. Not only did this process strengthen the perception and recognition of innovative and creative elements and rural areas, but it also established the recognition of a common local value. Given the current emphasis on the reuse of stock space resources, such as industrial heritage and historical buildings, it is particularly important to focus on the emotional connection between humans and the environment. From the perspective of emotional geography, it is of great significance that the emotional effect and meaning of constructing innovative and creative spaces on rural development are elucidated. This study provides not only a theoretical perspective for a deeper understanding of the relationship between the innovative and creative spaces and the locality of urban villages but also insights into promoting culturally oriented urban renewal. © 2023 The Author(s).",TestAnalysis
"Incorrect Affiliation In the published article, there was an error in affiliation [1]. Instead of “The Affiliated Taizhou People’s Hospital of Nanjing Medical University”, it should be “Department of Cardiovascular Surgery, The Affiliated Taizhou People’s Hospital of Nanjing Medical University, Taizhou School of Clinical Medicine, Nanjing Medical University, Nanjing, China”. The authors apologize for this error and state that this does not change the scientific conclusions of the article in any way. The original article has been updated. Text Correction In the published article, there was an error. We forgot to state the symbol † means those three authors contributed equally to this work. The corrected sentence appears after the author affiliation and before background and reads: “† those three authors contributed equally to this work” The authors apologize for this error and state that this does not change the scientific conclusions of the article in any way. The original article has been updated. Text Correction In the published article, we excluded some key words. The sentence previously stated: “infectious endocarditis, mitral valve repair, mitral valve replacement, clinical outcomes, meta-analysis infectious endocarditis, meta-analysis” The corrected sentence appears below: “infectious endocarditis, mitral valve plasty, mitral valve replacement, clinical outcomes, meta-analysis” The authors apologize for this error and state that this does not change the scientific conclusions of the article in any way. The original article has been updated. © 2023 Wang, Zhou, Bian, Li, Zhang, Chen and Jiang.",TestAnalysis
"The aim of the research is to identify semantic models of humorous utterances that express the stereotypical ideas of the lawyers' professional community about the content of the categories of its participants in informal settings. The research methodology integrates two approaches: a critical analysis of discourse and a semantic approach to humour based on scripts by Salvatore Attardo and Victor Raskin. We applied the following analysis model: (1) discursive analysis of texts in accordance with the procedure presented in the papers of foreign and Russian scholars; (2) analysis of humour in accordance with the six-level model of analysis proposed by Attardo; (3) as the research includes transformed statements consisting of a complex of elements and their interrelationships to varying degrees, the methodology is supplemented by the theory of conceptual integration developed by Gilles Fauconnier and Mark Turner. The research methods are: discourse analysis, including standard techniques of communicative-pragmatic and semantic analysis; content analysis, the semantic categories of which are the parameters of the sociocommunicative level of the model, and the units are their typical lexical markers. The data include Internet memes constituting the content of professional legal groups on the social networks Instagram and Facebook. The data include 260 units. The analysis revealed a quantitative predominance in Internet memes expressing the subjects of legal discourse of models based on contrast and referential humour. The semantic dominants actualised in such models coincide with the stereotypical attitudes currently existing in society in relation to the legal community and its professional participants. The uneven distribution of models in accordance with the categories of participants indicates the predominance of reflection in relation to several professional participants - an advocate and a lawyer: intensity of professional activity and high fatigue, prestige of professional status and high social responsibility of professional participants, competence and professionalism (unprofessionalism), complexity and incomprehensibility of the language, high profit. In relation to non-professional participants (client/accused/defendant/respondent/witness), the stereotypes about their stupidity, greed, arrogance, venality are replicated. Referential models are distinguished by the diversity of the subjects represented and the uniformity of the meanings expressed: the subject's originality of thinking, cunningness and resourcefulness. Semantic models based on conceptual integration were identified only in relation to professional participants - a lawyer. They actualise such values as professionalism, reliability, competence; stress associated with responsibility at work, danger and charm of the profession, special status; superiority; friendliness; help and superpowers of the professional. © 2023 Tomsk State University. All rights reserved.",TestAnalysis
"[Objective] This paper decomposes the named entity recognition models based on neural network for Chinese medical texts. We investigate the impacts of single neural network module and the collaboration of multiple modules on the entity recognition performance. [Methods] First, we chosed the benchmark datasets from CCKS2017, CCKS2019, and IMCS-NER for named entity recognition tasks. Then, we conducted extensive experiments to compare the performance of different single modules of the aforementioned layers. Third, we built and compared entity recognition models based on ensemble, parallel, and serial neural models. [Results] Using hfl/chinese-macbert-base, hfl/chinese-roberta-wwm-ext, hfl/chinese-bert-wwm-ext in the symbolic representation layer significantly improved the performance of entity recognition models, the average F1-scores reached 0.8816, 0.8816 and 0.8812 respectively. Stacking neural models at the context encoding layer improved the performance of the neural network. Moreover, ensembled neural networks could achieve the best performance, the F1-scores reached 0.9330, 0.8211 and 0.9181 respectively. [Limitations] More research is needed to examine our findings with datasets in other languages. [Conclusions] The characteristics of single neural modules and their collaboration could significantly affect the performance of the named entity recognition of Chinese medical texts. © 2023, Chinese Academy of Sciences. All rights reserved.",TestAnalysis
"Model organisms are instrumental substitutes for human studies to expedite basic, translational, and clinical research. Despite their indispensable role in mechanistic investigation and drug development, molecular congruence of animal models to humans has long been questioned and debated. Little effort has been made for an objective quantification and mechanistic exploration of a model organism's resemblance to humans in terms of molecular response under disease or drug treatment. We hereby propose a framework, namely Congruence Analysis for Model Organisms (CAMO), for transcriptomic response analysis by developing threshold-free differential expression analysis, quantitative concordance/discordance scores incorporating data variabilities, pathway-centric downstream investigation, knowledge retrieval by text mining, and topological gene module detection for hypothesis generation. Instead of a genome-wide vague and dichotomous answer of ""poorly"" or ""greatly"" mimicking humans, CAMO assists researchers to numerically quantify congruence, to dissect true cross-species differences from unwanted biological or cohort variabilities, and to visually identify molecular mechanisms and pathway subnetworks that are best or least mimicked by model organisms, which altogether provides foundations for hypothesis generation and subsequent translational decisions. © 2023 National Academy of Sciences. All rights reserved.",TestAnalysis
"Objectives: To analyze the global research trends of hypertrophic cardiomyopathy (HCM) from 2000 to 2022 and explore new frontiers in this field. Methods: We reviewed the literature in the Web of Science Core Collection database from January 2000 to August 2022 using the retrieval strategy of medical subject headings combined with text words. We focused on articles and reviews that were published in English. Relevant data of the target publications, such as title, authors, organizations, abstract, keywords, published date, journal, and number of citations, were collected. The R software with the “bibliometrix” and VOSviewer software was used to process and visualize the information. Results: Among a total of 20,581 records related to HCM, 13,427 from 103 countries and regions, 8,676 affiliations, and 46,645 researchers were included. Most of the publications in this field were from the United States, followed by Japan, the United Kingdom, and China. We also report the top 10 institutions and most influential researchers, cited articles, and highest-frequency keywords (echocardiography, heart failure, sudden cardiac death, genetics, atrial fibrillation, magnetic resonance imaging/cardiac magnetic resonance, prognosis, mutation, arrhythmia, late gadolinium enhancement). In addition, keywords trend analysis indicated that the novel medicine Mavacamten, genetic diagnosis, and cardiac magnetic resonance have attracted the most attention for the treatment and diagnosis of HCM over the past five years. Conclusion: The present study reports on the global research trends of HCM over the past two decades using bibliometric analysis. It may enlighten new frontiers in the diagnosis, treatment, and risk prevention of HCM. Copyright © 2023 Zheng, He, Li and Jia.",TestAnalysis
"Drawing on critical theories of labor and commodification, this qualitative embedded case study explores how students experience alienation and intimacy in the work of writing for an English language arts class. Analysis of fieldnotes from 30 observations, student writing products, and reflective interviews with focal students and the teacher illuminated the meaningful assemblages where conditions of intimacy permeated instruction. Two practices supported intimacy in working conditions: knowledge about writing built through a collective process of noticing, and open-ended work time characterized by “managed nonmanagement” (Tsing, 2015, p. 176), or calculated flexibility in rules and expectations. Findings illustrate how a literacy practice might contribute to students’ experience of alienation or intimacy (or both) while writing, depending on conditions of industrialization and commodification. Even as the teacher strove to deindustrialize work, commodification through grades and standardized assessments heightened alienation in the writing environment. The study provides an example of an educational context governed by an industrial system of assessment where local actors (the teacher and students) disrupted alienation by working in smaller scales and more closely with texts. Copyright © 2023 by the National Council of Teachers of English. All Rights Reserved.",TestAnalysis
"During the operation and maintenance management of power equipment in the electric power grid, a massive amount of unstructured text information is available. The construction of a power equipment text semantic analysis model for mining the unstructured text information to improve the efficiency and accuracy of equipment defect and fault diagnosis, and assist power grid operation and maintenance decision-making is a practical and challenging task. This paper proposes a semantic analysis model of power equipment text based on a super large-scale pre-training method (Power BERT). The proposed solution adopts the multi-head attention mechanism and multi-layer embedded semantic expression structure. The total number of model parameters exceeds 110 million to implement the understanding and analysis of the information contained in the power text. The data sources cover the power professional corpus consisting of power standards and management regulations (more than1.862 billion characters in total). It adopts various mask mechanisms, e.g., character mask, entity mask and fragment mask and dynamic loading strategies to carry out the model pre-training, task scenario training and optimization for the text entity recognition, information extraction and defect diagnosis. The proposed solution is assessed through comparison with the conventional deep learning algorithms, and the numerical results demonstrate that the proposed solution can improve the recall and accuracy of verification set and test set by 20%~30% based on a limited number of samples. ©2023 Chin.Soc.for Elec.Eng.",TestAnalysis
"We novelly applied established ecology methods to quantify and compare language diversity within a corpus of short written student texts. Constructed responses (CRs) are a common form of assessment but are difficult to evaluate using traditional methods of lexical diversity due to text length restrictions. Herein, we examined the utility of ecological diversity measures and ordination techniques to quantify differences in short texts by applying these methods in parallel to traditional text analysis methods to a corpus of previously studied college student CRs. The CRs were collected at two time points (Timing), from three types of higher-ed institutions (Type), and across three levels of student understanding (Thinking). Using previous work, we were able to predict that we would observe the most difference based on Thinking, then Timing and did not expect differences based on Type allowing us to test the utility of these methods for categorical examination of the corpus. We found that the ecological diversity metrics that compare CRs to each other (Whittaker’s beta, species turnover, and Bray–Curtis Dissimilarity) were informative and correlated well with our predicted differences among categories and other text analysis methods. Other ecological measures, including Shannon’s and Simpson’s diversity, measure the diversity of language within a single CR. Additionally, ordination provided meaningful visual representations of the corpus by reducing complex word frequency matrices to two-dimensional graphs. Using the ordination graphs, we were able to observe patterns in the CR corpus that further supported our predictions for the data set. This work establishes novel approaches to measuring language diversity within short texts that can be used to examine differences in student language and possible associations with categorical data. Copyright © 2023 Shiroda, Fleming and Haudek.",TestAnalysis
"Rabies is a deadly viral infection for which there is still no definitive cure. Many researchers are making publication on this subject. The current study used bibliometric techniques to examine the rabies literature and highlighted current rabies research trends as well as prospective future hotspots for rabies research. In this bibliometric study, all data were retrieved from the Web of Science Science Citation Index-Expanded (SCI-E) database on January 1, 2023, using the selected terms (""rabies virus"" [MeSH Terms] OR ""rabies virus"" [Text Word] OR ""rabies"" [MeSH Terms] OR ""rabies"" [Text Word]) in the title field of the search engine. The search was further narrowed by the document type (article), language (English), and year of publication (1992–2022). According to the used search strategy, we reached a total of 5973 articles. The average number of citations per document was 21.3. Over 300 articles per year were published in the years 2020, 2021, 2019, 2018, and 2017. The rabies literature was written by authors from 158 different countries. The main countries with the highest number of articles on rabies were the USA, China, and France. Germany, India, Brazil, England, Japan, and Canada Research collaboration and cooperation between institutions and researchers in developing countries need to be supported by developed countries. The analysis provides information on the overall situation of rabies research worldwide. The analysis also provides a better understanding of the trends in rabies development over the past 30 years, which can serve as a scientific benchmark for subsequent studies. © 2023.",TestAnalysis
"This study deals with a set of issues related to the development of a conceptual model for automatic proofreading of technical documentation. The purpose of this study is to investigate the prospects for creating the software for automatic proofreading of text documents with an assessment of the prospects for its subsequent implementation in various areas of scientific cognition and in activities of various educational institutions. The methodological approach is a combination of a systematic study of modern algorithms for checking technical documents with an analysis of the prospects for building a concept for creating an optimal model for automatic document proofreading. The main results of this study should be the definition of the main areas for the development of issues for the creation of the concept under consideration and identification of the constituent elements of the conceptual model for automatic proofreading of technical documentation, which is important from the standpoint of ensuring the proper level of quality of functioning of such a system. The prospects for further research in this area are determined by the relevance of the stated topic conditioned by the urgent need to develop and implement an effective system for verifying technical documents as soon as possible. © 2023 Lavoisier. All rights reserved.",TestAnalysis
"Purpose: This paper aims to evaluate service user (SU) and clinician acceptability of video care, including future preferences to inform mental health practice during COVID-19, and beyond. Design/methodology/approach: Structured questionnaires were co-developed with SUs and clinicians. The SU online experience questionnaire was built into video consultations (VCs) via the Attend Anywhere platform, completed between July 2020 and March 2021. A Trust-wide clinician experience survey was conducted between July and October 2020. Chi-squared test was performed for any differences in clinician VC rating by mental health difficulties, with the content analysis used for free-text data. Findings: Of 1,275 SUs completing the questionnaire following VC, most felt supported (93.4%), and their needs were met (90%). For future appointments, 51.8% of SUs preferred video, followed by face-to-face (33%), with COVID-related and practical reasons given. Of 249 clinicians, 161 (64.7%) had used VCs. Most felt the therapeutic relationship (76.4%) and privacy (78.7%) were maintained. Clinicians felt confident about clinical assessment and management using video. However, they were less confident in assessing psychotic symptoms and initiating psychotropic medications. There were no significant differences in clinician VC rating by mental health difficulties. For future, more SUs preferred using video, with a quarter providing practical reasons. Originality/value: The study provides a real-world example of video care implementation. In addition to highlighting clinician needs, support at the wider system/policy level, with a focus on addressing inequalities, can inform mental health care beyond COVID-19. © 2022, Emerald Publishing Limited.",TestAnalysis
"Background: Chronic health conditions in children and adolescents can have profound impacts on education, well-being and health. They are described as non-communicable illnesses that are prolonged in duration, do not resolve spontaneously, and rarely cured completely. Due to variations in the definition of chronic health conditions and how they are measured prevalence estimates vary considerably and have been reported to be as high as 44% in children and adolescents. Of young people with a chronic health condition, an estimated 5% are affected by severe conditions characterised by limitations to daily activities impacting their ability to attend school. School attendance is important for academic and social skill development as well as well-being. When children and adolescents are absent from school due to a chronic health condition, school engagement can be affected. Disengagement from school is associated with poorer academic achievement, social-emotional functioning and career choices. Education support services for children and adolescents with chronic health conditions aim to prevent disengagement from school, education and learning during periods where their illness caused them to miss school. However, there is limited evidence on the effectiveness of educational support interventions at improving school engagement and educational/learning outcomes for children and adolescents with chronic health conditions. Objectives: To describe the nature of educational support interventions for children and adolescents with a chronic health condition, and to examine the effectiveness of these interventions on school engagement and academic achievement. Search methods: We searched eight electronic databases which span the health/medical, social sciences and education disciplines between 18 and 25 January 2021: Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE (Ovid), Embase (Ovid). CINAHL (EBSCO), PsycINFO (EBSCO), ERIC (Education Resources Information Center), Applied Social Sciences Index and Abstracts: ASSIA (ProQuest), and PubMed (from 2019). We also searched five grey literature trials registers and databases between 8 and 12 February 2021 to identify additional published and unpublished studies, theses and conference abstracts, as well as snowballing reference lists of included studies. Selection criteria: Randomised controlled trials (RCTs), controlled before-and-after studies and interrupted time series studies that met the inclusion criteria were selected. Other inclusion criteria were: participants - must include children or adolescents (aged four to 18 years) with a chronic health condition, intervention - must include educational support, outcomes - must report the primary outcomes (i.e. school engagement or academic achievement) or secondary outcomes (i.e. quality of life, transition to school/school re-entry, mental health or adverse outcomes). Data collection and analysis: Two people independently screened titles and abstracts, and full-text articles, to identify included studies. Where disagreements arose between reviewers, the two reviewers discussed the discrepancy. If resolution was unable to be achieved, the issues were discussed with a senior reviewer to resolve the matter. We extracted study characteristic data and risk of bias data from the full texts of included studies using a data extraction form before entering the information into Review Manager 5.4.1. Two people independently extracted data, assessed risk of bias of individual studies and undertook GRADE assessments of the quality of the evidence. Meta-analysis was not possible due to the small number of studies for each outcome. Our synthesis, therefore, used vote-counting based on the direction of the effect/impact of the intervention. Main results: The database searches identified 14,202 titles and abstracts. Grey literature and reference list searches did not identify any additional studies that met the inclusion criteria. One hundred and twelve full-text studies were assessed for eligibility, of which four studies met the eligibility criteria for inclusion in the review. All studies were randomised controlled studies with a combined total of 359 participants. All included studies were disease-specific; three studies focused on children with cancer, and one study focused on children with Attention Deficit Hyperactivity Disorder (ADHD). There was evidence that education support improved school engagement with three of four studies favouring the intervention. Three studies measured academic achievement but only two studies provided effect estimates. Based on the vote-counting method, we found contradictory results from the studies: one study showed a positive direction of effect and the other study showed a negative direction of effect. One study measured transition back to school and found a positive impact of education support favouring the intervention (SMD 0.18, 95% CI -0.46 to 0.96, no P value reported). The result came from a single study with a small sample size (n = 30), and produced a confidence interval that indicated the possibility of a very small or no effect. The overall certainty of evidence for these three outcomes was judged to be 'very low'. Two of four studies measured mental health (measured as self-esteem). Both studies reported a positive impact of education support interventions on mental health; this was the only outcome for which the overall certainty of evidence was judged to be 'low' rather than 'very low'. No studies measured or reported quality of life or adverse effects. Risk of bias (selection, performance, detection, attrition, reporting and other bias) was assessed using the Cochrane risk of bias tool for randomised trials (version 1). Overall risk of bias for all studies was assessed as 'high risk' because all studies had at least one domain at high risk of bias. Authors' conclusions: This review has demonstrated the infancy of quality research on the effectiveness of education support interventions for children and adolescents with chronic health conditions. At best, we can say that we are uncertain whether education support interventions improve either academic achievement or school engagement. Of the secondary outcomes, we are also uncertain whether education support interventions improve transition back to school, or school re-entry. However, we suggest there is some evidence that education support may slightly improve mental health, measured as self-esteem. Given the current state of the evidence of the effectiveness of education support interventions for children and adolescents with chronic health conditions, we highlight some important implications for future research in this field to strengthen the evidence that can inform effective practice and policy. Copyright © 2023 The Cochrane Collaboration. Published by John Wiley & Sons, Ltd.",TestAnalysis
"This research aimed at investigating Sayyid Thanthawi's ijtihād pattern and methodology for deciding the law on making donations for church construction. As stated by Islamic teachings, Christians do not regard God to be One since they believe in the Trinity (the Father, the Son, and the Holy Spirit). Within the national state, however, Muslims and Christians coexist, work together, and assist one another. Conflicts of interest in coexistence might emerge as a result of religious differences. This current study is library research using qualitative descriptive analysis. The data used were secondary data in the form of books written by Sheikh Sayyid Thanthawi, Mufti of the Arab Republic of Egypt, as well as other relevant books. This research found that from Sayyid Thanthawi's viewpoint, a Muslim is permitted to donate to the construction of a church. Sayyid Thanthawi's ijtihād is moderate since it considers the greater benefit and fosters harmony among religious communities, without ignoring the demands of the Qur'anic text. The ijtihād approach employed is the maṣlahah theory, which takes into account the benefits and harm that would be caused by the fatwa's issuing. The implication of this ijtihād is the establishment of concord and peace between Muslims and Christians in Egypt. However, some Egyptian religious scholars restrict donations to church construction, arguing that it is the same as donating to the development of gambling businesses and nightclubs. ©Universitas Islam Negeri Ar-Raniry. All rights reserved.",TestAnalysis
"We’re in the midst of the “big data” age right now. Users generate enormous amounts of text data through a variety of means, including social media sites, e-commerce sites, and many kinds of scientific investigations. With this “Text data,” companies may have a better understanding of how the public perceives their brand and use that information to guide future business decisions. As a result, it is imperative for businesses to use sentiment social media data (Big data) to generate forecasts. Open-source big data tools and machine learning techniques are needed to process massive amounts of text data in real time. To this end, we developed a machine learning algorithm-based system for analyzing sentiment in large datasets. Here, the system for text analysis system reviews datasets utilizing the Apache Spark has been built and implemented utilizing the Nave Bayes and Support Vector Machines classification techniques. In addition, accuracy was used to gauge how well the algorithms worked. As demonstrated by these experiments, the Algorithms are quite effective at managing large sentiment datasets. This will be more useful for businesses, governments, & individuals to increase their value. © 2023, Ismail Saritas. All rights reserved.",TestAnalysis
"This article is a review of the book The Evidential Model of a Scientific Text by Sergey Grichin. The monograph describes evidentiality, one of the leading discursive categories of a scientific text. Grichin answers the questions: How does new knowledge emerge? How is it converted into a text? How does the dialogue between the author and his predecessors come about? Answering these questions, Grichin substantiates the status of evidentiality as a universal text-forming category. This category reflects all cognitive actions of the author of the text, so the study of evidentiality requires a complex, interdisciplinary approach. In the reviewed book, this approach is represented by the synthesis of functional stylistics, cognitive linguistics, discourse analysis, psychology and logic. The author of the monograph fully and clearly formulates the research methodology and defines the key concepts: evidential sense, evidential unit, evidential indicators, etc. Grichin establishes the extra-linguistic factors influencing the representation of evidential meanings in a scientific text, and describes the linguistic units for expressing these meanings. The correlation between the category of evidentiality and the category of certainty / uncertainty is shown. Regularities in the perception of evidential information by the addressee are defined. The novelty of the research lies in the fact that the category of evidentiality is presented as an integrative, multifactor model, which takes into account extralinguistic (discursive) and linguistic factors of communicative and cognitive activity of the author of the text. The scientific significance of the developed model is ensured by the fact that Grichin interprets evidentiality in a wider and deeper way than it was accepted in traditional linguistics (traditionally evidentiality is understood as referring to the source of someone else’s speech). The monograph considers evidentiality as a multifactorial category, which is a tool for structuring scientific discourse. The evidentiality model is developed by Grichin on the basis of the analysis of vast material, which includes more than 300 texts in 13 branches of science. To check the validity of the concept, journalistic and colloquial (dialectal) texts are used in addition to scientific texts. The regularities of the addressee’s perception of evidential senses are analysed by means of experimental methods. The reviewers note the value of the monograph for speech studies, in particular: development of a cognitive and discursive method of scientific text analysis; identification of new extralinguistic factors of scientific communication; establishment of mechanisms of generation and perception of scientific texts. © 2023 Tomsk State University. All rights reserved.",TestAnalysis
"[Objective] This paper proposes a fake news detection method based on the difference between news titles and contents, aiming to address the issues of extracting features from short news texts or retrieving comments. [Methods] Firstly, we designed the Cos-Gap calculation method to obtain the difference between news titles and contents’textual and emotional features. Then, we constructed a News Differential Heterogeneous Graph Network (NDHN) based on the obtained differential features and the Heterogeneous Graph Attention Networks. The NDHN contains edges constructed based on differential features and nodes constructed based on semantic and emotional features of title, content, and emotion. [Results] We examined the proposed model on the GossipCop dataset and found that the NDHN can improve the classification accuracy by 2.7% and the F1 by 3.2%. [Limitations] This method is suitable for analyzing the news with title and has limitations for untitled texts from Sina Weibo or Twitter. [Conclusions] The new model could effectively detect fake news from social media. © 2023, Chinese Academy of Sciences. All rights reserved.",TestAnalysis
"Purpose About 25 % of the German population suffers from smoking. Although smoking cessation is one of the most effective approaches to reduce tobacco-related consequences, it is not well implemented in basic health care. Also, in GP practices it is only offered in a handful of cases. This study examines how GPs deal with the topic of smoking cessation and which factors hamper the implementation of smoking cessation. Methods Guided individual interviews were conducted with 13 GPs from teaching practices of the Institute of Family Medicine in Bonn. The interviews were audio-recorded and transcribed. Facilitated by MAXQDA the text document was analysed using thematic qualitative text analysis with deductive-inductive coding. Results GPs report different ways in which they implement smoking cessation in practice, describing combined interventions as most effective in practice. Nicotine replacement therapy and drug prescribing are reserved for heavy smokers with unsuccessful attempts to quit. In their experience, varenicline is effective and well tolerated. However, GPs report that they are cautious about using varenicline as they are afraid of side effects due to the warnings for the other cessation drug bupropion. According to the GPs the main barriers for smoking cessation are a lack of time in the practice, lack of patient motivation and the costs of medication. Conclusion The interviewed GPs concentrate on their motivated patients when applying smoking cessation. However, there is no structured treatment for nicotine addiction. As a consequence, the number of smoking interventions is low and effective therapies are rarely used. As a structured treatment is associated with a higher workload, there is a need for financial reward. In addition, GPs could be supported by providing more external smoking cessation services. © 2023 Georg Thieme Verlag. All rights reserved.",TestAnalysis
"In the United States alone, approximately 2 billion tons of hazardous material products are manufactured each year for both household and industrial applications and contribute to thousands of worker chemical exposures with as many as 50,000 deaths from prolonged exposure each year. The potential hazards and impacts of these chemicals for human health and the environment are primarily communicated to the public through Safety Data Sheets (SDSs) from the chemical vendors or distributors. These documents provide a standardized approach for how and what information is provided to product users to assist them with assessment of precautionary measures, hazard mitigation, emergency response or cleanup procedures, and environmental, health, and safety (EHS) management. Despite the criticality for hazard communication (HAZCOM) precision, legacy SDS management and industry business practices leave the overall ability to effectively manage chemicals vulnerable to significant liability through a lack of full constituent disclosure, injection of data quality errors through various handling of SDS information and manual data entry, and the lack of direct SDS-to-product association. Chemical spills and accidents often require individuals to look for the appropriate SDS on a local computer, online, or in workplace binders; each of which results in information returned that is often found to be outdated or incorrect. Workplace HAZCOM violations remain among the top citations during EHS inspections by regulatory agencies. More important, however, is the lack of precise association of SDS to hazardous products that can occur through chemical management lifecycles. Incorrect SDSs can yield significant liability, as subsequent environmental and occupational health analyses and reporting are based upon incorrect and, in some cases, entirely different chemical formulations. This paper focuses on the need for a paradigm shift in our chemical management systems and how a standardized management system and various recent technological advances can be incorporated into Environmental Management System operations to reduce or eliminate these liabilities. The following advancements can be used to enhance the lifecycle management of workplace chemicals, reduce potential exposure and spill risks, reduce workplace hazards, and increase the efficiency and accuracy of environmental reporting through a more streamlined systems approach. EHS system enhancement applications discussed in this paper include the following: the need for a centralized universal SDS repository with full chemical disclosure of all product constituents and a nationally adopted machine language SDS standard. The use of artificial intelligence/machine learning in environmental systems and how they can be used as a medium to transition toward an automated standard by reverse-engineering and partitioning SDS components into machine-encoded text that can be validated and uploaded to a centralized repository. Algorithmic and meta-algorithmic approaches to SDS requirement and data validation, hazard characteristic code calculations, and determination of potentially less hazardous substitutions. Application of Natural Language Processing methods for real-time updates from scientific journals, regulatory agencies, and other reputable sources to produce “living” SDSs capable of informing users of relevant regulatory updates, news, and research. Embedded SDSs or SDS links in product barcodes with QR code reader technology to retrieve precise SDSs for each product in emergency situations. Use of advanced QR codes embedding authentication layers, authenticity verification, and alerts of potential product or inventory problems or discrepancies. Benefits of radio frequency identification technology in providing accurate SDS associations while also minimizing manual tracking of hazardous material and hazardous waste containers and monitoring for expired shelf life, incompatible storage, temperature sensitivities, and other inventory concerns. © 2023 The Authors. Published by American Chemical Society.",TestAnalysis
"Background: The organ transplantation sector in China is facing a severe shortage of donors, and the organ donation rate needs to be increased. Since 2015, voluntary donation by citizens has become the only source of organs for transplantation in China. In recent years, there has been a relatively positive change in young people's attitudes toward organ donation after death. The aim of the study was to understand young people's perceptions and attitudes toward organ donation and the factors that influence them and can positively impact the promotion of organ donation. Methods: By analyzing relevant literature and legal texts, we developed a questionnaire. Information was obtained through questionnaires and interviews, and 501 valid questionnaires were returned from the target group. A chi-square test was used to examine whether there were significant differences in the willingness to organ donation among young people with different characteristics. A factor analysis was used to investigate the main factors influencing the different attitudes of young people toward organ donation, and a one-way ANOVA was used to examine whether young people with different characteristics were affected differently by different factors. Results: In our survey of young people aged 18–30 years, 99.2% of respondents knew about organ donation, 47.1% were willing to donate organs, and 15.2% understood that there were corresponding laws and regulations for organ donation. The study's findings showed that urban residents are more willing to be organ donators than rural residents; people with higher education levels have better awareness and are more willing to donate an organ; and people with religious beliefs are more likely to donate organs. The main factors that support the willingness of young people to donate are the social environment that provides support, their optimism in dealing with death, and their desire to realize their final value after death. The main factors for those unwilling to donate were low awareness or misconceptions about organ donation among individuals and their families and their attitudes toward death. As the people who took the questionnaire are probably interested in organ donation, the sample results will show a higher percentage of people who know about organ donation. We hope to discuss further with a larger and broader sample coverage to improve the estimates' validity and reflect the overall picture more accurately in a future study. Conclusion: Young people knew about organ donation but had a low depth of awareness. Household registration type, education level, and religious affiliation significantly correlate with people's willingness to donate. The supportive environment for organ donation in society and the correct understanding of the organ donation process and laws and regulations can influence people's willingness to donate. Copyright © 2023 Chen, Wei and Ai.",TestAnalysis
"Background: Given the limited resources of health system, economic evaluations studies can provide appropriate evidences for resource allocation by clarifying the possible consequences of a decision. Present study aimed to evaluate the implemented approaches for economic evaluation studies of pharmacoeconomic in Iran. Methods: This study was carried out using the critical review method. All studies related to economic evaluation studies of pharmacoeconomic in Iran, indexed in PubMed and SID databases and Google Scholar search engine, were searched by using appropriate keywords and search strategies until 2021. Further, published papers from Iranian researchers in the field of health economics and pharmacoeconomics and pharmaceutical administration were extracted with the scientometric system of the Health Ministry. Then, retrieved papers were screened by title, abstract, and the whole text. Finally, papers were evaluated by applying the Drummond quality assessment checklist, and finally appropriate ones were selected. Finally, 29 papers were selected and analyzed. Results: Out of total available papers (n=1324), 29 papers had inclusion criteria to evaluate. The selected papers were analyzed based on 10 parameters, including type of analysis, type of comparator, source of clinical effectiveness, time horizon, used model, perspective of the analysis, measured expected outcomes, discounting of costs and outcomes, sensitivity analysis, and subgroup analysis. Most studies have used cost utility analysis. Shortcomings were found in some aspects as follows: some studies did not mention the applied model, or the time horizon. Moreover, some studies had time horizon more than one year, while the cost and consequences were not discounted. Conclusion: In recent years, economic evaluation studies in the field of pharmacoeconomic in Iran have been center attention in line with global trend. In order to make a decision regarding the allocation of resources based on the findings of economic evaluation studies, these studies should be conducted with the systematic and transparent approach. Therefore, it is necessary to develop a standard framework for implementing and reporting the results of economic evaluation studies in Iran. Copyright © 2023 Emamgholipour et al. Published by Tehran University of Medical Sciences.",TestAnalysis
In order to improve the service task execution ability of robots in different home environments，an environment-adaptive service strategy generation method was proposed，which could generate the service strategy based on the current environmental goods information． Firstly，term frequency-inverse document frequency (TF-IDF) algorithm was used to construct service instruction set，keyword sequence set and service strategy data set．Secondly，semantic parsing and block analysis were carried out for irregular natural language instructions，which were decomposed and mapped to structured service instructions to simplify the semantic space and obtain the corresponding keyword sequence to be selected． Finally，the Protégé ontology knowledge base containing the current family environment information was matched and inferred to obtain the service keyword sequence，and the GPT-2 model fine-tuned by the service strategy data set was guided to generate the adaptive service strategy．Experimental results show that this method can improve the accuracy of service strategy generation，and the final generated strategy is more feasible in a specific family environment. © 2023 Huazhong University of Science and Technology. All rights reserved.,TestAnalysis
"The relationship between human visual experience and evoked neural activity is central to the field of computational neuroscience. The purpose of visual neural encoding and decoding is to study the relationship between visual stimuli and the evoked neural activity by using neuroimaging data such as functional magnetic resonance imaging (fMRI). Neural encoding researches attempt to predict the brain activity according to the presented external stimuli, which contributes to the development of brain science and brain-like artificial intelligence. Neural decoding researches attempt to predict the information about external stimuli by analyzing the observed brain activities, which can interpret the state of human visual perception and promote the development of brain computer interface (BCI). Therefore, fMRI based visual neural encoding and decoding researches have important scientific significance and engineering value. Typically, the encoding models are based on the specific computations that are thought to underlie the observed brain responses for specific visual stimuli. Early studies of visual neural encoding relied heavily on Gabor wavelet features because these features are very good at modeling brain responses in the primary visual cortex. Recently, given the success of deep neural networks (DNNs) in classifying objects in natural images, the representations within these networks have been used to build encoding models of cortical responses to complex visual stimuli. Most of the existing decoding studies are based on multi-voxel pattern analysis (MVPA) method, but brain connectivity pattern is also a key feature of the brain state and can be used for brain decoding. Although recent studies have demonstrated the feasibility of decoding the identity of binary contrast patterns, handwritten characters, human facial images, natural picture/video stimuli and dreams from the corresponding brain activation patterns, the accurate reconstruction of the visual stimuli from fMRI still lacks adequate examination and requires plenty of efforts to improve. On the basis of summarizing the key technologies and research progress of fMRI based visual neural encoding and decoding, this paper further analyzes the limitations of existing visual neural encoding and decoding methods. In terms of visual neural encoding, the development process of population receptive field (pRF) estimation method is introduced in detail. In terms of visual neural decoding, it is divided into semantic classification, image identification and image reconstruction according to task types, and the representative research work of each part and the methods used are described in detail. From the perspective of machine learning, semantic classification is a single label or multi-label classification problem. Simple visual stimuli only contain a single object, while natural visual stimuli often contain multiple semantic labels. For example, an image may contain flowers, water, trees, cars, etc. Predicting one or more semantic labels of the visual stimulus from the brain signal is called semantic decoding. Image retrieval based on brain signal is also a common visual decoding task where the model is created to “decode” neural activity by retrieving a picture of what a person has just seen or imagined. In particular, the reconstruction techniques of simple image, face image and complex natural image based on deep generative models (including variational auto-encoders (VAEs) and generative adversarial networks (GANs)) are introduced in the part of image reconstruction. Secondly, 10 open source datasets commonly used in this field were statistically sorted out, and the sample size, number of subjects, types of stimuli, research purposes and download links of the datasets were summarized in detail. These datasets have made important contributions to the development of this field. Finally, we introduce the commonly used measurement metrics of visual neural encoding and decoding model in detail, analyze the shortcomings of current visual neural encoding and decoding methods, propose feasible suggestions for improvement, and show the future development directions. Specifically, for neural encoding, the existing methods still have the following shortcomings: 1) the computational models are mostly based on the existing neural network architecture, which cannot reflect the real biological visual information flow; 2) due to the selective attention of each person in the visual perception and the inevitable noise in the fMRI data collection, individual differences are significant; 3) the sample size of the existing fMRI data set is insufficient; 4) most researchers construct feature spaces of neural encoding models based on fixed types of pre-trained neural networks (such as AlexNet), causing problems such as insufficient diversity of visual features. On the other hand, although the existing visual neural decoding methods perform well in the semantic classification and image identification tasks, it is still very difficult to establish an accurate mapping between visual stimuli and visual neural signals, and the results of image reconstruction are often blurry and lack of clear semantics. Moreover, most of the existing visual neural decoding methods are based on linear transformation or deep network transformation of visual images, lacking exploration of new visual features. Factors that hinder researchers from effectively decoding visual information and reconstructing images or videos mainly include high dimension of fMRI data, small sample size and serious noise. In the future, more advanced artificial intelligence technology should be used to develop more effective methods of neural encoding and decoding, and try to translate brain signals into images, video, voice, text and other multimedia content, so as to achieve more BCI applications. The significant research directions include 1) multi-modal neural encoding and decoding based on the union of image and text; 2) brain-guided computer vision model training and enhancement; 3) visual neural encoding and decoding based on the high efficient features of large-scale pre-trained models. In addition, since brain signals are characterized by complexity, high dimension, large individual diversity, high dynamic nature and small sample size, future research needs to combine computational neuroscience and artificial intelligence theories to develop visual neural encoding and decoding methods with higher robustness, adaptability and interpretability. © 2023 Editorial and Publishing Board of JIG. All rights reserved.",TestAnalysis
"Studies suggest that the lack of diversity in the science workforce may be partially attributed to implicit bias. Collectively, implicit biases are ingrained among youth from their upbringing, culture, and media, which are subsequently reflected in their language choices. Reform efforts made in post-secondary science education have targeted implicit bias by challenging the use of gendered language (he, she) and modeling gender inclusive language. However, the impact of such reforms are unexplored among K-12 aged learners. Utilizing the theoretical lens of implicit cognition, student-produced text within 288 primary (n = 47) and secondary (n = 241) Draw a Scientist Tests (DASTs) were analyzed using critical discourse analysis to explore how gender-exclusive language (GEL) and gender-inclusive language (GIL) was used by students when describing scientists. Findings suggest that middle school boys were most likely to use GIL, whereas high school girls were the least likely to use GIL. However, when specifying gender, elementary boys were most likely to use male-exclusive language, and high school girls were the most likely to use female-exclusive language. Further analyses suggest that students' implicit perceptions of scientists (character traits, academic behaviors, the field of study) were influenced by their gender, grade level, and the scientist's perceived gender or gender neutrality. © 2023 School Science and Mathematics Association.",TestAnalysis
"In recent months, there has been a remarkable surge in artificial intelligence (AI) development, with ChatGPT emerging as a notable application. ChatGPT, an OpenAI chatbot, achieved an impressive milestone of 100 million monthly active users within two months of its launch in January, making it the fastest-growing consumer application to date. Experts predict that AI will significantly impact 50 percent of businesses in the next five years. ChatGPT has already showcased its versatility in the medical field, aiding in tasks like medical exam preparation and serving as an in-office scribe. As its potential in healthcare continues to expand, ChatGPT holds promising prospects for the future. Additionally, research on AI and religion is gaining traction, exploring topics such as ethical implications, integration into religious practices, analysis of religious texts, interfaith dialogue facilitation, and the theological impact of AI on creation. The increasing number of scholarly publications on the subject indicates a growing interest in exploring the complex relationship between artificial intelligence and religion. © 2023, Program Studi Ilmu Agama Islam Program Magister, Universitas Islam Indonesia. All rights reserved.",TestAnalysis
"Introduction With the worsening of population ageing globally, the number of the elderly with chronic and incurable diseases such as malignant tumours is gradually increasing, and the need for palliative care is growing. As a primary task in the end-of-life phase, symptom management is an essential aspect of palliative care, which aims to alleviate distressing symptoms of terminally ill patients and improve their quality of life. Virtual reality (VR) technology, which allows the creation of simulated environments in which a three-dimensional experience is generated, has been increasingly used in palliative care for symptom management. Therefore, we aim to conduct a systematic review to investigate the effects of VR-based interventions on end-of-life patients. Methods and analysis This protocol for conducting a systematic review and meta-analysis will be prepared following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses 2020 statement. We will conduct a series of searches from inception to 31 July 2022 in the following databases: PubMed, Embase, Web of Science, the Cochrane Library, JBI, EBSCO, CNKI, Wanfang and SinoMed. The key concepts of virtual reality' and end-of-life' will be combined in each database using both free-text terms and controlled vocabulary terms (eg, MeSH/Emtree terms), if available. Two independent reviewers will use raw data to explore the effectiveness of VR for symptom management in end-of-life patients. The Cochrane Risk-of-Bias tool will be used to assess the risk of bias of included studies. Disagreements will be resolved by a third independent reviewer to reach a consensus. For the included articles, Review Manager software will be used for data synthesis and I 2 statistics will be used to measure the heterogeneity. Subgroup analyses and sensitivity analyses will be used to identify the source of heterogeneity. Ethics and dissemination As this is a protocol for a systematic review and meta-analysis, patients will not be included in this study. For this reason, ethical approval is not required. In order to disseminate the research findings, the results and conclusions of this review will be submitted to a worldwide journal. PROSPERO registration number CRD42022344679. © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.",TestAnalysis
"Pearl River Delta is the most densely populated and urbanized area in China. As the pilot area of reform and opening up, Pearl River Delta takes the lead in its urbanization in China and represents the development trend of China's urbanization. Therefore, a great number and diversity of previous studies on urbanization in the Pearl River Delta warrant further review and reflection. This study focused on publications about urbanization in the Pearl River Delta from 1983 to 2020 in the collection of Chinese core journals and dissertations in the China Academic Journals Full-text Database (CNKI). The quantitative characteristics of published papers, the scientific cooperation network of core authors and institutions, research topics, and historical research hotspots were analyzed for different periods through bibliometrics and mapping knowledge domains based on CiteSpace. Results indicated that: (1) the number of publications of the relevant research showed an upward trend, which was divided into the following four stages: initial (1983-1991), exploratory (1992-2002), prosperity (2003-2011), and deep cultivation (2012-2020) stages. (2) The research institutions gradually expanded from south China universities, with Sun Yat-sen University emerging as the core to form a national network of research collaboration, and the scholar network has expanded from occasional collaboration to form a variety of cooperation networks within and across institutions. (3) In the evolution process of knowledge, research topics that scholars focused on included economic zone, rural urbanization, urban agglomeration, Guangdong-Hong Kong-Macao Greater Bay area, new-type urbanization, innovation, while other historical hotspots that scholars focused on included economic zone, new-type urbanization, and Guangdong-Hong Kong-Macao Greater Bay area. (4) The research showed the characteristics of policy and practice orientations, the continuous expansion of vision and scope, and the theoretical research stages evolving from lag to advance and then to synchronization. After the urbanization development stage of a metropolitan circle and urban agglomeration was jointly entered, the theoretical construction of localization was slightly insufficient, and that of the people-oriented urbanization mode was lacking. (5) Pearl River Delta entered the regional urbanization stage, with the metropolitan areas and urban agglomerations being the main body. The driving force of urbanization development shifted to scientific and technological innovation, while the development features shifted to intensive, high-quality, and people-oriented urbanization. Finally, this study argued that future studies on urbanization in Pearl River Delta should focus on the theoretical and practical pathways of the coordinated development of urban agglomeration in the Guangdong-Hong Kong-Macao Greater Bay area, innovation-driven development strategy, and people-oriented urbanization. © 2023 TROPICAL GEOGRAPHY. All rights reserved.",TestAnalysis
"This article interrogates the historiography of the field of classical Judaism and suggests what a revisionist feminist historiography of this foundational period might look like. Feminist analysis of gender, class, and race in antiquity allows us to see how scholarly biases today reinscribe and even exceed ancient prejudices. Building on Blossom Stefaniw's essay ""Feminist Historiography and Uses of the Past""and deploying Saidiya Hartman's method of critical fabulation to analyze synagogue inscriptions and rabbinic texts, this article offers counternarratives of Jewish daily life in the period of Late Antiquity. Through investigation of evidence for enslaved, manumitted, and fostered people in the households of the late antique Jewish patriarchs, this article emphasizes the contribution of ostensibly nonnormative Jews to late antique synagogues, rabbinic learning, and Jewish society in Late Antiquity. It argues that our imaginings of Jewish society and the Jewish household in premodernity must change to accommodate the evidence of these heretofore marginalized Jews and the challenges posed by their enslaved status and/or gendered identity. This restoration of excluded perspectives and traditions represents a more ethical historiographic practice, which produces more inclusive and accurate representations of the past, sets the stage for recognizing continuities through the medieval era, and, finally, enables a different present, one with subjects empowered to construct more ethical social norms within and outside the academy.  © 2023 by the Regents of the University of California.",TestAnalysis
"Purpose: During the COVID-19 outbreak, clinical schools across the UK were forced to switch their learning from face-to-face to online platforms. This paper aims to describe the experiences of psychiatry teachers and medical students at Cambridge University of the online psychiatry case-based tutorials during the COVID-19 outbreak and the lessons learned from this implementation. Design/methodology/approach: The authors conducted qualitative focus groups with students followed by in-depth individual interviews with students and teachers. Findings: In a data-led systematic text condensation analysis, this study found seven themes: the COVID-19 context, the structure of the course, teachers’ educational ethos, beyond the (teaching) script, possibilities for learning or teaching reflective practice, attitudes to online learning and suggestions for future development. The authors then applied the normalisation process theory (NPT) as the theoretical frame of reference. This model has previously been applied to the implementation of telemedicine in psychiatry, to understand how new technology can become embedded in clinical care. Originality/value: This study’s results show how the NPT model can be modified to support the delivery of medical education online, including reflective learning and practice as an iterative process at every stage of the implementation and delivery of the teaching. © 2022, Emerald Publishing Limited.",TestAnalysis
"[Objective] This paper builds an automated detection model to effectively identify mis/dis-information from social media, aiming to balance the speed and accuracy of processing massive data. [Methods] The classification model is the mainstream processing technique to detect for mis/dis-information. However, most of them could not extract deep semantic features from the texts. Therefore, we used the single text feature BFID model (BERT False-Information-Detection) as the benchmark model, and proposed two new methods with fused semantic enhancement to detect the mis/dis-information. [Results] We examined the new models with data from Sina Weibo. The accuracy of the model based on fused sentiment feature BFID-SEN (BFID-Sentiment) increased about 1.59 percentage point, while the accuracy of model with fused image feature BFID-IMG (BFID-Image) model improved by 0.78 percentage point. [Limitations] The ability to fuse semantic enhancement is limited due to the small corpus size, sentiment categories and multimodal disinformation training datasets. [Conclusions] The proposed methods are able to more effectively identify false information from social media. © 2023, Chinese Academy of Sciences. All rights reserved.",TestAnalysis
"This article seeks to address the question of how membership in the European Union (EU) affects the foreign policy positions of its Member States. Most of the existing research has focused on single case studies and relied on qualitative methods, encountering difficulties in providing a systematic and consistent general picture about the causal effect of membership. Instead, this study adopts a comprehensive and quantitative approach. Drawing from constructivist theory in International Relations, it clarifies a general theoretical framework for Foreign Policy Europeanization. It then employs national speeches at the United Nations General Debate to construct two measures of similarity with the EU's positions and norms in international affairs. Applying these to a difference-in-differences approach, it finds substantial evidence that, after several years of membership, countries gradually converge towards the positions and norms of the Union. It is argued that these overall findings are consistent with a socialization effect, but not with material cost-benefit calculations. © 2023 Kluwer Law International BV, The Netherlands.",TestAnalysis
"This text is an analysis of a series of pinhole photographs, by Anne Peschken and Marek Pisarsky (Urban Art), entitled East Side Story I (Myślibórz). Photo research on migration and arrival stories, 2019 on-going. The main thesis is that these photographs are a model example of images which, while addressing the theme of migration in the representational layer, also activate the processual and migratory nature of visual forms themselves. In order to substantiate this thesis, the East Side Story project is examined in the following contexts: critical border (art) studies; H. Belting’s anthropology of the image; memory studies; re-enactment; the blurriness of images made with a pinhole camera; A. Berleant’s re-thinking aesthetics and the notion of aesthetic embodiment. Reflecting on the tension between history, memory, identity and politics and activating the critical potential of borderscaping, Peschken and Pisarsky transform the landscape of the Polish-German borderland into an anachronistic narrative agent. The photographs from the East Side Story series are thus transgenerational corpographies of memory, showing that migration is a key and inalienable element of Polish history. © The Author(s) 2023.",TestAnalysis
"The text explains the main themes and conceptual arguments of the thematic issue on the reception of Ratzel's spatial theories in Italy, France, Germany and the USA. The work and impact of Friedrich Ratzel between 1880 and 1945 are examined in the perspective of a history of transformation based on the history of knowledge. As a result, the case studies demonstrate that Ratzel's work had an international impact on the object constitution of the academic subject of geography, firstly through the later widespread geopolitical theorising, secondly with regard to the conceptualisation of anthropogeography and thirdly in the relationship of the discipline to the formation of nation states, territorial rule and colonial expansion. Equally decisive is that some interpretations of Ratzel's writings turn out to be rather appropriations of already existing receptions of his work. This reception of reception is undoubtedly a key element of a differentiated impact analysis.  © Copyright: ",TestAnalysis
"Background: Receiving a breast cancer diagnosis and treatment is both a physical and emotional journey. Previous studies using single-source data have revealed common and culture-specific emotional experiences of patients living with breast cancer. However, few studies have combined such data from multiple sources. Thus, using a variety of data sources, the current study sought to explore the emotional experiences of women in China newly diagnosed, post-operative, or undergoing chemotherapy. We posited that even though women living with breast cancer in China have multiple channels through which they can express these emotional experiences, little variance would be found in their emotional expressivity and the themes they want to express due to cultural inhibitions. Methods: Text data from female patients newly diagnosed, post-operative, or undergoing chemotherapy were collected between June 2021 and January 2022 via a Python web crawler, semi-structured interviews, and an expressive writing intervention. Data were transcribed and subjected to thematic analysis. Reporting followed the consolidated criteria for reporting qualitative studies (COREQ) guidelines. Results: Analyses were based on 5,675 Weibo posts and comments published by 448 posters and 1,842 commenters, transcription texts from 17 semi-structured interviews, and 150 expressive writing texts. From this total collection of 461,348 Chinese characters, three major themes emerged: (i) conflicting emotions after diagnosis; (ii) long-term suffering and treatment concerns; and (iii) benefit finding and cognitive reappraisal. Conclusions: Despite gathering information from various sources, we found that distress from body-image disturbances, gender role loss and conflict, and changes in sexuality and fertility, were consistent among this sample of female Chinese patients with breast cancer. However, when women engaged actively in benefit finding and cognitive reappraisal with strong social support, patients were able to find ways to adapt and reported post-traumatic growth. Strong social support was an important facilitator in this growth. These study findings emphasize that healthcare professionals ought to increase cultural sensitivity, provide multiple channels to encourage patients to express their emotions, and incorporate screening for patients' emotional distress at all diagnostic and treatment phases as part of routine nursing care. Copyright © 2023 Li, Ure, Zheng, Zheng, Liu, Zhou, Jian, Sun, Li, Xie, Mai, Zhao, Liu, Lai, Fu and Wu.",TestAnalysis
"Background and Objective: Heart failure (HF) in the pediatric population is a multi-factorial process with a wide spectrum of etiologies and clinical manifestations, that are distinct from the adult HF population, with congenital heart disease (CHD) as the most common cause. CHD has high morbidity/mortality with nearly 60% developing HF during the first 12 months of life. Hence, early discovery and diagnosis of CHD in neonates is pivotal. Plasma B-type natriuretic peptide (BNP) is an increasingly popular clinical marker in pediatric HF, however, in contrast to adult HF, it is not yet included in pediatric HF guidelines and there is no standardized reference cut-off value. We explore the current trends and prospects of biomarkers in pediatric HF, including CHD that can aid in diagnosis and management. Methods: As a narrative review, we will analyze biomarkers with respect to diagnosis and monitoring in specific anatomical types of CHD in the pediatric population considering all English PubMed publications till June 2022. Key Content and Findings: We present a concise description of our own experience in applying plasma BNP as a clinical biomarker in pediatric HF and CHD (tetralogy of fallot vs. ventricular septal defect) in the context of surgical correction, as well as untargeted metabolomics analyses. In the current age of Information Technology and large data sets we also explored new biomarker discovery using Text Mining of 33M manuscripts currently on PubMed. Conclusions: (Multi) Omics studies from patient samples as well as Data Mining can be considered for the discovery of potential pediatric HF biomarkers useful in clinical care. Future research should focus on validation and defining evidence-based value limits and reference ranges for specific indications using the most up-to-date assays in parallel to commonly used studies. © Cardiovascular Diagnosis and Therapy. All rights reserved.",TestAnalysis
"Background: The Alvarado score (AS) has not been widely used for diagnosing acute appendicitis although it has shown to be a good predictor for diagnosing appendicitis. The aim was to perform a systematic review of the available literature and synthesize the evidence. Methods: A systematic review was performed as per the PRISMA guidelines using search engines like Ovid, PubMed, and Google Scholar with predefined, strict inclusion and exclusion criteria. The quality assessment of included studies was performed using the QUADAS 2 tool. Summary statistics were performed for all variables. A linear regression model was performed between dependent and independent variables using STATA software. Heterogeneity testing showed significant heterogeneity within the included studies; hence, a forest plot with pooled estimates could not be constructed, and therefore a meta-regression was performed. Results: Seventeen full-text articles met inclusion and exclusion criteria. Ten of which were identified as low-risk studies. Five studies were included in final data pooling with total patients being 2239 and mean age of 31.9 years. (1) Linear regression demonstrated an association between 'histological appendicitis' and 'AS 7-0' with patients receiving intervention, with a significant P value of less than 0.005. (2) Meta-regression demonstrated a positive coefficient (0.298), a positive Z score of 2.20 with a significant P value of 0.028 for patients with 'high AS' who received interventions that were significantly proven to be 'histologically appendicitis', indicating a cause-and-effect relationship. Conclusion: High AS (7 and above) is a significant predictor of acute appendicitis. The authors recommend further prospective randomized clinical trials to establish a cause-and-effect relationship. Copyright © 2023 The Author(s). Published by Wolters Kluwer Health, Inc. This is an open access article distributed under the terms of the Creative Commons Attribution-Non Commercial-No Derivatives License 4.0 (CCBY-NC-ND), where it is permissible to download and share the work provided it is properly cited. The work cannot be changed in any way or used commercially without permission from the journal.",TestAnalysis
"BACKGROUND: Hundreds of randomised controlled trials and dozens of meta-analyses have examined psychotherapies for depression-yet not all points in the same direction. Are these discrepancies a result of specific meta-analytical decisions or do most analytical strategies reaching the same conclusion? OBJECTIVE: We aim to solve these discrepancies by conducting a multiverse meta-analysis containing all possible meta-analyses, using all statistical methods. STUDY SELECTION AND ANALYSIS: We searched four bibliographical databases (PubMed, EMBASE, PsycINFO and Cochrane Register of Controlled Trials), including studies published until 1 January 2022. We included all randomised controlled trials comparing psychotherapies with control conditions without restricting the type of psychotherapy, target group, intervention format, control condition and diagnosis. We defined all possible meta-analyses emerging from combinations of these inclusion criteria and estimated the resulting pooled effect sizes with fixed-effect, random-effects, 3-level, robust variance estimation, p-uniform and PET-PEESE (precision-effect test and precision-effect estimate with SE) meta-analysis models. This study was preregistered (https://doi.org/10.1136/bmjopen-2021-050197). FINDINGS: A total of 21 563 records were screened, and 3584 full texts were retrieved; 415 studies met our inclusion criteria containing 1206 effect sizes and 71 454 participants. Based on all possible combinations between inclusion criteria and meta-analytical methods, we calculated 4281 meta-analyses. The average summary effect size for these meta-analyses was Hedges' gmean=0.56, a medium effect size, and ranged from g=-0.66 to 2.51. In total, 90% of these meta-analyses reached a clinically relevant magnitude. CONCLUSIONS AND CLINICAL IMPLICATIONS: The multiverse meta-analysis revealed the overall robustness of the effectiveness of psychotherapies for depression. Notably, meta-analyses that included studies with a high risk of bias, compared the intervention with wait-list control groups, and not correcting for publication bias produced larger effect sizes. © Author(s) (or their employer(s)) 2023. No commercial re-use. See rights and permissions. Published by BMJ.",TestAnalysis
"The article analyses the essay “Waiting for the Passage-Boat” (1857) by the Russian writer and publicist Dmitry Vasilyevich Grigorovich. The essay was published in the magazine Sovremennik (“Contemporary”), and its publication seemed to draw a line under the discussion of the slaver and serfdom question in Russian magazines. Grigorovich’s prose played a role in this discussion. Grigorovich was one of the first writers of Russian realism (the so-called “natural school”) and tried to move away from the theatre vaudeville and sentimental images of Russian peasants in his novellas The Village and Anton-Goremyka. His subsequent texts on peasant themes, written during the “gloomy seven years”, varied the source material, sometimes showing a movement towards melodrama. The article offers a variant of a narratological and hermeneutic reading of the essay in the aspect of reflection and narration. In the author’s opinion, Grigorovich demonstrates the exhaustion of the peasant theme in literature, using the technique of multiple storytelling (from Hoffmann’s Serapion Brothers or Odoevsky’s Russian Nights). This becomes most obvious at that moment of the narrative, when the “right to voice” passes to casual interlocutors, while the narrator, correlated with the writer, loses this right. He is not recognized as the author of stories in his environment and takes the passive role of a listener. The use of allusions, remeniscences (from Karamzin, Radishchev, Mérimée, de Prevost), and auto-quotation creates “noise” in the communication channel, making it difficult to perceive these stories as “bitter truth” (Stendhal), at the same time convincing the reader of the impossibility of finding an adequate description language for peasant everyday life. In this regard, Grigorovich’s position coincides with that of Honore de Balzac in the introduction to his Les Paysans or of Pavel Annenkov that was declared in his main article: you can expect a lot of pleasure from the expression in art of the course of common life, many pictures, original faces, excellent descriptions, but hardly real knowledge of this course as a subject for discussion and conclusion. Yet many of the writers and a very large number of readers have in mind this latter goal; but it is the same as judging about the height of the people who built the Egyptian pyramid by the pyramid’s height. This epistemological impossibility is illustrated in Grigorovich’s essay: the nobles and the peasant world exist in parallel. Thus, interlocutors do not feel empathy, and the purpose of conversation is not to change reality, but to spend time. Thus, the conversation of the nobles can be correlated with the Socratic dialogue, in which the possibility of the maieutic acquisition of truth is not realized due to the failure of communication. The arrival of the passage-boat demonstrates the inconsistency and exhaustion of conversations about people’s happiness, becomes a marker of such a failure. The article is illustrated with fragments of critical articles and epistolary works by Grigorovich. whose 200th anniversary inspires researchers to search for the latest interpretations and update the ways of reading the writer’s texts. Results and observations that are presented in the article can be used in teaching the history of 19th-century Russian literature. © 2023 Tomsk State University. All rights reserved.",TestAnalysis
"The famous Moroccan traveller Muahammad b. Battuta, who left Tangier in 1325, claims to have made a journey that took him across most of the then Islamicate world. The country in which he recounts having stayed the longest was India, where he says he remained from 1333 to 1341/1342, mostly in the Islamic Sultanate of Delhi. A long section of his Riahla is dedicated to the sub-continent and modern historians of this region ascribe to it an important documentary value, although it has been argued that Ibn Battuta may have borrowed - not to imply copied - information from other sources in other parts of the work. As concerns India, Ibn Battuta speaks of two epidemics and one deadly disease that occurred in 1334-5 and 1344. Some scholars have referred to them as cholera, while others have suggested it was the plague - thus supporting the hypothesis that the medieval plague pandemic had struck India before reaching the Middle East. How did this confusion arise? What exactly does Ibn Battuta's Riahla relate? Do Indo-Persian sources confirm these epidemics? Do they and/or Ibn Battuta's Riahla allow us to discount the presence of the Medieval Plague in India, or rather do they assert it? In order to answer these questions, this paper analyses the information on the Indian epidemics in Ibn Battuta's Riahla and compares the text with its translations in the principal European languages and with Indo-Persian chronicles. These analyses reveal something of a lexical muddle which, in my opinion, has contributed to some errors and misunderstandings regarding the diseases in question. But another question arises: is it possible to read the information provided by Ibn Battuta and the Indian chronicles in a consilient way, that is, taking into account not only the analysis of written documents, but also the recent and current findings in genetics of plague, and in particular on the Black Death? Finally, an attempt is made to answer a question that has to be asked, particularly in light of the criticism often levelled at Ibn Battuta. Considering that in one of these events he claims to have witnessed the epidemic, is there any reason to suppose that he did not? Regarding the other two events that he did not claim to witness firsthand, is there any cause to doubt his claims?  Copyright © The Author(s), 2023. Published by Cambridge University Press on behalf of SOAS University of London.",TestAnalysis
"In this paper we challenge a staple of modern scholarship, which considers Hippias’ Synagogé as the first instance of Greek doxographical work. In this article, I offer a fresh analysis of the relevant ancient texts and of the state of scholarship. The result of this investigation casts doubt on the real nature and scope of Hippias’ Synagogé as a mere collection of passages. I argue that this usually taken for granted interpretation does not capture what the Synagogé may have been. By contrast, I suggest restoring the entertaining nature and rhetorical strategy that lie at the heart of Hippias’ literary effort. © 2023 Classical Association of the Middle West and South, Inc.. All rights reserved.",TestAnalysis
"Purpose: There is ambiguity regarding whether coronavirus disease 2019 (COVID-19) is a boon or bane for the IT services industry. On the one hand, it has created opportunities, especially with the growth of collaborative technologies. On the other hand, many firms have reduced their IT budgets owing to the ongoing recession. This study explores how IT firms have assessed the risk of the pandemic in the early days and informed capital market participants. In addition, it examines the impact of such online disclosures on information asymmetry. Design/methodology/approach: The authors analysed annual reports of publicly listed firms in the USA filed on the Securities and Exchange Commission website in 2020 and examined whether the disclosure scenario of technology firms was different from that of the other industries. Moreover, the risk sentiment of COVID-19-related disclosures was assessed by employing text analytics. Information asymmetry was measured using the bid–ask spread. Findings: Overall, it was found that IT services firms were less likely to discuss the COVID-19 pandemic in their annual reports. Interestingly, it was observed that technology firms that chose to communicate about the pandemic had a lower incidence of words related to risks. Furthermore, communicating about COVID-19 in annual reports calms investors and improves the information asymmetry situation about the firm. Variation in the severity of the pandemic and the responses of state governments was controlled for by employing state-fixed effects in the empirical models. Originality/value: The authors inform the literature on corporate disclosures and technology and highlight the importance of effectively communicating about the pandemic. © 2021, Emerald Publishing Limited.",TestAnalysis
"Abstract: The quality of water is usually identified according to its physical, chemical and biological characteristics. The degradation of groundwater quality in a coastal region due to natural processes such as saline water intrusion, wind-driven sea spray and marine aerosols, and interaction of groundwater. This paper aim to perform water quality assessment to determine the effects of saltwater intrusion and groundwater suitability for domestic and agricultural applications. This assessment reports utilizing geographic information system (GIS) and ions geochemistry for appraisal of the groundwater quality around Mallipattinam coastal region, Thanjavur District, Tamil Nadu. There was a meaningful relationship exist among electrical conductivity, chloride, sodium, magnesium and sulphate with total dissolved solids concentrations of groundwater. This study investigates the interaction between groundwater and saltwater from empirical data collected in 15 locations around Mallipattinam coastal region, parameters namely Na+, $${\text{SO}}_{4}^{{2 - }}$$ and Cl− are responsible for the electrical conductivity (EC) variability in groundwater samples. When comparing our results with potable water quality standards described by various establishments, it had been found that concerning 60% sample water don’t seem to be appropriate for consumption purposes. The correlation coefficient for certain variables was performed in this study. EC, Total Dissolved Solids (TDS), chloride had a meaningful relationship amongst themselves and also with Na+, K+ and sulphate. Fluoride and nitrates exist no meaningful correlations with any of the parameters. Chloride also positively correlated with TDS, EC, Na+ and $${\text{SO}}_{4}^{{2 - }}$$. Sodium exhibited a positive correlation with K+, Cl− and $${\text{SO}}_{4}^{{2 - }}$$. The groundwater taken for analysis is categorized as a normal sulfate and chloride type. Hydrochemical groundwater analysis showed that a maximum number of groundwaters belong to the Na+-K+-Cl−-$${\text{SO}}_{4}^{{2 - }}$$ category. © 2023, Pleiades Publishing, Ltd.",TestAnalysis
"Although the number of people with dementia has been increasing rapidly in the Chinese-speaking world, there are relatively few Chinese children’s books published on the topic. This article analyses two Chinese-language picturebooks that approach the representation of dementia in contrasting ways. Azihaimo xiansheng [Mr Alzheimer] (2017) by Chen Yihui and Xue Huiying downplays the threat of the disease by anthropomorphising it as a friendly man while Zhanxin de yitian [A NewDay] (2017) by Guo Yu and Lianggen creates a surrealist nightmarish vision of what a person with dementia feels like daily. The article argues that, although the former book romanticises dementia while the latter presents it as a terrifying condition, both texts infantilise the person with dementia, thus reinforcing ageist tropes. © International Research Society for Children’s Literature.",TestAnalysis
"Background: Accurate measurement of food-related parenting practices is necessary to inform related interventions and program evaluation. Valid tools reflect cultural attributes that affect household food environments and feeding practices. Simple, unidirectional language adaptation approaches are insufficient to capture these attributes in assessment tools. My Child at Mealtime (MCMT) is a 27-item, validated, visually enhanced self-assessment tool to measure food-related parenting practices of low-income English-speaking parents of preschoolers. Objectives: The aim of this study was to describe the cross-cultural adaptation of MCMT into its Spanish version Mi Niño a la Hora the Comer (Mi Niño) and to establish its face validity, factor structure, and internal consistency. Methods: MCMT was adapted into its Spanish version after an iterative process that triangulated cognitive interviews with verification of conceptual equivalence by content experts to establish face validity and semantic equivalence. The resulting tool underwent confirmatory factor analysis to determine whether internal consistency was equivalent across the 2 versions. Results: Four rounds of cognitive interviews (n = 5, n = 6, n = 2, and n = 4, respectively) with Spanish-speaking women caregivers of children aged 3–5 y recruited from Head Start were conducted. Ten items were modified throughout the adaptation process. Modifications included improved clarity (6 items), comprehension (7 items), appropriateness (4 items), suitability (4 items), and usefulness (2 items) of text and/or accompanying visuals. Confirmatory factor analysis with a sample of Spanish-speaking caregivers (n = 243) resulted in 2 reliable factors representing “child-centered” (α = 0.82) and “parent-centered” (α = 0.87) food-related parenting practices. Conclusions: Face validity, semantic equivalence, and internal consistency of Mi Niño were established. This tool can be used in community settings to inform program content and measure changes in food-related parenting practices of Spanish-speaking parents and assist in setting food-related parenting goals. The next steps include exploring the correspondence of Mi Nino with mealtime behaviors observed through video recording. © 2023 The Authors",TestAnalysis
"The ""material genome project"" is mainly to change the ""trial and error"" mode of material research. Through the collection and sorting of previous experimental data, combined with simulation computing technology and information technologies such as big data and blockchain, it can establish the basic database, big data management platform, high-throughput simulation computing, experiment and analysis platform of materials, and introduce advanced AI technology such as machine learning to provide effective data support for the rapid development of high-performance new materials. According to the data processing requirement in ultra-high strength steel research, the genome database of ultra-high strength steel and its management platform are established based on the basic data collection and high flux simulation calculation of ultra-high strength steel. It presents the structural framework of database system and the overall architecture of genome data management platform, and shows some applications developed on this platform, such as integrating experimental data to form experiment report, parsing computing data to form customized visualization, and so on. This platform can accommodate various data type, including numeric, text, rich text, table, function, image, etc. and support the storage and management of TB-level mass data and the index and retrieve of million-level data records. It can implement the intelligent management of the whole process from online collection, normalized processing, storing and managing to retrieving and analyzing, so as to provide requisite data supporting for the research work of ultra-high strength steel. As a result, the platform can effectively improve the data utilization and analysis capability of research group and provide high-quality data services for developing new ultrahigh strength steel. © 2023 Chinese Society for Metals. All rights reserved.",TestAnalysis
"The peculiarities of a new stage in Russian traditional popular culture, dating from the first half of the 20th century, when many dialect speakers began to read and write, require to study the influence that is exerted on oral dialect communication by written speech. Today, in dialect speech, we need to distinguish the features originated from the oral character of this form of communication from the unwritten character of folk speech culture as a foundation of dialect communication, and from the inclusion of written components in the language consciousness of dialect speakers. The analysed material is the speech of dialect speaking Old Believers from the village Belogornoe in Saratov Oblast; the object of observation is the peculiarities of inclusion of written culture elements into the dialect speech; the main research method is the text-based analysis of dialect speech. Literate dialect speaking Old Believers’ speech is typically dialectal – by its phonetic and grammatical structure, its lexical specificity, its communicative organization, as well as from the point of view of verbalized features distinguishing the dialect speakers’ consciousness. At the same time, the informants’ speech represents a specific synthesis of oral dialect communication features with penetrating elements of bookish and written discourses, mainly religious one. The interaction of the dialect speech basis with other discursive elements can be seen in the lexical composition of dialect speaking Old Believers’ speech, in the manner of coping with the inclusions from other discourses, in the functioning of heterogeneous language units, as well as in the forms of linguistic reflection. While remaining basically dialectal with its non-functional variability as a distinguishing feature of dialectal communication, the speech of literate dialect speakers is characterized by some elements of linguistic means’ functional distribution and by the strengthening of meta-linguistic reflection. The authors conclude that changes in dialect communication, connected with the expansion of literacy among dialect speakers, have a variable character. They are determined by the source of literacy and by the circle of written texts constituting the communicative space of a dialect speaker. The peculiarities of synthesizing written culture with the Old Believers’ dialect speech are a variant of the general dynamics of folk speech tradition. © 2023 Tomsk State University. All rights reserved.",TestAnalysis
"Objectives To identify ML tools in hospital settings and how they were implemented to inform decision-making for patient care through a scoping review. We investigated the following research questions: What ML interventions have been used to inform decision-making for patient care in hospital settings? What strategies have been used to implement these ML interventions? Design A scoping review was undertaken. MEDLINE, Embase, Cochrane Central Register of Controlled Trials (CENTRAL) and the Cochrane Database of Systematic Reviews (CDSR) were searched from 2009 until June 2021. Two reviewers screened titles and abstracts, full-text articles, and charted data independently. Conflicts were resolved by another reviewer. Data were summarised descriptively using simple content analysis. Setting Hospital setting. Participant Any type of clinician caring for any type of patient. Intervention Machine learning tools used by clinicians to inform decision-making for patient care, such as AI-based computerised decision support systems or "" € model-based'""decision support systems. Primary and secondary outcome measures Patient and study characteristics, as well as intervention characteristics including the type of machine learning tool, implementation strategies, target population. Equity issues were examined with PROGRESS-PLUS criteria. Results After screening 17 386 citations and 3474 full-text articles, 20 unique studies and 1 companion report were included. The included articles totalled 82 656 patients and 915 clinicians. Seven studies reported gender and four studies reported PROGRESS-PLUS criteria (race, health insurance, rural/urban). Common implementation strategies for the tools were clinician reminders that integrated ML predictions (44.4%), facilitated relay of clinical information (17.8%) and staff education (15.6%). Common barriers to successful implementation of ML tools were time (11.1%) and reliability (11.1%), and common facilitators were time/efficiency (13.6%) and perceived usefulness (13.6%). Conclusions We found limited evidence related to the implementation of ML tools to assist clinicians with patient healthcare decisions in hospital settings. Future research should examine other approaches to integrating ML into hospital clinician decisions related to patient care, and report on PROGRESS-PLUS items. Funding Canadian Institutes of Health Research (CIHR) Foundation grant awarded to SES and the CIHR Strategy for Patient Oriented-Research Initiative (GSR-154442). Scoping review registration https://osf.io/e2mna. © 2023 BMJ Publishing Group. All rights reserved.",TestAnalysis
"Background and objective: To deal with recent issues such as climate change, rural aging, food security, and the Fourth Industrial Revolution, there is a growing interest in smart farms that can efficiently produce food with ICT. In response to the international issues, this study analyzed articles on smart farms published in international journals and KCI journals as well as Instagram hashtags through text mining and identified relevant research trends and public awareness. Methods: This study collected total 584 articles on smart farms from 2010 to 2021 and hashtags in Instagram posts uploaded in 2021. To improve the reliability of the analysis results, nouns were exclusively extracted from the abstracts and hashtags, and data preprocessing was performed by removing nouns that appear customarily and combining synonyms. After that, we analyzed frequency, degree centrality, betweenness centrality, and topic modeling. Results: The analysis results of words with high frequency and centrality by research data are as follows. KCI and international journal articles had a tendency to mainly focus on ICT system development for efficient operation of smart farms. However, KCI articles considered relevant policies to establish the technologies. On the other hand, international journal articles tended to conduct research on smart farms in a wider area of agricultural fields than KCI articles. The main topics on Instagram were diet food, rural migration, and urban agriculture. This result shows that healthy food, experiences, and education through smart farms are gaining public interest. Conclusion: Currently, there is insufficient analysis of research trends in smart farms. In this vein, this study has significance as it included academic trends and public awareness by considering both research articles and Instagram posts. We expect the results of this study to be used as useful data for decision making to set the research and policy directions required to advance smart farms in the future. © 2023 by the Society for People, Plants, and Environment.",TestAnalysis
"Video captioning requires that the model has the abilities of video understanding, video-Text alignment, and text generation. Due to the semantic gap between vision and language, conducting video-Text alignment is a crucial step to reduce the semantic gap, which maps the representations from the visual to the language domain. However, the existing methods often overlook this step, so the decoder has to directly take the visual representations as input, which increases the decoder's workload and limits its ability to generate semantically correct captions. In this paper, we propose a video-Text alignment module with a retrieval unit and an alignment unit to learn video-Text aligned representations for video captioning. Specifically, we firstly propose a retrieval unit to retrieve sentences as additional input which is used as the semantic anchor between visual scene and language description. Then, we employ an alignment unit with the input of the video and retrieved sentences to conduct the video-Text alignment. The representations of two modal inputs are aligned in a shared semantic space. The obtained video-Text aligned representations are used to generate semantically correct captions. Moreover, retrieved sentences provide rich semantic concepts which are helpful for generating distinctive captions. Experiments on two public benchmarks, i.e., VATEX and MSR-VTT, demonstrate that our method outperforms state-of-The-Art performances by a large margin. The qualitative analysis shows that our method generates correct and distinctive captions.  © 2023 Association for Computing Machinery.",TestAnalysis
"Machine learning offers a convenient and intelligent tool for a variety of applications in the fields ranging from fundamental research to financial analysis. With the explosive growth of data streams, i.e., ""big data,""optical machine learning with the inherent capacity for massive parallel processing is gradually attracting attention. Despite significant experimental and theoretical progress in this area, limited by the coherent manipulation of multibeams, high dimensional optical vector or matrix operation is still challenging. Here, by using the second harmonic generation of high dimensional orbital angular momentum superposition states, we present a compact and robust optical clustering machine, which is the crucial component in machine learning. In experiment, we conduct supervised clustering for classification of three- and eight-dimensional vectors and unsupervised clustering for text mining of 14-dimensional texts both with high accuracies. The presented optical clustering scheme could offer a pathway for constructing high speed and low energy consumption machine learning architectures.  © 2023 Author(s).",TestAnalysis
"The return voyage of the Argonauts described in the Library presents remarkable differences compared to the model provided by Apollonius of Rhodes. Here we focus specifically on two aspects of the trip in Apollodorus’s version, with the aim of providing new insights on these elements of the story that deviate from Apollonius: the order of the stages in the Adriatic Sea and the absence of the Libyan episode. As a result, our analysis allows us to appreciate, beyond the canonical value acquired by Apollonius’s text in the early imperial period, the important role played by other local myths, even glimpsing the influence of more ancient traditions about the journey of the Argonauts. Moreover, Apollodorus’ authorial choices seem to reveal a general scepticism for the part of the mythographer regarding the possibility of adapting the landscape of the mythological traditions to the geographical knowledge of his time. © 2023 Classical Association of the Middle West and South, Inc.. All rights reserved.",TestAnalysis
"The research aims to prove the validity of studying the confessional language personality (LP) by domestic written monuments and to identify the representational aspects and means of the Old Believers’ worldview. The research material is original texts of two diaries (1915–1923 and 1956–1975) and personal notes (1940–1980) written by the Old Believers’ community members living in the north of Tomsk Oblast. The total lexical volume of these sources is about 15 thousand word usages. The analysis is based on the sociolinguistic portraiture method, which involves describing linguistic facts reflected in texts of different levels (graphics, vocabulary, grammar, etc.) and the authors’ personal qualities indicating their religious attitudes. We first examine LPs recognized a priori as confessional, then texts in search for information verifying the hypothesis of analysis in them. This analysis is based on Yuri Karaulov’s idea of the three-level LP structure, as well as the experience of describing individual religious LPs presented in linguistic works by Tolstova (2007), Chikovani (2016), Plotnikova (2021). We revealed all the features identifying this confessional community: marginality, insularity, heightened self-consciousness, self-sufficiency, traditionalism, eschatology. These features are related to each other. All of them are manifested textually by different means: special lexical items, grammatical forms, graphics, descriptions of people of one’s circle and their activities in the coordinates of natural time and reclaimed areas, or by a hidden polemic suggesting the reflection of only positive aspects of being in this description. The markers of Old Believers’ LP at the verbal(grammatical)-semantic level are lexical items with a confessional meaning (Isus, Rozhestvo, bratets, otche), a wide variation due to bookish and written linguistic means (noshch’, ezero, glagolit’, desnitsa, sil’nAGO, vtorYY), mastery of the semi-uncial writing norms. The traditional values of the Old Believer world (LP’s cognitive level) manifested in records include the affirmation of the equality of all community members; family-like closeness of like-minded people; the recognition of authorities only in terms of spirituality (otche –godfather); the high significance of labor, books, sacred texts; the realized need for strict adherence to all religious canons (for example, the admissibility of only passive hunting, voluntary assumption of functions of community chroniclers). In our opinion, the tasks of preserving the Old Believers’ sacred space that express the writers’ interests and goals reflected in the records constitute the pragmatic (motivational) level of the confessional LP. Although we revealed the three-level structure mainly on the material of two specific confessional LPs, there are reasons to correlate the identified features with the generalized Old Believer’s LP. © 2023 Tomsk State University. All rights reserved.",TestAnalysis
"The article analyses the feuilleton as a speech genre. The communicative tasks, linguistic embodiment, images of the author and the addressee in the context of studying the forms of interaction between literature and journalism in transitional epochs are investigated. Based on the texts of Shpilka (Vasily Ivanov) and Nadezhda Lukhmanova, the author of the article examines the strategies and tactics of the feuilleton in the newspaper Yuzhny kray for 1900–1905. The term “feuilleton” contains at least two meanings: (1) a heading with artistic and journalistic texts; (2) genre commonality of texts. The determination of the genre by socio-cultural circumstances and the natural revival of the satirical trend for the pre-revolutionary time are substantiated. Among the features uniting the texts, the article notes the concentration on current events, the lightness and liveliness of the style, the combination of artistic and journalistic properties in the texts, the ease and spontaneity of the composition. Social and political issues, as well as the principles of relevance and topicality, began to dominate by 1905. The growth of sociality in the feuilleton can be explained by a number of factors: impact as a fundamental feature of the genre, as well as the format of the newspaper text itself, where an ongoing dialogue with subscribers is conducted, which provides influence and enhances the role of interaction with the interests of readers. One cannot fail to note the factor of time, especially before the revolution, when the polarity in views among members of society increased, and journalism and propaganda strategies were used more, including through newspaper materials. In the space of feuilleton studies, literary and artistic features and journalistic ideas are combined. For Shpilka’s texts, the most appropriate definition would be the following: the feuilleton is an artistic and journalistic genre in which the comic essence of negative phenomena and situations of reality is revealed through the inverse, associative development of a theme using allegory techniques. Lukhmanova’s texts in form and direction gravitate towards the novella. They are characterized by confession, narrative essay, descriptiveness and detail. Thus, when comparing the works of the two feuilletonists, it is more appropriate to speak of the varieties of the feuilleton. The works of both authors lead to the intersection of journalism and literature, which corresponds to the original borderline of the genre. In the space of their feuilleton studies, literary and artistic features and journalistic ideas are combined. © 2023 Tomsk State University. All rights reserved.",TestAnalysis
"Objective: To explore the abuse and neglect phenomenon in long-term care facilities for the elderly population. Method: The systematic review comprised search on PubMed, CINAHL, MEDLINE and ScienceDirect databases following Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. The key words used were older people care, long-term care, older people and older adults. Articles published in the last 5 years between 2017 to 2021 in recognised English-language journals and whose full text was available on the websites were included. Details of the selected studies were noted and analysed. Results: Of the 336 studies initially identified, 15(4.46%) were reviewed in detail. Of them, 3(20%) had been done in North America, 6(40%) in Europe and 6(40%) in Asia. The prevalence of abuse and neglect in long-term care facilities for the elderly was generally high, with nursing home staff mostly involved due to burnout syndrome or related to personal factors, such as childhood adversity and work-related stress. Conclusion: Better understanding is critical for improving the quality of care in long-term care facilities to prevent abuse and neglect with the elderly. © 2023 Pakistan Medical Association. All rights reserved.",TestAnalysis
"Problem-based learning (PBL) has been used in different domains, and there is overwhelming evidence of its value. As an emerging field with excellent prospects, learning analytics (LA)—especially multimodal learning analytics (MMLA)—has increasingly attracted the attention of researchers in PBL. However, current research on the integration of LA with PBL has not related LA results with specific PBL steps or paid enough attention to the interaction in peer learning, especially for text data generated from peer interaction. This study employed MMLA based on machine learning (ML) to quantify the process engagement of peer learning, identify log behaviors, self-regulation, and other factors, and then predict online PBL performance. Participants were 104 fourth-year students in an online course on social work and problem-solving. The MMLA model contained multimodal data from online discussions, log files, reports, and questionnaires. ML classification models were built to classify text data in online discussions. The results showed that self-regulation, messages post, message words, and peer learning engagement in representation, solution, and evaluation were predictive of online PBL performance. Hierarchical linear regression analyses indicated stronger predictive validity of the process indicators on online PBL performance than other indicators. This study addressed the scarcity of students’ process data and the inefficiency of analyzing text data, as well as providing information on targeted learning strategies to scaffold students in online PBL. Copyright © 2023 Wang, Sun, Cheng and Luo.",TestAnalysis
"Transplant-associated thrombotic microangiopathy (TA-TMA) is an increasingly recognized complication of allogeneic and autologous hematopoietic cellular therapy (HCT), associated with significant morbidity and mortality. Although the central drivers of the disease are thought to be endothelial damage and complement activation, no specific diagnostic biomarkers have been identified. TA-TMA is typically diagnosed using criteria comprised of non-specific clinical and laboratory features. Some patients will have a self-remitting course, but more than half develop multi-organ dysfunction or die, making prognostic biomarkers critical. Prevention of TA-TMA, an approach central to other HCT complications such as graft-versus-host disease, is largely untested in part due to a lack of identified early high-risk biomarkers. We conducted a systematic review to summarize the diagnostic, early risk, and prognostic biomarkers of TA-TMA. We screened the titles and abstracts of 1524 citations. After screening out duplications, we read the abstracts of 979 papers and fully reviewed 132 full-text publications. Thirty-one publications fulfilled the inclusion criteria of more than five patients with TA-TMA and a reported measure of association with diagnosis, prognosis, or risk of later development of the disease. Fourteen studies (45%) were with adults, 12 (39%) were with children <18 years old, three included both children and adults, and two did not report age. There were 53 biomarker or biomarker signature entries, and a total of 27 unique biomarkers. Only four biomarkers reported sensitivity and specificity. The single biomarker with the most robust data was sC5b-9, which conferred diagnostic, prognostic, and risk implications. Studies of combinations of biomarkers were rare. No meta-analyses were performed because of significant heterogeneity between studies. The limitations of studies included small sample size, study designs with a high risk of bias (i.e., case–control), the timing of sample collection, and the selection of controls. Furthermore, only two (6%) studies included a training and validation cohort. Cut-off points are needed to stratify groups, as most biomarkers do not have normal values, or normal values cannot be assumed in the HCT setting. In the future, multi-institutional, collaborative efforts are needed to perform rigorously designed, prospective studies with serially enrolled patients, with samples collected at the time of TA-TMA diagnosis, careful selection of controls, and validation of selected biomarkers and cut-off points in a separate cohort. Copyright © 2023 Schoettler, Bhatt and Vasu.",TestAnalysis
"Purpose: Intelligent manufacturing has attracted extensive attention from national strategy, academic research and enterprises' practices. The purpose of this study is to investigate the influence of intelligent manufacturing on performance in manufacturing firms. Moreover, how intelligent manufacturing technology affects enterprise performance, this study provided a practice that can be replicated by other businesses. Design/methodology/approach: This study uses text mining to collect the intelligence level of Chinese listed companies. It uses quantitative analysis to test the proposed model based on samples of 2,091 manufacturers. Findings: Intelligent manufacturing has positive effect on short-term performance and long-term performance. Intelligent manufacturing can empower firms with ambidextrous capabilities, including exploit capability and explore capability. Exploit capability has positive effects on short-term performance and long-term performance. Explore capability has negative effects on short-term performance, but has positive effects on long-term performance. Originality/value: On the theoretical side, it enriches the research framework between intelligent manufacturing and enterprise performance. This study explains the preconditions and results of ambidextrous capabilities. Moreover, based on the practice-based view (PBV), this study proposes that technologies can be used as strategies, filling a gap in the existing research on strategic management. On the practical side, how to quantify the intelligent manufacturing level of enterprises provides a certain reference. Also, this study provides an easy to imitate practice that can serve as a model for under-performing enterprises. © 2022, Emerald Publishing Limited.",TestAnalysis
"This research aimed to study the role of selective attention, the retention and executive components of working memory, and verbal aptitude in producing explanatory inferences in the comprehension of expository texts. For this purpose, 171 undergraduates completed tests of working memory, selective attention, verbal aptitude, and explanatory inference questionnaires after reading expository texts. The results of the structural equation modeling indicated that the production of explanatory inferences is determined directly by verbal aptitude and the executive component of verbal working memory. The analysis also detected a mediation interaction effect between the abilities to produce explanatory inferences, selective attention span, and the ability to store verbal information in working memory. These components indirectly affected the ability to infer via the executive component of working memory. This suggest that the ability to make explanatory inferences in the comprehension of expository texts is strongly related to verbal aptitude and the capacity to process information in working memory, while the ability to manage selective attention and retain verbal information in short-term memory have an impact on the ability to generate inferences mediated by working memory. © 2023, Fundacion para el Avance de la Psicologia. All rights reserved.",TestAnalysis
"In the original publication [1], the data of aroma components in Table 2 were not complete. Therefore, we decided to make additional improvements, thus giving a more complete picture of the composition and dynamic changes of the floral aroma in the three species of Tilia. This article has been updated at some points as follows: Abstract—The sentence “47 aroma compounds were preliminarily identified, including terpenes, alcohols, ethers, esters, aldehydes, heterocyclics and alkanes” was replaced with “A total of 70 volatile components were detected, 43 aroma compounds were identified”. The content “9 crucial aroma components” was replaced with “14 crucial aroma components”. Results—Subsequent results and points based on data from Table 2 have been updated along with the corresponding figures and tables. Discussion—The sentence “The three species from Tilia were all in the blooming stage when the peak period of fragrance emission as seen by the results” was replaced with “The emissions of major aroma components in the three species of Tilia were basically in the blooming stage as seen by the results”. The content “9 key floral scent components” was replaced with “14 key floral scent components”. Paragraph in Section 2.5 should be corrected as: Excel (Microsoft Office Standard 2019, Microsoft Corporation, Redmond, WA, USA) was used to calculate the relative content (%) of each aroma component; UpSet diagrams were performed by using the OmicShare tools, a free online platform for data analysis (https://www.omicshare.com/tools), accessed on 5 June 2022; SPSS Statistics 26.0 software (IBM, Armonk, NY, USA) was used for the Kruskal–Wallis non-parametric test; SIMCA 14.1.0.2047 software (Umetrics, Umeå, Sweden) was used for the PLS-DA model, drawing score scatter plot and loading scatter plot, calculation of VIP value and permutation test; Matlab R2021a software (Math Works Corporation, Natick, MA, USA) was used for calculating the aroma similarity rates; aroma characteristics were collected from ‘The Good Scents’ company network database (www.thegoodscentscompany.com), accessed on 5 January 2022. OriginPro 2021 software (OriginLab Corporation at Northampton, MA, USA) was applied to draw heat map. Updated tables and figures are shown below: Aroma components and relative contents in samples of the three species from Tilia. Note: RT—Retention time; RI—Retention index; NI—Not identified. UpSet diagrams based on the aroma components at different flowering stages of the three species. (a) T. cordata; (b) T. tomentosa; (c) T. miqueliana. Note: “set size” represents the dataset of aroma components in each species of Tilia at different flowering periods; the horizontal bar chart on the left represents the statistical value of floral fragrance components in each period; the single point of the intermediate matrix represents the existence of unique aroma components in a certain period, and 2 or 3 points are connected by lines to represent the unique components with intersection of multiple periods; the numbers at the top of the vertical bars represent the values of the unique aroma components at the intersection points at different periods. PLS-DA model for aroma components at different stages of the three species. (a) Score scatter plot; (b) Loading scatter plot. Permutation test of PLS-DA model. (a) T. cordata; (b) T. miqueliana; (c) T. tomentosa. Characteristics of the 14 crucial components in the PLS-DA model. VIP: variable importance in projection. Aroma similarity rates between the three species of Tilia at different flowering stages. Note: The closer clustering relationship is, the aroma similarity rate draws nearer to 1.000. Heat map of content distributions about 14 crucial components in the three species from Tilia. We have revised all affected figures and tables as well as values reported in the main text in the corrected article. The authors apologize for any inconvenience caused and state that the scientific conclusions are unaffected. This correction was approved by the Academic Editor. The original publication has also been updated. © 2023 by the authors.",TestAnalysis
"Foreign tourism has gained immense popularity in the recent past. To make a rational decision about the destination to be visited one has to go through variety of social media sources with very large number of reviews, which is a tedious task. Automated analysis of these reviews is quite complex as it involves non structured text data having slang terms also. Moreover, these reviews are pouring in continuously. To overcome this problem, this paper provides a Big Data analytics-based framework to make appropriate selection of the destination on the basis of automated analysis of social media contents based upon the adaptation and augmentation of various tools and technologies. The framework has been implemented using Apache Spark and Bidirectional Encoder Representation Transformers (BERT) deep learning models through which raw text review are analysed and a final score based on five metrics is obtained to recommend destination for visit. © 2023 International Journal on Recent and Innovation Trends in Computing and Communication. All rights reserved.",TestAnalysis
"Objective To compare the perioperative outcomes and safety of percutaneous nephrostomy (PCN) and retrograde ureteral stenting (RUS) in the treatment of acute obstructive upper urinary tract infection. Methods A comprehensive search was performed on the MEDLINE, EMBASE and Cochrane Central Register of Controlled Trials to identify relevant literatures. The retrieval period was from the establishment of the database to August 2022. Inclusion criteria: ①Randomized controlled trial (RCT) of PCN and RUS in the treatment of acute obstructive upper urinary tract infection; ②Studies provided accurate data for analysis, including the total number of subjects and the results of each index; ③The full text of the study was available, and different literatures published in the same cohort were included in the newly published data. ④The observation indexes included the time for the recovery of body temperature, creatinine, leukocyte, operation, radiation exposure, postoperative fever, postoperative pain, and the incidence of postoperative fistulotomy or stent displacement. Exclusion criteria: ①non-RCT study; ②unable to obtain the full text. Two researchers independently screened the literature and evaluated the literature quality, and all the statistical data were analyzed by RevMan5.3 software. Results Seven trials enrolled 727 patients were included in the meta-analysis, 412 in the PCN group and 315 in the RUS group included. Meta-analysis revealed that the advantages of PCN were lower incidence of postoperative hematuria (OR=0.54, 95%CI 0.30-0.99, P=0.040) and lower incidence of insertion failure (OR=0.42, 95%CI 0.21-0.81, P=0.010), but the fluoroscopy time of RUS group was shorter than that of PCN group (MD=0.31, 95%CI 0.14-0.48, P<0.01). Moreover, there was no significant difference in time to normalization of temperature, time to normalization of creatinine, time to normalization of WBC, operative time, postoperative fever, postoperative pain, postoperative nephrostomy tube or stent slippage rate between the two surgical methods(P>0.05). Conclusions The radiation exposure time of PCN was longer than that of RUS, but the incidence of postoperative hematuria and catheterization failure was lower than that of RUS. © 2023 Chinese Journal of Urology. All rights reserved.",TestAnalysis
"When a digital collection has been processed by OCR, the usability expecta-tions of patrons and researchers are high. While the former expect full text search to return all instances of terms in historical collections correctly, the lat-ter are more familiar with the impacts of OCR errors but would still like to apply big data analysis or machine-learning methods. All of these use cases depend on high quality textual transcriptions of the scans. This is why the National Library of Luxembourg (BnL) has developed a pipeline to improve OCR for existing digitised documents. Enhancing OCR in a digital library not only demands improved machine learning models, but also requires a coherent reprocessing strategy in order to apply them efficiently in production systems. The newly developed software tool, Nautilus, fulfils these requirements using METS/ALTO as a pivot format. The BnL has open-sourced it so that other libraries can re-use it on their own collections. This paper covers the creation of the ground truth, the details of the reprocessing pipeline, its production use on the entirety of the BnL collection, along with the estimated results. Based on a quality prediction measure, developed during the project, approximately 28 million additional text lines now exceed the quality threshold. © 2023, Igitur, Utrecht Publishing and Archiving Services. All rights reserved.",TestAnalysis
"This research evaluates the media treatment given to translators and interpreters during the war in Ukraine, with the main objective of finding out the coverage they have received in El Mundo, one of the most widely read newspapers in Spain. To this end, its publications from 24 February to 14 April 2022 were analysed quanti-qual-itatively. The resulting corpus yielded a total of 49 texts/60,000 words and revealed the media invisibility of these professionals in the Spanish press, despite their im-portant role in conflict situations. © GKA Ediciones, authors.",TestAnalysis
"Introduction The production of clinical practice guidelines (CPGs) has grown in the past years. Notwithstanding, the quality of these documents and their recommendations for the treatment of schizophrenia in children and adolescents is still unknown. Objective To assess the quality of the guidelines and recommendations for the treatment of schizophrenia in this population. Methods CPGs from 2004 to December 2020 were identified through a systematic search on EMBASE, MEDLINE, PsycINFO, PubMed, Epistemonikos, VHL, Global Index Medicus and specific CPG databases. The CPGs' quality was independently assessed by three reviewers using AGREE II and they were considered of high quality if they scored ≥60% in domains 3 and 6. The evidence classification systems were described, the quality of recommendations was assessed in pairs using AGREE-REX and the recommendations were compared. Results The database search retrieved 3182 results; 2030 were screened and 29 were selected for full-text reading. Four guidelines were selected for extraction. Two CPGs were considered of high quality in the AGREE II assessment. We described the commonly agreed recommendations for each treatment phase. The pharmacological recommendations were described in all treatment phases. Scores of AGREE-REX were lower for psychosocial recommendations. Conclusion There are still few clinical studies and CPGs regarding schizophrenia in children and adolescents. The quality of the documents was overall low, and the quality of the recommendations report has much to improve. There is also a lack of transparency about the quality of the evidence and the strength of the recommendations. Protocol registration number CRD42020164899. © 2023 BMJ Publishing Group. All rights reserved.",TestAnalysis
"Sentiment analysis is a vital area of current research. The area of sentiment analysis is extensively used for observing text data and identifying the sentiment element. Every day, e- commerce sites produce a massive amount of text information from customer's comments, reviews, tweets, and feedbacks. One of the most recent technological advances in web development is the emergence of social networking websites. It aids in communication and knowledge gathering. Aspect - based evaluation of this information can help businesses to gain a greater understanding of their consumers' expectations and then shape their plans accordingly. It is difficult to convey the exact sentiment of a review. In this study, we demonstrated an approach that focuses on sentimental aspects of the item's characteristics. Consumer reviews on Amazon and IMDB have been presented and evaluated. We obtained the dataset from the UCI repository, where each analysis's opinion rates are first observed. To get meaningful information from datasets, and to eliminate noise, the pre-processing operations are performed by the system such as tokenization, punctuation, whitespace, special character, and stop-word removal. For the purpose of accurately representing the preprocessed data, feature selection methods such as word frequency-inverse document frequency are utilized (TF–IDF). The customer reviews from three datasets Amazon, Yelp, and IMDB is merged and classification is performed using classifiers such as Naïve Bayes, Random Forest, K-Nearest Neighbor (KNN), and Support Vector Machine (SVM). In last, we provide some insight into the future text classification work. © 2023 Lavoisier. All rights reserved.",TestAnalysis
"[Purpose/Significance] We used to process soybean leaf data by looking at them and process data manually, but this method is very inefficient. In order to improve the classification accuracy and efficiency of soybean leaf images, further for storage and management of these images, we used the deep learning technique to make an in-depth study of text data and image data of soybean leaves for the image recognition and classification. The application of deep learning in agricultural data management mainly focuses on the image recognition and classification of plants and plant phenotypes in large-scale data, detection and classification of agricultural diseases and pests, detection and classification of crops and weeds, and prediction of crop yield. Through case analysis, our sample data demonstrated the application process of deep learning technology. [Method/Process] This paper systematically described the whole process of classification and recognition of agricultural data by using the deep learning technique. Through recognition and disease monitoring of plant leaves, the leaf morphology of soybean plants in the soybean experimental field of Heilongjiang Academy of Agricultural Sciences was taken as an example. We analyzed the image features of soybean leaf morphology, and carried out the classification and recognition research of soybean leaf morphology based on deep learning. Deep learning techniques have replaced shallow classifiers that use manual feature training and can identify soybean leaves with a high degree of accuracy as long as sufficient data are available for training. We adopted DenseNet model, which is suitable for common network model. The advantages of this model are that it has the best performance and the least storage requirements. First袁 we selected support vector machine (SVM) and random forest (RF) in traditional machine learning methods to identify soybean leaf morphology. Second, AlexNet and ResNet were selected to identify soybean leaf morphology. Finally, the recognition accuracy of different methods were compared with the DenseNet network adopted in this paper. [Results/Conclusions] Through the training of DenseNet model, the recognition accuracy of 94% was achieved, which successfully solved the problems of long time, low efficiency and low recognition accuracy of traditional methods in processing image classification of soybean leaves, and could meet the actual needs of agricultural image data classification. Future research efforts will strive to collect a wide range of large and diverse data sets to facilitate soybean leaf recognition, and focus on developing reliable background removal techniques and incorporating other forms of data to improve the accuracy and reliability of soybean leaf recognition systems. © Agricultural Information Institute, Chinese Academy of Agricultural Sciences. All Rights Reserved.",TestAnalysis
"Objective: Based on experiences following the Great East Japan Earthquake and nuclear power plant accident in 2011, Nuclear Emergency Core Hospitals (NECHs) were designated as centers for radiation disaster management in Japan. This study aimed to investigate their current status and identify areas for improvement. Methods: This cross-sectional study was conducted in October 2018. Demographic data were collected by a questionnaire with free text responses about attitudes toward NECHs. Considerations regarding risk communications during a radiation disaster were analyzed using qualitative text mining analysis. Results: A total of 36 hospitals participated in this study. Only 31% of NECHs anticipated a radiation disaster. The importance of business continuity plans and risk communications was shown. Text analysis identified 7 important categories for health care workers during a radiation disaster, including media response, communications to hospital staff, risk communications, radiation effects on children, planning for a radiation disaster in the region, rumors, and the role in the region. Conclusion: The radiation disaster medical system and NECHs in Japan were surveyed. The importance of risk communications, planning for a radiation disaster in each region, and the role in the region are identified as issues that need to be addressed.  © The Author(s), 2022. Published by Cambridge University Press on behalf of Society for Disaster Medicine and Public Health, Inc.",TestAnalysis
"Introduction: Teachers’ self-efficacy is an important indicator of student teachers’ preparedness for teaching. Interventions using video lessons are effective in increasing student teachers’ self-efficacy. However, there is a lack of research on emotional and reflective processes in the context of video-based interventions. Methods: The present study examined emotions and reflection as well as their effects on changes in self-efficacy in a video-based intervention. A total of 159 student teachers participated in the study. The participants were randomly assigned to three groups: Two groups analyzed video lessons in which group roup one received open-ended observation tasks (ig1) and group two received structured observation tasks (ig2). Participants in the control group (cg) analyzed text-based case studies with open-ended observation tasks. Results: The results show that self-efficacy increased with medium effect size (d = 0.68) in video group two (ig2), whose members analyzed videos using structured observation tasks but not in video group one (ig1), whose members analyzed open-ended observation tasks, and in the control group. In addition, there were significant relations between positive arousal and reflection. Finally, regression analyses showed that reflection was a significant predictor for changes in self-efficacy, whereas no significant effect of emotional arousal was detected. Discussion: In conclusion, the findings of this study indicate that video-based interventions with structured observation tasks increased self-efficacy among student teachers. Furthermore, the findings provide novel evidence on the association between reflection, self-efficacy and emotion in video-based interventions in teacher education. Copyright © 2023 Schlosser and Paetsch.",TestAnalysis
"Topic modeling is the task of identifying topics in a corpus of documents. This is useful for search engines, customer service automation, and any other situation where document topics are important to know. There are numerous studies conducted about this field. Given the importance of topic modeling in various areas, this survey paper, explore some articles related to topic modeling (between 2013 to 2020) based on multiple methods such as: Latent Dirichlet Allocation (LDA), Latent Semantic Analysis (LSA), and Non Negative Matrix Factorization (NMF), on different social media sources such as (Amazon, Reddit, and Yelp). LDA and NMF general concepts are presented, in addition to the challenges of topic modeling and methods of evaluation. This paper does not go deep into the details of each of these methods. It only describes the high-level view that related to topic modeling in text mining. © 2023 American Institute of Physics Inc.. All rights reserved.",TestAnalysis
"Introduction Women with breast cancer who do not adhere to adjuvant endocrine therapy (AET) have increased risks of mortality and recurrence. There are multiple barriers to AET adherence, including medication side-effects, beliefs about medication, memory and psychological distress. We developed four intervention components, each targeting a different barrier. This pilot trial is part of the preparation phase of the Multiphase Optimisation Strategy, and aims to establish key trial parameters, establish intervention component adherence, establish availability and feasibility of outcome and process data, estimate variability in planned outcome measures and estimate cost of developing and delivering each intervention component. Methods and analysis The four intervention components are as follows: short message service text reminders (target: memory); a written information leaflet (target: medication beliefs); a guided self-help Acceptance and Commitment Therapy programme (target: psychological flexibility to reduce distress) and a self-management website (target: side-effect management). To evaluate the feasibility of recruitment, acceptability of the intervention components and the availability of outcome data, we will conduct a multisite, exploratory pilot trial using a 2 4-1 fractional factorial design, with a nested process evaluation. We will randomise 80 women with early-stage breast cancer who have been prescribed AET to one of eight experimental conditions. This will determine the combination of intervention components they receive, ranging from zero to four, with all conditions receiving usual care. Key outcomes of interest include medication adherence and quality of life. Progression to the optimisation phase will be based on predefined criteria for consent rates, patient adherence to intervention components and availability of medication adherence data. Ethics and dissemination The study was reviewed by the Wales Research Authority Research Ethics Committee 3 (21/WA/0322). Written informed consent will be obtained from all patients before randomisation. The results of this trial will be disseminated in a peer-reviewed journal. Trial registration number ISRTCN10487576. © 2023 BMJ Publishing Group. All rights reserved.",TestAnalysis
The text-based person search task aims at retrieving images of target pedestrians in a large-scale database with text as a query，which is highly practical in social and public safety. In contrast with the conventional crossmodal retrieval task，all categories in this task are pedestrians. However，the slight appearance difference among different pedestrians makes it difficult to discriminate，and poor shooting conditions cause the production of bad image quality. Therefore，the effective extraction of robust and discriminative visual features is an important challenge to this task. In response，a text-based person search algorithm based on self-supervised learning was designed，which formulated the self-supervised learning and text-based person search task in the form of multitask learning. Both tasks were trained at the same time and shared similar model parameters. As an auxiliary task，the self-supervised task aims to learn more robust and discriminative visual features for the person search task. Specifically，visual and textual features were first extracted，and the image inpainting was applied as a self-supervised task，aiming to learn richer semantic information and become more robust to occlusion data. Based on the particularity of the person image，a mirror flip prediction task was further designed to learn discriminative details by training the network to predict whether the image was mirror-flipped or not. This was applied to enable the person search task to distinguish difficult samples. Extensive experiments on the public dataset have demonstrated the superiority and effectiveness of the proposed approach，thereby improving the Top-1 accuracy of person search by 2.77%. Experimental results also show that the two self-supervised tasks are complementary，and better retrieval performance can be achieved using them at the same time. © 2023 Tianjin University. All rights reserved.,TestAnalysis
"Text classification is the method of allocating a particular piece of text to one or more of a number of predetermined categories or labels. This is done by training a machine learning model on a labeled dataset, where the texts and their corresponding labels are provided. The model then learns to predict the labels of new, unseen texts. Feature selection is a significant step in text classification as it helps to identify the most relevant features or words in the text that are useful for predicting the label. This can include things like specific keywords or phrases, or even the frequency or placement of certain words in the text. The performance of the model can be improved by focusing on the features that are most important to the information that is most likely to be useful for classification. Additionally, feature selection can also help to reduce the dimensionality of the dataset, making the model more efficient and easier to interpret. A method for extracting aspect terms from product reviews is presented in the research paper. This method makes use of the Gini index, information gain, and feature selection in conjunction with the Machine learning classifiers. In the proposed method, which is referred to as wRMR, the Gini index and information gain are utilized for feature selection. Following that, machine learning classifiers are utilized in order to extract aspect terms from product reviews. A set of customer testimonials is used to assess how well the projected method works, and the findings indicate that in terms of the extraction of aspect terms, the method that has been proposed is superior to the method that has been traditionally used. In addition, the recommended approach is contrasted with methods that are currently thought of as being state-of-the-art, and the comparison reveals that the proposed method achieves superior performance compared to the other methods. In general, the method that was presented provides a promising solution for the extraction of aspect terms, and it can also be utilized for other natural language processing tasks. © 2023 International Journal on Recent and Innovation Trends in Computing and Communication. All rights reserved.",TestAnalysis
"Purpose: The impact of a mixture of positive and negative media coverage on long-run hotel survival remains unknown. This paper aims to investigate how the mixed positive and negative media coverage, namely, inconsistent media coverage, influences long-run hotel survival. Design/methodology/approach: A yearly panel data set covering 792 news-reported hotels in Guangdong province of China, over the period 2010–2020, is analyzed using an inconsistency analysis framework consisting of text mining and survival analysis. The estimates of exponential models on the same observations and Cox estimates on alternative observations are used for robustness checks. Findings: The inconsistency calculation method proposed here can measure the controversy degree well. There exists a U-shaped relationship between inconsistency of media coverage and hotel longevity, and hotel survival is significantly reduced only when the degree of inconsistency is within the range of 17.8%–53.6%. The U-shaped relationship is moderated by negative hotel image and by online media coverage on hotel operation strategy topics. Practical implications: This study provides suggestions for hotel managers to use media coverage inconsistency to increase long-run hotel survival in the digital era. Originality/value: To the best of the authors’ knowledge, this paper is one of the first to investigate long-run hotel survival factors from the perspective of media coverage inconsistency. It also proposes a method to calculate the degree of media coverage controversy, which helps to quantify the relationship between the degree of inconsistency and hotel survival. © 2022, Emerald Publishing Limited.",TestAnalysis
"The aim of the article is to analyze the symbolism of clouds in the idiostyle of Sergey Yesenin. The object of the analysis is the “atmospheric phenomena” symbolism within the semantic field of “nature”. The focus of the research is the specificity of the symbolism of clouds in the linguistic image of the poet’s world. The research methods of semantic analysis and linguistic description are used. The material for the analysis is fragments of poetic texts by Sergey Yesenin. An attempt is made to describe the mechanism of creating a symbolic sense, which is also a metaphorical sense and is based on associative, analogous thinking. The factual material illustrates the role of the semantic phenomenon of the contextual connotation of words (lexemes) in a poetic text. The article shows that the symbolism of clouds in Yesenin reflects certain phenomena, e.g., things (beard, lace), atmospheric phenomena (rain), place (cornfield), physical phenomena (chill), animals (horse), perception of the world (unhappiness, illusion, mystery), people (believers). The attention was paid to the exceptional transparency of the phenomenon of things (honey, smoke, threshold, blade, beard, lace, lake, torn clothing (outfit)), which create the so-called functional metaphor. The conducted analysis will contribute to the enrichment of knowledge on the creation of a model of mechanisms controlling symbolic-metaphorical (figurative) thinking, as well as to further studies on the functioning mechanism of associative (metaphorical) thinking. A possibility of comparative analysis of clouds symbolism in the idiostyles of other Russian or European poets is suggested. © 2023 Tomsk State University. All rights reserved.",TestAnalysis
"The article interprets the mystery codes in the poem “Field Hospital” by Arseny Tarkovsky. The research is based on the principles of mythopoetic and structural-semantic analysis of the text, and provides a systematic approach to the work, taking into account the specifics of its plot-genre paradigmatics and figurative-symbolic language. The inner world of the poem is organized by the logic of the mystery topos with its key coordinates: frontier ontology; the evolving character of time and the reflection of its dynamics in the “dialectic of the soul”; existential self-reflection and detachment of the hero’s consciousness. The motivic complex of the border, repeatedly manifested in the text and culminating in the symbolism of the limb, becomes a meta-image, in the semantic field of which all the named parameters of the mystery continuum intersect. The model of reality recreated in Tarkovsky’s poem goes beyond mythological monism, but it clearly correlates with the mystery organization of the chronotope: the mystic is aware of the multidimensionality of the universe and the existence of boundaries between different spheres of reality – primarily profane-everyday and sacred – as well as the possibility of moving across these boundaries, which, ultimately, is one of the results of mystery initiations. The plot-forming meaning in “Field Hospital” is acquired by allusive references to the mystery texts of culture: the ancient Egyptian, Christian, alchemical mysteries are dialogically integrated in the act of birth – transfiguration – resurrection experienced by Tarkovsky’s hero. The central place in this paradigm is given to the mystery of Osiris and Isis, the symbolic codes of which are reflected in a number of iconic motifs, images, and details. The key among them are the motif of dismemberment and the semantic complex of the victim associated with it; the symbolism of death – resurrection; the archetypal dyad of a newborn – infant; a tree-natural code associated with the lyrical hero; the allusively designated image of Isis, personifying the female harmonizing principle of the universe. If the motif of dismemberment contains a specific reference to the theme of Osiris, then the other elements in this series also relate to the mystery of Christ and, accordingly, to the texts of culture associated with it, including the mysteries of the alchemists. The study leads to the conclusion that Tarkovsky’s “Field Hospital” is read as a metatext, where in a situation of semantic dialogue different culturological modes of mystery coexist, and the mystery consciousness itself enters into a relationship of mutual reflection with the mythological and tragic worldview. The logic of the myth is intertwined in the development of the lyrical plot with the logic of tragedy, which in turn is overcome through a detached view of the tragic situations experienced and the mystery-conscious acceptance of fate and life in all their manifestations. © 2023 Tomsk State University. All rights reserved.",TestAnalysis
"Background: Personalized medicine (PM) is now the new frontier in patient care. The application of this new paradigm extends to various pathologies and different patient care phases, such as diagnosis and treatment. Translating biotechnological advances to clinical routine means adapting health services at all levels is necessary. Purpose: This article aims to identify the elements for devising a framework that will allow the level of PM implementation in the country under study to be quantitatively and qualitatively assessed and that can be used as a guideline for future implementation plans. Methods: A systematic review was conducted per the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement. The research question was: What are the domains for determining the level of implementation of PM at the national level? The domains for assessing the degree of PM implementation, which would form the framework, were established. Results: 19 full-text studies that met the inclusion criteria were peer-selected in the systematic review. From all the studies that were included, 37 elements—encompassed in 11 domains—were extracted for determining the degree of PM implementation. These domains and their constituent elements comprise the qualitative and quantitative assessment framework presented herein. Each of the elements can be assessed individually. On the other hand, the domains were standardized to all have the same weight in an overall assessment. Conclusions: A framework has been developed that takes a multi-factorial approach to determine the degree of implementation of PM at the national level. This framework could also be used to rank countries and their implementation strategies according to the score they receive in the application of the latter. It could also be used as a guide for developing future national PM implementation strategies. Systematic review registration: https://www.crd.york.ac.uk/prospero/display_record.php?ID=CRD42022338611, Identifier: CRD42022338611. Copyright © 2023 Aguilera-Cobos, García-Sanz, Rosario-Lozano, Claros and Blasco-Amaro.",TestAnalysis
"As a powerful text generation model, the Variational AutoEncoder(VAE) has attracted more and more attention. However, in the process of optimization, the variational auto-encoder tends to ignore the potential variables and degenerates into an auto-encoder, called a posteriori collapse. A new variational autoencoder model is proposed in this paper, called Hierarchical Status Regularisation Variational AutoEncoder (HSR-VAE), which can effectively alleviate the problem of posterior collapse through hierarchical coding and state regularization and has better model performance than the baseline model. On this basis, based on the nanometer memristor, the model is combined with the memristor Recurrent Neural Network (RNN). A hardware implementation scheme based on a memristor recurrent neural network is proposed to realize the hardware acceleration of the model, which called Hierarchical Variational AutoEncoder Memristor Neural Networks (HVAE-MHN). Computer simulation experiments and result analysis verify the validity and superiority of the proposed model. © 2023 Science Press. All rights reserved.",TestAnalysis
"Abstract: An increase in the activity of free radical oxidation is considered as a nonspecific process characteristic of the pathogenesis of various diseases accompanied by antioxidant deficiency. Being bioregulators capable of increasing protective forces, antioxidants are important links in a multistage system of regulation and coordination of various body functions. The structure and function of enzymes involved in the regulation of oxidative stress can be significantly affected by genetic polymorphisms. To date, the role of genes encoding the activity of enzymes of the antioxidant system in the pathogenesis of many diseases remains unexplored, which is of great interest to researchers from various fields. The article presents an overview and analysis of the data of modern scientific literature on the study of the role of antioxidant defense components in the regulation of metabolic processes, their genetic determinants, and generalized data on modern methods for the determination of some antioxidants. While writing the review, the database of the scientific electronic library eLibrary was used, with the keywords being “oxidative stress,” “free radical oxidation,” “antioxidant protection,” “antioxidants,” “antioxidant enzymes,” “enzyme genes,” “antioxidant-responsive element,” and “research methods”; the filters were years of publication of 2012–2022, publications with full text, and publications available for viewing, as well as an English-language database of medical and biological publications created by the National Center for Biotechnology Information (NCBI), with the keywords “free radical oxidation,” “antioxidant protection,” “antioxidants,” “antioxidant enzymes,” “enzyme genes,” “oxidative stress,” “metabolism,” and “methods.”. © 2023, Pleiades Publishing, Ltd.",TestAnalysis
"[Objective] This paper tries to enrich the event logic of traditional fine-grained sentiment analysis from the perspective of emotion-triggering events.[Methods] We analyzed the OCC model’s sentiment generation rules and conditions to create the <event, sentiment> binary groups using event extraction and text classification methods.[Results] The proposed model constructed rules for emotion generation and built a theoretical basis for classifying sentiments. The model effectively identified emotion-triggering events (F1=0.933 8) and sentiments (F1=0.963 7). It generated <event, sentiment> binary groups (F1=0.889 2) to realize event-level fine-grained sentiment analysis. [Limitations] The structure of sentiment generation rules is simple and cannot reflect the diversity of netizens’emotions. The corpus built at present has domain limitations and each corpus only contains one type of emotion-triggering event.[Conclusions] By associating event evaluations and emotions with the help of the OCC model, our new model becomes more in line with human thinking. The model has good interpretability and transferability, which enhances the granularity level of emotional objects in existing studies. It provides new ideas for research in the field of textual sentiment analysis. © 2023, Chinese Academy of Sciences. All rights reserved.",TestAnalysis
"Objective: To explain the factors related to the implementation of antenatal care in developing countries. Methods: The systematic review was conducted in June 2020 and comprised literature search on Scopus, Cumulated Index to Nursing and Allied Health Literature, PubMed and Garba Rujukan Digital databases for cross-sectional, survey-based, prospective, mixed-method, correlational, experimental, longitudinal, cohort and case-control studies published after 2015 in either English or Indonesian. The studies included involved pregnant women and discussed the factors of implementing antenatal care in developing countries, and explained the factors related to the implementation of antenatal care in accordance with the World Health Organisation recommendation. The Population, Intervention, Comparison, Outcomes and Study framework was used, and the Preferred Reporting Items for Systematic Reviews and Meta-Analysis guidelines were followed. Data was analysed using descriptive statistics with a narrative approach. Results: Of the 9,733 studies initially found, 50(0.005%) were shortlisted for full-text review, and, of them, 15(30%) were reviewed and analysed. There were 3(20%) each from Pakistan and Ghana, 2(13.3%) each from Nepal and India, and 1(6.66%) each from Jordan, Egypt, Yemen, South Africa and Vietnam. Overall, 10(66.6%) were cross-sectional studies. There were five factors identified regarding antenatal care; behaviour intention, social support, accessibility of information, personal autonomy, and action situations, including economic status, availability of facility and transportation. Conclusion: Antenatal care in pregnant women in developing countries is influenced by several factors, and economic status and the availability of facilities and infrastructure optimise the use of such services. © 2023 Pakistan Medical Association. All rights reserved.",TestAnalysis
"TypeNet is a Siamese network model based on two-layer Long-Short Term Memory (LSTM) branch structure. It has achieved good results in the classification of free-text keystroke event sequences, but lacks interpretation. Therefore, the TypeNet model is transformed, and a Siamese network TypeNet II based on a single-layer LSTM branch structure is proposed. A multi-layer perceptron is used to measure the similarity of two feature sequences reflected by the absolute value of the difference between the output embeddings of the two branches. After the model training, the multi-layer perceptron is simulated by a multivariate binomial expression. Based on the obtained multivariate binomial expression, the classification judgment of the model can be explained. The experimental results show that the classification effect of the TypeNet II model exceeds the existing TypeNet model. The results of multivariate binomial regression are generalized, and there is a nonlinear relationship between the absolute value of the difference of the embeddings and the similarity measure. © 2023 Science Press. All rights reserved.",TestAnalysis
"This article examines the relationship between the script and the literary language of British Library, MS Cotton Nero A.x., particularly Pearl, Cleanness, and Sir Gawain and the Green Knight, arguing that the manuscript's penmanship, little studied, offers an interpretation of its poems. It begins with an extended analysis of and reflection on the script itself, identified as a form of textualis. The script is then connected to the aesthetic ideals of the texts through the language of Cleanness, in a scene adapted from the Book of Daniel that describes God's 'writing on the wall' as 'tied letters'. This representation of an inscriptional process internal to the poem reflects on the visual effect of the manuscript's own textualis. By tracking other instances where 'tied' and its synonyms are used to describe embellishment in Pearl and Gawain as well as Cleanness, the article opens up a broader analysis of the poetic themes in Cotton Nero, bringing an ideal of calligraphic inscription into a constellation of rich material metaphors for divine transcendence. By connecting Cotton Nero's script to the ideals of its poetry, this article ultimately argues that the script is fully unified with the poetry in a common aesthetics that sees material writing as a ready vehicle for immaterial elevation.  © 2022 The Author(s). Published by Oxford University Press. All rights reserved.",TestAnalysis
"Introduction Opioid prescribing rates are disproportionately high in the North of England. In addition to patients' complex health needs, clinician prescribing behaviour is also a key driver. Although strategies have been initiated to reduce opioid prescribing nationally, the COVID-19 pandemic has interrupted service provision and created challenges for the system and health professionals to tackle this complex issue. A pilot intervention using smartphone video messaging has been developed to remotely explain the rationale for opioid reduction and facilitate self-initiation of support. The aim of this study is to evaluate the potential benefits, risks and economic consequences of € at scale' implementation. Methods and analysis This will be a mixed-methods study comprising a quasi-experimental non-randomised before-and-after study and qualitative interviews. The intervention arm will comprise 50 General Practitioner (GP) Practices using System 1 (a clinical computer system hosting the intervention) who will deliver the video to their patients via text message. The control arm will comprise 50 practices using EMIS (a different computer system) who will continue usual care. Monthly practice level prescribing and consultation data will be observed for 6 months postintervention. A general linear model will be used to estimate the association between the exposure and the main outcome (opioid prescribing; average daily quantity (ADQ)/1000 specific therapeutic group age-sex related prescribing unit). Semi-structured interviews will be undertaken remotely with purposively selected participants including patients who received the video, and health professionals involved in sending out the videos and providing additional support. Interviews will be audio recorded, transcribed and analysed thematically. Ethics and dissemination Ethics approval has been granted by the NHS Health Research Authority Research Ethics Committee (22/PR/0296). Findings will be disseminated to the participating sites, participants, and commissioners, and in peer-reviewed journals and academic conferences. Trial registration number NCT05276089. © 2023 BMJ Publishing Group. All rights reserved.",TestAnalysis
"In 2017, guidelines were published for reporting structural modelling of small-Angle scattering (SAS) data from biomolecules in solution that exemplified best-practice documentation of experiments and analysis. Since then, there has been significant progress in SAS data and model archiving, and the IUCr journal editors announced that the IUCr biology journals will require the deposition of SAS data used in biomolecular structure solution into a public archive, as well as adherence to the 2017 reporting guidelines. In this context, the reporting template tables accompanying the 2017 publication guidelines have been reviewed with a focus on making them both easier to use and more general. With input from the SAS community via the IUCr Commission on SAS and attendees of the triennial 2022 SAS meeting (SAS2022, Campinas, Brazil), an updated reporting template table has been developed that includes standard descriptions for proteins, glycosylated proteins, DNA and RNA, with some reorganization of the data to improve readability and interpretation. In addition, a specialized template has been developed for reporting SAS contrast-variation (SAS-cv) data and models that incorporates the additional reporting requirements from the 2017 guidelines for these more complicated experiments. To demonstrate their utility, examples of reporting with these new templates are provided for a SAS study of a DNA-protein complex and a SAS-cv experiment on a protein complex. The examples demonstrate how the tabulated information promotes transparent reporting that, in combination with the recommended figures and additional information best presented in the main text, enables the reader of the work to readily draw their own conclusions regarding the quality of the data and the validity of the models presented. © 2023 International Union of Crystallography. All rights reserved.",TestAnalysis
"This text presents a brief synthesis of the most important problems associated with the application of private law in the public sector which have arisen in the last 200 years in the states of Continental Europe. In the author's view, the application of private law in the public sector is one of the key issues tackled by legal theorists in the EU Member States. At the same time, this issue is not limited to private-law relations involving public entities. In the last 200 years, the institutions and principles of civil law have also served as the building blocks for the development of public (administrative) law. The analysis of the application of private law in the public sector can be very inspiring and fruitful. Such investigations help in unravelling the issues indicated in the subheadings of this text. Among other things, they brings us closer to grasping the essence of the public-private law division. The place of private law in the whole legal system can thus be defined more precisely. This analysis also provides methodological grounds for developing the concept of the constitutionalization of private law, including its most spectacular manifestation, namely the horizontal application of the constitution. In the author's opinion, the analysis of the application of private law in the public sector also confirms the efficacy of the functional method, which, while being one of the oldest methods employed in comparative law, still prevails in this field. This method is grounded in the conviction that similar or even identical problems occur in different countries. This is especially true of countries which are closely related in terms of their legal systems - such as the EU Member States. Consequently, the measures applied in one legal system to address certain problems are the functional equivalent of the solutions applied in other legal systems. Of course, these equivalents or counterparts may have varying degrees of effectiveness. © 2023 The Author(s).",TestAnalysis
"Purpose: The role of industry 4.0 (I4.0) technologies for organizations to achieve a competitive advantage and mitigate disruptive emergency situations are well exhibited in literature. However, more light needs to be thrown into implementing I4.0 technologies to digitally transform organizations. This paper introduces a novel framework for formulating manufacturing strategy 4.0 (MS 4.0) that guides organizations to implement I4.0 successfully. Design/methodology/approach: The experts working in I4.0 and technology management domains were interviewed to determine the definition, role and process for formulating MS 4.0. Text mining using VOSViewer© is performed on the experts' opinions to determine the key terms from the opinions through keyword analysis. The identified key terms are mapped together using the existing traditional manufacturing strategy formulation framework to develop the MS 4.0 framework. Finally, the proposed MS 4.0 framework is validated through a triangulation approach. Findings: This study captured the role, definition and process to formulate MS 4.0 and proposed a framework to help practitioners implement I4.0 at manufacturing organizations to achieve competitiveness during normal and emergency situations. Research limitations/implications: The proposed MS 4.0 framework can assist industry practitioners in formulating the strategy for implementing the I4.0 technology/gies to digitally transform their manufacturing firm to retain the maximum manufacturing output and become market competent in normal and emergency situations. Originality/value: This study is the first of its kind in the body of knowledge to formulate a digital transformation strategy, i.e. MS 4.0, to implement I4.0 technologies through a manufacturing strategic lens. © 2022, Emerald Publishing Limited.",TestAnalysis
"In the ""Introduction,"" Ralf Rogowski provides biographical information and an overview of the development of Luhmann's social systems theory. In ""Luhmann and Constitutional Sociology: Law and Functional Differentiation Revisited,"" Chris Thornhill analyses how Luhmann's theory of functional differentiation can be used as a methodological device to examine the construction of an institutional and legal framework for governance in the world society. In ""Far from Equilibrium. Niklas Luhmann on Politics and Economy in 21st Century's World Society,"" Aldo Mascareño argues that the political and economic systems have intensified their unpredictable dynamics, hence increasing their levels of instability, as shown by critical events such as the 2008 financial crisis, the 2011 political upheavals, and the 2020 COVID-19 global pandemic. In ""Luhmann on Law and Legal Theory,"" Richard Nobles and David Schiff explain how legal argumentation yields sufficient redundancy and variety in the legal system to achieve the recursive reproduction of legal communications which gives the system opportunities to evolve autopoietically. In ""Epistemic Sociology: Luhmann's Theory of Science and Knowledge,"" Gert Verschraegen underscores the connection of science in society with other function systems such as the educational (coupled via curricula content in textbooks), the economy (coupled via patents), politics (coupled through research policy as well as policy advice), and the medical system (coupled through scientifically tested medicinal knowledge and operation practices). In ""Luhmann's Theory of Art,"" Paul Buckermann examines how Luhmann's functional method is key to understanding art and makes visible possibilities of order that otherwise remain invisible. In ""Luhmann on Religion and Secularization,"" Raf Vanderstraeten discusses, with reference to a host of examples, how the religious system contributed to the genesis of modern society, and how it was forced to adapt to the consequences of modern society's functional differentiation. In ""Niklas Luhmann and Critical Systems Theory,"" Kolja Möller and Jasmin Siri outline features of a critical systems theory and its potential for a critique of modern society. In ""Niklas Luhmann and His Sceptical Notion of Culture,"" Dirk Baecker outlines Luhmann's reserved attitude towards the concept of culture. In ""Luhmann, on Algorithms, in 1966,"" Elena Esposito analyses an early text of Luhmann on Law and Automation in Public Administration. In ""Niklas Luhmann Observed from a Luhmannian Perspective,"" Klaus Dammann analyses Luhmann's biography using Luhmannian concepts and in ""Three Encounters with Niklas Luhmann,"" Gunther Teubner narrates his academic and personal experiences with Luhmann. © 2023 Ralf Rogowski editorial matter and selection. All rights reserved.",TestAnalysis
"The importance of media-induced tourism has increased in the latest decade. The integration and collaboration of film elements is an especially effective pathway for the innovative development and upgrading of the experience of the cultural tourism industry. Existing studies on the mechanism of tourism destinations and cultural tourism development, mainly from the perspective of tourism destinations and tourist experience, have rarely explored the cultural tourism development mechanism from the perspective of interest-related community interaction in the film-enabling context. In this study, we conducted high-frequency word analysis and element category analysis of the online text data of the Japanese animation film Your Name from the angle of interest-related community interaction through utilizing online text analysis and Grounded Theory analysis. Based on the interest-related community interaction, we analyzed the elements of interest-related community interaction in cultural tourism triggered by the film, including tourist hotspots, tourism resources, the tourist experience, sightseeing expectations, tourism evaluation and information dissemination, and formulated the orientation pathway of film-enabling cultural tourism. In this study, we aimed to enrich cultural tourism research and provide a reference point and theoretical support for film-enabling cultural tourism in the Internet era by introducing the concept of interest-related community innovation to the scene of film-enabling cultural tourism. Copyright © 2023 Lao, Zhu and Liu.",TestAnalysis
"Background Respiratory syncytial virus (RSV) is the principal cause of acute lower respiratory infections (ALRI) among infants worldwide, and an important cause of morbidity, hospitalisation and mortality. While infants are universally exposed to RSV, most mortality occurs among normal term infants from low-income and middle-income countries. Breastfeeding has been suggested to have a protective effect against RSV infection. This study aims to determine the association of breastfeeding on the frequency and severity of RSV-associated ALRI among infants. Methods A systematic review was conducted using keywords and Medical Subject Headings on MEDLINE, PubMed, Google Scholar, EMBASE, MedRxiv and Cochrane Central Register of Controlled Trials. Full-text articles published in English from 2000 to 2021 that studied exclusively or partially breastfed infants who developed RSV-associated ALRI <12 months of age were included. Covidence software-based evidence extraction and Preferred Reporting Items for Systematic Reviews and Meta-Analyses Protocol guidelines were followed. Quality of evidence was analysed using UK National Service Framework grading and the risk-of-bias assessment using Robvis. Results Among 1368 studies screened, 217 qualified full-text review and 198 were excluded based on pre-agreed criteria. Nineteen articles published from 12 countries that included 16 787 infants from 31 countries (of which 8 middle-income) were retained for analysis. Results indicate that non-breastfeeding practices pose a significant risk for severe RSV-associated ALRI and hospitalisation. Exclusive breastfeeding for >4-6 months significantly lowered hospitalisation, length of stay, supplemental oxygen demand and admission to intensive care units. Conclusion In the context of no effective or standardised treatment for established RSV-associated ALRI, available evidence suggest that breastfeeding is associated with lower frequency and severity of RSV-associated ALRI, based on observational studies of variable grades of evidence and risk-of-bias. With both exclusive and partial breastfeeding benefiting infants who develop RSV-associated ALRI, breastfeeding should be promoted globally as an adjunct primary prevention; in addition to emerging immunoprophylaxis and maternal immunisation strategies. © 2023 Author(s).",TestAnalysis
"This paper studies the development of the movement and the meaning of hijrah in social media. Hijrah was originally understood as a process of leaving the past misguidance (jahiliyyah) and towards conditions that are in accordance with syariat. In its development, hijrah refers to a transformation of individuals who are less religious to more religious (Islamī). The form of this transformation can be seen from the choice of clothes, work preferences, and social relations models. The ideological process of the meaning of hijrah was carried out massively through social media. This is based on the search results on the internet about “hijrah” is more than other religious topics. This article answers how and why hijrah is interpreted and articulated by a number of digital activists. This research is qualitative research with a critical discourse analysis method combined with a digital hermeneutic approach. Based on research, digital activists who carry out the ideologization of the meaning of hijrah are preachers who have many followers on social media. Followers on social media are capital and modal in mainstreaming a discourse and idea. This article reveals that religious studies regarding hijrah on social media are not only related to understanding religious texts but are also part of religious commodification. In addition, the dominance of conservative groups is a fact that cannot be separated from the ideological flow of hijrah on social media. © 2023, Program Studi Ilmu Agama Islam Program Magister, Universitas Islam Indonesia. All rights reserved.",TestAnalysis
"Importance: Financial toxicity (FT) is the negative impact of cost of care on financial well-being. Patients with breast cancer are at risk for incurring high out-of-pocket costs given the long-term need for multidisciplinary care and expensive treatments. Objective: To quantify the FT rate of patients with breast cancer and identify particularly vulnerable patient populations nationally and internationally. Data Sources: A systematic review and meta-analysis were conducted. Four databases - Embase, PubMed, Global Index Medicus, and Global Health (EBSCO) - were queried from inception to February 2021. Data analysis was performed from March to December 2022. Study Selection: A comprehensive database search was performed for full-text, English-language articles reporting FT among patients with breast cancer. Two independent reviewers conducted study screening and selection; 462 articles underwent full-text review. Data Extraction and Synthesis: A standardized data extraction tool was developed and validated by 2 independent authors; study quality was also assessed. Variables assessed included race, income, insurance status, education status, employment, urban or rural status, and cancer stage and treatment. Pooled estimates of FT rates and their 95% CIs were obtained using the random-effects model. Main Outcomes and Measures: FT was the primary outcome and was evaluated using quantitative FT measures, including rate of patients experiencing FT, and qualitative FT measures, including patient-reported outcome measures or patient-reported severity and interviews. The rates of patients in high-income, middle-income, and low-income countries who incurred FT according to out-of-pocket cost, income, or patient-reported impact of expenditures during breast cancer diagnosis and treatment were reported as a meta-analysis. Results: Of the 11086 articles retrieved, 34 were included in the study. Most studies were from high-income countries (24 studies), and the rest were from low- and middle-income countries (10 studies). The sample size of included studies ranged from 5 to 2445 people. There was significant heterogeneity in the definition of FT. FT rate was pooled from 18 articles. The pooled FT rate was 35.3% (95% CI, 27.3%-44.4%) in high-income countries and 78.8% (95% CI, 60.4%-90.0%) in low- and middle-income countries. Conclusions and Relevance: Substantial FT is associated with breast cancer treatment worldwide. Although the FT rate was higher in low- and middle-income countries, more than 30% of patients in high-income countries also incurred FT. Policies designed to offset the burden of direct medical and nonmedical costs are required to improve the financial health of vulnerable patients with breast cancer.. © 2022 American Medical Association. All rights reserved.",TestAnalysis
"Introduction Antimicrobial resistance (AMR) is a growing global public health concern and is becoming a significant challenge in the management of patients with cancer. Due to the immunosuppressive nature of cancer treatment, infection is a common complication and the necessary high usage of antibiotics increases the risk of AMR. Failure to adequately prevent and treat infection in patients with cancer as a result of AMR can increase the morbidity and mortality of the disease. The objective of this scoping review is to understand the relationship between AMR and cancer in order to develop effective antimicrobial stewardship in this patient population and minimise the detrimental effects of AMR on cancer outcomes. Methods and analysis This scoping review will follow the Arksey and O'Malley methodology framework. An exploratory review of the literature on antibiotic resistance in cancer care will help to define the research questions (stage 1). A broad range of electronic databases (MEDLINE ALL, Cochrane Central Register of Controlled Trials, Cochrane Database of Systematic Reviews and Embase) and search terms will be used to retrieve relevant articles published between 2000 and 2021 (stage 2). Studies will be systematically selected based on the eligibility criteria by two independent reviewers (stage 3). The titles and abstracts will be appraised to determine whether articles meet the eligibility criteria. This will be followed by screening of the full texts and only relevant publications will be retrieved. Data will then be extracted, collated and charted (stage 4); and the summary of aggregated results will be presented (stage 5). Ethics and dissemination As this scoping review will collect and synthesise data from publicly available sources, no ethics review is required. When data collection and summarisation is completed, results will be disseminated through peer-reviewed publication and the key findings of the review will be presented at relevant conferences. © 2023 BMJ Publishing Group. All rights reserved.",TestAnalysis
"Objectives âEffective communication between surgeons and anesthesiologists is critical for high-quality, safe, and efficient perioperative patient care. Despite widespread implementation of surgical safety checklists and time-outs, ineffective team communication remains a leading cause of patient safety events in the operating room. To promote effective communication, we conducted a pilot trial of a virtual huddle between anesthesiologists and surgeons. Methods âAttending anesthesiologists and surgeons at an academic medical center were recruited by email to participate in this feasibility trial. An electronic health record-based smartphone application was utilized to create secure group chats among trial participants the day before a surgery. Text notifications connected a surgeon/anesthesiologist pair in order to introduce colleagues, facilitate a preoperative virtual huddle, and enable open-ended, text message-based communication. A 5-point Likert scale-based survey with a free-Text component was used to evaluate the utility of the virtual huddle and usability of the electronic platform. Results âA total of 51 unique virtual huddles occurred between 16 surgeons and 12 anesthesiologists over 99 operations. All postintervention survey questions received a positive rating (range: 3.50/5.00-4.53/5.00) and the virtual huddle was considered to be easy to use (4.47/5.00), improve attending-To-Attending communication (4.29/5.00), and improve patient care (4.22/5.00). There were no statistically significant differences in the ratings between surgery and anesthesia. In thematic analysis of qualitative survey results, Participants indicated the intervention was particularly useful in interdisciplinary relationship-building and reducing room turnover. The huddle was less useful for simple, routine cases or when participation was one sided. Conclusion âA preoperative virtual huddle may be a simple and effective intervention to improve communication and teamwork in the operating room. Further study and consideration of broader implementation is warranted. © 2023 Georg Thieme Verlag. All rights reserved.",TestAnalysis
"Objective To investigate the incidence of complications related to thread lift in the treatment of facial rejuvenation. Methods The databases of China National Knowledge Infrastructure (CNKI), VIP Chinese Science and Technology Journal Full-text Database (VIP-CSJFD), Wanfang Data, China Biology Medicine (CBM), PubMed, The Cochrane Library and Embase were searched from database establishment to April 20, 2022. The inclusion and exclusion criteria were developed to include relevant studies that met the criteria. Two investigators independently performed literature screening and data extraction; the STROBE statement scored the quality of inclusion criteria for cross-sectional studies, the total score was 0-22 points, and the research of which score >11 points was considered as high-quality research; data analysis was performed using Stata16.0 software; Egger test and funnel plot analysis were used to evaluate the publication bias of literature. Results Thirty-three articles involving 8 919 patients were included in this meta-analysis. The quality scores of 28 articles were > 11 points, and the remaining 5 articles were exactly 11 points, indicating that the overall quality of the articles was acceptable. The outcome measures of this meta-analysis included 11 indicators such as paresthesia, infection, facial asymmetry, facial nerve injury, mild unevenness or irregular contour, postoperative allergy, postoperative hematoma, pain, wire exposure or visibility, bruising, and swelling. The complication rates for each outcome measure were: paresthesia (1%), infection (0), facial asymmetry (2%), facial nerve injury (0), mild unevenness or contour irregularity (7%), postoperative allergy (0), postoperative hematoma (0), pain (17%), exposed or visible wire (7%), bruising (28%), swelling (55%). Egger test and funnel plot analysis showed that there was no publication bias in sensory abnormalities, facial asymmetry, postoperative allergy and pain. There may be some publication bias in the other 7 indicators. Conclusion Among the complications related to thread lift, postoperative swelling, pain and bruising are the most common, while the incidence of serious complications is rare. Most complications are transient and self-resolving, and in general, thread lift is a relatively safe treatment modality. © 2023 Chinese Medical Journals Publishing House Co.Ltd.",TestAnalysis
"Scholars have long been curious about the transmission of religious and philosophical ideas across Eurasia in antiquity. It is well known that Mani named a number of important figures from ""Eastern""religious traditions-such as Buddha and Zoroaster-among his list of prophetic forerunners in an effort to establish his own authority as a religious teacher. Recently published portions of the Dublin codex of the Manichaean Kephalaia provide an additional attestation of this prophetological paradigm in an even more amplified form, as it includes figures not previously attested. Textual analysis of this new testimonium invites us to reflect on how Mani and his early followers imagined their relationships to other religious traditions. It will be shown that, while Manichaean textual traditions were an important conduit of religious information across Eurasia, modern interpreters should be cautious about supposing that ancient readers of Manichaean texts made any meaningful association between the names of these prophetic forerunners and particular doctrines, which by then had been fully naturalized as ""Manichaean""teachings.  © 2023 by the Regents of the University of California.",TestAnalysis
"Background: The Institute of Family Medicine at the Medical Faculty of Magdeburg offers a course in the cross-sectional subject Q7 “Medicine of Aging and the Elderly” in the 5th year of undergraduate curriculum, in which community institutions are involved in addition to facilities of university medicine. Visits to various facilities in inpatient and community contexts are presented in seminars. Typical syndromes, diseases, and the special handling of diagnostics, treatment, and care of old age are deepened with the help of instant aging units and group exercises. Accompanying lectures complement the concept. Methods: The institute-internal teaching evaluation used standardized, paper–pencil questionnaires with 14 items (winter term 2017/18 and 2018/19). The response rate was about 95% in the winter term 2017/18 and about 85% in 2018/19. The evaluation was descriptive; free text data were evaluated by content analysis. Results: In 2017/18 (n = 170), the overall rating was 2.73 (SD 0.922) and in 2018/19 (n = 156) 2.58 (SD 0.831) on a 5-level grading scale. The visit of the observation sites, the active co-design of the seminars, and the instant aging units were rated positively. Due to the combination of different teaching formats, there were initially redundancies, which were revised for the winter term 2018/19. The desire for more practical exercises and the inclusion of social law aspects was implemented. Conclusions: The combination of lecture, observation, and seminar enables interactional theory–practice transfer as well as self and peer reflection. Practical case vignettes and experiences in different observation sites provide opportunities for interactional exchange during the seminars, so that relevant medical and psychosocial knowledge in medical care of elderly patients is conveyed. © 2023, The Author(s).",TestAnalysis
"The article describes the research of the narrative structure of gamebooks as an example of hypertext fiction. The aim of the research is to analyse the storyline of Raymond Queneau's gamebook “A Story of Your Own” as a literary hypertext narrative, to define the peculiarities of its structural organization and to come up with a narrative scheme of the gamebook. The methodology of the research is based on the narrative analysis predicated by the invariant narrative scheme offered by William Labov and Joshua Waletzky. The research novelty lies in the fact that for the first time a narrative analysis of a book-game is carried out taking into account its narrative and hypertext characteristics and the hypernarrative structure of a book-game is described and presented in the form of a scheme. The article dwells on the notions of the narrative, its prototype form and hypertext narrative as being a combination of hypertext and narrative. The author also defines the conception of the hypertext gamebook, follows its evolution. As a result of the analysis of Raymond Queneau's minimalistic gamebook, the author identifies following isomorphic characteristics of a gamebook: nonlinearity and variation of the plot structure, fragmentarity and interactivity (the dialogue between the author, the reader and the text). The gamebook narrative structure utilizes all the narrative components (Abstract, Orientation, Complicating Action, Evaluation, Resolution, Coda), but there are some deviations from the scheme of the prototype linear narrative such as the combination of all narrative components in one, the substantial repetition of a component, the implementation of a component in a different textone, elimination, the presence of narrative polycomponents and their discontinuity, the implementation of a new component of Evaluation by the reader. All these deviations fulfil their definite functions inherent in the game-book. The gamebook structural abnormities are explained by the hypertext strategy of the narration and by interactivity. They create a new fiction space with numerous textual branches, make it possible to expand and to restrict the framework of the narration, boost the narrative dynamics and encourage readers' activity. As a result of the research, the gamebook narrative scheme has been devised and described. This scheme includes potential authorial variations and it can be applied as the basis for the analysis of all kinds of hypertext narratives. © 2023 Tomsk State University. All rights reserved.",TestAnalysis
"Text Correction There was an error in the original publication [1]. The description of the neurodynamic nerve gliding technique was incorrect. A correction has been made to 2.3. Experimental Sessions, end of second paragraph: “A dorsiflexion was applied in this position. Then, the volunteer performed a cervical extension concomitantly with the release of the ankle toward a neutral position. Subsequently, a cervical flexion was again performed with a concomitant dorsiflexion” should be replaced by “Then, the volunteer performed cervical extension concomitantly with dorsiflexion. Subsequently, cervical flexion was performed again with concomitant plantarflexion”. The authors state that the scientific conclusions are unaffected. This correction was approved by the Academic Editor. The original publication has also been updated. © 2023 by the authors.",TestAnalysis
"The aim of the article is to present essential aspects of five emotions (joy, fear, love, sadness, anger) on the basis of written sources from ancient Egypt. Through selective analyses of the Egyptian emotion vocabulary, including metaphors and descriptions of physical states and reactions, some elementary concepts will be explained. In addition, it is a concern to point out some of the difficulties that can be associated with the investigation of emotions in ancient Egyptian texts. Therefore, brief references are given to current Egyptological studies that have been devoted to the topic adopting new methods. © 2023 The Authors. Religion Compass published by John Wiley & Sons Ltd.",TestAnalysis
"Background and Objectives. Anxiety and depressive disorders are the most prevalent mental disorders, and due to the COVID-19 pandemic, more people are suffering from anxiety and depressive disorders, and a considerable fraction of COVID-19 survivors have a variety of persistent neuropsychiatric problems after the initial infection. Traditional Chinese Medicine (TCM) offers a different perspective on mental disorders from Western biomedicine. Effective management of mental disorders has become an increasing concern in recent decades due to the high social and economic costs involved. This study attempts to express and ontologize the relationships between different mental disorders and physical organs from the perspective of TCM, so as to bridge the gap between the unique terminology used in TCM and a medical professional. Materials and Methods. Natural language processing (NLP) is introduced to quantify the importance of different mental disorder descriptions relative to the five depots and two palaces, stomach and gallbladder, through the classical medical text Huangdi Neijing and construct a mental disorder ontology based on the TCM classic text. Results. The results demonstrate that our proposed framework integrates NLP and data visualization, enabling clinicians to gain insights into mental health, in addition to biomedicine. According to the results of the relationship analysis of mental disorders, depots, palaces, and symptoms, the organ/depot most related to mental disorders is the heart, and the two most important emotion factors associated with mental disorders are anger and worry & think. The mental disorders described in TCM are related to more than one organ (depot/palace). Conclusion. This study complements recent research delving into co-relations or interactions between mental status and other organs and systems. © 2023 by the authors.",TestAnalysis
"This systematic review aimed to investigate the scientific literature on volumetric studies concerning the diagnosis and treatment of apical periodontitis using CBCT. A systematic review protocol was written following the preferred reporting items for the systematic reviews and meta-analyses (PRISMA) checklist. Four electronic databases were searched for relevant publications in English, which were published up to 21 January 2023. The inclusion criteria and corresponding search keys were applied. The risk of bias was assessed using the Joanna Briggs Institute Meta-Analysis of Statistic Assessment and Review Instrument. The search strategy identified 202 studies, with 123 studies excluded during the title and abstract screening and 47 studies left for full text screening. A total of 17 studies met the inclusion criteria. The lesion volume was measured and classified according to different indices which compared the effectiveness of their diagnostics. Moreover, the volume of AP lesions increased with the thickness of the maxillary sinus mucosa in primary and secondary infections and decreased due to endodontic treatment. Volumetric measurements using CBCT are useful in the correct definition of periapical tissue pathosis using a CBCT periapical volume index and assessment of the dynamics of the treatment of apical lesions. © 2023 by the authors.",TestAnalysis
"Purpose: The purpose of this study was to identify the main keywords, network properties, and main topics of news articles related to artificial intelligence technology in the field of nursing. Methods: After collecting artificial intelligence-and nursing-related news articles published between January 1, 1991, and July 24, 2022, keywords were extracted via preprocessing. A total of 3,267 articles were searched, and 2,996 were used for the final analysis. Text network analysis and topic modeling were performed using NetMiner 4.4. Results: As a result of analyzing the frequency of appearance, the keywords used most frequently were education, medical robot, telecom, dementia, and the older adults living alone. Keyword network analysis revealed the following results: a density of 0.002, an average degree of 8.79, and an average distance of 2.43; the central keywords identified were ’education,’ ‘medical robot,’ and ‘fourth industry.’ Five topics were derived from news articles related to artificial intelligence and nursing: ‘Artificial intelligence nursing research and development in the health and medical field,’ ‘Education using artificial intelligence for children and youth care,’ ‘Nursing robot for older adults care,’ ‘Community care policy and artificial intelligence,’ and ‘Smart care technology in an aging society.’ Conclusion: The use of artificial intelligence may be helpful among the local community, older adult, children, and adolescents. In particular, health management using artificial intelligence is indispensable now that we are facing a super-aging society. In the future, studies on nursing intervention and development of nursing programs using artificial intelligence should be conducted. © 2023, Korean Society of Nursing Science. All rights reserved.",TestAnalysis
"Sentiment analysis is a way to automatically understand and process text data to figure out how someone feels about an opinion sentence. If there are too many reviews, it will take a lot of time and they will start to be biased. Sentiment classification tries to solve this problem by putting user reviews into groups based on whether they are positive, negative, or neutral. The dataset comes from Drone Emprit Academic. It is made up of tweets with the words ""online learning method"" in them, with as many as 4887 data crawled from them. Information Gain and adaboost on the C4.5 (FS+C4.5) method are used in the feature selection method. We use feature options to get rid of bias and improve accuracy. The results of the experiments will be compared to other algorithms like C4.5 and random forest. Based on the results, the accuracy of the two standard decision tree models (C4.5 and random forest) went up from 48.21% and 50.35% to 94.47 %. The value of how accurate it was went up by 44 percent. The FS+C4.5 model, on the other hand, has an RMSE of 0.204 and a correlation of 0.944. So, adding the feature selection technique to the sentiment analysis of bold learning education can make the C4.5 algorithm even more accurate © 2023 Syamsu Rijal et al; published by UIKTEN. This work is licensed under the Creative Commons Attribution-NonCommercial-NoDerivs 4.0 License",TestAnalysis
"Clubfoot is a common congenital deformity of the lower limbs. It should be treated as soon as possible so that its correction is more easily achieved. The objective of this systematic review was to assess the effectiveness of the Ponseti method in the treatment of clubfoot. A bibliographic search was carried out in different databases, including PubMed and SciELO. Filters such as full text and randomized controlled trial were selected to find those articles that best matched our search. Among the results, we selected the ones that interested us, and the rest were discarded, either because they did not meet the requirements for our work or because they were repeated. In total, we collected 19 articles, but after using the critical evaluation instrument CASPe, 7 of them were eliminated, leaving us with a total of 12 articles for our systematic review. After analyzing the results obtained in the selected articles, we concluded that the Ponseti method is effective in the treatment of clubfoot, presenting a high success rate. © 2023 by the authors.",TestAnalysis
"Background and Aim: Administrative healthcare data are frequently used for studying incidence, prevalence, risk factors, and outcome of pediatric stroke. However, the accuracy of these data sources is uncertain. The aim of this study was to systematically analyze published data on the positive predictive value (PPV) and sensitivity of diagnoses used to identify pediatric stroke patients in administrative data. Methods: This systematic review was performed in accordance with Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement. We searched PubMed and Embase for studies, published in year 2000 or later, describing the PPV or sensitivity of diagnoses used to identify children with stroke in administrative data. The search was performed on June 9, 2022. Studies written in other languages than English, with less than 30 participants, and conference abstracts were excluded. Results: Eight studies were included after full-Text review from 2,475 potentially eligible records. These included 3,137 children. All studies reported data from high-income countries. Reported PPVs varied considerably across studies and stroke subtypes: Acute ischemic stroke, range 0.27-0.89; cerebral venous thrombosis, range 0.45-0.72; spontaneous subarachnoid hemorrhage, range 0.52-0.83; and spontaneous intracerebral hemorrhage, range 0.62-0.66. One study examined sensitivity of an ICD-9 search compared to a radiology report search and found that the ICD search had poor sensitivity (33%). Conclusion: Caution is recommended in the use and interpretation of nonvalidated administrative data for pediatric stroke. Data on the PPV and sensitivity of pediatric stroke diagnoses in administrative data remain limited and are only available from high-income countries.  © 2023 S. Karger AG. All rights reserved.",TestAnalysis
"Intelligent problem-solving technology is a typical application of artificial intelligence in the educational field. The purpose of intelligent problem-solving is to enable machine to solve problems like human beings and help people to find useful and accurate information in the test-questions. Correct understanding of test-questions is one of the key techniques of intelligent problem-solving. The existing methods are mainly to extract simple relations from text and graphs of test-questions. In the absence of text, deep understanding of graph elements and complex relationships are difficult, which is a challenge for machines. However, the information contained in motion test-question graphs is more abundant than that in the text, which is more beneficial for machine to solve problems. To solve this problem, based on the graph classification and characteristics analysis on test-questions, a novel automatic and weak text-dependent information extraction and thorough understanding method for test-question graph of junior high school physical mechanical motion is proposed (TQGIEU). It can extract information and understand regarding to test-question graphs based on several image preprocessing techniques and neural network topologies combined with the characteristics of test-question graphs, without relying on text processing. It will generate a readable mechanical motion solution at last. It fills the blank of automatic information extraction and thorough understanding for the test-question research of physical mechanical motion. The experimental results show that the accuracy of graph classification and line segmentation model are 99.60% and 90.87% respectively. The average accuracy of TQGIEU on test dataset is 83.08%, and the total F1 score of TQGIEU is 0.859, indicating that TQGIEU can provide a good information extraction and thorough understanding service for test-question graphs of junior high school physical mechanical motion with high performance. © World Scientific Publishing Company.",TestAnalysis
"It is well known that safety climate (SC) has paramount significance in safety science and accident prevention. In this paper, a bibliometric data mining is conducted to systematically review the research domain of SC. Overall, 1624 documents on SC are obtained, covering 4830 authors, 473 journals, 89 countries/regions, and 1766 institutions between 1980 and 2021. SC has obtained increasing attention since the number of publications related to SC grew from 1 in 1980 to 188 in 2020. Based on the bibliometric data, network analysis was carried out to understand the relationship among different countries/regions, authors, and keywords. Safety Science, Journal of Safety Research, and Accident Analysis and Prevention are the major sources of SC publications, and the USA, Australia, and China lead scientific collaboration production on SC research. Then, text mining of publication keywords is used to identify the hot topics and the evolution of mainstream research over time in the SC domain. The dominant topics in SC research include culture, performance, safety behavior, and model. Meanwhile, the limitations of past research on SC are analyzed and the differences between SC and safety culture are discussed. Moreover, recommendations for future research on SC are also given based on the results of bibliometric analysis and existing literature reviews. © 2022 Elsevier Ltd",TestAnalysis
"Within the discipline of semiotics, written text remains the primary mode of communication and analysis, despite the fact that, as all good semioticians know, signs occur in all modalities - which is why we think of artists and musicians, no less than novelists and poets, as applied semioticians par excellence. In 1997, Paul Cobley and Litza Jansz combined the semiotic tools of words and drawings to produce what is undoubtedly one of the most successful and influential texts for the dissemination of semiotic theory: the illustrated graphic guide called Semiotics for beginners (later published as Introducing semiotics). On the occasion of this well-deserved festschrift honoring Paul's life of work in semiotics, the authors felt it most appropriate to pay homage to Paul - and to the graphic guide with which he has inspired countless readers across the world to better understand the fundamentals of semiotics - by once again combining the semiotic tools of words and drawings to illustrate the ideas and history of this master semiotician. © 2023 De Gruyter Mouton. All rights reserved.",TestAnalysis
"Accurate prediction of the duration of traffic incidents is one of the most prominent prerequisites for effective implementation of proactive traffic incident management strategies. This paper presents a novel method for immediate prediction of traffic incident duration using an emerging supervised topic modeling. The proposed method employs natural language processing techniques for semantic text analysis of the text-based incident traffic incident dataset. The model applies the labeled latent Dirichlet allocation approach, and it is trained using 1,466 incident records collected by the Korea Expressway Corporation from 2016 to 2019. For training purposes, the proposed method divides the incidents into two groups based on the incident duration: incidents shorter than 2 h and incidents lasting 2 h or longer, following the incident management guidelines of the Federal Highway Administration Manual on Uniform Traffic Control Devices for Streets and Highways (2009). The model is tested with randomly selected incident records that were not used for the model training. The results demonstrate overall prediction accuracies of approximately 74% for incidents lasting up to 2 h, and 82% for incidents lasting 2 h or longer. © National Academy of Sciences: Transportation Research Board 2022.",TestAnalysis
"Supervised personal training is most effective in improving the health effects of exercise in older adults. Yet, low frequency (60 min, 1–3 sessions/week) of trainer contact limits influence on behavior change outside sessions. Strategies to extend the effect of trainer contact outside of supervision and that integrate meaningful and intelligent two-way communication to provide complex and interactive problem solving may motivate older adults to “move more and sit less” and sustain positive behaviors to further improve health. This paper describes the experimental protocol of a 16-week pilot RCT (N = 46) that tests the impact of supplementing supervised exercise (i.e., control) with a technology-based behavior-aware text-based virtual “Companion” that integrates a human-in-the-loop approach with wirelessly transmitted sensor-based activity measurement to deliver behavior change strategies using socially engaging, contextually salient, and tailored text message conversations in near-real-time. Primary outcomes are total-daily and patterns of habitual physical behaviors after 16 and 24 weeks. Exploratory analyses aim to understand Companion’s longitudinal behavior effects, its user engagement and relationship to behavior, and changes in cardiometabolic and cognitive outcomes. Our findings may allow the development of a more scalable hybrid AI Companion to impact the ever-growing public health epidemic of sedentariness contributing to poor health outcomes, reduced quality of life, and early death. © 2023 by the authors.",TestAnalysis
"As part of a business strategy, effective competitive research helps businesses outperform their competitors and attract loyal consumers. To perform competitive research, sentiment analysis may be used to assess interest in certain themes, uncover market conditions, and study competitors. Artificial intelligence (AI) has improved the performance of multiple areas, particularly sentiment analysis. Using AI, sentiment analysis is the process of recognizing emotions expressed in text. AI comprehends the tone of a statement, as opposed to merely recognizing whether particular words within a group of text have a negative or positive connotation. This article reviews papers (2012–2022) that discuss how competitive market research identifies and compares major market measurements that help distinguish the services and goods of the competitors. AI-powered sentiment analysis can be used to learn what the competitors’ customers think of them across all aspects of the businesses. © 2023 by the authors.",TestAnalysis
"Status Epilepticus (SE) is a neurological emergency resulting from the failure of mechanisms of seizure termination or from the initiation of mechanisms that lead to prolonged seizures. The International League Against Epilepsy (ILAE) identified 13 chromosomal disorders associated with epilepsy (CDAE); data regarding SE occurrence in these patients is lacking. A systematic scoping review was conducted to outline current literature evidence about clinical features, treatments, and outcomes of SE in pediatric and adult patients with CDAE. A total of 373 studies were identified with the initial search; 65 of these were selected and regarded as SE in Angelman Syndrome (AS, n = 20), Ring 20 Syndrome (R20, n = 24), and other syndromes (n = 21). Non-convulsive status epilepticus (NCSE) is frequently observed in AS and R20. No specific, targeted therapies for SE in CDAE are available to date; anecdotal reports about SE treatment are described in the text, as well as various brief- and long-term outcomes. Further evidence is needed to precisely portray the clinical features, treatment options, and outcomes of SE in these patients. © 2023 by the authors.",TestAnalysis
"Previous quantitative studies discussing interpreting types have focused on various features of linguistic forms in outputs. However, none of them has examined their informativeness. Entropy, as a measure of the average information content and the uniformity of the probability distribution of language units, has been applied to quantitative linguistic research on different types of language texts. In the present study, entropy and repeat rate were used to investigate the difference of overall informativeness and concentration of output texts between simultaneous interpreting and consecutive interpreting. We intend to figure out the frequency distribution patterns of word and word category in two types of interpreting texts. Analyses of linear mixed-effects models showed that entropy and repeat rate can distinguish the informativeness of consecutive and simultaneous interpreting outputs, and consecutive interpreting outputs entail a higher word entropy value and a lower word repeat rate than simultaneous interpreting outputs. We propose that consecutive interpreting is a cognitive process which reaches an equilibrium between production economy for interpreters and comprehension sufficiency for listeners, especially in the case where input speeches are more complex. Our findings also shed lights on the selection of interpreting types in application scenarios. The current research is the first of its kind in examining informativeness across interpreting types, demonstrating a dynamic adaptation of language users to extreme cognitive load. © 2023 by the authors.",TestAnalysis
"Background: The aim of this review of the literature was to find and summarize relevant research evidence available within the scientific sources and gray literature in accordance with the JBI recommendations. Search question: What effect does Basal Stimulation have on the cognitive–behavioral functions or temperament of a preterm or disabled infant? Methods: The following sources were searched: PSYCINFO, MEDLINE, PsycArticles, ERIC, Wiley Online Library, ProQuest Scopus, WOS, JSTOR, Google Scholar, and MedNar. The study contains an analysis of texts that have been published in the English, Czech, and German languages. The search time span was set at 15 years. Results: A total of 15 sources were found for the specified topic. Conclusions: In all cases, there was confirmation about the positive influence of the concept of “Basal Stimulation” on the cognitive–behavioral functions and temperament of premature and disabled children. © 2023 by the authors.",TestAnalysis
"Post-Occupancy Evaluation (POE) began in the 1960s and examines the effectiveness of the design of human-occupied environments. Philippe Boudon published Le Corbusier's Pessac, later translated into English as Lived-In Architecture. Le Corbusier's Pessac revisited. The book presents a series of interviews conducted with those involved in the design process and its inhabitants and is considered a milestone of POE. Numerous research publications have cited Boudon's study from different perspectives, but no text has been located that analyzes his method under the perspective of POE. The goal of this paper is to elaborate a diagram for the systematic comparison of cases of Post-Occupancy Evaluation in housing and to apply it to the analysis of the method proposed by Boudon, identifying its contributions in each aspect. This research is structured in four phases: Location and bibliographic selection on POE in housing; Identification of common topics in the literature for the characterization of POE methods; Creation of the comparative model of evaluation methods; Application of the model to Boudon's study to corroborate its correct functioning. As a result, it has been identified that Lived-In Architecture is a research-initiated assessment, has a general dimension, and focuses on the occupants' perspective. It uses retrospective understanding techniques and takes place during the operation stage of the dwellings with the objective of measuring the performance of the building. Therefore, it is considered within the investigative Post-Occupancy Evaluation studies. © 2023, Universitat Politecnica de Catalunya. All rights reserved.",TestAnalysis
"Anti-HER2 therapies have dramatically improved the prognosis of human epidermal growth factor receptor 2 (HER2)-overexpressing cancers. However, the correlation between the HER2 copy number and the response rate to anti-HER2 remains unclear. Here, following the PRISMA method, we performed a meta-analysis in the neoadjuvant setting in breast cancer to study the association between the HER2 amplification level and the pathological complete response (pCR) to anti-HER2 therapies. Nine articles (four clinical trials, five observational studies) were retrieved after full-text screening, involving 11,238 women with locally advanced breast cancer in the neoadjuvant setting. The median HER2/CEP17 ratio cut-off value was 5.0 ± 5.0 (min-max = 1.0–14.0). For the overall population, the median pCR rate was 48% using the random effect model. The studies were categorized in quartiles as follows: ≤2 (Class 1); 2.1 to 5.0 (Class 2); 5.1 to 7.0 (Class 3); and >7.0 (Class 4). After grouping, the pCR rates were 33%, 49%, 57%, and 79%, respectively. When we excluded the study by Greenwell et al., which accounted for 90% of the patients, using the same quartiles, we still observed an increasing rate of pCR as the HER2/CEP17 ratio increased. This is the first meta-analysis demonstrating the relationship between the HER2 amplification level and the percentage of pCR in the neoadjuvant setting among women with HER2-overexpressing breast cancer, with potential therapeutic applications. © 2023 by the authors.",TestAnalysis
"Relation extraction (RE) is a fundamental NLP task that aims to identify relations between some entities regarding a given text. RE forms the basis for many advanced NLP tasks, such as question answering and text summarization, and thus its quality is critical to the relevant downstream applications. However, evaluating the quality of RE models is non-trivial. On the one hand, obtaining ground truth labels for individual test inputs is tedious and even difficult. On the other hand, there is an increasing need to understand the characteristics of RE models in terms of various aspects. To mitigate these issues, this study proposes evaluating RE models by applying metamorphic testing (MT). A total of eight metamorphic relations (MRs) are identified based on three categories of transformation operations, namely replacement, swap, and combination. These MRs encode some expected properties of different aspects of RE. We further apply MT to three popular RE models. Our experiments reveal a large number of prediction failures in the subject RE models, confirming that MT is effective for evaluating RE models. Further analysis of the experimental results reveals the advantages and disadvantages of our subject models and also uncovers some typical issues of RE models. © 2023 by the authors.",TestAnalysis
"In 2018, in the Dialogue, Debate, and Discussion section of MOR 14.3, an interesting series of articles was published in the 'Forum on Tesla and the Global Automotive Industry', where researchers discussed the future dynamics of the global automotive sector. In their work, Perkins and Murmann (2018) contended that, based on Tesla's success, a well-funded company could develop a new electric vehicle (EV) from scratch and move it into production within three to five years if it would invest one to two billion USD in design, development, and manufacturing. Expressing a contrasting view, MacDuffie (2018) questioned this possibility, arguing that EV product architecture is unlikely to become substantially more modular and any new entrant would therefore have to develop the ordinary capabilities that current automotive original equipment manufacturers possess, and there is no guarantee that a firm can develop such capabilities. Teece (2018) joined the debate by proposing a capability-based framework within which to analyze four paradigm shifts that have marked progress in the global automotive industry: EVs, autonomous vehicles, connected cars, and personal mobility services. He argues that these paradigm shifts have created opportunities for new entrants while posing challenges to incumbent firms. To navigate through the uncertainty associated with these paradigm shifts, incumbent firms need to enhance and refine their dynamic capabilities and leverage their integration skills. Jiang and Lu (2018) based their contribution to this debate on the development of the Chinese EV market. In MOR 15.1, published in 2019, Teece (2019) further elaborated his framework to facilitate analysis of the prospects for Chinese firms seeking a stronger foothold in the global automobile market. All these articles have been well received by MOR readers and were ranked among the top 20 articles in full-text view times between June 2021 and June 2022. Copyright © The Author(s), 2023. Published by Cambridge University Press on behalf of The International Association for Chinese Management Research.",TestAnalysis
"Based on Shannon’s communication theory, in the present paper, we provide the theoretical background to finding an objective measurement—the text-entropy—that can describe the quality of digital natural language documents handled with word processors. The text-entropy can be calculated from the formatting, correction, and modification entropy, and based on these values, we are able to tell how correct or how erroneous digital text-based documents are. To present how the theory can be applied to real-world texts, for the present study, three erroneous MS Word documents were selected. With these examples, we can demonstrate how to build their correcting, formatting, and modification algorithms, to calculate the time spent on modification and the entropy of the completed tasks, in both the original erroneous and the corrected documents. In general, it was found that using and modifying properly edited and formatted digital texts requires less or an equal number of knowledge-items. In information theory, it means that less data must be put on the communication channel than in the case of erroneous documents. The analysis also revealed that in the corrected documents not only the quantity of the data is less, but the quality of the data (knowledge pieces) is higher. As the consequence of these two findings, it is proven that the modification time of erroneous documents is severalfold of the correct ones, even in the case of minimal first level actions. It is also proven that to avoid the repetition of the time- and resource-consuming actions, we must correct the documents before their modification. © 2023 by the authors.",TestAnalysis
"Objective: This study reviewed the literature on local or systemic administration of antisclerostin, presenting results associated with osseointegration of dental/orthopedic implants and stimulation of bone remodeling. Materials and Methods: An extensive electronic search was conducted through MED-LINE/PubMed, PubMed Central, Web of Science databases and specific peer-reviewed journals to identify case reports, case series, randomized controlled trials, clinical trials and animal studies comparing either the systemic or local administration of antisclerostin and its effect in osseointegration and bone remodeling. Articles in English and with no restriction on period were included. Results: Twenty articles were selected for a full-text, and one was excluded. Finally, 19 articles were included in the study (16 animal studies and 3 randomized control trials). These studies were divided into two groups, which evaluated (i) osseointegration and (ii) bone remodeling potential. Initially 4560 humans and 1191 animals were identified. At least 1017 were excluded from the studies (981 humans and 36 animals), totaling 4724 subjects who completed (3579 humans and 1145 animals). (a) Osseointegration: 7 studies described this phenomenon; 4 reported bone-implant contact, which increased in all included studies. Similar results were found for bone mineral density, bone area/volume and bone thickness. (b) Bone remodeling: 13 studies were used for description. The studies reported an increase in BMD with sclerostin antibody treatment. A similar effect was found for bone mineral density/area/volume, trabecular bone and bone formation. Three biomarkers of bone formation were identified: bone-specific alkaline phosphatase (BSAP), osteocalcin and procollagen type 1 N-terminal Pro-peptide (P1NP); and markers for bone resorption were: serum C-telopeptide (sCTX), C-terminal telopeptides of type I collagen (CTX-1), β-isomer of C-terminal telopeptides of type I collagen (β-CTX) and tartrate-resistant acid phosphatase 5b (TRACP-5b). There were limitations: low number of human studies identified; high divergence in the model used (animal or human); the variance in the type of Scl-Ab and doses of administration; and the lack of reference quantitative values in the parameters analyzed by authors’ studies (many articles only reported qualitative information). Conclusion: Within the limitations of this review and carefully observing all data, due to the number of articles included and the heterogeneity existing, more studies must be carried out to better evaluate the action of the antisclerostin on the osseointegration of dental implants. Otherwise, these findings can accelerate and stimulate bone remodeling and neoformation. © 2023 by the authors.",TestAnalysis
"Data visualization facilitates the overall analysis and in-depth mining of data. However, visualized data in the form of images are not conducive to machine understanding, which means it cannot meet the requirements of subsequent automated intelligent systems for practical engineering projects. The traditional method of curve image data reconstruction relying on manual features obtains the reconstructed data by point selection method or image pre-processing combined with manual input of coordinate axis information. Its accuracy and efficiency are low, and it does not have the characteristics of automation and high-volume processing. To solve this problem, we propose an end-to-end convolutional neural network model based on a deep learning approach. The model adopts a multi-task co-encoding-independent decoding structure, and combines an attention mechanism to effectively improve the information quality during the jump connection process to achieve multi-task joint learning for curve segmentation and text detection. We validate the effectiveness of the model on a curve image dataset, where the accuracy of curve segmentation and text detection achieved 94.0% and 99.5%, respectively. ICIC International ©2023.",TestAnalysis
"Background: Around 500/100,000 Canadians experience a traumatic brain injury (TBI) resulting in long-term disabilities and premature death. Physiotherapy is known to positively impact the prognosis of young adults following a TBI. Objective: This is a scoping review that aimed to identify research topics in physiotherapy interventions for seniors after a TBI, describe potential knowledge gaps, and uncover needs for future research. Methodology: Ten databases were interrogated (January–March 2022). We included texts published after 2010, in English or French, scientific papers, guidelines, and gray literature sources targeting in-hospital, acute-to-subacute interventions for people aged ≥55 years old with a moderate-to-severe TBI. The outcomes sought were physical/functional capacities, injury severity, and quality of life. Results: From 1296 articles, 16 were selected. The number of participants from the studies altogether was 248,794. We identified eight retrospectives studies, three clinical trials, and five articles from the gray literature. Articles were classified according to the nature of their analysis and outcomes: (1) interventional studies including physiotherapy (at least 10 types of rehabilitative or preventive interventions were identified); (2) studies evaluating prognostic factors (five factors identified); and (3) recommendations from clinical practical guidelines and other sources (gray literature). Our results provide evidence that physiotherapy is effective in TBI acute rehabilitation for the elderly to prevent complications arising from the primary injury and to improve functional capacities. Conclusion: The heterogeneity of our results does not allow us to infer the effectiveness of one intervention over another. However, we found that the elderly population benefits from physiotherapy interventions as much as adults, but the gap must be filled with higher-quality studies to make definite recommendations. © 2023 by the authors.",TestAnalysis
"Medical treatment and narratives are interrelated. We examined this interrelation by evaluating the medical dispute mediation system in Taiwan. We conducted 16 semi-structured interviews with legal and administrative specialists in medical mediation and physicians involved in mediation meetings. The interview data were reproduced into almost verbatim text for coding and analysis. We examined how narratives were discussed in the field of medicine and identified two approaches to narratives. One was the narrative from a patient's storytelling, that is, narrative-based medicine. The other was the narrative of medical staff, which included shared decision-making and decision aids. Discussions of these approaches revolved around the avoidance of conflicts during medical treatment. However, knowing how to handle unsuccessful medical treatment is crucial. By applying polyphony in narratives, physicians can comprehend the role of narratives in unsuccessful medical treatment, helping themselves to practice how to develop narratives to communicate with patients and their surrogates when encountering any difficulty in different stages of medical treatment. © 2023 The Authors",TestAnalysis
The Ethiopian magic scrolls are traditional parchment artifacts used by the Christians of Ethiopia as protection against disease and demonic possessions. On the occasion of their restoration in the Accademia delle Belle Arti di Bologna (Italy); a preliminary characterization before the treatments has been performed on four Ethiopian scrolls belonging to the Archivio storico della provincia di Cristo Re dei Frati Minori dell’Emilia Romagna of Bologna (Italy). In order to plan an effective preservative restoration procedure and; at the same time; to investigate the manufacturing techniques; the text and the decorations on the magic scrolls were studied and characterized. A combined approach by imaging and compositional techniques was used: Infrared Reflectography (IRR) for the preliminary characterization of the graphic supports and the identification of the points to sample the chemical measurements; and the spectroscopic analyses to clarify the hypothesized investigations and confirm the chemical composition of the inks. In particular; Attenuated Total Reflectance-Fourier Transform Infrared (ATR-FTIR) spectroscopy has provided information relating to the molecular composition of inks and pigments; while a characterization of the constituent elements is obtained with the Ion Beam Analysis (IBA). The ink composition proved to be consistent with data generally documented in the literature and contributing to the expansion of knowledge on Ethiopian magic scrolls and their production. © 2023 by the authors.,TestAnalysis
"Wearable activity trackers and smartphone apps have been shown to increase physical activity in children and adults. However, interventions using activity trackers and apps have rarely been tested in whole families. This study examined the experience and satisfaction with an activity tracker and app intervention (Step it Up Family) to increase physical activity in whole families. Telephone interviews were conducted with Queensland-based families (n = 19) who participated in the Step it Up Family intervention (N = 40, single-arm, pre/post feasibility study) in 2017/2018. Using commercial activity trackers combined with apps, the intervention included an introductory session, individual and family-level goal setting, self-monitoring, family step challenges, and weekly motivational text messages. Qualitative content analysis was conducted to identify themes, categories and sub-categories. In summary, parents reported that children were engaged with the activity tracker and app features to reach their daily step goals. Some technical difficulties were experienced with app navigation, syncing of activity tracker data, and tracker band discomfort. Although families liked that the weekly text messages reminded them to be active, they did not find them very motivating. Using text messages for physical activity motivation in families requires further testing. Overall, the intervention was well-received by families for increasing physical activity motivation. © 2023 by the authors.",TestAnalysis
"In Results,’’ the article by Osama , ‘‘Perioperative Mostafa El-Gamal Use of Cyproterone et al., published Acetate in with Journal Transurethral of Endourology Resection , 2015, of vol. Large 29, Prostate: no. 5, pp Preliminary 569–574, amendments have been made. The statistical analysis section has been modified by deleting a portion. The figures on the Tables now match those in the text. A clearer image of the data is now shown in the Results section. This will help the urologists understand the significance of the research data and thus benefit from the study. The authors are grateful for the changes. The revised pdf of the article is now online. © 2023 Mary Ann Liebert Inc.. All rights reserved.",TestAnalysis
"The strength of weak ties and brokerage theory both rely on the argument that weak bridging ties deliver novel information to create “vision advantages” for actors in brokerage positions. However, our conceptualization of novelty is itself fundamentally underdeveloped. We, therefore, develop a theory of how three distinct types of novelty-diversity, non-redundancy, and uniqueness-combine with network structure to create vision advantages in social networks. We test this theory using panel data on an evolving corporate email network. Three main results emerge from our analysis. First, we confirm the diversity-bandwidth tradeoff (DBT) at the heart of the vision advantage. As brokers' networks become more diverse, their channel bandwidth contracts, creating countervailing effects on access to novel information. Second, we uncover a mechanism driving the DBT, which helps explain differences in vision advantages across strong and weak ties. Strong, cohesive ties deliver greater information diversity and non-redundancy, whereas weak bridging ties contribute the most unique information (the information that is most different from what other contacts deliver). Third, we find network diversity (in contrast to network constraint) to be positively associated with longitudinal entropy, a measure of the accumulation of novel information over time. This suggests that weak bridging ties, which provide the most unique information through low bandwidth, structurally diverse channels, contribute the most to one's aggregation of novel information over time. Collectively, these results take a step toward resolving a long-standing debate in network theory about whether strong, cohesive networks or weak bridging networks contribute more to vision advantages. This work firmly establishes that it depends. Copyright: © 2022 INFORMS.",TestAnalysis
"Chagas disease (CD) is endemic in large parts of Central and South America, as well as in Texas and the southern regions of the United States. Successful parasites, such as the causative agent of CD, Trypanosoma cruzi have adapted to specific hosts during their phylogenesis. In this work, we have assembled an interactive network of the complex relations that occur between molecules within T. cruzi. An expert curation strategy was combined with a text-mining approach to screen 10,234 full-length research articles and over 200,000 abstracts relevant to T. cruzi. We obtained a scale-free network consisting of 1055 nodes and 874 edges, and composed of 838 proteins, 43 genes, 20 complexes, 9 RNAs, 36 simple molecules, 81 phenotypes, and 37 known pharmaceuticals. Further, we deployed an automated docking pipeline to conduct large-scale docking studies involving several thousand drugs and potential targets to identify network-based binding propensities. These experiments have revealed that the existing FDA-approved drugs benznidazole (Bz) and nifurtimox (Nf) show comparatively high binding energies to the T. cruzi network proteins (e.g., PIF1 helicase-like protein, trans-sialidase), when compared with control datasets consisting of proteins from other pathogens. We envisage this work to be of value to those interested in finding new vaccines for CD, as well as drugs against the T. cruzi parasite. © 2023 by the authors.",TestAnalysis
"As a summary of this study, at first, Questionnaire of selective question was performed. At second, Landscape resources were extracted by cluster analysis based on the questionnaire of free description. At third, Landscape characteristics were extracted by text mining analysis based on free writing. As a result, usability of data and analysis methods were exposed by questionnaire in Akita city. We think, this result is useful about landscape policies in other city. © 2023 Architectural Institute of Japan. All rights reserved.",TestAnalysis
"As an important infrastructure in the era of big data, the knowledge graph can integrate and manage data resources. Therefore, the construction of tourism knowledge graphs with wide coverage and of high quality in terms of information from the perspective of tourists’ needs is an effective solution to the problem of information clutter in the tourism field. This paper first analyzes the current state of domestic and international research on constructing tourism knowledge graphs and highlights the problems associated with constructing knowledge graphs, which are that they are time-consuming, laborious and have a single function. In order to make up for these shortcomings, this paper proposes a set of systematic methods to build a tourism knowledge graph. This method integrates the BiLSTM and BERT models and combines these with the attention mechanism. The steps of this methods are as follows: First, data preprocessing is carried out by word segmentation and removing stop words; second, after extracting the features and vectorization of the words, the cosine similarity method is used to classify the tourism text, with the text classification based on naive Bayes being compared through experiments; third, the popular tourism words are obtained through the popularity analysis model. This paper proposes two models to obtain popular words: One is a multi-dimensional tourism product popularity analysis model based on principal component analysis; the other is a popularity analysis model based on emotion analysis; fourth, this paper uses the BiLSTM-CRF model to identify entities and the cosine similarity method to predict the relationship between entities so as to extract high-quality tourism knowledge triplets. In order to improve the effect of entity recognition, this paper proposes entity recognition based on the BiLSTM-LPT and BiLSTM-Hanlp models. The experimental results show that the model can effectively improve the efficiency of entity recognition; finally, a high-quality tourism knowledge was imported into the Neo4j graphic database to build a tourism knowledge graph. © 2023 by the authors.",TestAnalysis
"After this article was published, similarities were noted between this article [1] and submissions by other research groups which call into question the validity and provenance of the reported results. In response to queries about these concerns, the first author provided the underlying data in S1 File. During editorial follow-up, it was noted that the statement in the Results section in article [1] that 46 potential studies were reviewed via the full-text is an error and should state that 47 potential studies were reviewed via the full-text. The authors commented on aspects of how data were collected and analyzed for this study, but overall their responses did not fully resolve the concerns. The PLOS ONE Editors issue this Expression of Concern to notify readers of the unresolved concerns discussed above, and to provide the data received from the authors. © 2023 The PLOS ONE Editors. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Gérard Genette believes that different texts are influenced by earlier works. He divides the relations between texts into five categories: Intertextualitie, Architextualite, Paratextualite, Metatextualite, and Hypertextualite. Since one of the most important issues in comparative literature is literary influence, and Genette in transtextuality theory explores the impact of texts on one another, it can be said that transtextuality is of great significance in comparative literature. Vampires are European legends that have attracted teenage audience, and Golshiri has introduced this genre to Iranian fiction for the first time. In this research, using the content analysis method, we want to examine Meyer’s vampire novels and Golshiri's Vampire according to their transtextual relations in order to answer the following questions: how is the primary text transferred to the secondary text in Golshiri’s Vampire? Which elements of transtextuality are used by Golshiri in his works? In what ways have the cultural relations influenced the secondary text? It is argued that in his works, Golshiri has used the intertextualitie, architextualite, paratextualite, and hypertextualite, and Iranian cultural relations have caused changes in the story. © The Author(s).",TestAnalysis
"Renal transplantation is the gold-standard treatment for adolescents and young adults with end-stage renal disease. Despite enjoying excellent short-term outcomes, they suffer the worst rates of premature transplant function loss. Health behaviors: such as lack of adherence to immunosuppressive medications, are felt to be the major contributory factor. Understanding the educational needs of young renal transplant recipients allows healthcare practitioners to better support patients in managing their chronic disease. The aim of this scoping review was to understand what is known about their educational needs. A scoping review methodology was followed. Following an online search, study titles, and abstracts were screened for eligibility, followed by full-text assessment and data extraction. Data were qualitatively analyzed using thematic analysis. A total of 29 studies were included in the scoping review. In young people who struggled with self-management, three themes were identified (1) the Needs of the disrupted youth, (2) the Needs of the disorganized youth (3) the Needs of the distressed youth. There was a paucity of research to identify the protective factors that enable young recipients to successfully manage their health. This review outlines current knowledge of the patient education needs of young transplant recipients. It also highlights remaining research gaps that will need to be addressed with future research. © 2023 by the authors.",TestAnalysis
"Engineering underpins the progress of modern societies. However, engineering activities are a key driver of climate change and engineers are responsible in many ways for disaster risk reduction. It is therefore imperative that engineering education accurately portrays the impact that the profession has on our climate and equips engineers with the knowledge to mitigate greenhouse gas emissions and to adapt infrastructure for climate resilience. Here, we explore how higher education prepares engineers to address the climate crisis via a curricula analysis of three departments (mechanical, civil, and electrical engineering). The pilot study investigated the extent of mitigation and adaptation to climate change (MACC) content across different disciplines by developing and applying an evaluation methodology. We found that module descriptions and learning objectives were largely without reference to MACC, further evidencing the dissociation of engineering education from the climate reality as cited in the literature. This novel approach goes beyond curricula analysis to integrate MACC within module outlines paving the way for future integration. This research demonstrates the urgent need for climate conscious engineering curricula. © 2023 by the authors.",TestAnalysis
"In recent years, overlapping entity relation extraction has received a great deal of attention and has made good progress in English. However, the research on overlapping entity relation extraction in Chinese still faces two key problems: one is the lack of datasets with overlapping entity instances, and the other is the lack of a neural network model that can effectively solve overlapping entity relation extraction. To address the above problems, this paper produces an interpersonal relationship dataset, NewsPer, for news texts and proposes a Chinese overlapping entity relation extraction model, DepCasRel. First, the model uses “Word-label” to incorporate the character features of Chinese text into the dependency analysis graph, and then uses the same binary labeling method to label the head and tail entities embedded in the text. Finally, the text’s triples are extracted. DepCasRel solves the problem that traditional methods make it difficult to extract triples with overlapping entities. Experiments on our manually annotated dataset NewsPer show that DepCasRel can effectively encode the semantic and structural information of text and improve the performance of an overlapping entity relation extraction model. © 2023 by the authors.",TestAnalysis
"This article reveals the continuity of Neoplatonic ideas in Greek-Byzantine patristics in the process of elaboration of the triadic dogma by the Church Fathers. Common and distinctive principles of Neoplatonism and Eastern Christianity are deduced from the point of view of the shaping of Christian ethics and the processing of Neoplatonic concepts in patristic texts. In more specific terms, Plotinus’ concept of the triad of the One–the Intellect–the Soul is considered, with special attention paid to analysis of the philosopher’s ideas of the One as Deity and the Origin of the world. It describes the process of emanation of the Neoplatonic trinity hypostasis and its connection with the material world through the World Soul. In comparison with Neoplatonism, the authors of the article present the molding of the dogma of the Holy Trinity in classical Greek-Byzantine patristics and highlight the new, theological-ethical vision of Plotinus’ triad as a form of the interconnection of the three Persons of the Trinity, expressing the absoluteness of interpersonal relations. In terms of philosophical ethics, the authors state that the Church Fathers’ understanding of the relationship among the three hypostases of the Holy Trinity serves as a model of perfect moral relationships demonstrating the absolute norms of morality for a human being. Neoplatonism was deprived of such a context in its interpretation of Plotinus’ triad. The creative and critical perception of Plotinus’ conceptual positions in the works of St. Athanasius is presented. Conclusions are made about the creative, sometimes critical, perception of the ideas of Neoplatonism in the formation of a new type of Christian ethics. © 2023 by the authors.",TestAnalysis
"The scholarly field of organizational prosociality is experiencing a renewed interest, yet despite its long track record, researchers still disagree on the definitions of primary concepts. Two umbrella terms, prosocial behaviors and kindness, are particularly baffling, as they are defined similarly, at times used synonymously, yet the differences between them are unclear. Consequently, the field suffers from conceptual ambiguity, which hampers its development. In this brief critical paper, we provide a review of the definitions of prosocial behavior and kindness, in an attempt to semantically untie the text, unpack the context, and discuss the subtext that underlies these concepts. Our analysis suggests that the two concepts overlap in their emphasis on dispositions and actions that aim to promote the welfare of others. However, acts of kindness and prosocial behaviors differ in actors, their target recipients and scale. Acts of kindness are performed by an individual and directed at a person or a small group, while prosocial behaviors can be performed by a person or an organization, and can be directed at a person or a group, but may also be directed at a much larger entity: an organization, community, nation, or society at large. © 2023 by the authors.",TestAnalysis
"Background: Several federal policies and initiatives emphasize collecting patients’ experience during pharmaceutical development processes. Family caregivers, who commonly manage a patient or care recipient's medications, are increasingly engaged in healthcare settings but are not yet formally involved in pharmaceutical development processes. To explore the potential benefit of such inclusion, we conducted a systematic literature review of U.S. studies pertaining to caregivers’ engagement in pharmaceutical assessment and development. We sought to: (1) quantify the number of analyses in the U.S. that incorporated caregiver evaluation of therapeutic agents, medications, or pharmaceuticals; (2) explore the characteristics of such studies (e.g., care context; patient age); and, (3) synthesize findings pertaining to caregiver engagement. Methodology: We assessed articles in PubMed and Google Scholar with specified search terms and eligibility criteria. Results: Our review identified 25 full-text articles on studies involving pediatric (n = 13) and adult patient (n = 12) populations. Most articles pertained to pharmaceutical assessment for ADHD and epilepsy among pediatric patients and to neurodegenerative-related disease among adult patients. Only a few studies in each patient population, pediatric and adult, compared patient and caregiver assessments for agreement or explored patient and caregiver outcomes. Conclusions: Findings suggest an opportunity for research on patient and caregiver agreement in medication evaluation as well as assessment of patient and caregiver outcomes as a result of caregiver engagement. Such analyses should also extend beyond pediatric and neurodegenerative care given that caregivers are shown to be included in treatment-decision making in other care contexts. © 2022 Elsevier Masson SAS",TestAnalysis
"This research aims to carry out a systematic review of the available literature about smart irrigation systems. It will be focused on systems using artificial intelligence techniques in urban and rural agriculture for soil crops to identify those that are currently being used or can be adapted to urban agriculture. To this end, a modified PRISMA 2020 method is applied, and three search equations are formulated. From those filters, and after a screening process, 170 articles are obtained. These articles are analyzed through VantagePoint, a text processing software. After this, they are taken through a detailed analysis phase in which 50 sources are selected as the most relevant to be read and analyzed by topic. Finally, the different phases of the analysis are used to draw conclusions that might be interesting for researchers working in this specific field or for the general public interested in rural and urban agriculture and its automation. © 2023 by the authors.",TestAnalysis
"COVID-19 vaccines have saved millions of lives; however, understanding the long-term effectiveness of these vaccines is imperative to developing recommendations for booster doses and other precautions. Comparisons of mortality rates between more and less vaccinated groups may be misleading due to selection bias, as these groups may differ in underlying health status. We studied all adult deaths during the period of 1 April 2021–30 June 2022 in Milwaukee County, Wisconsin, linked to vaccination records, and we used mortality from other natural causes to proxy for underlying health. We report relative COVID-19 mortality risk (RMR) for those vaccinated with two and three doses versus the unvaccinated, using a novel outcome measure that controls for selection effects. This measure, COVID Excess Mortality Percentage (CEMP), uses the non-COVID natural mortality rate (Non-COVID-NMR) as a measure of population risk of COVID mortality without vaccination. We validate this measure during the pre-vaccine period (Pearson correlation coefficient = 0.97) and demonstrate that selection effects are large, with non-COVID-NMRs for two-dose vaccinees often less than half those for the unvaccinated, and non-COVID NMRs often still lower for three-dose (booster) recipients. Progressive waning of two-dose effectiveness is observed, with an RMR of 10.6% for two-dose vaccinees aged 60+ versus the unvaccinated during April–June 2021, rising steadily to 36.2% during the Omicron period (January–June, 2022). A booster dose reduced RMR to 9.5% and 10.8% for ages 60+ during the two periods when boosters were available (October–December, 2021; January–June, 2022). Boosters thus provide important additional protection against mortality. © 2023 by the authors.",TestAnalysis
"Radical/extremist Islamist actors use social media to disseminate uncompromising stories of monist religious political orders and identities. As a reaction, counter-movements to online Islamist radicalism/extremism emerged in Western societies (and beyond), while uncertainty about effective outcomes remains widespread. In a bid to understand how inclusionary and exclusionary discursive spaces are created, we ask: How do some Muslim actors create discursive spaces open to self-reflection, pluralism and liberal-democratic principles, while others construct illiberal, particularistic and non/anti-democratic spaces? To respond to this question, we compare two contrasting storytellers, one who agitates for exclusionary Islamist radicalism/extremism (Generation Islam) and one who offers inclusionary prevention and deradicalization work against that (Jamal al-Khatib). We draw on novel narrative approaches to the Discourse Historical Approach (DHA) in Critical Discourse Studies (CDS), via which we compare text-level and context-level narratives disseminated about three Muslim-related crises: the racist terrorist attacks/genocide to represent the national, European and global level. Our two-layered, DHA-inspired narrative analysis illustrates that, at the level of text, narrative persuasion varies between both contrasting actors. While Jamal al-Khatib disseminates persuasive stories, Generation Islam is much less invested in narrative persuasion; it seems to address an already convinced audience. These two text-level strategies reveal their meaning in two antagonistic narrative genres: Jamal al-Khatib’s “self-reflexive savior” creates an inclusionary discursive space represented in a self-ironic narrative genre, while Generation Islam’s ”crusading savior” manufactures an exclusionary discursive space represented in a romance featuring a nostalgic return to the particularistic Islamic umma. © 2023 by the authors.",TestAnalysis
"Purpose There is robust evidence for offering supported self-management interventions for people with severe mental illness (SMI) throughout secondary mental health services, but their availability remains patchy. The aim of this systematic review is to synthesise the evidence on barriers and facilitators to implementing self-management interventions for people with SMI in secondary mental health care settings. Methods The review protocol was registered with PROSPERO (CRD42021257078). Five databases were searched to identify relevant studies. We included full-text journal articles with primary qualitative or quantitative data on factors which affect the implementation of self-management interventions for people with SMI in secondary mental health services. The included studies were analysed using narrative synthesis, using the Consolidated Framework for Implementation Research and an established taxonomy of implementation outcomes. Results Twenty-three studies from five countries met eligibility criteria. The barriers and facilitators identified in the review were mainly on the organisational level, but included some individual-level influences. Facilitators included high feasibility, high fidelity, a strong team structure, sufficient number of staff, support from colleagues, staff training, supervision, the presence of an implementation champion and adaptability of the intervention. Barriers to implementation include high staff turnover, staff shortage, lack of supervision, lack of support for staff delivering the programme, staff struggling with their increased workload, a lack of senior clinical leadership, and programme content perceived as irrelevant. Conclusion The findings from this research suggest promising strategies to improve implementation of self-management interventions. For services providing support for people with SMI, organisational culture should be considered, as well as the adaptability of interventions. © 2023 Islam et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"There is concern among the general public that information technology (IT) innovations may make existing jobs redundant. This may be perceived to pose a greater problem to future generations because new technologies, not limited to IT innovations, will be sophisticated in the future. Our previous work revealed that messages reminding people of familial support as a nudge can moderate risk-averse attitudes toward risks that are perceived to threaten future generations, which could be effective for other kinds of risks. Therefore, we conducted a randomized controlled trial to examine the message effects for information provision on IT innovations. The study was conducted via an online questionnaire survey in January 2020, before the COVID-19 pandemic, and more than 3,200 samples were collected from respondents aged 20 years or older living in Japan. The treatment groups received basic information supplemented with additional text or additional text and an illustration that highlighted IT innovations as support from previous generations. The control group received only the basic textual information. The effects of the intervention were evaluated by comparing changes in average subjective assessment of IT in the treatment groups with those in the control group. The intervention effect was statistically significant, and the sense of familial support after receiving the intervention messages was significantly increased in the treatment group that viewed the illustration compared with the control group. Additionally, we discuss how each component of the HEXACO personality traits influences responses to the intervention messages. Through a series of surveys, we demonstrated the potential of our framework for a wide variety of applications involving information provision perceived to involve future generations. © 2023 Komatsu et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Introduction Sarcoidosis is a rare systemic inflammatory granulomatous disease of unknown cause. It can manifest in any organ. The incidence of sarcoidosis varies across countries, and by ethnicity and gender. Delays in the diagnosis of sarcoidosis can lead to extension of the disease and organ impairment. Diagnosis delay is attributed in part to the lack of a single diagnostic test or unified commonly used diagnostic criteria, and to the diversity of disease manifestations and symptom load. There is a paucity of evidence examining the determinants of diagnostic delay in sarcoidosis and the experiences of people with sarcoidosis related to delayed diagnosis. We aim to systematically review available evidence about diagnostic delay in sarcoidosis to elucidate the factors associated with diagnostic delay for this disease in different contexts and settings, and the consequences for people with sarcoidosis. Methods and analysis A systematic search of the literature will be conducted using PubMed/Medline, Scopus, and ProQuest databases, and sources of grey literature, up to 25th of May 2022, with no limitations on publication date. We will include all study types (qualitative, quantitative, and mixed methods) except review articles, examining diagnostic delay, incorrect diagnosis, missed diagnosis or slow diagnosis of all types of sarcoidosis across all age groups. We will also examine evidence of patients' experiences associated with diagnostic delay. Only studies in English, German and Indonesian will be included. The outcomes we examine will be diagnostic delay time, patients' experiences, and factors associated with diagnostic delay in sarcoidosis. Two people will independently screen the titles and abstracts of search results, and then the remaining full-text documents against the inclusion criteria. Disagreements will be resolved with a third reviewer until consensus is reached. Selected studies will be appraised using the Mixed Methods Appraisal Tool (MMAT). A meta-analysis and subgroup analyses of quantitative data will be conducted. Meta-aggregation methods will be used to analyse qualitative data. If there is insufficient data for these analyses, a narrative synthesis will be conducted. Discussion This review will provide systematic and integrated evidence on the diagnostic delay, associated factors, and experiences of diagnosis delay among people with all types of sarcoidosis. This knowledge may shed light on ways to improve diagnosis delays in diagnosis across different subpopulations, and with different disease presentations. Ethics and dissemination Ethical approval will not be required as no human recruitment or participation will be involved. Findings of the study will be disseminated through publications in peer-reviewed journals, conferences, and symposia.  © 2023 Namsrai et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"The gut microbiota has been immensely studied over the past years because of its involvement in the pathogenesis of numerous diseases. However, gut microbiota data in Africa are limited. Therefore, it is crucial to have studies that reflect various populations in order to fully capture global microbial diversity. In the proposed scoping review, we will describe the gut microbiota’s appearance in terms of gut microbiota markers, in both health and disease in African populations. Relevant publications will be searched for in the PubMed, Scopus, Web of Science, Academic Search Premier, Africa-Wide Information, African journals online, CINAHL, and EBSCOhost and Embase databases. We will focus on articles published between January 2005 and March 2023. We will also determine if the studies to be included in the review would provide enough data to identify quantifiable gut microbiome traits that could be used as health or disease markers, identify the types of diseases that were mostly focused on in relation to gut microbiota research in Africa, as well as to discover and analyze knowledge gaps in the gut microbiota research field in the continent. We will include studies involving African countries regardless of race, gender, age, health status, disease type, study design, or care setting. Two reviewers will conduct a literature search and screen the titles/abstracts against the eligibility criteria. The reviewers will subsequently screen full-text articles and identify studies that meet the inclusion criteria. This will be followed by charting the data using a charting tool and analysis of the evidence. The proposed scoping review will follow a qualitative approach such that a narrative summary will accompany the tabulated/graphical results which will describe how the results relate to the review objectives and questions. As a result, this review may play a significant role in the identification of microbiota-related adjunctive therapies in the African region where multiple comorbidities coexist. Scoping review registration: Open Science Framework. © 2022 by the authors.",TestAnalysis
"Academic societies and funding bodies that conduct peer reviews need to select the best reviewers in each field to ensure publication quality. Conventional approaches for reviewer selection focus on evaluating expertise based on research relevance by subject or discipline. An improved perceiving conflict of interest (CoI) reviewer recommendation process that combines the five expertise indices and graph analysis techniques is proposed in this paper. This approach collects metadata from the academic database and extracts candidates based on research field similarities utilizing text mining; then, the candidate scores are calculated and ranked through a professionalism index-based analysis. The highly connected subgraphs (HCS) algorithm is used to cluster similar researchers based on their association or intimacy in the researcher network. The proposed method is evaluated using root mean square error (RMSE) indicators for matching the field of publication and research fields of the recommended experts using keywords of papers published in Korean journals over the past five years. The results show that the system configures a group of Top-K reviewers with an RMSE 0.76. The proposed method can be applied to the academic society and national research management system to realize fair and efficient screening and management. © 2023 by the authors.",TestAnalysis
"Knowledge graph technology has distinct advantages in terms of fault diagnosis. In this study, the control rod drive mechanism (CRDM) of the liquid fuel thorium molten salt reactor (TMSR-LF1) was taken as the research object, and a fault diagnosis system was proposed based on knowledge graph. The subject–relation–object triples are defined based on CRDM unstructured data, including design specification, operation and maintenance manual, alarm list, and other forms of expert experience. In this study, we constructed a fault event ontology model to label the entity and relationship involved in the corpus of CRDM fault events. A three-layer robustly optimized bidirectional encoder representation from transformers (RBT3) pre-training approach combined with a text convolutional neural network (TextCNN) was introduced to facilitate the application of the constructed CRDM fault diagnosis graph database for fault query. The RBT3-TextCNN model along with the Jieba tool is proposed for extracting entities and recognizing the fault query intent simultaneously. Experiments on the dataset collected from TMSR-LF1 CRDM fault diagnosis unstructured data demonstrate that this model has the potential to improve the effect of intent recognition and entity extraction. Additionally, a fault alarm monitoring module was developed based on WebSocket protocol to deliver detailed information about the appeared fault to the operator automatically. Furthermore, the Bayesian inference method combined with the variable elimination algorithm was proposed to enable the development of a relatively intelligent and reliable fault diagnosis system. Finally, a CRDM fault diagnosis Web interface integrated with graph data visualization was constructed, making the CRDM fault diagnosis process intuitive and effective. © 2023, The Author(s), under exclusive licence to China Science Publishing & Media Ltd. (Science Press), Shanghai Institute of Applied Physics, the Chinese Academy of Sciences, Chinese Nuclear Society.",TestAnalysis
"One important application of natural language processing (NLP) is the recognition of emotions in text. Most current emotion analyzers use a set of linguistic features such as emotion lexicons, n-grams, word embeddings, and emoticons. This study proposes a new strategy to perform emotion recognition, which is based on the homologous structure of emotions and narratives. It is argued that emotions and narratives share both a goal-based structure and an evaluation structure. The new strategy was tested in an empirical study with 117 participants who recounted two narratives about their past emotional experiences, including one positive and one negative episode. Immediately after narrating each episode, the participants reported their current affective state using the Affect Grid. The goal-based structure and evaluation structure of the narratives were analyzed with a hybrid method. First, a linguistic analysis of the texts was carried out, including tokenization, lemmatization, part-of-speech tagging, and morphological analysis. Second, an extensive set of rule-based algorithms was used to analyze the goal-based structure of, and evaluations in, the narratives. Third, the output was fed into machine learning classifiers of narrative structural features that previously proved to be effective predictors of the narrator’s current affective state. This hybrid procedure yielded a high average F1 score (0.72). The results are discussed in terms of the benefits of employing narrative structure analysis in NLP-based emotion recognition. © 2023 by the authors.",TestAnalysis
"Deep learning has improved the state-of-the-art in sentiment analysis for various languages, including Arabic. One aspect that can affect the performance of deep learning-based sentiment classification is the optimization method used for training the neural network. The conventional optimization method is carried out by a backpropagation (BP) algorithm that relies on gradient descent to find the minimum of a cost function. However, BP has the tendency to converge into local minima instead of global minima since neural networks generate complex error surfaces for even simple problems. In this study, for the purpose of improving the Arabic sentiment classification, we propose to use a genetic algorithm (GA) to train a deep neural network (DNN). GA is a meta-heuristic optimization algorithm inspired by the theory of natural evolution. The algorithm is expected to improve the classifier’s performance due to its capability to reach optimal or near-optimal solutions. The proposed method uses Arabic sentiment lexicons to extract various features considering different aspects for text representation. The effectiveness of the proposed method is evaluated by analyzing its performance, versus a DNN trained with BP algorithm. The experimental results show that the proposed method can present better F1-measure of 90.7% for Arabic sentiment classification than traditional BP-based DNN. © 2023 International Information and Engineering Technology Association. All rights reserved.",TestAnalysis
"There is an increasing motivation to implement pharmacist-led screening services in community pharmacies. This study aims to develop tools to support the pharmacist in the context of a diabetes and cardiovascular disease risk assessment service. Our development involved a multistep process using a user-centred approach, including a need assessment phase (14 patients, 17 pharmacists) and a creative design phase, followed by the evaluation of the materials (10 patients, 16 pharmacists). Three following themes covering educational needs emerged from stakeholders’ discussions: “content”, “layout”, and “form”, with three additional themes regarding the practical organisation: “software”, “awareness”, and “referral”. Based on the need assessment, tools for patient education purposes and awareness campaigns were created. During the development, special attention was paid to the writing style and structure with less text and more graphical colourful elements to suit patients with different health literacy and educational levels. The evaluation phase allowed researchers to observe participants engaging with the materials. Overall, participants were satisfied with the tools. The contents were considered valuable and relevant. However, adaptations were necessary to ensure their understanding and long-term usability. Finally, future research is required to evaluate the materials’ impact on patients’ behaviour towards their identified risk factors and ensure their effectiveness. © 2023 by the authors.",TestAnalysis
"Drug abuse is a serious problem in the United States, with over 90,000 drug overdose deaths nationally in 2020. A key step in combating drug abuse is detecting, monitoring, and characterizing its trends over time and location, also known as pharmacovigilance. While federal reporting systems accomplish this to a degree, they often have high latency and incomplete coverage. Social-media-based pharmacovigilance has zero latency, is easily accessible and unfiltered, and benefits from drug users being willing to share their experiences online pseudo-anonymously. However, unlike highly structured official data sources, social media text is rife with misspellings and slang, making automated analysis difficult. Generative Pretrained Transformer 3 (GPT-3) is a large autoregressive language model specialized for few-shot learning that was trained on text from the entire internet. We demonstrate that GPT-3 can be used to generate slang and common misspellings of terms for drugs of abuse. We repeatedly queried GPT-3 for synonyms of drugs of abuse and filtered the generated terms using automated Google searches and cross-references to known drug names. When generated terms for alprazolam were manually labeled, we found that our method produced 269 synonyms for alprazolam, 221 of which were new discoveries not included in an existing drug lexicon for social media. We repeated this process for 98 drugs of abuse, of which 22 are widely-discussed drugs of abuse, building a lexicon of colloquial drug synonyms that can be used for pharmacovigilance on social media. © 2023 by the authors.",TestAnalysis
"A new class of cryptosystems called verifiable encryption (VE) that facilitates the verification of two plaintexts without decryption was proposed in our previous paper. The main contributions of our previous study include the following. (1) Certain cryptosystems such as the one-time pad belong to the VE class. (2) We constructed an authentication algorithm for unlocking local devices via a network that utilizes the property of VE. (3) As a result of implementing the VE-based authentication algorithm using the one-time pad, the encryption, verification, and decryption processing times are less than 1 ms even with a text length of 8192 bits. All the personal information used in the algorithm is protected by Shanon’s perfect secrecy. (4) The robustness of the algorithm against man-in-the-middle attacks and plaintext attacks was discussed. However, the discussion about the security of the algorithm was insufficient from the following two perspectives: (A) its robustness against other theoretical attacks such as ciphertext-only, known-plaintext, chosen-plaintext, adaptive chosen-plaintext, chosen-ciphertext, and adaptive chosen-ciphertext attacks was not discussed; (B) a formal security analysis using security verification tools was not performed. In this paper, we analyze the security of the VE-based authentication algorithm by discussing its robustness against the above theoretical attacks and by validating the algorithm using a security verification tool. These security analyses, show that known attacks are ineffective against the algorithm. © 2023 by the authors.",TestAnalysis
"Artificial intelligence (AI) is the development of computer systems whereby machines can mimic human actions. This is increasingly used as an assistive tool to help clinicians diagnose and treat diseases. Periodontitis is one of the most common diseases worldwide, causing the destruction and loss of the supporting tissues of the teeth. This study aims to assess current literature describing the effect AI has on the diagnosis and epidemiology of this disease. Extensive searches were performed in April 2022, including studies where AI was employed as the independent variable in the assessment, diagnosis, or treatment of patients with periodontitis. A total of 401 articles were identified for abstract screening after duplicates were removed. In total, 293 texts were excluded, leaving 108 for full-text assessment with 50 included for final synthesis. A broad selection of articles was included, with the majority using visual imaging as the input data field, where the mean number of utilised images was 1666 (median 499). There has been a marked increase in the number of studies published in this field over the last decade. However, reporting outcomes remains heterogeneous because of the variety of statistical tests available for analysis. Efforts should be made to standardise methodologies and reporting in order to ensure that meaningful comparisons can be drawn. © 2023 by the authors.",TestAnalysis
"Limited research has evaluated the mental health effects during compounding disasters (e.g., a hurricane occurring during a pandemic), and few studies have examined post-disaster mental health with alternative data sources like crisis text lines. This study examined changes in crisis help-seeking for individuals in Louisiana, USA, before and after Hurricane Ida (2021), a storm that co-occurred during the COVID-19 pandemic. An interrupted time series analysis and difference-in-difference analysis for single and multiple group comparisons were used to examine pre-and post-changes in crisis text volume (i.e., any crisis text, substance use, thoughts of suicide, stress/anxiety, and bereavement) among help-seeking individuals in communities that received US Federal Emergency Management Agency individual and public assistance following a presidential disaster declaration. Results showed a significant increase in crisis texts for any reason, thoughts of suicide, stress/anxiety, and bereavement in the four-week, three-month, and four-month post-impact period. Findings highlight the need for more mental health support for residents directly impacted by disasters like Hurricane Ida. © 2023 The Authors. GeoHealth published by Wiley Periodicals LLC on behalf of American Geophysical Union.",TestAnalysis
"In the last decade’s media discourse, particular Arab immigrant groups received the name ‘Arab clans’ and have been portrayed as criminal kinship networks irrespective of actual involvement in crime. We question how ‘Arab clans’ are categorized, criminalized, and racialized in the German media. To answer this question, we collected clan-related mainstream media articles published between 2010 and 2020. Our first-step quantitative topic modeling of ‘clan’ coverage (n = 23,893) shows that the discourse about ‘Arab clans’ is situated as the most racialized and criminalized vis-à-vis other ‘clan’ discourses and is channeled through three macro topics: law and order, family and kinship, and criminal groupness. Second, to explore the deeper meaning of the discourse about ‘Arab clans’ by juxtaposing corpus linguistics and novel narrative approaches to the discourse-historical approach, we qualitatively analyzed 97 text passages extracted with the keywords in context search (KWIC). Our analysis reveals three prevalent argumentative strategies (Arab clan immigration out of control, Arab clans as enclaves, policing Arab clans) embedded in a media narrative of ethnonational rebirth: a story of Germany’s present-day need (‘moral panic’) to police and repel the threats associated with ‘the Arab clan Other’ in order for a celebratory return to a nostalgically idealized pre-Arab-immigration social/moral order. © 2023 by the authors.",TestAnalysis
"The act of lying and its detection have raised interest in many fields, from the legal system to our daily lives. Considering that testimonies are commonly based on linguistic parameters, natural language processing, a research field concerned with programming computers to process and analyse natural language texts or speech, is a topic of interest on this front. This study aimed to examine the linguistic styles of simulated deception and true testimonies collected with the aim of studying witness memory. Study participants were asked to act as a witness of a crime by retelling the story they had just read. Cognitive interviewing techniques were used to collect testimony under two conditions: truth and simulated deception. A sample of 48 participants volunteered to participate in the study. Analyses of the linguistic indicators and content were carried out. Specifically, we performed a comparison of testimonies of the same participant by condition to analyse the variation between (i) lexical and (ii) linguistic features and (iii) content and speech characteristics (disfluencies) depending on the narrative condition. Concerning lexical properties, adjectives were the most-varying grammatical category between truthful and deceptive testimonies. Furthermore, in the linguistic analysis, we observed that truthful testimonies were generally longer than deceptive ones in terms of the number of words and sentences and also characterised by more articulated sentence structures, and these differences were also statistically significant. Regarding the analysis of the content, cognitive criteria (details) and admitting lack of memory were more present in truthful statements. By providing an objective measure, these results are of interest in developing NLP tools for assessing the credibility of testimonies in forensics. © 2023 by the authors.",TestAnalysis
"Background: People with chronic illnesses have increased morbidity and mortality associated with COVID-19 infection. The influence of a person’s serious and/or comorbid chronic illness on COVID-19 vaccine uptake is not well understood. Aim: To undertake an in-depth exploration of factors influencing COVID-19 vaccine uptake among those with various serious and/or chronic diseases in the Australian context, using secondary data analysis of a survey study. Methods: Adults with cancer, diabetes and multiple sclerosis (MS) were recruited from 10 Australian health services to undertake a cross-sectional online survey (30 June to 5 October 2021) about COVID-19 vaccine uptake, vaccine hesitancy, confidence and complacency and disease-related decision-making impact. Free-text responses were invited regarding thoughts and feelings about the interaction between the participant’s disease, COVID-19, and vaccination. Qualitative thematic analysis was undertaken using an iterative process and representative verbatim quotes were chosen to illustrate the themes. Results: Of 4683 survey responses (cancer 3560, diabetes 842, and MS 281), 1604 (34.3%) included free-text comments for qualitative analysis. Participants who provided these were significantly less likely to have received a COVID-19 vaccination than those who did not comment (72.4% and 86.2%, respectively). People with diabetes were significantly less likely to provide free-text comments than those with cancer or MS (29.0%, 35.1% and 39.9%, respectively). Four key themes were identified from qualitative analysis, which were similar across disease states: (1) having a chronic disease heightened perceived susceptibility to and perceived severity of COVID-19; (2) perceived impact of vaccination on chronic disease management and disease-related safety; (3) uncertain benefits of COVID-19 vaccine; and (4) overwhelming information overload disempowering patients. Conclusions: This qualitative analysis highlights an additional layer of complexity related to COVID-19 vaccination decision making in people with underlying health conditions. Appreciation of higher susceptibility to severe COVID-19 outcomes appears to be weighed against uncertain impacts of the vaccine on the progression and management of the comorbid disease. Interactions by clinicians addressing individual factors may alleviate concerns and maximise vaccine uptake in people with significant underlying health conditions. © 2023 by the authors.",TestAnalysis
"The relationship between human rights and Islam is important in countries of the Arab world where religion plays a significant role in public debates and daily life. The topic is particularly relevant at a time of sharpening conflicts and polarization, when forms of government in the region, the current world order, and the legitimacy of international organizations are increasingly contested. Much of the scholarly work published in English on this topic draws on sources available in English. This review, therefore, aims to make a contribution to the field through analysis and discussion of academic papers published in Arabic. A search was made in Google Scholar in April 2022 which yielded 12 publications published in 2020 and 2021, after inclusion and exclusion criteria had been applied. These publications were analyzed drawing on the four framing categories. A summary is also given of the definitions, sources, and premises on which the arguments of the publications draw. The reviewed papers contrast the universal and divine foundation of Islamic human rights with the limitations of modern conceptualizations based on the Universal Declaration of Human Rights (UDHR). The latter is described as emanating from Western hegemonistic aspirations and as detached from moral and spiritual values. The papers consequently argue that human rights would be guaranteed globally by generalizing a system of governance based on Shari’a law and the ideal of the Rightly Guided Caliphs. Little attention is given to human rights abuses observed in Muslim societies, diverse interpretations of Islamic source texts, or concrete measures to improve human rights protections in practice. Importantly, the arguments presented in these papers tend to reinforce a contemporary discourse that frames conflicting visions on human rights as a ‘clash of civilisations’ between ‘Islam’ and ‘the West’. © 2023 by the authors.",TestAnalysis
"The financial business process worldwide suffers from huge dependencies upon labor and written documents, thus making it tedious and time-consuming. In order to solve this problem, traditional robotic process automation (RPA) has recently been developed into a hyper-automation solution by combining computer vision (CV) and natural language processing (NLP) methods. These solutions are capable of image analysis, such as key information extraction and document classification. However, they could improve on text-rich document images and require much training data for processing multilingual documents. This study proposes a multimodal approach-based intelligent document processing framework that combines a pre-trained deep learning model with traditional RPA used in banks to automate business processes from real-world financial document images. The proposed framework can perform classification and key information extraction on a small amount of training data and analyze multilingual documents. In order to evaluate the effectiveness of the proposed framework, extensive experiments were conducted using Korean financial document images. The experimental results show the superiority of the multimodal approach for understanding financial documents and demonstrate that adequate labeling can improve performance by up to about 15%. © 2023 by the authors.",TestAnalysis
"Based on Kevin Lynch’s cognitive method of urban image and Weibo’s review data, this study constructs a research framework with three modules as the core: city image structure, city image types, and cultural service evaluation. First, the geospatial information carried by comments is analyzed by GIS to obtain the image structure of the city; second, the picture data in the comments are divided into image types and the type ratio is calculated by the image semantic segmentation method based on deep full convolution neural network. Finally, the text data in the comments are extracted from the semantic word frequency analysis to evaluate the cultural service perception index words of the city image and combined with the analysis of the city image structure and the city image type so as to obtain the integrated comprehensive perception of the city image. The research shows that the introduction of big data and deep learning methods into city image research can make up for the shortcomings of traditional research samples, expand the dimension and breadth of urban cognition, reveal the social, cultural, and functional characteristics of the city, and is an important supplement to the five-element model of city image depicting the material form of the city. In addition, the results of the empirical study, taking Zhongshan City as an example, have implications for the realistic urban spatial planning, urban landscape design, and tourism industry layout of Zhongshan. © 2023 by the authors.",TestAnalysis
"Venous leg ulcer treatment is frequently discontinued in hospitals in contravention of national guidance, significantly affecting patient outcomes and increasing NHS costs. Aim: To identify, from the published literature, reasons for variable implementation. Method: Systematic review with narrative synthesis, including full papers in English with empirical qualitative data. Synonyms for venous leg ulcer, compression therapy and secondary care were searched across a range of health-related databases. The Critical Appraisal Skills Programme (CASP) checklist determined study quality, and meta-ethnography was used for data synthesis. Results: 7040 titles and abstracts and 41 full-text papers were screened with four papers selected. Three key themes were generated: educational needs surrounding implementation of compression therapy, patient factors regarding adherence and organisational resources including availability of appropriate equipment and trained staff. Conclusion: Barriers at the ward level were identified. There is a need to better understand why hospitals are not addressing them. © 2023 MA Healthcare Ltd. All rights reserved.",TestAnalysis
"Tour planning has become both challenging and time-consuming due to the huge amount of information available online and the variety of options to choose from. This is more so as each traveler has unique set of interests and location preferences in addition to other tour-based constraints such as vaccination status and pandemic travel restrictions. Several travel planning companies and agencies have emerged with more sophisticated online services to capitalize on global tourism effectively by using technology for making suitable recommendations to travel seekers. However, such systems predominantly adopt a destination-based recommendation approach and often come as bundled packages with limited customization options for incorporating each traveler’s preferences. To address these limitations, “thematic travel planning” has emerged as a recent alternative with researchers adopting text-based data mining for achieving value-added online tourism services. Understanding the need for a more holistic theme approach in this domain, our aim is to propose an augmented model to integrate analytics of a variety of big data (both static and dynamic). Our unique inclusive model covers text mining and data mining of destination images, reviews on tourist activities, weather forecasts, and recent events via social media for generating more user-centric and location-based thematic recommendations efficiently. In this paper, we describe an implementation of our proposed inclusive hybrid recommendation model that uses data of multimodal ranking of user preferences. Furthermore, in this study, we present an experimental evaluation of our model’s effectiveness. We present the details of our improvised model that employs various statistical and machine learning techniques on existing data available online, such as travel forums and social media reviews in order to arrive at the most relevant and suitable travel recommendations. Our hybrid recommender built using various Spark models such as naïve Bayes classifier, trigonometric functions, deep learning convolutional neural network (CNN), time series, and NLP with sentiment scores using AFINN (sentiment analysis developed by Finn Årup Nielsen) shows promising results in the directions of benefit for an individual model’s complementary advantages. Overall, our proposed hybrid recommendation algorithm serves as an active learner of user preferences and ranking by collecting explicit information via the system and uses such rich information to make personalized augmented recommendations according to the unique preferences of travelers. © 2023 by the authors.",TestAnalysis
"Enzyme inhibitors are frequently used to treat viral illnesses. Protease inhibitors are a promising class for combating novel and life-threatening viral infections. This research aimed to evaluate the efficacy and safety of lopinavir/ritonavir monotherapy or lopinavir/ritonavir plus interferon for the treatment of COVID-19. The PubMed, Scopus, Web of Science, and Cochrane Library databases were searched for English articles with full texts available online. ReviewManager software was used to conduct a meta-analysis, subgroup analysis, and sensitivity analysis. Following the creation of the protocol, the collected sources were sorted into categories and evaluated for quality. Risk and hazard ratios and the random effects model were implemented, with statistical heterogeneity assigned using the Higgins I2 statistic. Lopinavir/ritonavir, with or without interferon, was associated with a nonsignificant higher mortality rate (odds ratio [OR] 1.29; 95% confidence interval [CI] 0.95 to 1.761; p = 0.1), as was clinical improvement (OR 1.2; 95% CI 0.8 to 1.84; p = 0.36). The difference in the length of hospital stay was in favor of the control group but statistically insignificant (standardized mean difference [SMD] 0.07; 95% CI −0.44 to 0.57; p = 0.79). The pooled data showed that lopinavir/ritonavir, with or without interferon, was associated with a significantly higher number of adverse events than placebo (OR 1.2; 95% CI 1.09 to 2.34; p = 0.02). Serious adverse events were insignificantly increased in the treated group over the control group (OR 1.2; 95% CI 0.96 to 2.12; p = 0.08). In the subgroup analysis, it was found that interferon used with lopinavir/ritonavir did not have a statistically significant effect on mortality rates (OR 1.75; 95% CI 0.87 to 3.55; p = 0.37), adverse effects (OR 1.20; 95% CI 0.75 to 1.91; p = 0.27), or serious adverse effects (OR 1.86; 95% CI 1.17 to 2.96; p = 0.33). Treatment with lopinavir/ritonavir alone or in combination with interferon for COVID-19 did not significantly outperform placebo in this study. Large randomized clinical trials are required to evaluate lopinavir/ritonavir in conjunction with interferon for the treatment of COVID-19. Such studies would benefit greatly from being conducted in a double-blind fashion at multiple locations. © 2023 by the authors.",TestAnalysis
"A figurative language expression known as sarcasm implies the complete contrast of what is being stated with what is meant, with the latter usually being rather or extremely offensive, meant to offend or humiliate someone. In routine conversations on social media websites, sarcasm is frequently utilized. Sentiment analysis procedures are prone to errors because sarcasm can change a statement’s meaning. Analytic accuracy apprehension has increased as automatic social networking analysis tools have grown. According to preliminary studies, the accuracy of computerized sentiment analysis has been dramatically decreased by sarcastic remarks alone. Sarcastic expressions also affect automatic false news identification and cause false positives. Because sarcastic comments are inherently ambiguous, identifying sarcasm may be difficult. Different individual NLP strategies have been proposed in the past. However, each methodology has text contexts and vicinity restrictions. The methods are unable to manage various kinds of content. This study suggests a unique ensemble approach based on text embedding that includes fuzzy evolutionary logic at the top layer. This approach involves applying fuzzy logic to ensemble embeddings from the Word2Vec, GloVe, and BERT models before making the final classification. The three models’ weights assigned to the probability are used to categorize objects using the fuzzy layer. The suggested model was validated on the following social media datasets: the Headlines dataset, the “Self-Annotated Reddit Corpus” (SARC), and the Twitter app dataset. Accuracies of 90.81%, 85.38%, and 86.80%, respectively, were achieved. The accuracy metrics were more accurate than those of earlier state-of-the-art models. © 2023 by the authors.",TestAnalysis
"Background: Mindfulness-based interventions have been shown to be efficacious for reducing psychological distress and mental health symptoms and promoting well-being, including during pregnancy and postpartum. There is promising, though limited, evidence showing that interventions that focus on improving the mother-infant relationship are associated with improvements in both the mother-infant relationship and maternal mental health symptoms. The current study examines the effects of a prenatal mindfulness-based, reflective intervention designed to enhance maternal-fetal bonding on pregnancy-related distress and prenatal depressive symptoms. Methods: Out of a larger sample of 130 pregnant women in their second trimester, 15 women were recruited to participate in a 2-week long mindfulness-based, reflective intervention with daily short (<5-minute) activities. Multiple linear regression analyses were conducted to examine associations between the intervention and pregnancy-related distress and depression during the third trimester of pregnancy, controlling for race, age, education, union status, and first trimester depressive symptoms. Results: Results indicate that women who participated in the intervention during their second trimester reported lower pregnancy-related distress in their third trimester but no differences in depressive symptoms. Conclusions: A brief, mindfulness-based intervention delivered during pregnancy via cellphone texts can be a useful tool to reduce maternal distress related to pregnancy. Additional reflective exercises that address mood and global stress, as well as increasing the amount and/or frequency of the intervention, may be important for promoting maternal mental health more globally. © Lucia Ciciolla et al., 2023;",TestAnalysis
"The emergency response ability of police officers is a critical component of their career, and is also an important support for public security. However, few researchers have focused on the factors that influence emergency response ability, especially in the group of novice policemen. On the other hand, as the popular way to train emergency response ability, case-based instruction (CBI) generates various types of data, especially valuable text data; however, such text data is always ignored because of the lack of effective analysis methods. Therefore, this study employed automatic semantic analysis and hierarchical linear regression models to investigate the factors influencing the emergency response ability of novice policemen in the process of CBI. Results indicated that, among personal differences, prior knowledge, and basic professional skills, the latter showed stronger predictive validity than the others. In particular, information processing and judgment, command and decision, and order maintenance were the main indicators. This study also illustrated that automatic semantic analysis can effectively identify deep value from semantic data, which will support stakeholders to design strategies, make decisions, conduct evaluations in training and instructions, and ultimately help sustainable development in human careers. © 2023 by the authors.",TestAnalysis
"The objective of this systematic review was to analyze the recently published literature on the Internet of Robotic Things (IoRT) and integrate the insights it articulates on big data management algorithms, deep learning-based object detection technologies, and geospatial simulation and sensor fusion tools. The research problems were whether computer vision techniques, geospatial data mining, simulation-based digital twins, and real-time monitoring technology optimize remote sensing robots. Preferred Reporting Items for Systematic Reviews and Meta-analysis (PRISMA) guidelines were leveraged by a Shiny app to obtain the flow diagram comprising evidence-based collected and managed data (the search results and screening procedures). Throughout January and July 2022, a quantitative literature review of ProQuest, Scopus, and the Web of Science databases was performed, with search terms comprising “Internet of Robotic Things” + “big data management algorithms”, “deep learning-based object detection technologies”, and “geospatial simulation and sensor fusion tools”. As the analyzed research was published between 2017 and 2022, only 379 sources fulfilled the eligibility standards. A total of 105, chiefly empirical, sources have been selected after removing full-text papers that were out of scope, did not have sufficient details, or had limited rigor For screening and quality evaluation so as to attain sound outcomes and correlations, we deployed AMSTAR (Assessing the Methodological Quality of Systematic Reviews), AXIS (Appraisal tool for Cross-Sectional Studies), MMAT (Mixed Methods Appraisal Tool), and ROBIS (to assess bias risk in systematic reviews). Dimensions was leveraged as regards initial bibliometric mapping (data visualization) and VOSviewer was harnessed in terms of layout algorithms. © 2023 by the authors.",TestAnalysis
"Background: ""Breast awareness""is a recommendation that women understand the symptoms of breast cancer and become familiar with the usual look and feel of their breasts. It is recommended for women of all ages in breast cancer screening guidelines around the world. The objective of this study was to assess the evidence for breast awareness by investigating its effect on breast cancer outcomes in women of pre-mammographic-screening age (under age 40), at average risk of breast cancer. Methods: A systematic review was performed using PRISMA methodology. Following the search, abstracts and full-text articles were assessed against eligibility criteria. Data were extracted into evidence tables, risk of bias was assessed, narrative synthesis was performed, and results were described. Eligible studies were original research studies assessing the impact of breast awareness on cancer outcomes (such as stage at diagnosis or survival) in women ≤40. Medline, PubMed, and Cochrane Library were searched. Results: After screening the 6,204 abstracts identified in the search, no studies meeting all eligibility criteria were found. Two partially eligible studies were identified. These met the intervention and outcomes criteria but included mixed-age cohorts that included but were not limited to women ≤40. These studies provided low-level (Level IV) evidence of moderate quality that there is some benefit (earlier stage at diagnosis and/or improved survival) of breast awareness in a mixed-age cohort that included some younger women. Conclusions: No studies evaluating the impact of breast awareness exclusively in young women were identified. Limited evidence of benefit of breast awareness was found. Guidelines that recommend breast awareness should be reviewed and qualified with an explanation that the evidence of benefit is weak. Women have limited screening options available to them for the early detection of breast cancer until they reach mammographic screening age. The study was registered on Prospero (ID: CRD42021279457).  © 2023 S. Karger AG. All rights reserved.",TestAnalysis
"Purpose: Crowdfunding campaigns are a way to secure capital for organizations, entrepreneurs, artists, and more. Little research has focused on stylistic aspects of text associated with successful campaigns. Method: We used corpus analysis to analyze the text of 312,529 Kickstarter campaigns. We used a novel scoring method to compute how often verbs and words surrounding verbs were associated with success or failure. We then identified prominent stylistic aspects of text that were often included in successful and unsuccessful campaigns. Results: Stylistic elements strongly associated with success included using we instead of I, using contractions instead of full forms of verbs, inviting the reader to join the project and receive rewards, and projecting confidence via will instead of the more uncertain would. Conclusion: Stylistic findings interact. Specifically, using we and contractions together indicates outcomes strongly associated with success. Broadly, each of the findings point toward creators of campaigns attempting to build trust in the readers. The elements of this emergent style work together toward a goal of producing campaign text that describes a campaign readers accept and trust as likely to succeed. © 2023, Society for Technical Communication. All rights reserved.",TestAnalysis
"In modern biology and medicine, drug-drug similarity is a major task with various applications in pharmaceutical drug development. Various direct and indirect sources of evidence obtained from drug-centric data such as side effects, drug interactions, biological targets, and chemical structures are used in the current methods to measure the level of drug-drug similarity. This paper proposes a computational method to measure drug-drug similarity using a novel source of evidence that is obtained from patient-centric data. More specifically, patients’ narration of their thoughts, opinions, and experience with drugs in social media are explored as a potential source to compute drug-drug similarity. Online healthcare communities were used to extract a dataset of patients’ reviews on anti-epileptic drugs. The collected dataset is preprocessed through Natural Language Processing (NLP) techniques and four text similarity methods are applied to measure the similarities among them. The obtained similarities are then used to generate drug-drug similarity-based ranking matrices which are analyzed through Pearson correlation, to answer questions related to the overall drug-drug similarity and the accuracy of the four similarity measures. To evaluate the obtained drug-drug similarities, they are compared with the corresponding ground-truth similarities obtained from DrugSimDB, a well-known drug-drug similarity tool that is based on drug-centric data. The results provide evidence on the feasibility of patient-centric data from social media as a novel source for computing drug-drug similarity. © 2023 by the author.",TestAnalysis
"Background: Prediabetes has become a worldwide health problem. Multiple clinical trials have been conducted to determine the potential benefits of vitamin D supplementation in preventing the conversion to diabetes, but the results are inconsistent. The aims of this study were to evaluate the current knowledge and to suggest recommendations for researchers on designing future trials regarding that matter. Methods: Four databases were searched for randomized control trials from the last 10 years about vitamin D and insulin resistance. The systematic electronic literature search identified 2645 studies, of which thirty-eight qualified for full-text reading and discussion. Finally, eight trials were included. Results: Final results of seven trials reported that supplementation of vitamin D does not reduce insulin resistance nor reduces the risk of diabetes mellitus type 2 development in prediabetes. Only one trial showed improvements in fasting glucose and HOMA-IR. Conclusions: Due to the great variation and biases in study designs, an unambiguous interpretation of the results is not possible. To eliminate those vulnerabilities in the future, we made certain suggestions for study design. Long-term and well-designed studies are still required. © 2023 by the authors.",TestAnalysis
"The number of homeless people at airports has increased in recent years. As airports are safe, transit-accessible, convenient, and climate-controlled facilities with food and amenities, these places are attractive to homeless people who need a safe and secure place to stay. The main struggle of airports in this regard is maintaining a balance between customers, who are mostly the traveling public, and dealing with homeless people delicately. Moreover, because of their poverty and insufficient or no access to healthcare, these people suffer from physical and mental issues. With the COVID-19 pandemic, this problem became more critical. Many news media outlets started to report on homelessness at airports. News-framing impacts have some contribution in the context of this issue. However, the impact of news coverage on ‘‘airport and homelessness’’ has not yet been studied. News-framing effects have been identified in the context of tourist destinations. Although many studies have explored homelessness and transit, this issue at airports has not been well studied. This study provides a brief overview of the issue of homelessness in the transportation domain, including transit and aviation. Additionally, this study collected news articles related to ‘‘airport and homelessness’’ (71 articles) both during the COVID-19 pandemic (March 1, 2020–July 21, 2021) and before the pandemic (before March 1, 2020). These news articles contain around 50,000 words. As the data is unsupervised in nature, a text network analysis was performed to determine the latent information from these textual contents. The findings of this study can shed some light on this scientifically unexplored but widely discussed issue. © National Academy of Sciences: Transportation Research Board 2022.",TestAnalysis
"The aim of this study was to conduct a systematic literature review with a subsequent meta-analysis on the technical complications and failures of removable partial denture (RPD) therapy in the moderately reduced dentition. A systematic literature search of established medical databases, last updated 06/2022, was conducted. RCTs and prospective and retrospective studies were included that had information on technical complications and failures of RPDs, at least 15 participants, an observation period of at least two years and a drop-out rate of less than 25%. Publications were selected on the title, abstract and full-text level by at least three of the participating authors. The evidence of the included studies was classified using the GRADE system. The bias risk was determined using the RoB2 tool and the ROBINS-I tool. Of 19,592 initial hits, 43 publications were included. Predominantly, retention of the prosthesis, retention loss of anchor crowns (decementations), fractures/repairs of frameworks, denture teeth, veneering or acrylic bases, and a need for relining were reported depending on prosthesis type and observation time. Focusing on technical complications and failures, only very heterogeneous data were found and publications with the highest quality level according to GRADE were scarce. Whenever possible, data on technical complications and failures should be reported separately when referencing the tooth, the prosthesis and the patient for comparability. Prostheses with differing anchorage types should be analyzed in different groups, as the respective complications and failures differ. A precise description of the kinds of complications and failures, as well as of the resulting follow-up treatment measures, should be given. © 2023 by the authors.",TestAnalysis
"Introduction: Evidence on the use of brachytherapy in soft-tissue sarcoma (STS) is sparse. Therapy regimens are determined more by local interdisciplinary tumor conferences than by standardized protocols. Patient-specific factors complicate the standardized application of therapy protocols. The individuality of the treatment makes it difficult to compare results. Materials and Methods: A comprehensive literature search was conducted, whereby the literature from a period of almost 44 years (1977–2021) was graded and included in this systematic review. For this purpose, PubMed was used as the primary database. Search string included “soft-tissue sarcoma”, “brachytherapy”, and “extremity.” Four independent researchers reviewed the literature. Only full-text articles written in English or German were included. Results: Of the 175 identified studies, 70 were eligible for analysis based on the inclusion and exclusion criteria. The key points to compare were local complications, recurrence rate and correlation with margins of resection, and the use of brachytherapy regarding tumor grading. Conclusion: Brachytherapy represents an important subset of radiotherapy techniques used in STSs, whose indications and applications are constantly evolving, and for which a local control rate of 50% to 96% has been reported as monotherapy, depending on risk factors. However, the best benefit is seen in the combination of further resection and brachytherapy, and most authors at many other centers agree with this treatment strategy. © 2023 by the authors.",TestAnalysis
"Monkeypox is a rare disease caused by the monkeypox virus. This disease was considered eradicated in 1980 and was believed to affect rodents and not humans. However, recent years have seen a massive outbreak of monkeypox in humans, setting off worldwide alerts from health agencies. As of September 2022, the number of confirmed cases in Peru had reached 1964. Although most monkeypox patients have been discharged, we cannot neglect the monitoring of the population with respect to the monkeypox virus. Lately, the population has started to express their feelings and opinions through social media, specifically Twitter, as it is the most used social medium and is an ideal space to gather what people think about the monkeypox virus. The information imparted through this medium can be in different formats, such as text, videos, images, audio, etc. The objective of this work is to analyze the positive, negative, and neutral feelings of people who publish their opinions on Twitter with the hashtag #Monkeypox. To find out what people think about this disease, a hybrid-based model architecture built on CNN and LSTM was used to determine the prediction accuracy. The prediction result obtained from the total monkeypox data was 83% accurate. Other performance metrics were also used to evaluate the model, such as specificity, recall level, and F1 score, representing 99%, 85%, and 88%, respectively. The results also showed the polarity of feelings through the CNN-LSTM confusion matrix, where 45.42% of people expressed neither positive nor negative opinions, while 19.45% expressed negative and fearful feelings about this infectious disease. The results of this work contribute to raising public awareness about the monkeypox virus. © 2023 by the authors.",TestAnalysis
"Starting from the idea of the city as a palimpsest in which the traces of generations are superimposed, the text that follows reflects on the role of landscape and heritage as repositories of collective memory. To do this, after exposing the problem of the chosen case study (the patrimonial legacy of mining in Melilla), it justifies its suitability based on a specific strategic and conceptual framework, placing its starting point in contemporary landscape policies and heritage. Later, it presents a methodology for the analysis of subjective perception, which is complemented with historical and spatial analyses. The objective of this method is to measure how legible a heritage landscape is for the population. One of its main contributions is the transformation of the data from a survey into a cartography that shows the mental model of perception of this landscape for each population group analyzed. Its aim is to work as a diagnostic tool for landscape problems from perception analysis, which can be useful as a basis for proposing specific actions aimed at strengthening the relationship between heritage and its context. © 2023, Universitat Politecnica de Catalunya. All rights reserved.",TestAnalysis
"Urban regeneration by participatory methods is being discussed in many parts of the world, but conflicts between stakeholders emerge as a major challenge. In order to address this problem, a new approach to urban regeneration has been attempted in Korea. By targeting towns with university campuses, this project encourages active participation from university students as well as local residents. As a result of COVID-19 restrictions, the project adopted an online-based communication strategy. First, the online data was collected; second, the data for each participant was classified through data refinement; and third, the data analysis and data visualization were carried out at each stage using program R. The results revealed that the stakeholders exhibited different perceptions about the process, indicating a potential benefit of distinct role division for the success of the multiparty project. The significance of this study lies in the fact that it analyzes participants’ perceptions of urban regeneration using a text-mining process. The results of the study can serve as the basis for minimizing conflict and planning effective urban regeneration. © 2023 by the authors.",TestAnalysis
"Melasma is a challenging chronic skin condition associated with hyperpigmentation and unknown aetiology. This scoping review maps evidence of available treatments and their effectiveness in darker skin types. A comprehensive, systematic online search was conducted in Scopus, PubMed, CINAHL Complete, Cochrane, ScienceDirect, and Web of Science Core Collection. All eligible titles were exported to an EndNote20 library (Clarivate analytics, US). Thematic content analysis was performed to summarise data on current melasma treatments for darker skin types. The quality of included articles was appraised using the Mixed Methods Appraisal Tool (MMAT) 2018 version. A total of 2863 articles were retrieved from the databases, and 10 met the eligibility criteria following abstract and full-text screening. Our findings demonstrate that topical treatments, chemical peels, lasers, and tranexamic acid are common treatment modalities used in darker skin types. Although these treatments may be effective in the short term, they bring about undesirable side effects and sometimes worsen or result in reoccurrences of melasma. Based on the evidence mapped, current treatment modalities are not suitable for darker skin types. There are very few studies conducted on individuals of African descent. Further research is necessary to investigate treatment interventions that may be user-friendly when dealing with darker skin types. © 2023 by the authors.",TestAnalysis
"Objective School nurses are engaging worldwide to promote and protect children's health. Many researchers who examined the effectiveness of the school nurse criticized the inadequate methodology employed in many of the studies. We therefore carried out an evaluation on the effectiveness of school nurses based on a rigorous methodological approach. Methods In this overview of reviews we performed an electronic databank search and global research results on the effectiveness of school nurses were sought. We identified 1,494 records through database search. Abstracts and full texts were screened and summarized using the dual control principle. We summarized the aspects of quality criteria as well as the significance of the effectiveness of the school nurse. In the first step, k = 16 systematic reviews were summarized and evaluated following the AMSTAR-2 guidelines. In a second step, j = 357 primary studies included in these k = 16 reviews were summarized and assessed following the GRADE guidelines. Results Research results on the effectiveness of school nurses show that school nurses play a key role in improving the health of children with asthma (j = 6) and diabetes (j = 2), results on combating obesity are less certain (j = 6). The quality of identified reviews is mostly very low with only six studies of medium quality, of which one identified as a meta-analysis. A total of j = 289 primary studies were identified. Approximately 25% (j = 74) of identified primary studies were either randomized controlled trials (RCT) or observational studies, of which roughly 20% (j = 16) had a low risk of bias. Studies with physiological variables such as blood glucose or asthma labeling led to higher quality results. Conclusion This paper represents an initial contribution and recommends further evaluation of the effectiveness of school nurses, particularly in the areas of mental health or children from low socioeconomic backgrounds. The general lack of quality standards in school nursing research should be integrated into the scientific discourse of school nursing researchers to provide robust evidence for policy planners and researchers.  © 2023 Pawils et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"The aim of the present systematic review is to summarize current knowledge regarding the analysis of biomarkers extracted from peri-implant crevicular fluid (PICF) as predictors of peri-implant bone loss (BL). An electronic search was conducted on three databases, PubMed/MEDLINE, Cochrane Library, and Google Scholar, to find clinical trials published until 1 December 2022 suitable to answer the following focused question: in patients with dental implants, are biomarkers harvested from PICF predictive of peri-implant BL? The initial search yielded a total of 158 entries. After a full-text review and application of the eligibility criteria, the final selection consisted of nine articles. The risk of bias in included studies was assessed using the Joanna Briggs Institute Critical Appraisal tools (JBI). According to the present systematic review, some inflammatory biomarkers harvested from PICF (collagenase-2, collagenase-3, ALP, EA, gelatinase b, NTx, procalcitonin, IL-1β, and several miRNAs) seem to be correlated with peri-implant BL and may assist in the early diagnosis of pathological BL, that characterizes peri-implantitis. MiRNA expression demonstrated a predictive potential of peri-implant BL that could be useful for host-targeted preventive and therapeutic purposes. PICF sampling may represent a promising, noninvasive, and repeatable form of liquid biopsy in implant dentistry. © 2023 by the authors.",TestAnalysis
"Biomedical named entity recognition (BioNER) is a preliminary task for many other tasks, e.g., relation extraction and semantic search. Extracting the text of interest from biomedical documents becomes more demanding as the availability of online data is increasing. Deep learning models have been adopted for biomedical named entity recognition (BioNER) as deep learning has been found very successful in many other tasks. Nevertheless, the complex structure of biomedical text data is still a challenging aspect for deep learning models. Limited annotated biomedical text data make it more difficult to train deep learning models with millions of trainable parameters. The single-task model, which focuses on learning a specific task, has issues in learning complex feature representations from a limited quantity of annotated data. Moreover, manually constructing annotated data is a time-consuming job. It is, therefore, vital to exploit other efficient ways to train deep learning models on the available annotated data. This work enhances the performance of the BioNER task by taking advantage of various knowledge transfer techniques: multitask learning and transfer learning. This work presents two multitask models (MTMs), which learn shared features and task-specific features by implementing the shared and task-specific layers. In addition, the presented trained MTM is also fine-tuned for each specific dataset to tailor it from a general features representation to a specialized features representation. The presented empirical results and statistical analysis from this work illustrate that the proposed techniques enhance significantly the performance of the corresponding single-task model (STM). © 2023 by the authors.",TestAnalysis
"Interest influences adults’ and young learners’ learning in formal and informal contexts. Although interest and interest development frameworks have been used in research on student-learning, they are not used in teacher-focused research, especially as “outcomes” of teacher professional development (PD) activities. In this study, we used interest development as the outcome of PD in computer science (CS) and investigated the factors that influenced teachers’ (n = 5) interest development toward CS using various data sources and analysis methods. We found that interest development is (a) varied, (b) influenced by self-relation, knowledge, and affect, (c) associated with reengagement with PD activities, and (d) it can be captured using computational text analysis methods and online log data. © 2023 by the authors.",TestAnalysis
"Community portraits can deeply explore the characteristics of community structures and describe the personalized knowledge needs of community users, which is of great practical significance for improving community recommendation services, as well as the accuracy of resource push. The current community portraits generally have the problems of weak perception of interest characteristics and low degree of integration of topic information. To resolve this problem, the reader community portrait method based on the thematic and timeliness characteristics of interest labels (UIT) is proposed. First, community opinion leaders are identified based on multi-feature calculations, and then the topic features of their texts are identified based on the LDA topic model. On this basis, a semantic mapping including “reader community-opinion leader-text content” was established. Second, the readers' interest similarity of the labels was dynamically updated, and two kinds of tag parameters were integrated, namely, the intensity of interest labels and the stability of interest labels. Finally, the similarity distance between the opinion leader and the topic of interest was calculated to obtain the dynamic interest set of the opinion leaders. Experimental analysis was conducted on real data from the Douban reading community. The experimental results show that the UIT has the highest average F value (0.551) compared to the state-of-the-art approaches, which indicates that the UIT has better performance in the smooth time dimension. © 2023 KIPS",TestAnalysis
"Background and Aims: Alteration in humans' gut microbiota was reported in patients infected with severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2). The gut and upper respiratory tract (URT) microbiota harbor a dynamic and complex population of microorganisms and have strong interaction with host immune system homeostasis. However, our knowledge about microbiota and its association with SARS-CoV-2 is still limited. We aimed to systematically review the effects of gut microbiota on the SARS-CoV-2 infection and its severity and the impact that SARS-CoV-2 could have on the gut microbiota. Methods: We searched the keywords in the online databases of Web of Science, Scopus, PubMed, and Cochrane on December 31, 2021. After duplicate removal, we performed the screening process in two stages; title/abstract and then full-text screening. The data of the eligible studies were extracted into a pre-designed word table. This study adhered to the PRISMA checklist and Newcastle−Ottawa Scale Bias Assessment tool. Results: Sixty-three publications were included in this review. Our study shows that among COVID-19 patients, particularly moderate to severe cases, the gut and lung microbiota was different compared to healthy individuals. In addition, the severity, and viral load of COVID-19 disease would probably also be influenced by the gut, and lung microbiota's composition. Conclusion: Our study concludes that there was a significant difference in the composition of the URT, and gut microbiota in COVID-19 patients compared to the general healthy individuals, with an increase in opportunistic pathogens. Further, research is needed to investigate the probable bidirectional association of COVID-19 and human microbiome. © 2023 The Authors. Health Science Reports published by Wiley Periodicals LLC.",TestAnalysis
"Digital technologies are being increasingly utilized in healthcare to provide pertinent and timely information for primary prevention, such as vaccination. This study aimed to conduct a systematic review to describe and assess current digital health interventions to promote HPV vaccination among adolescents and parents of adolescents, and to recommend directions for future interventions of this kind. Using appropriate medical subject headings and keywords, we searched multiple databases to identify relevant studies published in English between 1 January 2017 and 31 July 2022. We screened and selected eligible studies for inclusion in the final analysis. We reviewed a total of 24 studies, which included interventions using text messages (4), mobile apps (4), social media and websites (8), digital games (4), and videos (4). The interventions generally improved determinants of HPV vaccination, such as HPV-related knowledge, vaccine-related conversations, and vaccination intentions. In particular, text message and social media interventions targeted improved vaccine uptake behaviors, but little meaningful change was observed. In conclusion, digital health interventions can cost-effectively provide education about HPV vaccination, offer interactive environments to alleviate parental vaccine hesitancy, and ultimately help adolescents engage in HPV vaccine uptake. © 2023 by the authors.",TestAnalysis
"Background: Human papillomavirus (HPV) infection is the most common sexually transmitted viral infection in the world. HPV vaccination adherence rates in men are generally lower than in women. The aim of this systematic review and meta-analysis was to assess adherence to HPV vaccination in young working-age males (18–30 years old). Methods: A systematic review was performed using three databases: PubMed, Scopus, and Web of Science, according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA). Results: After duplicate removal, the initial search resulted in 478 eligible papers. With the exclusion of 425 papers after screening the abstracts, full texts of 53 articles were reviewed. Subsequently, 45 were excluded. Among the eight studies included, four (50%) examined the vaccination adherence in young adults through data registered in nationwide insurance or private companies’ databases, three (37.5%) in young adults in different settings through data collected from surveys and questionnaires, and one (12.5%) an HPV vaccination campaign in a family medicine residency practice. Conclusion: Adherence to HPV vaccination in men of working age (18–30 years) does not appear to be adequate (pooled prevalence 11%). In order to achieve a higher level of compliance, it is important to place an emphasis on vaccination campaigns in schools as well as in the workplace, after consultation with and approval from local, regional, and federal public health agencies. © 2023 by the authors.",TestAnalysis
"Background: Workplace-based assessment (WBA) is a key assessment strategy in competency-based medical education. However, its full potential has not been actualized secondary to concerns with reliability, validity, and accuracy. Frame of reference training (FORT), a rater training technique that helps assessors distinguish between learner performance levels, can improve the accuracy and reliability of WBA, but the effect size is variable. Understanding FORT benefits and challenges help improve this rater training technique. Objective: To explore faculty's perceptions of the benefits and challenges associated with FORT. Methods: Subjects were internal medicine and family medicine physicians (n=41) who participated in a rater training intervention in 2018 consisting of in-person FORT followed by asynchronous online spaced learning. We assessed participants' perceptions of FORT in post-workshop focus groups and an end-of-study survey. Focus groups and survey free text responses were coded using thematic analysis. Results: All subjects participated in 1 of 4 focus groups and completed the survey. Four benefits of FORT were identified: (1) opportunity to apply skills frameworks via deliberate practice; (2) demonstration of the importance of certain evidence-based clinical skills; (3) practice that improved the ability to discriminate between resident skill levels; and (4) highlighting the importance of direct observation and the dangers using proxy information in assessment. Challenges included time constraints and task repetitiveness. Conclusions: Participants believe that FORT training serves multiple purposes, including helping them distinguish between learner skill levels while demonstrating the impact of evidence-based clinical skills and the importance of direct observation.",TestAnalysis
"Physical inactivity and a sedentary lifestyle are risk factors for excess weight and obesity in childhood. It is, therefore, necessary to adopt strategies which can modify these behaviors during childhood, the age at which habits are formed. This study aimed to evaluate the impact of an educational intervention using digital media and face-to-face activities involving children, parents, and the school community on the level of physical activity and sedentary behavior among schoolchildren. This was a secondary analysis of data obtained from a community trial in which students from four primary schools in Mexico City participated. Two schools were assigned to the intervention group (IG) and two to the control group (CG). The intervention lasted 12 months and included a face-to-face component, which involved sessions and workshops for parents and children, as well as visual material for children and a distance component utilizing electronic means (web portal and text messages to mobile phones) for parents. Anthropometric measurements were taken and information was collected on moderate to vigorous physical activity performed by the children and on the time that the schoolchildren spent in front of screens at the beginning of the study and at 6 and 12 months. Information on 201 children from the IG and 167 children from the CG was included in the analysis. At 12 months, the IG showed a mean decrease of 33.4 min/d [95% CI: −53.5 to −13.3] in screen time, while the CG showed an increase of 12.5 min/d [CI 95%: −10.5 to 35.6], p = 0.003. After 12 months of follow-up, applying this educational intervention reduced the time that schoolchildren spent in front of screens. Educational intervention is a feasible and accessible strategy for promoting changes in sedentary behaviors in the school-age population. © 2023 by the authors.",TestAnalysis
"Background Approximately seven to nine percent of couples of reproductive age do not get pregnant despite regular and unprotected sexual intercourse. Various psychosocial interventions for women and men with fertility disorders are repeatedly found in the literature. The effects of these interventions on outcomes such as anxiety and depression, as well as on the probability of pregnancy, do not currently allow for reliable generalisable statements. This review includes studies published since 2015 performing a method-critical evaluation of the studies. Furthermore, we suggest how interventions could be implemented in the future to improve anxiety, depression, and pregnancy rates. Method The project was registered with Prospero (CRD42021242683 13 April 2021). The literature search was conducted according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Six databases were searched and 479 potential studies were discovered. After reviewing the full texts, ten studies were included for the synthesis. Not all studies reported the three outcomes: four studies each for depression, three for anxiety and nine studies for pregnancy rates were included in the meta-analysis, which was conducted using the Comprehensive meta-analysis (CMA) software. Results Psychosocial interventions do not significantly change women’s anxiety (Hedges’ g -0,006; CI: -0,667 to 0,655; p = 0,985), but they have a significant impact on depression in infertile women (Hedges’ g -0,893; CI: -1,644 to -0,145; p = 0,026). Implementations of psychosocial interventions during assisted reproductive technology (ART) treatment do not increase pregnancy rates (odds ratio 1,337; 95% CI 0,983 to 1,820; p = 0,064). The methodological critical evaluation indicates heterogeneous study design and samples. The results of the studies were determined with different methods and make comparability difficult. All these factors do not allow for a uniform conclusion. Methodological critical evaluation Study design (duration and timing of intervention, type of intervention, type of data collection) and samples (age of women, reason for infertility, duration of infertility) are very heterogeneous. The results of the studies were determined with different methods and make comparability difficult. All these factors do not allow for a uniform conclusion. Conclusion In order to be able to better compare psychosocial interventions and their influence on ART treatment and thus also to achieve valid results, a standardised procedure to the mentioned factors is necessary. © 2023 Kremer et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Background: Obesity has become a public health problem in our society and is associated with many diseases, including type 2 diabetes mellitus, cardiovascular diseases, dyslipidemia, respiratory diseases, and cancer. Several studies relate weight loss in obese patients to improved anthropometric measurements and cardiometabolic risk. The objective of our study was to evaluate anthropometric changes, analytical parameters, insulin resistance, fatty liver, and metabolic scales, after a personalized weight loss program, through dietary advice to increase adherence to the Mediterranean diet and a motivational booster via mobile SMS messaging. Methods: Intervention study on a sample of 1964 workers, in which different anthropometric parameters were evaluated before and after dietary intervention: the metabolic score of insulin resistance; non-alcoholic fatty liver disease using different scales; metabolic syndrome; atherogenic dyslipidemia; and the cardiometabolic index. A descriptive analysis of the categorical variables was performed, by calculating the frequency and distribution of the responses for each one. For quantitative variables, the mean and standard deviation were calculated, since they followed a normal distribution. Bivariate association analysis was performed by applying the chi-squared test (corrected by Fisher’s exact statistic when conditions required it) and Student’s t-test for independent samples (for comparison of means). Results: The population subjected to the Mediterranean diet improved in all the variables evaluated at 12 months of follow-up and compliance with the diet. Conclusions: Dietary advice on a Mediterranean diet and its reinforcement with reminder messages through the use of mobile phones may be useful to improve the parameters evaluated in this study and reduce the cardiometabolic risk of patients. © 2023 by the authors.",TestAnalysis
"Background Communicable diseases pose a severe threat to public health and economic growth. The traditional methods that are used for public health surveillance, however, involve many drawbacks, such as being labor intensive to operate and resulting in a lag between data collection and reporting. To effectively address the limitations of these traditional methods and to mitigate the adverse effects of these diseases, a proactive and real-time public health surveillance system is needed. Previous studies have indicated the usefulness of performing text mining on social media. Objective To conduct a systematic review of the literature that used textual content published to social media for the purpose of the surveillance and prediction of communicable diseases. Methodology Broad search queries were formulated and performed in four databases. Both journal articles and conference materials were included. The quality of the studies, operationalized as reliability and validity, was assessed. This qualitative systematic review was guided by the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Results Twenty-three publications were included in this systematic review. All studies reported positive results for using textual social media content to surveille communicable diseases. Most studies used Twitter as a source for these data. Influenza was studied most frequently, while other communicable diseases received far less attention. Journal articles had a higher quality (reliability and validity) than conference papers. However, studies often failed to provide important information about procedures and implementation. Conclusion Text mining of health-related content published on social media can serve as a novel and powerful tool for the automated, real-time, and remote monitoring of public health and for the surveillance and prediction of communicable diseases in particular. This tool can address limitations related to traditional surveillance methods, and it has the potential to supplement traditional methods for public health surveillance. © 2023 Pilipiec et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"The paper deals with the analysis of conversation transcriptions between customers and agents in a call center of a customer care service. The objective is to support the analysis of text transcription of human-to-human conversations, to obtain reports on customer problems and complaints, and on the way an agent has solved them. The aim is to provide customer care service with a high level of efficiency and user satisfaction. To this aim, topic modeling is considered since it facilitates insightful analysis from large documents and datasets, such as a summarization of the main topics and topic characteristics. This paper presents a performance comparison of four topic modeling algorithms: (i) Latent Dirichlet Allocation (LDA); (ii) Non-negative Matrix Factorization (NMF); (iii) Neural-ProdLDA (Neural LDA) and Contextualized Topic Models (CTM). The comparison study is based on a database containing real conversation transcriptions in Italian Natural Language. Experimental results and different topic evaluation metrics are analyzed in this paper to determine the most suitable model for the case study. The gained knowledge can be exploited by practitioners to identify the optimal strategy and to perform and evaluate topic modeling on Italian natural language transcriptions of human-to-human conversations. This work can be an asset for grounding applications of topic modeling and can be inspiring for similar case studies in the domain of customer care quality. © 2023 by the authors.",TestAnalysis
"I present a posthumanist approach to literary interpretation using stylistic analysis. It is posthumanist since i) digital cameras/audio-video resources and editing applications prompt multimodal readings of literary works unlikely from human intuition alone; ii) anthropocentrism in literary texts is defamiliarised. I highlight how stylistic analysis can be used productively for developing multimodal creativity in posthumanist reading by motivating audio-video edits and effects. I model using Anne Brontë’s poem ‘Home’ (1846). When read only with intuition, ‘Home’ communicates young Brontë’s yearning for her family home. In contrast, this article has a non-intuitive digital multimodal realisation of this poem where a young Californian stuck in London because of pandemic (Covid-19) travel restrictions yearns for her home state in the aftermath of wildfires linked to anthropogenic climate change. This posthumanist transformative reading, flagging the negative repercussions of humans for their planetary home, defamiliarises the poem’s anthropocentric normality. Importantly, I show how stylistic analysis of ‘Home’ motivates creative use of audio-visual edits and effects in the posthumanist multimodal reading. The article makes contrast with standard interpretive practice in stylistics (‘humanist stylistics’). It also reflects on the value of posthumanist stylistics for extending students’ creative thinking in an educational context. © The Author(s) 2023.",TestAnalysis
"Background Digital therapeutics, an emerging type of medical approach, is defined as evidence-based therapeutic interventions through qualified software programs that help prevent, manage, or treat chronic diseases such as type 2 diabetes mellitus (T2DM), which has high social and economic burden. Klivo, a startup certified by the Brazilian Society of Diabetes, developed the first digital therapeutic product for managing T2DM in Brazil, reaching 21 of 24 states. Klivo has continuously been improving its model of behavior change on the basis of an intensive lifestyle intervention method that addresses individuals’ needs–the Klivo Intervention Program for T2DM (KIPDM). To test the most recent version of the KIPDM, we will evaluate the ongoing management of daily life habits in patients with T2DM by measuring clinically significant outcomes. To improve the transparency of further results, here we will present the study protocol and detail the plan for the research project, including the study design and the analysis strategies. Methods The KIPDM will be sponsored by health plans and healthcare provider organizations and will be free for patients (adults aged ≥ 18 years and <65 years; and glycated hemoglobin ≥ 7%). The program will be based on a 6-month management process that will supervise patients remotely. The program will include educational classes via the Klivo app, text messages, or e-mails. Evaluation will include objectively assessing clinical, laboratory, and behavioral outcomes such as health-related quality of life, mental health, medication adherence, and healthcare utilization. For this, validated electronic questionnaires will be available through the Klivo app. The primary outcome will be glycated hemoglobin (HbA1c) values. The secondary outcome will be time in target blood glucose range (TIR) estimated by capillary glycemia. Other outcomes of interest will be evaluated at baseline and stipulated time points (3 and 6 months after the start of the program). Expected outcomes KIPDM patients should present improved HbA1c and TIR along the intervention as compared to baseline values. Findings from this study will provide insights into the health improvement of T2DM and other cardiometabolic conditions such as hypertension, dyslipidemia, and obesity by using a digital therapeutic strategy. By analyzing the patient’s health over time, this study will also contribute to understanding comorbidities associated with this chronic condition in the Brazilian population. © 2023 de Oliveira et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Sarcasm is a linguistic phenomenon indicating a difference between literal meanings and implied intentions. It is commonly used on blogs, e-commerce platforms, and social media. Numerous NLP tasks, such as opinion mining and sentiment analysis systems, are hampered by its linguistic nature in detection. Traditional techniques concentrated mostly on textual incongruity. Recent research demonstrated that the addition of commonsense knowledge into sarcasm detection is an effective new method. However, existing techniques cannot effectively capture sentence “incongruity” information or take good advantage of external knowledge, resulting in imperfect detection performance. In this work, new modules are proposed for maximizing the utilization of the text, the commonsense knowledge, and their interplay. At first, we propose an adaptive incongruity extraction module to compute the distance between each word in the text and commonsense knowledge. Two adaptive incongruity extraction modules are applied to text and commonsense knowledge, respectively, which can obtain two adaptive incongruity attention matrixes. Therefore, each of the words in the sequence receives a new representation with enhanced incongruity semantics. Secondly, we propose the incongruity cross-attention module to extract the incongruity between the text and the corresponding commonsense knowledge, thereby allowing us to pick useful commonsense knowledge in sarcasm detection. In addition, we propose an improved gate module as a feature fusion module of text and commonsense knowledge, which determines how much information should be considered. Experimental results on publicly available datasets demonstrate the superiority of our method in achieving state-of-the-art performance on three datasets as well as enjoying improved interpretability. © 2023 by the authors.",TestAnalysis
"Patient education materials (PEM)s were extracted from provincial cancer agencies to determine their organizational health literacy by evaluating the quality, actionability, and functional accessibility (e.g., readability and understandability) of their PEMs. PEMs from 10 provincial agencies were assessed for their grade reading level (GRL), using eight numerical and two graphical readability scales, and underwent a difficult word analysis. The agencies were assessed for PEM quality using two methods (JAMA benchmarks and DISCERN), while actionability and understandability were assessed using the Patient Education Materials Assessment Tool (PEMAT). Seven hundred and eighty-six PEMs were analyzed. The overall average GRL was 9.3 ± 2.1, which is above the recommended 7th GRL for health information. The difficult word analysis showed that 15.4% ± 5.1% of texts contained complex words, 35.8% ± 6.8% of texts contained long words, and 24.2% ± 6.6% of texts contained unfamiliar words. Additionally, there was high overlap between the most frequently identified difficult words in the PEMs and the most frequently misunderstood words by cancer patients identified in the literature. Regarding quality indicators, no agency displayed all four indicators according to the JAMA benchmarks and DISCERN scores ranged between 38 (poor) to 66 (excellent). PEMAT scores ranged between 68% to 88% for understandability and 57% to 88% for actionability. PEMs continue to be written at a level above the recommended GRL across all provinces, and there was overall high variability in the quality, understandability, and actionability of PEMs among provincial agencies. This represents an opportunity to optimize materials, thus ensuring understanding by a wider audience and improving health literacy among Canadian cancer patients. © 2023 by the authors.",TestAnalysis
"A machine learning model for correcting errors in Ukrainian texts has been developed. It was established that the neural network has the ability to correct simple sentences written in Ukrainian; however, the development of a full-fledged system requires the use of spell-checking using dictionaries and the checking of rules, both simple and those based on the result of parsing dependencies or other features. In order to save computing resources, a pre-trained BERT (Bidirectional Encoder Representations from Transformer) type neural network was used. Such neural networks have half as many parameters as other pre-trained models and show satisfactory results in correcting grammatical and stylistic errors. Among the ready-made neural network models, the pre-trained neural network model mT5 (a multilingual variant of T5 or Text-to-Text Transfer Transformer) showed the best performance according to the BLEU (bilingual evaluation understudy) and METEOR (metric for evaluation of translation with explicit ordering) metrics. © 2023 by the authors.",TestAnalysis
"Danmaku data from an online course contains implicit information about the students, the teacher, and the course itself. To discover the information, we design a behavior-sentiment-topic mining procedure, and apply it on the danmaku from two electronics courses on Bilibili, a popular video sharing platform in China. The procedure enables us to obtain behavior patterns, text sentiments, and hidden topics, of those danmaku comments effectively. Results show similarities and differences between the danmaku from Fundamentals of Analog Electronics and that from Fundamentals of Digital Electronics. Some interesting observations are given according to the results. For example, students tend to experience an emotional upsurge right before the end of a course, which is due to their fulfilment for completing the course. Based on the observations, we make some suggestions for students, teachers, and platforms on how to improve the learning outcomes using the results of danmaku analysis. © 2023 by the authors.",TestAnalysis
"The Directed Acyclic Graph (DAG) is a graph representing causal pathways for informing the conduct of an observational study. The use of DAGs allows transparent communication of a causal model between researchers and can prevent over-adjustment biases when conducting causal inference, permitting greater confidence and transparency in reported causal estimates. In the era of ‘big data’ and increasing number of observational studies, the role of the DAG is becoming more important. Recent best-practice guidance for constructing a DAG with reference to the literature has been published in the ‘Evidence synthesis for constructing DAGs’ (ESC-DAG) protocol. We aimed to assess adherence to these principles for DAGs constructed within perioperative literature. Following registration on the International Prospective Register of Systematic Reviews (PROSPERO) and with adherence to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) reporting framework for systematic reviews, we searched the Excerpta Medica dataBASE (Embase), the Medical Literature Analysis and Retrieval System Online (MEDLINE) and Cochrane databases for perioperative observational research incorporating a DAG. Nineteen studies were included in the final synthesis. No studies demonstrated any evidence of following the mapping stage of the protocol. Fifteen (79%) fulfilled over half of the translation and integration one stages of the protocol. Adherence with one stage did not guarantee fulfilment of the other. Two studies (11%) undertook the integration two stage. Unmeasured variables were handled inconsistently between studies. Only three (16%) studies included unmeasured variables within their DAG and acknowledged their implication within the main text. Overall, DAGs that were constructed for use in perioperative observational literature did not consistently adhere to best practice, potentially limiting the benefits of subsequent causal inference. Further work should focus on exploring reasons for this deviation and increasing methodological transparency around DAG construction. © 2023 Watson et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"INTRODUCTION:Patients with hepatic encephalopathy (HE) suffer from significant symptoms and impaired quality of life. Improved understanding on the potential benefits of first-line HE therapies may aid patient-provider discussions regarding expected benefits of HE treatments. We aimed to perform a systematic review to assess the effects of lactulose and rifaximin on patient-reported outcomes (PROs).METHODS:We searched MEDLINE, EMBASE, and Cochrane Library databases for randomized trials or prospective cohort studies using lactulose and/or rifaximin for the management of HE and assessing changes in PRO using PRO instruments. Physician reviewers independently reviewed titles, abstracts, and full texts and extracted data independently. We performed random-effects meta-analyses to examine the effects of lactulose and rifaximin on PROs.RESULTS:We identified 16 studies representing 1,376 patients that met inclusion criteria. Most studies assessed treatment of covert HE. In patients with covert HE, lactulose significantly improved overall patient-reported health-related quality of life measured by the Sickness Impact Profile with an estimated pooled mean difference of 6.92 (95% confidence interval: 6.66-7.18) and showed improvements in several subscales. Conversely, rifaximin demonstrated a nonstatistically significant mean difference in the total Sickness Impact Profile of 4.76 (95% confidence interval: -4.23 to 13.76), with strong evidence of heterogeneity between these studies. Studies examining other PRO instruments showed improvements in overall health-related quality of life, social functioning, and sleep from both lactulose and rifaximin.DISCUSSION:Patients with HE treated with lactulose or rifaximin reported improvements in important PROs. These results may inform provider-patient communication and help manage patient expectations regarding the potential benefits of HE therapies. © 2023 Wolters Kluwer Health. All rights reserved.",TestAnalysis
"Reading disability (RD), which affects between 5 and 17% of the population worldwide, is the most prevalent form of learning disability, and is associated with underactivation of a universal reading network in children. However, recent research suggests there are differences in learning rates on cognitive predictors of reading performance, as well as differences in activation patterns within the reading neural network, based on orthographic depth (i.e., transparent/shallow vs. deep/opaque orthographies) in children with RD. Recently, we showed that native English-speaking children with RD exhibit impaired performance on a maze learning task that taps into the same neural networks that are activated during reading. In addition, we demonstrated that genetic risk for RD strengthens the relationship between reading impairment and maze learning performance. However, it is unclear whether the results from these studies can be broadly applied to children from other language orthographies. In this study, we examined whether low reading skill was associated with poor maze learning performance in native English-speaking and native German-speaking children, and the influence of genetic risk for RD on cognition and behavior. In addition, we investigated the link between genetic risk and performance on this task in an orthographically diverse sample of children attending an English-speaking international school in Germany. The results from our data suggest that children with low reading skill, or with a genetic risk for reading impairment, exhibit impaired performance on the maze learning task, regardless of orthographic depth. However, these data also suggest that orthographic depth influences the degree of impairment on this task. The maze learning task requires the involvement of various cognitive processes and neural networks that underlie reading, but is not influenced by potential differences in reading experience due to lack of text or oral reporting. As a fully automated tool, it does not require specialized training to administer, and current results suggest it may be a practicable screening tool for early identification of reading impairment across orthographies. © 2022 S. Karger AG, Basel.",TestAnalysis
"Error in Figure In the original publication [1], there was a mistake in Figure 4 as published. Some standard deviations were wrong. The corrected Figure 4 appears below Figure 4. Forest plot presenting the effect of exercise on the improvement of Quality of Life (QoL) measured with different instruments in patients with Head and Neck cancer (HNC) compared with control; pre–post intervention data. Values on x-axis denote Cohen’s d. The diamond illustrates the 95% confidence interval of the pooled effects. Text Correction There was an error in the original publication [1]. Two sentences, one in the summary and one in the results, have an error in the hundredths of some data. A correction has been made to Abstract section, the seventh sentence and Section 3.5, third paragraph The correct text of Abstract section, the seventh sentence is as follows: . . . showing a tendency in favor of intervention group, even when the global results did not show statistically significant improvements (pooled Cohen’s d 0.11; 95% CI: -0.27 to 0.50; I2 42.68%; p heterogeneity = 0.12). The correct text of Section 3.5, third paragraph is as follows: Regarding the data presented, there seems to be a tendency in favor of IG in terms of improvement in QoL after exercise program intervention (pooled Cohen’s d 0.11; 95% CI: -0.27 to 0.50; I2 42.68%; p heterogeneity = 0.12). The authors state that the scientific conclusions are unaffected. This correction was approved by the Academic Editor. The original publication has also been updated. © 2023 by the authors.",TestAnalysis
"Objective: To evaluate the role of cancer stem cell biomarkers in diagnosis and prognosis of OSCC patients. Methods: The search strategy was entered into PubMed NLM, EBSCO CINAHL, EBSCO Dentistry & Oral Sciences Source, Wiley Cochrane Library, and Scopus. The full text eligible studies (n=7) were assessed for their quality using the JBI Critical Appraisal Checklist to evaluates the methodological quality of the studies based on possibility of bias in its design, conduct, and analysis. Selected studies were further analysed based on different parameters such as publication year, sample size, and outcomes. Results: A total of 432 studies were identified through the search strategy. A total of 306 records were removed before screening either because of duplication or marked ineligible by the automation tools. The screened records were 126 out of which 104 were removed as they were not conducted on OSCC. Twenty-two reports were sought for retrieval, however, we could not find the full text of 3 studies and12 studies were excluded because the biomarkers were not associated with cancer stem cells. The most common cancer stem cell biomarkers associated with OSCC were MCT1,VEGF-A, GD15, HIF1 α, Ki67, Hsp 70, Cyclin D1, and CD44. Conclusions: Various stem cell biomarkers have been found to have diagnostic and prognostic role in oral squamous cell carcinoma such as Cyclin D1, VEGF-A, GD15, and CD44. They can be used to predict the overall survival rate, local progression-free survival rate, and distant metastasis-free survival rate in Head and Neck cancer patients. © 2023 Pakistan Medical Association. All rights reserved.",TestAnalysis
"Sentiment analysis has become an important area of research in natural language processing. This technique has a wide range of applications, such as comprehending user preferences in ecommerce feedback portals, politics, and in governance. However, accurate sentiment analysis requires robust text representation techniques that can convert words into precise vectors that represent the input text. There are two categories of text representation techniques: lexicon-based techniques and machine learning-based techniques. From research, both techniques have limitations. For instance, pre-trained word embeddings, such as Word2Vec, Glove, and bidirectional encoder representations from transformers (BERT), generate vectors by considering word distances, similarities, and occurrences ignoring other aspects such as word sentiment orientation. Aiming at such limitations, this paper presents a sentiment classification model (named LeBERT) combining sentiment lexicon, N-grams, BERT, and CNN. In the model, sentiment lexicon, N-grams, and BERT are used to vectorize words selected from a section of the input text. CNN is used as the deep neural network classifier for feature mapping and giving the output sentiment class. The proposed model is evaluated on three public datasets, namely, Amazon products’ reviews, Imbd movies’ reviews, and Yelp restaurants’ reviews datasets. Accuracy, precision, and F-measure are used as the model performance metrics. The experimental results indicate that the proposed LeBERT model outperforms the existing state-of-the-art models, with a F-measure score of 88.73% in binary sentiment classification. © 2023 by the authors.",TestAnalysis
"Citation and citation-based metrics are traditionally used to quantify the scholarly impact of scientific papers. However, for documents without citation data, i.e., newly published papers, the citation-based metrics are not available. By leveraging deep representation techniques, we propose a text-content based approach that may reveal the scholarly impact of papers without human domain-specific knowledge. Specifically, a large-scale Pre-Trained Model (PTM) with 110 million parameters is utilized to automatically encode the paper into the vector representation. Two indicators, τ(Topicality) and σ(Originality), are then proposed based on the learned representations. These two indicators leverage the spatial relations of paper representations in the semantic space to capture the impact-related characteristics of a scientific paper. Extensive experiments have been conducted on a COVID-19 open research dataset with 1,056,660 papers. The experimental results demonstrate that the deep representation learning method can better capture the scientific content in the published literature; and the proposed indicators are positively and significantly associated with a paper's potential scholarly impact. In the multivariate regression analysis for the potential impact of a paper, the coefficients of σand τare 5.4915 (P<0.001) and 6.6879 (P<0.001) for next 6 months prediction, 12.9964 (P<0.001) and 13.8678 (P<0.001) for next 12 months prediction. The proposed framework may facilitate the study of how scholarly impact is generated, from a textual representation perspective. © 2023 Elsevier Editora Ltda. All rights reserved.",TestAnalysis
"Whether prone positioning (PP) modulates acute lung inflammation by the modulation of biomechanical forces of ventilator-induced lung injuries (VILIs) remains unclear. We aimed to demonstrate that PP decreases acute lung inflammation in animals with experimental acute respiratory distress syndrome (ARDS). Animals were under general anesthesia and protective ventilation (tidal volume 6 mL·kg-1, PEEP 5 cmH2O). ARDS was induced by intratracheal instillation of chlorohydric acid. Animals were then randomized to PP, or to supine position (SP). After 4 h, a positron emission tomography (PET) acquisition with [11C](R)-PK11195 was performed coupled with computerized tomography (CT) acquisitions, allowing the CT quantification of VILI-associated parameters. [11C](R)-PK11195 lung uptake was quantified using pharmacokinetic multicompartment models. Analyses were performed on eight lung sections distributed along the antero-posterior dimension. Six animals were randomized to PP, five to SP (median [Formula: see text]/[Formula: see text] [interquartile range]: 164 [102-269] mmHg). The normally aerated compartment was significantly redistributed to the posterior lung regions of animals in PP, compared with SP. Dynamic strain was significantly increased in posterior regions of SP animals, compared with PP. After 4 h, animals in PP had a significantly lower uptake of [11C](R)-PK11195, compared with SP. [11C](R)-PK11195 regional uptake was independently associated with the study group, dynamic strain, tidal hyperinflation, and regional respiratory system compliance in multivariate analysis. In an experimental model of ARDS, 4 h of PP significantly decreased acute lung inflammation assessed with PET. The beneficial impact of PP on acute lung inflammation was consecutive to the combination of decreased biomechanical forces and changes in the respiratory system mechanics.NEW & NOTEWORTHY Prone position decreases acute lung macrophage inflammation quantified in vivo with [11C](R)-PK11195 positron emission tomography in an experimental acute respiratory distress syndrome. Regional macrophage inflammation is maximal in the most anterior and posterior lung section of supine animals, in relation with increased regional tidal strain and hyperinflation, and reduced regional lung compliance.",TestAnalysis
"Background Dental caries is defined as a dynamic diet microbial disease of teeth, which results in localized dissolution and destruction of the mineralized tissues of the teeth. Dental caries develops when there is a susceptible tooth exposed to pathogenic bacteria in the presence of substrate. Under these conditions, the bacteria metabolize substrate to form acid, which decalcifies teeth. Dental caries is among the top oral health problem in both developing and developed nations affecting around 20–50% of the population globally. Objective This study was conducted to assess the magnitude, associated factors, and antimicrobial susceptibility pattern of bacterial isolates among adult dental caries patients visiting Hiwot Fana specialized university hospital dental clinic from April 23 to-June 23, 2021. Methods An institutional-based cross-sectional study was conducted among 290 study participants. Convenient sampling techniques were used to select the study participants. Data was entered into Epi-info version 7.2.4.0 and exported to Statistical Package for the Social Sciences version 20 for analysis. The result was explained by using summary measures of texts, tables, and graphs after analysis by using bivariate and multivariate logistic regression. Statistical significance was defined at a p-value of less than 0.05. Result The overall magnitude of bacteria among dental caries patients was 68.3%. S mutans 74 (37.4%) and Lactobacillus spp 58(29.3%) were the most predominant isolated bacteria. Lack of teeth brushing (AOR: 2.8, 95% CI:1.6, 4.6), the habit of chewing khat always (AOR:4.8, 95%CI:2.10,8.80), the habit of chewing khat sometimes (AOR: 3.8: 95% CI: 2.520,9.48) and consumption of soft drinks (AOR: 1.9, 95% CI:1.2,3.1) were significantly associated with bacterial dental caries. Almost, all bacterial isolates were susceptible to ceftriaxone and ciprofloxacin compared to Amoxicillin, Azithromycin, chloramphenicol, clindamycin, doxycycline, erythromycin, gentamycin, penicillin, tetracycline, vancomycin and tobramycin. Conclusion Teeth brushing habit, consumption of soft drink and a habit of chewing khat affects dental health and they are associated with bacterial dental caries. Harari regional health bureau better to focus by giving health education to the community about dental caries based on identified associated factors with dental caries. © 2023 Maru et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"In the task of text sentiment analysis, the main problem that we face is that the traditional word vectors represent lack of polysemy, the Recurrent Neural Network cannot be trained in parallel, and the classification accuracy is not high. We propose a sentiment classification model based on the proposed Sliced Bidirectional Gated Recurrent Unit (Sliced Bi-GRU), Multi-head Self-Attention mechanism, and Bidirectional Encoder Representations from Transformers embedding. First, the word vector representation obtained by the BERT pre-trained language model is used as the embedding layer of the neural network. Then the input sequence is sliced into subsequences of equal length. And the Bi-sequence Gated Recurrent Unit is applied to extract the subsequent feature information. The relationship between words is learned sequentially via the Multi-head Self-attention mechanism. Finally, the emotional tendency of the text is output by the Softmax function. Experiments show that the classification accuracy of this model on the Yelp 2015 dataset and the Amazon dataset is 74.37% and 62.57%, respectively. And the training speed of the model is better than most existing models, which verifies the effectiveness of the model. © 2023 by the authors.",TestAnalysis
"In curriculum development, syllabus creation is an important activity. The need for a syllabus repository and data extraction is essential for creating a new syllabus. Faculties do this job manually by adding topics from their intelligence as well as analyzing syllabuses of the same course available on the search engine. Because it is a time-consuming job, this research aims to propose and implement a text-analyzing tool. The methodology is used, first to create a syllabus repository of computer science courses, do data extraction & normalization, analyzes the contents of different syllabuses, and suggests the contents to the faculties. This tool is experimented on the sample for creating the syllabus of C Programming. The result of the tool is that it suggests the topics that can be included in the syllabus to the faculties. The time and effort required to create a syllabus are reduced by using this tool. In the future weightage to the syllabuses can be given for classification that will give more accurate results while analyzing syllabuses. This tool can be improved by using machine learning algorithms for creating syllabus repositories and data extraction. Semantic comparison can give more accurate results by creating a specific model for computer terminologies. © 2023 by the authors.",TestAnalysis
"Objectives: Coronavirus disease 2019 (COVID-19) resulted in older adults' greater reliance on technology to contact friends and families. However, less is known regarding the association between frequency of varying modes of communication and loneliness among older adults during COVID-19, and current findings are mixed. Therefore, this study aimed to advance this understanding. Methods: Using the National Health and Aging Trends Study COVID-19 supplement data, multinomial regression analyses assessed how the frequency of four modes of contact (i.e., phone calls; electronic and social messaging such as e-mails/texts/social media messages; video calls; and in-person visits) during the COVID-19 pandemic was associated with feelings of loneliness among older adults compared to prepandemic (n = 2,564). Results: Compared to never/less than once a week in-person visits, daily in-person visits were associated with lower odds of reporting more frequent loneliness during COVID-19 versus ""about the same""as pre-COVID-19 while controlling for demographics, access to information and communication technologies (ICTs), digital literacy, and health covariates. Compared to those who reported never/less than once a week contact by electronic and social messaging, more frequent contact was associated with higher odds of reporting more frequent loneliness during COVID-19 versus ""about the same""as pre-COVID-19 while controlling for other variables in the model. Phone calls and video calls were not significantly related to loneliness. Discussion: Results suggest that ICTs may not decrease loneliness among older adults. This article discusses potential reasons and barriers, including digital exclusion, and provides recommendations to mitigate the negative effects of social isolation through technology for older adults.  © 2022 The Author(s). Published by Oxford University Press on behalf of The Gerontological Society of America. All rights reserved.",TestAnalysis
"Introduction: A woman’s nutrition during pregnancy and nursing affects the mother and the growing child. Similarly, the first two years of a child’s life are critical to their growth and development and are facilitated by optimum nutrition. Women’s nutrition-related knowledge, attitudes, and practices influence household food and nutrition security. Mobile health (mHealth) is a potentially effective health intervention in pandemic situations when physical gatherings are restricted. Objectives: To examine the effectiveness of a mobile phone-based nutrition education intervention targeting pregnant and nursing mothers in six Sri Lankan divisional secretariat areas. Method: This intervention was evaluated using a before and after within-subjects design. The intervention included 19 messages over four weeks sent via mobile phone, covering nutrition themes such as pregnancy care, infant and young child-feeding, diet, family care for mother and child, and cash management. The intervention was evaluated based on a quantitative survey using a structured interviewer-administered questionnaire and qualitative interviews using a semi-structured questionnaire. The study population was pregnant and nursing mothers. The objective of the qualitative interviews was to identify how respondents used messages and how satisfied they were with the project. The outcome measures were awareness/knowledge, attitudes, social norms, self-efficacy, behaviour intentions, and practices of pregnant and nursing mothers. Trained enumerators collected data using a mobile phone. Results: A total of 996 pregnant and nursing mothers participated in the pre-assessment survey, of which 720 completed the post-assessment. Most were nursing mothers (84.2% pre- and 78.9% post-assessment). Participants provided positive feedback on the intervention. Knowledge/awareness (t = −18.70, p < 0.01) and attitudes (t = −2.00, p < 0.05) increased when exposed to the intervention. Favourable improvements in the practices were also observed. Mothers’ practices related to breastfeeding and 24-h dietary diversity showed a statistically significant improvement. However, social norms and behaviour intentions did not significantly improve. The qualitative component also revealed favourable responses. Conclusion and Recommendations: The mobile intervention improved participants’ knowledge, awareness, attitude, and practices, but not social norms or behaviour intentions. This approach is recommended to be used on a larger scale in community settings. In addition, mobile technology could drive intervention in pandemic-related situations. © 2023 by the authors.",TestAnalysis
"Textual data suffers from two main problems, large number of features and class imbalance. Many conventional approaches and their variants exist in literature to solve both these problems. The classic synthetic minority oversampling technique (SMOTE) is the most explored technique for balancing the dataset. We introduced a new algorithm to balance the dataset, named distributed SMOTE (D_SMOTE), which overcomes the problem of lack of density and reducing the formation of small disjuncts. Further, another problem handled is the large number of features or high-dimensionality. To solve high-dimensionality, a novel feature selection technique is introduced known as modified biogeography-based optimization (M_BBO). The proposed model, M_BBO, performs modification in ranking of variables using feature weighting algorithm rather than randomly ranking. We have proposed two new expressions in D_SMOTE and one new expression in M_BBO. The extensive experimental results are computed out on four text classification datasets with four machine learning classifiers. The results are concluded using three performance measures, area under curve, G-mean, and F1-score. Our empirical and statistical observation for four class-imbalanced datasets shows that the proposed D_SMOTE outperforms the other similar oversampling technique. We have also compared our proposed algorithm, M_BBO+D_SMOTE, with other models on 17 imbalanced text classification datasets. Our model outperformed the other models in 14 datasets. We have also compared our model with bidirectional encoder representations from transformers. To validate the experimental analysis, statistical Friedman test is employed. © 2020 IEEE.",TestAnalysis
"With the development of science and computer technology, social networks are changing our daily lives. However, this leads to new, often hidden dangers in areas such as cybersecurity. Of these, the most complex and harmful is the Advanced Persistent Threat attack (APT attack). The development of personality analysis and prediction technology provides the APT attack a good opportunity to infiltrate personality privacy. Malicious people can exploit existing personality classifiers to attack social texts and steal users’ personal information. Therefore, it is of high importance to hide personal privacy information in social texts. Based on the personality privacy protection technology of adversarial examples, we proposed a Supervised Character Resemble Substitution personality adversarial method (SCRS) in this paper, which hides personality information in social texts through adversarial examples to realize personality privacy protection. The adversarial examples should be capable of successfully disturbing the personality classifier while maintaining the original semantics without reducing human readability. Therefore, this paper proposes a measure index of “label contribution” to select the words that are important to the label. At the same time, in order to maintain higher readability, this paper uses character-level resemble substitution to generate adversarial examples. Experimental validation shows that our method is able to generate adversarial examples with good attack effect and high readability. © 2023 by the authors.",TestAnalysis
"The normalized compression distance (NCD) is a similarity measure between a pair of finite objects based on compression. Clustering methods usually use distances (e.g., Euclidean distance, Manhattan distance) to measure the similarity between objects. The NCD is yet another distance with particular characteristics that can be used to build the starting distance matrix for methods such as hierarchical clustering or K-medoids. In this work, we propose Zgli, a novel Python module that enables the user to compute the NCD between files inside a given folder. Inspired by the CompLearn Linux command line tool, this module iterates on it by providing new text file compressors, a new compression-by-column option for tabular data, such as CSV files, and an encoder for small files made up of categorical data. Our results demonstrate that compression by column can yield better results than previous methods in the literature when clustering tabular data. Additionally, the categorical encoder shows that it can augment categorical data, allowing the use of the NCD for new data types. One of the advantages is that using this new feature does not require knowledge or context of the data. Furthermore, the fact that the new proposed module is written in Python, one of the most popular programming languages for machine learning, potentiates its use by developers to tackle problems with a new approach based on compression. This pipeline was tested in clinical data and proved a promising computational strategy by providing patient stratification via clusters aiding in precision medicine. © 2023 by the authors.",TestAnalysis
"A noninvasive tool for cardiovascular risk stratification has not yet been established in the clinical routine analysis. Previous studies suggest a prolonged Tpeak-Tend interval (the interval from the peak to the end of the T-wave) to be predictive of death. This meta-analysis was designed to systematically evaluate the association of the Tpeak-Tend interval with mortality outcomes. Medline (via PubMed), Embase and the Cochrane Library were searched from 1 January 2008 to 21 July 2020 for articles reporting the ascertainment of the Tpeak-Tend interval and observation of all-cause-mortality. The search yielded 1920 citations, of which 133 full-texts were retrieved and 29 observational studies involving 23,114 patients met the final criteria. All-cause deaths had longer Tpeak-Tend intervals compared to survivors by a standardized mean difference of 0.41 (95% CI 0.23–0.58) and patients with a long Tpeak-Tend interval had a higher risk of all-cause death compared to patients with a short Tpeak-Tend interval by an overall odds ratio of 2.33 (95% CI 1.57–3.45). Heart rate correction, electrocardiographic (ECG) measurement methods and the selection of ECG leads were major sources of heterogeneity. Subgroup analyses revealed that heart rate correction did not affect the association of the Tpeak-Tend interval with mortality outcomes, whereas this finding was not evident in all measurement methods. The Tpeak-Tend interval was found to be significantly associated with all-cause mortality. Further studies are warranted to confirm the prognostic value of the Tpeak-Tend interval. © 2023 by the authors.",TestAnalysis
"Cyberbullying is a form of aggression in which electronic communication such as e-mails, mobile phone calls, text messages, instant messenger contacts, photos, social networking sites and personal webpages are used to threaten or intimidate individuals. Cognitive-behavioral therapy (CBT) counselling based on empathic training may reduce cyberbullying among adolescents. The present study investigated the impact of developing empathy skills in reducing cyberbullying among a sample of adolescents using two groups (i.e., an experimental group and control group). The experimental group received counselling intervention based on CBT with special focus on improving empathy whereas the control group received CBT general counselling. The participants comprised 217 adolescents (experimental group = 98 adolescents, control group = 119 adolescents) with a mean age of 15.1 years (SD ± 1.5). The measures included the Toronto Empathy Questionnaire (TEQ) and the Bullying, Cyberbullying Scale for Adolescents (BCS-A). Results showed that there were statistically significant differences on TEQ scores and BCS-A scores in the experimental and control groups after the intervention but more so in favor of the experimental group in terms of reduced levels of cyberbullying (both victimization and perpetration). Positive gains among the experimental group in both empathy and reduced cyberbullying remained at two-month follow-up. It is recommended that teachers and school counselors tackling cyberbullying should use empathy training as part of their cyberbullying prevention programs. © 2023 by the authors.",TestAnalysis
"Inferencing skills uniquely contribute to the reading comprehension skills of older grade-school and college students. Evidence also suggests that children's reading component skills, such as decoding and language comprehension, differentially contribute to various reading comprehension assessments. However,additional research is needed to investigate the complex relations of foundational reading skills and inferencing skills to sentence-level and passage-level reading comprehension assessments with struggling adult readers. This study examined the relations between struggling adult readers' (N = 125) text-based (decoding, fluency), language-based (morphological awareness, vocabulary, language comprehension), and inferencing skills. The indirect effects of language-based reading component skills to sentence-level and passage-level reading comprehension measures through inferencing were also examined. Vocabulary and morphological awareness indirectly predicted passage-level reading comprehension through inferencing. Word reading fluency and vocabulary knowledge uniquely predicted sentence-level comprehension whereas inferencing skills predicted passage-level comprehension. These results suggest that inferencing is an important contributor to the reading comprehension skills of struggling adult readers. These findings also emphasize a need for multiple measures of comprehension to understand the complexity and underlying component processes involved in struggling adults' reading comprehension skills. Educational implications for adult literacy programs are discussed. © 2023 Elsevier Inc.",TestAnalysis
"Background: Understanding patient experience is key to optimize access and quality of outpatient cancer rehabilitation (physical or occupational therapy, PT/OT) services. Methods: We performed a retrospective mixed-method analysis of rehabilitation medical record data to better understand patient experience and aspects of care that influenced experience. From the medical record, we extracted case characteristics, patient experience data (Net Promoter Survey®, NPS) and patient-reported outcome (PRO) data. We categorized cases as ‘promoters’ (i.e., highly likely to recommend rehabilitation) or ‘detractors’, then calculated NPS score (−100 [worst] to 100 [best]). We identified key themes from NPS free-text comments using inductive content analysis, then used Pearson [r] or Spearman [ρ] correlation to explore relationships between NPS, characteristics, and PRO improvement. Results: Patients (n = 383) were 60.51 ± 12.02 years old, predominantly women with breast cancer (69.2%), and attended 14.23 ± 12.37 visits. Most were ‘promoters’ (92%); NPS score was 91.4. Patients described two experiences (themes) that influenced their likelihood to recommend rehabilitation: (1) feeling comfortable with the process and (2) observable improvement in health/functioning, and described attributes of clinic staff, environment and clinical care that influenced themes. Likelihood to recommend rehabilitation was associated with achieving the minimal clinical important difference on a PRO (ρ = 0.21, p < 0.001) and cancer type (ρ = 0.10, p < 0.001). Conclusion: Patients who received specialized cancer PT/OT were highly likely to recommend rehabilitation. Feeling comfortable with the rehabilitation process and making observable improvements in health and/or functioning influenced likelihood to recommend. Rehabilitation providers should leverage the findings of this study optimize access to and quality of cancer rehab services. © 2023 by the authors.",TestAnalysis
"In the era of the Internet of Things, innovative business model initiatives continue to deepen, and the trend of search domains continues to expand. This paper aims to scientifically analyze research trends of the Internet of Things in relation to Business Model Innovation through bibliometric studies. The data were collected using the Clarivate Web of Science (WoS) Core Collection (SSCI and SCI indexed) from 2005 to 2022 (November). However, the publications for the research domains started in 2015. The results show that scientific publications on the Internet of Things in relation to Business Model Innovation have increased gradually since 2019. The WoS database is utilized for analyses because it contains journals and conference proceedings deemed more relevant by the academic domain and highly reputable sources for bibliometric studies. The VOS viewer, R Language, and Microsoft Excel were also used to analyze and complete the study. Bibliometric and scientometric analyses were conducted to identify publication patterns, text analysis, most important keywords (co-word, word cloud, and co-occurrence), trends for the topicality, and content clustering for the publication periods. The visualization of the research trends of the Internet of Things in relation to Business Model Innovation resulted in four co-occurrence clusters leading to some of the topic areas mentioned as follows: (1) The Internet of Things, (2) Business model innovation, (3) Technology infrastructure, and (4) Digital transformation and capabilities. The results of this study will assist academics in identifying worldwide research trends related to the Internet of Things and Business Model Innovation as well as recommending future research areas. © 2023 by the authors.",TestAnalysis
"Narratology is a discipline that undertakes the task of analyzing the techniques and narrative structures of a narrative text which is presented as a report of interconnected incidents in an artistic form. Narratological study of a narrative text such as Samuel Beckett’s Waiting for Godot, with its different religious, mythological, philosophical and psychological aspects, provides new perspectives for the readers. Also, with a structural analysis of this play and understanding its narrative functions, one can reach a better understanding of its themes. The uncertainty of meaning in Waiting for Godot is one of the significant characteristics of this play which makes various readings possible for the reader. Therefore, by using a descriptive analytical methodology and drawing upon Roland Barthes’ theory of narrative codes, this study tries to analyze the play in order to show the open and manifold quality of different meanings in this play; in other words, it examines whether the text of Waiting for Godot is a scriptible (“writerly”) text or a lisible (“readerly”) text a closed text, turning the reader into a mere consumer. Also, the narrative functions of the text as well as its implications and hidden meanings are analyzed to gain a better understanding of the hidden concepts. The findings of this research reveal that, 1) the text of the play Waiting for Godot has an adaptable structure to Barthes’ theory of narrative codes; as such, in some occasions, Barthes’ critical patterns about the excessive stillness or lack of movement of the actors challenge the text of the play on its aesthetic foundation and provide a deeper understanding of the two characters, the “half crazy” and the “half philosopher”. 2) By creating multiple oppositions and by using the genre of absurd theater, Beckett has managed to create relationships between the characters in their dialogues, through which he successfully conveys his religious and philosophical ideas to the readers. 3) This play is a writerly text and has multiple meanings which are reproduced by the reader and eventually lead the readers toward a better understanding of its hidden themes and beauties. © The Author(s).",TestAnalysis
"This study assessed differences in the oral health-related quality of life (OHRQoL) between subtypes of Ehlers-Danlos syndrome (EDS). For statistical analysis, participants were divided according to their subtype: classical EDS (cEDS), hypermobile EDS (hEDS), and vascular EDS (vEDS). All other subtypes were descriptively analyzed. Free-text questions and the German short form of the Oral Health Impact Profile (OHIP-14) were used. Finally, 295 questionnaires were included, representing 10 different EDS subtypes. The mean OHIP score of all participants was 19.6 points (standard derivation (SD) ± 12.3). The most predominant subtypes showed similar reduced OHRQoL, with 18.0 (cEDS, ±12.9), 19.5 (hEDS, ±12.0), and 15.2 (vEDS, ±11.6) OHIP points. For all other subtypes, the OHIP values varied. Participants waited an average of 21.8 years (±12.8) for their diagnosis. However, within the predominant subtypes, vEDS patients waited a noticeably shorter period of 13.3 years (±13.0; p = 0.004) compared to participants with hEDS. Additionally, this study showed no difference in OHRQoL for the predominant subtypes regardless of whether a participant was a self-help group member (18.8, ±12.0) or not (19.4, ±12.1; p = 0.327). © 2023 by the authors.",TestAnalysis
"In the context of China’s “digital power” strategy, the realization of a green and low-carbon shift in manufacturing has become a necessary condition to promote the economy, and the digital factor has increasingly become a new driving force. The text mining and IPCC methods were used to measure manufacturing enterprise digitalization and the level of enterprise carbon emission intensity from 2011 to 2021, respectively. This study then explored the impact of digitalization on manufacturing enterprise carbon emission intensity based on the least squares method model and instrumental variable method model. This research comes to three conclusions. (1) Digitalization can significantly reduce the enterprise carbon emission intensity of China’s manufacturing industry, and the influence shows a “marginal increase.” (2) Notably, a mechanism analysis indicates the intermediary effect sizes of four crucial intermediaries: green technology innovation > financing constraint > information asymmetry > energy use efficiency. Interestingly, digital information resources positively moderate the positive effect of digitalization on carbon emission intensity through three paths: financing constraints, green technology innovation, and information asymmetry. (3) The influence shows evident signs of heterogeneity—as environmental regulation, financial development, executive education, and R&D quality advance, the inhibiting effect of digitalization on enterprise carbon emission intensity becomes more pronounced. Finally, corresponding policy suggestions are proposed. © 2023 by the authors.",TestAnalysis
"Background: Breastfeeding rates have stagnated recently despite recommendations to breastfeed until age 2 years. Antenatal breast milk expression (ABME) is a method used to prepare the breast for breastfeeding. However, there is limited evidence available on the benefits, risks, and impact of ABME on maternal-infant breastfeeding dyads. Methods: This review identified and summarized studies on women who engaged in ABME and their personal experiences. Databases searched included PubMed MEDLINE, Web of Science, Cumulative Index of Nursing and Allied Health Literature (CINAHL), and EMBASE. Initially, abstracts and titles were reviewed, and then, full-text studies were screened for inclusion by two blinded authors. Two authors assessed the quality of the studies using a standardized tool, two authors completed data extraction, and one author completed data harmonization into tables. Results: A total of 1,410 studies were identified (after duplicates removed) and 10 citations qualified for the inclusion criteria. Only two studies received an overall rating of strong quality and low-risk bias. The selected articles varied in primary outcomes; however, main focuses were experiences, knowledge, and perspective after practicing ABME. Data varied on timing of ABME, but most studies started between 34 and 36 weeks. The average amount of expressed milk was reported in four studies but was variable. Conclusions: This systematic review found that the literature is limited regarding ABME, and most studies were focused on women with diabetes. The current limited evidence suggests that ABME may be a helpful tool in improving maternal breastfeeding confidence and breastfeeding outcomes. Negative side effects reported related to ABME included difficulty learning the technique, discomfort, and feeling of awkwardness while expressing. Future research should focus on higher quality studies regarding use of ABME, proper teaching of ABME technique, and the use of ABME to improve breastfeeding outcomes in diverse populations of maternal-infant dyads.  © 2023 Mary Ann Liebert, Inc., publishers.",TestAnalysis
"—The article aimed to determine the specificity of computer game discourse, its features, key linguistic characteristics, and communicative features. The methodology included the analysis of computer game discourse materials, in particular, dictionary articles, texts of electronic messages, and computer conferences, as well as recordings of fragments of the spoken language of users and users of computer games. The specific feature of computer discourse is the selective combination of features, typical for other types and forms of communication. Computer discourse has some communicative features: electronic communication channel; mediated communication; distance communication; emotionality transmission through emoji symbols; genre heterogeneity; discourse participants' creativity. Computer discourse is characterized by the dominance of English-language lexical bases (barbarisms and semantic translations) and a tendency to unify the norms and rules of communication. Despite such specificity, computer jargon in its functioning and especially word formation is subject to the laws of the Ukrainian language. In particular, affixal, non-affixal, and lexico-semantic are the most widespread modes of word formation in the computer lexicon. At the same time, lexico-semantic can be combined with other known ways. Computer vocabulary is characterized by the use of speech games and means of speech expression. The key tendency in the formation of computer discourse is to reduce the ways of information transmission as much as possible. © 2023 ACADEMY PUBLICATION.",TestAnalysis
"Graph Convolutional Network (GCN) for aspect-based sentiment classification has attracted a lot of attention recently due to their promising performance in handling complex structure information. However, previous methods based on GCN focused mainly on examining the structure of syntactic dependency relationships, which were subject to the noise and sparsity problem. Furthermore, these methods tend to focus on one kind of structural information (namely syntactic dependency) while ignoring many other kinds of rich structures between words. To tackle these problems, we propose a novel GCN based model, named Structure-Enhanced Dual-Channel Graph Convolutional Network (SEDC-GCN). Specifically, we first exploit the rich structure information by constructing a text sequence graph and an enhanced dependency graph, then design a dual-channel graph encoder to model the structure information from the two graphs. After that, we propose two kinds of aspect-specific attention, i.e., aspect-specific semantic attention and aspect-specific structure attention, to learn sentence representation from two different perspectives, i.e., the semantic perspective based on the text encoder, and the structure perspective based on the dual-channel graph encoder. Finally, we merge the sentence representations from the above two perspectives and obtain the final sentence representation. We experimentally validate our proposed model SEDC-GCN by comparing with seven strong baseline methods. In terms of the metric accuracy, SEDC-GCN achieves performance gains of 74.42%, 77.74%, 83.30%, 81.73% and 90.75% on TWITTER, LAPTOP, REST14, REST15, and REST16, respectively, which are 0.35%, 4.22%, 1.62%, 0.70% and 2.01% better than the best performing baseline BiGCN. Similar performance improvements are also observed in terms of the metric macro-averaged F1 score. The ablation study further demonstrates the effectiveness of each component of SEDC-GCN. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"The article deals with one of the effects of health inequalities and gaps in access to treatments for rare diseases, namely health-driven emigration. The purpose of the paper is to systematize knowledge about the phenomenon of health emigration observed among families affected by rare diseases, for which reimbursed treatment is available, but only in selected countries. The topic proved to be niche; the issue of “health emigration in rare diseases” is an area for exploration. Therefore, the further analysis used text mining and machine learning methods based on a database selected based on keywords related to this issue. The results made it possible to systematize the guesses made by researchers in management and economic fields, to identify the most common keywords and thematic clusters around the perspective of the patient, drug manufacturer and treatment reimbursement decision-maker, and the perspective integrating all the others. Since the topic of health emigration was not directly addressed in the selected sources, the authors attempted to define the related concepts and discussed the importance of this phenomenon in managing the support system in rare diseases. Thus, they indicated directions for further research in this area. © 2023 by the authors.",TestAnalysis
"As a strategic guarantee for the rapid development of electric vehicles, the construction and development of electric vehicle charging infrastructure (EVCI) is closely related to the industrial policies formulated by the government. This paper takes policy texts relevant to EVCI in China since 2014 as the research materials, taking policy instruments and the industrial chain as analysis dimensions. Policy content analysis is conducted to explore the EVCI policy content, structure characteristics of policy instruments, and evolution characteristics of EVCI policy in China. Our research reveals that China’s EVCI policy system is relatively perfect, but the use of policy instruments is not balanced and, in particular, is not coordinated with the EVCI industrial chain they supported. In this regard, the government should pay more attention to the use of demand-side policy instrument to enhance the driving force for the development of the EVCI industry. With more scientific and reasonable arrangement of the distribution and implementation of policy instruments in the EVCI industrial chain, the benign development of China’s EVCI industry can be promoted. This research contributes to strengthening the management and policy instrumentation of the central Chinese government, in order to support the realization of good governance of EVCI and the new energy vehicle development. © 2023 by the authors.",TestAnalysis
"The COVID-19 pandemic caused extensive disruption to higher education, highlighting the negative impacts of emergency shift to online instruction. As a result, advantages of intentionally designed, online programs in higher education were overshadowed during the pandemic. Furthermore, socioeconomic disparities were exacerbated during the pandemic which extended to STEM undergraduate transfer students, who are more likely to be low-income, from historically underrepresented groups, older, and first generation in their family to attend college. To better understand the impact of the pandemic on STEM undergraduates, including those in an intentionally designed online program, ordinal regression analysis of 352 student survey respondents enrolled in a life sciences major at a large, R1 institution in the United States spring 2020 through fall 2021 was performed. Three student types are compared: on-campus, first-time in college (FTIC); on-campus transfer (OC-TR); and online transfer (ONL-TR) students. The latter group receives all course delivery online, whereas on-campus student groups received predominately in-person course delivery prior to the pandemic. ONL-TR students were over six times less likely to report negative educational impact compared to on-campus students, FTIC and OC-TR, while controlling for parent education, income, gender, race/ethnicity, and GPA. Additional survey items further explored this result and were validated with academic records and thematic analysis of students’ text responses. A pre−/post-pandemic comparison revealed that students maintained a similar course load and GPA, despite increased perceptions of a lower GPA during the pandemic. OC-TR students were over two times more likely to express increased concern related to delayed graduation and higher frequency of feeling stress compared to FTIC and ONL-TR students. Meanwhile, low-income students were more likely to report stressors due to the pandemic’s impact on daily life, independent of student type. Taken together, students in this intentionally designed online program were more resilient to the educational and emotional impacts of the pandemic compared to on-campus students. The differences between student groups warn against generalization of student impacts and suggest further research into the positive role of online learning, not just for delivery of educational content and expanding access, but for academic and emotional stability for different student populations. Copyright © 2023 Ardissone, Galindo, Triplett and Drew.",TestAnalysis
"Introduction: Long-term cardiovascular (CV) risk is a concern for differentiated thyroid cancer (DTC) survivors. Methods: We performed a systematic review and meta-analysis evaluating the risks of CV mortality and morbidity in DTC survivors compared with the general population. Respective meta-analyses were conducted for data that were adjusted for relevant confounders and crude data. We searched five electronic databases from inception to October 2021, supplemented with a hand search. Two reviewers independently screened citations, reviewed full text articles, extracted data, and critically appraised the studies, with discrepancies resolved by a third reviewer. The primary outcome was CV mortality. Secondary outcomes included atrial fibrillation, ischemic heart disease, stroke, and heart failure. We estimated the relative risk (RR) and confidence intervals [CI] of outcomes using random-effects models (adjusted for age and gender), compared with the general population. Results: We reviewed 3409 unique citations, 65 full text articles, and included 7 studies. CV mortality risk was significantly increased in DTC survivors in one study adjusted for confounders—adjusted RR (aRR) 3.35 ([CI 1.66–6.67]; 524 DTC, 1572 controls). The risk of CV morbidity in DTC survivors, adjusted for risk factors, was estimated as follows: atrial fibrillation—aRR 1.66 [CI 1.22–2.27] (3 studies, 4428 DTC, I2 = 75%), ischemic heart disease—aRR 0.97 [CI 0.84–1.13] (2 studies, 3910 DTC, I2 = 0%), stroke—aRR 1.14 [CI 0.84–1.55] (2 studies, 3910 DTC, I2 = 69%), and heart failure—aRR 0.98 [CI 0.60–1.59] (2 studies, 3910 DTC, I2 = 79%). In meta-analyses of unadjusted data, the risks of CV mortality were not significantly increased but the CV morbidity risks were similar to adjusted data. Conclusions: There is limited evidence suggesting that DTC survivors may be at an increased risk of CV death and atrial fibrillation (after adjustment for confounders). We did not observe a significantly increased risk of ischemic heart disease, stroke, or heart failure. Most analyses were subject to significant heterogeneity and further research, with careful attention to CV risk factors, is needed to clarify CV risk in DTC survivors. ª Mary Ann Liebert, Inc.",TestAnalysis
"Microblog is an important platform for mining public opinion, and it is of great value to conduct emotional analysis of microblog texts during the current epidemic. Aiming at the problem that most current emotional classification methods cannot effectively extract deep text features, and that traditional word vectors cannot dynamically obtain the semantics of words according to their context, which leads to classification bias, this research put forward a microblog text emotion classification algorithm based on TCN-BiGRU and dual attention (TCN-BiGRU-DATT). First, the vector representation of the text was obtained using ALBERT. Second, the TCN and BiGRU networks were used to extract the emotional information contained in the text through dual pathway feature extraction, to efficiently obtain the deep semantic features of the text. Then, the dual attention mechanism was introduced to allocate the global weight of the key information in the semantic features, and the emotional features were spliced and fused. Finally, the Softmax classifier was applied for emotion classification. The findings of a comparative experiment on a set of microblog text comments collected throughout the pandemic revealed that the accuracy, recall, and F1 value of the emotion classification method proposed in this paper reached 92.33%, 91.78%, and 91.52%, respectively, which was a significant improvement compared with other models. © 2023 by the authors.",TestAnalysis
"As the core engine of the digital economy, the digital transformation can make modern enterprises survive and develop better now. By the sample data of listed companies in the years from 2015 to 2020, this paper identifies the degree of enterprise digital transformation through text analysis, empirically examines the impact mechanism of digital transformation on corporate risk-taking, and fully considers the heterogeneity problems. The findings are as follows: (1) Digital transformation can improve the level of enterprise risk taking, especially the improvement of enterprise financial stability and strategic risk taking; (2) in terms of enterprise attribute structure, digital transformation can significantly enhance the risk-taking level of non-state-owned enterprises and high-tech enterprises; (3) the mechanism identification test finds that innovation-driven and enterprise value enhancement play a strengthening role in the role of digital transformation in promoting enterprise risk-taking level, and resource allocation efficiency as a mediating path weakens the role of digital transformation on enterprise risk-taking level. This study provides a basis for promoting the improvement of enterprises risk-taking: digital transformation can help enterprises maintain financial stability, improve innovation output capacity, enterprise value level, enterprise risk-taking capacity and sustainable development. At the same time, the Chinese government should take measures to further stimulate the willingness of state-owned enterprises to digital transformation. © 2023 by the authors.",TestAnalysis
"Doctoral students are expected to contribute to their academic community by presenting their research findings in an internationally acceptable manner and to submit their dissertation. Students from non-English-speaking backgrounds might face challenges when writing publishable papers and dissertations in English. The aim of this study is to explore conceptual metaphors doctoral students used for characterizing their English academic writing experiences during their doctoral studies. A survey was conducted in the spring of 2022 inviting all non-native English-speaking doctoral students. They were asked to finish the sentence: “Writing an academic paper in English is like …..”. A total of 255 doctoral students (125 females; 127 males; 3 not stated) studying at 14 Hungarian universities volunteered to participate. They were from 49 countries and used 52 mother tongues. The metaphor dataset was analyzed following Lakoff and Johnson’ (1980) theoretical framework. Ten conceptual domains emerged from the dataset: WORK, TEXT PRODUCTION, CHALLENGE, STRUGGLE, CHANGING PLACES, ACTIVITIY, NOURISMENT, EASY TASK, CONSTRUCTION, and COMPLEX PROCESS. Only four students shared very negative metaphors on their experiences; whereas most students’ metaphors reflected optimism, even though they implied various demanding features of English academic writing. Students’ metaphors offered new authentic insights into their emic perspectives on their lived experiences. © 2023 The Authors",TestAnalysis
"BACKGROUND: The COVID-19 pandemic continues to exert a significant toll on the Australian primary healthcare system. Although wellbeing challenges faced by hospital-based healthcare workers are widely discussed, less is known about the experiences of general practitioners (GPs) during the initial phases of the pandemic. This paper reports qualitative survey data from Australian GPs, examining their workplace and psychosocial experiences during the initial months of the pandemic. METHODS: An Australia-wide, cross-sectional, online survey of frontline healthcare workers was conducted in 2020. A qualitative approach using content analysis was utilised to examine responses to four free-text questions from GPs. RESULTS: A total of 299 GPs provided 888 free-text responses. The findings reveal that general practice was overlooked and undervalued within the pandemic response, resulting in negative impacts on GP wellbeing. Four themes were identified: (1) marginalisation of GPs; (2) uncertainty, undersupported and undervalued in the workplace; (3) isolation and disrupted personal lives; and (4) strategies to support GPs during times of crises. Key concerns included poor access to personal protective equipment, occupational burnout and poor wellbeing, insufficient workplace support, and conflicting or confusing medical guidelines. CONCLUSIONS: Primary healthcare constitutes an essential pillar of the Australian healthcare system. This study presents the many factors that impacted on GP wellbeing during the COVID-19 pandemic. Enabling GP voices to be heard and including GPs in decision-making in preparation for future crises will enhance the delivery of primary care, reducing the burden on hospital services, and help sustain a safe and effective health workforce long term.",TestAnalysis
"Aspect-based sentiment analysis (ABSA) is a method used to identify the aspects discussed in a given text and determine the sentiment expressed towards each aspect. This can help provide a more fine-grained understanding of the opinions expressed in the text. The majority of Arabic ABSA techniques in use today significantly rely on repeated pre-processing and feature-engineering operations, as well as the use of outside resources (e.g., lexicons). In essence, there is a significant research gap in NLP with regard to the use of transfer learning (TL) techniques and language models for aspect term extraction (ATE) and aspect polarity detection (APD) in Arabic text. While TL has proven to be an effective approach for a variety of NLP tasks in other languages, its use in the context of Arabic has been relatively under-explored. This paper aims to address this gap by presenting a TL-based approach for ATE and APD in Arabic, leveraging the knowledge and capabilities of previously trained language models. The Arabic base (Arabic version) of the BERT model serves as the foundation for the suggested models. Different BERT implementations are also contrasted. A reference ABSA dataset was used for the experiments (HAAD dataset). The experimental results demonstrate that our models surpass the baseline model and previously proposed approaches. © 2023 by the authors.",TestAnalysis
"With the current shift in the mass media landscape from journalistic rigor to social media, personalized social media is becoming the new norm. Although the digitalization progress of the media brings many advantages, it also increases the risk of spreading disinformation, misinformation, and malformation through the use of fake news. The emergence of this harmful phenomenon has managed to polarize society and manipulate public opinion on particular topics, e.g., elections, vaccinations, etc. Such information propagated on social media can distort public perceptions and generate social unrest while lacking the rigor of traditional journalism. Natural Language Processing and Machine Learning techniques are essential for developing efficient tools that can detect fake news. Models that use the context of textual data are essential for resolving the fake news detection problem, as they manage to encode linguistic features within the vector representation of words. In this paper, we propose a new approach that uses document embeddings to build multiple models that accurately label news articles as reliable or fake. We also present a benchmark on different architectures that detect fake news using binary or multi-labeled classification. We evaluated the models on five large news corpora using accuracy, precision, and recall. We obtained better results than more complex state-of-the-art Deep Neural Network models. We observe that the most important factor for obtaining high accuracy is the document encoding, not the classification model's complexity. © 2023 by the authors.",TestAnalysis
"Based on the then high-tech industry policy documents issued by Beijing in 2017, this paper builds a complex network model to reflect the internal structure of Beijing’s High-Technology Industry Chain (BHIC), and then analyzes the coevolutionary mechanisms of ten top high-technology industries and their detailed sectors. Especially for the science and technology service (S&T) industry, this paper measures its function and status in the system and studies its concrete approach to stabilize the development of the industry chain. Finally, policy suggestions to promote the development of the S&T service industry in specialization, networking, and scale are put forward. © 2023 by the authors.",TestAnalysis
"Myotonic dystrophy type 1 (DM1) is an autosomal dominant hereditary disease caused by abnormal expansion of unstable CTG repeats in the 3′ untranslated region of the myotonic dystrophy protein kinase (DMPK) gene. This disease mainly affects skeletal muscle, resulting in myotonia, progressive distal muscle weakness, and atrophy, but also affects other tissues and systems, such as the heart and central nervous system. Despite some studies reporting therapeutic strategies for DM1, many issues remain unsolved, such as the contribution of metabolic and mitochondrial dysfunctions to DM1 pathogenesis. Therefore, it is crucial to identify molecular target candidates associated with metabolic processes for DM1. In this study, resorting to a bibliometric analysis, articles combining DM1, and metabolic/metabolism terms were identified and further analyzed using an unbiased strategy of automatic text mining with VOSviewer software. A list of candidate molecular targets for DM1 associated with metabolic/metabolism was generated and compared with genes previously associated with DM1 in the DisGeNET database. Furthermore, g:Profiler was used to perform a functional enrichment analysis using the Gene Ontology (GO) and REAC databases. Enriched signaling pathways were identified using integrated bioinformatics enrichment analyses. The results revealed that only 15 of the genes identified in the bibliometric analysis were previously associated with DM1 in the DisGeNET database. Of note, we identified 71 genes not previously associated with DM1, which are of particular interest and should be further explored. The functional enrichment analysis of these genes revealed that regulation of cellular metabolic and metabolic processes were the most associated biological processes. Additionally, a number of signaling pathways were found to be enriched, e.g., signaling by receptor tyrosine kinases, signaling by NRTK1 (TRKA), TRKA activation by NGF, PI3K-AKT activation, prolonged ERK activation events, and axon guidance. Overall, several valuable target candidates related to metabolic processes for DM1 were identified, such as NGF, NTRK1, RhoA, ROCK1, ROCK2, DAG, ACTA, ID1, ID2 MYOD, and MYOG. Therefore, our study strengthens the hypothesis that metabolic dysfunctions contribute to DM1 pathogenesis, and the exploitation of metabolic dysfunction targets is crucial for the development of future therapeutic interventions for DM1. © 2023 by the authors.",TestAnalysis
"Introduction: Brain tumors cause morbidity and mortality in part through peritumoral brain edema. The current main treatment for peritumoral brain edema are corticosteroids. Due to the increased recognition of their side-effect profile, there is growing interest in finding alternatives to steroids but there is little formal study of animal models of peritumoral brain edema. This study aims to summarize the available literature. Methods: A systematic search was undertaken of 5 literature databases (Medline, Embase, CINAHL, PubMed and the Cochrane Library). The generic strategy was to search for various terms associated with “brain tumors”, “brain edema” and “animal models”. Results: We identified 603 reports, of which 112 were identified as relevant for full text analysis that studied 114 peritumoral brain edema animal models. We found significant heterogeneity in the species and strain of tumor-bearing animals, tumor implantation method and edema assessment. Most models did not produce appreciable brain edema and did not test for observable manifestations thereof. Conclusion: No animal model currently exists that enable the investigation of novel candidates for the treatment of peritumoral brain edema. With current interest in alternative treatments for peritumoral brain edema, there is an unmet need for clinically relevant animal models. © 2023, The Author(s).",TestAnalysis
"Background The majority of Nepalese people are involved in farming. However, due to limited knowledge of zoonoses and poor preventive practices on the part of livestock farmers, vulnerabilities to zoonotic diseases are very high. The main objective of this study was to assess the regional variation in zoonoses-related knowledge and preventive practices of livestock farmers in different ecological regions of Nepal. Material and methods Descriptive cross-sectional quantitative research design was followed in the study. The total sample size was 380 livestock farmers from randomly selected three ecological regions of Nepal. Systematic sampling techniques were applied for data collection. Data were entered into an excel sheet and then imported into Statistical Package for Social Sciences (SPSS) software. The data were calculated using descriptive statistics. Univariate, and bivariate analyses were performed, and the result of the study was presented in the form of text and tables based on their nature. Results Of the studied six zoonotic diseases, most of the respondents (95.8%) knew about zoonotic bird flu; 90.7% of them, were about rabies; and 54.2% knew about swine flu. However, a few respondents knew about bovine tuberculosis, neurocysticercosis, and brucellosis. Ecolog-ically, the highest number of respondents in Nawalpur had knowledge of rabies (95.3%), and swine flu (61.6%), whereas 98.3% of them had knowledge of avian influenza in Tana-hun; and 12.5% of neurocysticercosis in Manang. Regarding zoonoses preventive practices such as regular hand washing with soap water, mask-wearing, gloves, boots, the respon-dents’ representation of 60.8%, 6.6%, 1.8%, and 1.3% respectively in such practices show that although these are easy and cost-effective, personal protective equipment (PPE), such preventive practices were extremely underperformed. Not only that, only 12% of respondents maintain a standard distance (>15m.) between their house and shed. Similarly, 17% still consumed meat from sick animals, and vaccination of livestock was also found poor coverage (36%) in the study. Conclusions Livestock farmers need to be more knowledgeable about many common zoonotic diseases, and their preventive practices still need improvement, with significant regional variation in the study. This has invited various zoonosis threats for them. Therefore, it is recommended that the interventional programs related to common zoonoses be conducted for livestock farmers to solve the problem. © 2023 Bagale et al.",TestAnalysis
"Background and purpose: The results of various studies on the effect of evening primrose oil (EPO) on cervical ripening are controversial. The purpose of this systematic review and meta-analysis was to assess the effect of EPO on cervical ripening and birth outcomes. Materials and methods: The Cochrane Library, Embase, PubMed, Scopus, Web of Science and Persian databases were searched for studies published from the inception of the databases up to February 2021 (search updated in May 2022). Full-text articles published in English or other languages, randomized controlled trials, and quasi experimental studies with control group were included. Studies published in form of conference proceedings, and those whose full texts were not available, as well as studies with control groups receiving other treatments for cervical ripening, and those in which the intervention group received drugs besides EPO were all excluded. The Cochrane handbook was used to determine the risk of bias of the included studies. All data were analyzed using Review Manager 5.4 and reported in forest plots. Results: Seven trials involving 920 women were included in the meta-analysis. In five studies, including 652 participants, cervical ripening was evaluated using Bishop score. The use of EPO was found to significantly improved Bishop score (MD = 3.23; 95% CI: 3.17, 3.29). The meta-analysis showed no significant differences between two comparison groups in terms of 1-min Apgar score and length of the second stage of labor. However, the two groups were significantly different in terms of their 5-min Apgar score and the time interval between administration of EPO and birth. Based on subgroup analysis by route of administration, both vaginal and oral use of EPO increased Bishop score significantly in the intervention group compared to the placebo group. Conclusion: This study showed that using EPO in term and post-term pregnant women was clinically effective in improving their Bishop score. © 2023",TestAnalysis
"The world is facing several challenges, and the problem of sustainable development is one of the most important. It is worth considering that European countries are playing a significant role as pioneers in building a sustainable world, such as those promises made by signing the Paris Agreement and European Taxonomy. To achieve ambitious targets within sustainable development, a huge amount of capital is necessary, while financial and capital market participants are expected to demonstrate a high level of engagement in the domain of sustainability. Facing growing interest and demand, a relatively new product—the ESG (environmental, social, and governance) investment fund—was introduced. Scientific literature is providing some controversial views regarding the overall evaluation of this product. Therefore, additional research providing different angles would contribute to a better understanding. This study examines European ESG funds in the energy sector, from the perspective of news flows and investors. It is worth noting that the authors use the word “European” to refer to members of the European Union (EU). The paper consists of the following parts. In the introduction, the current state of this issue is discussed. The following section offers a literature review and a news flow analysis that contributes to a deeper understanding of these issues. A description of the methodology applied for the data analysis follows this, and the final section presents the research results and conclusions. The authors apply statistical analysis and the Carhart model to determine the differences in the performance of the ESG and conventional funds and use their own tool for text analysis to examine the relevance of the topic of ESG to attract client interest. The authors claim that the performance of the European ESG equity funds do not show a statistically significant difference from the non-ESG equity funds in the majority of the periods examined. The application of the adjusted Carhart model demonstrates that the factor of sustainability has a non-significant and negative effect on the fund performance. Finally, the authors highlight the urgent necessity for the unified usage of keywords and terminology, such as “ESG”, “sustainability”, etc., to ensure comparison and attribution possibilities. © 2023 by the authors.",TestAnalysis
"Objective To develop a summary format of clinical practice guideline (CPG) recommendations to improve understandability among health care professionals. Methods We developed a summary format based on current research and used the ""Think Aloud""technique in one-on-one cognitive interviews to iteratively improve it. Interviews of health care professionals from Children's Oncology Group-member, National Cancer Institute Community Oncology Research Program sites were conducted. After every five interviews (a round), responses were reviewed, and changes made to the format until it was well understood and no new, substantive suggestions for revision were raised. We took a directed (deductive) approach to content analysis of the interview notes to identify concerns related to recommendation summary usability, understandability, validity, applicability and visual appeal. Results During seven rounds of interviews with 33 health care professionals, we identified important factors that influenced understandability. Participants found understanding weak recommendations more challenging than strong recommendations. Understanding was improved when the term 'conditional' recommendation was used instead of 'weak' recommendation. Participants found a Rationale section to be very helpful but desired more information when a recommendation entailed a practice change. In the final format, the recommendation strength is clearly indicated in the title, highlighted, and defined within a text box. The rationale for the recommendation is in a column on the left, with supporting evidence on the right. In a bulleted list, the Rationale section describes the benefits and harms and additional factors, such as implementation, that were considered by the CPG developers. Each bullet under the supporting evidence section indicates the level of evidence with an explanation and the supporting studies with hyperlinks when applicable. Conclusions A summary format to present strong and conditional recommendations was created through an iterative interview process. The format is straightforward, making it easy for organizations and CPG developers to use it to communicate recommendations clearly to intended users.  © 2023 Santesso et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Neck pain is the fourth leading cause of disability, and is the most common musculoskeletal disorder. High-heel shoes, one of the significant identities of females, cause pain in the neck as well as in feet and ankle regions. The current narrative review was planned to explore evidence to highlight the biomechanical factors of high-heel shoes as the source of neck pain, which mostly remains undiagnosed. PubMed and Google Scholar search engines were explored for full text of research articles published in English language from 2016 to 2021. Of the 82 studies initially found, 22(27%) were shortlisted for full-text assessment, and, of them, 6 (27.27%) were selected for detailed analysis. Despite other contributing factors, kinematics and kinetics should be considered primarily during neck pain management. Based on best available evidence, high heels increase the individual's height, but result in significant decrease in trunk flexion. Evidence also suggests that the type and width of heels do not affect as much as the height of the heels in the context of pain and functional issues in the cervical region. © 2023 Pakistan Medical Association. All rights reserved.",TestAnalysis
"Background: The delivery of quality, safe, and patient-centered care is foundational for professional practice. The primary nursing model allows nurses to have excellent knowledge about patients and families and to plan and coordinate care from admission to discharge, with better management of health situations. Nurses play a crucial role in improving patients’ outcomes, namely those sensitive to nursing care. The knowledge of the relationship between the primary nursing model and the nursing-sensitive outcomes provides new scientific evidence that strengthens the relevance of this nursing care organization model in the inpatients’ health outcomes. This systematic review describes the relationship between nurse-sensitive inpatients’ outcomes and the primary nursing care model. Methods: A systematic review was conducted with a narrative synthesis, and the following databases were searched: MEDLINE, CINAHL, Web of Science, Nursing & Allied Health Collection, SciELO Collections, and Cochrane. Results: A total of 22 full texts were assessed, of which five were included in the study according to the selection criteria. The analysis results indicated that the primary nursing care model was related to nursing-sensitive patient safety outcomes. Patients’ experience was also considered a nursing-sensitive outcome, namely in the satisfaction with nursing care. Conclusion: The negative outcomes are clearly related to the primary nursing care model. There is scarce research that relates primary nursing to positive outcomes, such as patients’ functional status and self-care abilities, and more studies are needed. © 2023 by the authors.",TestAnalysis
"Aspect-based sentiment analysis (ABSA) aims to identify the sentiment of an aspect in a given sentence and thus can provide people with comprehensive information. However, many conventional methods need help to discover the linguistic knowledge implicit in sentences. Additionally, they are susceptible to unrelated words. To improve the performance of the model in the ABSA task, a multi-task sentiment analysis model based on Bidirectional Encoder Representation from Transformers (BERT) and a Knowledge Graph (SABKG) is proposed in this paper. Expressly, part-of-speech information is incorporated into the output representation of BERT, thereby obtaining textual semantic information through linguistic knowledge. It also enhances the textual representation to identify the aspect terms. Moreover, this paper constructs a knowledge graph of aspect and sentiment words. It uses a graph neural network to learn the embeddings in the triplet of “aspect word, sentiment polarity, sentiment word”. The constructed graph improves the contextual relationship between the text’s aspect and sentiment words. The experimental results on three open datasets show that the proposed model can achieve the most advanced performance compared with previous models. © 2023 by the authors.",TestAnalysis
"Background: Conflicting findings have described the association between prolonged heart rate-corrected QT interval (QTc) and cardiovascular disease. Aims: To identify articles investigating the association between QTc and cardiovascular disease morbidity and mortality, and to summarize the available evidence for the general and type 2 diabetes populations. Methods: A systematic search was performed in PubMed and Embase in May 2022 to identify studies that investigated the association between QTc prolongation and cardiovascular disease in both the general and type 2 diabetes populations. Screening, full-text assessment, data extraction and risk of bias assessment were performed independently by two reviewers. Effect estimates were pooled across studies using random-effect models. Results: Of the 59 studies included, 36 qualified for meta-analysis. Meta-analysis of the general population studies showed a significant association for: overall cardiovascular disease (fatal and non-fatal) (hazard ratio [HR] 1.68, 95% confidence interval [CI] 1.33–2.12; I2 = 69%); coronary heart disease (fatal and non-fatal) in women (HR 1.27, 95% CI 1.08–1.50; I2 = 38%; coronary heart disease (fatal and non-fatal) in men (HR 2.07, 95% CI 1.26–3.39; I2 = 78%); stroke (HR 1.59, 95% CI 1.29–1.96; I2 = 45%); sudden cardiac death (HR 1.60, 95% CI 1.14–2.25; I2 = 68%); and atrial fibrillation (HR 1.55, 95% CI 1.31–1.83; I2 = 0.0%). No significant association was found for cardiovascular disease in the type 2 diabetes population. Conclusion: QTc prolongation was associated with risk of cardiovascular disease in the general population, but not in the type 2 diabetes population. © 2023 The Authors",TestAnalysis
"The treatment of locally advanced rectal cancer (LARC) requires a multimodal approach combining neoadjuvant radiotherapy or chemoradiotherapy (CRT) and surgery. Predicting tumor response to CRT can guide clinical decision making and improve patient care while avoiding unnecessary toxicity and morbidity. Circulating biomarkers offer both the advantage to be easily accessed and followed over time. In recent years, biomarkers such as proteins, blood cells, or nucleic acids have been investigated for their predictive value in oncology. We conducted a comprehensive literature review with the aim to summarize the status of circulating biomarkers predicting response to CRT in LARC. Forty-nine publications, of which forty-seven full-text articles, one review and one systematic review, were retrieved. These studies evaluated circulating markers (CEA and CA 19-9), inflammatory biomarkers (CRP, albumin, and lymphocytes), hematologic markers (hemoglobin and thrombocytes), lipids and circulating nucleic acids (cell-free DNA [cfDNA], circulating tumor DNA [ctDNA], and microRNA [miRNA]). Post-CRT CEA levels had the most consistent association with tumor response, while cfDNA integrity index, MGMT promoter methylation, ERCC-1, miRNAs, and miRNA-related SNPs were identified as potential predictive markers. Although circulating biomarkers hold great promise, inconsistent results, low statistical power, and low specificity and sensibility prevent them from reliably predicting tumor response following CRT. Validation and standardization of methods and technologies are further required to confirm results. © 2023 by the authors.",TestAnalysis
"Background The internet has become an increasingly important resource for health information, especially for lay people. However, the information found does not necessarily comply with the user’s health literacy level. Therefore, it is vital to (1) identify prominent information providers, (2) quantify the readability of written health information, and (3) to analyze how different types of information sources are suited for people with differing health literacy levels. Objective In previous work, we showed the use of a focused crawler to “capture” and describe a large sample of the “German Health Web”, which we call the “Sampled German Health Web” (sGHW). It includes health-related web content of the three mostly German speaking countries Germany, Austria, and Switzerland, i.e. country-code top-level domains (ccTLDs) “.de”, “.at” and “.ch”. Based on the crawled data, we now provide a fully automated readability and vocabulary analysis of a subsample of the sGHW, an analysis of the sGHW’s graph structure covering its size, its content providers and a ratio of public to private stakeholders. In addition, we apply Latent Dirichlet Allocation (LDA) to identify topics and themes within the sGHW. Methods Important web sites were identified by applying PageRank on the sGHW’s graph representation. LDA was used to discover topics within the top-ranked web sites. Next, a computer-based readability and vocabulary analysis was performed on each health-related web page. Flesch Reading Ease (FRE) and the 4th Vienna formula (WSTF) were used to assess the readability. Vocabulary was assessed by a specifically trained Support Vector Machine classifier. Results In total, n = 14,193,743 health-related web pages were collected during the study period of 370 days. The resulting host-aggregated web graph comprises 231,733 nodes connected via 429,530 edges (network diameter = 25; average path length = 6.804; average degree = 1.854; modularity = 0.723). Among 3000 top-ranked pages (1000 per ccTLD according to PageRank), 18.50%(555/3000) belong to web sites from governmental or public institutions, 18.03% (541/3000) from nonprofit organizations, 54.03% (1621/3000) from private organizations, 4.07% (122/3000) from news agencies, 3.87% (116/3000) from pharmaceutical companies, 0.90% (27/3000) from private bloggers, and 0.60% (18/3000) are from others. LDA identified 50 topics, which we grouped into 11 themes: “Research & Science”, “Illness & Injury”, “The State”, “Healthcare structures”, “Diet & Food”, “Medical Specialities”, “Economy”, “Food production”, “Health communication”, “Family” and “Other”. The most prevalent themes were “Research & Science” and “Illness & Injury” accounting for 21.04% and 17.92% of all topics across all ccTLDs and provider types, respectively. Our readability analysis reveals that the majority of the collected web sites is structurally difficult or very difficult to read: 84.63% (2539/3000) scored a WSTF ≥ 12, 89.70% (2691/3000) scored a FRE ≤ 49. Moreover, our vocabulary analysis shows that 44.00% (1320/3000) web sites use vocabulary that is well suited for a lay audience. Conclusions We were able to identify major information hubs as well as topics and themes within the sGHW. Results indicate that the readability within the sGHW is low. As a consequence, patients may face barriers, even though the vocabulary used seems appropriate from a medical perspective. In future work, the authors intend to extend their analyses to identify trustworthy health information web sites. © 2023 Zowalla et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"This paper aims to provide a systematic literature review of sustainable corporate governance to prevent fraud through the tone at the top perspective. In recent years, studies on corporate governance and sustainability have considerably increased. The main aspects of the intersection of these fields were analyzed, especially considering the role of fraud and risk management. Indeed, corporate fraud can hinder corporate sustainability goals. However, to remove fraudulent behavior, rules of conduct, formal recommendations, or the implementation of business ethics programs are often insufficient. In this sense, corporate ethics linked to governance has been referred to as “tone at the top”. Given the significant progress in this area and the lack of a generally accepted theory, an exhaustive organization of the research is needed. Based on these assumptions, this study employed text network analysis to systematically analyze the research contributions collected from the Scopus database for the period 1990–2021. This study establishes networks using the main information of scientific contributions, such as “Abstract”, “Title”, and “Keywords”, and performs analyses, such as co-occurrence and content analyses. The main findings highlight the growing importance of corporate governance in sustainability and propose the emerging role of tone at the top as one of the main drivers of corporate governance sustainability to prevent fraud. We conclude by suggesting some insights derived from the study. The results could be useful for both the academic and professional communities, offering an opportunity for future research. © 2023 by the authors.",TestAnalysis
"2022-00482 Trinidad et al. p. 1804, 1807 In this article, a coauthor’s name was misspelled. The name has been corrected from Rasnik to Rasnick. Also, in exhibit 1, the column “Transportation” should not have a checkmark in the row “Area Deprivation Index.” The text describing the exhibit has been corrected to read “four of fifteen” instead of “five of fifteen” indices. The article has been corrected online. 2019-00859 Barnett et al. p. 2048, 2051, 2052 In this article, a coding error resulted in an overestimate of the number of counties that gained access to their first buprenorphine-waivered provider in 2019. In the abstract, the number of counties is 165, not 285, representing 3.4 million residents, not 5.7 million. In the second paragraph of the section “Study Results” and in exhibit 1, these and several other numbers have been corrected. The error did not affect the article’s results; the conclusions of the analysis remain unchanged. The article has been corrected online. © 2023, Project HOPE. All rights reserved.",TestAnalysis
"Experiencing pain and insufficient relief can be devastating and negatively affect a patient’s quality of life. Developments in oncology such as new treatments and adjusted pain management guidelines may have influenced the prevalence of cancer pain and severity in patients. This review aims to provide an overview of the prevalence and severity of pain in cancer patients in the 2014–2021 literature period. A systematic literature search was performed using the databases PubMed, Embase, CINAHL, and Cochrane. Titles and abstracts were screened, and full texts were evaluated and assessed on methodological quality. A meta-analysis was performed on the pooled prevalence and severity rates. A meta-regression analysis was used to explore differences between treatment groups. We identified 10,637 studies, of which 444 studies were included. The overall prevalence of pain was 44.5%. Moderate to severe pain was experienced by 30.6% of the patients, a lower proportion compared to previous research. Pain experienced by cancer survivors was significantly lower compared to most treatment groups. Our results imply that both the prevalence of pain and pain severity declined in the past decade. Increased attention to the assessment and management of pain might have fostered the decline in the prevalence and severity of pain. © 2023 by the authors.",TestAnalysis
"The amplified development in science and technology has made the lifestyle of human beings fast-paced but much easier at the same time when compared to the previous eras. It is also notable that man has turned the impossible into possible with such advanced technology in various fields such as medicine, education, commerce, and so on. Human beings find it hard to communicate with their family members, friends, and peers because of their hurried mechanical life. Under such circumstances, it is obvious that man does not find time to harmonize with nature. The ancient Hindu writings portray nature as God and emphasize the fact that the worship of nature by humans and treating other living beings with respect maintained the ecological balance. Climate change and the proliferation of numerous pathogens are currently the greatest worries. Such threat-posing viruses not only place human lives in peril but also upset the ecosystem's balance. This paper analyses the select text Mahabharata whi ch is both an ancient literary text and a religious book to highlight the fact that the current ecological imbalance is the result of human indifference to nature. The study throws light on the narratives found in the select text to argue the same and puts forth the measures to attain environmental harmony. © 2023 ACADEMY PUBLICATION.",TestAnalysis
"Web tables are essential for applications such as data analysis. However, web tables are often incomplete and short of some critical information, which makes it challenging to understand the web table content. Automatically predicting column types for tables without metadata is significant for dealing with various tables from the Internet. This paper proposes a CNN-Text method to deal with this task, which fuses CNN prediction and voting processes. We present data augmentation and synthetic column generation approaches to improve the CNN’s performance and use extracted text to get better predictions. The experimental result shows that CNN-Text outperforms the baseline methods, demonstrating that CNN-Text is well qualified for the table column type prediction. © 2023 by the authors.",TestAnalysis
"Migrant and refugee youth (MRY) in Australia face specific experiences that inform their sexual and reproductive health and rights (SRHR). Migrant and refugee communities experience poor health outcomes and low service uptake. Additionally, youth are vulnerable to poor sexual health. This review examines the understandings and perspectives of MRY. A systematic review was conducted as per Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. The protocol is registered with PROSPERO: CRD42021241213. Nine databases were systematically searched. Inclusion criteria specified literature reporting on migrant and/or refugee youth perspectives and attitudes towards sexual and reproductive health; peer-reviewed qualitative, mixed-methods and/or quantitative studies or grey literature reports; records using Australian research; literature published in English between January 2000 and March 2021. Records that did not report on MRY and did not examine participant views or perspectives; were abstract-only, reviews, pamphlets, protocols, opinion pieces or letters; did not include Australian research; were published before 2000 and/or in a language other than English were excluded. Two reviewers screened titles, abstracts and full-text articles. The Mixed Method Appraisal Tool was used to assess studies' methodological quality. Thematic synthesis methods guided data extraction and analysis. Twenty-eight papers were included in the final review. Three themes were identified in MRY constructions of SRHR: (1) experiences of silence and shame; (2) understandings of and responses to SRHR risks; (3) navigation of relationships and sexual activity. Socioecological factors shaped MRY perspectives at individual, interpersonal, institutional and societal levels. Societal factors and interpersonal relationships significantly influenced decision making.",TestAnalysis
"Objective: Patient positioning is a matter of ongoing debate in the surgical treatment of vestibular schwannoma (VS). Main endpoints of this discussion are preservation of facial nerve functioning, extent of resection, and complications. In this meta-analysis, we aim to investigate the impact of patient positioning on VS surgery via the retrosigmoid approach. Methods: We searched for eligible comparative trials on PubMed, Cochrane library, and Web of Science. Positioning groups were compared regarding facial nerve outcome, extent of resection, postoperative hydrocephalus, postoperative CSF leaks, perioperative venous air embolism, and perioperative mortality. Two groups of positions were defined, and the following positions were allocated to those groups: (1) Semi-sitting and Sitting-position; (2) Lateral position, supine position with extensive head rotation, lateral oblique (=Fukushima/Three-quarter prone), and park-bench position. Results: From 374 full-text screenings, 7 studies met the criteria and were included in our meta-analysis comprising 1640 patients. Our results demonstrate a significantly better long-term (≥6 months) outcome of the facial nerve after VS surgery in the semi-sitting positioning (OR: 1.49, 95%CI: 1.03-2.15, p = 0.03). Positioning did not influence the extent of resection, rate of postoperative CSF leaks, and the presence of a postoperative hydrocephalus. Overall incidence of venous air embolisms was significantly associated with VS surgery in sitting positioning (OR: 6.77, 95% CI: 3.66-12.54, p < 0.00001). Perioperative mortality was equal among both positioning groups. Conclusion: Semi-sitting positioning seems to be associated with an improved facial nerve outcome after VS surgery via the retrosigmoid approach. Venous air embolisms are significantly more often observed among VS patients who underwent surgery in the sitting position, but the perioperative mortality is equal in both positioning groups. Both positioning groups are a safe procedure. Multicentric prospective randomized trials are needed to evaluate the risk-benefit ratio of each positioning in VS surgery via the retrosigmoid approach. Copyright © 2023 Vychopen, Arlt, Güresir and Wach.",TestAnalysis
"For decades, Fourth Amendment protections have turned on “reasonable expectations of privacy.” But a new era may be dawning. There is growing interest among judges and scholars in turning away from privacy toward property or positive law as the touchstone for Fourth Amendment protections. Yet many questions remain about how that approach should work, such as where judges should look for positive law and precisely what role positive law should play in Fourth Amendment analysis. This Article answers those questions, and in so doing lays forth a new, comprehensive theory of the Fourth Amendment. We argue that courts should interpret the Fourth Amendment’s protections by looking to “general law”—the common law under the control of no particular sovereign. Courts looking to general law would draw on ancient property concepts such as trespass, license, and bailments in determining the scope of protections. But they would also draw on custom, social practices, and modern legal developments to identify and flesh out common-law rules unknown at the Founding. The general-law approach has numerous advantages over competitor theories. It makes better sense of the Fourth Amendment’s text and has deeper roots in its history. It is surprisingly easy to reconcile with a great deal of Fourth Amendment doctrine, while also suggesting important refinements in various areas. And it gives courts the flexibility to protect Fourth Amendment values in a changing world while also structuring and guiding the judicial task more than an untethered inquiry into privacy expectations. Private law, then, holds the key to understanding the Fourth Amendment’s limits on public power. © 2023, Yale Journal on Regulation. All rights reserved.",TestAnalysis
"In the originally published version of this manuscript, in Table 3 of the above manuscript, an error was identified with how the table was generated from the underlying databases that resulted in small errors (each <1% in magnitude) in the frequencies and corresponding percentages of: total cases, age-adjusted incidence, sex, and race/ethnicity for several tumor types. Additionally affected were the median ages at diagnoses (with interquartile ranges [IQR]) for these tumor types. Notably, the correct median age at diagnosis for WHO grade 4 IDH-mutant astrocytomas is: 47 years (IQR: 36-60). This error also affected the total count of “Glioblastoma” in Supplemental Table 1, resulting in an error of <3%. The remaining analyses of the manuscript were unaffected, the manuscript’s text was unaffected, and the manuscript’s conclusions remain unchanged. The corrected Tables are displayed below, with the corrected results denoted with bolding. The authors apologize for this error that has now been corrected. (Table Presented). © The Author(s), 2023.",TestAnalysis
"This systematic review and meta-analysis was aimed to investigate the conscious sedation efficiency in patients with intellectual disability undergoing dental treatment (PROSPERO CRD42022344292). Four scientific databases were searched by ad-hoc prepared strings. The literature search yielded 731 papers: 426 were selected, 42 were obtained in full-text format, and 4 more were added after hand searching. Fourteen studies were finally included, 11 of which were included in the meta-analysis (random effect model). A high heterogeneity in the drugs used and route of administration was retrieved. Success rate, occurrence of side effects, and deep sedation occurrence were combined to give an overall efficiency of each drug. N2O/O2 reported the highest efficiency (effect size = 0.90; p < 0.01) and proved to be more efficient when used alone. Nine papers reported a success rate of sedation of 80% or more. The prevalence of side effects (6 studies) ranged from 3% to 40%. Enteral and parenteral benzodiazepines showed the same overall efficiency (effect size = 0.86). No meta-analysis has yet been conducted to define the most effective and safest way to achieve conscious sedation in patients with intellectual disability; nitrous oxide appears to be the best choice to perform conscious sedation in patients with intellectual disability undergoing dental treatment. © 2023 by the authors.",TestAnalysis
"In Denmark, religious behavior is usually very private. Little is known of religious and spiritual needs of patients and family during critical illness and hospitalization. We aimed to explore contemporary thoughts and prayers related to critical illness and hospitalization expressed in hospital chapel Guest Books. Qualitative content analysis of written texts was performed on Guest Books completed from 2005–2019. We identified the main themes of health and illness, life and death, and science and religion. Visitors welcomed the Guest Books as a place to express religious and spiritual thought, even in a nominally nonreligious society. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TestAnalysis
"China’s religious social services complement the statutory welfare. Clarifying the situations and characteristics of different types of religious social services is conducive to promoting their better integration into public welfare. With the help of existing policy texts, research documents, and website data, this paper employs the thematic framework analysis method to analyze texts and documents and uses NVivo12 and SPSS26 to analyze website data. We explore the similarities and differences between contemporary Chinese Protestant social services and Buddhist social services from the perspectives of the service program, service organizations, and service resources, starting from multiple dimensions such as vertical and horizontal, similarity and difference. The main findings include the following: (a) In terms of service programs, Protestant social services are more inclusive than Buddhist social services and more public in terms of participant selection, religious environment, and the use of spiritual methods. Protestant social services are more open in terms of service value and public expression, while Buddhist social services are more localized and are politically consistent with the government. (b) In terms of service organizations, Protestant social services and Buddhist social services are based on three main types of legal persons. Protestant social services were the first to register organizational legal persons. Protestant social organizations differentiated into special service institutions and have core organizations with strong mobilization capabilities (CCC/TSPM). There is little difference between Protestant and Buddhist social services in private non-enterprise units and foundations (transparency index, business scope). (c) In terms of service resources, both Protestant and Buddhist social services rely on donations. The sources of funds for Protestant social services are more international, diversified, and market-oriented. In terms of government resource acquisition, Protestant social services actively “adapt”, while Buddhist social services passively “rely”. © 2023 by the authors.",TestAnalysis
"A quantitative X-ray Photoelectron Spectroscopy (XPS) study has been undertaken on different experimental data sets of ZrN thin films deposited using reactive Bipolar Pulsed Dual-Magnetron Sputtering (BPDMS) on silicon/stainless steel substates, to obtain dense, pure and homogeneous coatings, free from morphological defects. Zirconium nitride (ZrN) occupies a central role within the class of transition metal nitrides (TMN) for its excellent properties, such as high hardness, low resistivity and chemical/thermal stability when its stoichiometric ratio is 1:1. Many deposition techniques, reported in the literature, tried to obtain oxygen-free and defect-free structures, but they proved a hard task. In this paper it has been demonstrated, using quantitative XPS, that stoichiometric, pure and homogeneous ZrN films have been grown at certain deposition conditions, optimized also via optional accessories mounted on the deposition apparatus. Almost all the films considered for microanalytical characterization resulted as completely oxygen-free, pure (with a lowest-detection limit of 1%) and homogeneous. Apart from these features, a stoichiometric ratio (N/Zr) close to one was calculated for six samples of the ten investigated, with a precision of ± 0.01. In this frame XPS, widely known for being a highly surface-sensitive technique (average depth resolution of 20–30 Å), and powerful for characterizing the chemical composition of materials, has been extensively employed to extract information both in the surface regions and in depth. A cluster ion beam Ar+ 2500 facility on our main XPS chamber has not proved adequate for depth-profiling acquisitions. Therefore, Ar+ ion sputtering was performed instead. To the best of our best knowledge, the results achieved in the present paper possess a level of accuracy never reached before. Rigorous calibration procedures before and during experimental spectrum acquisitions and a careful and scrupulous data processing using software CasaXps v.2.3.24PR1 were carried out to ensure a low percentage error. Progress has also been made for shake-up satellite extraction and interpretation from Zr 3d high-resolution spectra with the help of the literature milestones reported in the text. The total absence of oxygen inside most of the films prevented the formation of zirconium oxide compounds during deposition, which are generally resonant with the binding energy of the shake-up satellite peaks and hide them. A little summary about the experimental shake-up satellite peaks revealed and extracted from the Zr 3d region, after Shirley background subtraction and data processing, will be presented in the last subparagraph of the “Results” section for the ZrN samples analyzed. Figures of Zr 3d deconvoluted spectra for in-depth area analysis have been reported. The quantitative satellite contribution to the Zr 3d total area would not be included in stoichiometric calculations. © 2023 by the authors.",TestAnalysis
"With increasing costs of healthcare in England and Wales following the COVID-19 pandemic, finding alternatives to traditional medical interventions is more important than ever. Social prescribing provides a way of addressing health and well-being through using non-medical methods that may help relieve costs to the NHS. Evaluating interventions, such as social prescribing, which have high social (but not easily quantifiable) value, can be problematic. Social return on investment (SROI) is a method of assigning monetary values to both social value as well as traditional assets, so provides a way of evaluating social prescribing initiatives. This protocol outlines the steps that will be taken in a systematic review of the SROI literature surrounding social prescribing-type integrated health and social care interventions based in the community in England and Wales. Online academic databases such as PubMed Central, ASSIA and Web of Science will be searched, as will grey literature sources such as Google Scholar, the Wales School for Social Prescribing Research (WSSPR) and Social Value UK. Titles and abstracts from the articles returned by the searches will be reviewed by one researcher. Those selected for full text review will be independently reviewed and compared by two researchers. Where the researchers disagree a third reviewer will help resolve any differences. Information collected will include identifying stakeholder groups, assessing the quality of SROI analyses, identifying intended and unintended changes of social prescribing interventions, and comparing social prescribing initiatives in terms of SROI costs and benefits. Quality assessment will be independently conducted on the selected papers by two researchers. The researchers will discuss to obtain consensus. Where there is disagreement, a third researcher will resolve these cases. A pre-existing quality framework will be developed and used to assess the quality of the literature. © 2023 Hopkins et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"This study assumes that linguistic structure plays a significant role in comprehending sentences and texts. It also assumes that the process of learning requires inferences to make connections across and within the local and global discourse contexts. To establish these connections, there is a need of integrating information from prior content of discourse and knowledge or from the reader's schemata to build a coherent memory that represents the events and concepts which describe the texts. To that end, the paper reviews studies on depth-first versus breadth-first models, adopted by the parsers, which address the linguistic structure in sentence and text comprehension. It further examines how the readers’ or listeners’ long-term memory and mental models affect the sentence and text comprehension. The findings of the study show that vocabulary depth and breadth are two important constructs to consider while assessing higher-level processing of reading comprehension. It also shows that having a comprehensive understanding of the gradations of the meaning of a word in a variety of contexts will permit the readers to develop a better understanding of the text, and in turn, to better express themselves. © 2023 ACADEMY PUBLICATION.",TestAnalysis
"With the advent of the Internet era, Chinese users tend to choose to express their opinions on social media platforms represented by Sina Weibo. The changes in people’s emotions toward cities from the microblogging texts can reflect the image of cities presented on mainstream social media, and thus target a good image of cities. In this paper, we collected microblog data containing “Shanghai” from 1 January 2019 to 1 September 2022 by Python technology, and we used three methods: Term Frequency-Inverse Document Frequency keyword statistics, Latent Dirichlet Allocation theme model construction, and sentiment analysis by Zhiwang Sentiment Dictionary. We also explore the impact of the COVID-19 epidemic on Shanghai’s urban image in the context of the “Shanghai Territorial Static Management”, an important public opinion topic during the COVID-19 epidemic. The results of the study show that the “Shanghai-wide static management” of COVID-19 epidemic has significantly reduced the public’s perception of Shanghai and negatively affected the city’s image. By analyzing the data results, we summarize the basic characteristics of Shanghai’s city image and provide strategies for communicating Shanghai’s city image in the post-epidemic era. © 2023 by the authors.",TestAnalysis
"Several key challenges are faced during sentiment analysis. One major problem is determining the sentiment of complex sentences, paragraphs, and text documents. A paragraph with multiple parts might have multiple sentiment values. Predicting the overall sentiment value for this paragraph will not produce all the information necessary for businesses and brands. Therefore, a paragraph with multiple sentences should be separated into simple sentences. With a simple sentence, it will be effective to extract all the possible sentiments. Therefore, to split a paragraph, that paragraph must be properly punctuated. Most social media texts are improperly punctuated, so separating the sentences may be challenging. This study proposes a punctuation-restoration algorithm using the transformer model approach. We evaluated different Bidirectional Encoder Representations from Transformers (BERT) models for our transformer encoding, in addition to the neural network used for evaluation. Based on our evaluation, the RobertaLarge with the bidirectional long short-term memory (LSTM) provided the best accuracy of 97% and 90% for restoring the punctuation on Amazon and Telekom data, respectively. Other evaluation criteria like precision, recall, and F1-score are also used. © 2023 by the authors.",TestAnalysis
"The risk of vertical transmission from breastfeeding with HIV (BFHIV) has been found to be very low in optimal scenarios with sustained maternal viral suppression during pregnancy and postpartum. Medical providers must account for the risk of this serious adverse event alongside parental autonomy, breastfeeding benefits, and patient values. To assess provider practices, comfort, and challenges with BFHIV, an online mixed-method survey was sent to breastfeeding and HIV provider listservs from June to July 2021. The target population was US medical professionals from diverse practice settings with experience in clinical issues associated with BFHIV, including physicians, advanced practice providers, nurses, and lactation consultants. Data analysis utilized nonparametric hypothesis testing, ordinal regression, and reflexive thematic analysis. Most providers reported counseling pregnant people with HIV on infant feeding choices, but fewer specifically endorsed counseling about breastfeeding. Of 84 unique institutions identified by 100 included respondents, 10% had an institutional protocol supporting BFHIV. Institutional protocols were associated with higher degrees of provider comfort with BFHIV in optimal scenario clinical vignettes. Providers perceived that White patients faced fewer BFHIV barriers than patients with other racial identities. Discomfort balancing the goals to protect infants from infection risk and support the parent's role in infant feeding decisions was a key theme in free text responses; this manifested in a spectrum of management styles ranging from patient's informed choice to paternalism. This study highlights the tension providers navigate regarding BFHIV discussions, calling for patient care guidelines and protocols grounded in risk reduction and respect of patient autonomy. © Allison Lai, et al., 2023; Published by Mary Ann Liebert, Inc. 2023.",TestAnalysis
"Background: In the post-epidemic era, online medical care is developing rapidly, and online doctor teams are attracting attention as a high-quality online medical service model that can provide more social support for patients. Methods: Using online doctor teams on the Haodf.com platform as the research subject, this study investigates the key factors in the process of doctor–patient communication, which affects patients’ emotional well-being. We also explore the different roles played by doctors as leaders and non-leaders in doctor–patient communication. From the perspective of language style, we select representative factors in the process of doctor–patient communication, namely the richness of health vocabulary, the expression of emotions, and the use of health-related terms (including perceptual words and biological words). We extract both team-level and individual-level linguistic communication styles through textual and sentiment analysis methods and empirically analyze their effects on patients’ emotional well-being using multiple linear regression models. Results: The results show that the expression of positive emotions by the team and attention to patients’ perceptions and biological conditions benefit patients’ emotional well-being. Leaders should focus on the emotional expression, whereas non-leaders should focus on the use of perceptual and biological words. Conclusions: This study expands the application of linguistic styles in the medical field and provides a practical basis for improving patients’ emotional well-being. © 2023 by the authors.",TestAnalysis
"Importance: Large-scale data on type-specific human papillomavirus (HPV) prevalence and disease burden worldwide are needed to guide cervical cancer prevention efforts. Promoting the research and application of health care big data has become a key factor in modern medical research. Objective: To examine the prevaccination prevalence of high-risk HPV (hrHPV) and type distribution by cervical cytology grade in Estonia. Design, Setting, and Participants: This cross-sectional study used text mining and the linking of data from electronic health records and health care claims to examine type-specific hrHPV positivity in Estonia from 2012 to 2019. Participants were women aged at least 18 years. Statistical analysis was performed from September 2021 to August 2022. Main Outcomes and Measures: Type-specific hrHPV positivity rate by cervical cytological grade. Results: A total of 11 017 cases of cervical cytology complemented with data on hrHPV testing results between 2012 and 2019 from 66 451 women aged at least 18 years (mean [SD] age, 48.1 [21.0] years) were included. The most common hrHPV types were HPV16, 18, 31, 33, 51 and 52, which accounted for 73.8% of all hrHPV types detected. There was a marked decline in the positivity rate of hrHPV infection with increasing age, but the proportion did not vary significantly based on HPV type. Implementation of nonavalent prophylactic vaccination was estimated to reduce the number of women with high-grade cytology by 50.5% (95% CI, 47.4%-53.6%) and the number with low-grade cytology by 27.8% (95% CI, 26.3%-29.3%), giving an overall estimated reduction of 33.1% (95% CI, 31.7%-34.5%) in the number of women with precancerous cervical cytology findings. Conclusions and Relevance: In this cross-sectional study, text mining and natural language processing techniques allowed the detection of precursors to cervical cancer based on data stored by the nationwide health system. These findings contribute to the literature on type-specific HPV distribution by cervical cytology grade and document that α-9 phylogenetic group HPV types 16, 31, 33, 52 and α-7 phylogenetic group HPV 18 are the most frequently detected in normal-to-high-grade precancerous lesions in Estonia.",TestAnalysis
"Community governance is the “micro-cell” of social governance and the foundation of the governance system. The rational selection logic of community governance policy reflects the value orientation, goal selection, and tool guarantee of governance policy. It is the result of the interaction between government and public values and it reflects the final value choice in the form of policy text and tries to balance policy rationality through accurate calculation. Through the analysis of 100 government work reports and 63 community governance policy documents of the Chinese government from 2013 to 2022, it was found that “People-oriented” was the core value orientation of governance policy. “Better life” was a key target choice for governance policy. “Diversified tools” were an important implementation guarantee for governance policy. These rational choices were consistent between the central and the local governments, but there was a conflict between localities. Urban and rural community governance policies need to establish a public space between policy rationality and value selection to solve the targeting bias of policy rationality in the future. This paper solves the conflict between policy rationality and value choice using the paths of expert think tank construction, highlighting leading goals, and using technology empowerment, to adjust the tension between the two through reasonable value choice and balanced policy rationality, to achieve the goal of urban and rural community governance modernization. © 2023 by the authors.",TestAnalysis
"Research still does not frequently use the concept of value creation through the application of big data analytics. Additionally, the internet serves as a limitless supply of knowledge that comes from different people all over the world and is delivered in a variety of ways, including text documents, photos, audio files, and video. Search engine is a tool used to find different types of information on the internet. The issue that frequently occurs when looking for information online is that the search results for the intended subject are frequently unrelated to the terms entered. In order to increase the relevance of the data obtained from the search results, the goal of this study is to implement the query expansion approach, which involves reformulating the initial query in order to add several phrases utilizing a thesaurus. The waterfall model was used in conjunction with the Software Development Life Cycle (SDLC) in the research. The results showed that the creation of a document search engine based on an information retrieval system was able to enhance data relevance and the standard of document search outcomes in big data analysis. The recall results are higher due to the usage of query expansion, which allowed for the retrieval of more pertinent documents. It is clear that by adopting this technique, the relevancy of the data in the search system can be improved. © School of Engineering, Taylor's University.",TestAnalysis
"Background: Psychoactive substance use and the regulations that govern it both have the potential to lead to harm. A ‘public health approach’ (PHA) is frequently invoked as a means of addressing these harms, but the term is used in inconsistent and contradictory ways. This study systematically reviewed the English-language academic literature to understand how a public health approach to substance use is defined and described. Methods: This review employed thematic synthesis, a methodology designed to rigorously synthesize qualitative evidence. Eligible articles were published in peer-reviewed journals, in the English language, with full text available, and focused primarily on substance use. There were no limits on year of publication. Original research, opinion/commentary, and reviews were included. The searches were conducted in October 2021 in CINAHL, Embase, Medline, PAIS Index, PsycINFO, Scopus, Sociological Abstracts, and Web of Science. Results: 272 articles from 25 countries, published between 1950 and 2021, were synthesized. Definitions of a PHA have changed over time and differ by substance. The most commonly cited characteristics of a PHA were: for alcohol, regulation, e.g. of price and availability (54% of articles); for cannabis: regulation (68%); for illicit drugs: that a PHA is distinct from a criminal justice approach (63%); for opioids: substance use disorder treatment (55%); and for tobacco: regulation (62%). Conclusion: There is no consensus on the definition of a public health approach to substance use, but there is substantial agreement when it comes to PHAs to specific substances. There are also similarities in how they are described for legal substances versus illicit ones. This review found areas of disagreement regarding the extent to which PHAs should focus on individual-level factors. Policymakers, academics, and others developing or implementing PHAs to substance use should be explicit about their aims and objectives – as well as the premises and assumptions underlying them. © 2023 The Author(s)",TestAnalysis
"Studies showed that interpreters might differ in performance when it comes to directionality. Nevertheless, limited research has been undertaken concerning the impact of directionality on student interpreters’ performance in consecutive interpreting (CI), a type of interpreting categorised by the working mode. This study aims to investigate the relationship between directionality and performance by adopting a quantitative approach. Four student interpreters from a Chinese university were selected as samples with a homogeneity sampling method. The participants used Chinese as their first language (L1, or A language) and English as a second language (L2, or B language). Analytic rating scales were combined with propositional analysis to assign scores for different aspects of accuracy and completeness in the product of the CI test by student interpreters. To determine the impact of directionality on performance, paired samples t-test was adopted in the current study by testing the significance of the difference between two mean scores of the CI test. The results showed that directionality affected the performance of student interpreters. Overall, the participants performed better in the into-B direction than in the into-A direction. Thus, it is recommended that teachers pay more attention to training listening comprehension ability of the source text in into-A direction. © 2023 ACADEMY PUBLICATION.",TestAnalysis
"This scoping review mapped and synthesised existing evidence on the influence of individual, parental, peer, and societal-related factors on adolescents’ decisions to use contraception in sub-Saharan Africa (SSA). Peer-reviewed and review articles published before May 2022, targeting adolescents aged 10–19 years were searched in PubMed, MEDLINE with Full Text via EBSCOhost, PsychINFO via EBSCOhost, CINAHL with Full Text via EBSCOhost, Google Scholar, Science Direct, and Scopus databases. Seven studies were included and analysed using thematic analysis based on the social-ecological model (SEM) and reported using the preferred reporting items for systematic reviews and meta-analyses (PRISMA). Individual (fear of side effects, fear of infertility), parental (parental disappointment and disapproval), peer (social stigma), partner (association with promiscuity and multiple sexual partners), societal and community (contraceptive use disapproval and stigma), and institutional and environmental factors (lack of privacy and confidentiality) influence contraceptive decisions among adolescents. These also include a lack of accurate information, social exclusion, negative health provider attitudes, and a lack of infrastructure that provides privacy and safe spaces. Identifying and addressing core issues within the context of local cultural practices that restrict contraceptive use is important. Holistic, inclusive approaches that promote the well-being of adolescents must be utilised to provide a conducive environment that ensures privacy, confidentiality, safety, and easy access to contraceptive services. © 2023 by the authors.",TestAnalysis
"Social media is a platform where people communicate, share content, and build relationships. Due to the current pandemic, many people are turning to social networks such as Facebook, WhatsApp, Twitter, etc., to express their feelings. In this paper, we analyse the sentiments of Indian citizens about the COVID-19 pandemic and vaccination drive using text messages posted on the Twitter platform. The sentiments were classified using deep learning and lexicon-based techniques. A lexicon-based approach was used to classify the polarity of the tweets using the tools VADER and NRCLex. A recurrent neural network was trained using Bi-LSTM and GRU techniques, achieving 92.70% and 91.24% accuracy on the COVID-19 dataset. Accuracy values of 92.48% and 93.03% were obtained for the vaccination tweets classification with Bi-LSTM and GRU, respectively. The developed models can assist healthcare workers and policymakers to make the right decisions in the upcoming pandemic outbreaks. © 2023 by the authors.",TestAnalysis
"Black/African American communities continue to be disproportionately impacted by HIV with Black people with HIV (PWH) exhibiting poorer outcomes along the HIV treatment cascade. Psychosocial burden may, in part, explain these health disparities among PWH. We implemented a culturally adapted intervention [individualized Texting for Adherence Building (iTAB)] to improve ART adherence among 89 Black PWH in San Diego, CA. We aimed to (1) characterize psychosocial risk factors (depression, negative life events, discrimination, medical mistrust) hypothesized to be barriers to HIV outcomes among Black PWH and (2) determine if these factors influence intervention engagement, HIV outcomes, and self-reported physical and mental health. We identified three levels of psychosocial burden (low, moderate, high) through hierarchical cluster analysis. Participants in the high burden cluster (n = 25) experienced the highest levels of depression, negative life events, and discrimination, in addition to the poorest intervention outcomes, HIV outcomes, and physical and mental health compared to low and moderate burden clusters. Participants in the low (n = 29) burden cluster had less medical mistrust than the moderate (n = 34) and high burden clusters, but low and moderate clusters did not differ on any outcomes. Overall, self-reported ART adherence was 83%, which is above estimates of ART adherence in the Western region of the United States. The iTAB intervention shows promise in improving HIV-related outcomes among Black PWH with low to moderate psychosocial burden; however, additional supports may need to be identified for those with high psychosocial burden. © Copyright 2023, Mary Ann Liebert, Inc., publishers 2023.",TestAnalysis
"During the course of a review of our publication, we found two errors in the Figure 3 Caption and Conclusions. We wish to make the following corrections to this paper [1]. Figure Caption In the original publication, there was a mistake in the figure caption for Figure 3. FTDM matrices 1F, ... ,5F for the S0!S1 transition of azobenzene calculated with nine methods indicated in the top. FTDM elements are expressed in %, i.e., multiplied by 100. The correct figure caption appears below. Figure 3. FTDM matrices 1F, ... ,5F for the (Formula presented.) transition of azobenzene calculated with nine methods indicated in the top. FTDM elements are expressed in %, i.e., multiplied by 100. Text Correction in Conclusions In the original publication, there was a mistake in “fraction of transition density” (FTDM) as published. The corrected version is “fraction of transition density matrix” (FTDM). The authors state that the scientific conclusions are unaffected. This correction was approved by the Academic Editor. The original publication has also been updated. © 2023 by the author.",TestAnalysis
"Purpose: To systematically collect published research in order to identify and quantify risk factors for delirium in advanced cancer patients. Methods: The Cochrane Library, PubMed, Proquest, CINAHL, Web of Science, Ovid MEDLINE, Embase, Scopus, Chinese Wanfang Data, Chinese Periodical Full-text Database (VIP), Chinese Biomedical Literature Database (CBM), and Chinese National Knowledge Infrastructure (CNKI) were systematically searched for cohort or case-control studies reporting individual risk factors for delirium among advanced-stage cancer patients published prior to March 2022. The Newcastle-Ottawa Scale was used to assess the methodological quality of included studies. The pooled adjusted odds ratio (aOR) and its 95% confidence interval were calculated using the RevMan 5.4 software package. Results: A total of 15 studies with data from 3106 advanced cancer patients were included in our analysis. Nine studies were high-quality and six were of moderate quality. Pooled analyses revealed that 11 risk factors were statistically significant. High-intensity risk factors included sleep disturbance, infection, cachexia and the Palliative Prognostic Index; medium-intensity risk factors included male sex, renal failure, dehydration and drowsiness; low-intensity risk factors included age, total bilirubin and opioid use. Antibiotic use was found to have been a protective factor. Conclusions: We identified 12 independent risk factors that were significantly associated with delirium in advanced cancer patients and provide an evidence-based foundation to implement appropriate preventive strategies. © 2023 Elsevier Ltd",TestAnalysis
"Through a content analysis, this paper explores the features of fake news on Spanish politics registered on the Maldita.es, Newtral, EFE Verifica and Verificat verifica-tion platforms between January 1 and March 31, 2022. These messages are spread mainly through Twitter and Facebook, using the text as support. The predominance of the ideological purpose, the high presence of stories of absolute invention, the shared role of anonymous and supplanted sources, the use of the informative style and the preponderance of left-wing formations as the object of hoaxes are also demonstrated. © GKA Ediciones, authors.",TestAnalysis
"Point of interest (POI) recommendation has received significant attention in recent years, most existing studies exploit multiple auxiliary information to alleviate the problem of data sparsity, and consider the sequential features of user mobility. However, few studies consider the category-level characteristics derived from each user's historical check-in frequencies, and the characteristics between different latent factors. In this paper, we exploit category-level multiple characteristics to generate recommendation. First, we obtain the frequency characteristics by in-depth analysis of the historical check-in frequencies for different categories by each user, and propose a scheme including KL-divergence and text analysis algorithm. Then we propose a category-level sequential-and non-sequential influence-Aware probabilistic generative model (CSNS), which models the characteristics (correlation and indeterminate decisiveness) between user latent behavior topics and latent sequence patterns. We design two stages to generate recommendations. In the first stage, CSNS and frequencies characteristics are exploited jointly to recommend the POI categories that users may visit. In the second stage, we depend on user profiles and poi features, and sort the candidate POI sets by combining the POI categories provided in the first stage. Comprehensive experiments on two real-world datasets demonstrate that our method outperforms the existing state-of-The-Art POI recommendation models.  © 1989-2012 IEEE.",TestAnalysis
"The point-vortex system is a system of longstanding interest in nonlinear dynamics, describing the motion of a two-dimensional inviscid fluid that is irrotational except at a discrete set of moving point vortices, at which the vorticity diverges. The leapfrogging orbit consists of two rotating pairs of like-signed vortices which, taken as a quartet, propagate at constant velocity. It is known that if the two pairs are initially widely separated, the motion is stable, while if they are closer together it becomes unstable, with this relation represented by a dimensionless parameter α defined in the text. We here demonstrate analytically that the transition from stability to instability happens at a critical value α=ϕ−2, where ϕ is the golden ratio. This value had been hypothesized based on careful numerics by Tophøj and Aref, and by the present authors using a semi-analytic argument but not previously demonstrated through exact analysis. © 2023 Elsevier Ltd",TestAnalysis
"In this paper, based on Sina Weibo data, a natural language processing (NLP) analysis method was used to analyze the temporal and spatial sequence characteristics of people’s attention and the characteristics of text content with the help of microblogs posted by people within 6 days after the 2022 Lushan M6.1, Maerkang M5.8 and Luding M6.8 earthquakes. Moreover, the same analysis method was used on the content of comments on microblogs posted by official media outlets within 6 days after the earthquakes to analyze the changes in people’s sentiments and the differences in the sentiments in various regions, and the influencing factors were also analyzed. The results of this research show the following: In terms of the spatial and temporal distributions, people’s attention was affected by the earthquakes themselves and their social impacts, and the first 2 h was often a period of an outbreak of attention, with the publishing areas mainly concentrated in Sichuan and Guangdong. In terms of people’s sentiments, the overall microblogging sentiment of the three earthquakes was positive, and the sentiment value of the people in Sichuan was generally low compared with that of the people in the other regions. Not only was the fluctuation in sentiment affected by the influence of the region, but it was also positively related to the sentiment of official microblogs. The results of this research provide reference for guiding people’s sentiments after earthquakes in the new media era. © 2023 by the authors.",TestAnalysis
"Purpose: Understanding what is known about the language profiles of children with hearing loss (CHL) is vital so that researchers and teachers can identify the specific complex syntactic structures that CHL may struggle to master. An understanding of which aspects of complex syntax pose difficulties for CHL is necessary to inform the kind of intervention that will facilitate learning complex syntax for this cohort of children. This scoping review aims to identify what is currently known about the complex syntax use of CHL who communicate through spoken language, and uncover gaps in the literature to guide further research. Method: Ascoping review was conducted following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews guidelines. The Covidence software was utilized to manage the initial and full-text screening process for the search. Results: From a total of 304 studies, 42 studies were identified that met the eli-gibility criteria. The review highlights the use of broad-based language assess-ments and limited use of specific descriptions of the types of complex syntactic structures and skills. Conclusions: Findings highlight the need for assessment protocols and analysis methods that better support the description of complex syntax profiles for CHL. School-age CHL continue to display challenges with complex syntax development. The review highlighted the need for further research to improve understanding of the complex syntax strengths and vulnerabilities of CHL. Further investigation is needed to better understand their ability to combine ideas and build complexity in their language use, which in turn can inform teaching in schools and interventions for children who require support. © 2023 American Speech-Language-Hearing Association.",TestAnalysis
"Generalization has always been a keyword in deep learning. Pretrained models and domain adaptation technology have received widespread attention in solving the problem of generalization. They are all focused on finding features in data to improve the generalization ability and to prevent overfitting. Although they have achieved good results in various tasks, those models are unstable when classifying a sentence whose label is positive but still contains negative phrases. In this article, we analyzed the attention heat map of the benchmarks and found that previous models pay more attention to the phrase rather than to the semantic information of the whole sentence. Moreover, we proposed a method to scatter the attention away from opposite sentiment words to avoid a one-sided judgment. We designed a two-stream network and stacked the gradient reversal layer and feature projection layer within the auxiliary network. The gradient reversal layer can reverse the gradient of features in the training stage so that the parameters are optimized following the reversed gradient in the backpropagation stage. We utilized an auxiliary network to extract the backward features and then fed them into the main network to merge them with normal features extracted by the main network. We applied this method to the three baselines of TextCNN, BERT, and RoBERTa using sentiment analysis and sarcasm detection datasets. The results show that our method can improve the sentiment analysis datasets by 0.5% and the sarcasm detection datasets by 2.1%. © 2023 by the authors.",TestAnalysis
"This paper attempts to examine the genealogical framework of “lamp records” (denglu 燈錄) of the Chan Buddhist tradition using analytical tools and methods of Historical Social Network Analysis (HSNA) and graph theory. As an exploratory study, the primary objectives are to investigate the possibilities offered by HSNA and visualization tools for research on Chan genealogy in lamp records, explore the benefits of this approach over traditional lineage charts, and reflect on its limitations. The essay focuses on the Chan community portrayed in the Goryeo 高麗 edition of the Zutang ji 祖堂集 (Collection of the Patriarchal Hall; K.1503). It shows that the lineage reportedly stemming from Qingyuan Xingsi 青原行思 (d. ca. 740) and Shitou Xiqian 石頭希遷 (701–791), as well as the branch descending from Tianhuang Daowu 天皇道悟 (748–807) to Xuefeng Yicun 雪峰義存 (822–908) and his successors, play a crucial role within the structure of the Zutang ji’s genealogical network. The study further highlights possible irregularities in lineage claims by contrasting metrics of degree and betweenness centrality with features of the text (e.g., number of hagiographic entries, length of the entries). © 2023 by the author.",TestAnalysis
"Objective: To systematically assess the effectiveness and safety of using acupuncture-moxibustion therapy alone to treat adult overactive bladder (OAB) by taking oral Western medication solely as the control, and to provide evidence-based reference for acupuncture-moxibustion treatment of OAB. Methods: A systemic search was conducted through China National Knowledge Infrastructure (CNKI), Wanfang Academic Journal Full-text Database (Wanfang), Chongqing VIP Database (CQVIP), China Biology Medicine Disc (CBM), PubMed, Cochrane Library, and Excerpta Medica Database (EMBASE). RevMan 5.3 was used for meta-analysis. Statistical descriptions were made using standardized mean difference (SMD), confidence interval (CI), and risk ratio (RR). Results: Eight randomized controlled studies were finally recruited and were analyzed after being grouped according to intervention methods. Regarding urinary symptoms, compared with sole use of oral Western medication, acupuncture plus moxibustion can more effectively reduce 24 h urinary frequency [P=0.01, SMD=−0.57, 95%CI (−1.02, −0.12)], 24 h nocturia frequency [P=0.03, SMD=0.49, 95%CI (0.05, 0.94)], and OAB syndrome score (OABSS) [P<0.001, SMD=−3.67, 95%CI (−4.48, −2.86)]. Acupuncture combined with moxibustion and oral Western medication work equivalently in comparing 24 h urinary urgency frequency [P=0.38, SMD=−0.17, 95%CI (−0.57, 0.22)], 24 h urgent incontinence frequency [P=0.25, SMD=0.26, 95%CI (−0.18, 0.70)], and single voiding volume [P=0.22, SMD=1.15, 95%CI (−0.70, 3.00)]. There were no significant differences between acupuncture/electroacupuncture and oral medication in comparing 24 h urinary frequency [P=0.46, SMD=0.07, 95%CI (−0.12, 0.26)], 24 h urinary urgency frequency [P=0.18, SMD=0.70, 95%CI (−1.71, 0.32)], 24 h nocturia frequency [P=0.46, SMD=−0.71, 95%CI (−2.60, 1.17)], 24 h urgent incontinence frequency [P=0.08, SMD=−0.22, 95%CI (−0.48, 0.03)], single voiding volume [P=0.09, SMD=0.17, 95%CI (−0.02, 0.36)], or OABSS [P=0.96, SMD=−0.07, 95%CI (−2.65, 2.52)]. Compared with oral Western medication, moxibustion can more effectively reduce 24 h urinary frequency [P<0.001, SMD=−6.53, 95%CI (−7.65, −5.44)] and 24 h urinary urgency frequency [P<0.001, SMD=−1.6, 95%CI (−2.85, −0.36)]. In comparing the adverse reaction rate, acupuncture-moxibustion was associated with a lower rate compared with oral medication [P=0.002, RR=0.07, 95%CI (0.01, 0.37)], but the difference was statistically insignificant between acupuncture/electroacupuncture and oral medication [P=0.40, RR=0.57, 95%CI (0.16, 2.12)]. Conclusion: Acupuncture-moxibustion is equivalent to the sole use of oral Western medication in improving urinary symptoms in OAB patients and has a higher safety rating. © 2023, Shanghai Research Institute of Acupuncture and Meridian.",TestAnalysis
"Introduction The COVID-19 pandemic has amplified pre-existing challenges to health promotion and care across the world, and particularly in low- and middle-income countries (LMICs). This qualitative study draws on data from a panel of immunisation experts and uses a novel framework of vaccine delivery domains to explore perspectives from those who live and work in these settings on the challenges to implementing COVID-19 vaccine programs in LMICs. Methods We conducted a thematic content analysis of 96 participant free text replies to questions from Round I of a three-round Delphi consensus study amongst global experts on COVID-19 vaccine implementation. Results Participant responses highlighted challenges to vaccine program implementation including issues related to equity; governance, decision-making, and financing; regulatory structures, planning, and coordination; prioritisation, demand generation, and communication; vaccine, cold chain, logistics, and infrastructure; service delivery, human resources, and supplies; and surveillance, monitoring, and evaluation. Conclusion We reflect on our findings in light of global efforts to address vaccine inequity and emphasise three key areas salient to improving vaccination efforts during novel infectious disease outbreaks: 1) Ensuring safe and sustainable service delivery in communities and at points of care; 2) Strengthening systems for end-to-end delivery of vaccines, therapeutics, diagnostics, and essential supplies; 3) Transforming structural paradigms towards vaccine equity. © 2023 Haldane et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"The enrichment of social media expression makes multimodal sentiment analysis a research hotspot. However, modality heterogeneity brings great difficulties to effective cross-modal fusion, especially the modality alignment problem and the uncontrolled vector offset during fusion. In this paper, we propose a bimodal multi-head attention network (BMAN) based on text and audio, which adaptively captures the intramodal utterance features and complex intermodal alignment relationships. Specifically, we first set two independent unimodal encoders to extract the semantic features within each modality. Considering that different modalities deserve different weights, we further built a joint decoder to fuse the audio information into the text representation, based on learnable weights to avoid an unreasonable vector offset. The obtained cross-modal representation is used to improve the sentiment prediction performance. Experiments on both the aligned and unaligned CMU-MOSEI datasets show that our model achieves better performance than multiple baselines, and it has outstanding advantages in solving the problem of cross-modal alignment. © 2023 by the authors.",TestAnalysis
"Adolescents living with chronic conditions such as HIV (ALHIV) are challenged to remain adherent and engaged in HIV care. Technology offers a promising platform to deliver behaviour-change interventions to adolescents. The largest proportion of ALHIV resides in sub-Saharan Africa; yet little is known about the effectiveness, feasibility and acceptability of technology-enabled interventions to deliver and support health care to ALHIV in resource-constraint settings. This study aims to explore the literature and synthesise the evidence for the effectiveness, acceptability, and feasibility of technology-enabled health interventions for ALHIV in low and middle-income countries (LMIC). Eight electronic databases (Ebscohost, CINAHL, ERIC, MEDLINE, PubMed, SCOPUS, Science Direct, and Sabinet) and Google Scholar will be searched to identify technology-enabled health interventions for ALHIV in LMIC published from 2010–2022. Quantitative and qualitative studies reporting on technology-enabled health interventions for predominantly adolescents (10–19 years) will be included. The review will be performed, and findings reported according to the Preferred Reporting Items for Systematic Reviews and Meta-analyses Protocols. A two-stage process of screening titles and abstracts, and then full-text, will be performed independently by two reviewers. The quality of the included studies will be assessed using the Critical Appraisal Skills Programme checklists, and the Risk of Bias in Non-randomised Studies of Interventions tool will be used to assess the risk of bias. The review will involve publications already in the public domain; therefore, ethics approval is not required. The results will be disseminated through a peer-reviewed journal publication and/or conference proceedings. Copyright: © 2023 Crowley et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TestAnalysis
"Authorship profiling is a subtask of authorship identification. This task can be regarded as an analysis of personal writing styles, which has been widely investigated. However, no previous studies have attempted to analyze the authorship of classical Chinese poetry. First, we provide an approach to evaluate the popularity of poets, and we also establish a public corpus containing the top 20 most popular poets in the Tang Dynasty for authorship profiling. Then, a novel poetry authorship profiling framework named multidimensional domain knowledge poet profiling (M-DKPP) is proposed, combining the knowledge of authorship attribution and the text’s stylistic features with domain knowledge described by experts in traditional poetry studies. A case study for Li Bai is used to prove the validity and applicability of our framework. Finally, the performance of M-DKPP framework is evaluated with four poem datasets. On all datasets, the proposed framework outperforms several baseline approaches for authorship attribution. © 2023 by the authors.",TestAnalysis
"BACKGROUND: Previous studies have tried to determine the relationship between sexting and risky behaviour to discover whether sexting fits into a deviance or normalcy discourse. This study investigated the relationship between sexting and sexual risk behaviours, contraception use and gender. METHODS: The design was a cross-sectional analysis of data from the sixth National Survey of Secondary Student and Adolescent Sexual Health, collected in 2018. There were 8263 Australian adolescents (aged 14-18years). Participants were fairly evenly split by gender, and 73% identified as heterosexual. Participants were asked a series of questions about their engagement in sexting, sexual behaviour and sexual health behaviours. RESULTS: A total of 52% of participants had sent a sext in the previous 2months, with most being text-based sexts. Sexters were 3.29times more likely to have engaged in anal or vaginal intercourse, and 2.88times more likely to have gotten pregnant than non-sexters. Sexters (M =2.76) had significantly more partners than non-sexters (M =2.35), t (3763)=-10.99, P X 2 (1)=0.38, P =0.535, or contraceptive use based on sexting status. CONCLUSIONS: Sexters are more likely to have engaged in sexual intercourse and have more partners than non-sexters. Sexting is not strongly associated with other risky behaviours. Evidence for differences between sexters and non-sexters in protecting against STIs and pregnancy was not found, as there were no significant differences in contraceptive use.",TestAnalysis
"A critical aspect of coronary heart disease (CHD) care and secondary prevention is ensuring patients have access to evidence-based information. The purpose of this review is to summarise the guiding principles, content, context and timing of information and education that is beneficial for supporting people with CHD and potential communication strategies, including digital interventions. We conducted a scoping review involving a search of four databases (Web of Science, PubMed, CINAHL, Medline) for articles published from January 2000 to August 2022. Literature was identified through title and abstract screening by expert reviewers. Evidence was synthesised according to the review aims. Results demonstrated that information-sharing, decision-making, goal-setting, positivity and practicality are important aspects of secondary prevention and should be patient-centred and evidenced based with consideration of patient need and preference. Initiation and duration of education is highly variable between and within people, hence communication and support should be regular and ongoing. In conclusion, text messaging programs, smartphone applications and wearable devices are examples of digital health strategies that facilitate education and support for patients with heart disease. There is no one size fits all approach that suits all patients at all stages, hence flexibility and a suite of resources and strategies is optimal. © 2023 by the authors.",TestAnalysis
"The world is facing a new era in which social media communication plays a fundamental role in people's lives. Along with proven benefits, several collateral drawbacks have risen, one being the widespread of false information with malicious intents, oftentimes using anonymous or false identities. Fighting this problem is challenging, especially when considering the nature of text messages involved on social media platforms: a sea of small messages and a myriad of users. Attributing the authorship of such messages is an ambitious endeavor; nevertheless, it is a way to fight this undesired disinformation scenario. In this work, we tackle the problem of authorship attribution of tiny messages, but, different from what has been done with longer texts, we rely upon data-driven approaches, avoiding handcraft features and harnessing recent advances of deep neural networks in the field of pattern recognition. By modeling small texts employed in social media as unidimensional signals, we propose a deep learning model to project these messages onto a manifold suitable for the task of authorship attribution. We provide two state-of-the-art solutions tailored for different setups and strategies for the scenario of authorship verification. These advances were possible, thanks to three additional contributions: an updated dataset based on the Twitter® platform, new sanitization techniques to improve the quality of the training data, and novel visual analytics techniques to help the development of authorship attribution solutions.  © 2014 IEEE.",TestAnalysis
"INTRODUCTION: Evidence about predictors of poor outcomes such as cerebral infarction (CI) after aneurysmal subarachnoid hemorrhage (aSAH) has not been fully elucidated. EVIDENCE ACQUISITION: We performed a systematic review and meta-analysis on studies with adults with aSAH considering RCT and non-RCT, prospective, and retrospective cohort studies describing clinical, imaging as well as angiographic studies in patients with aSAH. EVIDENCE SYNTHESIS: After reviewing the complete text, 11 studies were considered eligible, out of which four were ruled out. Degree of clinical severity was the most predictive factor with a higher degree at the presentation on different severity scales being associated with a statistically significant increasing the risk of suffering a CI following aSAH (OR 2.49 [95% CI 1.38-4.49] P=0.0003). Aneurysm size increased the risk of CI (OR 1.49 [95% CI 1.20-1.85] P=0.0003; I2=4%). In six studies analyzed, it was found that an important factor for the subsequent development of CI is vasospasm (OR 7.62 [2.19, 26.54], P=0.0001). CONCLUSIONS: The development of vasospasm is a risk factor for CI development after aSAH. In our review, three factors were associated with an increased risk of CI: clinical severity at presentation, vasospasm, and aneurysm size. The major limitation of this meta-analysis is that included studies were conducted retrospectively or were post hoc analyses of a prospective trial. © 2022 Edizioni Minerva Medica.",TestAnalysis
"Background: Rotator cuff tears are a common source of shoulder pain and dysfunction. An irreparable rotator cuff tear poses a particular treatment challenge. There have been few studies reporting the outcomes of lower trapezius tendon (LTT) transfer for irreparable rotator cuff injuries. Therefore, the purpose of this review is to summarize the postoperative functional outcomes and complications of patients undergoing a LTT transfer for massive irreparable rotator cuff injuries. Methods: A scoping review was performed using the Medline, Embase, Cochrane Central Register of Controlled Trials, and Google Scholar databases with the search terms “trapezius” AND “transfer.” Of 362 studies included for initial screening, 37 full-text citations were reviewed, with 5 studies meeting all the inclusion criteria to be included in the review. Two reviewers extracted data on study design, patient demographics, surgical technique, functional outcomes, range of motion (ROM), and complications for each study according to the predefined criteria. Results: Improvements in the preoperative to postoperative functional status, identified using the Disabilities of the Arm, Shoulder, and Hand (50.34 to 18), The American Shoulder and Elbow Surgeons Score (48.56 to 80.24), Visual Analog Scale (5.8 to 1.89), Single Assessment Numeric Evaluation (34.22 to 69.86), and Subjective Shoulder Value (52.24 to 77.66), were evident across all 5 studies. Preoperative to postoperative increases in ROM were seen for flexion (85 to 135), external rotation (18 to 52), and abduction (50 to 98). The overall complication rate was 18%, with seroma formation (8%) as the most common postoperative complication. Discussion/Conclusion: Our analysis showed that LTT transfer improved postoperative function, ROM, and pain for patients with irreparable rotator cuff tears with an overall complication rate of 18%. Future controlled studies are required to directly compare LTT transfer to other tendon transfers and other surgical techniques for irreparable rotator cuff tears. © 2022 The Authors",TestAnalysis
"The promotion of community governance by digital means is an important research topic in developing smart cities. Currently, community governance is mostly based on reactive response, which lacks timely and proactive technical means for emergency monitoring. The easiest way for residents to contact their properties is to call the property call center, and the call centers of many properties store many speech data. However, text sentiment classification in community scenes still faces challenges such as small corpus size, one-sided sentiment feature extraction, and insufficient sentiment classification accuracy. To address such problems, we propose a novel community speech text sentiment classification algorithm combining two-channel features and attention mechanisms to obtain effective emotional information and provide decision support for the emergency management of public emergencies. Firstly, text vectorization based on word position information is proposed, and a SKEP-based community speech–text enhancement model is constructed to obtain the corresponding corpus. Secondly, a dual-channel emotional text feature extraction method that integrates spatial and temporal sequences is proposed to extract diverse emotional features effectively. Finally, an improved cross-entropy loss function suitable for community speech text is proposed for model training, which can achieve sentiment analysis and obtain all aspects of community conditions. The proposed method is conducive to improving community residents’ sense of happiness, satisfaction, and fulfillment, enhancing the effectiveness and resilience of urban community governance. © 2023 by the authors.",TestAnalysis
"Aims/Hypothesis: Only 51% of patients with type 2 diabetes achieve the hemoglobin A1c (HbA1c) <7% target. Mind and body practices have been increasingly used to improve glycemic control among patients with type 2 diabetes, but studies show inconsistent efficacy. The authors conducted a systematic review and meta-analysis to assess the association between mind and body practices, and mean change in HbA1c and fasting blood glucose (FBG) in patients with type 2 diabetes. Methods: The authors conducted a literature search of Ovid MEDLINE, Embase, and ClinicalTrials.gov seeking through June 10, 2022, published articles on mind and body practices and type 2 diabetes. Two reviewers independently appraised full text of articles. Only intervention studies were included. Reviewers extracted data for meta-analysis. Restricted maximum likelihood random-effects modeling was used to calculate the mean differences and summary effect sizes. The authors assessed heterogeneity using Cochran's Q and I2 statistics. Funnel plots were generated for each outcome to gauge publication bias. Weighted linear models were used to conduct study-level meta-regression analyses of practice frequency. Results: The authors identified 587 articles with 28 meeting the inclusion criteria. A statistically significant and clinically relevant mean reduction in HbA1c of -0.84% (95% confidence interval [CI]: -1.10% to -0.58%; p < 0.0001) was estimated. Reduction was observed in all intervention subgroups: mindfulness-based stress reduction: -0.48% (95% CI: -0.72% to -0.23%; p = 0.03), qigong: -0.66% (95% CI: -1.18% to -0.14%; p = 0.01), and yoga: -1.00% (95% CI: -1.38% to -0.63%; p < 0.0001). Meta-regression revealed that for every additional day of yoga practice per week, the raw mean HbA1c differed by -0.22% (95% CI: -0.44% to -0.003%; p = 0.046) over the study period. FBG significantly improved following mind and body practices, with overall mean difference of -22.81 mg/dL (95% CI: -33.07 to -12.55 mg/dL; p < 0.0001). However, no significant association was found between the frequency of weekly yoga practice and change in FBG over the study period. Conclusions/Interpretation: Mind and body practices are strongly associated with improvement in glycemic control in patients with type 2 diabetes. The overall mean reduction in HbA1c and FBG was clinically significant, suggesting that mind and body practices may be an effective, complementary nonpharmacological intervention for type 2 diabetes. Additional analyses revealed that the mean decrease in HbA1c was greater in studies requiring larger number of yoga practice sessions each week. © Copyright 2023, Mary Ann Liebert, Inc., publishers 2023.",TestAnalysis
"(1) Background: Research has shown that patients with mental health diagnoses experience less anxiety and depressive symptoms and higher levels of ‘well-being’ when they spend time in natural environments as part of their treatment. It has been suggested that there is a relationship between the outdoor settings and the recovery of psychiatric patients. Recovery describes an individual process, which can vary from person to person. (2) Methods: This scoping review examined the relationship between the physical environment and the recovery of psychiatric patients. Systematic searches in three online databases, namely Medline, Embase, and PsycINFO, were performed using a selection of psychiatric, environmental, and recovery terms and included both quantitative and qualitative studies. In general, ‘well-being’ serves as an overarching indicator when it comes to research on how outdoor settings can affect mental health. Well-being was expressed in terms of mood, social relations, and autonomy. (3) Results: A total of 8138 records were screened, 85 studies were included for full-text reading, and five articles were included in the final analysis. The review showed in general that outdoor settings, more specifically gardening, contact with nature, and a safe environment can be related to the well-being of patients on psychiatric wards. (4) Conclusions: The five reviews allow us to conclude that outdoor settings can be seen as a comprehensive resource for mental health. © 2023 by the authors.",TestAnalysis
"Through rapid advances, vertical farming (VF) systems are becoming an addition to conventional agricultural practices that under increasing climate stress can contribute to more sustainable food production. The present research advances extant consumer research on VF by exploring how consumers associate the different characteristics of VF with the technology's pros and cons, and how these link to their personal values. To this end, consumers’ cognitive structures relating to VF were uncovered through means-end chains (MECs) and laddering methodology. While both soft and hard laddering approaches remain in use, innovation and methodological development are focused on hard laddering. The present research contributes to this expansion by trailing a hybrid-hard laddering approach that is suitable for online surveys and large sample sizes while incorporating some aspects of soft laddering. Participants lived in Singapore (SG) (n = 547) or Germany (DE) (n = 537) and completed the laddering task after reading an information text about VF. Data analysis resulted in hierarchical value maps (HVM) which were compared by country and groups of participants with different attitudes to VF. Both altruistic and self-centred motives were key to acceptance of VF while energy use emerged as a concern. For some consumers positive linkages were established to “pleasure and enjoyment” and this may be harnessed to enhance uptake. The hybrid-hard laddering approach was successful in so far as the results fitted expectations. However, room for improvement exists. © 2022 Elsevier Ltd",TestAnalysis
"Purpose: To systematically examine and summarize the current evidence regarding the effects of virtual reality (VR) on physical, cognitive, and psychological outcomes in cancer rehabilitation. Methods: Six bioscience and engineering databases were searched. Two independent reviewers screened the titles and abstracts of 2397 records and retrieved 25 full-text articles. Inclusion criteria included patients with a current or previous diagnosis of cancer; VR was used as an intervention for physical, cognitive, or psychological impairments and functional limitations; and clinical trials with at least two arms and with both pre- and post-intervention assessments. Reviewers assessed methodological quality using the Physiotherapy Evidence Database scale. Results: Seventeen studies including 799 patients with cancer were identified. Within-group pooled analysis indicated that patients demonstrated significant improvement in pain (P < 0.001), fatigue (P < 0.001), anxiety (P < 0.001), upper extremity function (P < 0.001), and quality of life (P = 0.008) after VR intervention. Between-group pooled analysis indicated significant improvements with VR in pain (P = 0.004), anxiety (P < 0.001), and upper extremity function (P < 0.001) compared with the control. Three studies reported the positive effects of VR on cognition. Conclusions: VR demonstrates promising effects in physical, cognitive, and psychological aspects of patients with cancer. VR can be incorporated into a comprehensive cancer rehabilitation program to alleviate impairments and functional limitations. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TestAnalysis
"Objective: To assess which interventions are effective in reducing fluid absorption at the time of hysteroscopy.DATA SOURCE: Ovid MEDLINE, Ovid EMBASE, PubMed (non-MEDLINE records only), EBM Reviews - Cochrane Central Register of Controlled Trials (CENTRAL), ClinicalTrials.gov, and Web of Science were searched from inception to February 2022 without restriction on language or geographic origin.METHODS OF STUDY SELECTION: Following PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines, all English-language, full-text articles reporting fluid balance, with an intervention and comparator arm, were included. Title and abstract screening and full-text review were completed independently by two authors. Conflicts were resolved through discussion and consensus. Studies' risk of bias was assessed using the Cochrane Risk of Bias Tool for RCTs and the Newcastle-Ottawa Scale for observational studies.TABULATION, INTEGRATION, AND RESULTS: The search identified 906 studies, 28 of which were eligible for inclusion, examining the following interventions: gonadotropin-releasing hormone (GnRH) agonist; ulipristal acetate; vasopressin; danazol; oxytocin; and local, general, and regional anesthesia. A significant reduction in mean fluid absorption was seen in patients preoperatively treated with danazol (-175.7 mL, 95% CI -325.4 to -26.0) and a GnRH agonist (-139.68 mL, 95% CI -203.2, -76.2) compared with patients in a control group. Ulipristal acetate and type of anesthesia showed no difference. Data on type of anesthesia and vasopressin use were not amenable to meta-analysis; however, four studies favored vasopressin over control regarding fluid absorption. Mean operative time was reduced after preoperative treatment with ulipristal acetate (-7.1 min, 95% CI -11.31 to -2.9), danazol (-7.5 min, 95% CI -8.7 to -6.3), and a GnRH agonist (-3.3 min, 95% CI -5.6 to -0.98). Conclusion: Preoperative treatment with a GnRH agonist and danazol were both found to be effective in reducing fluid absorption and operative time across a range of hysteroscopic procedures. High-quality research aimed at evaluating other interventions, such as combined hormonal contraception, progestin therapy, and vasopressin, are still lacking in the literature.  © 2023 by the American College of Obstetricians and Gynecologists.",TestAnalysis
"The Semantic Coherence Dataset has been designed to experiment with semantic coherence metrics. More specifically, the dataset has been built to the ends of testing whether probabilistic measures, such as perplexity, provide stable scores to analyze spoken language. Perplexity, which was originally conceived as an information-theoretic measure to assess the probabilistic inference properties of language models, has recently been proven to be an appropriate tool to categorize speech transcripts based on semantic coherence accounts. More specifically, perplexity has been successfully employed to discriminate subjects suffering from Alzheimer Disease and healthy controls. Collected data include speech transcripts, intended to investigate semantic coherence at different levels: data are thus arranged into two classes, to investigate intra-subject semantic coherence, and inter-subject semantic coherence. In the former case transcripts from a single speaker can be employed to train and test language models and to explore whether the perplexity metric provides stable scores in assessing talks from that speaker, while allowing to distinguish between two different forms of speech, political rallies and interviews. In the latter case, models can be trained by employing transcripts from a given speaker, and then used to measure how stable the perplexity metric is when computed using the model from that user and transcripts from different users. Transcripts were extracted from talks lasting almost 13 hours (overall 12:45:17 and 120,326 tokens) for the former class; and almost 30 hours (29:47:34 and 252,270 tokens) for the latter one. Data herein can be reused to perform analyses on measures built on top of language models, and more in general on measures that are aimed at exploring the linguistic features of text documents. © 2022 The Authors",TestAnalysis
"OBJECTIVE: To conduct a systematic review and meta-analysis to determine whether targeting a higher mean arterial pressure (MAP) compared with a lower MAP in adults with shock results in differences in patient important outcomes. DATA SOURCES: We searched MEDLINE, EMBASE, the Cochrane Library, and ClinicalTrials.gov through May 2021. STUDY SELECTION: Titles and abstracts were screened independently and in duplicate to identify potentially eligible studies, then full text for final eligibility. We included parallel-group randomized controlled trials in adult patients with a diagnosis of shock requiring vasoactive medications. The higher MAP group was required to receive vasoactive medications to target a higher MAP as established by study authors, whereas the lower MAP group received vasoactive medications to target lower MAP. DATA EXTRACTION: In triplicate, reviewers independently extracted data using a prepiloted abstraction form. Statistical analyses were conducted using the RevMan software Version 5.3. DATA SYNTHESIS: Six randomized controlled trials (n = 3,690) met eligibility criteria. Targeting a higher MAP (75-85 mm Hg) compared with lower MAP of 65 mm Hg resulted in no difference in mortality (relative risk [RR], 1.06; 95% CI, 0.98-1.15; I2= 0%; p = 0.12; moderate certainty. Targeting a higher MAP resulted in no difference in the risk of undergoing renal replacement therapy (RR, 0.96; 95% CI, 0.83-1.11; I2= 24%; p = 0.57; moderate certainty); however, a subgroup analysis comparing patients with and without chronic hypertension demonstrated that a higher MAP may reduce the risk of undergoing renal replacement therapy (RR, 0.83; 95% CI, 0.71-0.98; I2= 0%; p = 0.02). CONCLUSIONS: In conclusion, our systematic review and meta-analysis demonstrated with moderate certainty that there is no difference in mortality when a higher MAP is targeted in critically ill adult patients with shock. Further studies are needed to determine the impact of mean arterial pressure on need for renal replacement therapy in this population. © 2023 Lippincott Williams and Wilkins. All rights reserved.",TestAnalysis
"Internet-based media and online business make people use it a lot, especially the high use of cell phones everywhere in the world. These encourage organizations to gain insights from people far away. This creates a tremendous growth of information on the Internet. Concepts are important implications for practically all human practices and practices. It looks for feelings before making a decision. People share their opinions, thoughts, ideas, attitudes, feelings etc. with known languages on social media platform. Most people express their opinions in mixed languages (English with their mother tongue). Analyzing diverse texts is a very challenging area for practitioners and researchers. In this research work, it presents an ensemble technique by collaborating Generative Adversarial network (GAN) and Self-Attention Network (SAN) to analyze the tweets that contains diversified languages. The GAN layer helps to arrange the preprocessed tweets into positive and negative. The SAN layer helps to identify the neutral tweets. The proposed technique is compared along with the existing Concurrent Neural Network (CNN) along with Self-Attention Network (SAN) on Tanglish tweets. The proposed work produced better accuracy than the existing work. © 2023 The Authors",TestAnalysis
"Clinical coding is the process of converting health information, which may be a combination of free text language and a clinician's interpretation of this, into a computer-readable formal language. Well-known examples of clinical coding systems include the International Classification of Diseases (ICD-10) and Systematized Nomenclature of Medicine Clinical Terms (SNOMED CT). These coding systems exist to avoid the complexities and ambiguity of human language and convey benefit to both individual clinicians and patients, but also by allowing for data analysis at the scale of entire populations. Advantages to proper clinical coding for individual hospitals or practices include audit, research, creation of decision support systems, accurate communication between teams, and to ensure hospitals receive appropriate re-numeration for their services. At the national level such coding allows for epidemiological study and the strategic allocation of health resources, whilst at the international level clinical coding allows for statistical reporting, monitoring of health inequality, and unambiguous communication between countries in a common language. © 2022",TestAnalysis
"Introduction: Healthcare providers and organizations occasionally use electronic messages to provide information to patients. There is insufficient data on whether patients actually read the emails they receive. In this study, we aimed to assess the cooperation of patients in reading multiple information pages sent over 6 months from their diabetologist via email. Methods: Adults with non-optimally controlled type 2 diabetes received via email, once every 2 weeks for 6 months, a message containing information and tips on how to improve diabetes control through lifestyle choices. The information was provided in a format that required the recipient to actively click on a “read more” tab in order to reveal the entire text. Each email contained a short questionnaire requesting a response. Analysis compared the effect of patient variables on co-operation with reading the emails and answering the questionnaires. Main findings: 45 patients completed the study, 53.3% of them read 66–100% of the emails, 17.8% read 34–65% of the emails and only 26.7% read less than 33% of the emails. Women answered more questionnaires than men did. Answering a questionnaire on nutrition or medications correlated with reading the following email sent. Conclusions: This study is the first to demonstrate that most patients do indeed read a significant portion of emails sent by their physician. Email could be an effective means of sharing information and improving patient engagement with treatment. © 2022 Elsevier B.V.",TestAnalysis
"In China, vehicles with L2 driving automation are already widespread, while L3-L5 automated vehicles (AVs) are not allowed on the road. Surprisingly, crashes involving vehicles with L2 driving automation contributed to the public's discussion of L3-L5 AVs. Understanding the variations in public perception of AVs is imperative, which could significantly affect the future evolution of AVs. Respondents have few opportunities to express their views freely in survey-based studies relying on structured questionnaires (e.g., Likert scale). We collected 42,111 comments from Chinese mainstream social media platforms (Sina Weibo and Tik Tok) in August 2021 and applied advanced text mining technology (Latent Dirichlet Allocation topic model, text network analysis, and sentiment analysis) to understand variations in public perception of AVs before and after the crashes. The results show that the public expresses more blame for vehicles with L2 driving automation than human drivers and has misunderstandings about the current development of L3-L5 AVs, which is closely connected with publicity from automobile companies and media. Women were more negative than men both before and after the crash, and the sentiment difference was most significant in the first three days of the crash. This research provides new ideas for a timely understanding of the public perception of AVs. Findings contribute to specific policy recommendations to help in the technological change and wider adoption of AVs. © 2023 Elsevier Ltd",TestAnalysis
"This article examines the differential impact of variances in the quality and taste comments found in online customer reviews on firm sales. Using an analytic model, the authors show that although increased variance in consumer reviews about taste mismatch normally decreases subsequent demand, it can increase demand when mean ratings are low and/or quality variance is high. In contrast, increased variance in quality always decreases subsequent demand, although this effect is moderated by the amount of variance in tastes. Since these theoretical demand effects are predicated on the assumption that consumers can differentiate between the two sources of variation in ratings, the authors conduct a survey to test this assumption, demonstrating that participants are indeed able to reliably distinguish quality from taste evaluations in two subsets of 5,000 reviews taken from larger data sets of reviews for 4,305 restaurants and 3,460 hotels. The authors use these responses to construct sets of reviews that they use in a controlled laboratory experiment on restaurant choice, finding strong support for the theoretical predictions. These responses are also used to train classifiers using a bag-of-words model to predict the degree to which each review in the larger data sets relates to quality and/or taste, allowing the authors to estimate the two types of review variances. Finally, the authors estimate the effects of these variances in overall ratings on establishment sales, again finding support for the theoretical results. © American Marketing Association 2022.",TestAnalysis
"Background: Nutrition and physical activity are associated with prostate cancer recurrence and mortality. Few randomized controlled trials (RCT) have examined the effects of long-term exercise and diet changes on prostate cancer clinical, biological, and patient-reported outcomes. Methods: Prostate 8-II is a 4-arm RCT among 200 men with prostate cancer who chose radical prostatectomy (RP) as their primary treatment. Men are enrolled prior to RP and randomized to exercise-only, diet-only, exercise + diet, or usual care (50/arm). Participants begin their assigned intervention 0–5 weeks prior to RP and continue for 24-months following surgery. The 3 active intervention arms receive access to a web-portal and text messages, coaching calls, and other intervention resources (e.g., heart rate sensor and resistance bands and/or recipe booklet). Weekly exercise goals for the exercise intervention groups are 150 min moderate or 75 min vigorous aerobic exercise, 2 strength sessions, and 2 flexibility sessions. Diet intervention groups work with a dietitian to customize their goals (e.g., increase cruciferous vegetables, cooked tomatoes, healthy fats, fish; limit processed meats, whole milk). The primary endpoint is biochemical recurrence. Secondary endpoints include change in tumor biomarkers from biopsy to RP as well as patient-reported outcomes (e.g., quality-of-life), blood and urine biomarkers, and anthropometry at 0, 6, 12, and 24 months. Conclusion: This 4-arm RCT will examine the impact of change in exercise and diet (alone or in combination) on prostate cancer recurrence, biology, and quality-of-life. © 2023",TestAnalysis
"Background: This review’s goals were to investigate apremilast’s efficacy versus placebo in palmoplantar psoriasis (PP) and palmoplantar pustulosis (PPP), and apremilast’s efficacy versus methotrexate in PP. Methods: A literature search was conducted in PubMed, clinicaltrials.gov, and Embase in July 2022. Publications investigating subjects with PP or PPP, treated with apremilast, which reported palmoplantar-specific outcomes were used. Exclusion criteria included cases of drug-induced PP/PPP, case studies, non-English texts, omission of palmoplantar-specific outcomes, and incomplete publications. Studies were assessed for risk of bias using Cochrane Review Manager application and CASP checklist. Primary endpoints were a 50% improvement of the Palmoplantar Psoriasis/Pustulosis Area and Severity Index (PPPASI 50) and improvement of the Palmoplantar Physician Global Assessment (PPPGA) to 0 or 1 in patients with baseline PPPGA ≥ 3. Results: Seventeen original studies including five placebo-controlled randomized clinical trials (RCTs), one phase II clinical trial, two randomized methotrexate comparative trials, six cohort studies, and three case series were analyzed, totaling 1117 participants. Meta-analysis of four placebo-controlled RCTs investigating PP found apremilast treatment to be superior to placebo in achieving a PPPGA of 0/1 (baseline PPPGA of ≥ 3) after 16 weeks of treatment (n = 244; OR = 2.69 [1.39–5.22]). Apremilast was superior to placebo in achieving PPPASI 50 at week 16 in the only placebo-controlled RCT of PPP (78.3 vs. 40.9%) [P = 0.0003]. Apremilast was comparable to methotrexate in achieving PPPASI 50 at week 16 in PP (59.5 vs. 64.3%; n = 84; [P = 0.65]). Non-randomized studies generally showed marked improvement in PPPASI, PPPGA, and DLQI scores following apremilast treatment. Discussion: Apremilast treatment in PP and PPP resulted in significant improvement in objective, palmoplantar-specific clinical parameters versus placebo, and comparable efficacy with methotrexate in PP. Limitations in interpreting these results include variations in palmoplantar-specific metrics used and risk of bias of included studies. © 2023, The Author(s).",TestAnalysis
To improve the accuracy of the static membrane deflection calculation for the collapse mode capacitive micromachined ultrasonic transducer (CMUT) fabricated by sacrificial release (SR) method. The beam theory was used and the substrate supporting force can be modeled by a coefficient to the load on the membrane. The surrounding supporting post bending can be modeled by applying the elastic support boundary conditions (ESBCs) for the peripheral part of the membrane. CMUT devices have been fabricated using the SR process to validate this analytical analysis. Young's modulus of \text {Si}-{{3}} \text {N}-{{4}} was derived as 200 GPa by a method using center deflections of several different radii single-layer conventional devices under 1 atm. The analytical deflection results and contact radius results for the collapse mode CMUT membranes were testified by experimental results under 1 atm and were found matching the experimental results. This showed that the analysis can provide improved results for SR fabricated CMUT devices by including the substrate supporting effect and the post bending effect.  © 2001-2012 IEEE.,TestAnalysis
"Objectives: To explore indicators of the following questionable research practices (QRPs) in randomized controlled trials (RCTs): (1) risk of bias in four domains (random sequence generation, allocation concealment, blinding of participants and personnel, and blinding of outcome assessment); (2) modifications in primary outcomes that were registered in trial registration records (proxy for selective reporting bias); (3) ratio of the achieved to planned sample sizes; and (4) statistical discrepancy. Study Design and Setting: Full texts of all human RCTs published in PubMed in 1996–2017 were automatically identified and information was collected automatically. Potential indicators of QRPs included author-specific, publication-specific, and journal-specific characteristics. Beta, logistic, and linear regression models were used to identify associations between these potential indicators and QRPs. Results: We included 163,129 RCT publications. The median probability of bias assessed using Robot Reviewer software ranged between 43% and 63% for the four risk of bias domains. A more recent publication year, trial registration, mentioning of CONsolidated Standards Of Reporting Trials-checklist, and a higher journal impact factor were consistently associated with a lower risk of QRPs. Conclusion: This comprehensive analysis provides an insight into indicators of QRPs. Researchers should be aware that certain characteristics of the author team and publication are associated with a higher risk of QRPs. © 2022 The Authors",TestAnalysis
"This paper examines the effects of online campaigns celebrating frontline workers on COVID-19 outcomes regarding new cases, deaths, and vaccinations, using the United Kingdom as a case study. We implement text and sentiment analysis on Twitter data and feed the result into random regression forests and cointegration analysis. Our combined machine learning and econometric approach shows very weak effects of both the volume and the sentiment of Twitter discussions on new cases, deaths, and vaccinations. On the other hand, established relationships (such as between stringency measures and cases/deaths and between vaccinations and deaths) are confirmed. On the contrary, we find adverse lagged effects from negative sentiment to vaccinations and from new cases to negative sentiment posts. As we assess the knowledge acquired from the COVID-19 crisis, our findings can be used by policy makers, particularly in public health, and prepare for the next pandemic. © 2023 Elsevier Ltd",TestAnalysis
"Background People with advanced cancer frequently use the GP out-of-hours (GPOOH) service. Considerable amounts of routine GPOOH data are uncoded. Therefore, these data are omitted from existing healthcare datasets. Aim To conduct a free-text analysis of a GPOOH dataset, to identify reasons for attendance and care delivered through GPOOH to people with advanced cancer. Design and setting An analysis of a GPOOH healthcare dataset was undertaken. It contained all coded and free-text information for 5749 attendances from a cohort of 2443 people who died from cancer in Tayside, Scotland, from 2013–2015. Method Random sampling methods selected 575 consultations for free-text analysis. Each consultation was analysed by two independent reviewers to determine the following: assigned presenting complaints; key and additional palliative care symptoms recorded in free text; evidence of anticipatory care planning; and free-text recording of dispensed medications. Inter-rater reliability concordance was established through Kappa testing. Results More than half of all coded reasons for attendance (n= 293; 51.0%) were ‘other’ or ‘missing’. Free-text analysis demonstrated that nearly half (n= 284; 49.4%) of GPOOH attendances by people with advanced cancer were for pain or palliative care. More than half of GPOOH attendances (n= 325; 56.5%) recorded at least one key or additional palliative care symptom in free text, with the commonest being breathlessness, vomiting, cough, and nausea. Anticipatory care planning was poorly recorded in both coded and uncoded records. Uncoded medications were dispensed in more than one-quarter of GPOOH consultations. Conclusion GPOOH delivers a substantial amount of pain management and palliative care, much of which is uncoded. Therefore, it is unrecognised and under-reported in existing large healthcare data analyses. © The Authors.",TestAnalysis
"Background: Although patient-reported outcome measures (PROMs) have become a regularly used metric, there is little consensus on the methodology used to determine clinically relevant postoperative outcomes. We systematically reviewed the literature for studies that have identified metrics of clinical efficacy after total hip arthroplasty (THA) including minimal clinically important difference (MCID), patient acceptable symptom state (PASS), minimal detectable change (MDC), and substantial clinical benefit (SCB). Methods: A systematic review examining quantitative metrics for assessing clinical improvement with PROMs following THA was conducted according to Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines using the MEDLINE database from 2008 to 2020. Inclusion criteria included full texts, English language, primary THA with minimum 1-year follow-up, use of metrics for assessing clinical outcomes with PROMs, and primary derivations of those metrics. Sixteen studies (24,487 THA patients) met inclusion criteria and 11 different PROMs were reported. Results: MCIDs were calculated using distribution methods in 7 studies (44%), anchor methods in 2 studies (13%), and both methods in 2 studies (13%). MDC was calculated in 2 studies, PASS was reported in 1 study using anchor-based method, and SCB was calculated in 1 study using anchor-based method. Conclusion: There is a lack of consistency in the literature regarding the use and interpretation of PROMs to assess patient satisfaction. MCID was the most frequently reported measure, while MDC, SCB, and PASS were used relatively infrequently. Method of derivation varied based on the PROM used; distribution method was more frequently used for MCID. © 2022 Elsevier Inc.",TestAnalysis
"Surveillance of drug overdose deaths relies on death certificates for identification of the substances that caused death. Drugs and drug classes can be identified through the International Classification of Diseases, Tenth Revision (ICD-10), codes present on death certificates. However, ICD-10 codes do not always provide high levels of specificity in drug identification. To achieve more fine-grained identification of substances on death certificate, the free-text cause-of-death section, completed by the medical certifier, must be analyzed. Current methods for analyzing free-text death certificates rely solely on lookup tables for identifying specific substances, which must be frequently updated and maintained. To improve identification of drugs on death certificates, a deep-learning named-entity recognition model was developed, utilizing data from the Kentucky Drug Overdose Fatality Surveillance System (2014–2019), which achieved an F1-score of 99.13%. This model can identify new drug misspellings and novel substances that are not present on current surveillance lookup tables, enhancing the surveillance of drug overdose deaths. © The Author(s) 2022. Published by Oxford University Press on behalf of the Johns Hopkins Bloomberg School of Public Health. All rights reserved.",TestAnalysis
"A large number of Web APIs have been released as services in mobile communications, but the service provided by a single Web API is usually limited. To enrich the services in mobile communications, developers have combined Web APIs and developed a new service, which is known as a mashup. The emergence of mashups greatly increases the number of services in mobile communications, especially in mobile networks and the Internet-of-Things (IoT), and has encouraged companies and individuals to develop even more mashups, which has led to the dramatic increase in the number of mashups. Such a trend brings with it big data, such as the massive text data from the mashups themselves and continually-generated usage data. Thus, the question of how to determine the most suitable mashups from big data has become a challenging problem. In this paper, we propose a mashup recommendation framework from big data in mobile networks and the IoT. The proposed framework is driven by machine learning techniques, including neural embedding, clustering, and matrix factorization. We employ neural embedding to learn the distributed representation of mashups and propose to use cluster analysis to learn the relationship among the mashups. We also develop a novel Joint Matrix Factorization (JMF) model to complete the mashup recommendation task, where we design a new objective function and an optimization algorithm. We then crawl through a real-world large mashup dataset and perform experiments. The experimental results demonstrate that our framework achieves high accuracy in mashup recommendation and performs better than all compared baselines. © 2022 Chongqing University of Posts and Telecommunications",TestAnalysis
"Recently, deep learning has been widely used to solve existing computing problems through large-scale data mining. Conventional training of the deep learning model is performed on a central (cloud) server that is equipped with high computing power, by integrating data via high computational intensity. However, integrating raw data from multiple clients raises privacy concerns that are increasingly being focused on. In federated learning (FL), clients train deep learning models in a distributed fashion using their local data; instead of sending raw data to a central server, they send parameter values of the trained local model to a central server for integration. Because FL does not transmit raw data to the outside, it is free from privacy issues. In this paper, we perform an experimental study that explores the dynamics of the FL-based Android malicious app detection method under three data distributions across clients, i.e., (i) independent and identically distributed (IID), (ii) non-IID, (iii) non-IID and unbalanced. Our experiments demonstrate that the application of FL is feasible and efficient in detecting malicious Android apps in a distributed manner on cellular networks. © 2023 by the author.",TextMining
[No abstract available],TextMining
"Danmaku data from an online course contains implicit information about the students, the teacher, and the course itself. To discover the information, we design a behavior-sentiment-topic mining procedure, and apply it on the danmaku from two electronics courses on Bilibili, a popular video sharing platform in China. The procedure enables us to obtain behavior patterns, text sentiments, and hidden topics, of those danmaku comments effectively. Results show similarities and differences between the danmaku from Fundamentals of Analog Electronics and that from Fundamentals of Digital Electronics. Some interesting observations are given according to the results. For example, students tend to experience an emotional upsurge right before the end of a course, which is due to their fulfilment for completing the course. Based on the observations, we make some suggestions for students, teachers, and platforms on how to improve the learning outcomes using the results of danmaku analysis. © 2023 by the authors.",TextMining
"This study aims to compare three popular machine learning (ML) algorithms including random forest (RF), boosting regression tree (BRT), and multinomial logistic regression (MnLR) for spatial prediction of groundwater quality classes and mapping it for salinity hazard. Three hundred eighty-six groundwater samples were collected from an agriculturally intensive area in Fars Province, Iran, and nine hydro-chemical parameters were defined and interpreted. Variance inflation factor and Pearson’s correlations were used to check collinearity between variables. Thereinafter, the performance of ML models was evaluated by statistical indices, namely, overall accuracy (OA) and Kappa index obtained from the confusion matrix. The results showed that the RF model was more accurate than other models with the slight difference. Moreover, the analysis of relative importance also indicated that sodium adsorption ratio (SAR) and pH have the most impact parameters in explaining groundwater quality classes, respectively. In this research, applied ML algorithms along with the hydro-chemical parameters affecting the quality of ground water can lead to produce spatial distribution maps with high accuracy for managing irrigation practice. © 2023, The Author(s), under exclusive licence to Springer Nature Switzerland AG.",TextMining
"The impact of bitumen components on soil and groundwater resources is of environmental importance. Contaminants’ influx into the environment from bitumen components through anthropogenic activities such as exploration, mining, transportation, and usage of bitumen in all its forms have been reported globally. However, gaps exist in the geogenic occurrence of bitumen in the shallow subsurface such as in southwest Nigeria, contaminating the soil and groundwater resources. This review presents in situ bitumen seeps as a source of geogenic soil and groundwater contaminants in southwestern Nigeria. We conducted a systematic review of literatures based on defined selection criteria. We derived information on the state of knowledge about bitumen seep occurrences and distribution in southwestern Nigeria. Also, the processes that exacerbate bitumen contaminants’ influx into soil and groundwater were enunciated. At the same time, case examples highlighted areas for possible in situ bitumen contamination studies in Nigeria. The results of this review showed that a multidisciplinary approach has been employed to assess and monitor the contaminants resulting from the various activities involving the exploitation and application of bitumen in Nigeria. These studies emphasize bitumen contaminants as emanating from anthropogenic sources. The results also suggested that bitumen studies have been mainly exploratory to improve the understanding of the economic potential of the hydrocarbon reserve. Also, recent advances in bitumen contaminants studies accounted for the heterogeneous nature of the bitumen. This allows for the optimized categorization of the mechanism and processes undergone by the different bitumen components when released as environmental contaminants. However, a knowledge gap exists in characterizing and understanding the effects of in situ bitumen seeps as a geogenic source of soil and groundwater contamination. This review identifies the possibility of geogenic soil and groundwater contamination by in situ bitumen seeps in the coastal plain sand of the Dahomey basin in southwestern Nigeria. The impact of the bitumen contaminants on the environment was discussed, while methods for accessing the occurrence and distribution of the bitumen contaminants were highlighted. © 2023, The Author(s).",TextMining
"Snow cover as an important water resource is essential for regional water environment system. The Three-Rivers Headwater Region (THR) in the Tibetan Plateau is the source of the Yellow River, the Yangtze River and the Lantsang River with fragile ecological environment and large snow cover. The analysis of hydrochemistry in snow cover can provide reliable data for the research of environmental changes. Snow cover samples in 57 sites across the THR region were collected, and arsenic (As) and major ions were analyzed to investigate the distribution characteristics. The snow cover samples were weakly alkaline with water type of SO4–Cl–Ca–Mg. The As concentration varied from 0.24 to 6.12 μg/L with average value of 1.25 μg/L. Major ions and As have similar distribution characteristics, with higher levels in the northern part of the study area due to anthropogenic influence and special geography. Qualitative and semi-quantitative analysis of snow cover samples based on principal component analysis and absolute principal component score-multiple linear regression indicated that As was substantially controlled by burning of fossil fuels and local mining activities, while major ions mainly derived from terrestrial dust, human activities and marine sources. Although there were different trajectories at the sampling points, the air mass in THR was mainly controlled by the westerly circulation. The water quality of THR was excellent with water quality index <50. This work will shed lights for the migration and transformation of pollutants in the Tibet Plateau and for assessing the impact of human activities on geochemical cycling of pollutants. © 2023 Turkish National Committee for Air Pollution Research and Control",TextMining
"Digital twins are a kind of digital industrial technologies developed in recent years. This paper introduces the construction process of dynamic digital twin system for deep-sea mining system. Deepsea mining system has a complex composition, complicated operation procedure, and extreme working environment. It is of great significance to establishing dynamic digital twin system for deep-sea mining system to carry out visual monitoring and data management for the whole life cycle of mining process, and realize interactive control in the deep-sea mining operation. In this paper we establish a high-precision and multi-scale digital model for the physical entities of deep-sea mining system, which maps the mining system from physical object to digital space to drive the digital model with updated status collected from physical space. The application framework, key technologies, development process and operation process of the system are explained, and the development process of dynamic digital twin system for deep-sea mining based on state diagnosis is expounded, which is of great significance in deep-sea mining. © 2023 Editorial Board of Journal of Harbin Engineering. All rights reserved.",TextMining
"Induced pluripotent stem cells (iPSCs) can differentiate into all types of cells and can be used in livestock for research on biological development, genetic breeding, and in vitro genetic resource conservation. The Bactrian camel is a large domestic animal that inhabits extreme environments and holds value in the treatment of various diseases and the development of the local economy. Therefore, we transferred four mouse genes (Oct4, Sox2, Klf4, and c-Myc) into Bactrian camel fetal fibroblasts (BCFFs) using retroviruses with a large host range to obtain Bactrian camel induced pluripotent stem cells (bciPSCs). They were comprehensively identified based on cell morphology, pluripotency gene and marker expression, chromosome number, transcriptome sequencing, and differentiation potential. The results showed the pluripotency of bciPSCs. However, unlike stem cells of other species, late formation of stem cell clones was observed; moreover, the immunofluorescence of SSEA1, SSEA3, and SSEA4 were positive, and teratoma formation took four months. These findings may be related to the extremely long gestation period and species specificity of Bactrian camels. By mining RNA sequence data, 85 potential unique pluripotent genes of Bactrian camels were predicted, which could be used as candidate genes for the production of bciPSC in the future. Among them, ASF1B, DTL, CDCA5, PROM1, CYTL1, NUP210, Epha3, and SYT13 are more attractive. In conclusion, we generated bciPSCs for the first time and obtained their transcriptome information, expanding the iPSC genetic information database and exploring the applicability of iPSCs in livestock. Our results can provide an experimental basis for Bactrian camel ESC establishment, developmental research, and genetic resource conservation. © 2023 by the authors.",TextMining
"If the shearer is cutting coal using the “memory cutting” technique,a manual demonstration is required. The memory cutting technology has higher requirements on the reserving conditions of coal seams. When the coal seam fluctuates greatly,frequent manual demonstrations are required. The “memory cutting” technology only optimizes the cutting path of the coal seam roof for the next cutting. Along the advancing direction of the shearer,it is impossible to accurately plan and control the pitching angle of the shearer according to the reserving conditions of the coal seam. Based on the concept of shearer self-adaptive intelligent cutting,this paper designs the operation mode of the shearer intelligent cutting system in the fully mechanized working face. In this model,the high-precision three-dimensional geological model of the working face is first constructed by using the highly accurate geophysical data of the coal seam,and then the future cutting path of the shearer is planned by using the model. At the same time,the high-precision three-dimensional geological model is dynamically corrected by using the latest geological data of the working face during the mining process. In this paper,the high-precision three-dimensional dynamic geological model is coupled with the shearer mining planning algorithm. According to the model,a shearer mining control baseline planning algorithm that can adapt to the changes of the coal seam is proposed,which realizes the pitching control of the shearer in the advancing direction and the cutting control in the pulling direction,as well as the efficient cooperation between the update of the geological model,the planning of the mining baseline and the adjustment of the shearer drum. The calculation service interface of the drum adjustment parameters in the intelligent cutting system and the communication protocol between the intelligent cutting system is designed. Addtionally,the shearer control system is considered. This realizes the precise control of the shearer drum based on the planning cutting path. The intelligent cutting system of fully mechanized working face is applied to guide the production of shearers. The practice shows that the shearer intelligent cutting system is suitable for coal seams with various degrees of floor inclination. The cutting line of the shearer can better fit the roof and floor lines of the coal seam,which can save resources and improve production efficiency. © 2023 Authors. All rights reserved.",TextMining
"Association rule mining is an efficient method to mine the association relationships between different items from large transaction databases, but is vulnerable to privacy leakage as operates over users’ sensitive data directly. Privacy-preserving association rule mining has emerged to protect users’ privacy during rule mining. Unfortunately, existing privacy-preserving association rule mining schemes suffer from high overhead, fail to support multiple users, and are challenging to prevent collusion attacks between twin-server. To this end, in this paper, we propose a privacy-preserving association rule mining solution via multi-key fully homomorphic encryption over the torus (MKTFHE), which efficiently supports multiple users through a single server only. Specifically, we first construct some multi-key homomorphic gates based on MKTFHE. Then, we designed a series of privacy-preserving computational protocols based on multi-key homomorphic gates. Finally, we build a privacy-preserving association rule mining system with a single cloud server to support multiple users. Moreover, privacy analysis and performance evaluation demonstrate our proposal is efficient and feasible. In contrast to existing solutions, the proposed scheme outperforms encryption and communication, saving approximately 8.5% running time. © 2023 The Author(s)",TextMining
"Out-of-school children (OSC) surveys are conducted annually throughout Pakistan, and the results show that the literacy rate is increasing gradually, but not at the desired speed. Enrollment campaigns and targets system of enrollment given to the schools required a valuable model to analyze the enrollment criteria better. In existing studies, the research community mainly focused on performance evaluation, dropout ratio, and results, rather than student enrollment. There is a great need to develop a model for analyzing student enrollment in schools. In this proposed work, five years of enrollment data from 100 schools in the province of Punjab (Pakistan) have been taken. The significant features have been extracted from data and analyzed through machine learning algorithms (Multiple Linear Regression, Random Forest, and Decision Tree). These algorithms contribute to the future prediction of school enrollment and classify the school’s target level. Based on these results, a brief analysis of future registrations and target levels has been carried out. Furthermore, the proposed model also facilitates determining the solution of fewer enrollments in school and improving the literacy rate. © 2023 by the authors.",TextMining
"Many traditional educational management models are being switched or shifted into online platforms; thus, assessing behavioral aspects of learners is essential to improving the quality of online teaching and learning processes. Currently, a problem in managing online teaching of courses is that instructors do not have the appropriate tools and techniques to be fully aware of students’ behavioral patterns in a data-driven and process-aware approach. This study is divided into three main parts. In the first part, a dataset of online students is transformed and preprocessed. In the second part, the Fuzzy Miner algorithm supported by Fluxicon Disco is applied to the dataset to understand the learning process of the students in terms of the duration and length of the tutorial videos watched online (i.e., fully watched, partially watched, paused, and resumed intervals) and in terms of the frequencies of all activities. In the third part, a comparison between behavioral patterns of high-performance group of students versus their low-performance counterparts attending the same course was conducted, and we used the Dotted Chart Analysis technique supported by ProM to conduct and make the comparisons. The results of the study showed significant differences between the two groups in terms of the duration spent on the tutorial videos and in terms of the sequence and order of the activities performed and executed. The findings of the research can be used by instructors, administrators, and educational managers to improve the course curriculum management process or to boost effective coaching and teaching styles, leading to the optimization of students’ learning process by increasing educators’ awareness about students’ weaknesses and strengths. © 2023 by the authors.",TextMining
[No abstract available],TextMining
"Objectives Motor neuron disease (MND) is an incurable progressive neurodegenerative disease with limited treatment options. There is a pressing need for innovation in identifying therapies to take to clinical trial. Here, we detail a systematic and structured evidence-based approach to inform consensus decision making to select the first two drugs for evaluation in Motor Neuron Disease-Systematic Multi-arm Adaptive Randomised Trial (MND-SMART: NCT04302870), an adaptive platform trial. We aim to identify and prioritise candidate drugs which have the best available evidence for efficacy, acceptable safety profiles and are feasible for evaluation within the trial protocol. Methods We conducted a two-stage systematic review to identify potential neuroprotective interventions. First, we reviewed clinical studies in MND, Alzheimer's disease, Huntington's disease, Parkinson's disease and multiple sclerosis, identifying drugs described in at least one MND publication or publications in two or more other diseases. We scored and ranked drugs using a metric evaluating safety, efficacy, study size and study quality. In stage two, we reviewed efficacy of drugs in MND animal models, multicellular eukaryotic models and human induced pluripotent stem cell (iPSC) studies. An expert panel reviewed candidate drugs over two shortlisting rounds and a final selection round, considering the systematic review findings, late breaking evidence, mechanistic plausibility, safety, tolerability and feasibility of evaluation in MND-SMART. Results From the clinical review, we identified 595 interventions. 66 drugs met our drug/disease logic. Of these, 22 drugs with supportive clinical and preclinical evidence were shortlisted at round 1. Seven drugs proceeded to round 2. The panel reached a consensus to evaluate memantine and trazodone as the first two arms of MND-SMART. Discussion For future drug selection, we will incorporate automation tools, text-mining and machine learning techniques to the systematic reviews and consider data generated from other domains, including high-throughput phenotypic screening of human iPSCs.  © 2023 BMJ Publishing Group. All rights reserved.",TextMining
"Mine slope landslides seriously threaten the safety of people’s lives and property in mining areas. Landslide prediction is an effective way to reduce losses due to such disasters. In recent years, micro-deformation monitoring radar has been widely used in mine slope landslide monitoring. However, traditional landslide prediction methods are not able to make full use of the diversified monitoring data from these radars. This paper proposes a landslide time prediction method based on the time series monitoring data of micro-deformation monitoring radar. Specifically, deformation displacement, coherence and deformation volume, and the parametric degree of deformation (DOD) are calculated and combined with the use of the tangent angle method. Finally, the effectiveness of the method is verified by using measured data of a landslide in a mining area. The experimental results show that our proposed method can be used to identify the characteristics of an imminent sliding slope and landslide in advance, providing monitoring personnel with more reliable landslide prediction results. © 2023 by the authors.",TextMining
"Accident analysis is used to discover the causes of workplace injuries and devise methods for preventing them in the future. There has been little discussion in the previous studies of the specific elements contributing to deadly construction accidents. In contrast to previous studies, this study focuses on the causes of fatal construction accidents based on management factors, unsafe site conditions, and workers' unsafe actions. The association rule mining technique identifies the hidden patterns or knowledge between the root causes of fatal construction accidents, and one hundred meaningful association rules were extracted from the two hundred and fifty-three rules generated. It was discovered that many fatal construction accidents were caused by management factors, unsafe site circumstances, and risky worker behaviors. These analyses can be used to demonstrate plausible cause-and-effect correlations, assisting in building a safer working environment in the construction sector. The study findings can be used more efficiently to design effective inspection procedures and occupational safety initiatives. Finally, the proposed method should be tested in a broader range of construction situations and scenarios to ensure that it is as accurate as possible. © 2023 The Authors",TextMining
"Hyperspectral image (HSI) anomaly detection (HSI-AD) has become a hot issue in hyperspectral information processing as a method for detecting undesired targets without a priori information against unknown background and target information, which can be better adapted to the needs of practical applications. However, the demanding detection environment with no prior and small targets, as well as the large data and high redundancy of HSI itself, make the study of HSI-AD very challenging. First, we propose an HSI-AD method based on the nonsubsampled shearlet transform (NSST) domain spectral information divergence isolation double forest (SI2FM) in this paper. Further, the method excavates the intrinsic deep correlation properties between NSST subband coefficients of HSI in two ways to provide synergistic constraints and guidance on the prediction of abnormal target coefficients. On the one hand, with the “difference band” as a guide, the global isolation forest and local isolation forest models are constructed based on the spectral information divergence (SID) attribute values of the difference band and the low-frequency and high-frequency subbands, and the anomaly scores are determined by evaluating the path lengths of the isolation binary tree nodes in the forest model to obtain a progressively optimized anomaly detection map. On the other hand, based on the relationship of NSST high-frequency subband coefficients of spatial-spectral dimensions, the three-dimensional forest structure is constructed to realize the co-optimization of multiple anomaly detection maps obtained from the isolation forest. Finally, the guidance of the difference band suppresses the background noise and anomaly interference to a certain extent, enhancing the separability of target and background. The two-branch collaborative optimization based on the NSST subband coefficient correlation mining of HSI enables the prediction of anomaly sample coefficients to be gradually improved from multiple perspectives, which effectively improves the accuracy of anomaly detection. The effectiveness of the algorithm is verified by comparing real hyperspectral datasets captured in four different scenes with eleven typical anomaly detection algorithms currently available. © 2023 by the authors.",TextMining
"One of the basic requirements for providing quality teaching and learning to stakeholders is the ICT competency of teachers in the academe or institution. Individual skills are an essential aspect of achieving effective education with the aid of modern technologies. The need to support teachers' professional development is underscored by technological and pedagogical breakthroughs in ICT and Education. This study aims to predict the ICT competency level of teachers using classification algorithms, and the university used the results of the study to make interventions for teachers' need for training and development to capacitate the ICT skills of teachers. For this purpose, through WEKA data mining tool, the test options used are 10 folds cross-validation for the 7 classification algorithms: Naïve Bayes, J48, RepTree, Random Forest, Random Tree, Hoeffding Tree, and Logistic Model Tree (LMT) to predict teachers' competency level in terms of technology operations and concepts, social and ethical, pedagogical and professional. The accuracy of the algorithms was used to evaluate their performance. Furthermore, based on the overall findings of the algorithm performance, the LMT algorithm is recommended for predicting the ICT skill level of teachers. Moreover, the findings of this study will be used as a benchmark for conducting training to assist and capacitate teachers' ICT skills and gain experience in dealing with new devices, modern technologies, and new pedagogical approaches. © School of Engineering, Taylor's University.",TextMining
"In the 21st century, problems relating to energy, economy, and the environment have become increasingly severe across the world, and critical issues around environmental pollution, ecological imbalance, and an energy crisis have emerged. The Yellow River basin is an important ecological barrier, economic region, and energy base in Northern China. Environmental pollution in the Yellow River basin has become increasingly problematic, especially since the reform and opening up of China, along with the rapid development of the industrial economy and mining for energy resources. In this study, 64 of the 73 prefecture-level cities in the Yellow River basin were selected as the research object, including 18 cities in the downstream region, 26 cities in the midstream region, and 20 cities in the upstream region. The data used in this study were from 2004 to 2019. On the basis of temporal variation and spatial differentiation of the three factors of economy, energy, and environment, the impulse response function and the generalized method of moments (GMM) were adopted to evaluate the effects of energy utilization and economic growth on the ecological environment. Their roles in affecting the ecological environment were analyzed along with the underlying mechanisms. Overall, energy utilization, economic growth, and ecological environment are in good condition, showing a steady upward trend. Regional differences still exist, but the gap is gradually narrowing. There are some differences in the impulse response of the ecological environment to the economic growth and energy utilization in the upstream, midstream, and downstream regions of the Yellow River basin. The effect is leveled out or weakened in the middle and later phases of the impact. Compared with the downstream and upstream regions, economic growth and energy utilization in the midstream regions have less impact on the ecological environment. The two factors of energy utilization potential and economic potential have significant positive impacts on the ecological environment. The current situation of energy utilization has to some extent a positive impact on the ecological environment. Economic scale has a certain negative impact on the ecological environment. © 2023 by the authors.",TextMining
"Future work sentences (FWS) are the particular sentences in academic papers that contain the author's description of their proposed follow-up research direction. This paper presents methods to automatically extract FWS from academic papers and classify them according to the different future directions embodied in the paper's content. FWS recognition methods will enable subsequent researchers to locate future work sentences more accurately and quickly and reduce the time and cost of acquiring the corpus. At the same time, changes in the content of future work will be illuminated, and a foundation will be laid for a more in-depth semantic analysis of future work sentences. The current work on automatic identification of future work sentences is relatively small, and the existing research cannot accurately identify FWS from academic papers, and thus cannot conduct data mining on a large scale. Furthermore, there are many aspects to the content of future work, and the subdivision of the content is conducive to the analysis of specific development directions. In this paper, Nature Language Processing (NLP) is used as a case study, and FWS are extracted from academic papers and classified into different types. We manually build an annotated corpus with six different types of FWS. Then, automatic recognition and classification of FWS are implemented using machine learning models, and the performance of these models is compared based on the evaluation metrics. The results show that the Bernoulli Bayesian model has the best performance in the automatic recognition task, with the Macro F1 reaching 90.73%, and the SCIBERT model has the best performance in the automatic classification task, with the weighted average F1 reaching 72.63%. Finally, we extract keywords from FWS and gain a deep understanding of the key content described in FWS, and we also demonstrate that content determination in FWS will be reflected in the subsequent research work by measuring the similarity between future work sentences and the abstracts.  © 2022 Elsevier Ltd.",TextMining
"In the context of China’s “digital power” strategy, the realization of a green and low-carbon shift in manufacturing has become a necessary condition to promote the economy, and the digital factor has increasingly become a new driving force. The text mining and IPCC methods were used to measure manufacturing enterprise digitalization and the level of enterprise carbon emission intensity from 2011 to 2021, respectively. This study then explored the impact of digitalization on manufacturing enterprise carbon emission intensity based on the least squares method model and instrumental variable method model. This research comes to three conclusions. (1) Digitalization can significantly reduce the enterprise carbon emission intensity of China’s manufacturing industry, and the influence shows a “marginal increase.” (2) Notably, a mechanism analysis indicates the intermediary effect sizes of four crucial intermediaries: green technology innovation > financing constraint > information asymmetry > energy use efficiency. Interestingly, digital information resources positively moderate the positive effect of digitalization on carbon emission intensity through three paths: financing constraints, green technology innovation, and information asymmetry. (3) The influence shows evident signs of heterogeneity—as environmental regulation, financial development, executive education, and R&D quality advance, the inhibiting effect of digitalization on enterprise carbon emission intensity becomes more pronounced. Finally, corresponding policy suggestions are proposed. © 2023 by the authors.",TextMining
"Spatio-temporal ground-movement measurements and mappings have been carried out in the Campine coalfield in Belgian Limburg since the closure of the mines to document post-mining effects. MT-InSAR measurements are compared to groundwater head changes in the overburden and to height data from the closest GNSS stations. Radar interferometry is used to estimate the extension and the velocity of ground movements. In particular, the MT-InSAR technique has been applied to SAR acquisitions of the satellites ERS-1/2 (1991–2005), ENVISAT (2003–2010), COSMO-SkyMed (2011–2014), and Sentinel-1A (2014–2022). The images were processed and used to highlight a switch from subsidence to uplift conditions in the western part of the coal basin, while the eastern part had already been affected by a rebound since the beginning of the ERS-1/2 acquisitions. Following the closure of the last active colliery of Zolder in 1992 and the subsequent cease of mine-water pumping, a recharge of mine-water aquifers occurred in the western part of the basin. This process provoked the change from subsidence to uplift conditions that was recorded during the ENVISAT period. In the center of the coal-mining area, measured uplift velocities reached a maximum of 18 mm/year during the ENVISAT period, while they subsided at −12 mm/year during the ERS-1/2 period. Mean velocities in the western and eastern parts of the coalfield area have decreased since the last MT-InSAR measurements were performed using Sentinel-1A, while the Zolder coal mine continues to rise at a faster-than-average rate of a maximum of 16 mm/year. The eastern part of the coalfield is still uplifting, while its rate has been reduced from 18 mm/year (ERS-1/2) to 9 mm/year (Sentinel-1A) since the beginning of the radar–satellite observations. Time-series data from the two GNSS stations present in the study area were used for a local comparison with the evolution of ground movements observed by MT-InSAR. Two leveling campaigns (2000, 2013) were also used to make comparisons with the MT-InSAR data. The station’s measurements and the leveling data were in line with the MT-InSAR data. Overall, major ground movements are obviously limited to an extension of the actual underground-mining works and rapidly diminish outside of them. © 2023 by the authors.",TextMining
"The relationship between risk factors for de novo hygroma in patients with traumatic brain injury (TBI) was investigated. We collected data on 222 patients with TBI to determine the risk factors for de novo hygroma, including sex, age, centrum semiovale perivascular space (CSO-PVS) grade, trauma cause, hypertension, and diabetes. The importance of the risk factors was analyzed, and the feature contribution of the risk factors to all patients and each patient was analyzed using predictive modeling. Additionally, association rule mining was performed to determine the relationship between all factors, and the performance metrics of the predictive model were calculated. The overall feature importance was analyzed in the order of age, CSO-PVS, hypertension, and trauma cause. However, trauma cause, underlying disease, age, and sex as risk factors were different for a specific patient through the individual feature analysis. The mean area under the curve for the predictive model was 0.80 ± 0.04 using K-fold cross validation. We analyzed the risk factors for de novo hygroma in TBI and identified detailed relationships. Age and CSO-PVS severity were strongly correlated with de novo hygroma. Furthermore, according to the results of feature importance analysis and association rule mining, the significance of the risk factors may vary in each individual patient. © 2023 by the authors.",TextMining
"Aiming at the problems of low accuracy of coal gangue recognition and difficult recognition of mixed gangue rate, a coal rock recognition method based on modal fusion of RGB and infrared is proposed. A fully mechanized coal gangue transportation test bed is built, RGB images are obtained by camera, and infrared images are obtained by industrial microwave heating system and infrared thermal imager. the image data of the whole coal, whole gangue, and coal gangue with different gangue mixing as training and test samples, identify the released coal gangue and its mixing rate. The AlexNet, VGG-16, ResNet-18 classification networks and their convolutional neural networks with modal feature fusion are constructed. results: The classification accuracy of ResNet networks on RGB and infrared image data is higher than AlexNet and VGG-16 networks. The early convergence network performance of ResNet is verified through the convergence of different models. The recognition rate of the network is 97.92 the confusion matrix statistics, which verifies the feasibility of the application of modal fusion method in the field of coal gangue recognition. The fusion of modal features and early models of ResNet coal gangue, which is the basic premise for realizing intelligent coal caving. © 2023 Zhao et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TextMining
"The physical world can be controlled directly over the Internet once a Cyber-Physical 1 System (CPS) infrastructure is established. The Intelligent Transportation System (ITS) encompasses Wireless Sensor Network (WSN), Vehicular ad hoc network (VANET), and 5G-enabled Internet of Things (IoT) solutions to transform traditional transportation into an ITS. This research investigates the option of running a blockchain-driven security assurance model to safeguard intelligent roads and smart vehicles as part of ITS. The proposed model considers a semi-distributed model in blockchain deployment to ensure satisfactory Internet of Vehicles (IoV) service while mining acceptable security assurance. The experimental outcomes on intelligent roads and smart parking management indicate that the proposed model achieves comparably good data delivery and reduced latency, paving the way to an innovative deployment of blockchain technologies in IoV for a dependable and trustworthy ITS. © 2023 by the authors.",TextMining
"Background and study aim: The study was designed to detect novel Adverse Events (AEs) of pantoprazole by disproportionality analysis in the FDA (Food and Drug Administration) database of Adverse Event Reporting System (FAERS) using Data Mining Algorithms (DMAs). Pantoprazole, the most commonly over-utilized Over The Counter (OTC) medication, was selected to assess any short-term or long-term AEs. The study aimed to analyze the novel adverse events of pantoprazole using the FAERS database. Materials and methods: A retrospective case/non-case disproportionality analysis was performed in the FAERS database. This study was based on AEs reported to FAERS from 2006Q1-2021Q3. Openvigil 2.1 was used for data extraction. Reporting Odds Ratio (ROR), Proportional Reporting Ratio (PRR), and Information Component (IC) were applied to measure the disproportionality in reporting. A value of ROR-1.96SE > 1, PRR ≥ 2, and IC-2SD > 0 were considered as the threshold for a positive signal. Results: A total of 1050 reports of dyspepsia, 7248 reports of hypocalcemia and 995 reports of hyponatremia were identified. A potential positive signal for dyspepsia (ROR-1.96SE = 2.231, PRR = 2.359, IC-2SD = 1.13), hypocalcemia (4.961, 5.45, 2.23) and hyponatremia (3.948, 4.179, 1.92) were identified for pantoprazole. Conclusion: Data mining in the FAERS database produced three potential signals associated with pantoprazole. As a result, further clinical surveillance is needed to quantify and validate potential hazards associated with pantoprazole-related adverse events. © 2022 Pan-Arab Association of Gastroenterology",TextMining
"Almost 40% of US adults provide informal caregiving, yet research gaps remain around what burdens affect informal caregivers. This study uses a novel social media site, Reddit, to mine and better understand what online communities focus on as their caregiving burdens. These forums were accessed using an application programming interface, a machine learning classifier was developed to remove low information posts, and topic modeling was applied to the corpus. An expert panel summarized the forums’ themes into ten categories. The largest theme extracted from Reddit’s forums discussed the personal emotional toll of being a caregiver. This was followed by logistic issues while caregiving and caring for parents who have cancer. Smaller themes included approaches to end-of-life care, physical equipment needs when caregiving, and the use of wearables or technology to help monitor care recipients. The platform often discusses caregiving for parents which may reflect the age of Reddit’s users. This study confirms that Reddit forums are used for caregivers to discuss the burdens associated with their role and the types of stress that can result from informal caregiving. © 2023 by the authors.",TextMining
"Background: As the number of tumor cases significantly increases, so does the quantity of tumor data. The mining and application of large-scale data have promoted the development of tumor big data. Among them, the visualization methods of tumor big data can well show the key information in a large volume of data and facilitate the human brain to receive information. Therefore, tumor big data visualization methods are a key part of the development of tumor big data. Process: This paper first summarizes the connotation, sources, characteristics, and applications of tumor big data, and expounds the current research status of tumor big data visualization at home and abroad. Then, this paper focuses on four mainstream visualization presentation methods of tumor big data, namely the visualization of tumor spatiotemporal data, the visualization of tumor hierarchy and network data, the visualization of tumor text data, and the visualization of multidimensional tumor data, and gives specific application scenarios. After this, the paper introduces the advantages, disadvantages, and scope of the use of five data visualization websites and software that can be easily obtained by readers. Finally, this paper analyzes the problems existing in tumor big data visualization, summarizes the visualization methods, and proposes the future of tumor big data visualization. © 2023 by the authors.",TextMining
"The dynamic compression performance of titanium alloys is important for material design under shock, but the intrinsic relationship between them and basic mechanical properties is still unclear. In this work, based on the mechanical-property data set of Ti20C sheet (4788 pieces of data), the correlation between them was constructed through data-driven and machine-learning methods. Through the trained random-forest regression models, the Quantitative Maps were constructed, and the dynamic compression strength σD, critical fracture strain εf, as well as impact absorption energy ED, were effectively predicted, with the accuracy rates all over 86.11%. Accordingly, the zone of excellent dynamic performance and corresponding quasi-static tensile properties in Maps can be rapidly screened. Furthermore, combined with microstructure observation, it was found that nano-scale acicular secondary α-phase significantly increased σD, micro-scale secondary α-phase resulted in excellent dynamic strength and plasticity, while the equiaxed, bimodal and mixture microstructure without secondary α-phase corresponded to the high value of εf. Meanwhile, both nano-scale and micro-scale secondary α-phase contributed to the high value of ED. Finally, the generalization capabilities of models were validated. By comparing predicted values with experimental values, it was found the models realized the relatively accurate prediction of dynamic compression performance on other titanium alloys. © 2023 The Authors",TextMining
"The implementation of smart networks has made great progress due to the development of the Internet of Things (IoT). LoRa is one of the most prominent technologies in the Internet of Things industry, primarily due to its ability to achieve long-distance transmission while consuming less power. In this work, we modeled different environments and assessed the performances of networks by observing the effects of various factors and network parameters. The path loss model, the deployment area size, the transmission power, the spreading factor, the number of nodes and gateways, and the antenna gain have a significant effect on the main performance metrics such as the energy consumption and the data extraction rate of a LoRa network. In order to examine these parameters, we performed simulations in OMNeT++ using the open source framework FLoRa. The scenarios which were investigated in this work include the simulation of rural and urban environments and a parking area model. The results indicate that the optimization of the key parameters could have a huge impact on the deployment of smart networks. © 2023 by the authors.",TextMining
"Fibre-optic sensing technology has recently become popular for oil and gas extraction, mining, geotechnical engineering, and hydrogeology applications. With a successful track record in many applications, distributed acoustic sensing using straight fibre-optic cables has become a method of choice for seismic studies. However, distributed acoustic sensing using straight fibre-optic cables cannot detect off-Axial strain at high incident angles (the angle between the ray and normal vector of the surface); hence, a helically wound cable design was introduced to overcome this limitation. The helically wound cable field data at the New Afton deposit in British Columbia, Canada, showed that the quality of the data is highly dependent on the incident angle and surrounding media. A 3D finite element model developed using COMSOL Multiphysics quickly and efficiently assessed the effects of various materials surrounding a helically wound cable for simple geometry for scenarios corresponding to a real deployment of such cable underground at the New Afton mine. The proposed numerical modelling workflow could be applied to more complicated scenarios (e.g., non-linear material constitutive behaviour and the effects of pore fluids). The results of this paper can be used as a guideline for analyzing the impact of surrounding media and incident angle on the response of helically wound cable, optimizing the installation of helically wound cable in various conditions, and validating boundary conditions of 3D numerical models built for analyzing complex scenarios.  © 2023 Copernicus GmbH. All rights reserved.",TextMining
"Lameness is one of the culling factors such as mastitis, low milk yield, and infertility that cause economic losses in herd management as they threaten animal health and welfare. The purpose of this study was to evaluate the early detection of lameness in Brown Swiss cattle by using a data mining algorithm by both integrating lameness scores and some image parameters such as Lab (CIE L*, a*, b*), HSB (hue, saturation, brightness), RGB (red, green, blue) by processing thermal images with ImageJ program. In the study, the variables obtained as a result of processing the skin surface temperatures and thermal images taken at the fetlock joint of 33 Brown Swiss cattle were used as independent variables. Also, healthy cows (lameness scores 1 and 2) and unhealthy cows (lameness scores 3, 4, and 5) used in the diagnosis of lameness were used as a binary response variable. Classification and regression tree (CART) was used as a data mining algorithm in the diagnosis of lameness. As a result, the CART algorithm correctly classified 12 of the 13 heads unhealthy cows according to locomotion scores. According to locomotion scores by using CART analysis in this study, independent variables that are used to classify healthy and unhealthy (lame) animals were determined as maximum temperature (Tmax), green (mean), L (max), and age (P<0.05). The cut-off values of these independent variables were predicted as 32.40, 149.14, 97.11, and 5.50 for Tmax, green (mean), L (max), and age, respectively. Also, the sensitivity, specificity, and area under the ROC curve (AUC) of the CART algorithm for locomotion scoring were found as 92.31%, 95%, and 93.7% respectively. The area under ROC curve (AUC) was found to be significant in the diagnosis of lameness (P<0.01). Results showed that the use of CART classification algorithm together with thermal camera and image processing methods is a usefull tool in the detection of lameness in the herds. It is recommended that more comprehensive studies by increasing the number of animals in the future would be more beneficial. © 2023, The Author(s), under exclusive licence to Springer Nature B.V.",TextMining
"At the end of 2015, the Fundão dam belonging to the Samarco S.A. mining company was ruptured, releasing a flood of mud into the Gualaxo do Norte River, which advanced into the Doce River. The aim of the present study was to apply exploratory multivariate approaches to water quality data obtained during sampling campaigns at the Gualaxo do Norte River during the dry and rainy seasons, between July 2016 and June 2017. A total of 27 locations along the river were sampled, covering unaffected areas and regions influenced by the tailings waste from the dam. Determinations of chemical, physical, and microbiological water quality parameters were performed. Application of principal component analysis (PCA) resulted in the first two components together explaining 39.49% and 37.91% of the total variance for the dry and rainy season data, respectively. In both cases, the PCA groups were related to variables such as turbidity and total solids, which both presented higher values in regions affected by the mud flow. These results are in agreement with those obtained by the Kohonen neural network method, where two-dimensional maps confirmed the samples according to the affected and unaffected area by the disaster. Graphical Abstract: [Figure not available: see fulltext.] © 2023, The Author(s), under exclusive licence to Springer Nature Switzerland AG.",TextMining
"Remote sensing technology is widely used in the application of the extraction of lineaments in geological research. However, most of the current traditional lineament extraction methods are based on edge detection technology using a digital filter to extract the mitochondrial features in the image. These previously used algorithms are generally unable to extract the mitochondrial features in the shadow area on the mountain and the area parallel to the direction of the solar incident angle. In this paper, we have improved the STA algorithm (Line Segment Tracking method). The line segmentation and connection methods were firstly proposed, and then 32 search directions were set with one pixel as the center to find the best continuity direction of the lineament. A threshold was then set in this direction to determine whether it was a line element. Finally, line elements were connected into lineaments for further lineament interpretation. The lineament data from three different directions were collected in the Gaosong ore field in the Gejiu mining area, namely at the first place the traditional Canny algorithm, then the improved line segment tracking method, and finally the field measurement. The coefficients of the three-type lineament variations were compared by calculating the lineaments’ strength and their density attributes. It shows that the lineament variability extracted based on the improved line segment tracking method is closer to the measured lineament variability. The results show that the lineaments extracted by the improved algorithm are closer to the measured data. The improved algorithm has higher precision than the traditional Canny algorithm. More realistic and comprehensive lineaments can be attained by using the improved method to extract lineaments in the mining area, which is helpful to the study of the geology of the mining area and helps to construct a more accurate structure model to serve the needs of the mine production. © 2023 by the authors.",TextMining
"Myotonic dystrophy type 1 (DM1) is an autosomal dominant hereditary disease caused by abnormal expansion of unstable CTG repeats in the 3′ untranslated region of the myotonic dystrophy protein kinase (DMPK) gene. This disease mainly affects skeletal muscle, resulting in myotonia, progressive distal muscle weakness, and atrophy, but also affects other tissues and systems, such as the heart and central nervous system. Despite some studies reporting therapeutic strategies for DM1, many issues remain unsolved, such as the contribution of metabolic and mitochondrial dysfunctions to DM1 pathogenesis. Therefore, it is crucial to identify molecular target candidates associated with metabolic processes for DM1. In this study, resorting to a bibliometric analysis, articles combining DM1, and metabolic/metabolism terms were identified and further analyzed using an unbiased strategy of automatic text mining with VOSviewer software. A list of candidate molecular targets for DM1 associated with metabolic/metabolism was generated and compared with genes previously associated with DM1 in the DisGeNET database. Furthermore, g:Profiler was used to perform a functional enrichment analysis using the Gene Ontology (GO) and REAC databases. Enriched signaling pathways were identified using integrated bioinformatics enrichment analyses. The results revealed that only 15 of the genes identified in the bibliometric analysis were previously associated with DM1 in the DisGeNET database. Of note, we identified 71 genes not previously associated with DM1, which are of particular interest and should be further explored. The functional enrichment analysis of these genes revealed that regulation of cellular metabolic and metabolic processes were the most associated biological processes. Additionally, a number of signaling pathways were found to be enriched, e.g., signaling by receptor tyrosine kinases, signaling by NRTK1 (TRKA), TRKA activation by NGF, PI3K-AKT activation, prolonged ERK activation events, and axon guidance. Overall, several valuable target candidates related to metabolic processes for DM1 were identified, such as NGF, NTRK1, RhoA, ROCK1, ROCK2, DAG, ACTA, ID1, ID2 MYOD, and MYOG. Therefore, our study strengthens the hypothesis that metabolic dysfunctions contribute to DM1 pathogenesis, and the exploitation of metabolic dysfunction targets is crucial for the development of future therapeutic interventions for DM1. © 2023 by the authors.",TextMining
"Person re-identification (Re-ID) aims to retrieve a particular pedestrian’s identification from a surveillance system consisting of non-overlapping cameras. In recent years, researchers have begun to focus on open-world person Re-ID tasks based on non-ideal situations. One of the most representative of these is cross-modal person Re-ID, which aims to match probe data with target data from different modalities. According to the modalities of probe and target data, we divided cross-modal person Re-ID into visible–infrared, visible–depth, visible–sketch, and visible–text person Re-ID. In cross-modal person Re-ID, the most challenging problem is the modal gap. According to the different methods of narrowing the modal gap, we classified the existing works into picture-based style conversion methods, feature-based modality-invariant embedding mapping methods, and modality-unrelated auxiliary information mining methods. In addition, by generalizing the aforementioned works, we find that although deep-learning-based models perform well, the black-box-like learning process makes these models less interpretable and generalized. Therefore, we attempted to interpret different cross-modal person Re-ID models from a mathematical perspective. Through the above work, we attempt to compensate for the lack of mathematical interpretation of models in previous person Re-ID reviews and hope that our work will bring new inspiration to researchers. © 2023 by the authors.",TextMining
"Automatic brain tumor detection in MR Images is one of the basic applications of machine vision in medical image processing, which, despite much research, still needs further development. Using multiple machine learning techniques as an ensemble system is one of the solutions that can be effective in achieving this goal. In this paper, a novel method for diagnosing brain tumors by combining data mining and machine learning techniques has been proposed. In the proposed method, each image is initially pre-processed to eliminate its background region and identify brain tissue. The Social Spider Optimization (SSO) algorithm is then utilized to segment the MRI Images. The MRI Images segmentation allows for a more precise identification of the tumor region in the image. In the next step, the distinctive features of the image are extracted using the SVD technique. In addition to removing redundant information, this strategy boosts the speed of the processing at the classification stage. Finally, a combination of the algorithms Naïve Bayes, Support vector machine and K-nearest neighbor is used to classify the extracted features and detect brain tumors. Each of the three algorithms performs feature classification individually, and the final output of the proposed model is created by integrating the three independent outputs and voting the results. The results indicate that the proposed method can diagnose brain tumors in the BRATS 2014 dataset with an average accuracy of 98.61%, sensitivity of 95.79% and specificity of 99.71%. Additionally, the proposed method could diagnose brain tumors in the BTD20 database with an average accuracy of 99.13%, sensitivity of 99% and specificity of 99.26%. These results show a significant improvement compared to previous efforts. The findings confirm that using the image segmentation technique, as well as the ensemble learning, is effective in improving the efficiency of the proposed method. © 2023 by the authors.",TextMining
"Capillary electrophoresis has matured into a highly sensitive and widely applied analytical method over the last forty years. Here we combine text mining and computational chemistry to paint, with very broad strokes, the applicability and trends in the scientific literature on capillary electrophoresis, simultaneously demonstrating that this is not only possible, but reveal both expected and unexpected details of this history. All software and data are freely available on GitHub (https://github.com/ReinV/SCOPE) and OSF (https://osf.io/e56zt/). © 2023 The Authors",TextMining
"The Thar Desert, Sindh, Pakistan is characterized by low productivity. Besides, economy is based on agriculture, livestock and mining, nevertheless, livestock graze freely on public and private land. The aim of this research was to determine biomass production and to evaluate the effects of continuous and seasonal grazing on protected and unprotected plots. A 45 ha protected rangeland area of Hurrabad in the Umerkot Thar desert was selected and divided into three blocks of 15 ha each. Blocks of the same size were also established in unprotected area. The data for vegetation biomass, canopy cover, forage nutrients and weight gain of animals in two seasons (spring and summer) was collected from both protected and unprotected sites. The results showed that biomass significantly increased in summer in both sites. However, the biomass values in protected sites were significantly higher. Similarly, the vegetation cover also seemed to increase in summer in both protected (90.7% ± 0.29%) and unprotected sites (39.2% ± 0.09%). The foliar concentrations of all nutrients varied significantly with season. The average final live-weight gain for does on the protected grazing sites during the 42-day period in spring and the 96 days after the monsoon was almost double that of does grazing on the unprotected site during 2016 and 2017 (P < 0.05). The study concludes that the protection of grazing lands during certain periods can lead to better production of vegetation and livestock and improve range conditions. © 2023, Science Press, Institute of Mountain Hazards and Environment, CAS and Springer-Verlag GmbH Germany, part of Springer Nature.",TextMining
"Ion-adsorption rare earth mining areas are located in southern China’s ecologically fragile red soil hills region. For a long time, under the influence of multiple factors such as low mining technology and indiscriminate mining, this area has experienced serious environmental problems. Therefore, it is crucial for the ecological management and restoration of mining areas to accurately conduct a quantitative evaluation of ecological restoration status. We used remote sensing and geographic information data to establish an ecosystem resilience evaluation index system consisting of five criteria (land stress, vegetation conditions, surface conditions, biodiversity, and air pollution) and 17 evaluation factors. The Lingbei rare earth mining area in Dingnan County in the red soil hill region was used as a case study since it is a representative ion adsorption rare earth mining area. The restoration status of the mining area was evaluated from 2000 to 2020. The results showed the following: (1) From 2000 to 2020, the ecological resilience level of the mining area was 0.695, 0.685, 0.664, 0.651, and 0.657, exhibiting a decrease followed by an increase. (2) Spatially, the ecological resilience was low at the mine site and increased with increasing distance, indicating that rare earth mining adversely affected ecological resilience in the mining area. (3) The regional ecological resilience has improved over time due to the implementation of green development policies. However, the rate of improvement is slow and ecological restoration of mining areas will remain an ongoing challenge in the future. This study can provide a scientific basis and practical reference for the ecological protection and restoration of mining areas. © 2023 by the authors.",TextMining
"Purpose: Immune checkpoint inhibitors (ICIs) are a promising option for the treatment of patients with various cancers. Emerging case reports have raised awareness on hepatotoxicity, a potentially fatal adverse event (AE) that may be associated with the use of ICIs. This study assessed the potential association between ICIs and hepatotoxicity through the mining of data from the US Food and Drug Administration's AE Reporting System (FAERS). Methods: A total of 9,217,181 AEs reported in the period from quarter 1 of 2004 to quarter 3 of 2021 were assessed. Information components (ICs) and reporting odds ratios (RORs) were used to evaluate the association between the use of ICIs and hepatotoxicity. Findings: A total of 52,463 AE reports listed ICIs, used alone or in combination, as a suspected drug. Of these, 1481 cases were related to both ICIs and hepatotoxicity. The use of ICIs was significantly associated with hepatotoxicity compared to all other drugs, making it a safety signal (IC = 1.43 [95% CI, 1.36–1.51]; ROR = 2.78 [95% CI, 2.64–2.93]). With monotherapy, all ICIs, except tremelimumab, were associated with liver damage. The most commonly prescribed combination therapy was nivolumab + ipilimumab (321 cases) with a significant signal detected. Notably, ICI use was significantly associated with hepatic failure (IC = 1.24 [95% CI, 1.06–1.42]; ROR = 2.40 [95% CI, 2.13–2.72]). The risk for ICI-associated hepatotoxicity (including hepatic failure) was greater with ICI combination therapy than with ICI monotherapy. All subgroups by sex and age also showed significant associations between ICI use and hepatotoxicity. Implications: A significant association was detected between ICI use and hepatotoxicity. The risk for hepatotoxicity (including hepatic failure) was greater with ICI combination therapy compared with ICI monotherapy. © 2023",TextMining
"In consideration of uncertainties of material fatigue characteristics caused by the dimension size and manufacturing process, an interval strain energy density method for assessing fatigue life of welded structure was presented in this paper. Based on the limit experimental data, the data sequence was expanded by the least squares method to obtain the upper and lower strain energy density life curves of welded joints. Then, the cyclic stress and strain were calculated through the nonlinear finite element analysis for the electric mining dump truck welded frame structure, whose accuracy was testified by the mine road surface test data. The interval fatigue life at possible fatigue failure positions was estimated. In order to extend the life span of the frame and achieve its lightweight, a multi-objectives optimization design was conducted, based on the Kriging surrogate model. The optimal solution was acquired by the non-dominated sorting genetic algorithm. The results showed that the lower bound lifetime of welded frame was bettered from 5.63 years to 14.97 years while its weight reduced by 12.58%. © 2023, The Author(s), under exclusive licence to The Brazilian Society of Mechanical Sciences and Engineering.",TextMining
"The age-related loss of the cognitive function is a growing concern for global populations. Many factors that determine cognitive resilience or dementia also have metabolic functions. However, this duality is not universally appreciated when the action of that factor occurs in tissues external to the brain. Thus, we examined a set of genes involved in dementia, i.e., those related to vascular dementia, Alzheimer’s disease, Parkinson’s disease, and the human metabolism for activity in 12 metabolically active tissues. Mining the Genotype-Tissue Expression (GTEx) data showed that most of these metabolism–dementia (MD) genes (62 of 93, 67%) exhibit a higher median expression in any of the metabolically active tissues than in the brain. After identifying that several MD genes served as blood-based biomarkers of longevity in other studies, we examined the impact of the intake of food, nutrients, and other dietary factors on the expression of MD genes in whole blood in the Framingham Offspring Study (n = 2134). We observed positive correlations between flavonoids and HMOX1, taurine and UQCRC1, broccoli and SLC10A2, and myricetin and SLC9A8 (p < 2.09 × 10−4). In contrast, dairy protein, palmitic acid, and pie were negatively correlated, respectively, with the expression of IGF1R, CSF1R, and SLC9A8, among others (p < 2.92 × 10−4). The results of this investigation underscore the potential contributions of metabolic enzyme activity in non-brain tissues to the risk of dementia. Specific epidemiological or intervention studies could be designed using specific foods and nutrients or even dietary patterns focused on these foods and nutrients that influence the expression of some MD genes to verify the findings presented here. © 2023 by the authors.",TextMining
"This paper aims to address the difficult to pinpoint fault cause of the full parallel AT traction power supply system with special structure. The fault characteristics are easily covered up, and high transition impedance only affects the singularity of the wavehead, making the traveling waves hard to identify. Moreover, the classification accuracy of the traditional time-frequency analysis method is not sufficiently high to distinguish precisely. In this paper, a fault classification method of traction network based on single-channel improved Hilbert–Huang transform and deep learning is proposed. This method extracts effective fault features directly from the original fault signals and classifies the fault types at the same time. The accuracy of data categorization is increased by directly applying the Hilbert–Huang transform to fault signals to extract transient fault features and produce one-dimensional feature data, which are analyzed by the time-frequency energy spectrum. Using the similarity recognition method of long-short-term memory neural network, the extracted high-frequency one-dimensional feature data are trained and tested to classify fault signals more accurately. In order to verify the effectiveness of this method, several kinds of short-circuit and lightning strike faults are continuously simulated and verified in this paper. Considering various fault conditions and factors, the proposed improved HHT+LSTM method is compared with the LSTM method for direct processing of the original signals. The improved HHT + LSTM classification algorithm achieves an accuracy of 99.99%. © 2023 by the authors.",TextMining
"Cryo-electron tomograms capture a wealth of structural information on the molecular constituents of cells and tissues. We present DeePiCt (deep picker in context), an open-source deep-learning framework for supervised segmentation and macromolecular complex localization in cryo-electron tomography. To train and benchmark DeePiCt on experimental data, we comprehensively annotated 20 tomograms of Schizosaccharomyces pombe for ribosomes, fatty acid synthases, membranes, nuclear pore complexes, organelles, and cytosol. By comparing DeePiCt to state-of-the-art approaches on this dataset, we show its unique ability to identify low-abundance and low-density complexes. We use DeePiCt to study compositionally distinct subpopulations of cellular ribosomes, with emphasis on their contextual association with mitochondria and the endoplasmic reticulum. Finally, applying pre-trained networks to a HeLa cell tomogram demonstrates that DeePiCt achieves high-quality predictions in unseen datasets from different biological species in a matter of minutes. The comprehensively annotated experimental data and pre-trained networks are provided for immediate use by the community. © 2023, The Author(s).",TextMining
"Surface water quality deterioration is mainly occurring due to anthropogenic activities at an alarming rate in developing countries. Jharkhand has been undergoing exponential urbanisation and mining, causing immense surface water pollution and water stress. The state is heavily dependent on artificial dams for its daily water supply demands. Therefore, an effort is made to monitor and ascertain the surface water quality and the influence of nearby land use pattern on water quality, in the selected five dams, namely, Hatia dam, Kanke dam, Getalsud dam, Galudih barrage, and Chandil dam are done. These dams are built on the Subarnarekha river basin, located in the Jharkhand state on a seasonal basis and associated land use land cover (LULC) changes, changes in vegetation cover using normalised difference vegetation index (NDVI) and water body changes using normalised difference water index (NDWI) that have occurred in a 5-year gap i.e. 2016 and 2021. The secondary data for the year 2016 was obtained from the Jharkhand pollution control board report published by the government of Jharkhand, India. For the year 2021, the samples were collected from sampling sites for pre, post and monsoon seasons. The chemical analysis of collected water samples was done in the laboratory for parameters like pH, dissolved oxygen, biological oxygen demand, total calcium and magnesium, hardness, total dissolved and suspended solids, alkalinity, chlorine etc. and compared with the standard values prescribed by world health organisation (WHO) and Indian standards (IS) 10500:2012. The seasonal water quality status was analysed using the water quality index (WQI) for the pre, post and monsoon seasons of 2016 and 2021. Then, the use of supervised classification method for land use land cover (LULC), normalised difference vegetation index (NDVI) and normalised difference water index (NDWI) was opted to understand the relation between the change in water quality and quantity concerning its land use and land cover, by comparison of results from the year 2016 to 2021. LULC were found using the supervised maximum likelihood classification method in ArcGIS and its accuracy was checked using the kappa accuracy method, which was found to be varying from 87 to 95% for all sites. The results showed that the overall water quality varied from good to poor indicating that it can be used for human activities but may need pre-treatment before drinking. NDWI showed a massive increase in severe drought areas for Hatia, Kanke, Chandil and Galudih barrage, whereas moderate drought regions increased for Hatia, Getalsud, and Kanke. NDVI showed dense and moderate vegetation both decreased massively for all the dam sites indicating an alarming situation and the need to adopt better land management practices. © 2023, Geological Society of India, Bengaluru, India.",TextMining
"Transcriptional regulation has been adopted for developing metabolic engineering tools. The regulatory promoter is a crucial genetic element for strain optimization. In this study, a gene set of Aspergillus oryzae with highly constitutive expression across different growth stages was identified through transcriptome data analysis. The candidate promoters were functionally characterized in A. oryzae by transcriptional control of β-glucuronidase (GUS) as a reporter. The results showed that the glyceraldehyde triphosphate dehydrogenase promoter (PgpdA1) of A. oryzae with a unique structure displayed the most robust strength in constitutively controlling the expression compared to the PgpdA2 and other putative promoters tested. In addition, the ubiquitin promoter (Pubi) of A. oryzae exhibited a moderate expression strength. The deletion analysis revealed that the 5' untranslated regions of gpdA1 and ubi with the length of 1028 and 811 nucleotides, counted from the putative translation start site (ATG), respectively, could efficiently drive the GUS expression. Interestingly, both promoters could function on various carbon sources for cell growth. Glucose was the best fermentable carbon source for allocating high constitutive expressions during cell growth, and the high concentrations (6–8% glucose, w/v) did not repress their functions. It was also demonstrated that the secondary metabolite gene coding for indigoidine could express under the control of PgpdA1 or Pubi promoter. These strong and moderate promoters of A. oryzae provided beneficial options in tuning the transcriptional expression for leveraging the metabolic control towards the targeted products. © 2023, The Author(s), under exclusive licence to Microbiological Society of Korea.",TextMining
"Despite increasing mechanistic understanding, undetected and underrecognized drug–drug interactions (DDIs) persist. This elusiveness relates to an interwoven complexity of increasing polypharmacy, multiplex mechanistic pathways, and human biological individuality. This persistent elusiveness motivates development of artificial intelligence (AI)-based approaches to enhancing DDI detection and prediction capabilities. The literature is vast and roughly divided into “prediction” and “detection.” The former relatively emphasizes biological and chemical knowledge bases, drug development, new drugs, and beneficial interactions, whereas the latter utilizes more traditional sources such as spontaneous reports, claims data, and electronic health records to detect novel adverse DDIs with authorized drugs. However, it is not a bright line, either nominally or in practice, and both are in scope for pharmacovigilance supporting signal detection but also signal refinement and evaluation, by providing data-based mechanistic arguments for/against DDI signals. The wide array of intricate and elegant methods has expanded the pharmacovigilance tool kit. How much they add to real prospective pharmacovigilance, reduce the public health impact of DDIs, and at what cost in terms of false alarms amplified by automation bias and its sequelae are open questions. © 2023 Elsevier Inc.",TextMining
"Various relations existing in Electroencephalogram (EEG) data are significant for EEG feature representation. Thus, studies on the graph-based method focus on extracting relevancy between EEG channels. The shortcoming of existing graph studies is that they only consider a single relationship of EEG electrodes, which results an incomprehensive representation of EEG data and relatively low accuracy of emotion recognition. In this paper, we propose a fusion graph convolutional network (FGCN) to extract various relations existing in EEG data and fuse these extracted relations to represent EEG data more comprehensively for emotion recognition. First, the FGCN mines brain connection features on topology, causality, and function. Then, we propose a local fusion strategy to fuse these three graphs to fully utilize the valuable channels with strong topological, causal, and functional relations. Finally, the graph convolutional neural network is adopted to represent EEG data for emotion recognition better. Experiments on SEED and SEED-IV demonstrate that fusing different relation graphs are effective for improving the ability in emotion recognition. Furthermore, the emotion recognition accuracy of 3-class and 4-class is higher than that of other state-of-the-art methods. © 2023 by the authors.",TextMining
"Mining leads to excessive heavy metal contamination of agricultural products in Armenia and can adversely impact human health. We quantify the concentrations of toxic heavy metals (lead, nickel, cadmium, and mercury) in food sampled from local markets of the capital city, Yerevan. We combine these measured concentrations with data from a diet survey of 1,195 people. The results provide an estimate of people's heavy metal intake in a typical day. The study finds that only dietary exposure to lead raises consumer safety concerns. More than 50 % of the population have daily intakes of lead that exceed the benchmark dose level (BMDL10) of 0.63 μg/kg b.w./day established by European Food Safety Authority. Moreover, risk assessment results indicate that approximately 96 % of the population has dietary exposure values for lead that exceed the threshold level, with animal products as the primary source. The lead exposure observed in sampled population has the potential to increase blood pressure on average by 0.54 mmHg, lower IQ levels by 1.2 point, and reduce lifetime earnings by $5000. The study reveals a strong need to determine the specific pathways by which lead enters the food supply, to mitigate the excess exposures, and to reduce the potential or severity of the resulting adverse health impacts. © 2023 The Author(s)",TextMining
"With the gradual depletion of surface resources, rock instability caused by deep high stress and mining disturbance seriously affects safe mining. To create effective risk management, a rock instability risk field model using microseismic monitoring data is proposed in this study. Rock instability risk was presented visually in 3D visualization. The in-situ microseismic monitoring data was collected and analyzed to make calculation of peak ground velocity (PGV), peak ground acceleration (PGA), energy flux, energy and seismic moment. Indicator weights of PGV, PGA, energy flux are confirmed by using the analytic hierarchy process (AHP) to calculate risk severity. The Copula function is then used to solve the joint probability distribution function of energy and seismic moment. Then the spatial distribution characteristics of risk can be obtained by data fitting. Subsequently, the three-dimensional (3D) risk field model was established. Meanwhile, the established risk field is verified by comparing monitoring data without disturbance and the blasting data with disturbance. It is suggested that the proposed risk field method could evaluate the regional risk of rock instability reasonably and accurately, which lays a theoretical foundation for the risk prediction and management of rock instability in deep mining. © 2023 by the authors.",TextMining
"The gaining attention of underutilized oat crops for both food and feed, mining of quality and yield related genes/QTLs from available germplasms of oat is need of the hour. The large family of grasses has a vast number of germplasms that could be harnessed for bio-prospecting. The selection of cross-compatible oat germplasms by molecular markers could be used for the introgression of the novel traits into the elite background of oats. The process needs a thorough study of genetic diversity to see the evolutionary relatedness among germplasms. Considering this, in the present study, the genetic diversity of 38 oat germplasms with 12 agro-morphological traits was carried out using 22 Inter Simple Sequence Repeat (ISSR) markers. We found a high level of polymorphism and 158 distinctive alleles; on average 7.18 alleles per primer, further, high-yielding genotypes were identified with the help of phenotypic data and genetic diversity was analyzed by using DNA fingerprint-based principal component analysis, UPGMA dendrogram. Among these 38 germplasms; eight were identified as superior under high grain yield (OS-424, OS-403, NDO-1101, OL-10, UPO-212, OS-405, OS-6, and OS-346) and another eight germplasms were identified as superior for the high fresh weight (for fodder purpose, NDO-711, RO-19, OL-14, OL-1760/ OL-11, NDO-10, UPO-212, UPO-06-1, and RO-11-1). These results suggest that germplasms that are closely related (Cross-compatible) and have good potential for desirable traits could be used for varietal development by using marker-assisted selection. © 2023 Kumar et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TextMining
"Over the past few years, significant investments in smart traffic monitoring systems have been made. The most important step in machine learning is detecting and recognizing objects relative to vehicles. Due to variations in vision and different lighting conditions, the recognition and tracking of vehicles under varying extreme conditions has become one of the most challenging tasks. To deal with this, our proposed system presents an adaptive method for robustly recognizing several existing automobiles in dense traffic settings. Additionally, this research presents a broad framework for effective on-road vehicle recognition and detection. Furthermore, the proposed system focuses on challenges typically noticed in analyzing traffic scenes captured by in-vehicle cameras, such as consistent extraction of features. First, we performed frame conversion, background subtraction, and object shape optimization as preprocessing steps. Next, two important features (energy and deep optical flow) were extracted. The incorporation of energy and dense optical flow features in distance-adaptive window areas and subsequent processing over the fused features resulted in a greater capacity for discrimination. Next, a graph-mining-based approach was applied to select optimal features. Finally, the artificial neural network was adopted for detection and classification. The experimental results show significant performance in two benchmark datasets, including the LISA and KITTI 7 databases. The LISA dataset achieved a mean recognition rate of 93.75% on the LDB1 and LDB2 databases, whereas KITTI attained 82.85% accuracy on separate training of ANN. © 2023 by the authors.",TextMining
"Within the framework of precision medicine, the stratification of individual genetic susceptibility based on inherited DNA variation has paramount relevance. However, one of the most relevant pitfalls of traditional Polygenic Risk Scores (PRS) approaches is their inability to model complex high-order non-linear SNP-SNP interactions and their effect on the phenotype (e.g. epistasis). Indeed, they incur in a computational challenge as the number of possible interactions grows exponentially with the number of SNPs considered, affecting the statistical reliability of the model parameters as well. In this work, we address this issue by proposing a novel PRS approach, called High-order Interactions-aware Polygenic Risk Score (hiPRS), that incorporates high-order interactions in modeling polygenic risk. The latter combines an interaction search routine based on frequent itemsets mining and a novel interaction selection algorithm based on Mutual Information, to construct a simple and interpretable weighted model of user-specified dimensionality that can predict a given binary phenotype. Compared to traditional PRSs methods, hiPRS does not rely on GWAS summary statistics nor any external information. Moreover, hiPRS differs from Machine Learning-based approaches that can include complex interactions in that it provides a readable and interpretable model and it is able to control overfitting, even on small samples. In the present work we demonstrate through a comprehensive simulation study the superior performance of hiPRS w.r.t. state of the art methods, both in terms of scoring performance and interpretability of the resulting model. We also test hiPRS against small sample size, class imbalance and the presence of noise, showcasing its robustness to extreme experimental settings. Finally, we apply hiPRS to a case study on real data from DACHS cohort, defining an interaction-aware scoring model to predict mortality of stage II-III Colon-Rectal Cancer patients treated with oxaliplatin. © 2023 Massi et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TextMining
"The Editor-in-Chief and the publisher have retracted this article. The article was submitted to be part of a guest-edited issue. An investigation by the publisher found a number of articles, including this one, with a number of concerns, including but not limited to compromised editorial handling and peer review process, inappropriate or irrelevant references or not being in scope of the journal or guest-editedissue. Based on the investigation’s findings the Editor-in- Chief therefore no longer has confidence in the results and conclusions of this article. The author disagrees with this retraction. © 2021 King Fahd University of Petroleum & Minerals.",TextMining
"At present, China implements a quota-based trading mechanism to achieve carbon emission reduction, in which the allocation of carbon emission quotas among different provinces is short of considering the influence of unbalanced provincial development. Heterogeneity among the provincial-level three major industries, namely, agriculture, manufacturing and mining, and service industries, is a case in point. To address this insufficiency, this paper proposes a novel parallel data envelopment analysis (DEA) based method for carbon emission quota allocation. The method models each province as a decision-making unit (DMU) and the provincial-level three major industries as parallel sub-decision-making units (SDMUs). A distinguished feature of the method is that it makes explicit tradeoffs between efficiency and equality considerations for policymakers in allocating the carbon quotas among three heterogeneous provincial-level major industries. The empirical results show that the proposed method effectively improves the overall provincial gross domestic product (GDP) potentials through the reallocation of carbon quotas among industries while the equality level is not worse off. This work is helpful for policymakers to achieve a long-term emission reduction target and provides suggestions for improving the initial allocation mechanism of a national carbon trading market. © 2023 by the authors.",TextMining
"Approaches based on near infrared hyperspectral imaging (NIR-HSI) technology combined with machine learning have been developed to classify the leaves of hybrid cherry tomatoes and then identify the species of hybrid cherry tomato plants. The near infrared (NIR) hyperspectral images of 400 cherry tomato leaves (100 per species) were collected in the wavelength range of 900–1700 nm. Machine learning algorithms such as linear discriminant analysis (LDA), random forest (RF), and support vector machine (SVM) were employed to construct leaf classification models with the hyperspectral data preprocessed by Savitzky-Golay (SG) smoothing filter, first derivative (first Der) and standard normal variate (SNV). Principle of Component Analysis (PCA) was also used to reduce the data dimension and extract spectral features. It is revealed that the LDA model reaches the highest classification accuracy among the three machine learning algorithms and SNV can lead to higher improvement in model accuracy than other preprocessing methods of SG smoothing and first Der. Analysis based on PCA spectral feature extraction demonstrates that differences occur in internal material content in the leaves of cherry tomato plants with different species, which renders the models being able to distinguish between the species. Another important work was performed to reveal the different effects of the mesophyll and vein regions (VR) on the accuracy of the leaf classification model. It is demonstrated that the classification accuracy is improved by a value of 0.033 or 0.042 when mesophyll substitutes vein or whole leaf as regions of interest (ROI) to extract reflectance spectra for modeling. As a result, the accuracy of the training and test set respectively reached a high value of 0.998 and 0.973 for the LDA classification model combined with the SNV preprocessing method. The results propose that the use of mesophyll region (MR) as ROI can improve the performance of the leaf classification model, which provides a new strategy for efficient and non-destructive classification of different hybrid cherry tomato plants. © The Author(s) 2023.",TextMining
"With the Glasgow Climate Pact 2021, the global community has committed explicitly to phasing down coal consumption. Yet the coal supply sector continues to develop new capacities, despite the risk of asset stranding. This article presents the first assessment of the implications of 1.5∘C mitigation pathways for the coal mining industry. Based on open coal mine data and a new version of the open coal sector model COALMOD-World, the prospects for individual coal mining regions and their risk of early mine closures and asset stranding are analyzed. Results show that global cumulative production capacity from operating thermal coal mines exceed the remaining consumption values for 2020 through 2050 by more than 50%. This supply-consumption discrepancy would hit Russia and the USA especially hard, causing the stranding of around 80% of operating capacities in each case. But the early closure of operating coal mines would affect all of the world’s major thermal coal producing regions, with most regions seeing more than three-fourths of their mine capacity closing early by 2030. Stranded assets from operating coal mines would total some USD2015 120 to 150 billion until 2050, with an additional USD2015 100 billion should currently proposed new coal mining projects be realized. If demand declines in accordance with 1.5∘C pathways, new coal mines or mine extensions would be redundant in all coal regions. Although the stranded asset value of mines is relatively small compared to that of the coal power plant sector, early closures would especially affect workers and local communities. Thus, efforts are urgently needed to ensure a just transition in coal mining regions and to address excess operating and proposed coal supply capacities that continue to fuel global warming. © 2023 The Author(s). Published by IOP Publishing Ltd.",TextMining
"The European Union (EU) countries have declared the ambitious goal of providing carbon-free economic development. Considering this, the EU countries are going to pursue relevant policies for a step-by-step refusal of mining and coal energy, consequently reducing greenhouse gas emissions. The analysis of the theoretical background showed that renewable energy is the core dimension of reducing greenhouse gas emissions. In this case, the paper aims to justify the impact of core dimensions (knowledge spillover, innovation, and environmental regulation) that could boost renewable energy penetration into all sectors and levels. The following methods are applied to test the hypotheses: stationarity testing in panels; cross-section dependence testing; cointegration testing; and estimation in heterogeneous parameter models. The data are obtained from Eurostat, the OECD, and the World Data Bank. The object of research is the EU country in the period 2010–2020. The findings confirm the hypothesis on the statistically significant impact of innovation and knowledge spillover on renewable energy. In addition, environmental regulation has a mediating positive effect on interconnections among knowledge spillover, innovations, and renewable energy. In this case, countries should boost the development of appropriate environmental regulations, which should be effective and transparent for all stakeholders. © 2023 by the authors.",TextMining
"The high quality development of national parks plays an important role in promoting the formation of a reasonable, moderate and orderly land space protection pattern and building a harmonious coexistence of human and nature. However, a lack of public participation has limited the development of high-quality national parks in China. Understanding public concern and awareness of national parks is necessary for promoting greater public participation. This paper provides insight into this problem by combining Weibo and questionnaire survey data, then uses a combination of text mining, a Latent Dirichlet Allocation (LDA) theme model, and descriptive statistics to analyze the current state of public concern and awareness of national parks. By analyzing Weibo data, we find: (1) Public concern for national parks is increasing year by year. (2) More economically developed regions may pay more attention to national parks. (3) Public concern for national parks focuses on the construction of national parks in other countries and the institutional reform and ecotourism of national parks in China. Meanwhile, we also find that: (1) Most of the public are willing to actively pay attention to the construction of national parks. (2) The public is not yet fully aware of national parks in China; for example, the number of national parks, their construction, and other issues are still not widely known. (3) Public awareness of the construction goals, functional positioning, and other issues are not generally understood. To sum up, there is still much room for the public to improve their control and awareness of national parks. Finally, we put forward some suggestions to improve the public’s concern with and awareness of national parks, which can promote public participation in their development. This study will be important for sustainable development of the natural reserve system and global biodiversity protection in China. © 2023 by the authors.",TextMining
"The wide deployment of machine learning algorithms has become a severe threat to user data privacy. As the learning data is of high dimensionality and high orders, preserving its privacy is intrinsically hard. Conventional differential privacy mechanisms often incur significant utility decline as they are designed for scalar values from the start. We recognize that it is because conventional approaches do not take the data structural information into account, and fail to provide sufficient privacy or utility. As the main novelty of this work, we propose Matrix Gaussian Mechanism (MGM), a new $ (\epsilon,\delta)$(ϵ,δ)-differential privacy mechanism for preserving learning data privacy. By imposing the unimodal distributions on the noise, we introduce two mechanisms based on MGM with an improved utility. We further show that with the utility space available, the proposed mechanisms can be instantiated with optimized utility, and has a closed-form solution scalable to large-scale problems. We experimentally show that our mechanisms, applied to privacy-preserving federated learning, are superior than the state-of-the-art differential privacy mechanisms in utility.  © 2002-2012 IEEE.",TextMining
"Rationale: Obstructive sleep apnea (OSA)-induced endothelial cell (EC) dysfunction contributes to OSA-related cardiovascular sequelae. The mechanistic basis of endothelial impairment by OSA is unclear. Objectives: The goals of this study were to identify the mechanism of OSA-induced EC dysfunction and explore the potential therapies for OSA-accelerated cardiovascular disease. Methods: The experimental methods include data mining, bioinformatics, EC functional analyses, OSA mouse models, and assessment of OSA human subjects. Measurements and Main Results: Using mined microRNA sequencing data, we found that microRNA 210 (miR-210) conferred the greatest induction by intermittent hypoxia in ECs. Consistently, the serum concentration of miR-210 was higher in individuals with OSA from two independent cohorts. Importantly, miR-210 concentration was positively correlated with the apnea-hypopnea index. RNA sequencing data collected from ECs transfected with miR-210 or treated with OSA serum showed a set of genes commonly altered by miR-210 and OSA serum, which are largely involved in mitochondrion-related pathways. ECs transfected with miR-210 or treated with OSA serum showed reduced [Formula: see text]o2 rate, mitochondrial membrane potential, and DNA abundance. Mechanistically, intermittent hypoxia-induced SREBP2 (sterol regulatory element-binding protein 2) bound to the promoter region of miR-210, which in turn inhibited the iron-sulfur cluster assembly enzyme and led to mitochondrial dysfunction. Moreover, the SREBP2 inhibitor betulin alleviated intermittent hypoxia-increased systolic blood pressure in the OSA mouse model. Conclusions: These results identify an axis involving SREBP2, miR-210, and mitochondrial dysfunction, representing a new mechanistic link between OSA and EC dysfunction that may have important implications for treating and preventing OSA-related cardiovascular sequelae.",TextMining
"Due to the large versatility in organic semiconductors, selecting a suitable (organic semiconductor) material for photodetectors is a challenging task. Integrating computer science and artificial intelligence with conventional methods in optimization and material synthesis can guide experimental researchers to develop, design, predict and discover high-performance materials for photodetectors. To find high-performance organic semiconductor materials for photodetectors, it is crucial to establish a relationship between photovoltaic properties and chemical structures before performing synthetic procedures in laboratories. Moreover, the fast prediction of energy levels is desirable for designing better organic semiconductor photodetectors. Herein, we first collected large sets of data containing photovoltaic properties of organic semiconductor photodetectors reported in the literature. In addition, molecular descriptors that make it easy and fast to predict the required properties were used to train machine learning models. Power conversion efficiency and energy levels were also predicted. Multiple models were trained using experimental data. The light gradient boosting machine (LGBM) regression model and Hist gradient booting regression model are the best models. The best models were further tuned to achieve better prediction ability. The reliability of our designed approach was further verified by mining the photovoltaic database to search for new building units. The results revealed that good consistency is obtained between experimental outcomes and model predictions, indicating that machine learning is a powerful approach to predict the properties of photodetectors, which can facilitate their rapid development in various fields. © 2023 by the authors.",TextMining
"With the outbreak of the SARS-CoV-2 o COVID-19 pandemic, multiple studies of risk factors and their influence on patient deaths have been developed. However, little attention is often paid to analyzing patients in risk groups despite the fact that they have been infected and inpatients can survive. In this article, with the dataset available from the Ministery of the health of Mexico, this paper proposes the use of the latent topic extraction algorithm Latent Dirichlet Allocation (LDA) for the study of COVID-19 survival factors in Mexico. The results let us conclude that in the year before strategies for prevention and control of COVID-19, the latent topics support that patients without comorbidities have a low risk of death, compared with the period of 2021, wherein in spite of having some risk factors patients can survive.  © 2003-2012 IEEE.",TextMining
"The task of ore transportation is performed in all mines, regardless of their type (open pit/underground) or mining process. A substantial number of enterprises utilize wheeled machines to perform ore haulage, especially haul trucks and loaders. These machines’ work consists of repeating cycles, and each cycle can be divided into 4 operations: loading, driving with full box/bucket, unloading and driving with empty box/bucket. Monitoring this process is essential to create analytical tools that support foremen and other management crew in achieving effective and optimal production and planning activities. Unfortunately, information gathered regarding the process is frequently based on operators’ oral testimony. This process not only allows for abuse but is also a repetitive and tedious task that must be performed by foremen. The time and attention of foremen is valuable as they are responsible for managing practically everything in their current mine section (machines, operators, works, repairs, emergencies, safety, etc.). Therefore, the automatization of the described process of information gathering should be performed. In this article, we present two neural network models (one for haul trucks and one for loaders) build for detecting work cycles of the ore haulage process. Both models were built utilizing a 2-stage approach. In the first stage, the models’ structures were optimized, while the second was focused on optimizing hyperparameters for the structure with best performance. Both of the proposed models were trained using data collected from on-board monitoring systems over hundreds of the machines’ work hours and utilized the same input features: vehicle speed, fuel consumption, selected gear and engine rotational speed. Models have been subjected to comprehensive testing during which the efficiency and stability of the model responsible for haul trucks was proven. Results for loaders were not as high quality for haul trucks; however, some interesting facts were discovered that indicate possible directions for future development. © 2023 by the authors.",TextMining
"Occupational exposure assessment is important in preventing occupational coal worker’s diseases. Methods have been proposed to assess compliance with exposure limits which aim to protect workers from developing diseases. A Bayesian framework with informative prior distribution obtained from historical or expert judgements has been highly recommended for compliance testing. The compliance testing is assessed against the occupational exposure limits (OEL) and categorization of the exposure, ranging from very highly controlled to very poorly controlled exposure groups. This study used a Bayesian framework from historical and expert elicitation data to compare the posterior probabilities of the 95th percentile (P95) of the coal dust exposures to improve compliance assessment and decision-making. A total of 10 job titles were included in this study. Bayesian framework with Markov chain Monte Carlo (MCMC) simulation was used to draw a full posterior probability of finding a job title to an exposure category. A modified IDEA (“Investigate”, “Discuss”, “Estimate”, and “Aggregate”) technique was used to conduct expert elicitation. The experts were asked to give their subjective probabilities of finding coal dust exposure of a job title in each of the exposure categories. Sensitivity analysis was done for parameter space to check for misclassification of exposures. There were more than 98% probabilities of the P95 exposure being found in the poorly controlled exposure group when using expert judgments. Historical data and non-informative prior tend to show a lower probability of finding the P95 in higher exposure categories in some titles unlike expert judgments. Expert judgements tend to show some similarity in findings with historical data. We recommend the use of expert judgements in occupational risk assessment as prior information before a decision is made on current exposure when historical data are unavailable or scarce. © 2023 by the authors.",TextMining
"Drought is one of the most complex natural hazards. Therefore, precise drought monitoring and forecasting are the biggest tasks for hydrologists and environmentalists. Under grid data structure, this paper provides a new drought index—the adaptive standardized precipitation index (ASPI), for the evolution of drought, inferring its spatio-temporal patterns and detecting trends. The methodology of the proposed index is based mainly on dynamic time warping clustering algorithm and dynamic principal components. Historical simulated precipitation data from the Australian community climate and earth-system simulator model of coupled model intercomparison project 6 of 727 grid points scattered around the Tibet Plateau has been considered. Results show that as the time scale increases, the severe and extreme drought trends have increased significantly. Further, the significant decreasing magnitude in ASPI reveals the persistence of future drought in the Tibet Plateau region. From a data mining point of view, the outcomes associated with this research recommend the endorsement of ASPI for effective and precise drought monitoring under grid data structure. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TextMining
"This study aims to explore the winning and losing factors of Para Ice Hockey (PIH) games using a data mining-based decision tree analysis targeting the PIH games in international competitions organized by World Para Ice Hockey (WPIH). To achieve the study purpose and data collection, 66 games among the nations participating in the four international competitions for the last two years organized by WPIH, were selected as study subjects. The 3432 game records provided by WPIH were collected as study variables. The results of this study are as follows: First, the winning teams recorded 5.79 goals, 24.05 total shots on goal (SOG), 57.79% face-off winning percentage, 7.62 total saves (SVS), 0.24 total power play goals (PPGs), and 0.39 penalty-killing goals (PKGs) per game were recorded. The losing teams recorded 0.89 goals, 8.52 SOG, 42.21% face-off winning percentage, 18.26 SVS, 0.82 PPG, and 0.05 PKG and showed significant differences. When looking at game records by period, significant differences were revealed in the goals, SOG, and PPG except in the third period, and total shorthanded goals (SHGs) and SVS except in the second period. The winning teams showed the highest goals and SOG in the first, second, and third periods, while the losing teams showed the reverse order. Second, (1) according to the exploration result of winning and losing factors, excluding total goal-related variables, the probability of winning was 82.8% if the goal was 1 or more in the first period. The critical winning and losing factors were revealed as a goal in the first period and SOG in the second period in that order. (2) According to the exploration result of the winning and losing factors, excluding each period’s goal-related variables, the probability of winning was 81.4% if the SOG was 5 or more in the first period. As the essential winning and losing factors, SOG in the first period, SOG in the second period, and time on power play (TPP) in the third period were revealed. (3) The exploration result of winning and losing factors, excluding goals and shots-related variables, the probability of winning was 70.9% if the total face-off winning percentage was 46.23% or more. As the essential winning and losing factors, the total face-off winning percentage and SVS in the second period are shown in order. © 2023 by the author.",TextMining
"To improve intelligent construction standard systems in coal mines, we must promote the high-quality development of the coal mining industry. The current intelligent construction of coal mines is inefficient. Considering the complexity and diversity of coal mine intelligent construction index factors, this paper proposes an intelligent coal mine construction evaluation model that integrates the fuzzy decision-making trial and evaluation laboratory (FDEMATEL) and the analytical network process (ANP). Firstly, the evaluation index system is established based on the intelligent construction of coal mines. Secondly, the FDEMATEL is applied to deal with the fuzziness in the evaluation process and determine the influence relationship between the evaluation indexes of coal mine intelligent construction to draw the ANP network structure diagram. Finally, super decision software is used to calculate the weight of coal mine intelligent construction evaluation indexes, and then obtain the combination weight and correlation degree of each evaluation index. By applying the evaluation model to conduct a comprehensive evaluation of coal mine intelligent construction, the results show that there is a significant correlation between the indexes affecting the intelligent construction of coal mines. Basic platform intelligence and safety monitoring intelligence are the two most important aspects of intelligent coal mine construction. Database construction, mobile internet construction, big data support, and model algorithm support are the key indexes affecting the intelligent construction of coal mines. © 2023 by the authors.",TextMining
"Student graduation accuracy is one of the indicators of the success of higher education institutions in carrying out the teaching and learning process and as a component of higher education accreditation. So it is not surprising that building a system that can predict or classify students graduating on time or not on time is necessary for universities to monitor the exact number of students graduating on time using educational technology. Unfortunately, educational technology or machine learning with data mining approaches is less accurate in classifying classes with unbalanced data. Therefore, this research purpose is to build a machine learning system that can improve classification performance on unbalanced class data between students who graduate on time and graduate late. This study applies the Synthetic Minority Oversampling Technique (SMOTE) method to improve the classifying performance of the Support Vector Machine (SVM) data mining method. The results of the study concluded that using the SMOTE method increased the accuracy, precision, and sensitivity of the SVM method in classifying class data of unbalanced student graduation times. The SVM performance score rises by 3% for classification accuracy, 8% for classification precision, and 25% for classification sensitivity. © 2023 by the authors.",TextMining
"Background: In the post-epidemic era, online medical care is developing rapidly, and online doctor teams are attracting attention as a high-quality online medical service model that can provide more social support for patients. Methods: Using online doctor teams on the Haodf.com platform as the research subject, this study investigates the key factors in the process of doctor–patient communication, which affects patients’ emotional well-being. We also explore the different roles played by doctors as leaders and non-leaders in doctor–patient communication. From the perspective of language style, we select representative factors in the process of doctor–patient communication, namely the richness of health vocabulary, the expression of emotions, and the use of health-related terms (including perceptual words and biological words). We extract both team-level and individual-level linguistic communication styles through textual and sentiment analysis methods and empirically analyze their effects on patients’ emotional well-being using multiple linear regression models. Results: The results show that the expression of positive emotions by the team and attention to patients’ perceptions and biological conditions benefit patients’ emotional well-being. Leaders should focus on the emotional expression, whereas non-leaders should focus on the use of perceptual and biological words. Conclusions: This study expands the application of linguistic styles in the medical field and provides a practical basis for improving patients’ emotional well-being. © 2023 by the authors.",TextMining
"Importance: Large-scale data on type-specific human papillomavirus (HPV) prevalence and disease burden worldwide are needed to guide cervical cancer prevention efforts. Promoting the research and application of health care big data has become a key factor in modern medical research. Objective: To examine the prevaccination prevalence of high-risk HPV (hrHPV) and type distribution by cervical cytology grade in Estonia. Design, Setting, and Participants: This cross-sectional study used text mining and the linking of data from electronic health records and health care claims to examine type-specific hrHPV positivity in Estonia from 2012 to 2019. Participants were women aged at least 18 years. Statistical analysis was performed from September 2021 to August 2022. Main Outcomes and Measures: Type-specific hrHPV positivity rate by cervical cytological grade. Results: A total of 11 017 cases of cervical cytology complemented with data on hrHPV testing results between 2012 and 2019 from 66 451 women aged at least 18 years (mean [SD] age, 48.1 [21.0] years) were included. The most common hrHPV types were HPV16, 18, 31, 33, 51 and 52, which accounted for 73.8% of all hrHPV types detected. There was a marked decline in the positivity rate of hrHPV infection with increasing age, but the proportion did not vary significantly based on HPV type. Implementation of nonavalent prophylactic vaccination was estimated to reduce the number of women with high-grade cytology by 50.5% (95% CI, 47.4%-53.6%) and the number with low-grade cytology by 27.8% (95% CI, 26.3%-29.3%), giving an overall estimated reduction of 33.1% (95% CI, 31.7%-34.5%) in the number of women with precancerous cervical cytology findings. Conclusions and Relevance: In this cross-sectional study, text mining and natural language processing techniques allowed the detection of precursors to cervical cancer based on data stored by the nationwide health system. These findings contribute to the literature on type-specific HPV distribution by cervical cytology grade and document that α-9 phylogenetic group HPV types 16, 31, 33, 52 and α-7 phylogenetic group HPV 18 are the most frequently detected in normal-to-high-grade precancerous lesions in Estonia.",TextMining
"Scalar magnetic surveying using unmanned aerial vehicle (UAV) platforms is slowly gaining momentum within geophysical applications. So far, only a handful of studies have dealt with UAV-Towed scalar field measurements, while even fewer have considered towed scalar difference measurements (or gradients). In this paper, we demonstrate the possibilities and benefits of deploying precisely positioned noise-minimized UAV-Towed scalar transverse horizontal difference (THD) measurements for mineral exploration purposes. UAV-Towed gradiometry bird data are presented from the Nautanen area in northern Sweden and compared with ground magnetic surveys. This area is known for its iron oxide copper-gold mineralizations. The UAV survey spans a total area of 2.5 km2. It was covered using an average line spacing of 30 m and a constant flight altitude above ground level of 30 m. High-quality scalar total-field and THD data were collected with a dynamic noise level of the raw scalar data of about ±0.05 nT. Comparison with the ground magnetic data shows a strong correlation between magnetic anomaly lows and highs across the survey areas. A map with new structural information is presented based on subtle magnetic structures identified in discrete derivatives of the total magnetic intensity anomaly and THD data. Such systems may replace high-quality heliborne systems and reduce costs of the geophysical exploration phase. However, mapping with UAV-Towed systems is not straightforward. With typical UAV flight speeds of only 10-12 m/s, the wind often disturbs the 3D attitude of the bird during flights. Hence, advanced processing is required to obtain the intended gradients. Similar challenges are less important in surveying, where the survey speed often greatly exceeds the wind speed.  © 2023 by The Society of Exploration Geophysicists.",TextMining
"To accurately manage water resources, a precise prediction of reference evapotranspiration (ETref) is necessary. The best empirical equations to determine ETref are usually the temperature-based Baier and Robertson (BARO), the radiation-based Jensen and Haise (JEHA), and the mass transfer-based Penman (PENM) ones. Two machine learning (ML) models were used: least squares support vector regression (LSSVR) and ANFIS optimized using the particle swarm optimization algorithm (ANFPSO). These models were applied to the daily ETref at 100 synoptic stations for different climates of Iran. Performance of studied models was evaluated by the correlation coefficient (R), coefficient of determination (R2), mean absolute error (MAE), root mean square error (RMSE), scatter index (SI) and the Nash-Sutcliffe efficiency (NSE). The combination-based ML models (LSSVR4 and ANFPSO4) had the lowest error (RMSE = 0.34–2.85 mm d−1) and the best correlation (R = 0.66–0.99). The temperature-based empirical relationships had more precision than the radiation- and mass transfer-based empirical equations. © 2023 The Authors",TextMining
"Objective: To identify and synthesise research on applications of natural language processing (NLP) for information extraction and retrieval from clinical notes in dentistry. Materials and methods: A predefined search strategy was applied in EMBASE, CINAHL and Medline. Studies eligible for inclusion were those that that described, evaluated, or applied NLP to clinical notes containing either human or simulated patient information. Quality of the study design and reporting was independently assessed based on a set of questions derived from relevant tools including CHecklist for critical Appraisal and data extraction for systematic Reviews of prediction Modelling Studies (CHARMS). A narrative synthesis was conducted to present the results. Results: Of the 17 included studies, 10 developed and evaluated NLP methods and 7 described applications of NLP-based information retrieval methods in dental records. Studies were published between 2015 and 2021, most were missing key details needed for reproducibility, and there was no consistency in design or reporting. The 10 studies developing or evaluating NLP methods used document classification or entity extraction, and 4 compared NLP methods to non-NLP methods. The quality of reporting on NLP studies in dentistry has modestly improved over time. Conclusions: Study design heterogeneity and incomplete reporting of studies currently limits our ability to synthesise NLP applications in dental records. Standardisation of reporting and improved connections between NLP methods and applied NLP in dentistry may improve how we can make use of clinical notes from dentistry in population health or decision support systems. Protocol Registration. PROSPERO CRD42021227823. © 2023 Elsevier Inc.",TextMining
"Introduction: A safety signal concerning parkinsonism and related movement disorders with gabapentinoids (gabapentin and pregabalin) or tramadol was detected by reviewing individual case reports and data mining in spontaneous report databases. Well-designed pharmacoepidemiological studies are needed to assess the signal. Objective: This study aimed to investigate the association of exposure to gabapentinoids or tramadol with the risk of parkinsonism and related movement disorders. Methods: We conducted a case-crossover study using a Japanese electronic medical records database. Patients with newly diagnosed parkinsonism or related movement disorders between January 1, 2007, and April 14, 2019, were identified. The diagnosis date of outcomes was defined as the index date. We assessed the exposure of each patient to gabapentinoids or tramadol during a 90-day hazard period ending 1 day before the index date and in three 90-day reference periods. Multivariable conditional logistic regression models were employed to estimate adjusted odds ratios (aORs) and 95% confidence intervals (CIs). To confirm the robustness of the primary findings, we also performed sensitivity analyses using a case–case-time-control design, a different time window for hazard and reference periods, a different definition of outcome, and different number of reference periods. Results: A total of 28,972 eligible cases were included in the primary analysis. Exposure to gabapentinoids (aOR, 2.12; 95% CI, 1.73–2.61) and tramadol (aOR, 2.04; 95% CI, 1.57–2.64) was associated with increased risk. Results were consistent across sensitivity analyses. Conclusion: Our findings serve as a caution to physicians who prescribe gabapentinoids or tramadol in routine clinical practice. © 2023 Pharmacotherapy Publications, Inc.",TextMining
"Distant supervision is an efficient way to generate large-scale training data for relation extraction without human efforts. However, the accompanying challenges have been plaguing the advance of the extractor: (1) the automatically annotated labels for training data contain much noisy data and hurt the performance of the extractor; (2) the annotations, based on bag-level (cluster of sentences) instead of sentence-level (single sentence), are too coarse to train an accurate extractor; (3) hetergeneous sentences are hard for a denoising model to capture the underlying commonness among valid relational expressions. To address these issues, we bulid a novel sentence representation and craft reinforcement learning to select the expressive sentence for each relation mentioned in a bag. More specifically, we introduce entity-free sentence pattern incorporated with attentive type information. Furthermore, multiple interactions between entity-specific and entity-free representation are proposed to generate complementary sentence features (for challenge 3). Then we design a fine-grained reward function, and model the sentence selection process as an auction where different relations for a bag need to compete together to achieve the possession of a specific sentence based on its expressiveness. In this way, our model can be dynamically self-adapted, and eventually implements the accurate one-to-one mapping from a relation label to its chosen expressive sentence, which serves as training instances for the extractor (for challenge 1 and 2). The experimental results on two public datasets demonstrate the superiority of our model compared with current state-of-the-art methods for distantly supervised relation extraction.  © 1989-2012 IEEE.",TextMining
"Adverse outcome pathways provide a powerful tool for understanding the biological signaling cascades that lead to disease outcomes following toxicity. The framework outlines downstream responses known as key events, culminating in a clinically significant adverse outcome as a final result of the toxic exposure. Here we use the AOP framework combined with artificial intelligence methods to gain novel insights into genetic mechanisms that underlie toxicity-mediated adverse health outcomes. Specifically, we focus on liver cancer as a case study with diverse underlying mechanisms that are clinically significant. Our approach uses two complementary AI techniques: Generative modeling via automated machine learning and genetic algorithms, and graph machine learning. We used data from the US Environmental Protection Agency's Adverse Outcome Pathway Database (AOP-DB; aopdb.epa.gov) and the UK Biobank's genetic data repository. We use the AOP-DB to extract disease-specific AOPs and build graph neural networks used in our final analyses. We use the UK Biobank to retrieve real-world genotype and phenotype data, where genotypes are based on single nucleotide polymorphism data extracted from the AOP-DB, and phenotypes are case/control cohorts for the disease of interest (liver cancer) corresponding to those adverse outcome pathways. We also use propensity score matching to appropriately sample based on important covariates (demographics, comorbidities, and social deprivation indices) and to balance the case and control populations in our machine language training/testing datasets. Finally, we describe a novel putative risk factor for LC that depends on genetic variation in both the aryl-hydrocarbon receptor (AHR) and ATP binding cassette subfamily B member 11 (ABCB11) genes. © 2023",TextMining
"The porosity of rocks is an important parameter used in rock mechanics and underground mining. It affects the movement of fluids in the rock mass and the internal processes taking place (the ability to store water or gases), allowing us to characterize the type of rock and determine possible future applications. Conventional porosity testing methods (e.g., test drill cores in the laboratory) are complex and time-consuming. On the other hand, more modern technologies, such as computed tomography, are high-cost. In the presented study, a core sample with karst and porous structures inside was used. This core sample was poured with resin to reinforce the outer surfaces of the core and make it easier to cut with a rock saw. It was then cut into 3 mm thickness slices in preparation for the next step—the 3D optical scanning. Measurements were made with the ATOS CORE 500 optical scanner. Data processing was then performed in open-source software using popular and commonly used modeling methods. The 3D model of the core reconstructing the actual shape (with internal voids) and the standard model (without internal voids) were created. Based on these, the total porosity of the core was assessed. The presented solution ensures obtaining results with high accuracy at an adequate computational cost using cheap and easily available tools. © 2023 by the authors.",TextMining
"Classification is one of the most important topics in machine learning. However, most of these works focus on the two-class classification (i.e., classification into ‘positive’ and ‘negative’), whereas studies on multi-class classification are far from enough. In this study, we develop a novel methodology of multiple classifier systems (MCS) with one-vs-one (OVO) scheme for the multi-class classification task. First, the multi-class classification problem is divided into as many pairs of easier-to-solve binary sub-problems as possible. Subsequently, an optimal MCS is generated for each sub-problem using a roulette-based feature subspace selection and validation procedure. Finally, to identify the final class of a query sample, an OVO aggregation strategy is employed to obtain the class from the confidence score matrix derived from the MCS. To verify the effectiveness and robustness of the proposed approach, a thorough experimental study is performed. The extracted findings supported by the proper statistical analysis indicate the strength of the proposed method with respect to the state-of-the-art methods for multi-class classification problems. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",TextMining
"Network alignment aims to identify the correspondence of nodes between two or more networks. It is the cornerstone of many network mining tasks, such as cross-platform recommendation and cross-network data aggregation. Recently, with the development of network representation learning techniques, researchers have proposed many embedding-based network alignment methods. The effect is better than traditional methods. However, several issues and challenges remain for network alignment tasks, such as lack of labeled data, mapping across network embedding spaces, and computational efficiency. Based on the graph neural network (GNN), we propose the URNA (unsupervised rapid network alignment) framework to achieve an effective balance between accuracy and efficiency. There are two phases: model training and network alignment. We exploit coarse networks to accelerate the training of GNN after first compressing the original networks into small networks. We also use parameter sharing to guarantee the consistency of embedding spaces and an unsupervised loss function to update the parameters. In the network alignment phase, we first use a once-pass forward propagation to learn node embeddings of original networks, and then we use multi-order embeddings from the outputs of all convolutional layers to calculate the similarity of nodes between the two networks via vector inner product for alignment. Experimental results on real-world datasets show that the proposed method can significantly reduce running time and memory requirements while guaranteeing alignment performance. © 2023 by the authors.",TextMining
"In this paper, we introduce PyVT, an open-source Python toolkit for preprocessing and analysis of vessel spatio-temporal trajectories. The toolkit realizes four functions: trajectory preprocessing, trajectory data management, trajectory mining, and trajectory visualization. The toolkit is simple to use, provides satisfactory default parameter settings, and makes it easy for basic users to use and replicate its functionality in proprietary applications. More advanced users can further adjust the functions to meet their needs by optimizing parameters. At the same time, its design focuses on composability and reusability, making it functional modular and maintainable, allowing for further development. © 2023 The Author(s)",TextMining
"This paper proposes a novel density-based real-time segmentation algorithm, to extract ground point cloud in real time from point cloud data collected by roadside LiDAR. The algorithm solves the problems such as the large amount of original point cloud data collected by LiDAR, which leads to heavy computational burden in ground point search. First, point cloud data is filtered by straight-through filtering method and rasterized to improve the real-time performance of the algorithm. Then, the density of the point cloud in horizontal plane is calculated, and the threshold of the density is selected to extract the low-density regional point cloud according to the density statistical histogram and 95% loci. Finally, the low-density regional point cloud is used as the initial ground seeds for iterative optimization of ground parameters, and the ground point cloud is extracted by the fitted ground model to realize road point cloud extraction. The experimental results on 1055 frames of continuous data collected on real scenes show that the average time consumption of the proposed method is 0.11 s, and the average segmentation precision is 92.48%. This shows that the density-based road segmentation algorithm can reduce the time of point cloud traversal in the process of ground parameter fitting and improve the real-time performance of the algorithm while maintaining the accuracy of ground extraction. © 2023, China Society of Automotive Engineers (China SAE).",TextMining
"Shield tunneling machines are paramount underground engineering equipment and play a key role in tunnel construction. During the shield construction process, the “mud cake” formed by the difficult-to-remove clay attached to the cutterhead severely affects the shield construction efficiency and is harmful to the healthy operation of a shield tunneling machine. In this study, we propose an enhanced transformer-based detection model for detecting the cutterhead clogging status of shield tunneling machines. First, the working state data of shield machines are selected from historical excavation data, and a long short-term memory-autoencoder neural network module is constructed to remove outliers. Next, variational mode decomposition and wavelet transform are employed to denoise the data. After the preprocessing, nonoverlapping rectangular windows are used to intercept the working state data to obtain the time slices used for analysis, and several time-domain features of these periods are extracted. Owing to the data imbalance in the original dataset, the k-means-synthetic minority oversampling technique algorithm is adopted to oversample the extracted time-domain features of the clogging data in the training set to balance the dataset and improve the model performance. Finally, an enhanced transformer-based neural network is constructed to extract essential implicit features and detect cutterhead clogging status. Data collected from actual tunnel construction projects are used to verify the proposed model. The results show that the proposed model achieves accurate detection of shield machine cutterhead clogging status, with 98.85% accuracy and a 0.9786 F1 score. Moreover, the proposed model significantly outperforms the comparison models. © 2023, Science China Press.",TextMining
"Demand for data security is increasing as information technology advances. Encryption technology based on biometrics has advanced significantly to meet more convenient and secure needs. Because of the stability of face traits and the difficulty of counterfeiting, the iris method has become an essential research object in data security research. This study proposes a revolutionary face feature encryption technique that combines picture optimization with cryptography and deep learning (DL) architectures. To improve the security of the key, an optical chaotic map is employed to manage the initial standards of the 5D conservative chaotic method. A safe Crypto General Adversarial neural network and chaotic optical map are provided to finish the course of encrypting and decrypting facial images. The target field is used as a ""hidden factor"" in the machine learning (ML) method in the encryption method. An encrypted image is recovered to a unique image using a modernization network to achieve picture decryption. A region-of-interest (ROI) network is provided to extract involved items from encrypted images to make data mining easier in a privacy-protected setting. This study’s findings reveal that the recommended implementation provides significantly improved security without sacrificing image quality. Experimental results show that the proposed model outperforms the existing models in terms of PSNR of 92%, RMSE of 85%, SSIM of 68%, MAP of 52%, and encryption speed of 88%. © 2023 by the authors.",TextMining
"Tree-based scan statistics have been successfully used to study the safety of several vaccines without prespecifying health outcomes of concern. In this study, the binomial tree-based scan statistic was applied sequentially to detect adverse events in days 1–28 compared with days 29–56 after recombinant herpes zoster (RZV) vaccination, with 5 looks at the data and formal adjustment for the repeated analyses over time. IBM MarketScan data on commercially insured persons ≥50 years of age receiving RZV during January 1, 2018, to May 5, 2020, were used. With 999,876 doses of RZV included, statistically significant signals were detected only for unspecified adverse effects/complications following immunization, with attributable risks as low as 2 excess cases per 100,000 vaccinations. Ninety percent of cases in the signals occurred in the week after vaccination and, based on previous studies, likely represent nonserious events like fever, fatigue, and headache. Strengths of our study include its untargeted nature, self-controlled design, and formal adjustment for repeated testing. Although the method requires prespecification of the risk window of interest and may miss some true signals detectable using the tree-temporal variant of the method, it allows for early detection of potential safety problems through early initiation of ongoing monitoring. © The Author(s) 2022.",TextMining
"This paper presents the results of an exploration of the most resilient influences determining the attitude regarding prioritizing co-nationals over immigrants for access to employment. The source data were from the World Values Survey. After many selection and testing steps, a set of the seven most significant determinants was produced (a fair-to-good model as prediction accuracy). These seven determinants (a hepta-core model) correspond to some features, beliefs, and attitudes regarding emancipative values, gender discrimination, immigrant policy, trust in people of another nationality, inverse devoutness or making parents proud as a life goal, attitude towards work, the post-materialist index, and job preferences as more inclined towards self rather than community benefits. Additional controls revealed the significant influence of some socio-demographic variables. They correspond to gender, the number of children, the highest education level attained, employment status, income scale positioning, settlement size, and the interview year. All selection and testing steps considered many principles, methods, and techniques (e.g., triangulation via adaptive boosting (in the Rattle library of R), and pairwise correlation-based data mining—PCDM, LASSO, OLS, binary and ordered logistic regressions (LOGIT, OLOGIT), prediction nomograms, together with tools for reporting default and custom model evaluation metrics, such as ESTOUT and MEM in Stata). Cross-validations relied on random subsamples (CVLASSO) and well-established ones (mixed-effects). In addition, overfitting removal (RLASSO), reverse causality, and collinearity checks succeeded under full conditions for replicating the results. The prediction nomogram corresponding to the most resistant predictors identified in this paper is also a powerful tool for identifying risks. Therefore, it can provide strong support for decision makers in matters related to immigration and access to employment. The paper’s novelty also results from the many robust supporting techniques that allow randomly, and non-randomly cross-validated and fully reproducible results based on a large amount and variety of source data. The findings also represent a step forward in migration and access-to-job research. © 2023 by the author.",TextMining
"Foamed concrete is a versatile material that can be used in different construction applications and with proper mix designing, it can also be used as a structural member. The production of sustainable lightweight foamed concrete (LWFC) requires a proper mix design relation to achieve the desired physical and mechanical properties. Numerous studies have proposed empirical formula to predict the compressive strength of foamed concrete. However, the prediction relies on a number of parameters, whose contribution to the overall material needs to be optimized. A novel parametric feature extraction using principal component analysis (PCA) is proposed for data mining. Furthermore, the accuracy of the prediction formula is limited by the amount of data with variable parameters. Due to the large differences between the calculated and actual compressive strength results, this study aims to build up a PCA-feature optimized machine learning model to enhance the design-oriented strength modelling of foamed concrete. © 2023 Institution of Structural Engineers",TextMining
"To obtain an effective data mining method for cable-stayed bridge damage diagnosis, the algorithm of the cable-stayed bridge damage diagnosis model based on data mining was studied, and a data mining method is proposed. This method is oriented to the damage diagnosis of cable-stayed bridges. After algorithm comparison, the support vector machine (SVM) and limit gradient-boosting (XGBoost) algorithms, with advantages in damage location and quantification, are combined and optimized to obtain the damage diagnosis model for cable-stayed bridges. First, a refined benchmark finite element model is established by Abaqus, and postprocessing data such as vibration frequency and modal curvature are used as a data mining dataset. Second, feature se-lection is conducted, and the damage-sensitive modal curvature change rate index is selected as the feature of data mining. Next, the SVM and XGBoost algorithms are optimized by grid and random search, and the optimized SVM and XGBoost algorithms are used to locate and quantify the damage. Finally, the damage diagnosis model for cable-stayed bridges is obtained. Taking a cable-stayed bridge as an example, the proposed method is applied and analyzed, and the results show the effectiveness of the proposed method. © 2023 by the authors.",TextMining
"The original EEG data collected are the 1D sequence, which ignores spatial topology information; Feature Pyramid Networks (FPN) is better at small dimension target detection and insufficient feature extraction in the scale transformation than CNN. We propose a method of FPN and Long Short-Term Memory (FPN-LSTM) for EEG feature map-based emotion recognition. According to the spatial arrangement of brain electrodes, the Azimuth Equidistant Projection (AEP) is employed to generate the 2D EEG map, which preserves the spatial topology information; then, the average power, variance power, and standard deviation power of three frequency bands ((Formula presented.), (Formula presented.), and (Formula presented.)) are extracted as the feature data for the EEG feature map. BiCubic interpolation is employed to interpolate the blank pixel among the electrodes; the three frequency bands EEG feature maps are used as the G, R, and B channels to generate EEG feature maps. Then, we put forward the idea of distributing the weight proportion for channels, assign large weight to strong emotion correlation channels (AF3, F3, F7, FC5, and T7), and assign small weight to the others; the proposed FPN-LSTM is used on EEG feature maps for emotion recognition. The experiment results show that the proposed method can achieve Value and Arousal recognition rates of 90.05% and 90.84%, respectively. © 2023 by the authors.",TextMining
"To reveal the deformation and failure law of the gob-side roadway (GSR) and the main influencing factors in close extra-thick coal seams, the research methods of field monitoring, theoretical analysis, and numerical simulation are adopted in this paper. Field monitoring data shows that microseismic events occur and accumulate frequently in the surrounding rock and some overlying key layers of the GSR. Large deformation is experienced in the middle part of roadway near the solid coal side, the middle and upper parts of the roadway near the coal pillar side, and the roadway floor. The overlying strata of the GSR are fractured to form a composite structure as “low-level cantilever beam and high-level masonry beam”. The coal pillar is squeezed and effected by the composite beam structure and the rotation moment M, causing serious bulge in middle and upper part of the coal pillar side. The stability of the solid coal side of the roadway is affected by the stress transferred from gangue contact point. Numerical simulation shows that the immediate roof and key layer breakage are induced by the mining of the 30,501 working face. Shear and tension failures happen in the GSR due to overburden subsidence and rotary extrusion. The stress and displacement at the middle and upper of the roadway on the coal pillar side are larger than the other area. Compared with the solid coal side, the coal on the coal pillar side is obviously more fractured, with a lower bearing capacity. The peak stress in the coal pillar shows up 2 m away from the roadway, which is close to the length of bolt support. The mining-induced stress and the stress transferred from gangue contact point are the direct reasons for solid coal bulge beside the roadway. The peak stress on the solid coal side is located 7 m away from the roadway, at the gangue contact point where overburden fractures. The overburden strata loads and the transferred stress near the gangue contact point are transferred from the sides to the roadway floor. Their coupling effect with the in situ horizontal stress acts as the force source for the plastic floor heave. © 2023 by the authors.",TextMining
"With the emergence of the COVID-19 pandemic, access to physical education on campus became difficult for everyone. Therefore, students and universities have been compelled to transition from in-person to online education. During this pandemic, online education, the use of unfamiliar digital learning tools, the lack of internet access, and the communication barriers between teachers and students made precision education more difficult. Customizing models from previous studies that only consider a single course in order to make a prediction reduces the predictive power of the model because it only considers a small subset of the attributes of each possible course. Due to a lack of data for each course, overfitting often occurs. It is challenging to obtain a comprehensive understanding of the student’s participation during the semester system or in a broader context. In this paper, a model that is flexible and more generalizable is developed to address these issues. This model resolves the problem of generalized models and overfitting by using a large number of responses from college and university students as a dataset that considered a broader range of attributes, regardless of course differences. CatBoost, an advanced type of gradient boosting algorithm, was used to conduct this research, and enabled the developed model to perform effectively and produce accurate results. The model achieved a 96.8% degree of accuracy. Finally, a comparison was made with other related work to demonstrate the concept, and the experimental results proved that the Catboost model is a viable, accurate predictor of students’ performance. © 2023 by the authors.",TextMining
"Lake sediments are a reliable source of information about the past, including data of the origin of water bodies and their changes. Russia has more than 2 million lakes, so paleolimnological studies are relevant here. This review deals with the most significant studies of sequential accumulation of pollutants, including heavy metals in recent lake sediments in Russia. The key areas are northwestern regions of Russia (Murmansk Region, the Republic of Karelia, Arkhangelsk Region), the Urals (Chelyabinsk Region, the Republic of Bashkortostan), and Siberia. The review presents the data of pollutants accumulation, the sedimentation rate in lakes in the anthropogenic period, and the key sources of pollution of the environment in each of the mentioned regions. The article is divided into three parts (sections): industrial areas, urbanized areas, and background (pristine) areas so that readers might better understand the specifics of particular pollution and its impact on lake ecosystems. The impact of metallurgical plants, mining companies, boiler rooms, coal and mazut thermal power plants, transport, and other anthropogenic sources influencing geochemical characteristics of lakes located nearby or at a distance to these sources of pollution are considered. For instance, the direct influence of factories and transport was noted in the study of lake sediments in industrial regions and cities. In the background territories, the influence of long-range transport of pollutants was mainly noted. It was found that sedimentation rates are significantly lower in pristine areas, especially in the Frigid zone, compared to urbanized areas and industrial territories. In addition, the excess concentrations of heavy metals over the background are higher in the sediments of lakes that are directly affected by the source of pollution. At the end of the article, further prospects of the development of paleolimnological studies in Russia are discussed in the context of the continuing anthropogenic impact on the environment. © 2023 by the author.",TextMining
"The COVID-19 pandemic has had a negative impact on the mental health of the population such as increased levels of anxiety, psychological distress, isolation, etc. Access to mental health services has been limited due to the “overflow” of demands. The Recovery College (RC) model, an education-based approach, has addressed this challenge and provided online well-being and mental health courses to at-risk populations. The RC model proposes a co-learning space in an adult education program where learners from diverse backgrounds collectively learn and empower themselves to better address psychological well-being and mental health issues. The aim of this study was to document the experience of learners who participated in online RC courses during the COVID-19 pandemic and the perceived impact of these courses on their mental health. A qualitative interpretative descriptive study design was employed, and Miles and Huberman’s stepwise content analysis method was used to mine the data for themes. Fourteen structured online interviews were conducted with a sample representative of the diversity of learners. Five categories of themes emerged: (1) updating and validating your mental health knowledge, (2) taking care of yourself and your mental health, (3) improving and modifying your behaviors and practices, (4) changing how you look at yourself and others, and (5) interacting and connecting with others. Results suggest that online RC courses can be an effective strategy for supporting individual self-regulation and empowerment, breaking social isolation, and reducing the effects of stress in times of social confinement measures and limited access to care. © 2023 by the authors.",TextMining
"The definition of geostatistical domains is a stage in the estimation of mineral resources, in which a sample resulting from a mining exploration process is divided into zones that show homogeneity or minimal variation in the main element of interest or mineral grade, having geological and spatial meaning. Its importance lies in the fact that the quality of the estimation techniques, and therefore, the correct quantification of the mineral resource, will improve in geostatistically stationary areas. The present study seeks to define geostatistical domains of estimation for a mineral grade, using a non-traditional approach based on the k-prototype clustering algorithm. This algorithm is based on the k-means paradigm of unsupervised machine learning, but it is exempt from the one-time restriction on numeric data. The latter is especially convenient, as it allows the incorporation of categorical variables such as geological attributes in the grouping. The case study corresponds to a hydrothermal gold deposit of high sulfidation, located in the southern zone of Peru, where estimation domains are defined from a historical record of data recovered from 131 diamond drill holes and 37 trenches. The characteristics directly involved were the gold grade (Au), silver grade (Ag), type of hydrothermal alteration, and type of mineralization. The results obtained showed that clustering with k-prototypes is an efficient approach and can be used as an alternative or complement to the traditional methodology. © 2023 by the authors.",TextMining
"The early auxin responsive small auxin up-regulated RNA (SAUR) family is an important gene family in the auxin signal transduction pathway. This study focused on the regulatory mechanism of DlSAUR genes during early somatic embryogenesis (SE) and its response to hormone treatment and abiotic stress. Mining of the available Dimocarpus longan Lour. (D. longan) genome sequence yielded 68 putative SAUR genes. Transcript profiles based on RNA-seq data showed that most of the 24 detected DlSAUR genes were highly expressed in the globular embryos (GE) (10) and most of them responded to heat stress and 2,4-D treatment. The results of qRT-PCR showed that most of DlSAUR genes were up-regulated under auxin inhibitor N-1-naphthylphthalamic acid (NPA) and auxin indole-3-acetic acid (IAA) treatments. Moreover, NPA could promote longan SE. The assay for ATAC-seq data analysis showed that chromatin accessibility of 19 of the 24 DlSAUR genes were open during early SE, and most DlSAUR genes differentially expressed during early SE were not associated with H3K4me1 signal enrichment. The DlSAUR32 was selected for subcellular localization and RNA-seq analysis, which encode a cell nuclear-localized protein. Dual-luciferase assays and transient transformation showed that the transcription factors (TFs) DlWRKY75-1 and DlWRKY75-2 might bind to the DlSAUR32 promoters to inhibition gene transcription. Transient overexpression of DlWRKY75-1 and DlWRKY75-2 decreased IAA content in N. benthamiana leaves. Thus, the regulatory network composed of DlSAUR32 and its related TFs may regulate the early longan SE and be involved in the auxin response regulatory pathway of longan. © 2023 Elsevier Masson SAS",TextMining
"Soil moisture is a key parameter in hydrological research and drought management. The inversion of soil moisture based on land surface temperature (LST) and NDVI triangular feature spaces has been widely used in various studies. Remote sensing provides regional LST data with coarse spatial resolutions which are insufficient for field scale (tens of meters). In this study, we bridged the data gap by adopting a Data Mining Sharpener algorithm to downscale MODIS thermal data with Vis-NIR imagery from Sentinel-2. To evaluate the downscaling algorithm, an unmanned aerial system (UAS) equipped with a thermal sensor was used to capture the ultra-fine resolution LST at three sites in the Tang River Basin in China. The obtained fine-resolution LST data were then used to calculate the Temperature Vegetation Dryness Index (TVDI) for soil moisture monitoring. Results indicated that downscaled LST data from satellites showed spatial patterns similar to UAS-measured LST, although discrepancies still existed. Based on the fine-resolution LST data, a 10-m resolution TVDI map was generated. Significant negative correlations were observed between the TVDI and in-situ soil moisture measurements (Pearson’s r of (Formula presented.) and (Formula presented.)). Overall, the fine-resolution TVDI derived from the downscaled LST has a high potential for capturing spatial soil moisture variation. © 2023 by the authors.",TextMining
"With the ease of gene sequencing and the technology available to study and manipulate non-model organisms, the extension of the methodological toolbox required to translate our understanding of model organisms to non-model organisms has become an urgent problem. For example, mining of large coral and their symbiont sequence data is a challenge, but also provides an opportunity for understanding functionality and evolution of these and other non-model organisms. Much more information than for any other eukaryotic species is available for humans, especially related to signal transduction and diseases. However, the coral cnidarian host and human have diverged over 700 million years ago and homologies between proteins in the two species are therefore often in the gray zone, or at least often undetectable with traditional BLAST searches. We introduce a two-stage approach to identifying putative coral homologues of human proteins. First, through remote homology detection using Hidden Markov Models, we identify candidate human homologues in the cnidarian genome. However, for many proteins, the human genome alone contains multiple family members with similar or even more divergence in sequence. In the second stage, therefore, we filter the remote homology results based on the functional and structural plausibility of each coral candidate, shortlisting the coral proteins likely to have conserved some of the functions of the human proteins. We demonstrate our approach with a pipeline for mapping membrane receptors in humans to membrane receptors in corals, with specific focus on the stony coral, P. damicornis. More than 1000 human membrane receptors mapped to 335 coral receptors, including 151 G protein coupled receptors (GPCRs). To validate specific sub-families, we chose opsin proteins, representative GPCRs that confer light sensitivity, and Toll-like receptors, representative non-GPCRs, which function in the immune response, and their ability to communicate with microorganisms. Through detailed structure-function analysis of their ligand-binding pockets and downstream signaling cascades, we selected those candidate remote homologues likely to carry out related functions in the corals. This pipeline may prove generally useful for other non-model organisms, such as to support the growing field of synthetic biology. © 2023 Kumar et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",TextMining
"Addressing the blockchain technology (BCT) challenges, such as the high energy consumption is unavoidable in smart power systems to take maximum advantage. As an antithetical point, there is a structural duality between using BCT in the electrical grid due to its advantages and energy consumption. To this end, this research work is an inclination toward controlling the miner's energy consumption based on a realistic and efficacious two-stage energy mechanism toward the distributed energy concept and optimal placement of data mining devices. In this circumstance, such a new structure allows miners to mainly sustain their hash rates as a prominent index for security achievement and optimally decrease their cost. This paper suggests a novel distributed model for miners coincided with the smart electrical grid getting inspired by the Prima-Dual Method of Multipliers (PDMM) based distributed approach to settle down the needed power bartering between miners and energy supply resources. In addition, for a similar purpose, it seems to reach the ideal resolution needs to perform the modified reaffirmation of miners (the mining pool) within the secured grid. To execute this task, this research recommends the Intelligent Priority Selection (IPS) techniques as well. When all is said and done, the result of this approach can aid researchers with performing in the field of improving social advantages by the usage of the suggested method. © 2023 International Solar Energy Society",TextMining
"With deep learning-based methods growing (even with scarce data in some fields), few-shot remote sensing scene classification (FSRSSC) has received a lot of attention. One mainstream approach uses base data to train a feature extractor (FE) in the pre-training phase and employs novel data to design the classifier and complete the classification task in the meta-test phase. Due to the scarcity of remote sensing data, obtaining a suitable feature extractor for remote sensing data and designing a robust classifier have become two major challenges. In this paper, we propose a novel dictionary learning (DL) algorithm for few-shot remote sensing scene classification to address these two difficulties. First, we use natural image datasets with sufficient data to obtain a pre-trained feature extractor. We fine-tune the parameters with the remote sensing dataset to make the feature extractor suitable for remote sensing data. Second, we design the kernel space classifier to map the features to a high-dimensional space and embed the label information into the dictionary learning to improve the discrimination of features for classification. Extensive experiments on four popular remote sensing scene classification datasets demonstrate the effectiveness of our proposed dictionary learning method. © 2023 by the authors.",TextMining
"Receptor avidity through multivalency is a highly sought-after property of ligands. While readily available in nature in the form of bivalent antibodies, this property remains challenging to engineer in synthetic molecules. The discovery of several bivalent venom peptides containing two homologous and independently folded domains (in a tandem repeat arrangement) has provided a unique opportunity to better understand the underpinning design of multivalency in multimeric biomolecules, as well as how naturally occurring multivalent ligands can be identified. In previous work, we classified these molecules as a larger class termed secreted cysteine-rich repeat-proteins (SCREPs). Here, we present an online resource; ScrepYard, designed to assist researchers in identification of SCREP sequences of interest and to aid in characterizing this emerging class of biomolecules. Analysis of sequences within the ScrepYard reveals that two-domain tandem repeats constitute the most abundant SCREP domain architecture, while the interdomain “linker” regions connecting the functional domains are found to be abundant in amino acids with short or polar sidechains and contain an unusually high abundance of proline residues. Finally, we demonstrate the utility of ScrepYard as a virtual screening tool for discovery of putatively multivalent peptides, by using it as a resource to identify a previously uncharacterized serine protease inhibitor and confirm its predicted activity using an enzyme assay. © 2023 The Authors. Protein Science published by Wiley Periodicals LLC on behalf of The Protein Society.",TextMining
"The disturbance depth of traffic load has a direct impact on the stability of a room-and-pillar mining goaf. To quantitatively calculate the relationship between the traffic load disturbance depth and influencing factors, 49 groups of horizontal combinations of different influencing parameters are designed in this study, based on the orthogonal experimental design method. Midas GTS is used to simulate and obtain the corresponding traffic load disturbance depth data. A multivariate linear regression analysis of the traffic load disturbance depth is conducted, and a regression formula for calculating the traffic load disturbance depth is established. According to the traffic load disturbance depth, goaf depth, and the stability of the roof, coal pillar, and base plate under traffic load conditions, a judgment flow of the room-and-pillar mining goaf treatment method under traffic load conditions is established, and it is applied to the reconstruction and expansion project of the Jixi section of the Dan-A national highway. The results show that a geogrid can be used for treatment purposes when the traffic load disturbance depth is 1.5 times lower than the depth of the room-and-pillar mining goaf, or when the traffic load disturbance depth is 1.5 times greater than the depth of the room-and-pillar mining goaf but the roof, coal pillar, and base plate are stable. Additionally, grouting is needed for treatment in other cases. The results of this study can provide a scientific basis for the selection of treatment methods for room-and-pillar mining goafs underlying highways in the future. The results are of great significance in the field of engineering for the safety measures concerning highway room-and-pillar mining goafs. © 2023 by the authors.",TextMining
"OBJECTIVE: To explore the core herbs of two illustrious senior Traditional Chinese Medicine (TCM) Physicians for the treatment of liver cancer, and to further clarify the gene targets and pathway mechanisms of liver cancer that the core prescription (CP) may regulate. METHODS: We used the patient information of two illustrious senior TCM physicians from the Affiliated Hospital of Shandong University of Traditional Chinese Medicine and the Affiliated Hospital of Capital Medical University as the database. The CP was analyzed using the community network algorithm. The pathway mechanism was analyzed using network pharmacology method. And the prognostic survival genes were identified using Single factor cox regression analysis. Integrative Pharmacology-based Research Platform of Traditional Chinese Medicine (TCMIP), Herb, Online; Mendelian Inheritance in Man (OMIM), Genecards, Kyoto Encyclopedia of Genes and Genomes (KEGG), Genomic Data Commons (GDC), The Cancer Genome Atlas (TCGA), Gephi and R were used to mine CP, building a pathway network diagram. All the analyses were visualized. RESULTS: We found that the CP consistes of Huangqi (Radix Astragali Mongolici), Danshen (Radix Salviae Miltiorrhizae), Shuihonghuazi (Polygoni Orientalis Fructus), Baihuasheshecao (Herba Hedyotdis), Banzhilian (Herba Scutellariae Barbatae), and Ezhu (Rhizoma Curcumae Phaeocaulis), which were attributed to the two physicians respectively. The CP played an anticancer role through such pathways as signal transduction, energy metabolism, immune system and other pathways, covering a total of 112 pathways and 176 herb-disease-related genes. Fourteen genes have a significant impact on the prognosis and survival of liver cancer. CONCLUSION: Based on the liver cancer cases of two illustrious senior TCM physicians, we obtained the CP through data mining. The CP may mainly exert anticancer effects by inhibiting inflammatory response, angiogenesis, and enhancing the body's immune response. We screened out 14 genes in the CP that may be related to the prognosis of liver cancer, and these genes may play an important regulatory role in the prognosis of liver cancer. © 2023 JTCM. All rights reserved.",TextMining
"Maritime shipping network is essential for ship routing, scheduling, and flexibility analysis of the shipping system. This paper proposes a framework for extracting global maritime shipping traffic networks using automatic identification system (AIS) data based on machine learning methods. The framework consists of berthing area identification, trajectory selection and separation, waypoint area identification, edge generation, and network construction. Simultaneously, a route planning method using the A* algorithm based on a probability-directed graph model is proposed to verify the effectiveness of the maritime shipping network. The real-world global AIS data of bulk carriers in 2018 was used to extract maritime shipping networks to prove the framework. The framework successfully extracts maritime shipping networks containing 2769 berthing areas and 2688 waypoint areas over the world's oceans, and the results demonstrate that the estimated networks can be used to analyze the speed of navigation on edges and the size of flows between nodes. Additionally, along with the estimated shipping networks, distance-based route planning is still more stable even if generated routes considering node connection probabilities usually match the observed trajectories. It is concluded that the proposed framework and methods may help (1) provide a thorough framework to obtain and analyze maritime shipping traffic networks and (2) enrich route planning methods by considering historical navigation patterns. © 2022",TextMining
"Diabetes is the leading cause of death in the world, and it also affects kidney disease, loss of vision, and heart disease. Data mining techniques contribute to health care decisions for accurate disease diagnosis and treatment, reducing the workload of experts. Diabetes prediction is a rapidly expanding field of research. Early diabetes prediction will result in improved treatment. Diabetes causes a variety of health issues. Therefore, it is critical to prevent, monitor, and raise awareness about it. Type 1 and Type 2 diabetes can cause heart disease, renal problems, and eye difficulties. In this paper, we propose a diabetes prediction model using data mining techniques. We apply four data mining techniques such as Random Forest, Support Vector Machine (SVM), Logistic Regression, and Naive Bayes. The proposed mechanism is trained using Python and analysed with a real dataset, which is collected from Kaggle. Furthermore, the performance of the proposed mechanism is analysed using the confusion matrix, sensitivity and accuracy performance metrices. In logistic regression, the accuracy is high, i.e., 82.46%, in comparison to other data mining techniques. © 2022 The Authors",TextMining
"This study aims to improve the management efficiency of e-commerce platform and assists merchants on the e-commerce platforms in formulating a suitable sales plan urgently. Online sales forecasting analysis needs to be studied and shows that the management efficiency and operating income on an e-commerce platform is improved through accurate commodity sales forecasting. A novel online clothing sales forecasting model is proposed based on data mining technique. This study contributes to presenting the model references for e-commerce platform to make decisions on future sales and directions. (1) The gray correlation model was employed to mine the correlation degree between each feature and the clothing sales to select the features that have a great impact on clothing sales. (2) A sailfish optimization algorithm (SFO) algorithm with random disturbance strategy (SFOR) was proposed based on the SFO to improve the prediction effect of clothing sales. The benchmark function test results showed that the SFOR algorithm effectively avoided local extreme points. (3) The SFOR algorithm was used to solve the extreme learning machine (ELM) random parameter problem, and the SFOR-ELM-based online sales prediction model of clothing products suitable for multiple scenarios was constructed. In addition, three cases are applied to verify the SFOR-ELM-based online clothing sales forecast model. The verification results proved that SFOR-ELM achieved satisfactory prediction results, with its mean absolute percentage error values controlled below 5.1% and root mean square error values controlled below 16.2%. © 2022 Elsevier Ltd",TextMining
"Background: Natural language processing has been increasingly used in palliative care research over the last 5 years for its versatility and accuracy. Aim: To evaluate and characterize natural language processing use in palliative care research, including the most commonly used natural language processing software and computational methods, data sources, trends in natural language processing use over time, and palliative care topics addressed. Design: A scoping review using the framework by Arksey and O’Malley and the updated recommendations proposed by Levac et al. was conducted. Sources: PubMed, Web of Science, Embase, Scopus, and IEEE Xplore databases were searched for palliative care studies that utilized natural language processing tools. Data on study characteristics and natural language processing instruments used were collected and relevant palliative care topics were identified. Results: 197 relevant references were identified. Of these, 82 were included after full-text review. Studies were published in 48 different journals from 2007 to 2022. The average sample size was 21,541 (median 435). Thirty-two different natural language processing software and 33 machine-learning methods were identified. Nine main sources for data processing and 15 main palliative care topics across the included studies were identified. The most frequent topic was mortality and prognosis prediction. We also identified a trend where natural language processing was frequently used in analyzing clinical serious illness conversations extracted from audio recordings. Conclusions: We found 82 papers on palliative care using natural language processing methods for a wide-range of topics and sources of data that could expand the use of this methodology. We encourage researchers to consider incorporating this cutting-edge research methodology in future studies to improve published palliative care data. © The Author(s) 2022.",TextMining
"Topographic data are increasingly important to environmental models as fine-scale resolution, wide coverage data sets become available. Scale is an important consideration for predictive model quality. Recent advances in multiscale terrain analysis led to scaling techniques that allow the scale at which a topographic parameter is represented to vary spatially. This research compared predictive soil model performance across feature sets generated with different scaling strategies; including multiple heterogeneous strategies, common feature selection algorithms applied to homogeneously scaled data, and unscaled data. Model performance was assessed for accuracy and uncertainty. The results showed that unscaled data performed worse in all circumstances compared to multiscale feature sets. Overall, heterogeneous and homogeneous feature sets did not differ substantially in accuracy, prediction uncertainty, or error. However, one scaling strategy exploited the flexibility of heterogeneous scaling to consistently perform better than other feature sets for most soil properties in terms of accuracy, and consistently ranked among the least uncertain and least error prone (up to a 0.080 increase in accuracy with a corresponding 0.017 decrease in prediction uncertainty and 0.011 decrease in error relative to the second best method, in the case of the proportion of clay modelled at 5–15 cm depth). This was achieved by decoupling the definition of process scales from analytical parameterization, allowing the optimization to occur within broadly defined process scales. This research demonstrates how to exploit heterogeneous scaling of topographic attributes to improve model performance. © 2022 Elsevier Ltd",TextMining
"In recent years, the technical application of 3D LiDAR has gradually expanded to the field of built heritage. 3D scanning, high-precision measurement, and reconstruction have enriched the methods of built heritage preservation and significantly improved the quality of heritage preservation in China. 3D LiDAR has broken through the limitations of a single technology application and played a greater role in the field of heritage preservation on different scales. Through the collaboration of multi-technology, such as 3D printing, digital mapping, internet of things, machine learning, intelligent sensors, close-range photogrammetry, infrared detection, stress wave tomography, material analysis, XR technology, reverse engineering, etc., 3D LiDAR shows its technological advantages on exploring the remote real-time monitoring and digitization of the built heritage, geological and environmental data collection, prediction of sedimentation, deformation monitoring, weather monitoring,system life cycle health detection, digital reproduction of built heritage for developing scientific problems and engineering practices such as building contour recognition, information feature matching, structural reinforcement and damaged component replacement. In addition, through the docking with GIS, HBIM, XR, and CIM, it provides fine digital models and high-precision data benchmarks which contribute to the heritage visual reproduction; and through the docking with 3Ds Max, SketchUp, and other modeling software, it has contributed to the renewal design of the built heritage, space optimization, and the scientificity and rationality of the heritage value evaluation. However, past technology applications also highlighted many problems such as limited recorded information, a large amount of data, high difficulty in collaboration, non-standardized and fragmented data, and difficulty in data mining and comprehensive utilization. There are still deficiencies in building a built heritage data backplane, and the development of a dynamic, three-dimensional, intelligent and refined heritage monitoring system, and further research is needed on these issues. This study reviews the previous academic progress and application of 3D LiDAR in the reconstruction of built heritage and multi-technology collaboration in the process of preservation, clarifies the current research hotspots and methods, the frontier issues of concern, and also clarifies the specific problems and challenges in the future. © 2022 The Authors",TextMining
"This paper presents an annotated dataset used in the MOOD Antimicrobial Resistance (AMR) hackathon, hosted in Montpellier, June 2022. The collected data concerns unstructured data from news items, scientific publications and national or international reports, collected from four event-based surveillance (EBS) Systems, i.e. ProMED, PADI-web, HealthMap and MedISys. Data was annotated by relevance for epidemic intelligence (EI) purposes with the help of AMR experts and an annotation guideline. Extracted data were intended to include relevant events on the emergence and spread of AMR such as reports on AMR trends, discovery of new drug-bug resistances, or new AMR genes in human, animal or environmental reservoirs. This dataset can be used to train or evaluate classification approaches to automatically identify written text on AMR events across the different reservoirs and sectors of One Health (i.e. human, animal, food, environmental sources, such as soil and waste water) in unstructured data (e.g. news, tweets) and classify these events by relevance for EI purposes. © 2023 The Authors",TextMining
"In recent decades, urbanization has led to an increase in building material stock. The high-resolution quantification of building stock is essential to understand the spatial concentration of materials, urban mining potential, and sustainable urban development. Current approaches rely excessively on statistics or survey data, both of which are unavailable for most cities, particularly in underdeveloped areas. This study proposes an end-to-end deep-learning model based on multi-source remote sensing data, enabling the reliable estimation of building stock. Ground-detail features extracted from optical remote sensing (ORS) and spatiotemporal features extracted from nighttime light (NTL) data are fused and incorporated into the model to improve accuracy. We also compare the performance of our feature-fusion model with that of an ORS-only regression model and traditional NTL regression for Beijing. The proposed model yields the best building-stock estimation, with a Spearman's rank correlation coefficient of 0.69, weighted root mean square error of 0.58, and total error in the test set below 14%. Using gradient-weighted class activation mapping, we further investigate the relationship between ORS features and building-stock estimation. Our model exhibits reliable predictive capability and illustrates the tremendous value of the physical environment for estimating building stock. This research illustrates the significant potential of ORS and deep learning for stock estimation. Large-scale, long-term building-stock investigations could also benefit from the end-to-end predictability and the data availability of the model. © 2022 by the International Society for Industrial Ecology.",TextMining
"Microseismic monitoring is crucial for risk assessment in mining, fracturing and excavation. In practice, microseismic records are often contaminated by undesired noise, which is an obstacle to high-precision seismic locating and imaging. In this study, we develop a new denoising method to improve the signal-to-noise ratio (SNR) of seismic signals by combining wavelet coefficient thresholding and pixel connectivity thresholding. First, the pure background noise range in the seismic record is estimated using the ratio of variance (ROV) method. Then, the synchrosqueezed continuous wavelet transform (SS-CWT) is used to project the seismic records onto the time-frequency plane. After that, the wavelet coefficient threshold for each frequency is computed based on the empirical cumulative distribution function (ECDF) of the coefficients of the pure background noise. Next, hard thresholding is conducted to process the wavelet coefficients in the time-frequency domain. Finally, an image processing approach called pixel connectivity thresholding is introduced to further suppress isolated noise on the time-frequency plane. The wavelet coefficient threshold obtained by using pure background noise data is theoretically more accurate than that obtained by using the whole seismic record, because of the discrepancy in the power spectrum between seismic waves and background noise. After hard thresholding, the wavelet coefficients of residual noise exhibit isolated and lower pixel connectivity in the time-frequency plane, compared with those of seismic signals. Thus, pixel connectivity thresholding is utilized to deal with the residual noise and further improve the SNR of seismic records. The proposed new denoising method is tested by synthetic and real seismic data, and the results suggest its effectiveness and robustness when dealing with noisy data from different acquisition environments and sampling rates. The current study provides a useful tool for microseismic data processing.  © 2022 The Author(s). Published by Oxford University Press on behalf of The Royal Astronomical Society.",TextMining
"Recognizing the stage of fruit maturity and thus determining the optimum harvesting time is critical since the competitive market requires high-quality products at a competitive price. Furthermore, in the context of the global water crisis, harvesting watermelons at an inappropriate ripening stage causes water wasting of around 280 kg per kilo of watermelon as a virtual water footprint, highlighting the necessity of criteria for harvesting ripe watermelons by the farmers. This research thus aims to classify the Charleston Gray watermelon type into three categories i.e. unripe, ripe, and overripe using portable acoustic signal processing, data mining methods, and artificial intelligence approaches. Signal processing in the time and frequency domains and Wavelet Transformation were used to extract essential features from acoustic signals of the watermelons. This was followed by the selection of the significant features in classification using a t-test mean comparison. Sample categorization was accomplished using Support Vector Machines and the K-Nearest Neighbor techniques. Considering the effect of three impact positions (the stem side, middle, and flower side), two materials (Polyoxymethylene and metal balls) and two diameters (15 and 10 mm diameter) for striker ball, using Principal Component Analysis and application of various signal processing methods, 3360 models were established. Based on the frequency equipped with the Mahalanobis distance, the K-Nearest Neighbor classifier presented the best result with a 77.3 % classification rate for signals obtained from the small metal ball and stem side impact position. In comparison, experts accurately had categorized 52 % of the samples in total. © 2022 Elsevier B.V.",TextMining
"Backround: This study aimed to analyze the semantic network and content analyses of the posts published in a subreddit related to orthodontic treatment on Reddit (Advance Publications, Inc., San Francisco, California). Methods: The eight threads in the r/Braces subreddit were divided into two categories: 1) “treatment process” (Braces are off!!!, Braces progress, Before and after!, and Day 1!) and 2) “question/problem” (Question, Discussion!, Need advice! and Rant!). For both categories, a semantic network analysis was performed using the Leximancer software (Leximancer Pty Ltd., Brisbane, Australia). In addition, the quality of the posts published in the “question” thread and the usefulness of the replies provided to these questions (useful, misleading, or neutral) were analyzed. Results: Seven themes (braces, teeth, months, day, worth, started, and result) that mostly emphasized orthodontic treatment and treatment duration were elicited from the “treatment process” category, and seven themes (teeth, orthodontist, braces, week, bands, brush, and extractions) that mostly emphasized orthodontic treatment, orthodontists, and time were elicited from the “question/problem” category. It was also revealed that users voted on the posts related to the “treatment process” category and moved the posts to the list of top posts on the platform. In the “question” thread, 47.79% of the posts asked for advice and 21.11% of them were related to failures. In addition, 69% of the replies were categorized as “useful.” Conclusions: Reddit is a successful data mining platform, and the users provide highly useful replies to the questions posted on Reddit regarding orthodontic treatment. © 2022",TextMining
"This study aimed to link experimental data dealing with complex agroecological systems. For sharing and linking collected data with the generic AEGIS (Agro-Ecological Global Information System) database, our work described in this data paper consists in mapping researcher variables to the AEGIS dictionary variable for different tropical crops (sugarcane, rice, sorghum or cover crops). Additionally, this data paper presents a study case based on sugarcane intercropping systems for evaluating 3 matching measures of variables. © 2022",TextMining
"Dense mining areas are regions with relatively concentrated mining enterprises or occupied land, which are also regions with intense economic and resource development conflicts and environmental protection. However, ecological assessments by remotely sensed technology do not consider the characteristics of mining areas. To fill the knowledge gap, we employed seven indexes, i.e., fractional vegetation cover, greenness above bare soil, wetness, black particulates, land surface temperature, iron oxides, and the landscape fragmentation index, to construct the iron mine remote sensing-based ecological index (IM-RSEI) by Landsat data. We chose Qian'an City and Qianxi County in Tangshan City, China, as the study area where iron ore-related industries are concentrated. The results showed that the ecological environment generally deteriorated first and then improved that the IM-RSEI values for 1992, 2000, 2009, and 2018 were 0.5102, 0.4776, 0.4882, and 0.5001, respectively. The mean IM-RSEI values for the dense mining area and surrounding multi-gradient buffer zones, from near to far, were 0.5412, 0.5146, 0.5076, 0.4756, and 0.4563, implying that mining activities endangered the surrounding ecological quality. This study assessed the ecological environment in dense mining areas from multiple perspectives by remote sensing technology. The research conclusions can provide a reference for pollution control during mining development in Qian'an, Qianxi, and similar mining areas. © 2022 The Author(s)",TextMining
"This article proposes the basic way of behaving of the quantum Sherrington-Kirkpatrick (SK) model at nothing and limited temperatures is examined. Through the investigation of the Binder cumulate, the entire stage chart of the model has been distinguished, and the connection length type has been gotten from the scaling examination of the mathematical information. The creator has noticed, at a restricted temperature, a change from old style to quantum-variance overwhelmed values for both the basic Binder cumulate and the relationship length example. The way of behaving of the request boundary appropriation of the model in the glass stage has been explored (at limited and zero temperatures). Notwithstanding a nonergodic zone overwhelmed by old style changes (where imitation balance is disregarded), the creators found a low-temperature ergodic locale overwhelmed by quantum vacillations in the optics stage. In this quantum-vacillation overwhelmed region, the request boundary dissemination has a minuscule top around its most probable worth, steadily moving toward a delta capability in the restriction of limitless framework size (demonstrating copy balance rebuilding or periodicity in the framework). In light of the investigation of the autocorrelation of the twists in both ergodic and nonergodic districts, the creators found a huge reduction in the unwinding time (as well as an adjustment of the unwinding conduct) in the quantum-vacillation overwhelmed (ergodic) locale of the optics stage contrasted with the traditional change ruled (nonergodic) locale. While strengthening courses get through this ergodic region, the tempering chance (to achieve an extremely low energy level of the conventional SK model) turns out to be essentially framework size free. © 2022 Elsevier GmbH",TextMining
"In Mohammadi [1], The authors regret to inform that the citation for the bds.m code written by Professor Ludwig Kanzler were not included to Table 1. The updated Table 1 note is shown below. Note: Tests are Lee, White, and Granger (LWG); Terasvirta, Lee, and Granger (TLG); Tsay; Brock, Dechert, and Sheinkman (BDS); MC Leod Li (MCLoLi); Ramsy; Keenan; and AutoRegressive Conditional Heteroscedasticity (ARCH). Data generating process are white noise (WN), first-order autoregressive (AR1), second-order autoregressive (AR2), second order moving average (MA2), third order moving average (MA3), fifth order moving average (MA5), autoregressive moving average of various orders (ARMA1,1; ARMA2,1; ARMA2,2 and ARMA2,3). SizDist stands for distortion of empirical size from nominal. The BDS p-values are computed by using the code developed by Ludwig Kanzler. Reference: L. Kanzler, BDS: MATLAB module to calculate Brock, Dechert & Scheinkman test for independence, Statistical Software Components T871803, Boston College Department of Economics, Massachusetts, 1998. S. Mohammadi, Neural network for univariate and multivariate nonlinearity tests. Stat. Anal. Data Mining ASA Data Sci. J. 13 (2019), 9250–9270. © 2022 Wiley Periodicals LLC.",TextMining
"In the mining industry, current grade control practices lack a standardised framework that can assess the reliability of average grade estimates computed for selective mining units (otherwise known as grade-blocks) within a mining bench. This article describes two measures that can quantify sampling fairness and geochemical consensus. Concretely, sampling fairness considers spatial factors such as sampling density and bias in the spatial distribution of blastholes whereas geochemical consensus considers the agreement between the assay samples within a grade-block. Geochemical disparity is measured using a robust distance estimator and a masking formula that takes into account the proportion of outliers and magnitude of differences observed above a threshold. The efficacy of the consensus measure is demonstrated through validation experiments. The results confirm the MCD (minimum covariance determinant) robust estimator can breakdown when the fraction of outliers exceeds (n−k−1)/(2n). For k≥2 variables and a sample size n≥10, this typically leads to an underestimation of the true extent and impact of outliers when they exceed 40%. An extension based on split-sequence analysis is proposed to overcome this limitation. The method is evaluated using production data from an open-pit iron ore deposit. An open-source implementation of the proposed algorithms is available on GitHub. © 2022 Elsevier Ltd",TextMining
"The hydraulic transport is a process commonly used in mining and other industries for moving fine particles or ore concentrates in pipes over long distances using a water stream. The control and monitoring of this process requires sensor technology capable of measuring data that can be related to characteristics of the two-phase flow. A novel sensor technology with high potential for this purpose is the acoustic emission (AE) technology. Within this work, we conducted experimental tests measuring AE on a hydraulic transport system considering different sand concentrations in the flow. The analysis shows that the friction of sand particles against the pipe wall has a strong relationship with the AE activity. Besides, a deeper analysis of the AE signals revealed that the flow regime has an important influence on the generation of continuous AE and AE bursts due to turbulences that facilitate impacts of particles against the pipe wall. The main contribution of this paper is to provide experimental evidence and insights on how the AE measurements can be used for monitoring and controlling of hydraulic transport processes. © 2022, Society for Mining, Metallurgy & Exploration Inc.",TextMining
"Objective: Vaccination is one of the most powerful and effective protective measures against Coronavirus disease 2019 (COVID-19). Currently, several blogs hold content on vaccination attitudes expressed on social media platforms, especially Sina Weibo, which is one of the largest social media platforms in China. Therefore, Weibo is a good data source for investigating public opinions about vaccination attitudes. In this paper, we aimed to effectively mine blogs to quantify the willingness of the public to get the COVID-19 vaccine. Materials and Methods: First, data including 144,379 Chinese blogs from Weibo, were collected between March 24 and April 28, 2021. The data were cleaned and preprocessed to ensure the quality of the experimental data, thereby reducing it to an experimental dataset of 72,496 blogs. Second, we employed a new fusion sentiment analysis model to analyze the sentiments of each blog. Third, the public's willingness to get the COVID-19 vaccine was quantified using the organic fusion of sentiment distribution and information dissemination effect. Results: (1) The intensity of bloggers’ sentiment toward COVID-19 vaccines changed over time. (2) The extremum of positive and negative sentiment intensities occurred when hot topics related to vaccines appeared. (3) The study revealed that the public's willingness to get the COVID-19 vaccine and the actual vaccination doses shares a linear relationship. Conclusion: We proposed a method for quantifying the public's vaccination willingness from social media data. The effectiveness of the method was demonstrated by a significant consistency between the estimates of public vaccination willingness and actual COVID-19 vaccination doses. © 2022 Elsevier B.V.",TextMining
"Twelve files have been obtained after the extraction of data from raster PDF images of sonic log graphs. These files data regard exploration wells placed in the Adriatic Sea pertaining the Apulia (Branzino-1, Chiara-1, Cristina-1, Famoso-1, Giove-1, Giove-2, Grazia-1, Grifone-1, Medusa-1, Sabrina-1, Simona-1, and Sparviero-1bis), and the related raster sonic log graphs are free accessible at the ViDEPI Project (www.videpi.com) of the Ministry for the Economic Development of the Italian Government. Two columns A and B of data, i.e., interval transit time Δt [µs/ft] and depth [m], respectively, characterise each file. Hence, 18,396 pairs of Δt-depth values have been obtained. The picking of the data occurred by the use of WebPlotDigitizer© free software. These data are relevant for the interpretation of reflection seismic lines throughout the Adriatic Sea, mainly in the offshore the Apulia. Moreover, the interpretation of those reflection seismic lines located in the adjacent offshore zones, such as the Ionian Sea, can benefit from these data; the values can be important for seismological goals around the Apulia, as well. From these data, Δt-depth diagrams can be originated by the use of software capable of building 2D graphs from values in CSV files (e.g. Matlab©). © 2022 The Author(s)",TextMining
"Diabetes has been acknowledged as a well-known risk factor for renal and cardiovascular disorders, cardiac stroke and leads to a lot of morbidity in the society. Reducing the disease prevalence in the community will provide substantial benefits to the community and lessen the burden on the public health care system. So far, to detect the disease innumerable data mining approaches have been used. These days, incorporation of machine learning is conducive for the construction of a faster, accurate and reliable model. Several methods based on ensemble classifiers are being used by researchers for the prediction of diabetes. The proposed framework of prediction of diabetes mellitus employs an approach called stacking based ensemble using non-dominated sorting genetic algorithm (NSGA-II) scheme. The primary objective of the work is to develop a more accurate prediction model that reduces the lead time i.e., the time between the onset of diabetes and clinical diagnosis. Proposed NSGA-II stacking approach has been compared with Boosting, Bagging, Random Forest and Random Subspace method. The performance of Stacking approach has eclipsed the other conventional ensemble methods. It has been noted that k-nearest neighbors (KNN) gives a better performance over decision tree as a stacking combiner. © 2023 Institute of Advanced Engineering and Science. All rights reserved.",TextMining
"We consider the detection and localization of change points for the off-line sequence of observations. Specifically, we propose a new multi-segmentation algorithm for detecting multiple change-points, named shape-based multiple segmentation algorithm, which is a generalization of binary segmentation. The proposed method is combined with deep mining on the shape information of the test statistics curve to overcome the Gaussian distribution hypothesis limitation and the limitation of traditional segmentation methods only being able to detect one change-point per stage. Combined with shape context, a robust testing statistic was developed via a shape-based descriptor statistic instead of the traditional CUSUM statistic. Then a data-driven threshold by the rightmost sudden-drop point is proposed, and the change points are further identified by single-peak identification. An efficient multiple segmentation based on a shape recognition procedure is implemented to locate change points. The effectiveness of the proposed procedure is illustrated using both synthetic data sets and real world data from electrical distribution networks. © 2023",TextMining
"Online medical platform is a platform for patients to post their medical experience, collect medical information, and link doctors and patients for related medical activities. As the number of patients and doctors registered on the platform increases, there is an urgent need to consider how patients can identify useful information from the vast amount of information to help them make medical choices, and how the platform can provide distinctive medical choices based on the risk preferences of patients. In this paper, we propose a decision-making model that integrates a machine-learning method and a multi-criteria decision-making method to help patients to select physicians based on user-generated content considering interactive criteria and risk preferences of patients. Firstly, by data mining methods, various criteria included in user-generated content that influence patients' selection behavior are retrieved to construct a physician evaluation system. Secondly, a sentiment analysis method based on a medical review corpus is developed to mine satisfaction information from text reviews. Finally, a multi-criteria decision-making method is proposed considering patients' risk-averse preferences for medical services and the interactions among criteria. The validity of the proposed model is demonstrated by a case study of ranking psychologists from haodf.com. The comparisons with other methods and sensitivity analysis results provide suggestions to patients to choose psychologists and the website to rank psychologists. © 2022 Elsevier Ltd",TextMining
"Faults are geologic structures that can cause disasters and thereby affect the safety of coal mines. To achieve improved fault interpretation accuracy during 3D seismic exploration of coal mines, we develop a seismic fault identification method based on a combination of kernel principal component analysis (KPCA), genetic particle swarm optimization (GPSO), and a support vector machine (SVM). The Dongwupan area of the Sihe Coal Mine in Shanxi Province, which mainly contains small faults, is the research area, and we extract 20 types of seismic attributes. According to the median difference between fault and nonfault data, we select the 12 leading seismic attributes with differences greater than 0.1 in descending order. Considering the information redundancy and the nonlinear relationships among seismic attributes, we adopt the KPCA method to reduce and optimize the selected seismic attributes, thereby effectively capturing the main information contained in the data and eliminating noise. Moreover, we introduce the GPSO algorithm to effectively optimize the SVM model parameters, and we construct a KPCA-GPSO-SVM model to classify and predict faults. Through model testing, the average fault identification accuracy of the model is 98.89%. Relative to the KPCA-particle swarm optimization-SVM, principal component analysis-GPSO-SVM, and GPSO-SVM models, the accuracy is improved by 3.3%, 7.8%, and 16.7%, respectively. We apply the proposed model to predict the fault distribution in the research area, and we compare the predictions to the actual exposed faults. The results indicate that the KPCA-GPSO-SVM model can suitably realize fault distribution prediction in a mining area. Moreover, compared with manual fault interpretation, the developed method is faster, more intuitive, and can better identify small faults. © 2023 Society of Exploration Geophysicists and American Association of Petroleum Geologists.",TextMining
"Over the past decade, the use of artificial intelligence techniques in the field of health-monitoring has gained significant interest, especially for structures such as building and bridges. However, applications to industrial systems such as equipment-piping systems in nuclear plants have not been explored. In this paper, it is shown that the existing techniques developed for buildings and bridges cannot be extended directly to equipment-piping systems as the response of such systems is governed by multiple localized modes unlike that in buildings and bridges. This paper proposes a new approach that consists of three key aspects: (i) a novel vector of degradation-sensitive features extracted from measured data, (ii) using a deep Artificial Neural Network (ANN) for diagnosis of degradation location and degradation severity, and (iii) consideration of uncertainty in degradation severity when training the ANN. Degradation in piping-equipment systems can occur due to flow-accelerated erosion and corrosion. These locations can potentially exhibit damage such as localized yielding or initiation of cracking due to an external event such as an earthquake. Moreover, such locations can at times go undetected by current inspection techniques. Therefore, a robust framework is needed for detection of degradation after a seismic event. This manuscript proposes a proof-of-concept framework, which utilizes data collected from sensors to generate a deep ANN database for predicting degraded locations and severity in a piping-equipment system. Degradation severity is classified as minor, moderate, and severe. In the suggested methodology, a novel vector of degradation-sensitive features is extracted from the sensor data to train the ANN. A simple piping-equipment system is selected to demonstrate feature extraction as a means to simplify pattern recognition, explore the design and parameters of an ANN, and develop a sensor placement strategy. The effectiveness of the proposed framework is demonstrated on a realistic primary safety system of a two-loop nuclear reactor. It is shown that the proposed post-hazard condition assessment framework is able to detect degraded locations along with the severity levels, including minor degradation, with considerably higher accuracy. © 2022 Elsevier Ltd",TextMining
"Precision livestock farming (PLF) offers farmers real-time monitoring and management system. PLF provides a real-time warning when something goes wrong so that the farmer can take immediate action to solve the problem. PLF introduces many new challenges and questions that must be resolved. Some of these challenges are related to the integration of grazing and animal health into the beef-production process. This article introduces an architecture for the self-managing of a beef-production farm. In particular, the architecture includes three autonomous cycles of data analysis tasks (ACODAT) that allow beef producers to have adequate coordination, optimization and planning of the productive process, which are: (i) circuit preparation, (ii) animal purchase, and (iii) animal fattening. This article also instantiates, in a farm, the autonomous animal-fattening cycle, as the first step towards efficient and effective beef-production processes. The main contributions of this architecture are (i) the ability to use everything mining to improve the knowledge of the system and decision-making processes, and (ii) three ACODAT for real-time analysis for sustainable and environmentally-friendly livestock production. The results are encouraging since the ACODAT allows smart management of the beef-production process, naturally introducing artificial-intelligence techniques to develop these tasks. Particularly, modeling using ACODAT allows an adequate description of a precision livestock process. Likewise, the preliminary results of some of the tasks of ACODAT are stimulating because they allow evaluating the feasibility of the proposal. For example, a first task for the identification of cattle fattening has a Mean Absolute Error (MAE) of 5.4 kg, which will be used by ACODAT to identify anomalies in the fattening process. The instantiation of the animal-fattening cycle shows the viability and robustness of this proposal. © 2022 Elsevier Inc.",TextMining
"Artificial intelligence (AI) is a machine science that can mimic human behaviour like intelligent analysis of data. AI functions with specialized algorithms and integrates with deep and machine learning. Living in the digital world can generate a huge amount of medical data every day. Therefore, we need an automated and reliable evaluation tool that can make decisions more accurately and faster. Machine learning has the potential to learn, understand and analyse the data used in healthcare systems. In the last few years, AI is known to be employed in various fields in pharmaceutical science especially in pharmacological research. It helps in the analysis of preclinical (laboratory animals) and clinical (in human) trial data. AI also plays important role in various processes such as drug discovery/manufacturing, diagnosis of big data for disease identification, personalized treatment, clinical trial research, radiotherapy, surgical robotics, smart electronic health records, and epidemic outbreak prediction. Moreover, AI has been used in the evaluation of biomarkers and diseases. In this review, we explain various models and general processes of machine learning and their role in pharmacological science. Therefore, AI with deep learning and machine learning could be relevant in pharmacological research. © 2023, The Author(s) under exclusive licence to Maj Institute of Pharmacology Polish Academy of Sciences.",TextMining
"COVID-19 has negative impacts on supply chain operations between countries. The novelty of the study is to evaluate the sectoral effects of COVID-19 on global supply chains in the example of Turkey and China, considering detailed parameters, thanks to the developed System Dynamics (SD) model. During COVID-19 spread, most of the countries decided long period of lockdowns which impacted the production and supply chains. This had also caused decrease in capacity utilizations and industrial productions in many countries which resulted with imbalance of maritime trade between countries that increased the freight costs. In this study, cause and effect relations of trade parameters, supply chain parameters, demographic data and logistics data on disruptions of global supply chains have been depicted for specifically Turkey and China since China is the biggest importer of Turkey. Due to this disruption, mainly exports from Turkey to China has been impacted in food, chemical and mining sectors. This study is helpful to plan in which sectors; the actions should be taken by the government bodies or managers. Based on findings of this study, new policies such as onshore activities should consider to overcome the logistics and supply chain disruptions in global supply chains. This study has been presented beneficial implications for the government, policymakers and academia. © 2022 Elsevier Ltd",TextMining
"Currently, the available CR spectrum is not being used to their full potential. Certainly, the CR system is capable of meeting this challenge. Whenever a licensed user has to start another transmission on that channel, spectrum handoff allows an unlicensed user to leave its current channel. The SU then switches to a different channel to finish the incomplete transmission. This technique uses the handshaking protocol to transmit and receive an acknowledgment before data transmission to obtain the user's wait time.This paper describes the Convolution Neural Network automatically extracts the features without any human supervision. For classification, a two-layer hidden neural-network is utilized once features are extracted. The CNN performs convolution operation to extract the complex features of the data that is significant for doing regression. First, the preprocessed data is delivered to the CNN's input layer. The CNN conducts a convolution operation on the data to extract the complex features that are important for regression. The developed model consists of a sequence layer, Long Short Term Memory (LSTM) layer, fully connected layer, and a regression layer. LSTM memory cells were used in the LSTM layer to provide extended memory support. LSTM units save the essential past state information to increase performance by accounting for dependencies, and they erase the unnecessary information to save memory an [1]d energy. The fully linked layer collects the processed output from all of the LSTM hidden units. The regression layer receives a single output as a result of this. The regression layer computes an output for which the loss value is computed and propagated backwards during the training phase. This is done for all of the training iterations until the loss is zero. The anticipated values of waiting time are next tested using a fully trained regression model. The observed waiting time as a function of the number of rounds played. The loss and RMSE (Root mean square error) keep decreasing for increasing number of iterations of training. © 2022",TextMining
"Mineral exploration reports include not only a large number of geological profiles but also geological text by offering valuable information and knowledge about the geological environments in which mineral deposits form. Extracting and understanding historical data can assist in the fast analysis of geological content and support 3D model construction. However, geological texts are written in unstructured form and have many correlations with geological profiles. It is a challenging task to derive meaningful geological information without manually reading through a large collection of reports, which is a formidable task for geologists. This paper proposes a geological profile-text association framework for constructing a knowledge graph, and it aims to understand the contents of the geological profile, transform a larger amount of textual data into structure form, and link the geological profile and text to a graph-based knowledge representation that assists further analysis of knowledge discovery. The concept of constructing vector geological profile rock layer objectification is proposed to make each rock layer with geometric features and attribute information for the geological profile, and the geological entity relationship is extracted to form a triple by deep learning and stored and expressed in the form of a graph structure for geological text. Finally, a geological profile and text association model is established by word vector similarity. The proposed approach is capable of rapidly and robustly understanding geological profiles, extracting geological texts, establishing correlations between them, and performing geological knowledge mining. © 2022 The Author(s)",TextMining
"This work evaluates the effects of climate change on the surface water resources (river flow) of the Sanjabi basin, Iran, by comparing data-mining, lumped, and distributed models, namely artificial neural networks (ANN), the identification of unit hydrographs and component flows from rainfall, evaporation, and streamflow (IHACRES) model, and the soil and water assessment tool (SWAT). Climate projections in terms of monthly temperature and rainfall made by 17 atmosphere–ocean general circulation models (AOGCMs) by the 5th Assessment Report (AR5) of the Intergovernmental Panel on Climate Change (IPCC) under emission scenarios of Representative Concentration Pathways (RCPs) (RCP2.6, RCP4.5, and RCP8.5) during the baseline period 1971–2000 and future periods 2040–2069 and 2070–2099 are applied in the Sanjabi basin. The predictive skill of the AOGCMs is evaluated with performance criteria. The evaluation results indicate the CNRM-CM5 model features the best performance in terms of rainfall, average temperature, and minimum temperature projections, and the GFDL-CM3 provides the most accurate maximum temperature projections. Four downscaling methods (change factor (Delta), ClimGEN, LARS-WG, and Genetic Programming (GP)) are compared based on the R2, RMSE, MAE, and NSE. The predictive skill of the LARS-WG method was the highest. ANN, IHACRES, and SWAT are implemented to project future runoff following calibration and testing. The IHACRES model exhibits the best performance. The IHACRES model is applied to project future runoff under climate-change scenarios. The results indicate a reduction in runoff under all emission scenarios in the two future periods, with the RCP8.5 scenario featuring the largest reductions in runoff in 2040–2069 and 2070–2099 and being equal to 42.0 and 44.3%, respectively. © 2022 Elsevier B.V.",TextMining
"Present investigation is focused on the synthesis of poly-aniline coated iron ore mining waste (PANI@IOMW) adsorbent and its utilization for remediation of Cr (VI) from water using batch process. The studied adsorbent shows excellent Cr (VI) mitigation properties with highest efficiency of 99% at significantly low dosage of 0.15 g, pH 2.0, 90 min contact time and 50 mgL−1initial concentrations. Non-linear regression analysis shows that Freundlich isotherm is considers as a suitable model for mitigation of Cr (VI) with Qmax of 73.29 mg/g for 50 mgL−1 Cr (VI) concentration. Pseudo second order kinetics model is considered as a best fitted model for the present investigation. Thermodynamic study shows that adsorption is spontaneous and endothermic in nature. The value of mean free energy (0.983 J/mol at 303 K) and activation energy (7.96 kJmol−1 at 303 K) shows that adsorption of Cr (VI) on PANI@IOMW occurs through physisorption. Surface study of PANI@IOMW was done using FESEM, EDX, FTIR, XRD, XRF, XPS, HR-TEM and AFM analysis. The comparison of % efficiency of Cr (VI) removal obtained by response surface methodology (RSM) (99.06%) and experimental studies under the optimum conditions (99%) suggested that quadratic model is suitable model for Cr (VI) adsorption. The adsorbent PANI@IOMW shows regeneration ability up to two cycles without losing its properties. Thus PANI@IOMW adsorbent can be used for treatment of water containing Cr (VI) as good alternative as compared to chemical adsorbents used by the industries. © 2022 Institution of Chemical Engineers",TextMining
"The potential benefits of incorporating biotic, as well as abiotic, predictors in niche and species distribution models (SDMs), as well as how to achieve this, is still debated, with their interpretability and explanatory potential being particularly questioned. It is therefore important to stress test modelling methodologies that include biotic factors against use cases where there is ample knowledge of the potential biotic component of the niche. Relatively well studied and important vector-borne diseases offer just such an opportunity, where knowledge of the agents involved in the transmission cycle –vectors and hosts– can serve to calibrate and test the niche model and corresponding SDM. Here, we study the contributions of biotic –14 vectors, 459 potential hosts– and abiotic –258 climatic categories– predictors to the explanatory and predictive features of the niche and corresponding SDM for the etiological agent of Chagas disease, Trypanosoma cruzi, in Mexico. Using an established spatial data mining technique, we generate biotic, abiotic and biotic+abiotic niche and SDM models. We test our models by comparing predictions of the most important probable hosts of Chagas disease with a previously published list of confirmed hosts. We quantify, compare, and contrast the individual and total contributions of predictors to the niche and distribution of Chagas disease in Mexico. We assess the relative predictive potential of these variables to model performance, showing that models that include relevant biotic niche variables lead to more predictive, more ecologically realistic SDMs. Our research illustrates a useful general procedure for identifying and ranking potential biotic interactions and for assessing the relative importance of biotic and abiotic predictors. We conclude that the inclusion of both abiotic and biotic predictors in SDMs not only provides more predictive and accurate models but also models that are more understandable and explainable from an ecological niche perspective. © 2022",TextMining
"Objective: The rapid growth of medical data has greatly promoted the wide exploitation of machine learning for paramedical diagnosis. Inversely proportional to their performance, most machine learning models generally suffer from the lack of explainability, especially the local explainability of the model, that is, the case-specific explainability. Materials and Methods: In this paper, we proposed a GBDT (Gradient Boosting Decision Tree)-based explainable model for case-specific paramedical diagnostics, and mainly make the following contributions: (1) an adaptive gradient boosting decision tree (AdaGBDT) model is proposed to boost the path-mining for decision effectively; (2) to learn a case-specific feature importance embedding for a specific patient, the bi-side mutual information is applied to characterize the backtracking on the decision path; (3) through the collaborative decision-making by globally explainable AdaGBDT with case-based reasoning (CBR) in the case-specific metric space, some hard cases can be identified by the means of visualized interpretation. The performance of our model is evaluated on the Wisconsin diagnostic breast cancer dataset and the UCI heart disease dataset. Results: Experiments conducted on two datasets show that our AdaGBDT achieves the best performance, with the F1-value of 0.9647 and 0.8405 respectively. Moreover, a series of experimental analyses and case studies further illustrate the excellent performance of feature importance embedding. Conclusion: The proposed case-specific explainable paramedical diagnosis via AdaGBDT has excellent predictive performance, with both promising case-level and consistent global explainability. © 2022 Elsevier Ltd",TextMining
"Modeling and predicting air pollution concentrations is important to provide early warnings about harmful atmospheric substances. However, uncertainty in the dynamic process and limited information about chemical constituents and emissions sources make air-quality predictions very difficult. This study proposed a novel deep-learning method to extract high levels of abstraction in data and capture spatiotemporal features at hourly and daily time intervals in NEOM City, Saudi Arabia. The proposed method integrated a residual network (ResNet) with the convolutional long short-term memory (ConvLSTM). The ConvLSTM method was boosted by a ResNet model for deeply extracting the spatial features from meteorological and pollutant data and thereby mitigating the loss of feature information. Then, health risk assessment was put forward to evaluate PM10 and PM2.5 risk sensitivity in five districts in NEOM City. Results revealed that the proposed method with effective feature extraction could greatly optimize the accuracy of spatiotemporal air quality forecasts compared to existing state-of-the-art models. For the next hour prediction tasks, the PM10 and PM2.5 of MASE were 9.13 and 13.57, respectively. The proposed method provides an effective solution to improve the prediction of air-pollution concentrations while being portable to other regions around the world. © 2022 Elsevier Ltd",TextMining
"Inadequate experts in managing resources at the lower level of education to enhance effective teaching and learning for quality education is a significant challenge in developing nations. Many basic schools lack basic educational resources such as sitting places and writing places for learners. Inadequate teaching and learning resources negatively affect the educational policies in a country. It is common to see the media projecting the challenges of a school lacking these resources. The use of an Expert System (ES) in Artificial Intelligence (AI) to assist in effective management is a necessity. In this paper, an agile neural expert system is proposed using differential equations with an initial value problem. The technique combines both rule-based and neural networks in handling the problem. The expertise of the Human Expert (HE) is used in a knowledge-based to assist in managing the resources in schools. This has been possible with the use of Data Mining (DM) techniques and modeling of projected population growth, affecting enrolment in schools and necessitating the provision of resources to cater to the growing population. For efficiency and effectiveness in planning, provision, and management of the resources, smart notification has been embedded in the system to monitor the availability and provision of the resources by prompting the various actors in the requisition, verification, validation, and approval of resources to be supplied to schools. The system proves a higher efficiency demonstrating speed in decision-making, accuracy in decisions and ease to use. © 2023 The Author(s)",TextMining
"Objectives: Bone tuberculosis (TB) is the third most common types of extrapulmonary tuberculosis. It is critical to understand mycobacterial adaptive strategies within bone lesions to identify mycobacterial factors that may have role in disease pathogenesis. Methods: Whole genome microarray was used to characterize the in-vivo transcriptome of Mycobacterium tuberculosis (M.tb) within bone TB specimens. Mycobacterial virulent proteins were identified by bioinformatic software. An in vitro osteoblast cell line model was used to study the role of these proteins in bone TB pathogenesis. Results: 914 mycobacterial genes were significantly overexpressed and 1688 were repressed in bone TB specimens. Pathway analysis of differentially expressed genes demonstrated a non-replicative and hypometabolic state of M.tb, reinforcement of the mycobacterial cell wall and induction of DNA damage repair responses, suggesting possible survival strategies of M.tb within bone. Bioinformatics mining of microarray data led to identification of five virulence proteins. The genes encoding these proteins were also upregulated in the in vitro MC3T3 osteoblast cell line model of bone TB. Further, exposure of osteoblast cells to two of these virulence proteins (Rv1046c and Rv3663c) significantly inhibited osteoblast differentiation. Conclusion: M.tb alters its transcriptome to establish infection in bone by upregulating certain virulence genes which play a key role in disturbing bone homeostasis. © 2022 The British Infection Association",TextMining
"Wetlands are transitional zones between terrestrial and aquatic ecosystems. They have the potential to continuously provide human beings with food, raw materials, and other substances. Also, wetland landscape pattern changes have profound impacts on the climate of plateau areas and accelerate the rate of climate change, so it is crucial to extract long time series of plateau wetland information. Concurrent with large-scale urbanization, industrial development and construction, and rapid population increases, the lakeside wetlands in the Dianchi Lake Basin are changing rapidly. However, scholars have not yet extracted long time series wetland information for this area, so the long-term evolution of these wetlands cannot be clarified. In this study, we used the Google Earth Engine (GEE) platform to extract wetland information for the Dianchi Basin from 1988 to 2020 from Landsat data and generated 33 wetland maps by applying a random forest classification model to identify trends and a confusion matrix to assess accuracy. The results showed that the overall trend of wetland area from 1988 to 2020 showed an increasing area, and the total wetland area increased by 31.11 km2 (+9.67 %). Furthermore, the overall accuracy of most years exceeded 80 %, the QADI was no higher than 0.2, the user accuracy and producer accuracy were higher than 80 % and 70 %, respectively, for swamps and water bodies, and the remaining non-wetland categories also achieved robust classification accuracy. Thus, the results of this study can compensate for the lack of information on wetland changes in the region over the past 33 years and provide data support and a scientific basis for sustainable wetland development in the plateau. © 2022 The Author(s)",TextMining
"Accurately predicting the 3D in situ stress field is critical in coal mining. We have proposed a workflow that is based on 3D seismic attributes to predict the in situ stress field of a coal mine located in Sijiazhuang, Shanxi, China. First, we interpreted the faults and folds within our study area. Then, we determine the directions and types of in situ stress by analyzing the interpreted faults and folds. Under the assumption that the process of strata deformation can be simulated by a thin-plate theory, we deduce the equations to compute in situ stress as a function of seismic curvature attribute and elastic parameters inverted from seismic data. We also proposed a stability factor that is based on the computed stress field. The results find that the in situ stress field within our study area is dominated by the compression stress along the northwest-southeast direction. Based on the proposed stability coefficient, we further predicted the zones that have abnormal rock mass stability. © 2023 Society of Exploration Geophysicists and American Association of Petroleum Geologists.",TextMining
"The propagation of antibiotic resistance genes (ARGs) in freshwater reservoirs threatens ecosystem security and human health, and has attracted increasing attention. A series of recent research articles on ARGs provides a unique opportunity for data-driven discoveries in this emerging field. Here, we mined data from a total of 290 samples from 60 reservoirs worldwide with a data-driven framework (DD) developed to discover geographical distribution, influencing factors and pollution hotspots of ARGs in freshwater reservoirs. Most data came from Asia and Europe where nine classes of ARGs were most frequently detected in reservoirs with multi-drug resistance and sulfonamide resistance genes prevailing. Factors driving distribution of reservoir ARGs differed between reservoir waters and sediments, and interactions among these factors had linear or nonlinear enhancement effects on the explanatory power of ARG distribution. During the cold season, small-sized reservoir waters rich in organic carbon, mobile genetic elements (MGEs) and antibiotics had a higher pollution potential of ARGs; during the spring drought, sediments in large reservoirs located in densely populated areas were more conducive to dissemination of ARGs due to their richness in antibiotics and MGEs. Thus, distribution pattern of ARG pollution hotspots in reservoir waters and sediments varies greatly depending on the differences of internal and external factors. From the “One Health” perspective, this widespread contamination of freshwater reservoirs by ARGs we discovered through the DD framework should be a push to promote integrated research across regions and disciplines. Especially the human - food-chain - ecosystem interface needs an improved understanding of ARG contamination mechanisms and targeted monitoring and evaluation systems should be developed to maintain all ecosystem services in freshwater reservoirs as well as to safeguard human health. © 2022 Elsevier Ltd",TextMining
"In the course of mining activities, large amounts of data are collected by multiple scientific disciplines. Software to assist mining engineers in planning and decision-making is, however, absent; the software used in the mining industry is not capable of a holistic approach, and therefore does not function as a data integration interface. What is required to fill this gap/to resolve this issue is an application that is platform-independent, integrates multiple types of data and does not require GIS knowledge. In this paper, a webGIS application, MaGISter-mine, is presented that can solve the problems arising during mining activities. MaGISter-mine was created as a data integrating surface that makes querying and measuring geographical data easy. The MaGISter-mine application is able to handle photogrammetry models and laser-scanned point clouds, while distance, area and volume can also be easily calculated. The software can draw 2D profiles from 3D files. Time- and space-dependent changes between two surveys can be analysed, too. Geological strata can be edited, and new surfaces can be generated by kriging interpolation. During the development of the webGIS application, mostly open-source software and libraries were used. The spatial database consists of the PostgreSQL relational database management system and its extension, called PostGIS. To perfect accessibility on the client side, GeoServer with Apache Tomcat and Apache webserver were employed. The webGIS application was developed using OpenLayers, three.js and Potree, written in PHP, SQL, HTML, CSS and JavaScript languages. © 2022 The Authors",TextMining
"The sudden change in online group opinion under the attack of external stimulus is what managers of any social organization should strive to avoid. To predict the sudden change in online group opinion, the evolution of online group opinion is considered as a complex system. The resilience index, which measures the accumulated pressure of this complex system, is developed as an indicator to predict the sudden change in group opinion. The employees’ opinion of Dada, a crowdsourcing logistics platform in China, is taken as an example. Text data of group opinion are treated. The methods of fitting the catastrophe model and building the resilience index model for group opinion of Dada forum are demonstrated. Verification is performed. The method of searching thresholds of the resilience index is designed, and two thresholds are obtained. The factors that influence the thresholds are investigated. The proposed resilience index and its modeling method have contributions to researches on online group opinion as well as complex systems, and have practical implications for business enterprises in face of customer group opinion in marketing and governments confronted with public group opinion. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TextMining
"Nowadays Earth observation satellites provide forest fire authorities and resource managers with spatial and comprehensive information for fire stabilization and recovery. Burn severity mapping is typically performed by classifying bi-temporal indices (e.g., dNBR, and RdNBR) using thresholds derived from parametric models incorporating field-based measurements. Analysts are currently expending considerable manual effort using prior knowledge and visual inspection to determine burn severity thresholds. In this study, we aim to employ highly automated approaches to provide spatially explicit damage level estimates. We first reorganize a large-scale Landsat-based bi-temporal burn severity assessment dataset (Landsat-BSA) by visual data cleaning based on annotated MTBS data (approximately 1000 major fire events in the United States). Then we apply state-of-the-art deep learning (DL) based methods to map burn severity based on the Landsat-BSA dataset. Experimental results emphasize that multi-class semantic segmentation algorithms can approximate the threshold-based techniques used extensively for burn severity classification. UNet-like models outperform other region-based CNN and Transformer-based models and achieve accurate pixel-wise classification results. Combined with the online hard example mining algorithm to reduce class imbalance issue, Attention UNet achieves the highest mIoU (0.78) and the highest Kappa coefficient close to 0.90. The bi-temporal inputs with ancillary spectral indices work much better than the uni-temporal multispectral inputs. The restructured dataset will be publicly available and create opportunities for further advances in remote sensing and wildfire communities. © 2022",TextMining
"A frame differencing pixel (FDP) design based on fully depleted silicon-on-insulator (FD-SOI) technology is presented, demonstrating the capability of the FDP to perform pixel-level real-time frame difference (FD) for motion extraction and image preprocessing. The photo charges are collected by the diode under the buried oxide (BOX) and sensed by the MOSFET above. The capacitance of the BOX is used to generate the FD signal without incurring more area costs. TCAD simulations of the FD-SOI FDP were performed to help the analysis. An optimal pixel design model was developed to describe the relationship between noise performance and area allocation. According to the simulation results, the FDP could achieve light sensitivity of 25.6 μA/(μJ/cm2) and a differential signal-to-noise ratio of 35 dB with a 4 μm pixel pitch and 76% fill factor.  © 1963-2012 IEEE.",TextMining
"Social network users scatter geographically, where each maintains a self-centered star graph (i.e., relationships directed related to them). Clustering on such subgraphs can provide valuable insights into the graph structure. Despite its significance, one could not simply collect the unfettered star graph information from users due to privacy concerns. Local differential privacy (LDP), as an emerging privacy model, has been widely adopted in privacy-preserving data collection and analysis. Most existing LDP-based graph analysis methods encode star graphs via adjacency bit vector and suffer from heavy noise due to the sparsity of social networks. Besides, they cluster all nodes indifferently yet ignore that nodes with different degrees are affected differently by noise injection, making the clustering results unsatisfactory. To tackle these issues, we propose Wdt-SCAN, a degree vector based private graph clustering scheme to achieve high quality clustering without compromising individual privacy. Concretely, we design a degree vector encoding model with optimal length to represent star graphs, which reduces the massive noise caused by sparsity. To improve the clustering accuracy, a two-round agglomeration-based decentralized graph clustering method is proposed, which partitions nodes into core nodes and ordinary nodes, and then clusters core nodes to form a graph skeleton as prior knowledge to alleviate the impact of noise injection on ordinary nodes. Theoretical analysis and experiments on real-world datasets show that our proposed method can obtain desirable clustering result while satisfying edge LDP. © 2022 Elsevier Ltd",TextMining
"Deep-sea mining riser continuously suffer from internal Solid-liquid two-phase fluid abrasion and external wind-wave-current coupling load during operation, and structure damage gradually accumulates. Because of high slenderness ratio and flexibility, it is difficult to identify modal parameters, and the damage sensitivity of single measuring point response is low when applying traditional damage detection method to deep-sea mining riser. To solve the problems, a data fusion and one dimension residual convolutional auto-encoder (1D-RCAE) based method is proposed for deep-sea mining riser damage identification. Firstly, PCA is used to fuse bending strain responses from multiple measuring points into one variable. Then, the 1D-RCAE is used to extract the damage sensitive feature (DSF) from the fused variable. Lastly, the Mahalanobis distance between the extracted DSF under the currently testing and the baseline conditions is selected as the damage index. The damage detection effectiveness is verified on a 500m numerical model and a laboratory model of deep-sea mining riser, and the result shows that the accuracy of damage identification is higher than 98%. At the same time, the effects of noise pollution and changing marine environment is explored. © 2023 Chinese Vibration Engineering Society. All rights reserved.",TextMining
"The energy-absorbing bolt is an advanced reinforcing element in rock mass to absorb the deformation energy. In this paper, the time-dependent reinforcement provided by the energy-absorbing bolt was analyzed based on assumptions of the reinforced rock unit (RRU) model for systematic bolting. The energy-absorbing bolt was simulated with an ideal elastic–plastic material law. The rheological behavior of the energy-absorbing bolt was represented by the connection of a Hookean elastic element and a Saint Venant element in series. The constitute model and creep behavior of the RRU under a sudden stress change were obtained by assuming the rock was a general Kelvin material. It showed the RRU exhibited an instantaneous jump in the strain, transient creep, and steady-state creep under a sudden change of external stress. The resulting stress in the rock decreased progressively as that in the energy-absorbing bolt could sustain the loading as large as its designed yielded stress. The constitutive models of RRU were applied to predict the convergences of surrounding rock mass in a mining roadway, in Anhui province, China. Good agreements were achieved between the analytical solutions and the field-monitored data. © 2022 Elsevier Ltd",TextMining
"Web servers store every event in the form of logs, which contain the retrieved URL, client IP address, access time, HTTP status code, etc. There are several useful methods to analyze these log files, which are mainly based on sequential text mining techniques for applications like prefetching or driving critical information about system's security. Finding ways to convert web server log files into graph structures may open new horizons in complex network analysis for investigation, comparison, and prediction. Since visibility graph has various successful usages for analyzing different time series data, web server log files as a kind of time-series data have the potential to be converted into visibility graph. In this research, we propose a novel method to convert web server log files into horizontal visibility graphs. Afterward, we demonstrate the result of the method on two popular datasets, NASA and Online Judge web server log files, and perform exploratory and visibility graph analysis techniques like centrality measures computation and community detection to show the promising future for the research. Moreover, we introduce a novel algorithm for a common application in web server log file analysis, web prefetching, based on a modified version of link prediction on the extracted visibility graph, and evaluate it based on AUC assessment and propose the next page to prefetch in each dataset. Finally, we propose several choices to extend the research in case of technical and practical aspects. © 2023 Elsevier B.V.",TextMining
"Distributed denial of service attacks are common and very severe threat to various computing technology like Cloud, IoT and Blockchain because of the disruption they cause to the services that are provided. Many different types of DDoS attacks are there, each with a unique action, making it difficult for network monitoring and control systems to identify and prevent them. The objective of this research work is to explore and select a set of data to represent DDoS attack events and attack traffic information. A pre-processing phase is used to clean and transform the data, and afterwards the generation of a model of machine learning for multi-class classification is done. This is carried out to identify the various classification of different types of DDoS attacks. We have used CIC dataset for the experiment which contains all types of DDoS attack and huge in number of records. Random Forest, Support Vector Machine, Naive Bayes, Decision Tree, XGBoost, and AdaBoost are six different types of machine learning algorithms employed in this research. FRom the results, AdaBoost achieves the best accuracy of 99.87% in 27.4 s of computation time. Naive Bayes has the fastest computing time (3.2 s) with 94.15% accuracy, where as Support Vector Machine has the slowest time, a lazy learner (229m26s for training and 0.2 s for prediction) and has the low accuracy (95.73%). © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"The anthropogenic impact on the aquatic environment of the Raša River (Croatia) was investigated through the analysis of seven polybrominated diphenyl ethers (PBDEs), seven polychlorinated biphenyls (PCBs), three DDT isomers, and 22 major and trace elements using yellow European eel (Anguilla anguilla L.) as a biological indicator of contamination. The obtained data indicated generally low contamination status in the surrounding area. Levels of all organic contaminants in muscle significantly increased with lipid content, length, weight and body condition. In both muscle and liver, most metal(loid)s decreased or remained unchanged with increasing size, while at downstream location only several elements (Cd, Cu, Fe, Na, Se, U, V, Zn) accumulated in the liver with fish growth. Spatial analysis revealed higher pressure of Ag, Cd, Cr, Mo, Tl, U, and V at the downstream location, revealing the potentially limited impact of historical coal mining industry on the lower reaches of the Raša River. © 2022 Elsevier Ltd",TextMining
"Partition the sample space to the user requirement is an easy and efficient cluster method in many applications. Kmeans is one of the simple and efficient partition algorithms used in many cluster solutions. We suggest Multivariant Silhouette method to predict the cluster count value for Kmeans algorithm. The work proposes three new algorithms for initial seed selection. The Kmeans algorithm is modified using statistical measure Mean, Median, Partition centre for the cluster centroid calculation. In conventional Kmeans algorithm, the samples are compared with all the partition centroids to decide the inclusion of a sample in a cluster. In Kmeans9+ algorithm, the samples are compared only with the centroids of current and eight nearest neighbouring cluster partitions. It reduces the needless comparisons of samples with cluster centroids and improve the efficiency of the algorithm. The performance of created algorithms is evaluated using data from UCI and KBPE SSLC. Cluster efficiency analysis is done using the cluster evaluation indices such as Silhouette and Dunn Index. Nine nearest neighbour uniform partition cluster model Kmeans9+ improve the performance of the K means algorithm and obtain the natural cluster results with minimum iterations. © 2023",TextMining
"Understanding the composition and reactivity of dissolved organic matter (DOM) at molecular level is vital for deciphering potential regulators or indicators relating to anaerobic process performance, though it was hardly achieved by traditional analyses. Here, the DOM composition, molecular reactivity and transformation in the enhanced sludge fermentation process were comprehensively elucidated using high-resolution mass spectrometry measurement, and data mining with machine learning and paired mass distance (PMD)-based reactomics. In the fermentation process for dewatered sludge, persulfate (PDS) pretreatment presented its highest performance in improving volatile fatty acids (VFAs) production with the increase from 2,711 mg/L to 3,869 mg/L, whereas its activation in the presence of Fe (as well as the hybrid of Fe and activated carbon) led to the decreased VFAs production performance. In addition to the conventional view of improved decomposition and solubilization of N-containing structures from sludge under the sole PDS pretreatment, the improved VFAs production was associated with the alternation of DOM molecular compositions such as humification generating molecules with high O/C, N/C, S/C and aromatic index (AImod). Machine learning was capable of predicting the DOM reactivity classes with 74–76 % accuracy and found that these molecular parameters in addition to nominal oxidation state of carbon (NOSC) were among the most important variables determining the generation or disappearance of bio-resistant molecules in the PDS pretreatment. The constructed PMD-based network suggested that highly connected molecular network with long path length and high diameter was in favor of VFAs production. Especially, -NH related transformation was found to be active under the enhanced fermentation process. Moreover, network topology analysis revealed that CHONS compounds (e.g., C13H27O8N1S1) can be the keystone molecules, suggesting that the presence of sulfur related molecules (e.g., cysteine-like compounds) should be paid more attention as potential regulators or indicators for controlling sludge fermentation performance. This study also proposed the non-targeted DOM molecular analysis and downstream data mining for extending our understanding of DOM transformation at molecular level. © 2022 Elsevier Ltd",TextMining
"It is critical in cloud computing to have excellent data accessibility and system performance. To improve system availability, commonly used data should be duplicated to many places, allowing users to access it from a nearby site. Deciding on a sensible number and location for replicas is a difficult problem in cloud computing. Therefore, a novel Data Replication system based on data mining techniques is being proposed in this research work. The data replication is done here by locating commonly utilized data patterns in a node's massive database. This will be accomplished using an optimization-assisted frequent pattern mining approach, with a novel hybrid algorithm performing the best threshold selection. The proposed hybrid algorithm referred to as Greywolves Updated Exploration and Exploitation with Sealion Behaviour (GUEES), hybrids the concept of Sealion Optimization Model (SLnO) and Grey wolf optimization (GWO) algorithms. Apart from this, the mining will be carried out under the defining dual constraints such as (i) Prioritization and (ii) Cost. The prioritization falls under two cases: queuing both high and low-priority data, and the cost relies on the evaluation of storage demand. The high-priority queues are optimized with the GUEES model. Finally, a comparative validation is carried out to validate the efficiency of the adopted model. Accordingly, when the number of requests=1000, the network usage of the proposed model is 35.07%, 34.9%, 30.5%, 29.23%, 24.57%, 16.8%, and 16.85% higher than the existing methods like SMO, LA, ROA, GWO, SLnO, PSO, HCS, respectively. © 2022",TextMining
"As the principal means of oil and natural gas transportation, oil and gas pipeline systems suffer from common corrosion problems, accurate corrosion prediction of oil and gas pipelines has an essential influence on pipe material selection, remaining useful life prediction, maintenance planning, etc. At present, a large number of corrosion monitoring techniques are applied in oil and gas pipeline systems. The monitored data have the characteristics of multidimensional quantities, noise interference, non-linearity, etc. Machine learning can effectively solve the limitations of relying solely on mathematical models to achieve intelligent corrosion prediction and improve the corrosion control effect. Considering the corrosion prediction problems in oil and gas pipeline systems, the application of machine learning methods in corrosion rate prediction, oil and gas pipeline leakage and defect assessment, and corrosion image recognition were focused on in this paper. By constructing the application framework of machine learning in the field of oil and gas pipeline corrosion prediction, the necessity of data preprocessing and feature correlation analysis are indicated in this paper. Furthermore, random forest and deep learning have extensive application prospects in this field. Finally, the application prospects of machine learning were discussed. © 2022 Elsevier Ltd",TextMining
"This paper deals with the numerical simulation of rock cutting laboratory tests using the discrete element method. The main objective is to provide a method for calibrating numerical DEM models of rock cutting in a systematic way so that realistic results are yielded. The numerical models are developed with the discrete element code Yade, which models rocks as a collection of bonded spheres. The models are calibrated in a four-step process based on the design of experiments method and optimization. The calibrated models are evaluated both quantitatively and qualitatively against actual laboratory cutting tests, in terms of the ratio of the simulated mean cutting force to the actual one and the cutting force time series, respectively. The fully calibrated models showed that the simulated cutting process matched qualitatively the actual cutting force recordings and underestimated the mean cutting force by approximately 3%. It is concluded that well-calibrated numerical simulations of the rock cutting process can provide not only a better understanding of the process itself but also quantitative data regarding the cutting force and energy requirements. © 2022, Society for Mining, Metallurgy & Exploration Inc.",TextMining
"This study developed a noncontact deflection monitoring technique using terrestrial laser scanner (TLS) and images for faster, safer, and efficient 2D/3D bridge deflection measurements. The technique was applied to assess the serviceability performance of two timber trestle railroad bridges located in Florida and validated based on bridge deflections from deflectometers. A key challenge includes extracting control points that are visible both in images and TLS data due to different modalities of the data. Hence, this study presents a method of extracting linear features from both images and TLS data. The camera pose was derived from images and TLS data by using a linear feature-based registration algorithm. The deformations in the structure were then detected by measuring the points of interest for different loads. There are several unique contributions of the study. First, there is no requirement for the use of targets which improves the safety of bridge engineers. Second, it is a relatively cost-effective technique for obtaining bridge deflections due to moving train loads, as the use of a laser scanner as part of the noncontact technique is only once in a lifetime for a given bridge. Alternatively, total stations can also be used to capture linear features. Finally, this technique produced accurate deflection measurements using a linear feature-based registration technique. This study found that the noncontact deflection monitoring technique agrees well with actual deformations observed from deflectometers.  © 2022 American Society of Civil Engineers.",TextMining
"Principal calcium sulphate rocks, such as gypsum and anhydrite, originate from evaporitic processes. Gypsum is considered an industrial raw material with high economic value, but anhydrite has no economic interest. Therefore, delineating the interface between sedimentary cover and gypsum, and differentiating gypsum from anhydrite has significant importance in the production planning of open pits. An electrical resistivity tomography study was carried out in the Bala gypsum formation (Central Anatolia, Turkey) to map the gypsum–anhydrite interface. Because open-pit mining is economical up to a certain depth due to the cost of excavation, delineation of the upper boundary of gypsum is also necessary. As the survey's primary purpose is to delineate the interfaces of the sedimentary cover–gypsum and gypsum–anhydrite layers in shallow depths (50 m), a structure-based model search scheme that includes a sequential use of global and local search methods has been applied for the derivation of the subsurface resistivity model. The conventional cell-based conceptual model using the damped least-squares inversion method is also used for comparison purposes. The strong resistivity contrast leads to an easy identification of cover and gypsum for both conceptual models. However, only the structure-based conceptual model delineates the interface between gypsum and anhydrite. The estimated interfaces derived from the structure-based model are consistent with the borehole data. This case history for gypsum investigation indicates the value of selecting an appropriate conceptual model for a specific exploration problem. © 2022 European Association of Geoscientists & Engineers.",TextMining
"The accurate measurement of the temperature of coal spontaneous combustion is a key technology for coal spontaneous combustion and fire prevention and is important to realising safe coal mining and reducing energy losses. A soft sensor model based on a hybrid-kernel-function support vector machine with an improved genetic algorithm is proposed for the nonlinear relationship between the concentration of a characteristic gas of coal spontaneous combustion and the temperature of the coal body. The natural oxidation process of the coal body is simulated using a coal-spontaneous-combustion oxidation warming experiment bench. The gas concentration and maximum temperature of the coal body at different moments in an oxidation warming experiment are taken as the model input data. Various soft sensor models are automatically optimised by a genetic algorithm in the training process, and the performances of the models are compared and evaluated in the field. The results show that the evaluation indexes of the hybrid-kernel-function model are better than those of the single-kernel function. In the training process, the evaluation indexes of the model with hyperparameters automatically optimised by the genetic algorithm are better than those other models, further verifying the nonlinear relationship between the gas concentration and coal temperature in the process of coal spontaneous combustion and oxidation. The use of the improved support vector machine model basically results in no deviation between the soft sensor results and actual temperature data in the field test, indicating that the soft sensor model has high accuracy, generalisation ability and applicability. The improved support vector machine model has a mean absolute percentage error of ≤ 1.616%, mean absolute error of ≤ 0.533 ℃, and root-mean-square error of ≤ 0.608 ℃. These results indicate that the soft sensor problem of coal spontaneous combustion can be considered a typical small-sample regression method. The proposed method can be further applied to similar problems in the energy industry. © 2023 The Institution of Chemical Engineers",TextMining
"Wastewater from industrial process of uranium ore mining contains a large amount of this radioactive pollutant. Regarding the advantages of biosorption, it was found that varieties of biomasses such as agricultural waste, algae and fungi are effective for uranium removal. However, there is limited research on cyanobacteria, therefore, cyanobacteria, Anagnostidinema amphibium (CAA) was investigated by batch method for the first time for biosorption of uranium (VI). Optimization of biosorption parameters showed that maximum removal efficiency of 92.91% was reached at pH range of 9–11 with 50 mg of cyanobacteria to 100 mg/L U(VI) initial concentration, at 25 °C within 40 min. Used biosorbent exhibited very good selectivity for U(VI) ions and reusability in IV sorption/desorption cycles. Characterization of CAA surface was performed by FTIR, EDS, EDXRF and SEM analysis and it has shown various functional groups (CONH, COOH, OH, PO alkyl group) and that it is very rich in elements such as iron, potassium and calcium. In binary systems, contained of U(VI) and selected ions, CAA exhibits very good selectivity towards U(VI) ions. Kinetic data revealed the best accordance of experimental data with the pseudo-second-order model and isotherms data agreed with Freundlich model. Thermodynamic data implied that U(VI) biosorption process by A. amphibium exhibited spontaneity and modelling of the investigated process showed that the adsorption of uranium ions occurs mainly via peptidoglycan carboxyl groups. Overall results show that these cyanobacteria with a maximum sorption capacity of 324.94 mg/g have great potential for the processing of wastewater polluted with uranium (VI). © 2022 The Authors",TextMining
"The number of biomedical articles published is increasing rapidly over the years. Currently there are about 30 million articles in PubMed and over 25 million mentions in Medline. Among these fundamentals, Biomedical Named Entity Recognition (BioNER) and Biomedical Relation Extraction (BioRE) are the most essential in analysing the literature. In the biomedical domain, Knowledge Graph is used to visualize the relationships between various entities such as proteins, chemicals and diseases. Scientific publications have increased dramatically as a result of the search for treatments and potential cures for the new Coronavirus, but efficiently analysing, integrating, and utilising related sources of information remains a difficulty. In order to effectively combat the disease during pandemics like COVID-19, literature must be used quickly and effectively. In this paper, we introduced a fully automated framework consists of BERT-BiLSTM, Knowledge graph, and Representation Learning model to extract the top diseases, chemicals, and proteins related to COVID-19 from the literature. The proposed framework uses Named Entity Recognition models for disease recognition, chemical recognition, and protein recognition. Then the system uses the Chemical - Disease Relation Extraction and Chemical - Protein Relation Extraction models. And the system extracts the entities and relations from the CORD-19 dataset using the models. The system then creates a Knowledge Graph for the extracted relations and entities. The system performs Representation Learning on this KG to get the embeddings of all entities and get the top related diseases, chemicals, and proteins with respect to COVID-19. © 2023 Elsevier Ltd",TextMining
"Coalbed methane (CBM) disasters are a major safety problem in coal mining. CBM concentration prediction and early-warning technology play a vital role in the prevention and control of CBM disasters. Traditional prediction methods have some shortcomings such as unreasonable data analysis, inability to predict in real time, long prediction time, and overfitting. This study uses a large amount of coal mine CBM data and develops a fast and high-precision CBM concentration prediction method based on deep learning theory, which can be used for CBM disaster early-warning. The proposed method has the following advantages: (1) it combines three exponential smoothing methods, the autoregressive model, wavelet domain denoising method, and principal component analysis. This method optimizes data with outliers, missing values, and noise. (2) Particle swarm optimization and genetic algorithm are used to optimize the network parameters of the gated recurrent unit. The application and verification of the optimized model show that the running time and accuracy are significantly improved. (3) By combining the optimized prediction model with Spark streaming, an early-warning system is developed, which can complete the efficient early-warning of CBM concentration within 8 s. The proposed method provides decision-making support for mine safety and CBM disaster prevention and control. © 2022 Elsevier Ltd",TextMining
"The screening of genomic variations within the male-specific region of the mammalian Y chromosome (MSY) is one of the most effective ways to investigate paternal evolutionary history and identify molecular markers related to male fertility. The current study was to identify single nucleotide polymorphisms (SNPs) within single-copy genes of the ovine MSY, and confirm whether they are associated with testicular size. A total of 21 Y-specific gene fragments were successfully amplified to screen Y-SNPs in 956 rams across nine sheep breeds. Three Y-SNPs, including SRY16: g.88 A > G in South African Mutton Merino sheep, ZFY16: g.146 C > T in Suffolk and South African Mutton Merino sheep, and EIF2S3Y2: g.77 C > G in Hu and Tan sheep, were identified using DNA-pooled sequencing and PCR restriction fragment length polymorphism (PCR-RFLP) methods. The investigation of the global distribution for three Y-SNPs showed that the C allele of ZFY16: g.146 C > T co-segregated with haplogroup y-HC, and the C/G allele of EIF2S3Y2: g.77 C > G co-segregated with haplogroup y-HA/y-HB1 in Hu sheep according to data mining from a previous study. In addition, association analysis revealed that ZFY16: g.146 C > T had a significant effect on yearling scrotal circumference in Suffolk sheep, and EIF2S3Y2: g.77 C > G was significantly associated with testicular and epididymis weight in Hu sheep (P ≤ 0.05). The current study concluded that Y-SNPs were associated with testicular size in specific sheep, which provides valuable candidate makers for selecting elite rams at an early age. © 2022",TextMining
"Salt cavern solution mining is a complicated process of fluid dynamics and chemical dynamics, including salt boundary dissolution, cavern expansion, brine flow, and species transport. The reaction processes occur simultaneously and interact with each other. In this study, a multiphysical coupled model is established to evaluate the realtime three-dimensional salt cavern shape expansion, the velocity field, and the brine concentration distribution. Then, the predicted results are compared with the field data of a Jintan Gas Storage Well in China. The average relative deviations with the turbulent flow are 5.7% for outlet brine concentration and 4.0% for cavern volume. The results show that salt cavern can be divided into four regions, including the shock region, plume region, reflow region, and suction region. The results also indicate that the turbulent flow will stimulate the formation of the vortex, thus affecting the distribution of brine concentration. And, the brine concentration distribution primarily influences cavern corrosion. The results suggest that adjusting the inject velocity and the tube position can change the cavern construction rate and the cavern shape. Overall, these results have guiding significance for the design and engineering practice of salt cavern construction for energy storage. © 2023 American Society of Mechanical Engineers (ASME). All rights reserved.",TextMining
"After completion, oil wells often require intervention services to increase productivity, correct oil flow losses, and solve mechanical failures. These interventions, known as workovers, are made using oil rigs, an expensive and scarce resource. The workover rig scheduling problem (WRSP) comprises deciding which wells demanding workovers will be attended to, which rigs will serve them, and when the operations must be performed, minimizing the rig fleet costs and the oil production loss associated with the workover delay. This study presents a data-driven optimization methodology for the WRSP using text mining and regression models to predict the duration of the workover activities and a mixed-integer linear programming model to obtain the solutions for the model. A sensitivity analysis is performed using simulation to measure the impact of the regression error in the solution. © 2022 The Author(s)",TextMining
"The Ossa-Morena Zone (OMZ, SW of the Iberian Peninsula) is a geotectonic domain that comprises a set of diversified ore deposits formed from Cambrian to Carboniferous-Permian ages. The Montemor-o-Novo – Ficalho Fe-Zn-(Pb) belt was a productive mining sector until the first half of the 20th century with potential for future mineral exploration, although the mechanisms responsible for ore deposition are, in some cases, poorly constrained. In this study the trace element composition of a large set of orebodies belonging to three iron deposits is examined, and the first δ18O analysis of magnetite from the Portuguese sector of OMZ is reported. Outcrop and drill core magnetite samples were collected from the Montemor-o-Novo Iron Complex (MIC), and from the Alvito and Azenhas-Orada deposits. New magnetite LA-ICP-MS data from the carbonate-hosted MIC deposits, classified as SEDEX-VMS, and from the Alvito and Azenhas-Orada skarn deposits are complemented by previously published data. This approach contributes to the classification of these deposits and provides new discriminatory proxies for skarn deposits worldwide. Close to 1000 LA-ICP-MS and EPMA magnetite spot analyses is explored, complemented by EPMA analysis of representative mineral phases from the host rocks. Three deposits from the MIC (Monges, Vale da Arca, and Serrinha) were studied, in which magnetite reveals a wide range of textures and trace element compositions. Using the Al + Mn vs Ti + V diagram the magnetite from the MIC is hardly discriminated from the magnetite data from the skarn deposits. Hence other discriminant factors have been used. Magnetite from the MIC is characterized by low contents of Co, Zn, and HFSE (e.g. Ta, Nb), and shows a close relation with low-temperature hydrothermal magnetite as revealed by the multivariate diagrams of trace elements. Skarn magnetite display high concentrations of temperature-dependent elements such as Ti, V, Al, Ga, Sn, Cr, and HSFE. Additionally, high contents of Co and Zn are ubiquitous for first generation magnetite from the skarn deposits, which might indicate that the ore source was enriched in such elements. Primary magnetite from the MIC deposits revealed δ18O signatures in the range 4.3 ‰ to 9.0 ‰ which, combined with magnetite trace element composition, suggests extensive overprinting of the primary signatures by late metamorphic events. Primary magnetite from the Azenhas-Orada deposits revealed δ18O signatures (4.0 ‰ – 5.6 ‰) suggesting a magmatic derived source for the mineralization, corroborating the hypothesis proposed in recent works. The δ18O signatures of magnetite from the Alvito skarn deposit indicate that extensive interactions between a magmatic fluid, with lighter 18O signatures, and the dolomite-calcite host rock, with heavier 18O signatures, have occurred. The results outline the potential of allying powerful multielement analysis of magnetite with stable isotope analysis and contribute to the refinement of geological models in the Ossa-Morena Zone that can be used in future mineral exploration. © 2022 Elsevier B.V.",TextMining
"Background: Helicobacter pylori is an infection of concern for its chronic colonization leading to peptic ulcers and gastric cancer. In recent times, microRNAs have been extensively studied to understand their role in the pathogenesis of this bacteria in diverse contexts of gastric diseases. The current analysis reports the microRNA-mRNA interactions that are associated with effective survival and virulence of this pathogen. Materials and Methods: We convened differentially regulated human microRNAs responsive to H. pylori infection (HP-hDEmiRs) at different multiplicity of infection and time points in human gastric cell lines through retrospective data mining of experimental studies. In view of the molecular disparity of clinical samples and animal models, data from tissue, serum/plasma, urine, and ascites were excluded. Further, we utilized diverse bioinformatics approaches to retrieve experimentally validated, high-confidence targets of the HP-hDEmiRs to analyze the microRNA-mRNA interactions that are relevant to H. pylori pathogenesis. Results: A total of 39 HP-hDEmiRs that showed unidirectional expression of either overexpression or downregulation were identified to modulate 23 targets explicitly studied under this infection. We also identified 476 experimentally validated targets regulated by at least 4 of the HP-hDEmiRs. In addition to the pathways prior-associated with H. pylori infection, the microRNA-mRNA interactome analysis identified several cellular processes and pathways highly associated with cell cycle, cell division, migration, and carcinogenesis. Conclusion: This study generated a platform to study the mechanisms utilized by this pathogen using microRNAs as surrogate. © 2022 John Wiley & Sons Ltd.",TextMining
"According to recent trends, food production must double by 2050 to meet the world's growing population's expected demand. To achieve this goal, agri-food companies have begun implementing different digital technologies to increase food production while utilising fewer resources, thus reducing production processes' environmental impact. This study aims to review Industry 4.0 and agri-food sustainability research published in the last decade. Text classification and data extraction machine learning techniques have been used to support the literature review process. Notably, text classification was used to support the screening phase of titles and abstracts, while data extraction was used to support the content analysis phase by identifying the main topics on which documents are focused. The descriptive analysis shows a summary of the leading scientific journals in the research field, as well as the most influential countries and the research topic evolution over time. The results of the study allowed us to identify ten main research clusters, providing in-depth discussions and perspectives on critical areas for future research avenues. Finally, this study provides significant implications for the agri-food industry, suggesting firms redesign their business models according to a logic that prioritises long-term, shared value creation over short-term efficiency, and profitability. Incorporating digital technologies may help control farming activities' impact on soil and air quality, minimising the use of natural resources, pollutants, and CO2 emissions, thus providing long-term economic, environmental, and social advantages. © 2022",TextMining
"Trust is an essential security component and plays a crucial role in building secure information processing systems. Many organizations have adopted zero-trust principles in their security mechanisms, especially in Cloud Computing environments, where everything is presumed to be semi-honest and untrustworthy until proven otherwise. This is in blunt contrast to the traditional perimeter-security model, where it is presumed that the malicious actors are always outside the perimeter of the trusted network, and trustworthy users are always inside the network. One of the most significant challenges with the notion of trust is that till now more focus was put on the subjective aspect of trust which was challenging to evaluate and verify. There is an urgent need to address the objective and verifiable notion of trust, especially in the systems involving Federated Learning as in Cloud environments. We propose a Rich model based zero-trust security framework for trust verification of SaaS and employ machine learning functionalities to perform multimedia data analytics over the service processing behaviors for improved visibility into service operations and risks. Our proposed model relies heavily on the features extracted form Federated learning on the data of different cloud service users that is subjected to AI processing. We utilized the Rich models for feature extraction of large scale multimedia data for monitoring cloud service behavior and employed Ensemble classifier for analyzing the data features and employed majority voting of individual learners for decision making. The experiments performed on the standard dataset proved that the proposed model successfully monitored and analyzed the behavior of cloud services for validating the legitimacy of trusted SaaS and detecting any trust violations. © 2022 Elsevier Ltd",TextMining
"Cyanide, which remains the preferred chemical used in the gold extraction process, has the potential to be disposed of on goldmine tailings. South Africa has nine goldfields, producing approximately a third of the world's gold to date. The cyanide interacts with metals in the tailings environment, where Prussian blue Fe43+[Fe2+(CN)6]3 and Turnbull's blue Fe32+[Fe3+(CN)6]2 are among these. In previous studies, Prussian blue or Turnbull's blue have been found as a blue substance in tailings material. PHREEQC modelling software was used adding the mineralogical data from 16 tailings samples from the Free State goldfield. The results revealed that Prussian blue prefers to precipitate in an oxic environment and Turnbull's blue prefers an anoxic environment. It was also determined that their precipitation is affected by the availability of iron in solution. As soon as all of the iron is consumed in solution, all excess cyanide produces HCN, which is a free cyanide which volatilizes. Contrarily, Prussian and Turnbull's blue are CNSAD compounds, only dissociating in extremely low pH condition in the absence of photolysis. Ultimately, these iron-cyanide compounds are able to immobilize cyanide, preventing seepage into environments such as the ground water. This along with an anoxic environment such as mine void, keeping the pH high, may be a possible solution for cyanide remediation. © 2022 Elsevier Ltd",TextMining
"In the business market, precision marketing of consumer products is beneficial to improve corporate profits. Based on the big data mining of customer consumption, this paper first analyzed precision marketing and then applied the K-means algorithm to classify customers. An improved particle swarm optimization (PSO) algorithm was designed to optimize the K-means algorithm. Finally, the IPSO-k-means algorithm was used to classify the customer consumption data established by the recency, frequency, and monetary (RFM) model. The results demonstrated that the classification accuracy of the IPSO-k-means algorithm was higher than that of K-means and PSO-k-means algorithms, and the average value reached 81.79%. In classifying 3000 customer consumption data in an APP, three categories were obtained, and some suggestions of marketing strategies were provided according to the different characteristics of these three categories of customers. The experimental results prove the reliability of the IPSO-k-means algorithm in customer classification and application feasibility in actual commercial consumer products. © 2023, The Institution of Engineers (India).",TextMining
"Background: As opioid prescriptions have risen, there has also been an increase in opioid use disorder (OUD) and its adverse outcomes. Accurate and complete epidemiologic surveillance of OUD, to inform prevention strategies, presents challenges. The objective of this study was to ascertain prevalence of OUD using two methods to identify OUD in electronic health records (EHR): applying natural language processing (NLP) for text mining of unstructured clinical notes and using ICD-10-CM diagnostic codes. Methods: Data were drawn from EHR records for hospital and emergency department patient visits to a large regional academic medical center from 2017 to 2019. International Classification of Disease, 10th Edition, Clinic Modification (ICD-10-CM) discharge codes were extracted for each visit. To develop the rule-based NLP algorithm, a stepwise process was used. First, a small sample of visits from 2017 was used to develop initial dictionaries. Next, EHR corresponding to 30,124 visits from 2018 were used to develop and evaluate the rule-based algorithm. A random sample of the results were manually reviewed to identify and address shortcomings in the algorithm, and to estimate sensitivity and specificity of the two methods of ascertainment. Last, the final algorithm was then applied to 29,212 visits from 2019 to estimate OUD prevalence. Results: While there was substantial overlap in the identified records (n = 1,381 [59.2 %]), overall n = 2,332 unique visits were identified. Of the total unique visits, 430 (18.4 %) were identified only by ICD-10-CM codes, and 521 (22.3 %) were identified only by NLP. The prevalence of visits with evidence of an OUD diagnosis in this sample, ascertained using only ICD-10-CM codes, was 1,811/29,212 (6.1 %). Including the additional 521 visits identified only by NLP, the estimated prevalence of OUD is 2,332/29,212 (7.9 %), an increase of 29.5 % compared to the use of ICD-10-CM codes alone. The estimated sensitivity and specificity of the NLP-based OUD classification were 81.8 % and 97.5 %, respectively, relative to gold-standard manual review by an expert addiction medicine physician. Conclusion: NLP-based algorithms can automate data extraction and identify evidence of opioid use disorder from unstructured electronic healthcare records. The most complete ascertainment of OUD in EHR was combined NLP with ICD-10-CM codes. NLP should be considered for epidemiological studies involving EHR data. © 2022",TextMining
"Many studies have used Digital Phenotyping of Mental Health (DPMH) to complement classic methods of mental health assessment and monitoring. This research area proposes innovative methods that perform multimodal sensing of multiple situations of interest (e.g., sleep, physical activity, mobility) to health professionals. In this paper, we present a Systematic Literature Review (SLR) to recognize, characterize and analyze the state of the art on DPMH using multimodal sensing of multiple situations of interest to professionals. We searched for studies in six digital libraries, which resulted in 1865 retrieved published papers. Next, we performed a systematic process of selecting studies based on inclusion and exclusion criteria, which selected 59 studies for the data extraction phase. First, based on the analysis of the extracted data, we describe an overview of this field, then presenting characteristics of the selected studies, the main mental health topics targeted, the physical and virtual sensors used, and the identified situations of interest. Next, we outline answers to research questions, describing the context data sources used to detect situations, the DPMH workflow used for multimodal sensing of situations, and the application of DPMH solutions in the mental health assessment and monitoring process. In addition, we recognize trends presented by DPMH studies, such as the design of solutions for high-level information recognition, association of features with mental states/disorders, classification of mental states/disorders, and prediction of mental states/disorders. We also recognize the main open issues in this research area. Based on the results of this SLR, we conclude that despite the potential and continuous evolution for using these solutions as medical decision support tools, this research area needs more work to overcome technology and methodological rigor issues to adopt proposed solutions in real clinical settings. © 2022 Elsevier Inc.",TextMining
"Karst areas, with their rich species and unique ecological environment, have attracted the attention of many researchers. The unique landscape has brought a wealth of species and great difficulties for research. Karst areas have complex landforms and numerous karst caves, which not only bring a lot of manpower and time investment to the research, but also increase the risk of the research. Therefore, the common field research method is not suitable for karst areas. To solve this problem, this paper adopts the form of UAV remote sensing, uses the visible band, through the calculation of normalized vegetation index, combined with the spectral characteristics of the investigated plants, to extract the vegetation information of the study area. In this paper, the final extracted vegetation information is obtained through practice, and compared with other vegetation extraction methods. It can be seen from the results that the vegetation information extraction method proposed in this paper to the visible band UAV remote sensing has higher extraction accuracy and better effect than other existing methods. Therefore, it can be used to extract vegetation information in complex terrain areas, reduce labor cost input, save research time, and obtain more targeted regional plants for targeted research, So as to improve the efficiency and level of vegetation research in karst areas. © 2022 Elsevier GmbH",TextMining
"Microorganisms associated with marine invertebrates consider an important source of bioactive products. This study aimed to screen for antimicrobial and anticancer activity of crude extracts of bacteria associated with Red sea nudibranchs and molecular identification of the bioactive isolates using 16Sr RNA sequencing, in addition to whole-genome sequencing of one of the most bioactive bacteria. This study showed that bacteria associated with Red sea nudibranchs are highly bioactive and 16Sr RNA sequencing results showed that two isolates belonged to Firmicutes, and two isolates belonged to Proteobacteria, and Actinobacteria. The whole genome sequence data of the isolated Nocardiopsis RACA4 isolate has an estimated genome length of 6,721,839 bp and the taxonomy showed it belongs to the bacteria Nocardiopsis dassonvillei. The De novo assembly of RACA-4 paired reads using Unicycler v0.4.8 initially yielded 97 contigs with an N50 value of 214,568 bp and L50 value of 10, The resulting assembly was further mapped to the reference genome Nocardiopsis dassonvillei strain NCTC10488 using RagTag software v.2.1.0 and a final genome assembly resulted in 39 contigs and N50 value of 6,726,007 and L50 of 1. Genome mining using anti-smash showed around 9.1% of the genome occupied with genes related to secondary metabolites biosynthesis. A wide variety of secondary metabolites belonging to Polyketides, Terpenes, and nonribosomal peptides were predicted with high degree of similarity to known compounds. Non-characterized clusters were also found which suggest new natural compounds discovered by further studies. © 2022 Elsevier B.V.",TextMining
"Raw data obtained by ultra-high pressure liquid chromatography–mass spectrometry, and processed lipid compositional data are presented alongside detailed methodology. Data were obtained as bovine liver lipid extract oxidizes, initiated by 2,2′-Azobis(2-amidinopropane) dihydrochloride, at 0, 6 and 24 h post initiation. Lipid oxidation data in the presence and absence of some supplements with antioxidant properties was obtained. The supplements used were grape seed extract, pine bark extract, milk thistle extract, hawthorn extract and turmeric extract. © 2023 The Authors",TextMining
"Clustering methods in data mining aim to group a set of patterns based on their similarity. In a data survey, heterogeneous information is established with various types of data scales like nominal, ordinal, binary, and Likert scales. A lack of treatment of heterogeneous data and information leads to loss of information and scanty decision-making. Although many similarity measures have been established, solutions for heterogeneous data in clustering are still lacking. The recent entropy distance measure seems to provide good results for the heterogeneous categorical data. However, it requires many experiments and evaluations. This article presents a proposed framework for heterogeneous categorical data solution using a mini batch k-means with entropy measure (MBKEM) which is to investigate the effectiveness of similarity measure in clustering method using heterogeneous categorical data. Secondary data from a public survey was used. The findings demonstrate the proposed framework has improved the clustering's quality. MBKEM outperformed other clustering algorithms with the accuracy at 0.88, v-measure (VM) at 0.82, adjusted rand index (ARI) at 0.87, and Fowlkes-Mallow's index (FMI) at 0.94. It is observed that the average minimum elapsed time-varying for cluster generation, k at 0.26 s. In the future, the proposed solution would be beneficial for improving the quality of clustering for heterogeneous categorical data problems in many domains. © 2023 Institute of Advanced Engineering and Science. All rights reserved.",TextMining
"This study intends to demonstrate the engineering application of ground penetrating radar (GPR) that would enable site engineers to prevent the high cost of blind drilling. At the tailing dump located in Zhairem Mining and Processing Plant, the challenge of sheet pile driving is encountered due to the indefinite watertight clay layer deposition depth that serves as a protective layer against groundwater contamination. A numerical model of the soil underlying the tailing dump is built using the existing hole data to compare and confirm the existing geological cross sections for three profile lines along the south and southeast parts of the tailing dump. GPR is employed to investigate the subsoil geological structure and detect the watertight clay layer deposition. On the basis of radargrams tied to the existing borehole data in the numerical model, 21 drill hole locations are suggested to assess and confirm the clay layer depth along profile lines at the tailing dump. The drilling results of the suggested holes confirmed the expected depth of the clay layer. It is concluded that GPR is a practical and economic subsurface mapping method that can prevent the high cost of blind digging of the ground and orient the drilling operations effectively. © 2023, Society for Mining, Metallurgy & Exploration Inc.",TextMining
"The history of pharmacovigilance started back 169 years ago with the death of a 15year-old girl, Hannah greener. However, the Thalidomide incident of 1961 brought a sharp change in the pharmacovigilance process, with adverse drug reaction reporting being systematic, spontaneous, and regulated timely. Therefore, continuous monitoring of marketed drugs was essential to ensure the safety of public health. Any observed adverse drug reaction detected by signals was to be reported by the health profession. Moreover, signal detection became the primary goal of pharmacovigilance based on reported cases. Among various methods used for signal detection, the Spontaneous Reporting System was most widely preferred; although, it had the limitation of ""under-reporting”. Gradually, the World Health Organization collaborating centre and “Uppsala Monitoring Centre” were established in 1978 for international monitoring of drugs. The centre was responsible for operating various databases like vigiflow, vigibase, vigilyze, and vigiaccess. Recently, huge data could be generated through spontaneous reporting linked with computational methods, such as Bayesian Framework, E-Synthesis. Furthermore, drug safety surveillance at an early stage prior to the official alerts or regulatory changes was made possible through social media. In addition, India created a National Pharmacovigilance Program, and Schedule Y of the Drug and Cosmetic Act 1945 was reviewed and amended in 2005. The collaboration of Information Technology and Pharmaceutical Company can further enhance the awareness regarding artificial intelligence in pharmacovigilance, which was in its infancy until 2017. Artificial intelligence helps improve the quality and accuracy of information much quickly. © 2023 Bentham Science Publishers.",TextMining
"This paper explores Wastewater-Based Epidemiology (WBE) as a tool enabling understanding of city's pain treatment in an intercity longitudinal study. An intensive 13-month monitoring programme was undertaken in two adjacent urban areas in South-West England: a small commuter town Keynsham and the city of Bath (>180 samples collected). The study has shown a great potential of using triangulated WBE and National health Service (NHS) prescription data in understanding pain treatment in two contrasting communities with strong apparent seasonal patterns of short pain medications vs chronic pain treatment as well as the type of treatment used (e.g. oral vs topical). Community-wide usage of Non-Steroidal Anti-inflammatory Drugs (NSAIDs) and paracetamol in the intercity study is population size and season driven with the highest usage recorded in winter months. This contrasts with other pain pharmaceuticals, especially those used for chronic pain, where no/limited seasonal usage was recorded. Unmetabolized NSAIDs are, to a large extent, directly disposed of into the sewerage system bypassing metabolism due to their topical application. This is particularly apparent in winter months with naproxen showing the highest seasonal variability. Pharma/met (ratio of pharmaceutical and its metabolite concentration) analysis allows for tracking topical (non-metabolic) application/down-the-drain disposal of pharmaceuticals with frequent instances of direct disposal of NSAIDs into the sewerage system observed. Normalisation of pharma markers to population size shows comparable estimates of pharma usage in the two cities confirming population as the main driver of pharma loads in wastewater. Variable application patterns of pain pharmaceuticals make back-calculation of intake more convoluted. Intake calculated using percentage excretion of parent NSAIDs will likely lead to overestimation, as it is assumed that NSAIDs are subject to extensive metabolism (this is not the case for topical applications). Intake calculated using percentage excretion of metabolites (or parent compound) as consumption markers leads to underestimation of NSAIDs usage due to contributions from topical application not being accounted for. Prescription data indicates cumulative internal and topical usage, but the data ignores large proportion of over-the-counter usage. Therefore, we have proposed a combined approach allowing for estimation of total usage including, and differentiating between, topical application and oral administration. © 2022 The Author(s)",TextMining
"In the past 20 years, with the rapid development of technology, the number of granted patents has also been increasing over years. How to utilize these data effectively is very important for making R&D policies and assisting in designing new technologies. In this paper, we map patents into a low-dimensional vector space, which is constructed by International Patent Classification (IPC) codes, through a deep learning model, i.e., Bidirectional Encoder Representations from Transformers (BERT). Then, this research makes the following contributions: first, we find that the generated vectors can describe the new technologies’ invention perspectives of patents accurately according to their texts; second, these vectors are combined with the physical meaning of patent citations (technological application) for the first time to solve some issues in designing new technologies from a different view; third, the citation relations and vectors of patents are adopted to explore the development rules of technology in terms of new technology's invention perspective; fourth, an approach is raised to assist inventors in designing new technologies through the forward citations of patents, whose vectors have great similarities to the initial ones’; finally, the patents granted by USPTO in the past 20 years are used to verify the effectiveness of our framework. © 2022 Elsevier B.V.",TextMining
"Gastrointestinal nematode (GINs) infections are one of the causative agents of health and economic issues in sheep production systems worldwide. Considerable genetic variations in resistance or susceptibility in different sheep breeds are documented, but published results are conflicting. Recent advances obtained by high-throughput technologies such as commercial SNP chips, whole-genome sequencing, or whole transcriptome profiling provide new insights into breeding for host resistance or nematode control at the genetic levels. This study aimed to identify potential biomarkers associated with the resistance to ovine GINs through a network analysis approach. Comprehensive gene and protein interaction networks were reconstructed for candidate genes involved in the most related immune pathways associated with resistance to ovine GINs using data mining from literature. Generally, 30 genes including CD53, CHIA, RELN, HRH1, EPS15, LRP8, ATP2B1, IL4, IL5, IL13, IL2RA, IL23R, TNFα, IFNγ, TBX21, SH3RF1, HERC2, PTPN1, BIN1, HERC5, C3AR1, NOS2, STAT5B, STAT4, CCL1, CCL8, VIL1, CXCR1, CXCR2, and CXCR4 located on chromosomes 1, 2, 3, 4, 5, 6, 11, 13, 19, and 20 have been found as containing effective regions with the most related pathways to nematode infections. The results obtained by network analysis showed two functional modules, belonging to the interleukins family (IL4, IL5, IL13, IL23R, and IL2RA) and chemokine receptors or ligands family (CXCR1, CXCR2, CXCR4, CCL1, and CCL8). Interleukins are a group of cytokines that are expressed by white blood cells with a major role in the immune system. Chemokines are also a family of chemoattractant cytokines which play a vital role in cell migration that influence the immune system by a process known as chemotaxis. The results provide useful information for the functional annotation of candidate genes related to parasite resistance and add new information towards a consensus on quantitative trait loci (QTLs) related to the incidence of nematode infections. © 2023, The Author(s), under exclusive licence to Springer Nature B.V.",TextMining
"In order to control antibiotic resistance genes (ARGs) diffusion in constructed wetlands, it is critical to explore the main factors influencing ARGs removal and understand its mechanism. Despite the fact that numerous studies have been conducted to determine the factors influencing ARGs removal by constructed wetlands in recent years, attempts to use published data and incorporate them into a comprehensive comparison and analysis are still limited. A framework for literature collection, data extraction and statistical analysis (LDS) was constructed in this study. The main factors influencing antibiotics and ARGs removal by constructed wetlands were identified using this framework. The results showed that nutrients, types of constructed wetlands and hydraulic loading were the principal factors influencing the removal of most antibiotics. The principal factors influencing the most ARGs removal were mobile genetic elements, plants, volume of constructed wetlands and running time. After purification by constructed wetlands, the risk coefficient of antibiotics decreased significantly, while the relative abundance of most ARGs did not change significantly. The analysis results of linear mixed model showed that the relationship between antibiotics and ARGs in effluent was closer than that in influent. LDS framework provides a new platform for the study of influencing factors of pollutant removal based on data mining. © 2023 Elsevier Ltd",TextMining
"Reliable prediction of spare parts is one of the most prevailing challenges for the manufacturing industry and equipment owners, which acts as a double-edged sword. If the objective function focuses on the lack of spare parts, it will cause capital sleep, and otherwise, it would make spare parts shortage. Therefore, the accuracy and reliability of this prediction have always been consequential. Howbeit, the non-uniformity of the spare parts in the real world is remarkable. Some of these parts have intermittent uses (fast-moving type), and some have less and irregular consumption (slow-moving type). Due to this uneven structure of slow-moving spare parts, the application of classical methods has low reliability and performance in forecasting. Therefore, this study concentrated on predicting slow-moving spare parts by developing a reliable and ensemble data mining approach with considering the managerial characteristics (e.g., repair ability and the irregularity of maintenance such as MTBF and MTTR…) along with their history of consumption (the amount of each order and the time interval between two charges). In the proposed approach, the amount of spare parts and the time of the following order is predicted based on an ensemble data mining model from the prediction of future consumption and the probability of scraping in the repair process. This simultaneous attention to data types (consumption and repairs) for slow-moving parts improves data adequacy. Whereas the focus of the literature has been more on improving the data mining models’ performance than on improving data adequacy; by emphasizing both issues at the same time, we can get more reliable results in predicting parts requests with more fluctuations in consumption. A clustering management model for classifying spare parts has been presented during the data preparation process to implement this model. And 51,335 slow-moving spare parts of a Steel Company have been organized and predicted. The results of this study reveal that the application of the proposed approach and ensemble model significantly increases the reliability of spare parts inventory (accuracy by up to 80% and newly defined reliability (RI) by up to 10%). © 2022 Elsevier B.V.",TextMining
"Smart cities have become an influential concept in urban development. Smart cities and their applications aim to maintain a high quality of life by using smart technologies and enhancing economic productivity. Previous systematic literature reviews have considered the development of smart cities and highlighted their applications and services. However, no prior studies have comprehensively investigated smart cities in relation to emergencies. To this end, the current paper aims to provide a research agenda reviewing the relevant literature that touches on smart technologies during emergencies like the ongoing COVID-19 pandemic. Based on a systematic methodology centred on text mining analysis, our research identified the following three themes: (a) emergency response, which covers emergency management, traffic and unmanned aerial vehicles, waste disposal, and contact tracing; (b) motivation and outcome, which includes such sub-themes as smart urbanism, quality of life and the economy; and (c) technology and data, which covers social media, machine learning, Internet of Things, data-driven applications, and object detection. We comprehensively discuss each theme and offer suggestions for future research. © 2023",TextMining
"The Paleoproterozoic sequences of the Kédougou-Kéniéba Inlier, West African Craton, contain major orogenic gold deposits mainly located in the vicinity of the Senegal-Mali Shear Zone in the Malian territory. Up to now few gold deposits has been discovered in the Senegalese side. Our new geological, geophysical and surface multi-element geochemistry data allow us to improve our understanding of the gold distribution within the Senegalese side (including the Boboti intrusion and its vicinity in the Falémé Volcanic Belt (FVB) and the Dialé-Daléma host rocks). On the one hand, the geological study shows variability of lithologies hosting gold mineralization in the FVB, including intermediate to felsic intrusions, andesite, quartz veins and sedimentary rocks. On the other hand, geophysical and surface multi-element geochemistry study, handled with regionalized Principal Component Analysis with kriging of gold factor unveil a change of the gold metal association from the Boboti intrusion (association of Au, Ni, Co, Cu and Pb) toward the FVB (association of Au and Zn), and the Dialé-Daléma sedimentary host rocks, where Au is only associated with As. Such variability of metal association can be used as an exploration guide to characterize gold-rich zones, whether located in the Dialé-Daléma Series, within the Boboti metaluminous pluton, or in the FVB areas. Furthermore, a comparison between soil and termite sampling shows that the latter is a good and more effective and suitable exploration guide in areas of high weathering profile and with intense surface mining activities, such as the FVB area. The continuity of gold anomalies from surface to the subsurface levels is confirmed by drilling data. This study has allowed us to better constrain the gold geochemical anomalies in high weathering environment such as the southeastern part of Senegal and produce a practical guide for exploration companies. © 2022 Elsevier B.V.",TextMining
"Real-world industrial processes frequently operate in different modes such as start-up, transient, and steady-state operation. Since different operating modes are governed by different process dynamics, deriving a single data-driven model representing the entire operation of such multimode processes is not a viable option. A reasonable solution to this problem is to develop a separate model for each operating mode, which requires the extraction of data for each operating mode from raw data. Based on this viewpoint, this work develops a data-driven modeling approach using clustering and featuring selection techniques to improve the quality of raw data and develop a predictive model for a multimode industrial process. In particular, the developed method focuses on training a steady-state predictive model as monitoring steady-state conditions is crucial for achieving the desired product quality. Firstly, K-means clustering is performed to extract data describing the steady-state operation mode from the available raw data. Next, feature selection is applied to the clustered data using Pearson's correlation coefficient to identify input features relevant to target features. Finally, an LSTM model is trained using the clustered data and identified features to predict the steady-state operation. The validity and effectiveness of the developed method are demonstrated using a real-world 2,3-Butanediol distillation process dataset. © 2022 The Author(s)",TextMining
"Coal mines are the major source of energy in industries and are important indicators of the economic growth of a country. Excessive withdrawal of coal from underground coal mines without stowing leads to surface deformation. In this study, Synthetic Aperture Radar Technology has been used to identify the surface deformation in the Korba Coal Mines of India. Korba coal mines are major coal-producing mines in India that come under South Eastern Coalfields Limited (SECL). It covers three underground mines. Depillaring has been done through the caving method, which may lead to the deformation of the area and its surroundings. Deformation may have devastating consequences if overlooked. So, it requires continuous monitoring of the area. Space-based SAR interferometry is the most preferred technique to monitor any mining area over a period of time. In this technique, known as the DInSAR technique, a deformation map can be generated from images of the same area acquired over different points of time. In the present study, images of the month of February of the years 2015, 2016, 2017, and 2019 have been successfully utilized for DInSAR analysis over the Rajgamar area. The Interferogram allows analysis of an entire mine site including pits and their surrounding area. High precision monitoring over wide coverage enables to bring out accurate deformation results due to the presence of coherent targets and monitoring risk across the study area. Maps generated from data were scrutinized and interpreted. Consequentially, 2015–2016 shows greater deformation than the other two corresponding maps generated 2015–2017 and 2015–2019 data. Results were validated through ground observations. Overall the area of the Rajgamar coal mine is getting deformed at a slow rate. © 2022 Elsevier B.V.",TextMining
"Laser scanning can provide timely assessments of mine sites despite adverse challenges in the operational environment. Although there are several published articles on laser scanning, there is a need to review them in the context of underground mining applications. To this end, a holistic review of laser scanning is presented including progress in 3D scanning systems, data capture/processing techniques and primary applications in underground mines. Laser scanning technology has advanced significantly in terms of mobility and mapping, but there are constraints in coherent and consistent data collection at certain mines due to feature deficiency, dynamics, and environmental influences such as dust and water. Studies suggest that laser scanning has matured over the years for change detection, clearance measurements and structure mapping applications. However, there is scope for improvements in lithology identification, surface parameter measurements, logistic tracking and autonomous navigation. Laser scanning has the potential to provide real-time solutions but the lack of infrastructure in underground mines for data transfer, geodetic networking and processing capacity remain limiting factors. Nevertheless, laser scanners are becoming an integral part of mine automation thanks to their affordability, accuracy and mobility, which should support their widespread usage in years to come. © 2023",TextMining
"The mining industry, in most cases, targets a specific valuable commodity that is present in small quantities within large volumes of extracted material. After milling and processing, most of the extracted material and the effluents are stored as waste (tailings) in impoundments, such as dams or waste dumps, or are backfilled into underground mines. In time, tailing materials may become an issue of environmental and health concern due to the hazardous elements, ions, and oxides contained within the waste material. In addition, handling and storage of such waste in dams may pose the risk of dam failure with catastrophic consequences to nature and nearby communities. On the other hand, tailings may offer potential as secondary sources of critical elements (CEs), including rare earth elements (REEs), which may have been overlooked during primary production and processing. Therefore, treating mine tailings as a resource has economic and environmental benefits by reducing the waste from new and historical mine sites through remining. One of the critical steps for taking advantage of these benefits is to spatially quantify the resources and the pollutants, which require the application of adequate data analysis and modeling methods, often to compositional geochemical data. Utilizing adequate methods is especially important for correctly quantifying resource potential, as the quantities will often be at low concentrations. This work presents quantification of resource potential (Au, Ag, Cu, Zn, Pb) and elements of environmental concern (Hg and As) from the tailings of a historic mine site, Katherine Mine, AZ, USA. Data reported by the U.S. Bureau of Mines (USBM) after extensive field campaigns in the 1990s, including sampling from tailing impoundment and surrounding areas for geochemical characterization and geophysical surveys, were used. First, compositional data (CoDa) analysis was employed to explore associations of sampling locations, geochemical parts, and the clustering of samples. Next, sequential Gaussian simulation (SGSIM) was applied to samples that showed a genetic link to tailing material after isometric log-ratio transformation (ilr) and mix/max autocorrelation factor (MAF) transformation for spatial modeling and uncertainty evaluation. Geostatistical results revealed spatial variability of concentrations within the tailing area. Uncertainty evaluation based on realizations indicated that Cu (14.27–20.01 t), Zn (44.23–76.23 t), and Pb (22.56–38.28 t) are the most abundant elements within a 5 %–95 % interval, followed by Ag and Au (~5.3 and 0.18 t, at 50th percentile), respectively. Of the elements of health concern, As was found to be ~4.8 t (50th percentile) in the tailing area. The work also showed that ~0.51 t As, 0.005 t Hg, 0.020 t of Au, and 0.62 t of Ag were carried to Lake Mohave by an ephemeral stream called Katherine Wash, which transects the tailings. © 2022",TextMining
"The processing of unstructured and structured documents involves the recognition of specific entity classes in the Named Entity Recognition (NER) and the categorization of these entities into certain predefined classes. Biomedical instances such as RNAs, DNAs, disorders, viruses, proteins, genes and chemical components are identified using Biomedical Named Entity Recognition (BNER). The techniques used to retrieve those other ebontities have a major role to play in this BNER. Supervised Machine Learning (SML) approaches are used in various BNER techniques.The primary benefit of supervised learning is the ability to gather data or generate data output from prior experiences. If your training set lacks the examples you wish to include in a class, the decision boundary of your model may be overstretched.The boundary condition is employed when a particle goes past the region where a boundary constraint is no longer valid.In these approaches, in order to enhance the recognition process's effectiveness, these features are used. A set of distinguishing and discriminating characteristics are used for identifying features, which is having ability for indicating entity occurrence.Bio curators annotates only limited number of articles also consumes more processing time. In this work, propose an Enhanced System for Curatable-Biomedical Named Entities Recognition (ECBNER) and feature extraction approaches for bio-medical named entity recognition using aimproved Particle Swarm Optimization (IPSO). Classification of curatable named-entities is useful in facilitating biocuration with a straightforward technique for accelerating workflow of proposed biocuration. Curatable and non-curatable are classified using a Support Vector Machine (SVM) in this work.The process of gathering and organizing knowledge, facts, and information in the realm of life sciences is known as “biocuration.” In ML, combination of classifiers provides productive exploration guidance and it is a successful strategy of it. An independent classifier's exhibition in characterization can be improved utilizing this. Consequence of different classifiers mix is accumulated to defeat singular classifiers conceivable nearby soft spot for delivering exceptionally strong acknowledgment. Quality/Disease NER is handled under Conditional Random Field (CRF) and all activity terms are gathered and prepared in a simultaneous way to extricate precise biomedical named substances. At long last, this overall structure to learn portrayal by joining general and area explicit highlights is proposed and assessed, demonstrating exact outcomes contrasted with existing systems. © 2022 Elsevier GmbH",TextMining
"Coupled matrix factorization (CMF) models jointly decompose a collection of matrices with one shared mode. For interpretable decompositions, constraints are often needed, and variations of constrained CMF models have been used in various fields, including data mining, chemometrics and remote sensing. Although such models are broadly used, there is a lack of easy-to-use, documented, and open-source implementations for fitting CMFs with user-specified constraints on all modes. We address this need with MatCoupLy, a Python package that implements a state-of-the-art algorithm for CMF and PARAFAC2 that supports any proximable constraint on any mode. This paper outlines the functionality of MatCoupLy, including three examples demonstrating the flexibility and extendibility of the package. © 2022 The Author(s)",TextMining
"Electronics manufacturing is a global industry and key to innovation in the virtual world because it is the physical backbone. The cost-effective development and manufacture of such electronic modules are critical to maintaining the competitiveness of high-wage manufacturing countries. Therefore, two approaches suggest themselves: Design for Manufacturing (DfM) and manufacturing optimization. To apply both approaches in industry, it is necessary to introduce models that describe the relationship between process input and process output. Applied to electronics manufacturing processes, this means that design, process parameters, and material properties must be mapped to process quality criteria in end-of-line testing. Recently, machine learning (ML) algorithms have been emerging and dominating other modeling methods such as numerical simulation. To develop such complex ML models, a unified data structure for each input and output must be defined. This paper proposes an extensible ML-enabled framework that provides direct and structured access to the printed circuit board (PCB) design and process parameters. This framework is used to perform structured data acquisition using a custom data mining board. During the manufacturing of these PCBs on a full surface mount technology (SMT) process line, all available process machine-level data is collected, archived, and parsed into a uniform, standardized, and flat data structure. This enables fast analysis of the correlation between inputs and quality criteria, direct access by ML algorithms, and training of models. Through these measures, the quality of the framework is validated and correlations are revealed and compared to previous literature. This shows the great importance of a data framework for the integration of data analysis technologies into industrial processes. © 2022 Elsevier B.V.",TextMining
"Digitalization through Industry 4.0 technologies is one of the essential steps for the complete collaboration, communication, and integration of heterogeneous resources in a manufacturing organization towards improving manufacturing performance. One of the ways is to measure the effective utilization of critical resources, also known as bottlenecks. Finding such critical resources in a manufacturing system has been a significant focus of manufacturing research for several decades. However, finding a bottleneck in a complex manufacturing system is difficult due to the interdependencies and interactions of many resources. In this work, a digital twin framework is developed to detect, diagnose, and improve bottleneck resources using utilization-based bottleneck analysis, process mining, and diagnostic analytics. Unlike existing bottleneck detection methods, this novel approach is capable of directly utilizing enterprise data from multiple levels, namely production planning, process execution, and asset monitoring, to generate event-log which can be fed into a digital twin. This enables not only the detection and diagnosis of bottleneck resources, but also validation of various what-if improvement scenarios. The digital twin itself is generated through process mining techniques, which can extract the main process map from a complex system. The results show that the utilization can detect both sole and shifting bottlenecks in a complex manufacturing system. Diagnosing and managing bottleneck resources through the proposed approach yielded a minimum throughput improvement of 10% in a real factory setting. The concept of a custom digital twin for a specific context and goal opens many new possibilities for studying the strong interaction of multi-source data and decision-making in a manufacturing system. This methodology also has the potential to be exploited for multi-objective optimization of bottleneck resources. © 2022 The Author(s)",TextMining
"Data-driven soft sensor technology has been widely developed to estimate quality-related variables, while following difficulties still limit its application in batch processes, such as different initial conditions, uneven-length of batches, and the extraction of within-batch multiphase features. To address these problems, a quality prediction and monitoring framework is proposed. Variables related to quality-related variables are first selected, and a data stacked strategy is proposed to transform three-dimensional batch data into time-lagged sequences that can be fed into soft sensor models. Aiming to extract the multiphase features, a novel differential recurrent neural networks is established by embedding differential operations into long short-term memory neural networks. Moreover, to ensure profitability, prediction residuals are employed for quality monitoring. Case study on a simulation dataset and an industrial-scale penicillin fermentation process demonstrates the effectiveness of the proposed method and its applicability to batch process monitoring and control in both academic research and industrial operation. © 2022 Elsevier Ltd",TextMining
"Nanoparticle carriers can improve antibiotic efficacy by altering drug biodistribution. However, traditional screening is impracticable due to a massive dataspace. A hybrid informatics approach was developed to identify polymer, antibiotic, and particle determinants of antimicrobial nanomedicine activity against Burkholderia cepacia, and to model nanomedicine performance. Polymer glass transition temperature, drug octanol-water partition coefficient, strongest acid dissociation constant, physiological charge, particle diameter, count and mass mean polydispersity index, zeta potential, fraction drug released at 2 h, and fraction release slope at 2 h were highly correlated with antimicrobial performance. Graph analysis provided dimensionality reduction while preserving nonlinear descriptor-property relationships, enabling accurate modeling of nanomedicine performance. The model successfully predicted particle performance in holdout validation, with moderate accuracy at rank-ordering. This data analytics-guided approach provides an important step toward the development of a rational design framework for antimicrobial nanomedicines against resistant infections by selecting appropriate carriers and payloads for improved potency. © 2022 Elsevier Inc.",TextMining
"In response to the many changes and uncertainties facing the future, sensing opportunities for innovation is an important agenda. Formulating strategies for sensing opportunities in innovation requires an ecosystem perspective that integrates the science, technology, and business (S-T-B) fields that shape the innovation ecosystem. This study was to identify potential in the innovation ecosystem focusing on a text mining technique and similarity-based analysis, which is the fundamental concept of Literature-Based Discovery, an approach to deriving hidden associations between two areas in bibliometric databases. The purpose of this study was sensing innovation opportunities through intelligent trends and interaction analysis in S-T-B fields in the value chain of smart grids, which is the research target area. Topic modeling, and cosine similarity measurements were carried out using scientific papers, patents, business publication data corresponding to the S-T-B ecosystem. Through multi-dimensional data sources corresponding to the S-T-B fields, the evolutionary path of the smart grid value chain and its potential as a strategic tool for future innovative challenges were identified. This study has practical and policy implications in that it identifies a niche in the innovation system and provides meaningful information that could contribute to the revitalization of participation in the private sector and consumers. © 2022 Elsevier Inc.",TextMining
"Background: Inactivity and unloading induce skeletal muscle atrophy, loss of strength and detrimental metabolic effects. Bed rest is a model to study the impact of inactivity on the musculoskeletal system. It not only provides information for bed-ridden patients care, but it is also a ground-based spaceflight analogue used to mimic the challenges of long space missions for the human body. In both cases, it would be desirable to develop a panel of biomarkers to monitor muscle atrophy in a minimally invasive way at point of care to limit the onset of muscle loss in a personalized fashion. Methods: We applied mass spectrometry-based proteomics to measure plasma protein abundance changes in response to 10 days of bed rest in 10 young males. To validate the correlation between muscle atrophy and the significant hits emerging from our study, we analysed in parallel, with the same pipeline, a cohort of cancer patients with or without cachexia and age-matched controls. Our analysis resulted in the quantification of over 500 proteins. Results: Unloading affected plasma concentration of proteins of the complement cascade, lipid carriers and proteins derived from tissue leakage. Among the latter, teneurin-4 increased 1.6-fold in plasma at bed rest day 10 (BR10) compared with BR0 (6.E9 vs. 4.3E9, P = 0.02) and decreased to 0.6-fold the initial abundance after 2 days of recovery at normal daily activity (R + 2, 2.7E9, P = 3.3E-4); the extracellular matrix protein lumican was decreased to 0.7-fold (1.2E9 vs. 8.5E8, P = 1.5E-4) at BR10 and remained as low at R + 2. We identified six proteins distinguishing subjects developing unloading-mediated muscle atrophy (decrease of >4% of quadriceps cross-sectional area) from those largely maintaining their initial muscle mass. Among them, transthyretin, a thyroid hormone-binding protein, was significantly less abundant at BR10 in the plasma of subjects with muscle atrophy compared with those with no atrophy (1.6E10 vs. 2.6E10, P = 0.001). Haptoglobin-related protein was also significantly reduced in the serum of cancer patients with cachexia compared with that of controls. Conclusions: Our findings highlight a combination or proteomic changes that can be explored as potential biomarkers of muscle atrophy occurring under different conditions. The panel of significant proteomic differences distinguishing atrophy-prone and atrophy-resistant subjects after 10 days of bed rest need to be tested in a larger cohort to validate their potential to predict inactivity-triggered muscle loss in humans. © 2022 The Authors. Journal of Cachexia, Sarcopenia and Muscle published by John Wiley & Sons Ltd on behalf of Society on Sarcopenia, Cachexia and Wasting Disorders.",TextMining
"7β-Hydroxysteroid dehydrogenases (7β-HSDHs) have attracted increasing attention due to their crucial roles in the biosynthesis of ursodeoxycholic acid (UDCA). However, most published 7β-HSDHs are strictly NADPH-dependent oxidoreductases with poor activity and low productivity. Compared with NADPH, NADH is more stable and cheaper, making it the more popular cofactor for industrial applications of dehydrogenases. Herein, by using a sequence and structure-guided genome mining approach based on the structural information of conserved cofactor-binding motifs, we uncovered a novel NADH-dependent 7β-HSDH (Cle7β-HSDH). The Cle7β-HSDH was overexpressed, purified, and characterized. It exhibited high specific activity (9.6 U/mg), good pH stability and thermostability, significant methanol tolerance, and showed excellent catalytic efficiencies (kcat/Km) towards 7-oxo-lithocholic acid (7-oxo-LCA) and NADH (70.8 mM-1s−1 and 31.8 mM-1s−1, respectively). Molecular docking and mutational analyses revealed that Asp42 could play a considerable role in NADH binding and recognition. Coupling with a glucose dehydrogenase for NADH regeneration, up to 20 mM 7-oxo-LCA could be completely transformed to UDCA within 90 min by Cle7β-HSDH. This study provides an efficient approach for mining promising enzymes from genomic databases for cost-effective biotechnological applications. © 2022 Elsevier Inc.",TextMining
"Wrapper methods are widely employed in feature selection for status prediction of lithium-ion batteries and Gaussian process regression (GPR) is often adopted for state-of-health (SOH) estimation. However, the number and the source of the features are not considered as constraints in the wrapper methods, most existing optimization algorithms for finding optimal hyperparameters of GPR easily get trapped into the local optimum. In this work, a newly developed meta-heuristic optimization algorithm, Hunger Game Search (HGS) is utilized, because of its robustness and competitive performance to find the solution of both constrained and unconstrained problems. Also to further improve HGS the chaos mechanism is embedded to form Chaos-HGS (CHGS). It is utilized to find global optimal hyperparameters in GPR and its binary variant (CBHGS) is adopted to solve feature selection problems. Effects of chaos maps and constraints upon SOH prediction and hyperparameters optimization are investigated. To gain a deeper understanding of wrapper method results, intrinsic characteristics of features are mined through Gaussian Process Latent variables model (GPLVM). Relationships between features and the capacity of the battery are examined through clustering analysis. The effectiveness of the proposed algorithms and data mining methods is verified on the lithium-ion battery dataset of the NASA Prognostics Center of Excellence. The results show that the features found by CBHGS working with GPR can provide SOH prediction with higher accuracy and lower cost. © 2022 Elsevier Ltd",TextMining
"Background: Currently, there are no effective differentiation-inducing agents for glio-mas. Drug repositioning is a time-saving, low-risk, and low-cost drug development strategy. In this study, drugs that could induce the differentiation of glioma cells were searched by using a drug re-positioning strategy. Methods: Data mining was used to screen for differentially expressed genes (DEGs). The STRING 11.0 database was used for enrichment analysis. The Connectivity Map database was used for drug screening. The ChEMBL and STITCH databases were used to search for drug targets. The SwissDock database was used for molecular docking. Results: A total of 45 DEGs were identified. The biological processes in which the DEGs were enriched mainly involved nervous system development and the regulation of biological processes. The enriched molecular functions mainly involved transcription-related molecular binding. The enriched cellular components mainly involved membrane-bound organelles and cellular protrusions. The enriched local network clusters mainly involved autophagy, the retinoic acid signalling path-way, and DNA methylation. The drug screening results showed that the drug with the highest score was acenocoumarol. A total of 12 acenocoumarol targets were obtained, among which histone deacetylase 1 (HDAC1) was the target with the highest degree value; the lowest ΔG value for acenocoumarol docked with HDAC1 was-7.52 kcal/mol, which was between those of the HDAC1 inhibitors romidepsin and vorinostat. Conclusion: Acenocoumarol may be a potential differentiation-inducing agent for glioma cells. © 2023 Bentham Science Publishers.",TextMining
"Stereo matching is a classical problem in computer vision. It has been widely used in many fields, especially autonomous driving in recent years. Two key aspects of speed and accuracy are both desirable but conflicting characteristics in autonomous driving. In this paper, we present CMNet, a lightweight stereo matching architecture for improving the trade-off between speed and accuracy on resource-limited devices. A novel feature extraction network consisted of a patch embedding layer and a ConvMLP-mixer is proposed. The patch embedding layer enhances the receptive field and makes the feature vectors compact. The accuracy of the disparity map is increased by mixing the spatial information in the channel dimension through the ConvMLP-mixer. The absolute difference volume is concatenated with the group-wise correlation volume to provide multi-dimensional matching cost information for the cost aggregation stage. Being evaluated on KITTI 2012 and KITTI 2015 stereo matching datasets, the inference time of CMNet on NVIDIA GTX 2080ti GPU is 8.7 ms. While realizing fast predictions beyond real-time, the results of D1-all are 3.41% on KITTI 2012 and 3.84% on KITTI 2015, achieving state-of-the-art result between speed and accuracy. Besides, the lightweight architecture of CMNet enables a fast inference time of 40.7 ms on Nvidia Jetson Nano to realize real-time applications on edge devices.  © 1967-2012 IEEE.",TextMining
"Big social data and user-generated content have emerged as important sources of timely and rich knowledge to detect customers’ behavioral patterns. Revealing customer satisfaction through the use of user-generated content has been a significant issue in business, especially in the tourism and hospitality context. There have been many studies on customer satisfaction that take quantitative survey approaches. However, revealing customer satisfaction using big social data in the form of eWOM (electronic word of mouth) can be an effective way to better understand customers’ demands. In this study, we aim to develop a hybrid methodology based on supervised learning, text mining, and segmentation machine learning approaches to analyze big social data on travelers’ decision-making regarding hotels in Mecca, Saudi Arabia. To do so, we use support vector regression with sequential minimal optimization (SMO), latent Dirichlet allocation (LDA), and k-means approaches to develop the hybrid method. We collect data from travelers’ online reviews of Mecca hotels on TripAdvisor. The data are segmented, and travelers’ satisfaction is revealed for each segment based on their online reviews of hotels. The results show that the method is effective for big social data analysis and traveler segmentation in Mecca hotels. The results are discussed, and several recommendations and strategies for hotel managers are provided to enhance their service quality and improve customer satisfaction. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",TextMining
"In this paper, we are proposing two novel swarm intelligence approaches for solving discrete problems. Two different continuous evolutionary algorithms inspired by the behaviour of elephants, namely elephant herding optimization and elephant swarm water search algorithm, are studied and analysed in order to propose discrete versions of the latter called discrete elephant herding optimization and discrete elephant swarm water search algorithm. As an illustration of how our proposals can work on discrete problems, a case study on association rule mining is carried out where the proposed discrete algorithms are modelled and applied on the problem in order to extract interesting association rules from large-scale databases. Extensive experiments on eight different real-life and relevant datasets with various sizes showed that both our proposals yield good results that compete and sometimes outperform state of the art algorithms. © 2022 John Wiley & Sons Ltd.",TextMining
"In recent years, the severity classification of some well-known diseases has gradually become a focus of researchers, especially diabetic retinopathy (DR) recognition caused by diabetes. Existing diagnostic methods usually require many annotated fundus images for training. However, in practical situations, the high time and economic cost of annotating images make it unaffordable for many researchers. In this paper, we design a semi-supervised learning framework to explore the associations between unlabeled data, with the help of a small number of labeled samples, for accurate fundus image classification of DR. Through the analysis of semi-supervised tasks, it can be observed that: (1) an attention mechanism that fits the data can improve the network's potential to extract critical features; (2) unlabeled data is as potentially valuable as labeled ones, and the association between these unknown samples can further improve the model's performance. Therefore, we propose a Multi-point Attention-based Semi-supervised Learning (MASL) framework that efficiently utilizes the massive unlabeled data for accurate DR classification. Specifically, we propose a multi-point attention mechanism that enables the model to extract subtle features from multiple perspectives of fundus images and discard invalid regions. In addition, we design a new self-supervision mechanism to force the model to perform mandatory similarity mining on unknown samples, maximizing the potential of squeezing unlabeled data based on the confidence of the selected unannotated samples. Sufficient experimental results demonstrate that our MASL method significantly outperforms other methods on two public datasets. © 2022 Elsevier Ltd",TextMining
"Beyond 5G (B5G) in mobile network technologies is the latest communication technology currently under development. B5G is expected to achieve superior capabilities in ultra-high network transmission speed, low latency, low energy consumption, and high coverage, comparing to current 5G network performance. Although B5G is still in the development and implementation stage, there are many patents and non-patent literature depicting B5G innovative technologies and applications. The landscapes of B5G technologies are great references for governments and industries to understand the advances in mobile communication for R&D strategies. Thus, this research focuses on developing a formal tech-mining workflow integrating semantic-based patent and non-patent literature analysis for ontology building, patent technological topic clustering, and graph convolutional network (GCN) modeling for depicting key technology interactions among clusters of sub-domain topics. This research emphasizes the study of B5G patent landscape and key technology interaction roadmap in comprehensive steps as a valuable reference for B5G mobile network R&D, as well as for conducting tech-mining of other technology domains of interests. © 2022 Elsevier Ltd.",TextMining
"Tree-ring records from sites affected by underground mining provide valuable data on the long-term development of subsidence troughs. However, due to complexity of local conditions, it is unclear whether the surface displacements are actually the result of mining operations or shallow landslides caused by extreme rainfall. This paper compares surface movements at two nearby sites in the Upper Silesian Coal Basin (Central Europe) that have been affected by underground coal mining. Dendrogeomorphic data on subsidence-related movements were obtained from 360 increment cores (90 trees) of European larch (Larix decidua Mill.). Subsidence between 1966 and 2013 was calculated from the corresponding digital elevation models and the actual morphometric parameters of the sites were related to tree-ring records. The effect of precipitation on surface displacements was evaluated using logistic regression models incorporating rainfall data from a nearby meteorological station and dendrogeomorphic event years. The subsidence at the edges of subsidence troughs (study sites) between 1966 and 2013 reached 4–9 m, which is relatively low compared to nearby (5 km radius) directly undermined sites with subsidence up to 22 m. Most events were dated to the 1930s, 1970s, 1990s, and late 2000s with a peak of activity in 1973 and other noteworthy events in 1986, 1995, and 2009. Event years at the site with a flatter topography, and more waterlogged and clay soils are well explained by higher triennial precipitation and higher Simple daily intensity index, suggesting a possible influence of near-surface displacements on the chronology of recorded events, whereas the elevated site with step-block topography showed no relationship between precipitation extremes and event years. We concluded that not only the time of mining operation, but also the site-specific conditions are crucial for characterization of surface displacements in the forested post-mining landscape. © 2022 Elsevier B.V.",TextMining
"Exploration of low-sulfidation epithermal Au deposits is expected to increase because these deposits are economically competitive and globally occurring as well as produce low environmental load via underground mining. Drilling is the main exploration tool for identifying mineralized zones in three dimensions; however, selecting drill targets is a major technical challenge in exploration work. This challenge can be addressed by effectively employing our conceptual model of a “cold-water trap,” an ore-deposition mechanism induced by cold groundwater in shallow aquifer. In two previous case studies on low-sulfidation epithermal deposits, this mechanism was verified via geological modeling and numerical simulations, and potential mineralized zones were three-dimensionally confirmed in undrilled areas. Here, we methodize the utilization of numerical simulations for epithermal Au exploration and prepare the operational guidelines for a new exploration method. In this method, the trapping scenario can be modified to explore deposits generated by incomplete cold-water trapping. Because this method functions effectively from the time at which the necessary data for geological modeling are obtained, it is adapted to operate over the time of drill exploration. Furthermore, the proposed method can be adapted to brownfield explorations, such as around the existing deposits. Sensitivity analysis revealed permeability to be the most important parameter for the numerical simulation. Analyzing drill cores with respect to fracture properties such as width and density as well as the extent of the hydrothermal alteration halo is crucial for the accurate estimation of permeability. © 2022, International Association for Mathematical Geosciences.",TextMining
"In drug review sentimental analysis (SA), users can share their experiences after consuming the drugs, which provides an accurate decision about the safety of the drug and public health. Patient-written medical and health-care reviews are among the most valuable and informative textual content on social media, but researchers in the areas of natural language processing (NLP) and data mining have not researched them thoroughly. These reviews provide insight into patients' interactions with doctors, treatment, and satisfaction or dissatisfaction with health services. The existing approaches have some problems like exploding/vanishing gradients and do not have sequential modeling. When learning long reviews, the exploding and vanishing gradient problems occurs. This problem makes it hard to tune parameters and learn in the network. The existing methods do not have sequential modeling because they fail to extract long dependencies for long reviews in both backward and forward directions. To overcome these issues, we proposed a Modular Lexicon Generation and a Fusion of Bidirectional threshold weighted mapping CNN-RNN (MLBTWCR) for classifying drug reviews based on users opinions. The Aspect based Modular Lexicon generation using the Advanced Dragon Fly Algorithm (AMLDA) is used to generate the score values for the lexicon and labels based on aspect. The Bidirectional Dropout Long and Short-Term Memory (Bi-DLSTM) and Bidirectional Gated Recurrent Unit (Bi-GRU) used for extracting long dependencies and for performing the sequence of arbitrary length in both backward and forward directions. The experimental results are evaluated using Drugslib.com and Drugs.com datasets. Based on evaluation result, the proposed MLBTWCR gives accuracy of 93.02%, recall of 88.72%, error rate of 11.2, false positive rate (FPR) of 11.3, false negative rate (FNR) of 13.6, running time of 15 s, and convergence speed of 0.2 and F-measure of 92.64%. Hence, our method performs well for the drug reviews classification based on aspects. © 2022 John Wiley & Sons, Ltd.",TextMining
This technical note calls for an interdisciplinary research agenda to study the intersection of policy problems and extreme events. We argue that extreme events can unveil chronic problems in societies such as political polarization. We used social media data following the 2014 Soma mining disaster in Turkey as an illustrative case study. Our findings indicate that polarized sense-making during and following extreme events can hinder the effectiveness of response and recovery operations. We conclude with some recommendations for using social media data during response operations to improve disaster communications in contexts characterized by high levels of political polarization.  © 2022 American Society of Civil Engineers.,TextMining
"This paper reports on a design science research (DSR) study that develops design principles for “green” – more environmentally sustainable – data mining processes. Grounded in the Cross Industry Standard Process for Data Mining (CRISP-DM) and on a review of relevant literature on data mining methods, Green IT, and Green IS, the study identifies eight design principles that fall into the three categories of reuse, reduce, and support. The paper develops an evaluation strategy and provides empirical evidence for the principles’ utility. It suggests that the results can inform the development of a more general approach towards Green Data Science and provide a suitable lens to study sustainable computing. © 2022, The Author(s).",TextMining
"Policy evaluation is the premise of the scientific formulation and effective implementation of a basin ecological compensation policy. However, whether the formulation of the basin ecological compensation policy (BECP) is reasonable or not lacks theoretical and technical support. This study constructed a model based on the PMC and text mining methods. PMC index model enables decision-makers to determine the level of consistency and the strengths and weaknesses of any policy from multiple angles and makes the evaluation results more targeted and operable. By establishing an evaluation system for BECP and building a multi-input-output table, the score of each policy is calculated. Based on this, the rationality of nine ecological compensation policies in the Yangtze and Yellow River basins was then examined. The results show that the average value of the PMC index for the nine policies is 7.23, which indicate the formulation of the basin ecological compensation policy in China is generally reasonable. Ranking of policy scores from high to low is P2 > P1 > P5 > P7 > P3 > P4 > P6 > P9 > P8. However, deficiencies exist in policy timeliness, incentive measures, and policy receptors. In addition, there is a large gap in the formulation of policies at different levels. Moreover, the level of local policies is uneven. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TextMining
"Random sample partition (RSP) is a newly developed data management and processing model for Big Data processing and analysis. To apply the RSP model for Big Data computation tasks, it is very important to measure the distribution consistency of different datasets. Existing measurement methods for continuous-attribute and discrete-attribute datasets cannot directly deal with mixed-attribute datasets. In this article, we design a hybrid method to measure the distribution consistency among different mixed-attribute datasets by using a multilayer extreme learning machine (MLELM) and the generalized maximum mean discrepancy (GMMD) criterion, abbreviated as MLELM-GMMD. MLELM is first used to transform original mixed-attribute datasets into corresponding deep encoding datasets. Then, the GMMD criterion is applied to check the distribution consistency of the deep encoding datasets. Four experiments have been done to validate the feasibility and effectiveness of MLELM-GMMD, i.e., the impact of MLELM on the amount of information during mixed-attribute data transformation, the impact of MLELM on distributions of mixed-attribute data, the distribution consistencies of RSP and non-RSP data blocks, and the comparison with other measurement methods. Experimental results show that the proposed MLELM-GMMD method can measure the distribution consistency of mixed-attribute datasets more accurately than one-hot encoding-based methods. © 2022 IEEE.",TextMining
"As a significant topic in Intelligent Transportation Systems (ITS), vehicle Re-Identification (Re-ID) has attracted increasing research attention. However, the variation of shooting scenes and the similar appearance among the vehicles with the same type and color lead to large intra-class variances and small inter-class variances, respectively. To address the problems, we propose a novel Mask-Aware Reasoning Transformer (MART) to extract the background-unrelated global features and perspective-invariant local features. The MART contains three effective modules including Foreground Global Features Extraction (FGFE), Mask-guided Local Features Extraction (MLFE) and Cross-images Local Features Reasoning (CLFR). Firstly, due to the complexity of background information in images, identity representation inevitably contains background elements, which may impact identity matching. To address this issue, we propose the FGFE to extract background-independent global features by introducing the mask semantic information to the inputs of Vision Transformer (ViT). Secondly, to fill the gap that the previous local features extraction methods cannot be directly applied to ViT, the MLFE is presented to extract distinctive local features by recombining token features according to vehicle mask. Thirdly, when local components are invisible in the image due to the occlusion problem, the corresponding local information is absent from the image, leading to unreliable local features. To solve this problem, the CLFR is proposed to reason the occluded local features by exploiting the correlation between cross-image local features. We carry out comprehensive experiments to illustrate the effectiveness of the MART on two challenging datasets. © 2000-2011 IEEE.",TextMining
"Since the rise of the gold price in 2000, artisanal and small-scale gold mining (ASGM) is a growing economic activity in developing countries. It represents a source of income for several millions of people in West Africa. Exploitation techniques have evolved from traditional gold panning to mechanization and use of chemical products that are harmful for the environment. Government strategies to control and regulate this activity are impeded by the difficulties to collect spatial information, due to the remote location and the mobile and informal natural of ASGM. Here we present and discuss the value of remote sensing techniques to complement the knowledge on artisanal mining impacts, including for detection of illegal sites, the evaluation of the degradation of soils and waters, the deforestation and the monitoring of expansion of ASGM with time. However, these techniques are blind regarding gender issues, labor relations, mobility, migration, and insecurity and need to be considered with knowledges from other disciplines. Remote sensing is also instilled with various powers accruing to those enabled to produce and interpret these data. Remote sensing should be therefore used in a reflexive manner that accounts for the social, ethical and political implications of ASGM governance informed by space observations. © 2022, The Author(s).",TextMining
"Using appropriate tools strategically to aid in problem solving is a crucial skill identified in K-12 mathematics curriculum standards. As more assessments transition from paper-and-pencil to digital formats, a variety of interactive tools have been made available to test takers in digital testing platforms. Using onscreen calculators as an example, this study illustrates how process data obtained from student interactions with a digitally-based large-scale assessment can be leveraged to explore how and how well test takers use interactive tools and unveil their mathematical problem-solving processes and strategies. Specifically, sequence mining techniques using the longest common subsequence were applied on process data collected from a nationally representative sample who took the National Assessment of Educational Progress (NAEP) mathematics assessment to examine patterns of eighth-grade students’ calculator-use behaviors and the content of calculator input across a series of items. Sequences of keystrokes executed on the onscreen calculator by test takers were compared to reference sequences identified by content experts as proficient and efficient use to infer how well and how consistently the calculator was used. Results indicated that calculator-use behaviors and content differed by item characteristics. Students were more likely to use calculators on calculation-demanding items that involve intensive and complex computations than on items that involve simple or no computation. Using the calculator on more calculation-demanding items and using it in a manner that is more efficient and more similar to reference sequences on these items were related to higher mathematical proficiency. Findings have implications for assessment design and can be used in educational practices to provide educators with actionable process-related information on tool use and problem solving. © 2022 Elsevier Ltd",TextMining
"Drought is the most widespread natural disaster in the world. How to monitor regional drought scientifically and accurately has become a hot topic for many scholars. In this paper, Geographically Integrated Dryness Index (GIDI) was integrated from an assortment source including Precipitation Condition Index (PCI), Temperature Condition Index (TCI), Soil Moisture Condition Index (SMCI), Vegetation Condition Index (VCI), and Standardized Precipitation Evapotranspiration Index (SPEI) (as the dependent variable) based on geographically weighted regression method. Besides, the comprehensive drought situation and changing trends in China from 2001 to 2019 were also examined. The results showed that (1) GIDI has excellent performance in monitoring medium- and long-term droughts and the monitoring results shows 2003, 2016, and 2019 were relatively wet years, while 2007, 2009, and 2011 were major drought years, and spring and March were the most frequent droughts season and month, respectively, and (2) except for the middle and upper reaches of the Yellow River and Northeastern China, which have a tendency to become wet, other places have a tendency to fluctuating dry. This study took advantage of simple and efficient methods to integrate existing indices to obtain a new index for monitoring a wider range of droughts, taking into account the physical mechanism of drought formation and the time scale of drought development, so it can scientifically evaluate the spatial and temporal distribution characteristics of drought and changes. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TextMining
"For widening the therapeutic options for Candida management, the druggability of Candida proteome was systematically investigated using an innovative pipeline of high-throughput data mining algorithms, followed by in vitro validation of the observations. Through this exercise, HIV-1 protease was found to share structural similarity with secreted aspartyl protease-3 (SAP3), a virulence protein of Candida. Using the molecular fingerprint of HIV-1 protease inhibitor GRL-09510, we performed virtual screening of peptidomimetic library followed by high-precision docking and MD simulations for discovery of SAP inhibitors. Wet-lab validation of the four shortlisted peptidomimetics revealed that two molecules, when used in combination with fluconazole, could significantly reduce the dosage of fluconazole required for 50% inhibition of Candida albicans. The SAP inhibitory activity of these peptidomimetics was confirmed through SAP assays and found to be on par with pepstatin A, a known peptidomimetic inhibitor of aspartyl proteases. © 2022 Wiley Periodicals LLC.",TextMining
"Performance prediction is an important research facet of educational data mining. Most models extract student behavior features from campus card data for prediction. However, most of these methods have coarse time granularity, difficulty in extracting useful high-order behavior combination features, dependence on 6 historical achievements, etc. To solve these problems, this paper utilizes prediction of grade point average (GPA prediction) and whether a specific student has failing subjects (failing prediction) in a term as the goal of performance prediction and proposes a comprehensive performance prediction model of college students based on behavior features. First, a method for representing campus card data based on behavior flow is introduced to retain higher time accuracy. Second, a method for extracting student behavior features based on multi-head self-attention mechanism is proposed to automatically select more important high-order behavior combination features. Finally, a performance prediction model based on student behavior feature mode difference is proposed to improve the model’s prediction accuracy and increases the model’s robustness for students with significant changes in performance. The performance of the model is verified on actual data collected by the teaching monitoring big data platform of Xi’an Jiaotong University. The results show that the model’s prediction performance is better than the comparison algorithms on both the failing prediction and GPA prediction. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",TextMining
"Software defect prediction (SDP) plays an important role in allocating testing resources and improving testing efficiency. Multi-source cross-project defect prediction (MSCPDP) based on transfer learning refers to transferring defect knowledge from multiple source projects to the target project. MSCPDP has drawn increasing attention from academic and industry communities, and some MSCPDP methods have been proposed. However, most existing MSCPDP models are not open-source. MSCPDPLab replicates nine state-of-the-art MSCPDP models with unified interface and integrates the processes of data loading, model training and testing, and performance evaluation (including 13 performance measures). This paper describes the toolbox's functionalities and presents its ease of use. © 2022 The Author(s)",TextMining
"Agrometeorological data is important in agricultural research, especially in agronomy and crop science, for investigating genotype by environment interactions. The AgERA5 dataset from the Copernicus Climate Data Store provides free and public access to global gridded daily agrometeorological data, from 1979 to present, with ready to use variables tailored for agricultural and agro-ecological studies. We developed the R package ag5Tools, which provides a simplified interface for downloading and extracting AgERA5 data. The package facilitates extracting time-series data for sets of geographic points in a format that can be conveniently used in statistical models applied in agricultural research. The use of the package is demonstrated with a synthetic dataset of multi-location trials in Arusha, Tanzania. © 2022 The Author(s)",TextMining
"The operation of intelligent coal mining in complex geological environment is still unable to realize automation. In order to realize the autonomous cutting of fully mechanized mining equipment and improve coal production, a mining and transportation equipment dynamic advancement path planning method based on spatial kinematics coordinate deduction prediction and real-time correction prediction of coal-rock state identification of equipment cutting current index are proposed. Firstly, the spatial motion law of the mining and transportation equipment is analyzed, and the mathematical model of the spatial motion of the mining and transportation equipment is established. The relationship between the adjustment of the shearer rocker arm and the pose change of the scraper conveyor is determined, and the coordinate deduction model of the spatial advancement position of the equipment is determined, which provides a theoretical basis for the advancement path planning of the mining and transportation equipment. Then, on the basis of the mathematical model construction, combined with real geological data and equipment information, the three-dimensional dynamic planning of the advancement path of the mining and transportation equipment is carried out from the two dimensions of the horizontal advancement direction and the shearer walking direction. At the same time, the relationship between the cutting current index of shearer and the state recognition of coal-rock mass is analyzed, and the coal-rock mass state identification of cutting current and the adjustment of rocker arm model is constructed, and the real-time dynamic correction of three-dimensional path is carried out, so that the planned path can better adapt to the sudden change of real geological environment. Then, using the unity3d virtual reality technology, a simulation system for the horizontal advancement path planning of the virtual mining and transportation equipment is constructed, which simulates the real advancement operation process of the mining and transportation equipment and conducts advancement training. Finally, the dynamic advancement scheme update prediction based on the existing actual cutting but ahead of the actual cutting is realized in the virtual scene, and the optimal scheme is transmitted into the existing prediction cutting system to guide the actual physical equipment mining. The path planning method can control the coordinate position error of the advancing cutting path within 15 mm, which provides ideas for the research on the advancing path planning of fully mechanized equipment. © 2022, Society for Mining, Metallurgy & Exploration Inc.",TextMining
"Tensors are multi-dimensional mathematical objects that allow to model complex relationships and to perform decompositions for analytical purpose. They are used in a wide range of data mining applications. In social network analysis, tensor decompositions give interesting insights by taking into consideration multiple characteristics of data. However, the power-law distribution of such data forces the decomposition to reveal only the strong signals that hide information of interest having a lighter intensity. To reveal hidden information, we propose a method to stratify the signal, by gathering clusters of similar intensity in each stratum. It is an iterative process, in which the CANDECOMP/PARAFAC (CP) decomposition is applied and its result is used to deflate the tensor, i.e., by removing from the tensor the clusters found with the decomposition. As the CP decomposition is computationally demanding, it is also necessary to optimize its algorithm, to apply it on large-scale data with a reasonable execution time, even with the several executions needed by the iterative process of the stratification. Therefore, we propose an algorithm that uses both dense and sparse data structures and that leverages coarse and fine grained optimizations in addition to incremental computations in order to achieve large scale CP tensor decomposition. Our implementation outperforms the baseline of large-scale CP decomposition libraries by several orders of magnitude. We validate our stratification method and our optimized algorithm on a Twitter dataset about COVID vaccines. © 2022 Elsevier Ltd",TextMining
"Preprocessing is an important part of any opinion mining method since it prepares the text reviews for classification. In preprocessing, string matching is crucial to remove matched unnecessary text from the input data. The majority of contemporary string matching algorithms use the character comparison method, which analyzes each character independently and takes more time. Furthermore, establishing the degree of similarity between the sub-string and pattern text is challenging in approximate matching algorithms that expect a full match. We propose an algorithm, namely ‘review preprocessing using Coiflet wavelet back-propagation neural network (RPP-COIF-BPN),’ for effective review preprocessing in order to address these challenges and limitations. This RPP-COIF-BPN algorithm uses a combination of a neural network and an exact string matching technique to filter irrelevant information from the input reviews. The proposed method is driven by the Coiflet wavelet; specifically, the 2D Coiflet process is performed in both directions to provide more energetic stop-word features, which increases string matching accuracy. The exact match comparison is performed only for the words matched in the BPN network, as opposed to traditional exact pattern matching, resulting in a considerable reduction in pattern matching time. The proposed method achieves 97.53% accuracy, and it consumes significantly less time of 2.08 s when compared with other string matching algorithms. The results indicated that the proposed RPP-COIF-BPN-based string matching performance is effective for preprocessing e-commerce reviews for opinion mining in a short amount of time with high testing accuracies. © 2022, King Fahd University of Petroleum & Minerals.",TextMining
"Open-pit mines are an important source of atmospheric particulate matter (PM) owing to the constant earth-moving and crushing. The well-known association between high PM concentrations and adverse health effects has made the permanent control of fugitive emissions from mines a public health concern. Nevertheless, the large size of these mines renders this task difficult and expensive to perform with regulatory apparatuses; subsequently, the mining industry requires other technologies with a suitable quality/price ratio. In this study, a novel methodology for the space–time monitoring of PM concentrations in open-pit mines using mobile low-cost sensors (LCSs) is proposed. The study was carried out in the renowned mine of Riotinto for three years (2019–2021). It included a detailed calibration of the mobile LCSs that fulfilled the European/US standards. Time tendency diagrams determined the maximum PM concentrations emitted (≈1600μg PM 10/m3) and also the seasonal variations. The spatial distribution also revealed the main sources of PM within the mine, which were the mining pit, mineral processing plant, spoil heap of fine materials, and main mining tracks. Finally, the integration of these data together with meteorological information allowed the discovery of the routes of escape of fugitive emissions from the mine toward nearby populations: toward W-SW, with concentrations primarily ranging between 50–100 μg PM10/m3 and 20–50 μg PM2.5/m3. The results of this research are important as mobile LCSs seem to solve the issue of fugitive emissions monitoring in mining ambiances and will aid the exploitations to become more environmentally friendly. © 2022 The Author(s)",TextMining
"Water quality is an important issue because of its relationship to humans and other living organisms. Predicting water quality parameters is very important for better management of water resources. The decision tree is one of the data mining methods that can create rules for classifying and predicting data using a tree structure. The purpose of this study is to use data mining techniques to investigate and predict the parameters of soluble phosphorus and oxygen in Lake Erie to achieve this purpose. The Classification And Regression Tree (CART) model is compared with the Chi-squared Automatic Interaction Detector (CHAID) model and the Quick Unbiased Efficient Statistical Trees (QUEST) model with the C5 model. Comparison and review of these models to express their applicability to identify water quality parameters are conducted. The results show that decision tree methods with the help of hydrochemical parameters can classify and predict water quality with high accuracy and in a short time. The number of available data is 327. To check the accuracy of the models, the difference between the observed data and the predicted data is used. In the prediction of dissolved oxygen, 214 cases with the CART model and 185 cases with the CHAID model differ by less than 2 units from the observed data. For phosphorus, 245 cases in the CART model and 237 cases in the CHAID model differ less than 0.2 the predicted data with the observed data. Therefore, the accuracy of the CART model is better. The prediction of 256 phosphorus parameter group numbers and 230 dissolved oxygen parameter group numbers with the C5 algorithm is correct. The results show that CART model is better than CHAID model in predicting data, and C5 model is better than QUEST model in predicting group numbers. © 2022, The Author(s), under exclusive licence to Springer Nature Switzerland AG.",TextMining
"Autonomous driving related researches require the analysis and usage of massive amounts of driving scenario data. Compared to raw data collected by sensors, scenario data provide a preliminary abstraction of driving tasks and processes, explicitly integrate information about the road environment and the dynamic and static attributes of traffic participants, making it easier to conduct task understanding and decision making. However, many existing driving scenario datasets have the following two problems. First, it is not clear which data fields need to be recorded for driving scenarios. The data storage formats and organization standards are inconsistent. Second, the datasets cannot establish driving scenario indexing effectively. Existing datasets are sparsely annotated and difficult to index, which is detrimental to data sampling and extraction for machine learning process, thus hindering efficient fusion and reuse. In this paper, we propose MetaScenario, a framework for driving scenario data. We describe driving scenarios and design the centralized and unified data framework for the storage, processing, and indexing of scenario data based on relational database. The concept of atom scenario is proposed and characterized using semantic graphs. We also annotate and classify behaviors and interactions of traffic participants in atom scenarios by extracting the spatiotemporal evolution of semantic information. The annotation facilitates the indexing and extraction of data. The scenario datasets are further evaluated via the data distribution and annotation statistics. MetaScenario can provide researchers with convenient tools for scenario data extraction and important analytical references. © 2016 IEEE.",TextMining
"Alzheimer's disease (AD) predominantly affects the elderly population with symptoms including, but not limited to, cognitive impairment and memory loss. Predicting AD and mild cognitive impairment (MCI) can lengthen the lifespan of patients and help them to access necessary medical resources. One potential approach to achieve an early diagnosis of AD is to use data mining techniques which explore various characteristic traits related to MCI, cognitively normal (CN), and AD subjects to build classifiers that reveal important contributors to the disease. These classifiers are used by physicians during the AD diagnostic process in a clinical evaluation. In this research, we compare between different data mining algorithms through empirical data approach to deal with the AD diagnosis. Experimental evaluation, using attribute selection methods, and classifiers from rule induction and other classification techniques have been conducted on data from the Alzheimer's Disease Neuroimaging Initiative (ADNI-MERGE). The results illustrate the good classification performance of classifiers with rules in predicting AD.  © 2023 World Scientific Publishing Co.",TextMining
"Data over the internet has been increasing everyday, and automatic mining of essential information from an enormous amount of data has become a challenging task today for an organisation with a huge dataset. In recent years, the prominent technology in the domain of Information Technology (IT) is big data, which is unstructured data that solves the computational complexity of classical database systems. The data is fast and big and typically derived from multiple and independent sources. The three main challenges are data accessing, semantics, and domain knowledge for various big data utilisations and complexities raised by big data volumes. One of the major limitations is the classification of big data. This paper introduces well-defined classification methodologies employed for big data classification. This paper reviews 50 research papers based on classification methods of big data, and such methodologies are primarily categorised into six different categories, namely K-Nearest Neighbor (KNN), Support Vector Machine (SVM), Fuzzy-based method, Bayesian-based method, Random Forest, and Decision Tree. In addition, detailed analysis and discussion are carried out by considering classification techniques, dataset utilised, evaluation metrics, semantic similarity measures, and publication year. In addition, research gaps and issues for several traditional big data classification techniques are explained to expand investigators' works to provide effective big data management.  © 2023 World Scientific Publishing Co.",TextMining
"Automatic extraction of relations between gene mutations and cancer entities occurring in the cancer literature using text mining can rapidly provide vital information to support precision cancer medicine. However, mutation-cancer relation extraction is more challenging than general relation extraction from free text, since it is often not possible without cancer-specific background knowledge and thus the model replies on a deeper understanding of complex surrounding tokens. We propose a deep learning model that jointly extracts mutations and their associated cancers. Background knowledge comes from two different knowledge bases which store different types of information about mutations. Given the different ways in which knowledge is stored in these two resources, we propose two separate methods for embedding knowledge, namely sentence-based knowledge integration and attribute-aware knowledge integration. The evaluation demonstrated that our model outperforms a number of baseline models and gains 96.00%, 92.57% and 94.57% F1 scores on three public datasets, EMU BCa, EMU PCa, and BRONCO, thus illustrating the effectiveness of our knowledge integration approach. The auxiliary experiments show that our models can utilize more informative text from the KBs and link the mutations to their corresponding cancer disease although the input text provides insufficient context.  © 2022 IEEE.",TextMining
"Multi-view subspace clustering has received widespread attention. Since data may violate the linear assumption in many practical applications, multi-view subspace clustering methods based on deep neural network are developed in recent years. However, most existing DNN based methods only focus on the utilization of the deepest features (i.e., features extracted from the deepest layer), regardless of the informative shallow features (i.e., features extracted from the shallow ones) and the fusion of multi-scale features (i.e., deep and shallow features), which may make their clustering performance suboptimal. In addition, these methods usually do not impose appropriate constraints on the extracted features to ensure that they can maintain the inherent local geometric structure of multi-view data, which is unfavorable for subspace learning. To deal with the limitations mentioned above, we propose a novel DNN based subspace clustering method for multi-view data called Deep Multi-view Subspace Clustering via Structure-preserved Multi-scale Features Fusion. Specifically, the graph knowledge of multi-view data is introduced to constrain the extracted features so that they have the structure-preserved property. Simultaneously, by fully exploiting the consistency of the extracted structure-preserved multi-scale features, DMSC-SMFF can learn the more discriminative common shared subspace representation, which can be employed by the spectral clustering module to obtain clustering results. Moreover, the optimization algorithm based on the Alternating Direction Method (ADM) is developed to optimize our objective function. Furthermore, DMSC-SMFF can also be applied to single-view data. Plentiful experimental results on five benchmark datasets demonstrate the effectiveness and superiority of the proposed method. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",TextMining
"Ozone pollution in China has gradually increased, attracting extensive attention. Existing studies on ozone pollution typically take environmental and chemical perspectives. As air pollution is closely related to social and economic activities, it is also important to study ozone pollution from a socioeconomic perspective. Using the association rule mining technique, we uncovered hidden patterns between ozone variance and socioeconomic factors in macro-, meso-, and micro-scenarios in 297 Chinese cities. We found that the acceleration of urbanization and industrialization has indeed aggravated urban ozone pollution. The supply of water and power resources may be a significant factor influencing urban ozone pollution. Transportation hub cities with more developed economies and industries are more likely to suffer from ozone pollution in summer and autumn. Human behavior is a critical factor influencing the weekly variance in ozone concentration during weekdays and weekends. The influence of plant-derived VOC emissions on the formation of ozone cannot be overlooked. Our results deepen the understanding of ozone pollution in Chinese cities, and we provide corresponding policy recommendations to alleviate ozone pollution and improve air quality. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TextMining
"Background: Similar to clinical palpation, Ultrasound elastography (USE) helps distinguish between tissues by providing information on their elasticity. While it has been widely explored and has been applied to many body organs, USE has not been studied as extensively for application in neurosurgery. The current systematic review was performed to identify articles related to the use of interoperative USE in neurosurgery. Methods: Search included MEDLINE(R) database. Only original peer-reviewed full-text articles were included. No language or publication year restrictions were imposed. Two independent reviewers assessed the search results for relevance. The identified articles were screened by title, abstract, and full-text review. Results: Seventeen articles were included in the qualitative analysis and 13 articles were related to oncology, epilepsy (n = 3), and spine (n = 1). In oncology, USE was found useful in defining tumor stiffness, aiding surgical planning, detecting residual tumors, discriminating between tumor and brain tissue, and differentiating between different tumors. In epilepsy, USE could improve the detection of epileptogenic foci, thereby enhancing the prospect of complete and safe resection. The application in spinal surgery was limited to demonstrating that a compressed spinal cord is stiffer than the decompressed one. Conclusions: USE was found to be a safe, quick, portable, and economic tool that was a useful intraoperative adjunct to provide information corresponding to a variety of neurosurgical diseases, at different stages of surgery. This review describes the current intraoperative neurosurgical applications of USE, the concept of elasticity, and different USE modalities as well as the technical challenges, limitations, and possible future implications. © 2022 Elsevier Inc.",TextMining
"Streaming data is ubiquitous in modern machine learning, and so the development of scalable algorithms to analyze this sort of information is a topic of current interest. On the other hand, the problem of l1-penalized least-square regression, commonly referred to as LASSO, is a quite popular data mining technique, which is commonly used for feature selection. In this work, we develop a homotopy-based solver for LASSO, on a streaming data context, that massively speeds up its convergence by extracting the most information out of the solution prior receiving the latest batch of data. Since these batches may show a non-stationary behavior, our solver also includes an adaptive filter that improves the predictability of our method in this scenario. Besides different theoretical properties, we additionally compare empirically our solver to the state-of-the-art: LARS, coordinate descent and Garrigues and Ghaoui’s data streaming homotopy. The obtained results show our approach to massively reduce the computational time require to convergence for the previous approaches, reducing up to 3, 4 and 5 orders of magnitude of running time with respect to LARS, coordinate descent and Garrigues and Ghaoui’s homotopy, respectively. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"In Remote Sensing(RS) data analysis, Remote Sensing Change Detection(CD) is an important technology. The existing Remote Sensing Change Detection(RS-CD) methods do not fully consider the advantages and disadvantages of Convolution and Transformer in feature extraction, which will restrict the overall performance of the network to a certain extent. Therefore, this paper proposes a Dual Branch Feature Guided Aggregation Network composed of convolutional neural network(CNN) and Transformer. In the encoding stage, based on the respective characteristics of Convolution and Transformer, a dual-branch backbone network is constructed to extract the spatial information and semantic information of the image respectively; And through the Feature Guidance Aggregation Module, the two branches can guide each other for feature mining, so as to avoid the occurrence of false detection and missed detection of change areas due to insufficient fusion to the greatest extent. Finally, in the decoding stage, the different levels of features extracted by the two branches are fully used for fusion and decoding. And the experiment shows that compared with the existing methods, the mean intersection over union(MIoU) index on the four public datasets are improved by 1.25%, 1.55%, 1.38% and 1.71%. © 2022 The Author(s)",TextMining
"Worldwide cities are becoming more sustainable and are being monitored using data collection techniques at various geographical levels. Given the growing volume of data, there is a need to identify challenges associated with the processing, visualization, and analysis of the generated data from an urban scale. This study proposes a framework to investigate the capabilities of dimensionality reduction techniques (t-SNE, and UMAP) applied to city-scale data to identify key features of high consumption and generation areas based on building characteristics. The analysis is performed on measured data from 2735 postcodes consisting of 72000 households/buildings from a city in the Netherlands. The evaluation results showed that the UMAP's algorithm mean sigma quickly approaches a threshold of 0.6 at n_neighbor values of 50 and the low dimensional shape does not change with increasing values. Whereas the t-SNE's mean sigma value increases continuously with the increasing perplexity value, implying that t-SNE is significantly more sensitive to the perplexity parameter. The UMAP algorithm was used to extract information about the high photovoltaic generation and consumption regions. The proposed framework will assist grid operators and energy planners in extracting information from energy consumption data at the neighbourhood level by utilizing high dimensional reduction techniques. © 2022 The Author(s)",TextMining
"Rhodolith beds comprise a highly biodiverse and productive ecosystem that dominates the mid and outer shelf of the tropical eastern South American coast. Conservation planning and specific conservation measures are lacking, while impacts over rhodolith beds are escalating due to carbonate mining, and other activities such as oil and gas exploration and seaport dredging. Primary data detailing the spatial extent and characteristics of rhodolith beds within the Brazilian Economic Exclusive Zone (EEZ) depend on extensive acoustic surveys and ground truthing, which are costly and logistically challenging. Here, we compiled an extensive database of rhodolith occurrence from the scientific and grey literature. ‘Ensemble’ Ecological Niche Modelling (EENM) techniques predicted the total area suitable for rhodoliths across the Brazilian EEZ and gave insight into the environmental variables driving their distribution in this region. Using the suitability map produced from the ensemble model, we compared rhodolith spatial overlap with oil and gas and mining activities and marine protected areas (MPAs). Light, saturation state of calcite and minimum temperature were the main predictors of rhodolith occurrence. Rhodoliths were predicted to occur over ∼167,379 km2 of the Brazilian EEZ largely (∼95%) in the Amazonas (AM), Northeastern Brazil (NB) and Eastern Brazil (EB) ecoregions. The representation of rhodoliths in areas with mining and oil and gas activities was similar for the EEZ as a whole. Within each ecoregion, representation of rhodolith beds in MPAs is negatively related with their overlap with mining and oil and gas activities. Eastern Brazil (EB) stood out as the area with the highest representation of rhodoliths under threat, in an area 6.7 times larger than those represented in MPAs, including the south region of the largest continuous extension of rhodolith beds, in the Abrolhos bank. Within the NB and AM ecoregions, which are under growing industrialization, rhodolith beds are poorly represented in no-take MPAs. Our results provide a basis for moving toward more effective management and conservation strategies for rhodolith beds in Brazil's EEZ. © 2022 Elsevier Ltd",TextMining
"The interdisciplinary field of knowledge discovery and data mining emerged from a necessity of big data requiring new analytical methods beyond the traditional statistical approaches to discover new knowledge from the data mine. This emergent approach is a dialectic research process that is both deductive and inductive. The data mining approach automatically or semi-automatically considers a larger number of joint, interactive, and independent predictors to address causal heterogeneity and improve prediction. Instead of challenging the conventional model-building approach, it plays an important complementary role in improving model goodness of fit, revealing valid and significant hidden patterns in data, identifying nonlinear and non-additive effects, providing insights into data developments, methods, and theory, and enriching scientific discovery. Machine learning builds models and algorithms by learning and improving from data when the explicit model structure is unclear and algorithms with good performance are difficult to attain. The most recent development is to incorporate this new paradigm of predictive modeling with the classical approach of parameter estimation regressions to produce improved models that combine explanation and prediction. © 2022 The Authors",TextMining
"We propose a scheme of all-optical clock recovery (AOCR) based on ultrahigh-order mode locking by a semiconductor optical amplifier (SOA), which can directly extract the optical clock from non-return-to-zero (NRZ) pseudo-random-binary-sequence (PRBS) data. Firstly we demonstrate that the active mode locking system can generate stable high repetition frequency ultrashort pulse train, and adjusting the modulator's bias voltage and polarization states one can realize doubling the repetition frequency. Due to robust mode locking configuration, we successfully realize the AOCR up to 40 Gbits/s from the PRBS (231-1) NRZ optical signals without NRZ to RZ conversion, while the signal to noise ratio of the recovered optical clock is more than 20 dB with high stability, and the pulse width is short as 1.85 ps. Owing to the ultrafast nonlinear polarization rotation in the SOA, our scheme can execute AOCR for data rate of 100 Gbits/s and more. © 2022 Elsevier B.V.",TextMining
"Landscape-scale conservation that considers metapopulation dynamics will be essential for preventing declines of species facing multiple threats to their survival. Toward this end, we developed a novel approach that combines occurrence records, spatial–environmental data, and genetic information to model habitat, connectivity, and patterns of genetic structure and link spatial attributes to underlying ecological mechanisms. Using the threatened northern quoll (Dasyurus hallucatus) as a case study, we applied this approach to address the need for conservation decision-making tools that promote resilient metapopulations of this threatened species in the Pilbara, Western Australia, a multiuse landscape that is a hotspot for biodiversity and mining. Habitat and connectivity were predicted by different landscape characteristics. Whereas habitat suitability was overwhelmingly driven by terrain ruggedness, dispersal was facilitated by proximity to watercourses. Although there is limited evidence for major physical barriers in the Pilbara, areas with high silt and clay content (i.e., alluvial and hardpan plains) showed high resistance to dispersal. Climate subtlety shaped distributions and patterns of genetic turnover, suggesting the potential for local adaptation. By understanding these spatial–environmental associations and linking them to life-history and metapopulation dynamics, we highlight opportunities to provide targeted species management. To support this, we have created habitat, connectivity, and genetic uniqueness maps for conservation decision-making in the region. These tools have the potential to provide a more holistic approach to conservation in multiuse landscapes globally. © 2022 The Authors. Conservation Biology published by Wiley Periodicals LLC on behalf of Society for Conservation Biology.",TextMining
"This paper throws light on the bibliometric review of the impact of coal mining in India over the past 50 years, emphasizing environmental, especially water-related impacts. The data were refined from the Web of Science database and analyzed in a bibliometric map visualization software tool, VOSviewer, to grasp the research focus, status quo and analyze the trend and direction of the work being carried out in this area. The methodology was covered in three phases: search and document selection, software and data extraction, and analysis of results and trends. The study results indicated that (i) the publication has increased in the past two decades (2001–2021) with a steep increase in the period from 2010 to 2021 with 74.68% article types documents and a mere 7.74% review documents. (ii) In India, the significant contribution is made by the Indian Institute of Technology (Indian School of Mines), Dhanbad with Department of Science and Technology as a primary funding agency. (iii) The bibliometric map of co-occurrence of author keywords showed that keywords relating to the “pollution” (connected to air, water) from “Jharia coalfield” have highest occurrences in the relevant published works of literature and topics like “reclamation,” “mine spoil,” and application of approaches like “remote sensing and GIS” have lower linkage strengths in general. (iv) The result of the co-citation network study has marked the most significant authors and the highly cited sources of the database revealing Ghose M.K. and Singh A.K. as among the most cited authors with citations more than 150 in the field of our interest. (v) The trend of publication in the research area of Water Resources showed a significant increase after 2015. The keyword occurrence map reveals that water quality studies have been extensively studied, but quantifications of the coal mining-induced changes in water regimes at river basin scales are absent. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TextMining
"Spatiotemporal graph neural networks (GNNs) have been used successfully in traffic prediction in recent years, primarily owing to their ability to model complex spatiotemporal dependencies within irregular traffic networks. However, the feature extraction processes in these methods are limited in their exploration of the inner properties of traffic data. Specifically, graph and temporal convolutions are local operations and can hardly utilize information from wider ranges, which may affect the long-term prediction performance of such methods. Furthermore, deep spatiotemporal GNNs easily suffer from poor generalization owing to overfitting. To address these problems, this study presents a novel traffic prediction method that integrates self-supervised learning and self-distillation into spatiotemporal GNNs. First, a self-supervised learning module is used to explore the knowledge from the input data. An auxiliary task based on temporal continuity is designed to capture the contextual information in traffic data. Second, a self-distillation framework is developed as an implicit regularization approach that transfers knowledge from the model itself. The combination of self-supervision and self-distillation further mines the knowledge from the data and the model, and the generalization ability and stability of the prediction model can be improved. The proposed model achieved superior or competitive results compared with several strong baselines on six traffic prediction datasets. In particular, the maximum performance improvement ratios for the six datasets were 3.0% (MAE), 5.2% (RMSE), and 3.8% (MAPE). These results demonstrate the effectiveness of the proposed method.  © 2000-2011 IEEE.",TextMining
"Laser powder bed fusion (LPBF) has opened the window of in-situ alloying elemental powders for specific engineering and biomedical applications. However, since the LPBF process is non-linear, and the current numerical models are still at the experimental stage it is obligatory to determine the optimum process parameters for each powder composition. The current experimental data described the effects of laser powers and scanning speeds on fused tracks and layers produced using Ti10Mo6Cu powder blend. Fused single tracks were produced at varying scanning speeds and laser powers. The process parameter that falls within the conduction mode threshold was used to produce double layers at varied hatch distances. Layers were rescanned at an offset distance of half the hatch distances. The fused tracks and layers were metallurgically prepared according to the Struers protocol and etched with Kroll's reagent. Optical and scanning electron microscopes were used to measure the width (W), depth of penetration (D), and height (H) of the fused tracks to obtain the data for characterizing the geometry of the fused tracks. Data on the surface quality of the fused layers were extracted with a Surftest SJ-210 portable surface roughness tester, while microhardness test data was extracted using a FM-700 Digital Vickers Microhardness Tester. The data obtained could be used for validating numerical and analytical models, and for predicting fused track profiles. Data that originated from the layers could be used to predict the morphology of layers and the dispersion of elements during in-situ alloying. The methodology applied could be used by other researchers to determine the process parameters for other powder blend compositions and increase the materials database for the LPBF process. © 2022 The Author(s)",TextMining
"DNA double-strand breaks (DSBs) are repaired through three major pathways: Non-Homologous End-Joining (NHEJ), Microhomology-Mediated End-Joining (MMEJ), and Homology-Directed Repair (HDR), each requiring a specific set of diverse proteins. Such pathways and their proteins have been studied in model organisms, including arthropods; however, DSB repair pathways are scarcely described in Crustacea, a taxon that includes the commercially valuable penaeid shrimps (Crustacea: Decapoda: Penaeidae). In this work, transcriptome and proteome databases of Penaeus vannamei and other Crustacea species were scrutinized for each protein of the NHEJ pathway. The structural and functional attributes of such proteins in penaeids were determined using bioinformatics. Additionally, the expression of the NHEJ-related Ku70, Ku80, DNA-PKcs, DNA ligase 4 (Lig4), and HDR- and MMEJ-related protein transcripts were assessed in P. vannamei gills, midgut gland, hemocytes, and muscle by RT-PCR. DSB repair protein transcripts were found expressed in the four assayed tissues, particularly in the gills and midgut gland. Among DSB repair proteins, all the analyzed transcripts of proteins related to the NHEJ pathway were present in gills. To the best of our knowledge, this is the first report on the expression of DSB repair proteins in Decapoda. Together, proteomic, transcriptomic, and expression data suggest the functionality of NHEJ, HDR, and MMEJ pathways in P. vannamei and other decapods. The information presented here contributes to understanding the response to DSB breaks in shrimps, describing possible outcomes in oxidative stress studies and also in the designing of gene editing strategies, which have not been developed in Penaeidae. © 2022 Elsevier Inc.",TextMining
"Deep matrix factorizations (deep MFs) are recent unsupervised data mining techniques inspired by constrained low-rank approximations. They aim to extract complex hierarchies of features within high-dimensional datasets. Most of the loss functions proposed in the literature to evaluate the quality of deep MF models and the underlying optimization frameworks are not consistent because different losses are used at different layers. In this paper, we introduce two meaningful loss functions for deep MF and present a generic framework to solve the corresponding optimization problems. We illustrate the effectiveness of this approach through the integration of various constraints and regularizations, such as sparsity, nonnegativity and minimum-volume. The models are successfully applied on both synthetic and real data, namely for hyperspectral unmixing and extraction of facial features. © 2022 Elsevier Ltd",TextMining
"Travel mode choice prediction is essential for transportation planning and travel demand prediction. One of the conventional travel survey methods is collecting data over landline telephones, which lacks efficiency because of financial and time resource needs. In this regard, smartphone-assisted travel surveys can be applied to overcome the mentioned deficiencies. Smartphone-assisted travel surveys allow respondents to record GPS data, travel purpose, and travel mode via an application, simplifying the survey process. With various sensors equipped, the precision of data is ensured. Based on the survey results, varied approaches have been seen to travel mode identification. For this study, a travel survey was conducted in Hangzhou, China, supported by the smartphone application TraceRecord integrated with online mapping services. Several steps were undertaken to recognize different kinds of travel modes. First, preprocessing was adopted to screen out defective logs. With the employment of A-Map Application Programming Interface (API), trajectory segmentation was substantially boosted. Then, separately, features related to velocity, acceleration, and heading were extracted from the survey data. To achieve better accuracy and efficacy, two classification algorithms—support vector machine (SVM) and gradient boosting decision tree (GBDT)—were applied to model the travel mode identification problem. Compared with the SVM, GBDT produced a higher prediction accuracy of 90.16%. Further analysis was implemented based on the results of the GBDT model, and velocity-related features contributed the most to the identification problem. The study explores the possibility of applying travel mode recognition in real-world conditions and discusses further mining of the survey data. © National Academy of Sciences: Transportation Research Board 2022.",TextMining
"Operations in copper sulfide flotation plants (CSFP) are complex and governed by several variables such as available technologies, reagents, and environmental conditions. However, few investigations are related to studying the microbial communities. These aspects provide a reason to compare the bacterial communities of two CSFP operated with freshwater (FwFlo) and seawater (SwFlo), and study whether indigenous bacteria could be used as pyrite bioreagents. Analyses were determined through next-generation sequencing by Illumina MiSeq System and conducted throughout the entire process: (i) minerals before and after grinding; (ii) final concentrate and concentrate thickener overflow; (iii) final tailings and tailings thickener overflow; and (iv) intake water. Bacterial strains from both plants were tested as potential bioreagents, given their tendency to adhere to pyrite after 5 min. In both CSFP, Proteobacteria (relative abundance from 45.48% to 79.22%), followed by Bacteroidetes (9.37%–44.7%), were the most abundant phyla. Regarding species, Algoriphagus olei (11.35%–43.52%) was present exclusively in FwFlo samples in contact with process water and absent in the mineral before grinding, where Cupriavidus metallidurans (16.05%) and Pseudomonas_uc (11.79%) predominated. In SwFlo samples, Marinobacter flavimaris (3.47%–41.1%), and GU061212-s (10.92%–27.63%), were the most abundant microorganisms. All of them were also detected in intake seawater. The strains with the highest adhesion rate (from 29.84% ± 0.14–100%) were phylogenetically identified as species of the genera Marinobacter, Pseudomonas, Idiomarina, Halomonas, Bacillus, Aerocuccus, and Peribacillus. Our results reveal that bacterial communities are critically dependent on process waters during mining activities, and our data depicted that indigenous bacteria could be used as potential pyrite bioreagents, evidenced by a high adhesion rate. It is thus possible to propose that different indigenous bacterial strains could be considered as new bioreagents to reduce the impact of conventional flotation reagents on health from an environment friendly perspective. © 2022 Elsevier Inc.",TextMining
"Conventional rule learning algorithms aim at finding a set of simple rules, where each rule covers as many examples as possible. In this paper, we argue that the rules found in this way may not be the optimal explanations for each of the examples they cover. Instead, we propose an efficient algorithm that aims at finding the best rule covering each training example in a greedy optimization consisting of one specialization and one generalization loop. These locally optimal rules are collected and then filtered for a final rule set, which is much larger than the sets learned by conventional rule learning algorithms. A new example is classified by selecting the best among the rules that cover this example. In our experiments on small to very large datasets, the approach’s average classification accuracy is higher than that of state-of-the-art rule learning algorithms. Moreover, the algorithm is highly efficient and can inherently be processed in parallel without affecting the learned rule set and so the classification accuracy. We thus believe that it closes an important gap for large-scale classification rule induction. © 2023, The Author(s).",TextMining
"In the medical field, the clinical notes taken by the doctor, nurse, or medical practitioner are considered to be one of the most important medical documents. These documents hold information regarding the patient including the patient's current condition, family history, disease, symptoms, medications, lab test reports, and other vital information. Despite these documents holding important information regarding the patients, they cannot be used as the data are unstructured. Organizing a huge amount of data without any mistakes is highly impossible for humans, so ignoring unstructured data is not advisable. Hence, to overcome this issue, the web scraping method is used to extract the clinical notes from the Medical Transcription (MT) samples which hold many transcripted clinical notes of various departments. In the proposed method, Natural Language Processing (NLP) is used to pre-process the data, and the variants of the Term Frequency-Inverse Document Frequency (TF-IDF)-based vector model are used for the feature selection, thus extracting the required data from the clinical notes. The performance measures including the accuracy, precision, recall and F1 score are used in the identification of disease, and the result obtained from the proposed system is compared with the best performing machine learning algorithms including the Logistic Regression, Multinomial Naive Bayes, Random Forest classifier and Linear SVC. The result obtained proves that the Random Forest Classifier obtained a higher accuracy of 90% when compared to the other algorithms.  © 2023 World Scientific Publishing Company.",TextMining
"Background: Heart failure (HF) is the leading cause of morbidity and mortality worldwide, and there is an urgent need for more global studies and data mining approaches to uncover its underlying mechanisms. Multiple omics techniques provide a more holistic molecular perspective to study pathophysiological events involved in the development of HF. Methods: In this study, we used a label-free whole myocardium multi-omics characterization from three commonly used mouse HF models: transverse aortic constriction (TAC), myocardial infarction (MI), and homozygous Phospholamban-R14del (PLN-R14Δ/Δ). Genes, proteins, and metabolites were analysed for differential expression between each group and a corresponding control group. The core transcriptome and proteome datasets were used for enrichment analysis. For genes that were upregulated at both the RNA and protein levels in all models, clinical validation was performed by means of plasma level determination in patients with HF from the BIOSTAT-CHF cohort. Results: Cell death and tissue repair-related pathways were upregulated in all preclinical models. Fatty acid oxidation, ATP metabolism, and Energy derivation processes were downregulated in all investigated HF aetiologies. Putrescine, a metabolite known for its role in cell survival and apoptosis, demonstrated a 4.9-fold (p < 0.02) increase in PLN-R14Δ/Δ, 2.7-fold (p < 0.005) increase in TAC mice, and 2.2-fold (p < 0.02) increase in MI mice. Four Biomarkers were associated with all-cause mortality (PRELP: Hazard ratio (95% confidence interval) 1.79(1.35, 2.39), p < 0.001; CKAP4: 1.38(1.21, 1.57), p < 0.001; S100A11: 1.37(1.13, 1.65), p = 0.001; Annexin A1 (ANXA1): 1.16(1.04, 1.29) p = 0.01), and three biomarkers were associated with HF-Related Rehospitalization, (PRELP: 1.88(1.4, 2.53), p < 0.001; CSTB: 1.15(1.05, 1.27), p = 0.003; CKAP4: 1.18(1.02, 1.35), P = 0.023). Conclusions: Cell death and tissue repair pathways were significantly upregulated, and ATP and energy derivation processes were significantly downregulated in all models. Common pathways and biomarkers with potential clinical and prognostic associations merit further investigation to develop optimal management and therapeutic strategies for all HF aetiologies. © 2022 The Authors",TextMining
"The present spreading out in healthcare initiated with the appreciation of e-healthcare by interconnecting the medical sensors. IoT played a dynamic part in the healthcare industry, which founded the realization of the Industrial Internet of Things (IIoT). The IIoT is becoming a recognized measure of healthcare universally and is shifting the aptitude to treat patients. IIoT-enabled smart health can easily authenticate the patients and expedites efficient tracking. It supports critical information sharing for effective diagnosis and treatments. IIoT-enabled health systems are the combination of sensors, cameras, devices, and objects that produce a giant quantity of data called big data. The spreading out of Big Data founded the realization of Machine Learning (ML) to predict diseases for better treatment. The major goal of IIoT-enabled smart health systems is to investigate big data and provide valued insights for improved QoS. This research suggests an IIoT-enabled system for healthcare to process the Big Data generated by IIoT sensors using machine learning. The proposed scheme is the optimized parallel and distributed framework for real-time efficient processing. The proposed framework is comprised of three modules that are big data preparation, optimized model building, and big data computation. The data preparation is performed for accurate prediction and to get faster real-time big data processing. The current proposals lack effective prediction and resourceful parallel data processing. The proposed framework is simulated through an experiment with the parallel and distributed framework. The efficiency of the proposed scheme has been verified using authentic datasets with experimentations and simulations. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Neural decoding is of great importance in computational neuroscience to automatically interpret brain activities in order to address the challenging problem of mind-reading. Analyzing the vision-related EEG records is of great importance to discern the relation between visual perception and brain activity. Considering the recent advances and achievements in the field of deep neural networks, several architectures have been implemented to decode brain activities. In this paper, functional connectivity-based geometric deep network (FC-GDN) is proposed to leverage the spatio-temporal distributed information in EEG recordings evoked by images to directly extract hidden states of high-resolution time samples considering the functional connectivity between EEG channels. To this end, a topological connectivity graph is constructed based on the functional connectivity between EEG channels and time samples of each EEG channel are considered as a graph signal on top of corresponding graph node. Furthermore, a novel graph neural network architecture based on this efficient graph representation of EEG signals is proposed, in which visually provoked EEG recordings are used as training data in order to decode visual perception state of the participants in terms of extracted EEG patterns related to different image categories. The performance of the proposed FC-GDN is evaluated on the EEG-ImageNet dataset, consisting of 40 image categories and each category includes 50 sample images, shown to 6 participants while their EEG signals were recorded. The average accuracy of 98.4% is obtained for FC-GDN, showing an average improvement of 1.1% compared to the best state-of-the-art method. © 2022 Elsevier Ltd",TextMining
"In this study, we conducted a field survey for the large opening mine with the survey data serving as the numerical modeling inputs to investigate the booster fan airflow distribution using a computational fluid dynamics (CFD) model. A CFD model was created with a booster fan inside the model domain, the airflow distribution patterns around the booster fan were then examined to gain insights on the booster fans impact on the air distribution in the dedicated mining section. Based on the modeling results, the booster fan is an effective ventilation control for airflow direction in large opening mine and the booster fan placement can significantly influence the effectiveness of face pollutants’ removal through airflow recirculation. The fan can boost air velocity to create the multi-pillar scale airflow recirculation to dilute the extraction heading pollutants. Furthermore, the typical continuous traverse done by many mine operators, which only covering part of the entire cross section, may be inadequate around booster fans with errors ranging from 35% to 210%. The airflow calculated at the entry adjacent to the booster fan was 25% that of the fan setting with the subsequent entries exchange diminishing by ∼65.2% per entry indicating streamlining of airflow in the booster fan entry. While the geometry of the mine will play a significant role in determining the airflow distributions this study lays the groundwork for future studies on booster fan placement optimization and effectiveness for face ventilation. © 2022 Elsevier Ltd",TextMining
"Predictions of metal consumption are vital for criticality assessments and sustainability analyses. Although demand for a material varies strongly by region and end-use sector, statistical models of demand typically predict demand using regression analyses at an aggregated global level (“fully pooled models”). “Un-pooled” regression models that predict demand at a disaggregated country or regional level face challenges due to limited data availability and large uncertainty. In this paper, we propose a Bayesian hierarchical model that can simultaneously identify heterogeneous demand parameters (like price and income elasticities) for individual regions and sectors, as well as global parameters. We demonstrate the model's value by estimating income and price elasticity of copper demand in five sectors (Transportation, Electrical, Construction, Manufacturing, and Other) and five regions (North America, Europe, Japan, China, and Rest of World). To validate the benefits of the Bayesian approach, we compare the model to both a “fully pooled” and an “un-pooled” model. The Bayesian model can predict global demand with similar uncertainty as a fully pooled regression model, while additionally capturing regional heterogeneity in income elasticity of demand. Compared to un-pooled models that predict demand for individual countries and sectors separately, our model reduces the uncertainty of parameter estimates by more than 50%. The hierarchical Bayesian modeling approach we propose can be used for various commodities, improving material demand projections used to study the impact of policies on mining sector emissions and informing investment in critical material production. © 2022 The Authors. Journal of Industrial Ecology published by Wiley Periodicals LLC on behalf of International Society for Industrial Ecology.",TextMining
"Proteins are the main undertakers of life activities, and accurately predicting their biological functions can help human better understand life mechanism and promote the development of themselves. With the rapid development of high-throughput technologies, an abundance of proteins are discovered. However, the gap between proteins and function annotations is still huge. To accelerate the process of protein function prediction, some computational methods taking advantage of multiple data have been proposed. Among these methods, the deep-learning-based methods are currently the most popular for their capability of learning information automatically from raw data. However, due to the diversity and scale difference between data, it is challenging for existing deep learning methods to capture related information from different data effectively. In this paper, we introduce a deep learning method that can adaptively learn information from protein sequences and biomedical literature, namely DeepAF. DeepAF first extracts the two kinds of information by using different extractors, which are built based on pre-trained language models and can capture rudimentary biological knowledge. Then, to integrate those information, it performs an adaptive fusion layer based on a Cross-attention mechanism that considers the knowledge of mutual interactions between two information. Finally, based on the mixed information, DeepAF utilizes logistic regression to obtain prediction scores. The experimental results on the datasets of two species (i.e., Human and Yeast) show that DeepAF outperforms other state-of-the-art approaches.  © 2022 IEEE.",TextMining
"Ship collision accidents often result in serious casualties and property losses. Predicting the severity of ship collisions is beneficial to improve maritime transport safety. Therefore, this study proposes a data-driven approach integrating association rule mining (ARM), complex network (CN), and random forest (RF) to explore the correlation among risk factors and determine the critical risk factors for predicting the severity of ship collision accidents. Specifically, ARM is integrated with CN to develop the risk interaction network of ship collisions and to identify the criticality of risk factors. Then, RF is employed to predict the severity of ship collisions, and determine the risk factors that have a critical effect on severity prediction. The results show that poor team communication is the most critical risk factor for predicting the severity of ship collisions. Moreover, the criticality of risk factors is different in the risk networks and prediction model. Results from this study would help relevant stakeholders to assess current risks and tailor safety strategies to reduce the severity of ship collisions. © 2022",TextMining
"Self-Regulated Learning (SRL) is related to increased learning performance. Scaffolding learners in their SRL activities in a computer-based learning environment can help to improve learning outcomes, because students do not always regulate their learning spontaneously. Based on theoretical assumptions, scaffolds should be continuously adaptive and personalized to students' ongoing learning progress in order to promote SRL. The present study aimed to investigate the effects of analytics-based personalized scaffolds, facilitated by a rule-based artificial intelligence (AI) system, on students' learning process and outcomes by real-time measurement and support of SRL using trace data. Using a pre-post experimental design, students received personalized scaffolds (n = 36), generalized scaffolds (n = 32), or no scaffolds (n = 30) during learning. Findings indicated that personalized scaffolds induced more SRL activities, but no effects were found on learning outcomes. Process models indicated large similarities in the temporal structure of learning activities between groups which may explain why no group differences in learning performance were observed. In conclusion, analytics-based personalized scaffolds informed by students’ real-time SRL measured and supported with AI are a first step towards adaptive SRL supports incorporating artificial intelligence that has to be further developed in future research. © 2022 The Authors",TextMining
"Visualizing and analyzing multiple Pareto-optimal solutions obtained using an evolutionary multi- or many-objective optimization algorithm is as important a task as the task of finding them. Besides helping to choose a single preferred solution, they provide a better understanding of the trade-off among the objectives and also reveal key insights about interactions among variables and objectives for the Pareto-optimal solutions. Existing visualization methods do not provide a comprehensive account of both visualization and analysis of Pareto-optimal solutions. In this paper, we present an interpretable self-organizing map (iSOM) method that produces a more simplistic mapping of higher-dimensional variable spaces into two dimensions. Multiple iSOM plots, one for each objective, allows an easier visual understanding of trade-off among objectives. By identifying high trade-off Pareto-optimal solutions and marking them on the iSOM plots, we also provide decision-makers a comprehensive method to locate critical and likely preferred solutions on the Pareto-optimal front. The visualization and analysis of Pareto-optimal solutions using iSOMs are demonstrated on 11 problems involving three to five objectives. As discussed, the approach is generically applicable to higher-dimensional and constrained problems. © 2022 Elsevier B.V.",TextMining
"Heavy metal residues in former mining areas can pose a burden to the local environment and population even decades after closure of the mining sites. In the North Rhine-Westphalian (Germany) communities of Mechernich and Kall, both parts of the district of Euskirchen, lead residues are a source of health concerns for local residents. A statistically representative collective of both communities depending on sex, age, and area of residence was created, mirroring the local underage population. The blood lead levels (BLL) of 182 children and minors in the two adjacent communities were assessed via ICP-MSMS. The results were compared to German lead reference values, valid for the general underage population. In total, 32 (17.6%) of the subjects investigated exceeded the according reference values of 15 µg/L and 20 µg/L, respectively, depending on sex and age, thus pointing out an additional lead burden affecting children in the area. Potential lead sources contributing to the BLL were evaluated using a questionnaire. Factors that showed significant impact on the BLL were, other than age, sex, height, and weight, the factors occupancy, time spend in the garden, garden hand-to-mouth contact, consumption frequency of homegrown products, and lifestyle factors. The data presented enable both residents and the local authorities to further reduce lead exposure and to take appropriate personal and public action. © 2022, The Author(s).",TextMining
"As a significant extension of rough set theory, three-way decision (3WD) theory plays a crucial role in the data mining of uncertain information and decision-making analysis. Transfer learning (TL) is also a powerful knowledge discovery and deep learning strategy that has attracted the attention of many scholars. At present, many achievements have been made in related studies based on the concepts of sample transfer, feature transfer, and parameter transfer. However, there are few studies on multi-granularity fusion and TL for multisource data from the perspective of the stochastic dominance (SD) relation. In this paper, an intuitionistic fuzzy three-way transfer learning (IF3WTL) model based on rough almost stochastic dominance (RASD) is proposed. In this scenario, we first introduce the concept of a rough marginal information measure and the corresponding calculation method. Then, an RASD method is proposed to generate the multi-granularity distribution of same-category information in the source domain. In addition, 3WD theory is introduced to classify the target domain objects into positive, negative, and boundary regions based on the relation between marginal minimum risk information and the corresponding multi-granularity distribution. Furthermore, a secondary decision strategy with an SVM algorithm is implemented to iteratively process boundary region objects. The proposed method can reduce the differences in the data distribution among domains through RASD, improve noise tolerance, and obtain the degree of roughness of common information at different scales. Moreover, the proposed method adopts an iterative learning strategy, which can reduce the decision-making cost in cases with insufficient information and improve the accuracy of classification for objects in the boundary region. The rationality and effectiveness of the proposed model are verified through experiments with the ABIDE dataset and comparative analyses with the existing state-of-the-art methods. © 2022 Elsevier Ltd",TextMining
"No-reference image quality assessment (NR-IQA) aims to evaluate image quality without using the original reference images. Since the early NR-IQA methods based on distortion types were only applicable to specific distortion scenarios, and lack of practicality, it is challenging to designing a universal NR-IQA method. In this article, a multibranch convolutional neural network (MB-CNN) based NR-IQA method is proposed, which includes a spatial-domain feature extractor, a gradient-domain feature extractor, and a weight mechanism. The spatial-domain feature extractor aims to extract the distortion features from the spatial domain. The gradient-domain feature extractor is used to guide the spatial-domain feature extractor to pay more attention to the distortions of the structure information. Particularly, the spatial-domain feature extractor uses the hierarchical feature merge module to realize multiscale feature representation, and the gradient-domain feature extractor uses pyramidal convolution to extract the multiscale structure information of the distorted image. In addition, a position vector is proposed to build the weight mechanism by considering the position relationships between patches and its entire image for improving the final prediction performance. We conduct the experiments on five representative databases: LIVE, TID2013, CSIQ, LIVE MD and Waterloo Exploration Database, and the experimental results show that the proposed NR-IQA method achieves the state-of-the-art performance, which demonstrate the effectiveness of our proposed NR-IQA method. The code ofthe proposed MB-CNN will be released at https://github.com/NUIST-Videocoding/MB-CNN. © 2020 IEEE.",TextMining
"Selecting the optimal location for a new bank branch is challenging but worth studying due to its importance to growing a successful business. Bankers have been devoting a lot of effort to this issue. In recent years, the proliferation of multisource data in smart cities has called for more need for data-driven optimal location selection. Previous studies usually focus on mining different features and processing these data through domain expert knowledge. However, they fail to discover potential complicated factors interactions. Besides, most of these studies only use a single indicator to evaluate the candidate locations, which overlooks a lot of information, resulting in an inaccurate evaluation. In this study, we propose MATE, a Multi-task Attentive Tree-Enhanced model, to simultaneously predict multiple performance indicators of a bank branch's location. Our model takes advantage of the tree-based model, which can effectively extract cross features and provide interpretability according to inferred decision rules. In addition, we designed the financial embedding module and attentive interaction blocks, allowing MATE to obtain more complex and diverse features. Finally, extensive experiments on real-world bank datasets demonstrate the effectiveness of our method, which outperforms baseline and state-of-art methods from 17% to 41%.  © 2017 IEEE.",TextMining
"Many researchers have studied non-expert users’ perspectives of cyber security and privacy aspects of computing devices at home, but their studies are mostly small-scale empirical studies based on online surveys and interviews and limited to one or a few specific types of devices, such as smart speakers. This paper reports our work on an online social media analysis of a large-scale Twitter dataset, covering cyber security and privacy aspects of many different types of computing devices discussed by non-expert users in the real world. We developed two new machine learning based classifiers to automatically create the Twitter dataset with 435,207 tweets posted by 337,604 non-expert users in January and February of 2019, 2020 and 2021. We analyzed the dataset using both quantitative (topic modeling and sentiment analysis) and qualitative analysis methods, leading to various previously unknown findings. For instance, we observed a sharp (more than doubled) increase of non-expert users’ tweets on cyber security and privacy during the pandemic in 2021, compare to in the pre-COVID years (2019 and 2020). Our analysis revealed a diverse range of topics discussed by non-expert users, including VPNs, Wi-Fi, smartphones, laptops, smart home devices, financial security, help-seeking, and roles of different stakeholders. Overall negative sentiment was observed across almost all topics in all the three years. Our results indicate the multi-faceted nature of non-expert users’ perspectives on cyber security and privacy and call for more holistic, comprehensive and nuanced research on their perspectives. © 2022",TextMining
"Rate of penetration (ROP) represents drilling speed and its productive time during drilling operations in oil and gas wells. A predictive model that links ROP to its influential parameters is essential to optimize ROP for minimizing drilling costs. This study implements a comprehensive data mining approach utilizing Python toolboxes to improve ROP prediction in directional wells, which has not been addressed as much as vertical wells with respect to the downhole weight on the bit (WOB) and cutting transport. To do so, seven functions, including influential parameters, were identified to impact ROP in directional drilling. Drilling data of seven directional wells from an offshore rig in a gas field was compiled to set up the input dataset. The data preprocessing methods, consisting of the modified Z-score and Savitzky–Golay (SG) smoothing filter, were utilized to remove outliers and reduce the noises in the input dataset. Multilayer perceptron (MLP) neural network and random forest regression models were employed comparatively to predict ROP, and their architectures were designed by tuning hyperparameters of the models. The models' accuracy was statistically and graphically assessed by using the K-fold cross-validation and statistical metrics. The random forest model was demonstrated to be superior to the MLP neural network model in terms of accuracy and speed. The results represent that using calculated downhole WOB instead of measured surface WOB in the input dataset reinforces the models’ accuracy in the prediction of ROP. Statistical investigations such as partial correlation, mutual information, and permutation feature importance revealed that the cutting transport function can affect ROP in directional drilling as significantly as other influential parameters, which has not been mainly accounted for in the literature when establishing models for ROP prediction. © 2022 Elsevier B.V.",TextMining
"Revealing the complex correlation between population aging and CO2, and projecting their future dynamics are fundamentally necessary to inform effective policies toward a low-carbon and sustainable development in China. Differing from the existing studies, this study highlighted a quantitative investigation on the impact of aging on CO2 emissions across the different stages of regional development in China through a STIRPAT model based on balanced provincial panel data from 1995 to 2019, and projected the demographic change and CO2 emissions till 2050 by employing cohort model and scenario analysis. It is found that CO2 emissions in China has witnessed a significant growth during 1995–2019, and will exhibit an inverted U-shaped growth till 2050 with its peak appears between 2030 and 2040. Statistically, every 1% growth of aging population will cause a 0.62% increase in CO2 emissions in China. However, a big regional difference was also detected as aging contributed to CO2 reduction in the eastern region, but stimulated CO2 emissions in the central and western regions. Policy implications for achieving a low-carbon and aging-oriented sustainable development may include the integration of aging into the decision-making in industrial structure upgrading and CO2 emission reduction at both national and region levels, the promotion of further transition to low-carbon consumption and green products in the eastern region, and strengthening the deep fusion of aging-oriented industries with local resource and environmental endowment in the central and western regions such as the development of eco-agriculture and green pension industries. © 2022 Elsevier Ltd",TextMining
"With the increasing popularity of open educational resources in the past few decades, more and more users watch online videos to gain knowledge. However, most educational videos only provide monotonous navigation tools and lack elaborating annotations. This makes the task of locating interesting contents time consuming. To address this limitation, in this article, we propose a slide-based video navigation tool that is able to extract the hierarchical structure and semantic relationship of visual entities in videos, by integrating multichannel information. Features of visual entities are first extracted from the presentation slides by a novel deep learning framework. Then, we propose a clustering approach to extract hierarchical relationships between visual entities (e.g., formulas, texts, or graphs appearing in educational slides). We use this information to associate visual entities with their corresponding audio speech text, by evaluating their semantic relationship. We present two cases where we use the structured data produced by this tool to generate a multilevel table of contents and notes to provide additional navigation materials for learning. The evaluation experiments demonstrate the effectiveness of our proposed solutions for visual entity extraction, hierarchical relationship extraction, as well as corresponding speech text matching. The user study also shows promising improvement in the autogenerated table of contents and notes for facilitating learning. © 2008-2011 IEEE.",TextMining
"Transfer learning can realize cross-domain fault diagnosis of rotating machinery, where the model trained on many labeled samples collected in one working condition can be transferred to insufficient samples collected in the target working condition. Currently, the data features cannot be completely extracted by existing methods when the data distribution gap of the samples collected in different working conditions is quite large. In order to fully extract the data features of rotating machinery to achieve cross-domain fault diagnosis, this paper investigated a cross-domain fault diagnosis model of rotating machinery based on graph feature extraction. The proposed method can realize unsupervised fault diagnosis on rotating machinery running under different working conditions by extracting the numerical and structural features of source and target domains. First of all, data features with large data distribution gaps need to be fully extracted, so a convolutional network based on a deformable convolutional network (De-conv) is designed to extract the features with large differences in data distribution under various working conditions. Secondly, features are extracted based on a convolutional neural network for data values in existing domain adaptation (DA) methods while the structure features of machine monitoring data are ignored. Therefore, a composite spectral-based graph convolutional network is designed to extract structural features of data. Thirdly, fully extracted features are input into a universal DA network to achieve cross-domain fault diagnosis of unknown faults in rotating machinery under changing working conditions. Finally, a benchmarking data set and a data set collected from a practical experimental platform are used to verify the effectiveness of the proposed model, and the results show that it is more suitable for cross-domain fault diagnosis of rotating machinery than other comparison models. © 2022 IOP Publishing Ltd.",TextMining
"With the establishment of advanced metering infrastructure (AMI), more and more deep learning (DL) methods are being used for electricity theft detection. However, there are still problems such as the construction of a DL model that better fits the theft detection task, sample imbalance in the data set and overfitting of the model which limit the potential of DL models. Therefore, a novel end-to-end solution based on DL to solve these problems for electricity theft detection is proposed in this paper. First, we construct a model based on Transformer Neural Network (TNN), which extracts global features of consumption data by calculating the self-attention between each segment obtained by dividing the whole load sequence, and calculates the relative relationship between features for customer classification. Then, we refine the model to further improve its performance. Conv-attentional module is used to embed the input data and capture the local features in each segment. And we minimize the effect of sample imbalance by choosing a suitable loss function, and address the problem of model overfitting by adding normalization layers, dropout regularization and L2 regularization. In addition, grid search is used to determine the optimal values of the model hyper-parameters. Finally, the performance of the proposed model is verified by experiments using the Irish data set. The results show that our method is able to extract features more efficiently and thus has a higher true positive rate (TPR) with a lower false positive rate (FPR) than other state-of-the-art detectors, and it has strong robustness. © 2022 Elsevier Ltd",TextMining
"The real world involves many graphs and networks that are essentially heterogeneous, in which various types of relations connect multiple types of vertices. With the development of information networks, node features can be described by data of different modalities, resulting in multimodal heterogeneous graphs. However, most existed methods can only handle unimodal heterogeneous graphs. Moreover, most existing heterogeneous graph mining methods are based on meta-paths that depend on domain experts for modeling. In this paper, we propose a novel multimodal heterogeneous graph attention network (MHGAT) to address these problems. Specifically, we exploit edge-level aggregation to capture graph heterogeneity information to achieve more informative representations adaptively. Further, we use the modality-level attention mechanism to obtain multimodal fusion information. Because plain graph convolutional networks can not capture higher-order neighborhood information, we utilize the residual connection and the dense connection access to obtain it. Extensive experimental results show that the MHGAT outperforms state-of-the-art baselines on three datasets for node classification, clustering, and visualization tasks. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",TextMining
"The recognition of multiple Autonomous Underwater Vehicles (AUVs) equipped with Side-Scan Sonar (SSS) is the key to marine surveys, and autonomously and efficiently recognizing marine targets is an urgent open challenge. This paper proposes a lightweight Recurrent Transfer-Adaptive Learning (RTAL) to improve the recognition accuracy of SSS images. In this work, (1) we analyze the target features collected by multiple AUVs, calculate the similarity between features using Mahalanobis distance, and establish a threshold. (2) When the threshold is higher than the similarity, AUVs adopt improved Recurrent Transfer Learning (RTL) to reduce computational consumption and ensure the real-time performance of the algorithm. (3) When the similarity is lower than the threshold, AUVs adopt RTAL to reconstruct the data of the target information with inconspicuous features caused by the complex background, extract features efficiently, and reduce the interference of environmental factors. We compare several classical neural networks and validate them on dataset collected from AUVs sea trials. The experimental results show that our proposed method has high recognition speed and recognition accuracy.  © 1967-2012 IEEE.",TextMining
"Business processes are a key driver of organizational success, which is why business process improvement (BPI) is a central activity of business process management. Despite an abundance of approaches, BPI as a creative task is time-consuming and labour-intensive. Most importantly, its level of computational support is low. The few computational BPI approaches hardly leverage the opportunities brought about by computational creativity, neglect process data, and rely on rather rigid improvement patterns. Given the increasing amount of process data in the form of event logs and the uptake of generative machine learning for automating creative tasks in various domains, there is huge potential for BPI. Hence, following the design science research paradigm, we specified, implemented, and evaluated ProcessGAN, a novel computational BPI approach based on generative adversarial networks that supports the creation of BPI ideas. Our evaluation shows that ProcessGAN improves the creativity of process designers, particularly the originality of BPI ideas, and shapes up useful in real-world settings. Moreover, ProcessGAN is the first approach to combine BPI and computational creativity. © 2022 Elsevier B.V.",TextMining
"In the recent days, data's plays a significant role and its enormous quantity are extracted based on various IoT devices. Various IoT devices generates huge data and it is processed to extract the knowledge data through data analytics. To process those data, which are extracted and needs Deep Learning (DL) model as it needs large number of input and its attributes. The deep learning models helps in classifying the data and process those data generated from IoT and those useful optical data will be useful to those consumers. As huge data are circulated and it contains some private information's related to optics to be secure from the third parties along with effective data processing. The modified deep learning approach based on Cyber Physical Systems (CPS) is propose to effectively process those IoT based data with enhanced data security. Based on deep learning model, the data access algorithm helps to process the raw data generated from IoT time to time and it helps to convert the data to knowledge data. Then the data are secured based on policy access control against various attacks like DoS and DDoS. Based on the performance analysis, the approach helps to provide effective classification of data and reliable data's to be maintained. Then security on IoT data to be verified against DoS and DDoS attacks on cyber physical system on real time applications. © 2022 Elsevier GmbH",TextMining
"The application of the mitigation hierarchy (MH) to mining projects is challenging in situations of locational overlap between endemic flora and mineral deposits. We review flora surveys conducted in connection with the environmental impact assessment of several iron ore mining projects in an area of high degree of endemism in Eastern Amazon to discuss the practical implications of anticipating conservation strategies. Desktop studies and secondary data review were conducted to guide field searches to determine the distribution of endemic flora, resulting in 45 out of 46 endemic plant species having their known distribution extended to new areas. A framework for positioning flora conservation strategies in the MH is presented. Specific habitat requirements and scarce knowledge about endangered and endemic flora species are a conservation obstacle, since essential information to define species conservation strategies may be lacking. We show that anticipating conservation strategies can minimize time-lag uncertainties related to restoration success and biodiversity offsets. The more effort is placed in the preventative steps of the MH, the smaller the time-lag between impact (biodiversity losses) and conservation outcomes (biodiversity gains), decreasing uncertainties and reducing risks to biodiversity. © 2022, The Author(s).",TextMining
"Life cycle bridge maintenance is highly complex and multi-disciplinary oriented. Advanced technologies have been widely adopted, but the generated data and information are often intensive, specific and isolated, it is very difficult to contribute effectively for holistic bridge maintenance decisions. This paper investigates state-of-the-art methods used in bridge maintenance, a total of 2732 papers were selected for visualisation analysis and 323 papers were pinpointed for critical review. The review informs that mindset shifting from traditional and pre-digital, through data driven to knowledge-based approach is required for bridge engineers to holistically understand multi-sources of data and information to enable systematic thinking. The review further reveals the need for a knowledge-driven approach that can leverage bridge maintenance big data to provide smart holistic decisions, a novel knowledge-oriented framework was proposed in the end with an aim to unify and streamline different sources of data to facilitate new developments towards smart bridge maintenance. © 2022",TextMining
"Rural vitalization (RV) has attracted more and more attention in China, especially since the Rural Vitalization Strategy (RVS) was proposed to restrict rural decline in 2017. The evaluation of RV is an effective means to objectively identify the characteristics and problems of rural development, so exploring scientific and rational evaluation methods is important for sustainable rural development. Therefore, this study builds a data-driven evaluation framework from a “bottom-up” perspective, and selects Hubei Province as the object to evaluate the effectiveness of RV. The evaluation index system is formed based on the concept and connotation of RV, which contains six dimensions, namely thriving businesses (TB), pleasant living environments (PLE), social etiquette and civility (SEC), effective governance (EG), living in prosperity (LP), and organization system (OS). The empirical results indicate that there is a low level of variation of the total scores but an obvious disparity in the dimensional scores in 13 prefecture-level and 83 county-level regions. At county-level, the regional development stage has an impact on the effectiveness of RV, and regions with a higher economy or endowed with better resources perform better. The results of spatial analysis further reveal that there is regional agglomeration as well as differences in various dimensions, and regions with characteristic industries or policy support perform better. Compared with the traditional evaluation method, differentiated evaluation objectives and diversified data are considered in the evaluation process of this study. The results and discussion shown in this study could provide empirical evidence for policymakers to effectively promote RV in the future. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TextMining
"Despite the availability of global and continental climate datasets and climate change information, locally relevant quantification of historic trends in climate variables is still lacking in developing countries, especially at local scales. This is particularly true in the Department of Arequipa, Peru. An arid region with a booming population, substantial mining activities, and large irrigated agriculture, which is highly susceptible to climate change. This study aims to evaluate climate trends from 1988 to 2017 in the Arequipa Department and provide information that can facilitate stakeholders' adaptation to the rapid-changing climate. The daily precipitation (Prec), and maximum (Tmax) and minimum (Tmin) daily air temperature data used in this study came from the Servicio Nacional de Meteorología e Hidrología del Perú (SENAMHI) and the National Ocean and Atmospheric Administration's (NOAA) Global Summary of the Day (GSOD). Data passed through a quality checking process for removal of implausible data, data gap filling, and inhomogeneity detection. The Mann–Kendall test, at a significance level of 0.10, was used to determine trends and the Theil–Sen slope (Sen's slope) was used to estimate the magnitude of the change. Sen's slope was also calculated spatially, using the gridded Arequipa Climate Maps (ACM) dataset. Results indicate that precipitation seasonality has been increasing, as the observed increase in annual precipitation is happening mostly in the rainy season (December–March) and the start and end of the rainy season are delayed. Positive temperature trends were dominant in the whole region. Tmin is increasing more than Tmax, especially at higher altitudes. Exceptions to increasing temperatures were found in areas influenced by irrigation projects that underwent great expansion. The effect of increasing temperature on glaciers was evaluated by mapping the change in the area with average annual temperature below 0°C between the decades of 1988–1997 and 2008–2017, which reduced by 73.2%, with small areas disappearing and larger contiguous areas shrinking. © 2022 The Authors. International Journal of Climatology published by John Wiley & Sons Ltd on behalf of Royal Meteorological Society.",TextMining
"With the continuous enrichment of traffic Internet-of-Things data acquisition methods, more and more spatiotemporal data on road networks is collected in real time by various sensors and multimedia devices. The data-driven deep learning approach can make full use of real-time data from a road network to predict future traffic status. By mining the spatiotemporal relationships between road units, the ability to predict network evolutionary behaviors is improved, which provides a new method of traffic management. There are strong semantic relations between road intersections or road sections in terms of traffic evolution. Modeling the network only from a shallow spatial topological perspective ignores the important intrinsic association of the dynamic network. In this paper, we propose a semantic associative neural network (SANN) for traffic evolution analysis by modeling the propagation effects and similarity patterns between road units. Considering the inadequacy of the fixed adjacent matrix, graph convolution is used to encode the semantic features of a road network and embed them in a bidirectional recurrent neural network for sequence prediction. Finally, the experiments are conducted based on speed data sets to prove the effectiveness of the proposed method. The model achieved a well-predicted accuracy of 95.33% and 84.08% on Pems-Bay and Los Angeles data sets.  © 2022 American Society of Civil Engineers.",TextMining
"The tradeoff between higher efficiency and wider stability of performance map is still one of the bottlenecks to hamper the further research and development of advanced multistage axial-flow compressor. The recent rapid growth of computational resources and artificial intelligence has enabled data mining as one of the most effective and potential ways to gain a deep insight into the complex correlations between aerodynamic performance and three-dimensional geometry parameters. In the open literatures, however, few research works have been found on using the data mining that is independent of design optimization to extract priori design guidelines for multistage axial-flow compressor mainly due to the lack of proper data mining method focused on the interpretation of metamodel with full use of limited time-consuming computational fluid dynamics dataset. To tackle this issue, a metamodel-interpreted data mining framework is developed in which extreme gradient boosting (XGBoost) metamodel combined with Shapley additive explanation (SHAP) model are employed to locally interpret the feature importance of each sample in the computational fluid dynamics dataset and then extract the design guidelines in terms of the most influential geometry parameters and their beneficial variation directions. The developed method is applied to data mining of design guidelines for efficiency and stability enhancement of a front 3.5-stage transonic axial-flow compressor in ship-board gas turbine usage. The results show that the aerodynamic performance of the investigated multistage compressor is most sensitive to three-dimensional geometry parameters related to blade lean, blade twist, and variable stators. Specially, the variable stators mainly affect the stall margin at part speed. The blade lean mainly influences the adiabatic efficiency at design speed as well as the stall margin at both speeds, while the blade twist mainly influences the aerodynamic performance at design speed. New designs followed by the design guidelines are obtained and critical performance indicators related to the goals of the data mining task are verified. The stall margin at part speed is widened to 5.87% with adjustment of blade lean and twist and further to 23.31% with additional adjustment of variable stators. The peak adiabatic efficiency at design speed is improved by 0.06% in spite of extremely limited potential for efficiency enhancement of the original design. The present work is of scientific significance as well as industrial application value in the three-dimensional design optimization of advanced multistage axial-flow compressor at the affordable computational cost.  Copyright © 2022 by ASME.",TextMining
"In the toolbox for environmental governance under urban governments, is environmental institutional supply an effective tool to advance the improvement of economic growth quality? This study used data mining and text analysis to obtain the institutional data of 278 cities in China on environmental pollution management and assesses the quality of urban economic growth from the perspective of pollution reduction and total factor productivity improvement. Regression analysis with the temperature inversion in cities as the instrument confirms that environmental institution supply has significantly reduced the PM2.5 emission concentration in China's urban economic growth. Increasing environmental institutional supply has a more salient effect on green transformation in inland cities relative to coastal cities. In a more in-depth discussion, we combined productivity analysis that considering resource and environmental constraints and panel quantile regression and found that, while having a positive effect on cities in the lower quantile of total factor productivity, environmental institutional supply has a negative effect on cities in the higher quantile. Promoting green technological innovation and increasing employment in the field of environmental protection are important channels for environmental institutional supply that shapes a green urban economy. © 2022 Elsevier Inc.",TextMining
"Buruli ulcer (BU), a severe skin disease is caused by Mycobacterium ulcerans. There are concerns of therapeutic inefficacy of existing drugs coupled with chemoresistance. Databases have been shown to augment data mining and integrative systems pharmacology approaches towards the search for novel therapeutic moieties. So far, there is no known integrated database solely dedicated to BU drug discovery. In this work, Buruli ulcer database (BuDb) is a ""one-stop-shop""knowledgebase for supporting BU drug discovery. It contains both manually verified literature and database-curated data on BU. The BuDb provides comprehensive information on the various drug targets, tested compounds, existing drugs, ethnopharmacological plants and information on the genome of M. ulcerans. It also contains cross-referenced links to databases including PubMed, PubChem, DrugBank, NCBI, Gene Ontology (GO), UniProt, Prota4u, String database, KEGG Pathway and KEGG genome database. The BuDb has been implemented with accessibility features such as keyword and specific searches as well as browsing. BuDb is the first useful online repository of its kind integrated with enriched datasets that can aid in the discovery of new biotherapeutic entities for BU.  © 2023 The Author(s).",TextMining
"The auditing of business process execution may involve investigating selected process instances (traces) to identify the root causes of discrepancies. Discrepancies are unexpected business process behavior. Such discrepancies might reveal fraud, inefficiencies, or a model that does not reflect the process execution. One such discrepancy is consecutive activities in the event log that the business process model does not predict, called log-moves. In this work, we investigate strategies to select the minimum cost set of traces from the event log such that each log-move appears in at least one selected trace. A trace cost is any measure of effort required to audit it, such as the estimated required time. We also investigate how to distribute the selected traces among the auditors in order to balance the total costs allocated to them. We provide a mixed integer programming (MIP) formulation and a greedy algorithm for this problem, and empirically evaluate these solution approaches using two real-world datasets. The CPLEX solver finds the optimal solution of the MIP formulation for all instances in less than 75 min but presents exponential growth of execution time as we increase the number of auditors. On the other hand, the greedy heuristic has simple implementation, does not require an external solver, has polynomial time, and typically loses less than 15% of the solution quality for our datasets. The log-moves are obtained from the Directly-Follows Graph (DFG) of the business process model and event log; therefore, the model may be represented by any notation that allows the DFG extraction. For the particular case of business processes modeled as Process Trees, we provide an efficient algorithm for the DFG extraction. We also make no assumptions on how the business process model was built, either manually or by a process mining algorithm. © 2022 Elsevier Ltd",TextMining
"Tree matching techniques have been investigated in many fields, including web data mining and extraction, as a key component to analyze the content of web pages. However, when applied to existing web pages, traditional tree matching approaches, covered by algorithms like Tree-Edit Distance (TED) or XyDiff, either fail to scale beyond a few hundred nodes or exhibit a relatively low accuracy. In this article, we therefore propose a novel algorithm, named Similarity-based Flexible Tree Matching (SFTM), which enables high accuracy tree matching on real-life web pages, with practical computation times. We approach tree matching as an optimization problem and leverage node labels and local topology similarity in order to avoid any combinatorial explosion. Our practical evaluation demonstrates that SFTM significantly improves the state of the art in terms of accuracy, while allowing computation times significantly lower than the most accurate solutions. By gaining on these two dimensions, SFTM therefore offers an affordable solution to match complex trees in practice. © 2022 Elsevier Ltd",TextMining
"Ever-growing data availability combined with rapid progress in analytics has laid the foundation for the emergence of business process analytics. Organizations strive to leverage predictive process analytics to obtain insights. However, current implementations are designed to deal with homogeneous data. Consequently, there is limited practical use in an organization with heterogeneous data sources. The paper proposes a method for predictive end-to-end enterprise process network monitoring leveraging multi-headed deep neural networks to overcome this limitation. A case study performed with a medium-sized German manufacturing company highlights the method’s utility for organizations. © 2022, The Author(s).",TextMining
"China has large regions that freeze seasonally or multiple times a year. Special geological and climatic conditions must be considered for the engineering construction and mining of mineral resources in these regions, and slope stability in cold regions merits study. Taking the Yulong Copper Mine in the Tibet Autonomous Region as an example, the average altitude of this mining area is approximately 4000 m, the average daily minimum temperature in the coldest month is approximately −20 ℃, and the freezing period is long. Slope stability is considerably affected by freezing and thawing, and frozen rock creates several challenges to blasting and excavation, thereby restricting mine production efficiency. To study the dynamic mechanical characteristics of slope rock under low-temperature conditions, marble samples are drilled from the slope of the Yulong Copper Mine. With the help of the SHPB experimental system with a low-temperature control system, dynamic compression and tensile mechanics experiments are performed on rock samples under normal temperature and dry conditions, normal temperature and adequate water conditions, and low-temperature freezing conditions to explore the influence of temperature and water content on rock dynamic mechanical properties. The experimental results show that (1) the average uniaxial dynamic compression and tensile strength of frozen rock samples at −20 ℃ are increased compared with those at room temperature under the joint influence of water/ice phase transformation at low temperature and rock matrix cold shrinkage. Among these phenomena, the latter is the main reason that the strength of frozen rock increases substantially. Under four strain rates, the compressive stress increased by 1.30, 1.62, 1.41, and 1.43 times, and the tensile stress increased by 1.36, 1.28, 1.22, and 1.29 times, respectively. (2) Under the influence of pore water softening, a saturated rock sample has less dynamic strength than a dry rock sample. Therefore, the experimental data under the same strain rate show that the strength of a rock sample follows the order of frozen > dry > saturated. (3) For a given strain rate, the dynamic impact crushing time of saturated marble is the longest, and the decrease with increasing strain rate is the fastest. For a given strain rate, the crushing energy consumption is larger for a rock sample at freezing temperature than at normal temperature and increases greatly with increasing strain rate. © 2023 Science Press. All rights reserved.",TextMining
"Coal mine accident prevention is a key issue affecting the safety of coal production in China. From accident analysis, it has been found that the interaction of unsafe acts of coal miners is the main cause of catastrophic accidents, and that ignoring the interrelationship between behaviors may lead to missing hidden chains of incidents as well as to a gross underestimation of behavioral risk. Therefore, to solve the above problems, it is of significant practical importance to explore unsafe acts in accidents as a collection and to analyse their evolution and development trends. The purpose of this study is to analyse the interrelationships and potential behavior patterns among unsafe acts in coal mine gas explosion accidents from the perspective of network modelling and to propose a modelling method for the mine accident unsafe acts network (MAUAN). First, by mining the causes in 86 gas explosion accident reports, a MAUAN network composed of 95 unsafe-act nodes and 681 edges was determined. Second, by calculating the topology of the MAUAN, 3 key unsafe acts and 6 key behavior paths in the gas explosion accidents were determined. The research results show that 91% of unsafe acts in gas explosion accidents were violations. The lack of safety education and skills training for miners is the most influential unsafe act in gas explosion accidents, and the absence of operating procedures or prevention measures → failure to check gas concentration → risky operation without safety safeguards was the most critical link leading to the occurrence of gas accidents. Third, illegal mining practices have become another urgent problem today—in addition to gas accumulation and ignition source generation—with 83% of gas explosion accidents involving illegal mining. This study provides a reference for accident causation modelling and the identification of key causal factors from accident report data, and the results of the analysis provide a basis for decision making in coal mine accident prevention efforts to reduce future mining accidents. © 2022 The Institution of Chemical Engineers",TextMining
"Focus in quality assessment of iron ore is the content of total iron (TFe). Laser-induced breakdown spectroscopy (LIBS) technology possesses the merits of rapid, in situ, real-time multielement analysis for iron ore, but its application to quantitative TFe content is subject to interference of the iron matrix effect and the lack of suitable data mining tools. Here, a new method of LIBS-based variable importance back propagation artificial neural network (VI-BP-ANN) for quantitative TFe content in iron ore was first proposed. After the LIBS spectra of 80 representative iron samples were obtained, random forest (RF) was optimized by out-of-bag (OOB) error and then used to measure and rank variable importance. The variable importance thresholds and the number of neurons were optimized with five-fold cross-validation (CV) with correlation coefficient (R2) and root mean square error (RMSE). With using only 1.40% of full spectral variables to construct BP-ANN model, the resulted R2, the root mean squared error of prediction (RMSEP) and the modeling time of the final VI-BP-ANN model was 0.9450, 0.3174 wt%, and 24 s, respectively. Compared with full spectrum-based model, for example, BP-ANN, RF, support vector machine (SVM), and PLS and VI-RF model, the VI-BP-ANN model reduced overfitting and obtained the highest R2 and the lowest RMSE both for calibration and prediction. Meanwhile, the characteristics of variables selected by VI were analyzed. In addition to the elemental emission lines of Ca, Al, Na, K, Mn, Si, Mg, Ti, Zr, and Li, partial spectral baselines of 540–610 nm and 820–970 nm were also selected as characteristic variables, which indicated that VI can take into full consideration the elemental interactions and the spectral baselines. Our approach shows that LIBS combined with VI-BP-ANN is able to quantify TFe content rapidly and accurately in iron ore. © The Author(s) 2022.",TextMining
"Meta-analysis studies the literature reporting estimates of one parameter, which at present is assumed positive. The purpose of the analysis is to find the best meta-average, which corrects the mean of the estimates for bias. The two main biases are: (i) Publication bias, where the correction nearly always makes the average smaller. (ii) Omitted variable bias, where the correction typically makes the average larger. Consequently, the bias is likely to increase if the correction is for the wrong bias. This allows a game of meta-mining to be played. A case study demonstrates the scope for meta-mining, and that it has been done. The game of meta-mining is surely against the purpose of meta-analysis. © 2022 The Author. Kyklos published by John Wiley & Sons Ltd.",TextMining
"A fast effective inversion algorithm is proposed herein to interpret gravitational responses caused by mineralized/ore sources (sphere, vertical and horizontal cylinders). The algorithm relies on local wavenumber and correlation imaging techniques. The correlation factor (R) between the local wavenumber of observed gravitational field and that of computed field was calculated, and the maximum Rmax was considered to correspond to the best true model (parameters). The proposed algorithm was applied to two theoretical examples, including an example contaminated with regional background and another multisource example. Besides, the proposed approach was used on three different real field cases for mining/ore investigation from Canada and Cuba. From the results obtained from the theoretical and real examples and by comparing the results with drilling and literature information, it was concluded that the method is effective, is applicable even for more than one source, is accurate, and does not necessitate any prior knowledge of the source shape. © 2022, The Author(s).",TextMining
"Improving transport efficiency is one of the core issues in the field of deep-sea mining. Slip velocities have strong effects on the transport efficiency of deep-sea mineral nodules in the hydraulic conveying process. The present work proposes a probability model for predicting the transport velocity and efficiency, which can reflect the influence of different particle size distribution of large particles. By comparing with a numerical simulation, experimental data and empirical models, the proposed model is well verified and demonstrates advantages in accuracy. To acquire further knowledge of the optimal transport efficiency and the predominant factors, such as the volumetric concentration, the pipe diameter and the mixture velocity, effects of various parameters are explored in detail through the present model, including the medium particle diameter, the average dry solid production, the operating power, the particle density, and the fluid density. Furthermore, four general-purpose optimization algorithms, including the global search (GS), the MultiStart (MS), the pattern search (PS) and the genetic algorithm (GA), are combined to obtain the optimal transport efficiency and compared in an application study. The proposed model provides an efficient tool to fast optimize the transport efficiency of mineral nodules in hydraulic conveying pipes. © 2022 Elsevier B.V.",TextMining
"With the rapid development of edge intelligence (EI) and machine learning (ML), the applications of Cyber-Physical Systems (CPS) have been discovered in all aspects of the life world. As one of its most essential branches, Medical CPS (MCPS) determines human health and medical treatment in the Internet of Everything (IOE) era. Knowledge sharing is the critical point of MCPS and has also been humanity's best dream through the ages. This paper explores a novel knowledge-sharing model in MCPS and takes a pulmonary nodule detection task as a significant case for building an Unet-based mask generator. A Classification-guided Module (CGM)-based discriminator with knowledge from EMRs is set against a generator to offer a promising result for each mask from the inexperienced participant of federated ML. After an iterative communication between the federated server and its clients for knowledge sharing, the segmented sub-image owns a coincident attribute distribution with that of the EMRs from the experts. Besides, the adversarial network augment the data to normalize the data distribution for all the clients as a remission for none independent identically distributed (non-IID) data problem. We implement a detection framework on the simulated EI environment following an existing adaptive synchronization strategy based on data sharing and median loss function. On 1304 scans of the merged dataset, our proposed framework can help boost the detection performance for most of the existing methods of pulmonary nodule detection.  © 2013 IEEE.",TextMining
"An ensemble-learning-based multiobjective optimization is proposed for antenna design. By integrating the local search into multiobjective evolutionary algorithm based on decomposition (MOEA/D) and selecting appropriate solutions of the local search acquired with different offspring reproduction (OR) operators, the MOEA/D combined with ensemble OR (MOEA/D-EOR) is presented. Parallel local OR operators based on samples are also merged, for the first time, by exhaustively mining the evolution data of the optimization searching. The diversity and convergence of MOEA/D-EOR are verified by several widely used benchmark problems. The efficiency of MOEA/D-EOR is demonstrated by designing a high-performance bow-tie multiple-input and multiple-output (MIMO) antenna, which saves at least 25% of the optimization time. The overall performance of MOEA/D-EOR is further demonstrated by designing a $2\times $ 2 MIMO patch antenna in a compact size of $0.667\lambda _{0} \times 0.667\lambda _{0}$ , which achieves a high isolation of 24 dB in an operation band of 4.95-5.07 GHz.  © 1963-2012 IEEE.",TextMining
"The development of coal resources is necessary, but it has a huge negative impact on land, ecology, and the environment. With the increasing awareness of environmental protection and the requirements of related regulations, the design and practice of reclamation projects run through the mining life cycle and continue for a long time after the coal production. High-precision monitoring of mining disturbance and reclamation, quantifying the degree and time of vegetation disturbance and restoration, is of great significance to minimize the environmental effect of mining. Remote sensing, widely used as efficient monitoring tool, but there is not enough research on disturbance and reclamation monitoring taking into account large-scale areas and high temporal and spatial accuracy. Especially when mining sites remain unknown, how to distinguish the disturbance of coal mining and other human activities affecting the surface land cover has become a challenge. Therefore, this paper proposed a method to reconstruct the time series of mining disturbance and reclamation in a large area by using the POI (point of interest) and Landsat time series images using multiple buffer analysis methods. The process includes: (1) Retrieval of POI in the study area based on the public mining list using Python crawler, and buffering 100 km for preliminary extraction of potential mining areas; (2) Using spectral index mask and random forest algorithm to accurately extract the exposed coal on the Google Earth Engine (GEE) platform; (3) Buffering 10 km to identify the occurrence of disturbance and reclamation, using pixel-based temporal trajectory identification of LandTrendr algorithm under GEE. The method successful detect the change points of surface coal mining disturbance and reclamation in eastern Inner Mongolia of China. The results show that: (1) The method can effectively identify the extent of surface coal mining disturbance and reclamation, and the overall extraction accuracy is 81%. (2) Surface coal mining disturbance in eastern Inner Mongolia was concentrated in 2006–2011. By 2020, the total disturbed area is 627.8 km2, with an average annual disturbance of 18.5 km2, and the annual maximum disturbance to the ground reached 64.6 km2 in 2008. With the total reclaimed area being 236.3 km2, the reclamation rate is about 37.6%. This study provides a systematic solution and process for monitoring the disturbance and reclamation of surface coal mining in a large range with little known about the mines’ location. It can effectively identify the mining disturbance and reclamation process which can also be extended to other areas, providing a quantitative assessment of mining disturbance and reclamation, which can support further ecological restoration decision-making. © 2022 Elsevier Ltd",TextMining
"Purpose: The paper studies the applicability of aerial photography materials for identifying the consequences of oil mining technogenesis. Materials and methods: Multi-seasonal aerial photography of a karst river basin, where oil is being produced, was carried out using an unmanned aerial vehicle (UAV). Visual photographic delineation revealed the consequences of mechanical transformations, and some hydrocarbon inputs (bitumisation) and salts (technogenic salinisation) were also identified. Results: As a rule, it has been established that mechanical transformations are detected by the colour and shape of objects. Occasionally, it is also necessary to analyse indirect signs of photographic delineation: the shape of the shadow, the configuration of the borders, the traces of passage, etc. Signs of photographic delineation of technogenic salinisation are turbidity of water and the acquisition of a blue-white colour; the change of colour in the water body to green-yellow; and white salt manifestations on the soil surface. The bitumisation process is sufficiently reliable to identify the presence of open oil spills on the surface of soil or water. Conclusion: The use of orthophotos to detect the processes of bitumisation and technogenic salinisation is effective, especially in combination with direct field studies. The conditions for using aerial photography to identify the consequences of oil mining technogenesis are pixel resolution ≥ 20 cm/pixel (optimal ≥ 10 cm/pixel), snowless shooting season, cloudlessness and relatively low forest cover. The spatial distribution of the identified areas of all types of technogenesis indicates a close relationship with the location of oil mining facilities. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TextMining
"Whale optimization algorithm (WOA) is an emerging nature-inspired, swarm-intelligence based algorithm to solve optimization problems more efficiently. This algorithm is based on the bubble-net hunting strategy of the humpback whales. It has gained immense popularity among researchers, typically, due to its simple nature, fast convergence, and having minimum parameters. In the recent past, it has been widely adopted in various fields including data mining, machine learning, wireless sensor networks, cloud computing, civil engineering, and power systems due to its optimal performance. The WOA has given competitive results in comparison to the state-of-the-art optimization algorithms. In this study, we aim to present a comprehensive survey of WOA consisting of more than eighty existing variants of WOA. More specifically, we intend to put forward key aspects of WOA variants with reference to modifications and applications. Further, we classify the most dominant variants of WOA in distinct categories based on modification area such as equation modification, parameter tuning or the problem space for which an algorithm has been specifically altered. We believe that this study will be beneficial for the community working on optimization problems and it can serve as a basis for understanding the modification and improvement process of an optimization algorithm. © 2023 Institute of Advanced Engineering and Science. All rights reserved.",TextMining
"Clustering is still one of the most common unsupervised learning techniques in data mining since it allows the discovery of meaningful and interesting patterns, knowledge, rules and associations from large-scale datasets. K-medoids, a variant of K-means, is a popular clustering method that attempts to find the optimal combination of K medoids from among a set of potential combinations. It has been successfully applied to solve various real-life problems owing to its simplicity and effectiveness. Nevertheless, due to the exponential number of possible combinations of K medoids, it is extremely challenging to produce the optimal one within a reasonable amount of time. Therefore, in this work, we propose to formulate the problem of K-medoids clustering as an optimization problem and then combine two effective and powerful Swarm Intelligence (SI) algorithms, namely Firefly Algorithm (FA) and Particle Swarm Optimization (PSO), to select the appropriate combination of K medoids. We extensively evaluate the proposed FA-PSO for K-medoids-based clustering, abbreviated as FA-PSO-KMED, using 10 UCI datasets. We first use the Iterated F-Race (I/F-Race) algorithm to determine the optimal parameter settings for FA and PSO. Then, we compare the results of the proposed FA-PSO-KMED with those obtained using the well-known state-of-the-art K-medoids-based clustering algorithms: PAM, CLARA and CLARANS. We also compare the results with 11 popular swarm intelligence algorithms: PSO, ABC, CS, FA, BA, APSO, EHO, HHO, SMA, AO and RSA. Experimental results and statistical analysis show that the proposed FA-PSO-KMED is very promising and demonstrates a significant improvement over the other clustering algorithms. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TextMining
"Large datasets have become useful in data mining for processing, storing, and handling vast amounts of data. However, handling and processing large datasets is time-consuming and memory intensive. As a result, the researchers adopted a partitioning strategy to improve controllability and performance and reduce the time and memory required to handle large datasets. Unfortunately, the numerous clustering techniques available in the literature could confuse experts in choosing the best techniques for a given dataset. Furthermore, no clustering technique can tackle all problems, such as cluster structure, noise, or density. To manage large datasets, existing clustering techniques need scalable solutions. Therefore, this paper proposes an ensemble partition-based clustering with a majority voting technique for large dataset partitioning using the aggregation of k-means, k-medoids, fuzzy c-means, expectation-maximization (EM) and density-based spatial clustering of applications with noise (DBSCAN) techniques. These techniques cluster the large dataset individually in the first stage. The final clusters are discovered in the next stage through a majority voting technique among the five clustering algorithms. These five clustering algorithms assigned data instances to the cluster with the most votes. The experimental findings demonstrate that the ensemble partition-based clustering method surpasses the other five clustering algorithms in terms of execution time and accuracy. © 2023 Institute of Advanced Engineering and Science. All rights reserved.",TextMining
"Healthcare organizations accept information technology in a management system. A huge volume of data is gathered by healthcare system. Analytics offers tools and approaches for mining information from this complicated and huge data. The extracted information is converted into data which assist decision-making in healthcare. The use of big data analytics helps achievement of improved service quality and reduces cost. Both data mining and big data analytics are applied to pharma co-vigilance and methodological perspectives. Using effective load balancing and as little resources as possible, obtained data is accessible to improve analysis. Data prediction analysis is performed throughout the patient data extraction procedure to achieve prospective outcomes. Data aggregation from huge datasets is used for patient information prediction. Most current studies attempt to improve the accuracy of patient risk prediction by using a commercial model facilitated by big data analytics. Privacy concerns, security risks, limited resources, and the difficulty of dealing with massive amounts of data have all slowed the adoption of big data analytics in the healthcare industry. This paper reviews the various effective predictive analytics methods for diverse diseases like heart disease, blood pressure, and diabetes. © 2023, Institute of Advanced Engineering and Science. All rights reserved.",TextMining
"Detecting faults in communication wiring systems is always an intriguing research topic. Most current fault finding approaches are based on reflectometry. However, traditional reflectometry requires prior knowledge, such as the cable propagation wave velocity, to analyze the cable state and cannot determine the severity of cable faults. This paper introduces a fault severity prediction method based on a one-dimensional convolution residual network without cable prior knowledge. By correlating the channel transfer function (CTF) with the fault information, a pilot-based deep learning network that can extract fault features more accurately emerges. The method was applied to a communication cable fault detection experiment on a software-defined radio (SDR) platform to verify its effectiveness. Compared with other traditional detection methods, the proposed method is simpler and has better performance.  © 2004-2012 IEEE.",TextMining
"In 2019 there was an outbreak of coronavirus pandemic also known as COVID-19. Many scientists believe that the pandemic originated from Wuhan, China, before spreading to other parts of the globe. To reduce the spread of the disease, decision makers encouraged measures such as hand washing, face masking, and social distancing. In early 2021, some countries including the United States began administering COVID-19 vaccines. Vaccination brought a relief to the public; it also generated a lot of debates from anti-vaccine and pro-vaccine groups. The controversy and debate surrounding COVID-19 vaccine influenced the decision of several people in either to accept or reject vaccination. Because of data limitations, social media data, collected through live streaming public tweets using an Application Programming Interface (API) search, is considered a viable and reliable resource to study the opinion of the public on Covid-19 vaccine hesitancy. Thus, this study examines 3 sentiment computation methods (Azure Machine Learning, VADER, and TextBlob) to analyze COVID-19 vaccine hesitancy. Five learning algorithms (Random Forest, Logistics Regression, Decision Tree, LinearSVC, and Naïve Bayes) with different combination of three vectorization methods (Doc2Vec, CountVectorizer, and TF-IDF) were deployed. Vocabulary normalization was threefold; potter stemming, lemmatization, and potter stemming with lemmatization. For each vocabulary normalization strategy, we designed, developed, and evaluated 42 models. The study shows that Covid-19 vaccine hesitancy slowly decreases over time; suggesting that the public gradually feels warm and optimistic about COVID-19 vaccination. Moreover, combining potter stemming and lemmatization increased model performances. Finally, the result of our experiment shows that TextBlob + TF-IDF + LinearSVC has the best performance in classifying public sentiment into positive, neutral, or negative with an accuracy, precision, recall and F1 score of 0.96752, 0.96921, 0.92807 and 0.94702 respectively. It means that the best performance was achieved when using TextBlob sentiment score, with TF-IDF vectorization and LinearSVC classification model. We also found out that combining two vectorizations (CountVectorizer and TF-IDF) decreases model accuracy. © 2022 The Authors",TextMining
"The formation of alkaline earth(II)triscarbonatouranyl(VI) (AenUO2(CO3)3(4-2n)-) species that have been evidenced both in laboratory and in-field studies, is important from slightly acidic pH up to near degraded cementitious in carbonated waters. They are also showing distinctive luminescence properties with a hypsochromic shift relative to UO22+. The conditions of pH, activities of alkaline earth(II) free ions (mostly Mg2+ and Ca2+) and carbonate ions (HCO3−) can be predicted from the thermodynamic functions and constants. The predictive validity of the activity of major alkaline ions (mostly Na+) is determined from the models used to describe the ionic strength comportment of these species, particularly using coefficients from the specific ion interaction theory (SIT). The stability domains of these species are better defined as a function of the activity of the constituents, and applied to natural waters. In this work, using recently obtained complete thermodynamic data and SIT coefficients, we will draw the stability domains of the AenUO2(CO3)3(4-2n)- species in combinations of activities of H+, HCO3−, Mg2+, Ca2+, and Na+ for a wide selection of water compositions from the literature. Water samples were collected near a French mining legacy-site (Site du Bosc, Lodève, France). After determining the major ion compositions, we will verify that the luminescence signal of uranium is in agreement with the predicted speciation in the stability domains. © 2022 Elsevier B.V.",TextMining
"Kyrgyzstan is an earthquake-prone country at the border of the Pamir Thrust, north of the active shortening structure of the Pamir Mountains and the intra-continental mountain belt of the Tian Shan further north. The region has had several M7 + damaging earthquakes, which have killed thousands of people. In the West, the country is cut through by the 700-km-long NW–SE Talas-Fergana active strike-slip fault system, where no major earthquakes have been observed in the last 250 years even though paleoseismic studies show the potential to produce M7.0 + events. This study is the second part of a project to estimate the potential damage and losses on residential buildings as well as critical infrastructures in the case of a large earthquake in the two mining towns of Kadamjay and Aidarken in the SW of Kyrgyzstan. Microtremors were recorded on 82 sites and analyzed with the Horizontal-to-Vertical Spectral Ratio (HVSR) method. For each site, we estimate the average frequency of the clearest peak and its amplitude in the HVSR spectra to produce microzonation maps, in terms of response frequency. We further used these data for the calculation of ground shaking using a set of six seismic scenarios based on the known faults around the two towns. This approach has proved to be efficient in a country where the resources and available data are limited and when the time of investigation is short. The Kadamjay and Aidarken cities have been divided into different zones with specific predominant resonance frequency ranges, which information is useful for risk analysis, mitigation and buildings retrofit. In Kadamjay, three regions dominate which are related to the history of alluvial deposition in a series of terraces. The more elevated terrace could be the place of seismic site amplification. Aidarkan is much more homogenous in terms of thickness and type of alluvial deposits. © 2022, The Author(s) under exclusive licence to Institute of Geophysics, Polish Academy of Sciences & Polish Academy of Sciences.",TextMining
"The COVID-19 outbreak has affected everyday lives worldwide. As governments started to implement confinement and business closure measures, the economic impact was felt by entire societies immediately. The urgency of such a theme has led researchers to study the phenomenon. Accordingly, the purpose of this research is to provide the state of the art on relevant dimensions and hot topics of research to understand the economic impacts of COVID-19. In this survey, we conduct a text mining analysis of 301 articles published during 2020 which analyzed such economic impacts. By defining a set of relevant dimensions grounded on existing literature, we were able to extract a set of coherent topics that aggregate the collected articles, characterized by the predominance of a few sets of dimensions. We found that the impact on “financial markets” was widely studied, especially in relation to Asia. Next, we found a more diverse range of themes analyzed in Europe, from “government measures” to “macroeconomic variables.” We also discovered that America has not received the same degree of attention, and “institutions,” “Africa,” or “other pandemics” were studied less. We anticipate that future research will proliferate focusing on several themes, from environmental issues to the effectiveness of government measures. © 2022 John Wiley & Sons Ltd.",TextMining
"This study aims to improve the aerodynamic performance of a propeller for Mars exploration aircraft by applying multi-objective shape optimization to its airfoils. To increase the accuracy of performance evaluation in the low-Reynolds-number and high-subsonic flows condition on Mars, a Reynolds-averaged Navier–Stokes simulation using the γ-Reθ transition model, which can predict the laminar separation bubble and the location of the laminar–turbulent transition with high accuracy, is employed. Furthermore, multi-objective shape optimization is performed using a shape-definition method with a high degree of freedom to enable the inclusion of a variety of airfoil shapes. A multi-objective genetic algorithm is used to determine the optimal airfoil shape, and a Kriging model is used to reduce the computation time. The Adkins method is used to determine the optimal shape of the propeller using the designed airfoil. Then, the performance and efficiency of the propeller are investigated. Results demonstrate improvements in the power consumption and efficiency of the propeller using the designed airfoil over those of the propellers using reference airfoils. Quantitative and qualitative correlations between the design variables and airfoil performance are also analyzed using analysis of variance and self-organizing map methods to extract the geometric features that affect airfoil performance. © 2022, The Author(s), under exclusive licence to The Korean Society for Aeronautical & Space Sciences.",TextMining
"Semi-supervised learning (SSL) can utilize a large amount of unlabeled data for self-training and continuous evolution with only a few annotations. This feature makes SSL a potential candidate for dealing with data from changing and real-time environments, where deep-learning models need to be adapting to evolving and nonstable (non-i.i.d.) data streams from the real world, i.e., online evolutive scenarios. However, state-of-the-art SSL methods often have complex model design mechanisms and may cause performance degradation in a generalized and open environment. In an edge computing setup, e.g., typical in modern Internet of Things (IoT) applications, a multi-agent SSL architecture can help resolve generalization problems by sharing knowledge between models. In this paper, we introduce Mutual Match (MM), an online-evolutive SSL algorithm that integrates mutual interactive learning and soft-supervision consistency regularization, as well as unsupervised sample mining. By leveraging extra knowledge in the training process and the interactive collaboration between models, MM surpasses multiple top SSL algorithms in accuracy and convergence efficiency under the same online-evolutive experiment setup. MM simplifies the complexity of model design and follows a unified and easy-to-expandable pipeline, which can be beneficial to tasks with insufficient labeled data and frequently changing data distribution. © 2022, The Author(s).",TextMining
"Cryptocurrency based on blockchain technology has gradually become a choice for people to invest in, and several users have participated in the accumulation of massive transaction data. Complete transaction records in blockchains and the openness of data provide researchers with opportunities to mine and analyze data in blockchains. Network modeling and analysis of cryptocurrency transaction records are common methods in blockchain data analysis. The analysis of attribute graphs can provide insights into various economic indicators, illegal activities, and general Internet security, among others. Accordingly, this article aims to summarize and analyze the literature on cryptocurrency transaction data from the perspective of complex networks. To provide systematic guidance for researchers, we put forward a blockchain data analysis framework based on the introduction of the relevant background and reviewed the work from five aspects: blockchain data model, data acquisition on blockchains, existing analysis tools, available insights, and common analysis methods. For each aspect, we introduce the research problems, summarize the methods, and discuss the results and findings. Finally, we present future research points and several open questions in the study of cryptocurrency transaction networks.  © 1996-2012 Tsinghua University Press.",TextMining
"Classification is a classical research field due to its broad applications in data mining such as event extraction, spam detection, and medical treatment. However, class imbalance is an unavoidable problem in many real-world applications. It is challenging for conventional learning algorithms to deal with imbalanced datasets, since they tend to be biased towards the majority class, while the minority class is crucial as well. Many previous studies have been explored to solve class imbalance, such as data sampling and class switching. In this paper, we propose a hybrid strategy named Majority-to-Minority Resampling (MMR) to select switched instances, which adaptively samples potential instances from the majority class to augment the minority class. To reduce the loss of information after sampling, we also propose a Majority-to-Minority Boosting (MMBoost) algorithm for classification by dynamically adjusting weights of the sampled instances. We conduct extensive experiments using real-world datasets. Experimental results demonstrate that the proposed framework achieves competitive performance for dealing with imbalanced data compared to several strong baselines across different common metrics. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"As a new form of public transportation, shared bikes have greatly facilitated people’s travel in recent years. However, in the actual operation process, the uneven distribution of bicycles at each shared bicycle station has limited the travel experience. In this paper, we propose a deep spatio-temporal residual network model based on Region-reConStruction algorithm to predict the usage of shared bikes in the bike-sharing system. We first propose an Region-reConStruction algorithm (RCS) to partition the shared bicycle sites within a city into separate areas based on their geographic location information as well as bikes’ migration trends between stations. We then combine the RCS algorithm with a deep spatio-temporal residual network to model the key factors affecting the usage of shared bicycles. RCS makes good use of the migration trend of shared bikes during user usage, thus greatly improving the accuracy of prediction. Experiments performed on New York’s bike-sharing system show that our model’s prediction accuracy is significantly better than that of previous models. © 2022, The Author(s).",TextMining
"A plethora of healthcare data is produced every day due to the proliferation of prominent technologies such as Internet of Medical Things (IoMT). Digital-driven smart devices like wearable watches, wristbands and bracelets are utilized extensively in modern healthcare applications. Mining valuable information from the data distributed at the owners' level is useful, but it is challenging to preserve data privacy. Federated learning (FL) has swiftly surged in popularity due to its efficacy in dealing privacy vulnerabilities. Recent studies have demonstrated that Gradient Inversion Attack (GIA) can reconstruct the input data by leaked gradients, previous work demonstrated the achievement of GIA in very limited scenarios, such as the label repetition rate of the target sample being low and batch sizes being smaller than 48. In this paper, a novel method of End-to-End Gradient Inversion (E2EGI) is proposed. Compared to the state-of-the-art method, E2EGI's Minimum Loss Combinatorial Optimization (MLCO) has the ability to realize reconstructed samples with higher similarity, and the Distributed Gradient Inversion algorithm can implement GIA with batch sizes of 8 to 256 on deep network models (such as ResNet-50) and ImageNet datasets. A new Label Reconstruction algorithm is developed that relies only on the gradient information of the target model, which can achieve a label reconstruction accuracy of 81% in one batch sample with a label repetition rate of 96%, a 27% improvement over the state-of-the-art method. This proposed work can underpin data security assessments for healthcare federated learning.  © 2022 IEEE.",TextMining
"Fault prediction of electromechanical equipment can greatly reduce its maintenance cost and prevent catastrophic damage. In order to realize the accurate fault prediction of electromechanical equipment, a fault prediction method based on spatial-temporal graph information is proposed in this article. In the proposed method, the signal data of each intermittent monitoring period are expressed by Markov field graph information, and the spatial-temporal correlation features of graph information are extracted and studied by multivariate spatial-temporal graph neural networks. The effectiveness of Markov graph information for different state expressions is demonstrated by motor fault data from the motor fault experimental platform, and the bearing fault prognostics data is used to demonstrate the feasibility and accuracy of the proposed fault prediction method. The results show that based on the local spatial state information and global time correlation information of monitoring signals, this method could accomplish accurate long-term and short-term fault prediction tasks, respectively.  © 2005-2012 IEEE.",TextMining
"The increasing impact of Web 2.0 involves a growing usage of slang, abbreviations, and emphasized words, which limit the performance of traditional natural language processing models. The state-of-the-art Part-of-Speech (POS) taggers are often unable to assign a meaningful POS tag to all the words in a Web 2.0 text. To solve this limitation, we are proposing an auxiliary POS tagger that assigns the POS tag to a given token based on the information deriving from a sequence of preceding and following POS tags. The main advantage of the proposed auxiliary POS tagger is its ability to overcome the need of tokens' information since it only relies on the sequences of existing POS tags. This tagger is called auxiliary because it requires an initial POS tagging procedure that might be performed using online dictionaries (e.g., Wikidictionary) or other POS tagging algorithms. The auxiliary POS tagger relies on a Bayesian network that uses information about preceding and following POS tags. It was evaluated on the Brown Corpus, which is a general linguistics corpus, on the modern ARK dataset composed by Twitter messages, and on a corpus of manually labeled Web 2.0 data. © 2022 The Authors. Statistical Analysis and Data Mining published by Wiley Periodicals LLC.",TextMining
"Feature selection plays a very significant role for the success of pattern recognition and data mining. Based on the maximal relevance and minimal redundancy (mRMR) method, combined with feature subset, this paper proposes an improved maximal relevance and minimal redundancy (ImRMR) feature selection method based on feature subset. In ImRMR, the Pearson correlation coefficient and mutual information are first used to measure the relevance of a single feature to the sample category, and a factor is introduced to adjust the weights of the two measurement criteria. And an equal grouping method is exploited to generate candidate feature subsets according to the ranking features. Then, the relevance and redundancy of candidate feature subsets are calculated and the ordered sequence of these feature subsets is gained by incremental search method. Finally, the final optimal feature subset is obtained from these feature subsets by combining the sequence forward search method and the classification learning algorithm. Experiments are conducted on seven datasets. The results show that ImRMR can effectively remove irrelevant and redundant features, which can not only reduce the dimension of sample features and time of model training and prediction, but also improve the classification performance. © 2022, The Author(s).",TextMining
"The wide use of Deep learning (DL) has not been followed by the corresponding advances in software engineering (SE) for DL. Research shows that developers writing DL software have specific development stages (i.e., SE4DL stages) and face new DL-specific problems. Despite substantial research, it is unclear how DL developers' SE needs for DL vary over stages, application types, or if they change over time. To help focus research and development efforts on DL-development challenges, we analyze 92,830 Stack Overflow (SO) questions and 227,756 READMEs of public repositories related to DL. Latent Dirichlet Allocation (LDA) reveals 27 topics for the SO questions where 19 (70.4%) topics mainly relate to a single SE4DL stage, and eight topics span multiple stages. Most questions concern Data Preparation and Model Setup stages. The relative rates of questions for 11 topics have increased, for eight topics decreased over time. Questions for the former 11 topics had a lower percentage of accepting an answer than the remaining questions. LDA on README files reveals 16 distinct application types for the 227k repositories. We apply the LDA model fitted on READMEs to the 92,830 SO questions and find that 27% of the questions are related to the 16 DL application types. The most asked question topic varies across application types, with half primarily relating to the second and third stages. Specifically, developers ask the most questions about topics primarily relating to Data Preparation (2nd) stage for four mature application types such as sf Image\ Segmentation ImageSegmentation, and topics primarily relating to Model Setup (3rd) stage for four application types concerning emerging methods such as sf Transfer\ Learning TransferLearning. Based on our findings, we distill several actionable insights for SE4DL research, practice, and education, such as better support for using trained models, application-type specific tools, and teaching materials. © 1976-2012 IEEE.",TextMining
"Background: Formative assessments are vital for supporting learning and performance but are also considered to increase the workload of teachers. As self-assessments in higher education are increasingly facilitated via digital learning environments allowing to offer direct feedback and tracking students' digital learning behaviour these constraints might be reduced. Yet, learning analytics do not make sufficient use of data on assessments. Aims: This exploratory case study uses learning analytics methods for investigating students' engagement with self-assessments and how this relates to performance in the final exam and self-reported self-testing strategies. Materials & Methods: The research study has been conducted at a European university in a twelve-weeks course of a Bachelor's program in Economic and Business Education including nenroll = 159 participants. During the semester, students were offered nine self-assessments each including three to eight tasks plus one mid-term and one exam-preparation self-assessment including all prior self-assessments tasks. The self-assessment interaction data for each student included: the results of the last self-assessment attempt, the number of processed self-assessment tasks, and the time spent on the last self-assessment attempt, the total self-assessment attempts, and the first as well as last access of each self-assessment. Data analytics included unsupervised machine learning and process mining approaches. Results: Findings indicate that students use the self-assessments predominantly before summative assessments. Two distinct clusters based on engagement with self-assessments could be identified and engagement was positively related to performance in the final exam. The findings from learning analytics data were also indicated by students' self-reported use of self-testing strategies. Discussion: With the help of multiple data from self-reports, formal exams, and a learning analytics system, the findings provided multiple perspectives on the use of self-assessments and their relationships with course performance. These findings call for applying assessment analytics and related frameworks in learning analytics as well as providing learners with related adaptive feedback. Conclusion: Future research might investigate different (self-report) variables for clustering, other student cohorts or self-assessment forms. © 2022 The Authors. Journal of Computer Assisted Learning published by John Wiley & Sons Ltd.",TextMining
"Due to the increasing number of cyber incidents and overwhelming skills shortage, it is required to evaluate the knowledge gap between cyber security education and industrial needs. As such, the objective of this study is to identify the knowledge gaps in cyber security graduates who join the cyber security workforce. We designed and performed an opinion survey by using the Cyber Security Knowledge Areas (KAs) specified in the Cyber Security Body of Knowledge (CyBOK) that comprises 19 KAs. Our data was gathered from practitioners who work in cyber security organizations. The knowledge gap was measured and evaluated by acknowledging the assumption for employing sequent data as nominal data and improved it by deploying chi-squared test. Analyses demonstrate that there is a gap that can be utilized to enhance the quality of education. According to acquired final results, three key KAs with the highest knowledge gap are Web and Mobile Security, Security Operations and Incident Management. Also, Cyber-Physical Systems (CPS), Software Lifecycles, and Vulnerabilities are the knowledge areas with largest difference in perception of importance between less and more experienced personnel. We discuss several suggestions to improve the cyber security curriculum in order to minimize the knowledge gaps. There is an expanding demand for executive cyber security personnel in industry. High-quality university education is required to improve the qualification of upcoming workforce. The capability and capacity of the national cyber security workforce is crucial for nations and security organizations. A wide range of skills, namely technical skills, implementation skills, management skills, and soft skills are required in new cyber security graduates. The use of each CyBOK KA in the industry was measured in response to the extent of learning in university environments. This is the first study conducted in this field, it is considered that this research can inspire the way for further researches. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Context: The pull-based development model is widely used in open source projects, leading to the emergence of trends in distributed software development. One aspect that has garnered significant attention concerning pull request decisions is the identification of explanatory factors. Objective: This study builds on a decade of research on pull request decisions and provides further insights. We empirically investigate how factors influence pull request decisions and the scenarios that change the influence of such factors. Method: We identify factors influencing pull request decisions on GitHub through a systematic literature review and infer them by mining archival data. We collect a total of 3,347,937 pull requests with 95 features from 11,230 diverse projects on GitHub. Using these data, we explore the relations among the factors and build mixed effects logistic regression models to empirically explain pull request decisions. Results: Our study shows that a small number of factors explain pull request decisions, with that concerning whether the integrator is the same as or different from the submitter being the most important factor. We also note that the influence of factors on pull request decisions change with a change in context; e.g., the area hotness of pull request is important only in the early stage of project development, however it becomes unimportant for pull request decisions as projects become mature. © 1976-2012 IEEE.",TextMining
"In this article, we present a work using a smartphone with an off-the-shelf WiFi router for human activity recognition with various scales. The router serves as a hotspot for transmitting WiFi packets. The smartphone is configured with customized firmware and developed software for capturing WiFi channel state information (CSI) data. We extract the features from the CSI data associated with specific human activities, and utilize the features to classify the activities using machine learning models. To evaluate the system performance, we test 20 types of human activities with different scales including seven small motions, four medium motions, and nine big motions. We recruit 60 participants and spend 140 hours for data collection at various experimental settings, and have 36 000 data points collected in total. Furthermore, for comparison, we adopt three distinct machine learning models, including convolutional neural networks (CNNs), decision tree, and long short-term memory. The results demonstrate that our system can predict these human activities with an overall accuracy of 97.25%. Specifically, our system achieves a mean accuracy of 97.57% for recognizing small-scale motions that are particularly useful for gesture recognition. We then consider the adaptability of the machine learning algorithms in classifying the motions, where CNN achieves the best predicting accuracy. As a result, our system enables human activity recognition in a more ubiquitous and mobile fashion that can potentially enhance a wide range of applications such as gesture control, sign language recognition, etc.  © 2022 IEEE.",TextMining
"Unsupervised data clustering investigation is a standout among the most valuable tools and is an informative task in data mining that looks to characterize similar articles' gatherings. One of the eminent algorithms for the clustering field is K-means clustering. Scholars recommended enhancing the nature of K-means, and optimization algorithms were hybridized. In this study, a heuristic calculation, deer hunting optimization algorithm (DHOA), was adjusted for K-means data clustering by altering the fundamental parameters of DHOA calculation, which are propelled from the characteristic enlivened calculations. During this work, a new human-based descriptive DHOA has been developed following a human deer hunting strategy. In order to attack the fawn, hunters update their positions based on the movement of the leader and backward movement while also considering the angle of the deer. In this work, the DHOA was hybridized with K-means clustering and the performance of the proposed approach is tested against UCI repository data with different algorithms. © 2023 World Scientific Publishing Company.",TextMining
"Glioblastoma multiforme (GBM) is the most common type of brain tumors with high recurrence and mortality rates. After chemotherapy treatment, GBM patients still show a high rate of differentiating pseudoprogression (PsP), which is often confused as true tumor progression (TTP) due to high phenotypical similarities. Thus, it is crucial to construct an automated diagnosis model for differentiating between these two types of glioma progression. However, attaining this goal is impeded by the limited data availability and the high demand for interpretability in clinical settings. In this work, we propose an interpretable structure-constrained graph neural network (ISGNN) with enhanced features to automatically discriminate between PsP and TTP. This network employs a metric-based meta-learning strategy to aggregate class-specific graph nodes, focus on meta-tasks associated with various small graphs, thus improving the classification performance on small-scale datasets. Specifically, a node feature enhancement module is proposed to account for the relative importance of node features and enhance their distinguishability through inductive learning. A graph generation constraint module enables learning reasonable graph structures to improve the efficiency of information diffusion while avoiding propagation errors. Furthermore, model interpretability can be naturally enhanced based on the learned node features and graph structures that are closely related to the classification results. Comprehensive experimental evaluation of our method demonstrated excellent interpretable results in the diagnosis of glioma progression. In general, our work provides a novel systematic GNN approach for dealing with data scarcity and enhancing decision interpretability. Our source codes will be released at https://github.com/SJTUBME-QianLab/GBM-GNN.  © 1982-2012 IEEE.",TextMining
"Following the deaths of many Black Americans in spring 2020, public consciousness rose around the societal mega-threat of racism. In response, many organizations released public statements to condemn racism and affirm their stance on diversity, equity, and inclusion (DEI). However, little is known about the specific thematic contents covered in such diversity statements and their implications on important organizational outcomes. Taking both inductive and deductive approaches, we conducted two studies to advance our understanding in this area. Study 1 employed structural topic modeling (STM)—an advanced unsupervised machine-learning text-mining technique—and comprehensively analyzed the latent semantic topics underlying the diversity statements publicly released by Fortune 1000 companies in late May and early June 2020. The results uncovered six underlying latent semantic topics: (1) general DEI terms, (2) supporting Black community, (3) acknowledging Black community, (4) committing to diversifying the workforce, (5) miscellaneous words, and (6) titles and companies. Furthermore, drawing from the identity-blindness and identity-consciousness theoretical frameworks and leveraging millions of data points of employees’ DEI ratings retrieved from Glassdoor.com, Study 2 further tested and supported hypotheses that companies were more positively rated by their employees on organizational diversity and inclusion if they (1) released (vs. did not release) diversity statements and (2) emphasized identity-conscious (vs. identity-blind) topics in their diversity statements. Our findings shed light on important theoretical implications for the current research and offer practical recommendations for organizational scientists and practitioners in diversity management. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"The application of convolutional neural network (CNN) has greatly promoted the scope and scenario of intelligent fault diagnosis and brought about a significant improvement of intelligent model performance. Solving the feature extraction and fault diagnosis of machinery with heavy noise is beneficial for stable industrial production. However, the local properties of CNN prevent it from obtaining global features to collect sufficient fault information, leading to the degradation of fault diagnosis performance of CNN under heavy noise. In this article, a novel framework named Convformer-NSE is developed to extract robust features that integrate both global and local information, aiming at improving the end-to-end fault diagnostic performance of gearbox under heavy noise. First, Convformer is constructed to improve the nonlinear representation of the feature map, in which the sparse modified multi self-attention is used to model the long-range dependency of the feature map while keeping attention on local features. Then, the extracted spatial features at various scales are fused and fed in the designed novel Senet (NSE) for channel adaptivity learning. The Convformer-NSE is used for the analysis of raw vibration data of different gearbox systems. The experimental signal analyses demonstrate that our developed framework is superior to others.  © 1996-2012 IEEE.",TextMining
"A widespread and escalating public health problem worldwide is foodborne illness, and foodborne Salmonella infection is one of the most common causes of human illness.For the three most pathogenic Salmonella serotypes, Raman spectroscopy was employed to acquire spectral data.As machine learning offers high efficiency and accuracy, we have chosen the convolutional neural network(CNN), which is suitable for solving multi-classification problems, to do in-depth mining and analysis of Raman spectral data.To optimize the instrument parameters, we compared three laser wavelengths: 532, 638, and 785 nm.Ultimately, the 532 nm wavelength was chosen as the most effective for detecting Salmonella.A pre-processing step is necessary to remove interference from the background noise of the Raman spectrum.Our study compared the effects of five spectral preprocessing methods, Savitzky-Golay smoothing (SG), Multivariate Scatter Correction (MSC), Standard Normal Variate (SNV), and Hilbert Transform (HT), on the predictive power of CNN models.Accuracy(ACC), Precision, Recall, and F1-score 4 machine learning evaluation indicators are used to evaluate the model performance under different preprocessing methods.In the results, SG combined with SNV was found to be the most accurate spectral pre-processing method for predicting Salmonella serotypes using Raman spectroscopy, achieving an accuracy of 98.7% for the training set and over 98.5% for the test set in CNN model.Pre-processing spectral data using this method yields higher accuracy than other methods.As a conclusion, the results of this study demonstrate that Raman spectroscopy when used in conjunction with a convolutional neural network model enables the rapid identification of three Salmonella serotypes at the single-cell level, and that the model has a great deal of potential for distinguishing between different serotypes of pathogenic bacteria and closely related bacterial species.This is vital to preventing outbreaks of foodborne illness and the spread of foodborne pathogens. © 2022 Elsevier B.V.",TextMining
"Clustering is one of the most important problems in the fields of data mining, machine learning, and biological population division, etc. Moreover, robust variant for k-means problem, which includes k-means with penalties and k-means with outliers, is also an active research branch. Most of these problems are NP-hard even the most classical problem, k-means problem. For the NP-hard problems, the heuristic algorithm is a powerful method. When the quality of the output can be guaranteed, the algorithm is called an approximation algorithm. In this paper, combining two types of robust settings, we consider k-means problem with penalties and outliers (k-MPO). In the k-MPO, we are given an n-point set U (equation) Rd, a penalty cost pv ≥ 0 for each v U, an integer k ≤ n, and an integer z ≤ n. The target is to find a center subset S (equation) Rd with S ≤ k, a penalty subset P (equation) U and an outlier subset Z (equation) U with Z ≤ z, such that the sum of the total costs, including the connection cost and the penalty cost, is minimized. We offer an approximation algorithm using a heuristic local search scheme. Based on a single-swap manipulation, we obtain 274-approximation algorithm. © 2023 World Scientific Publishing Co.",TextMining
"The outbreak of the COVID-19 pandemic has significantly increased the demand for personal protective equipment, in particular face masks, thus leading to a huge amount of healthcare waste generated worldwide. Consequently, such an unprecedented amount of newly emerged waste has posed significant challenges to practitioners, policy-makers, and municipal authorities involved in waste management (WM) systems. This research aims at mapping the COVID-19-related scientific production to date in the field of WM. In this vein, the performance indicators of the target literature were analyzed and discussed through conducting a bibliometric analysis. The conceptual structure of COVID-19-related WM research, including seven main research themes, were uncovered and visualized through a text mining analysis as follows: (1) household and food waste, (2) personnel safety and training for waste handling, (3) sustainability and circular economy, (4) personal protective equipment and plastic waste, (5) healthcare waste management practices, (6) wastewater management, and (7) COVID-19 transmission through infectious waste. Finally, a research agenda for WM practices and activities in the post-COVID-19 era was proposed, focusing on the following three identified research gaps: (i) developing a systemic framework to properly manage the pandemic crisis implications for WM practices as a whole, following a systems thinking approach, (ii) building a circular economy model encompassing all activities from the design stage to the implementation stage, and (iii) proposing incentives to effectively involve informal sectors and local capacity in decentralizing municipal waste management, with a specific focus on developing and less-developed countries. © 2022 International Association for Gondwana Research",TextMining
"Objective: Childhood irritability, operationalized as disproportionate and frequent temper tantrums and low frustration tolerance relative to peers, is a transdiagnostic symptom across many pediatric disorders. Studies using task-dependent functional magnetic resonance imaging (fMRI) to probe neural dysfunction in irritability have increased. However, an integrated review summarizing the published methods and synthesized fMRI results remains lacking. Method: We conducted a systematic search using irritability terms and task functional neuroimaging in key databases in March 2021, and identified 30 studies for our systematic review. Sample characteristics and fMRI methods were summarized. A subset of 28 studies met the criteria for extracting coordinate-based data for quantitative meta-analysis. Ten activation-likelihood estimations were performed to examine neural convergence across irritability measures and fMRI task domains. Results: Systematic review revealed small sample sizes (median = 58, mean age range = 8-16 years) with heterogeneous sample characteristics, irritability measures, tasks, and analytical procedures. Meta-analyses found no evidence for neural activation convergence of irritability across neurocognitive functions related to emotional reactivity, cognitive control, and reward processing, or within each domain. Sensitivity analyses partialing out variances driven by heterogeneous tasks, irritability measures, stimulus types, and developmental ages all yielded null findings. Results were compared with a review on irritability-related structural anomalies from 11 studies. Conclusion: The lack of neural convergence suggests a need for common, standardized irritability assessments and more homogeneous fMRI tasks. Thoughtfully designed fMRI studies probing commonly defined neurocognitive functions may be more fruitful to elucidate the neural mechanisms of irritability. Open science practices, data mining in large neuroscience databases, and standardized analytical methods promote meaningful collaboration in irritability research. © 2022 American Academy of Child and Adolescent Psychiatry",TextMining
"The incursion of social media in our lives has been much accentuated in the last decade. This has led to a multiplication of data mining tools aimed at obtaining knowledge from these data sources. One of the greatest challenges in this area is to be able to obtain this knowledge without the need for training processes, which requires structured information and pre-labelled datasets. This is where unsupervised data mining techniques come in. These techniques can obtain value from these unstructured and unlabelled data, providing very interesting solutions to enhance the decision-making process. In this paper, we first address the problem of social media mining, as well as the need for unsupervised techniques, in particular association rules, for its treatment. We follow with a broad overview of the applications of association rules in the domain of social media mining, specifically, their application to the problems of mining textual entities, such as tweets. We also focus on the strengths and weaknesses of using association rules for solving different tasks in textual social media. Finally, the paper provides a perspective overview of the challenges that association rules must face in the next decade within the field of social media mining. © 2022, The Author(s).",TextMining
"Despite the widespread reliance on service bundles across industries (examples include theater season-tickets, vacation packages, and annual sports passes), the impact of consumer-specific factors on the post-purchase consumptions of such bundles has received limited academic attention. Drawing on regulatory focus theory, we show that a consumer’s regulatory orientation influences the consumption of service bundles, and that the impacts are mediated by construal level. Using six studies (including a field study and a quasi-field experiment using Twitter data) we illustrate that prevention-focused individuals demonstrate concrete construal and are better able to resolve the ambiguity in allocating costs and benefits to individual bundle components, leading to higher consumption. By examining the role of a consumer’s regulatory orientation, our work advances the theoretical understanding of consumer behavior in response to the bundling of services. We make an important methodological contribution by demonstrating how text-mining can be innovatively utilized to analyze consumer posts on Twitter to infer regulatory focus and understand service bundle consumption. Our studies provide practical guidance to managers seeking to infer (using publicly available Twitter data and consumer-provided inputs during purchase) and prime (using advertisements and nudges) regulatory focus to understand/influence service consumption. © The Author(s) 2022.",TextMining
"The social media podium offers a communal perspective platform for web marketing, advertisement, political campaign, etc. It structures like-minded end-users over the explicit group as a community. Community structure over social media is the collaborative group of globally spread users having similar interests regarding a communal topic, product or any other axis. In recent years, researchers have widely used clustering techniques of data mining to structure communities over social media. Still, due to a lack of network and implicit communal information, researchers cannot bind mutually robust and modular community structures. The collaborative features of social media are inherent with implicit and explicit end-users. The explicit nature of both active and passive users is easily extracted from the graphical structure of social media. On the other hand, the degree of information inclusion of implicit features depends upon end-users participation. The Implicit features of frequently active users are diversely available, while integrating passive and silent users’ implicit features over the community is tedious. This work proposed a social theory based influence maximization (STIM) framework for community detection over social media. It combines user-generated content with profile information, extracts passive social media users through influence maximization, and provides the user space for influencing inactive users. The STIM framework clusters identical nodes over the maximum influencing node axis based on their graphical parameters such as node degree, node similarity, node reachability, modularity, and node density. This framework also provides the structural, relational and mathematical concept for the functional grouping of like-minded people as a community over social media through social theory. Finally, an evaluation has been carried out over six real-time datasets. It analyses that convolution neural network over STIM structure more dense and modular communities via influence maximization. STIM acquired around 93% modularity and 94% Normalized Mutual Information (NMI), resulting in approximately 2.23% and 5.69% improvements in modularity and NMI, respectively, over the best-acquired result of the benchmark approach. © 2022, King Fahd University of Petroleum & Minerals.",TextMining
"Plans can only impact practice when elected officials adopt, enact, and approve funding for specific strategies. We explore ways to track implementation from the planning documents to elected officials’ priorities and to their voting patterns to identify the consistencies and gaps that may limit the impact of plans. We use Twitter data mining, text content analysis, and voting records from the digitized council minutes in Calgary, Alberta, between the 2017 municipal election and the last quarter of 2020. We connect the expressed preferences to votes for each councilor over the study period. On the two most salient topics—transit and affordable housing—those who expressed support on Twitter also supported investments. With one exception of an anti-tax councilor, over time, the rest of the councilors reached agreements on public investments (supra-local funding lightened the financial burdens for the city facilitating “yes” votes). Planners can derive meaningful information from the elected officials’ social media communication, such as concerns and support for specific planning initiatives, to promote successful plan implementation. This information can also enhance voters’ awareness of local officials’ views and actions on planning initiatives. © The Author(s) 2022.",TextMining
"In this research, we developed a hybrid recommender system based on description/dialetheic logic, which provides an innovative architecture for the recommendation based on ambiguous reasoning. In addition, our approach allows enriching the knowledge during the reasoning using the linked data paradigm. Thus, the architecture allows the integration of linked data, in order to be exploited by the recommender. On the other hand, the reasoning mechanisms of dialetheic logic allow handling situations of contradiction or inconsistency, to determine the information to offer to users. According to the reviewed literature, our proposal is the first that implements a dialetheic engine in a Recommender System. In general, there are a lot of works about the utilization of linked open data (LOD) to improve the Recommender Systems, for example, to enrich the information to recommend or to solve the cold start problem. However, there are no proposals to deal with the problems of ambiguity, incoherence or incompleteness of the information in these environments extended with LOD. In this way, this paper proposes a hybrid reasoning engine that uses the linked data paradigm for the knowledge extraction, and dialetheic logic for the management of inconsistency/ambiguity information, in order to obtain recommendations. Particularly, the information extracted with Linked Data is processed with the Dialetheic Logic reasoner to solve ambiguous cases. Thus, each recommendation is enriched with related content extracted from the linked data sources, which has been disambiguated. The results are very promising since our hybrid reasoning mechanism allows obtaining more precise recommendations, considering the different classical states of ambiguity in dialetheic logic (contingent statements about the future, failure of a presupposition, vagueness, counterfactual reasoning), according to various metrics of quality used to evaluate the recommendations achieved. © 2022 John Wiley & Sons Ltd.",TextMining
"The graph neural network has received significant attention in recent years because of its unique role in mining graph-structure data and its ubiquitous application in various fields, such as social networking and recommendation systems. Although most work focuses on learning low-dimensional node representation in static graphs, the dynamic nature of real-world networks makes temporal graphs more practical and significant. In this paper, we propose a dynamic graph representation learning method based on a temporal graph transformer (TGT), which can efficiently preserve high-order information and temporally evolve structural properties by incorporating an update module, an aggregation module, and a propagation module in a single model. The experimental results on three real-world networks demonstrate that the TGT outperforms state-of-the-art baselines for dynamic link prediction and edge classification tasks in terms of both accuracy and efficiency. © 2022 THE AUTHORS",TextMining
"The growing complexity of integrated systems makes root-cause analysis increasingly difficult. To address this challenge, advances in machine learning (ML) have been leveraged in recent years to design ML-based techniques for root-cause analysis. However, most of these methods require root-cause labels for defective samples obtained based on the analysis by human experts. In this article, we propose a multialgorithm two-stage clustering method with transfer learning for unsupervised root-cause analysis. First, a two-stage clustering method is proposed by applying multiple clustering methods to accommodate both numerical and categorical data and leveraging Silhouette score for model selection. Next, a double-bootstrapping method is proposed for data selection, transferring valuable information from a source product to a target product with insufficient data. In the first bootstrapping step, a random forest model is built to select effective source data. In the second bootstrapping step, clustering ensemble is applied to two-stage clustering to further improve the accuracy for root-cause analysis. Two case studies based on network products demonstrate the superior performance of the proposed approach compared to other state-of-the-art methods.  © 1982-2012 IEEE.",TextMining
"SDP (Stochastic Dynamic Programming) control strategy can mine the travel data of drivers, so that the energy-saving potential of vehicles could be improved. However, there are two problems need to be solved in the current SDP: firstly, the analysis and construction method of driver’s typical driving cycle is not clear; secondly, the adaptability of SDP algorithm to a typical driving cycle is insufficient. To solve the above problems, a driving cycle construction method for off-line SDP solution is proposed, which is based on “analysis, dimension reduction and clustering” process. In addition, a coupled control strategy (ECMS-SDP) based on driving conditions identification is developed. Because it is difficult to predict the driving conditions in real time, the working part of the coupled control strategy is calculated by the method of improved random forest. The simulation results show that ECMS-SDP control strategy can save 8%–15% fuel on average compared with CD-CS control strategy, and can save 4%–7% fuel on average compared with ECMS control strategy. The results prove that the ECMS-SDP coupled control strategy can respond well to the changing driving environment, and the fuel economy of vehicles is enhanced. © IMechE 2022.",TextMining
"The traffic data corrupted by noise and missing entries often lead to the poor performance of Intelligent Transportation Systems (ITS), such as the bad congestion prediction and route guidance. How to efficiently impute the traffic data is an urgent problem. As a classic deep learning method, Generative Adversarial Network (GAN) achieves remarkable success in image recovery fields, which opens up a new way for the traffic data imputation. In this paper, we propose a novel spatio-temporal GAN model for the traffic data imputation (STGAN). Firstly, we design the generative loss and center loss, which not only minimizes the reconstructed errors of the imputed entries, but also ensures each imputed entry and its neighbors conform to the local spatio-temporal distribution. Then, the discriminator uses the convolution neural network classifier to judge whether the imputed matrix conforms to the global spatio-temporal distribution. As for the network architecture of the generator, we introduce the skip-connection to keep all well preserved data unchanged, and employ the dilated convolution to capture the spatio-temporal correlation in the traffic data. The experimental results show that our proposed method obviously outperforms other competitive traffic data imputation methods. © 2022 IEEE.",TextMining
"This study attempts to predict secondary school students’ performance in English and Mathematics subjects using data mining (DM) techniques. It aims to provide insights into predictors of students’ performance in English and Mathematics, characteristics of students with different levels of performance, the most effective DM technique for students’ performance prediction, and the relationship between these two subjects. The study employed the archival data of students who were 16 years old in 2019 and sat for the Malaysian Certificate of Examination (MCE) in 2021. The learning of English and Mathematics is a concern in many countries. Three main factors, namely students’ past academic performance, demographics, and psychological attributes were scrutinized to identify their impact on the prediction. This study utilized the Orange software for the DM process. It employed Decision Tree (DT) rules to determine the characteristics of students with low, moderate, and high performance in English and Mathematics subjects. DT and Naïve Bayes (NB) techniques show the best predictive performance for English and Mathematics subjects, respectively. Such characteristics and predictions may cue appropriate interventions to improve students’ performance in these subjects. This study revealed students’ past academic performance as the most critical predictor, as well as a few demographics and psychological attributes. By examining top predictors derived using four different classifier types, this study found that students’ past Mathematics performance predicts their MCE English performance and students’ past English performance predicts their MCE Mathematics performance. This finding shows students’ performances in both subjects are interrelated. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"With the rapid development of electric vehicles (EV), the problem of charging safety is a multifaceted and complex issue. Taking the integration of electric vehicle charging as the research object, including power batteries, charging piles, and power distribution grids, charging data is collected based on data mining technology. At the same time, the factors affecting charging safety are analysed, and an integrated index set is established and optimised. The comprehensive fuzzy evaluation method is used to comprehensively analyse the monitoring data of the electric vehicle charging process, the weight is determined based on the grey correlation method and the expert scoring mechanism, and an integrated evaluation model of the electric vehicle charging process is established. Analyse five sets of charging data in Nanjing through calculation examples, and output the integrated health degree of the electric vehicle charging process so that the equipment can be maintained in a targeted manner, which effectively proves the practicability and reliability of the assessment model. © 2022 The Authors. IET Smart Grid published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.",TextMining
"Tea (Camellia sinensis L.) is considered as to be one of the most consumed beverages globally and a reservoir of phytochemicals with immense health benefits. Despite numerous advantages, tea compounds lack a robust multi-disease target study. In this work, we presented a unique in silico approach consisting of molecular docking, multivariate statistics, pharmacophore analysis, and network pharmacology approaches. Eight tea phytochemicals were identified through literature mining, namely gallic acid, catechin, epigallocatechin gallate, epicatechin, epicatechin gallate (ECG), quercetin, kaempferol, and ellagic acid, based on their richness in tea leaves. Further, exploration of databases revealed 30 target proteins related to the pharmacological properties of tea compounds and multiple associated diseases. Molecular docking experiment with eight tea compounds and all 30 proteins revealed that except gallic acid all other seven phytochemicals had potential inhibitory activities against these targets. The docking experiment was validated by comparing the binding affinities (Kcal mol−1) of the compounds with known drug molecules for the respective proteins. Further, with the aid of the application of statistical tools (principal component analysis and clustering), we identified two major clusters of phytochemicals based on their chemical properties and docking scores (Kcal mol−1). Pharmacophore analysis of these clusters revealed the functional descriptors of phytochemicals, related to the ligand–protein docking interactions. Tripartite network was constructed based on the docking scores, and it consisted of seven tea phytochemicals (gallic acid was excluded) targeting five proteins and ten associated diseases. Epicatechin gallate (ECG)-hepatocyte growth factor receptor (PDB id 1FYR) complex was found to be highest in docking performance (10 kcal mol−1). Finally, molecular dynamic simulation showed that ECG-1FYR could make a stable complex in the near-native physiological condition. Graphical abstract: [Figure not available: see fulltext.]. © 2022, The Author(s), under exclusive licence to Springer Nature Switzerland AG.",TextMining
"Conventional multiview clustering seeks to partition data into respective groups based on the assumption that all views are fully observed. However, in practical applications, such as disease diagnosis, multimedia analysis, and recommendation system, it is common to observe that not all views of samples are available in many cases, which leads to the failure of the conventional multiview clustering methods. Clustering on such incomplete multiview data is referred to as incomplete multiview clustering (IMC). In view of the promising application prospects, the research of IMC has noticeable advances in recent years. However, there is no survey to summarize the current progresses and point out the future research directions. To this end, we review the recent studies of IMC. Importantly, we provide some frameworks to unify the corresponding IMC methods and make an in-depth comparative analysis for some representative methods from theoretical and experimental perspectives. Finally, some open problems in the IMC field are offered for researchers. © 2022 IEEE.",TextMining
"As the number of unlabeled or mislabeled electroencephalogram (EEG) increases dramatically in such applications as cerebral disease diagnosis, rehabilitation, and brain-computer interfaces, the supervised approaches that require labels or markers become inapplicable. Unfortunately, there are few reports on unsupervised studies for unlabeled EEG data, especially for unlabeled EEG clustering. To address the challenging task, we propose an effective approach named ShVEEGc for EEG clustering inspired by an improved Shapley value in cooperative game theory. The idea of ShVEEGc is first utilizing an improved cosine similarity to measure the correlations of EEG data and then calculating the improved Shapley value based on the inherent connection between unlabeled EEG data, which considers both global connections and local relationships potentially hidden in EEG data. Thus, ShVEEGc not only has good anti-interference ability but also can mine potential relationships among unlabeled EEG data. The comparison experiments with fourteen state-of-the-art EEG time series clustering algorithms on eleven real-world EEG datasets with four standard evaluation criteria demonstrate the efficacy and superiority of ShVEEGc for EEG clustering. Besides, the discussion on the impact of several different similarity measures on ShVEEGc also illustrates that the improved cosine similarity proposed in this paper is more suitable for EEG data.  © 2017 IEEE.",TextMining
"Aspect term extraction (ATE), a fundamental subtask in aspect-based sentiment analysis, aims to extract explicit aspect term from reviewers’ expressed opinions. However, the distribution of samples containing different numbers of aspect terms is long-tailed. Due to the scarcity of long-tailed samples and the existence of multiple variable-length aspect terms inside each sample, most ATE models converge to an inferior state because they have difficulty capturing features. Popular data augmentation techniques used for addressing this problem, such as synonym replacement and back translation, cannot produce substantial improvements when using pretrained language models. In this paper, we present a novel span-level aspect term extraction (SATE) framework, which includes three main components: a simple and effective tag data augmentation (TaDA) module, an original pretrained language model, and an optimized heuristic decoding algorithm module. TaDA is based on a span-level tagging scheme and generates new pseudo training samples for long-tailed multiaspect samples. The pretrained model, deemed a general feature extractor, yields contextual token representations. Then, the decoding algorithm adopts an adjustment factor to extract the variable-length aspect terms simultaneously. All the techniques are seamlessly integrated into the stacked SATE framework to pinpoint the aspect terms. Empirical experiments on SemEval benchmark datasets of multiple domains achieve F1-scores of 86.92% and 86.28% for laptops and restaurants, respectively, demonstrating the superiority of our model compared with the well-known baseline models. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Sustainable Development Goals (SDG) are at the forefront of government initiatives across the world. The SDGs are primarily concerned with promoting sustainable growth via ensuring wellbeing, economic growth, environmental legislation, and academic advancement. One of the most prominent goals of the SDG is to provide learners with high-quality education (SDG 4). This paper aims to look at the perspectives of the Sustainable Development Goals improvised to provide quality education. We also analyze the existing state of multiple initiatives implemented by the Indian government in the pathway to achieving objectives of quality education (SDG 4). Additionally, a case study is considered for understanding the association among the observed indicators of SDG4. For this purpose, exploratory data analysis, and numerical association rule mining in combination with QuantMiner genetic algorithm approaches have been applied. The outcomes reveal the presence of a significant degree of association among these parameters pointing out the fact that understanding the impact of one (or more) indicator on other related indicators is critical for achieving SDG 4 goals (or factors). These findings will assist governing bodies in taking preventive measures while modifying existing policies and ensuring the effective enactment of SDG 4 goals, which also will subsequently aid in the resolution of issues related to other SDGs. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"The experience of diagnosis, decision-making and management in critical congenital heart disease is layered with complexity for both families and clinicians. We synthesise the current evidence regarding the family and healthcare provider experience of critical congenital heart disease diagnosis and management. A systematic integrative literature review was conducted by keyword search of online databases, MEDLINE (Ovid), PsycINFO, Cochrane, cumulative index to nursing and allied health literature (CINAHL Plus) and two journals, the Journal of Indigenous Research and Midwifery Journal from 1990. Inclusion and exclusion criteria were applied to search results with citation mining of final included papers to ensure completeness. Two researchers assessed study quality combining three tools. A third researcher reviewed papers where no consensus was reached. Data was coded and analysed in four phases resulting in final refined themes to summarise the findings. Of 1817 unique papers, 22 met the inclusion criteria. The overall quality of the included studies was generally good, apart from three of fair quality. There is little information on the experience of the healthcare provider. Thematic analysis identified three themes relating to the family experience: (1) The diagnosis and treatment of a critical congenital heart disease child significantly impacts parental health and wellbeing. (2) The way that healthcare and information is provided influences parental response and adaptation, and (3) parental responses and adaptation can be influenced by how and when support occurs. The experience of diagnosis and management of a critical congenital heart disease child is stressful and life-changing for families. Further research is needed into the experience of minority and socially deprived families, and of the healthcare provider, to inform potential interventions at the healthcare provider and institutional levels to improve family experience and support. © 2022, The Author(s).",TextMining
"Xuanbai Chengqi Decoction (XBCQD), a classic traditional Chinese medicine, has been widely used to treat COVID-19 in China with remarkable curative effect. However, the chemical composition and potential therapeutic mechanism is still unknown. Here, we used multiple open-source databases and literature mining to select compounds and potential targets for XBCQD. The COVID-19 related targets were collected from GeneCards and NCBI gene databases. After identifying putative targets of XBCQD for the treatment of COVID-19, PPI network was constructed by STRING database. The hub targets were extracted by Cytoscape 3.7.2 and MCODE analysis was carried out to extract modules in the PPI network. R 3.6.3 was used for GO enrichment and KEGG pathway analysis. The effective compounds were obtained via network pharmacology and bioinformatics analysis. Drug-likeness analysis and ADMET assessments were performed to select core compounds. Moreover, interactions between core compounds and hub targets were investigated through molecular docking, molecular dynamic (MD) simulations and MM-PBSA calculations. As a result, we collected 638 targets from 61 compounds of XBCQD and 845 COVID-19 related targets, of which 79 were putative targets. Based on the bioinformatics analysis, 10 core compounds and 34 hub targets of XBCQD for the treatment of COVID-19 were successfully screened. The enrichment analysis of GO and KEGG indicated that XBCQD mainly exerted therapeutic effects on COVID-19 by regulating signal pathways related to viral infection and inflammatory response. Meanwhile, the results of molecular docking showed that there was a stable binding between the core compounds and hub targets. Moreover, MD simulations and MM-PBSA analyses revealed that these compounds exhibited stable conformations and interacted well with hub targets during the simulations. In conclusion, our research comprehensively explained the multi-component, multi-target, and multi-pathway intervention mechanism of XBCQD in the treatment of COVID-19, which provided evidence and new insights for further research. Graphical abstract: [Figure not available: see fulltext.]. © 2022, The Author(s), under exclusive licence to Springer Nature Switzerland AG.",TextMining
"Conventional machine learning techniques may have lesser performance when they deal with complex data. For addressing this issue, it is important to build data mining frameworks coupled with robust knowledge discovery mechanisms. One of such frameworks, which addresses these issues is ensemble learning. It fuses data, builds models and mines data into a single framework. In spite of the work done on ensemble learning, there remain issues like how to manage the complexity, how to optimize the model, and how to fine-tune the model. Natural data processing schemes use parallel processing and are robust and efficient, hence are successful. Taking a cue from natural data processing architectures, we propose a parallelized CNN tree ensemble approach. The proposed approach is compared against the baseline which is the deep network used in the ensemble. The ResNet50 architecture is utilized for initial experimentation. The datasets used for this task are the ImageNet and natural images datasets. The proposed approach outperforms the baseline on all experiments on the ImageNet dataset. Further, benchmarking of the proposed approach against different types of CNNs is done on various datasets including CIFAR-10, CIFAR-100, Fashion-MNIST, FEI face recognition, and MNIST digits. Since our approach is adaptable for CNNs, it outperforms the baseline CNNs as well as the state-of-the-art techniques on these datasets. The CNNs architectures used for benchmarking are ResNet-50, DenseNet, WRN-28-10 and NSGANetV1. The code for the paper is available in https://github.com/mueedhafiz1982/CNNTreeEnsemble.git. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Discovering valuable information needs some extra focuses on business processes. Although data-centric techniques yield useful results, they are insufficient to explain the causes of the problems in the process. This study aims to reveal the relationship between customer satisfaction and other key performance indicators (KPIs) affected by the activities performed during the call process. The research applies process mining, a pragmatic analysis to obtain meaningful insights through event logs. Several statistical analyses also support the process mining to test the statistical significance. The study showed that customer satisfaction is positively affected by average handle time and first call resolution, whereas staff mistakes diminish it. Moreover, problem solving is much more important than waiting in the system. Waitlisted and Waitlisted back activities are crucial elements of a call center system. Moreover, the research presents an insight for customers who give the same score after the call. It explains not only KPIs’ effects but also reasons for giving satisfaction scores based on call process. Additionally, in previous studies, the customer satisfaction indicator was mainly emphasized, but other KPIs’ effects on satisfaction level were ignored. This paper evaluates the impact of the identified KPIs on satisfaction in a process-oriented manner. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Multi-view clustering research is a hot topic in the field of data mining, where complementary information between views can better describe data objects and improve the clustering performance. Non-negative matrix factorization (NMF) based multi-view clustering algorithm suffers from weak feature extraction, slow convergence speed and low accuracy. To solve these problems, this paper proposes a generalized deep learning multi-view clustering (GDLMC) algorithm based on NMF. Firstly, via decoupling the elements in the matrix, the matrix elements are non-negatively restricted using an activation function with a non-negative value domain, and the elements are updated employing stochastic gradient descent with learning rate guidance. Then, the corresponding gradients when the elements update are transformed into generalized weights and generalized biases, followed by combining the generalized weights and generalized biases with activation functions to construct generalized deep learning (GDL). Further, GDL is adopted to learn the corresponding low-dimensional matrix of each view and consensus matrix for obtaining the GDLMC algorithm. In addition, the detailed reasoning of the GDLMC algorithm are given. Finally, extensive experiments are conducted on four public datasets including regular and large-scale datasets, and the experimental results show that GDLMC has significant advantages.  © 2022 IEEE.",TextMining
"This paper examines the up-to-dateness of installed firmware versions of Internet of Things devices accessible via public Internet. It takes a novel approach to identify versions based on the source code of their web interfaces. It analyzes data sets of 1.06m devices collected using the IoT search engine Censys and then maps the results against the latest version each manufacturer offers. A fully scalable and adaptive approach is developed by applying the SEMMA data mining process. This approach relies on three data artifacts: raw data from Censys, a mapping table with firmware versions, and a keyword search list. The results confirm the heterogeneity of connected IoT devices and show that only 2.45 percent of the IoT devices 'in the wild' run the latest available firmware. Installed versions are 19.2 months old on average. This real-world evidence suggests that the updating processes and methods used by engineers so far are not sufficient to keep IoT devices up-to-date. This paper identifies and quantifies influencing factors and captures the global and diverse distribution of IoT devices. It finds manufacturer and device type influence the up-to-dateness of firmware, whereas the country in which the device is deployed is less significant. © 1976-2012 IEEE.",TextMining
"Proper regulation of the earth pressure on the bulkhead of earth-pressure balanced (EPB) shield tunneling machines is significant to ensure safe construction. This study proposes a procedure for regulating the bulkhead pressure by combining numerical simulations and data mining, and applies the procedure to a metro line constructed in sandy pebble stratum using EPB shield. Firstly, the relationship between the bulkhead pressure and the pressure on the tunnel face is carefully obtained from discrete element modeling, and the required supporting earth pressure is derived by considering the arching effect. Secondly, aided with the machine learning method, a model is constructed for predicting the average bulkhead pressure per ring according to the operational parameters (i.e., the average driving speed and the rotation speed of the screw conveyor). Given the target value of the bulkhead pressure, the optimal values of the operational parameters are obtained from the model. In addition, an autoregressive moving average stochastic process model is developed to monitor the real-time fluctuation of the bulkhead pressure and guide the actions taken in time to avoid dramatic fluctuations. The results indicate that the pressure difference between the tunnel face and the bulkhead is considerable, and the consideration of the arching effect can avoid overestimating the bulkhead pressure. A combination of the machine learning model and the stochastic process model provides a plausible performance in regulating the bulkhead pressure around the target value without dramatic fluctuation. © 2022",TextMining
"Face recognition (FR) has received remarkable attention for improving feature discrimination with the development of deep convolutional neural networks (CNNs). Although the existing methods have achieved great success in designing margin-based loss functions by using hard sample mining strategy, they still suffer from two issues: 1) the neglect of some training status and feature position information and 2) inaccurate weight assignment for hard samples due to the coarse hardness description. To solve these issues, we develop a novel loss function, namely Hardness Loss, to adaptively assign weights for the misclassified (hard) samples guided by their corresponding hardness, which accounts for multiple training status and feature position information. Specifically, we propose an estimator to provide the real-time training status to precisely compute the hardness for weight assignment. To the best of our knowledge, this is the first attempt to design a loss function by using multiple pieces of information about the training status and feature positions. Extensive experiments on popular face benchmarks demonstrate that the proposed method is superior to the state-of-the-art (SOTA) losses under various FR scenarios. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Vehicle trajectory prediction is a challenging problem in the field of autonomous driving, which is of great significance to the safety of autonomous driving and traffic roads. In view of the interaction between surrounding vehicles and target vehicle and its own trajectory, we propose a new graph network model to predict future vehicle trajectory. First, the correlation network of vehicles at each time is constructed based on the complex network method. In order to make up for the lack of real spatial relevance caused by the fixed graph, we propose an adaptive parameter matrix to coordinate and optimize the global spatio-temporal graph. Second, the global spatio-temporal features of vehicle historical trajectory data are extracted by stacked graph convolution module. Finally, the obtained graph features are coded based on seq2seq network, and the trajectory prediction of road vehicles at different times in the future is realized. Our model has been trained and verified on the published NGSIM US-101 and I-80 data sets. Compared with other advanced schemes, our model has more accurate results in the future time of 5 seconds. In predicting the future group trajectory of vehicles on the road, the accuracy of long-term prediction is 16.6% higher than that of the most advanced scheme.  © 2016 IEEE.",TextMining
"Purpose: To estimate among people living with chronic HIV, to what extent providing feedback on their health outcomes will affect the number and specificity of patient-formulated self-management goals. Methods: A personalized feedback profile was produced for individuals enrolled in a Canadian HIV Brain Health Now study. Goal specificity was measured by total number of specific words (matched to a domain-specific developed lexicon) per person-words using text mining techniques. Results: Of 176 participants enrolled and randomly assigned to feedback and control groups, 110 responses were received. The average number of goals was similar for both groups (3.7 vs 3.9). The number of specific words used in the goals formulated by the feedback and control group were 642 and 739, respectively. Specific nouns and actionable verbs were present to some extent and “measurable” and “time-bound” words were mainly missing. Negative binomial regression showed no difference in goal specificity among groups (RR = 0.93, 95% CI 0.78–1.10). Goals set by both groups overlapped in 8 areas and had little difference in rank. Conclusion: Personalized feedback profile did not help with formulation of high-quality goals. Text mining has the potential to help with difficulties of goal evaluation outside of the face-to-face setting. With more data and use of learning models automated answers could be generated to provide a more dynamic platform. © 2022, The Author(s), under exclusive licence to Springer Nature Switzerland AG.",TextMining
"Nowadays, we are witnessing a paradigm shift from the conventional approach of working from office spaces to the emerging culture of working virtually from home. Even during the COVID-19 pandemic, many organisations were forced to allow employees to work from their homes, which led to worldwide discussions of this trend on Twitter. The analysis of this data has immense potential to change the way we work but extracting useful information from this valuable data is a challenge. Hence in this study, the microblogging website Twitter is used to gather more than 450,000 English language tweets from 22nd January 2022 to 12th March 2022, consisting of keywords related to working from home. A state-of-the-art pre-processing technique is used to convert all emojis into text, remove duplicate tweets, retweets, username tags, URLs, hashtags etc. and then the text is converted to lowercase. Thus, the number of tweets is reduced to 358,823. In this paper, we propose a fine-tuned Convolutional Neural Network (CNN) model to analyse Twitter data. The input to our deep learning model is an annotated set of tweets that are effectively labelled into three sentiment classes, viz. positive negative and neutral using VADER (Valence Aware Dictionary for sEntiment Reasoning). We also use a variation in the input vector to the embedding layer, by using FastText embeddings with our model to train supervised word representations for our text corpus of more than 450,000 tweets. The proposed model uses multiple convolution and max pooling layers, dropout operation, and dense layers with ReLU and sigmoid activations to achieve remarkable results on our dataset. Further, the performance of our model is compared with some standard classifiers like Support Vector Machine (SVM), Naive Bayes, Decision Tree, and Random Forest. From the results, it is observed that on the given dataset, the proposed CNN with FastText word embeddings outperforms other classifiers with an accuracy of 0.925969. As a result of this classification, 54.41% of the tweets are found to show affirmation, 24.50% show a negative disposition, and 21.09% have neutral sentiments towards working from home. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Aspect-based sentiment analysis aims to predict sentiment polarities of given aspects in text. Most current approaches employ attention-based neural methods to capture semantic relationships between aspects and words in one sentence. However, these methods ignore the fact that sentences with the same aspect and sentiment polarity often share the structure and semantic information in a domain, which leads to lower model performance. To mitigate this problem, we propose a heterogeneous aspect graph neural network (HAGNN) to learn the structure and semantic knowledge from intersentence relationships. Our model is a heterogeneous graph neural network since it contains three different kinds of nodes: word nodes, aspect nodes, and sentence nodes. These nodes can pass structure and semantic information between each other and update their embeddings to improve the performance of our model. To the best of our knowledge, we are the first to use a heterogeneous graph to capture relationships between sentences and aspects. The experimental results on five public datasets show the effectiveness of our model outperforming some state-of-the-art models.  © 2014 IEEE.",TextMining
"Free text answers to short questions can reflect students' mastery of concepts and their relationships relevant to learning objectives. However, automating the assessment of free text answers has been challenging due to the complexity of natural language. Existing studies often predict the scores of free text answers in a 'black box' manner without analyzing their semantic components, which at least partially limit the prediction performance. In this article, we focus on fine-grained semantic facets in free text answers that correspond to knowledge to be mastered. Using a dataset with semantic facet annotation, we first show the correspondence of semantic facet matching states and answer quality, as well as the importance of semantic facets in automatic assessment of answer quality. We then extend the work to a dataset without semantic facet annotation and demonstrate the effectiveness of proposed automated methods in assessing answer quality, including semantic facet extraction, matching state prediction based on a neural framework, and feature engineering with semantic facets. The contribution of this research is twofold: 1) the proposed methods improve state-of-the-art performance of automatic assessment of free text answers and 2) it delves into fine-grained semantic components of free text answers, making it possible to explain the scores and generate detailed feedback. © 2008-2011 IEEE.",TextMining
"The neuromorphic event cameras can efficiently sense the latent geometric structures and motion clues of a scene by generating asynchronous and sparse event signals. Due to the irregular layout of the event signals, how to leverage their plentiful spatio-temporal information for recognition tasks remains a significant challenge. Existing methods tend to treat events as dense image-like or point-serie representations. However, they either suffer from severe destruction on the sparsity of event data or fail to encode robust spatial cues. To fully exploit their inherent sparsity with reconciling the spatio-temporal information, we introduce a compact event representation, namely 2D-1T event cloud sequence (2D-1T ECS). We couple this representation with a novel light-weight spatio-temporal learning framework (ECSNet) that accommodates both object classification and action recognition tasks. The core of our framework is a hierarchical spatial relation module. Equipped with specially designed surface-event-based sampling unit and local event normalization unit to enhance the inter-event relation encoding, this module learns robust geometric features from the 2D event clouds. And we propose a motion attention module for efficiently capturing long-term temporal context evolving with the 1T cloud sequence. Empirically, the experiments show that our framework achieves par or even better state-of-the-art performance. Importantly, our approach cooperates well with the sparsity of event data without any sophisticated operations, hence leading to low computational costs and prominent inference speeds. © 1991-2012 IEEE.",TextMining
"The gravitational clustering algorithm is a dynamic clustering model that achieves outstanding performance in uncovering the hidden clusters of a complex dataset with any shape, density and distribution. This algorithm is very suitable for mining irregular and unbalanced clusters from large-scale datasets with noise. However, the unbearable time overhead makes this algorithm ineffective to apply at large scales. Therefore, a parallel gravitational clustering algorithm based on grid partitioning (PGCGP) is developed in this paper. First, a grid partitioning strategy is designed to divide a large-scale dataset into multiple grids as evenly as possible. Second, a neighbourhood repair strategy is proposed to work with the gravitational clustering algorithm to accurately mine the clusters of a single grid. Finally, a border point alignment strategy is devised to determine whether to merge two small clusters located in different grids to discover the real clusters of the original large dataset by merging multiple grids. Extensive experiments on multiple artificial and real-world datasets verify that our PGCGP approach achieves good performance. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"In recent years, the concept of crowdsourcing becomes more popular and on demand due to the capability of solving many real-world problems in less time. The crowd-sourcing has several ben- efits such as increased speed, flexibility and efficiency in terms of collecting and processing the data. One of the major demands in this crowdsourcing is to find the truthfulness of the obtained data and to ascertain trustworthiness of the sources. Several existing approaches are used for truth discovery among crowd-sourced-based applications. But they work efficiently only for structured data and the accuracy levels are dependent on the availability of ground truth values. To over- come the above-mentioned issues a novel truth discovery model is proposed. In this work it uses knowledge extraction and truth discovery phases to process the data. Reliability scores are assigned to trustworthy users based on the frequency with which they provide true values over a period of time. It works on both categorical and continues data. So, finally the proposed model is tested on three real-valued data sets. Experimental results prove to provide better performance than the conventional approaches. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TextMining
"During mining, processing and utilization of coal, the environment is exposed to piles of coal, coal gangue and coal ash, which have human health concerns. Coal and coal gangue samples were obtained from a coal mining company located in Southern Province, Sinazongwe District, Zambia. The main objective of this research was to determine the level of heavy metals in coal gangue and coal from Sinazongwe District. Six metals (Ni, Pb, Cu, Cd, Fe and Zn) were determined using an atomic absorption spectrophotometer. The mean concentration of heavy metals in four grades of coal was as follows: Zn (23.83–71.67), Cu (20.82–44.59), Fe (7148.85–22,905.44), Ni (0.89–16.24), Cd (0.38–1.11) and Pb (13.96–46.02) mg/kg. The mean concentration of heavy metals in two types of coal gangues was as follows: Zn (36.62–63.56), Cu (1.51–44.28), Fe (11,619.86–12,193.46), Ni (6.48–7.89), Cd (0.97–1.17) and Pb (58.67–70.18) mg/kg. Generally, the concentrations of heavy metals detected were within the safe environmental disposal limits except Pb which was elevated in coal gangue. Digestion of samples was done in a mixture of hydrofluoric, nitric and perchloric acids. ANOVA was used to analyse the data, with means separated using Duncan’s multiple range test at 95% significance level. Generally, significant differences (p < 0.05) were noticed for the mean concentration of heavy metals with all four grades of coal. The mean concentrations of Zn, Cu, Ni and Pb showed significant differences with all grades of coal (p < 0.05). There was a significant difference (p < 0.05) in mean concentration of Zn with mudstone, sandstone and control sample. © 2022, The Author(s) under exclusive licence to Iranian Society of Environmentalists (IRSEN) and Science and Research Branch, Islamic Azad University.",TextMining
"Digital technology and literacy can heighten the transformation of teaching and learning in higher education institutions (HEIs). This study uncovers the extent to which digital technologies have been used to advance the teaching and learning process in HEIs, and the barriers and bottlenecks to why it may not have been effectively implemented across the HEIs. The study used nine selected countries in Latin America (LATAM) based on the main focus of the educators, commercial, and financial investors; to show the level of impact/implications of computer technologies on the teaching and learning processes. We applied a two-step (mixed) methodology (through a quantitative and qualitative lens) for the research investigation, using data collected from survey we administered to faculty members in HEIs across the different countries in LATAM. In turn, we implemented a Text Mining technique (sentiment and emotional valence analysis) to analyze opinions (textual data) given by the participants to help determine challenges and obstacles to using the digital technologies for teaching and learning in the region. Quantitatively, we applied a Kruskal–Wallis H-test to analyze the collected multiple choice and ranked items in the questionnaire in order to identify prominent factors that consummately influence the reach, barriers, and bottlenecks, and where the differences may lie across the different LATAM countries. The results show that the users upheld the emphasis on lack of training, infrastructures and resources, access to internet and digital platforms, as the main challenges to the teaching–learning process. The study also empirically discussed and shed light on critical factors the HEIs, particularly in LATAM, should resolve and adopt in support of the decision-making strategies, operational policies and governance, financial investments, and policymaking, at a time when “digital technologies” have become an inevitable and indispensable part of education and learning. © 2022, The Author(s).",TextMining
"Transportation networks are essential to the operation of societies and economies. Protecting the privacy of sensitive information is a meaningful conception in sustainable transport when mining the transportation data. In data mining, differential privacy (DP) has provable privacy guarantees for releasing sensitive data by introducing randomness into query results. However, it suffers from significant accuracy loss of outputs when the query has high sensitivity (e.g., triangle counting). The reason is that the range of random perturbation to each query result in DP is too large. It consists of all possible output values for a query that forms a large or even unbounded interval. However, when impose perturbation only in a small neighborhood of the true query result, the similarity measure based on randomness in DP fails. Thereupon, we introduce fuzziness into DP to formulate new models which have smaller disturbance via fuzzy similarity measures. In this article, we establish a novel and general theory of private data analysis, fuzzy differential privacy (FDP). The new theory FDP aims to acquire a more flexible tradeoff between the accuracy of outputs and the privacy-preserving level of data. FDP combines DP with fuzzy set theory by introducing fuzziness into the query results and characterizing similarities between outputs via multiple fuzzy similarity measures. From this perspective, DP can be viewed as a special case of FDP with probabilistic similarity measure. Compared with DP, FDP has three superiorities: 1) most fuzzy similarity measures in FDP support sliding window perturbation strategies we proposed, which refer to perturbation in a small neighborhood of the query results; 2) FDP adds noise to the query results only according to a fraction of all possible neighboring datasets; and 3) the fuzzy similarity with valued in [0,1] quantifies the privacy protection level intuitively. These three points enable more accurate outputs while providing provable and intuitive privacy guarantees. As for subgraph counting, the state-of-the-art method is ladder framework in DP. We illustrate FDP mechanisms by applying them to a common application in subgraph counting-triangle/4-cliques counting. Experiments show that FDP is effective and efficient with smaller output errors than DP.  © 1993-2012 IEEE.",TextMining
"As part of Big Data trends, the ubiquitous use of the Internet of Things (IoT) in the industrial environment has generated a significant amount of network traffic. In this type of IoT industrial network where there is a large equipment heterogeneity, security is a fundamental issue; thus, it is very important to detect likely intrusion behaviors. Furthermore, since the proportion of labeled data records is small in the IoT environment, it is challenging to detect various attacks and intrusions accurately. This investigation builds a semisupervised ladder network model for intrusion detection in the Industrial IoT. This model considers the manifold distribution of high-dimensional data and incorporates a manifold regularization constraint in the decoder of the ladder network. Meanwhile, the feature propagation between layers is strengthened by adding more cross-layer connections in this model. On this basis, a random attention-based data fusion approach is proposed to generate global features for intrusion detection. The experiments on the CIC-IDS2018 dataset show that the proposed approach can recognize the intrusion with less false alarm rate, while model training is time efficient. © 2005-2012 IEEE.",TextMining
"Deep metric learning has yielded impressive results in tasks such as clustering and image retrieval by leveraging neural networks to obtain highly discriminative feature embeddings, which can be used to group samples into different classes. Much research has been devoted to the design of smart loss functions or data mining strategies for training such networks. Most methods consider only pairs or triplets of samples within a mini-batch to compute the loss function, which is commonly based on the distance between embeddings. We propose Group Loss, a loss function based on a differentiable label-propagation method that enforces embedding similarity across all samples of a group while promoting, at the same time, low-density regions amongst data points belonging to different groups. Guided by the smoothness assumption that 'similar objects should belong to the same group', the proposed loss trains the neural network for a classification task, enforcing a consistent labelling amongst samples within a class. We design a set of inference strategies tailored towards our algorithm, named Group Loss++ that further improve the results of our model. We show state-of-the-art results on clustering and image retrieval on four retrieval datasets, and present competitive results on two person re-identification datasets, providing a unified framework for retrieval and re-identification.  © 1979-2012 IEEE.",TextMining
"The brain-computer interface (BCI) is a cutting-edge technology that has the potential to change the world. Electroencephalogram (EEG) motor imagery (MI) signal has been used extensively in many BCI applications to assist disabled people, control devices or environments, and even augment human capabilities. However, the limited performance of brain signal decoding is restricting the broad growth of the BCI industry. In this article, we propose an attention-based temporal convolutional network (ATCNet) for EEG-based motor imagery classification. The ATCNet model utilizes multiple techniques to boost the performance of MI classification with a relatively small number of parameters. ATCNet employs scientific machine learning to design a domain-specific deep learning model with interpretable and explainable features, multihead self-attention to highlight the most valuable features in MI-EEG data, temporal convolutional network to extract high-level temporal features, and convolutional-based sliding window to augment the MI-EEG data efficiently. The proposed model outperforms the current state-of-the-art techniques in the BCI Competition IV-2a dataset with an accuracy of 85.38% and 70.97% for the subject-dependent and subject-independent modes, respectively.  © 2005-2012 IEEE.",TextMining
"Unsupervised clustering is a crucial issue in data mining and pattern recognition. Based on deep learning paradigms, deep clustering algorithms have been studied extensively and obtained superior performance in various applications. However, most of previous methods did not use helpful information from neighborhood relations to form group-separated space, and the feature embedding is usually distorted during the training process. To tackle the former limitation, we develop a graph convolution based unsupervised learning algorithm named Stacked Graph Autoencoder (SGAE). Specifically, SGAE utilizes the message passing mechanism to aggregate information from neighbors and obtain a meaningful and separated latent representation. Since the adjacency matrix is unavailable in clustering tasks, a graph construction approach with two pruning strategies is introduced to generate a transition matrix. To reduce the distortion caused by the multi-layered network training process, we further propose a topological structure preservation mechanism. It uses the constructed adjacency graph as supervised information, to maintain the relationship between nodes in the original space. Experiments on several popular benchmark datasets show that SGAE achieves significant improvements compared to unsupervised and semi-supervised deep clustering methods.  © 2022 IEEE.",TextMining
"With the development of cloud storage, more and more users upload images to the cloud. However, images stored in the cloud face the risk of unauthorized data mining by cloud service providers and being stolen by hackers. Encryption can protect image privacy, but traditional image encryption algorithms sacrifice image usability for security. To protect privacy while preserving image usability, two approximate thumbnail-preserving encryption (TPE) schemes, called dynamic range preserving encryption (DRPE) and approximate TPE with LSB Embedding (TPE-LSB), have been presented by Marohn in 2017. However, there is the possibility of decryption failure for DRPE, the cipher image robustness is poor for TPE-LSB, which cannot resist noise attacks. Additionally, both methods have the problems of the high file expansion rate of cipher image and poor perceptual quality of cipher image thumbnail. To solve these problems, a multi-level DWT information self-embedding method for thumbnail preserving encryption (TPE-ISE) is proposed. Compared with the previous works, the TPE-ISE scheme achieves a controllable compression ratio of cipher images, the perceptual quality of cipher images is closer to that of plain images, and the ability of cipher images to resist noise attacks is stronger. A series of experiments verify the superiority of the proposed algorithm. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"We explore machine learning for accurately predicting imminent disk failures and hence providing proactive fault tolerance for modern large-scale storage systems. Current disk failure prediction approaches are mostly offline and assume that the disk logs required for training learning models are available a priori. However, disk logs are often continuously generated as an evolving data stream, in which the statistical patterns vary over time (also known as concept drift). Such a challenge motivates the need of online techniques that perform training and prediction on the incoming stream of disk logs in real time, while being adaptive to concept drift. We first measure and demonstrate the existence of concept drift on various disk models in production. Motivated by our study, we design StreamDFP, a general stream mining framework for disk failure prediction with concept-drift adaptation based on three key techniques, namely online labeling, concept-drift-aware training, and general prediction, with a primary objective of supporting various machine learning algorithms. We extend StreamDFP to support online transfer learning for minority disk models with concept-drift adaptation. Our evaluation shows that StreamDFP improves the prediction accuracy significantly compared to without concept-drift adaptation under various settings, and achieves reasonably high stream processing performance.  © 1968-2012 IEEE.",TextMining
"In this article, to estimate the battery state of health (SOH) under realistic electric vehicle (EV) conditions, a robust and efficient data-driven algorithm is developed and validated through comprehensive battery life testing. More than 50 state-of-the-art EV battery cells have been tested under a variety of cycling conditions with different charging protocols, dynamic driving cycles, voltage ranges, pulse rates, and temperatures. Some of the cells have also been tested under a combination of cycling and storage conditions, constant current and multistep charging, and a periodic temperature variation that mimics real life conditions. Only partial data (voltage, current, and temperature) within a narrow state-of-charge range under a dynamic driving condition are required to extract the health indicators. A neural network is trained to find the mapping between the health features and the battery SOH. The life test data are divided into three groups. The first dataset (≈55% of data) is used for training and initial validation and testing, whereas the second and third datasets (≈45% of data) are entirely used for the final validation and testing to minimize the network overfitting. The results show that the SOH estimation root-mean-squared error for all datasets is less than 0.9%, signifying the fidelity and reliability of the proposed method. © 1982-2012 IEEE.",TextMining
"In big data, the frequent item set mining is an important framework for many applications. Several techniques were used to mine the frequent item sets, but for the collapsed and complex data, it is difficult. Hence, the current research work aimed to model a novel Frequent Pattern Growth-Hybrid Ant Colony and African Buffalo Model (FPG-HACABM) is developed to overcome this issue and to reduce the execution time. Moreover, the Fitness function of HACABM is utilized to calculate the support count of each item and to improve the classification accuracy. Thus the proposed models classify the frequently utilized items accurately and arranged those items in descending order. This helps to run the big data transactional application effectively without any delay. Finally, the key metrics are validated with the existing models and better results are attained by achieving a high accuracy rate of 99.82% and less execution time of 0.0018 ms. © 2023 World Scientific Publishing Company.",TextMining
"Video recommendation has become a crucial role in mitigating the semantic gap in recommending the video based on visual features. This article proposed the exploitation of low-level visual features extracted from videos, and the input data to generate relevant recommendations. Initially, the video is pre-processed with Motion Adaptive Gaussian Denoising Filtering, which eliminates noise from video frames and achieves improved efficiency with high quality and video resolution, which requires less computation. After pre-processing, the paper proposed a content-based extraction approach to retrieve the temporal and spatial characteristics. The temporal characteristics represent the dynamic viewpoints of video, including average shot time and object movement, while the spatial characteristics illustrate a static effect, such as colour and lighting key. Subsequently, this utilizes a series of representative visual features to make the video content more accurate. Finally, the work incorporates a deep neural network to predict the video according to the input and the features extracted. The supervised learning algorithm Multilayer feed-forward is therefore proposed, which generated a series of outputs from a given input set (input data and the extracted features). The majority of deep learning solutions deliver deterministic outcomes and do not measure or monitor prediction variance, which can contribute to a loss of faith in automatic evaluation. Subsequently, Monte Carlo’s uncertainty techniques are used to estimate the exact video in accordance with the recommendation. The proposed method is implemented using MATLAB r2020a software with less computation time of 0.999 s and the performance of the proposed method is compared with the different existing methods like MMM, LP-LGSN, and CDPRec. Consequently, the proposed method produces higher performance in terms of precision, recall, F-measures, and nDCG and it produces higher accuracy of 0.94%, respectively. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Economic and operational advantages have led the supply chain of printed circuit boards (PCBs) to incorporate various untrusted entities. Any of the untrusted entities are capable of introducing malicious alterations to facilitate a functional failure or leakage of secret information during field operation. While researchers have been investigating the threat of malicious modification within the scale of individual microelectronic components, the possibility of a board-level malicious manipulation has essentially been unexplored. In the absence of standard benchmarking solutions, prospective countermeasures for PCB trust assurance are likely to utilize homegrown representation of the attacks that undermine their evaluation and do not provide scope for comparison with other techniques. In this article, we have developed a benchmarking solution to facilitate an unbiased and comparable evaluation of countermeasures applicable to PCB trust assurance. Based on a taxonomy tailored for PCB-level alterations, we have developed a toolflow for the automatic generation of Trojan benchmarks to facilitate a comprehensive evaluation against a large number of diverse Trojan implementations and application of data mining for trust verification. Using the toolflow, we have developed a suite of custom 'Trojan benchmarks' (i.e., PCB designs with Trojans) containing representative examples of Trojans in the taxonomy inserted in different PCB designs of varying complexity and functionality. Finally, with experimental measurements from a fabricated PCB and structural analysis of netlist, we analyze the stealthiness of the Trojan designs and present the runtime of the tool for a large number of PCB designs.  © 1982-2012 IEEE.",TextMining
"With the growth of the academic engines, the mining and analysis acquisition of massive researcher data, such as collaborator recommendation and researcher retrieval, has become indispensable for improving the quality and intelligence of services. However, most of the existing studies for researcher data mining focus on a single task for a particular application scenario and learning a task-specific model, which is usually unable to transfer to out-of-scope tasks. In this paper, we propose a multi-task self-supervised learning-based researcher data pre-training model named RPT, which is efficient to accomplish multiple researcher data mining tasks. Specifically, we divide the researchers' data into semantic document sets and community graph. We design the hierarchical Transformer and the local community encoder to capture information from the two categories of data, respectively. Then, we propose three self-supervised learning objectives to train the whole model. For RPT's main task, we leverage contrastive learning to discriminate whether these captured two kinds of information belong to the same researcher. In addition, two auxiliary tasks, named hierarchical masked language model and community relation prediction for extracting semantic and community information, are integrated to improve pre-training. Finally, we also propose two transfer modes of RPT for fine-tuning in different scenarios. We conduct extensive experiments to evaluate RPT, results on three downstream tasks verify the effectiveness of pre-training for researcher data mining. © 2022 IEEE.",TextMining
"Background and Aim: Deep learning technology has not been implemented successfully in oral cancer images classification due to the overfitting problem. Due to the network arrangement and lack of proper data set for training, the network might not produce the required feature map with dimension reduction which result in overfitting problems. This research aims to reduce the overfitting by producing the required feature map with dimension reduction through using Convolutional Neural Network. Methodology: The proposed system uses the Enhanced Convolutional Neural Network and the autoencoder technique to increase the efficiency of feature extraction process and compresses the information. In this technique, unpooling and deconvolution is done to generate the input data to minimize the difference between input and output data. Furthermore, it extracts characteristic features from the input data set which regenerates the input data from those features by learning a network to reduce the overfitting problem. Results: Different value of accuracy and processing time is achieved using different sample group of Confocal Laser Endomicroscopy (CLE) images. Based on result, it shows that the proposed solution is better than the current system. Also, the proposed system has improved the classification accuracy by 5 ~ 5.5% in average and reduced the processing time by 20 ~ 30 milliseconds in average. Conclusion: The proposed system is focused on accurately classifying the oral cancer cells of different anatomical locations from the CLE images. Finally, this study enhances the accuracy and processing time using autoencoder method and solve the problem of overfitting. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Background: The medicinal properties of plants can be predicted by virtue of phylogenetic methods, which nevertheless have not been utilized to explore the regularity of skin-related bioactivities of ethnomedicinal plants. We aim to investigate the distribution of skin efficacy of Asteraceae and Ranunculales plants on the species-level Tree of Life. Methods: The clinical efficacy data of 551 ethnomedicinal species belonging to Ranunculales, as well as 579 ethnomedicinal species of Asteraceae, were systematically collected and collated; these therapeutic data fell into 15 categories, including skin disease/cosmeceutical. The large phylogenetic tree of all China angiosperm species was used to detect the phylogenetic signals of ethnomedicinal plants by calculating the D statistic, phylogenetic diversity (PD), net relatedness index (NRI), and nearest taxon index (NTI). Of all Chinese ethnomedicinal plants of Ranunculales and Asteraceae, 339 (61.5% of all ethnomedicinal species) and 382 (66.0% of all) are used for skin problems. In Ranunculales, a clustered structure was suggested by the NRI value for skin uses. In Asteraceae, the skin utility was not clustered; Artemisia, Aster, Cremanthodium, Ligularia, and Saussurea are the most used Asteraceae genera for skin issues. Results: The clustering structure was identified in Artemisia, and the skin efficacy in other genera was of overdispersion (NRI < 0). NTI values and D statistics largely agree with NRI. When compared with PD values of different therapeutic categories, the PD value of the skin category was relatively high in Cremanthodium, Ranunculales, Asteraceae, and Artemisia, suggesting the enormous efficacy space in the new taxa of these taxonomic groups. Conclusion: By resolving the distribution of therapeutic effects of Ranunculales/Asteraceae taxa, the importance of phylogenetic methods in mining botanical resources with skin utilities is validated. © 2023 Bentham Science Publishers.",TextMining
"Situational awareness tries to grasp the important events and circumstances in the physical world through sensing, communication, and reasoning. Tracking the evolution of changing situations is an essential part of this awareness and is crucial for providing appropriate resources and help during disasters. Social media, particularly Twitter, is playing an increasing role in this process in recent years. However, extracting intelligence from the available data involves several challenges, including (a) filtering out large amounts of irrelevant data, (b) fusion of heterogeneous data generated by the social media and other sources, and (c) working with partially geo-tagged social media data in order to deduce the needs of the affected people. Spatio-temporal analysis of the data plays a key role in understanding the situation, but is available only sparsely because only a small fraction of people post relevant text and of those very few enable location tracking. In this paper, we provide a comprehensive survey on data analytics to assess situational awareness from social media big data.  © 2022 IEEE.",TextMining
"Objective: To evaluate the study quality and clinical value of radiomics studies on chondrosarcoma. Methods: PubMed, Embase, Web of Science, China National Knowledge Infrastructure, and Wanfang Data were searched for articles on radiomics for evaluating chondrosarcoma as of January 31, 2022. The study quality was assessed according to Radiomics Quality Score (RQS), Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD) checklist, Image Biomarker Standardization Initiative (IBSI) guideline, and modified Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2) tool. The level of evidence supporting clinical use of radiomics on chondrosarcoma differential diagnosis was determined based on meta-analyses. Results: Twelve articles were included. The median RQS was 10.5 (range, −3 to 15), with an adherence rate of 36%. The adherence rate was extremely low in domains of high-level evidence (0%), open science and data (17%), and imaging and segmentation (35%). The adherence rate of the TRIPOD checklist was 61%, and low for section of title and abstract (13%), introduction (42%), and results (56%). The reporting rate of pre-processing steps according to the IBSI guideline was 60%. The risk of bias and concern of application were mainly related to the index test. The meta-analysis on differential diagnosis of enchondromas vs. chondrosarcomas showed a diagnostic odds ratio of 43.90 (95% confidential interval, 25.33–76.10), which was rated as weak evidence. Conclusions: The current scientific and reporting quality of radiomics studies on chondrosarcoma was insufficient. Radiomics has potential in facilitating the optimization of operation decision-making in chondrosarcoma. Key Points: •Among radiomics studies on chondrosarcoma, although differential diagnostic models showed promising performance, only pieces of weak level of evidence were reached with insufficient study quality. •Since the RQS rating, the TRIPOD checklist, and the IBSI guideline have largely overlapped with each other, it is necessary to establish one widely acceptable methodological and reporting guideline for radiomics research. •The TRIPOD model typing, the phase classification of image mining studies, and the level of evidence category are useful tools to assess the gap between academic research and clinical application, although their modifications for radiomics studies are needed. © 2022, The Author(s), under exclusive licence to European Society of Radiology.",TextMining
"Accurate prediction of sea surface temperature (SST) is extremely important for forecasting oceanic environmental events and for ocean studies. However, the existing SST prediction methods do not consider the seasonal periodicity and abnormal fluctuation characteristics of SST or the importance of historical SST data from different times; thus, these methods suffer from low prediction accuracy. To solve this problem, we comprehensively consider the effects of seasonal periodicity and abnormal fluctuation characteristics of SST data, as well as the influence of historical data in different periods, on prediction accuracy. We propose a novel ensemble learning approach that combines the Predictive Recurrent Neural Network(PredRNN) network and an attention mechanism for effective SST field prediction. In this approach, the XGBoost model is used to learn the long-period fluctuation law of SST and to extract seasonal periodic features from SST data. The exponential smoothing method is used to mitigate the impact of severely abnormal SST fluctuations and extract the a priori features of SST data. The outputs of the two aforementioned models and the original SST data are stacked and used as inputs for the next model, the PredRNN network. PredRNN is the most recently developed spatiotemporal deep learning network, which simulates both spatial and temporal representations and is capable of transferring memory across layers and time steps. Therefore, we used it to extract the spatiotemporal correlations of SST data and predict future SSTs. Finally, an attention mechanism is added to capture the importance of different historical SST data, weigh the output of each step of the PredRNN network, and improve the prediction accuracy. The experimental results on two ocean datasets confirm that the proposed approach achieves higher training efficiency and prediction accuracy than the existing SST field prediction approaches do. © 2023, Higher Education Press.",TextMining
"Before developing a new mobile app, the development team usually endeavors painstaking efforts to review many existing apps with similar purposes. The review process is crucial in the sense that it reduces market risks and provides inspirations for app development. However, manual exploration of hundreds of existing apps by different roles (e.g., product manager, UI/UX designer, developer, and tester) can be ineffective. For example, it is difficult to completely explore all the functionalities of the app from different aspects including design, implementation, and testing in a short period of time. However, existing reverse engineering tools only provide basic features such as AndroidManifest.xml and Java source files for users. Following the conception of storyboard in movie production, we propose a system, named StoryDistiller, to automatically generate the storyboards for Android apps with rich features through reverse engineering, and assist different roles to review and analyze apps effectively and efficiently. Specifically, we (1) propose a hybrid method to extract a relatively complete Activity transition graph (ATG), that is, it first extracts the ATG of Android apps through static analysis method first, and further leverages dynamic component exploration to augment ATG; (2) extract the required inter-component communication (ICC) data of each target Activity by leveraging static data-flow analysis and renders UI pages dynamically by using app instrumentation together with the extracted required ICC data; (3) obtain rich features including comprehensive ATG with rendered UI pages, semantic activity names, corresponding logic and layout code, etc. (4) implement the storyboard visualization as a web service with the rendered UI pages and the corresponding rich features. Our experiments unveil that StoryDistiller is effective and indeed useful to assist app exploration and review. We also conduct a comprehensive comparison study to demonstrate better performance over IC3, Gator, Stoat, and StoryDroid. © 1976-2012 IEEE.",TextMining
"In complex traffic scenes, accurate identification of pedestrian orientations can help drivers determine pedestrian trajectories and help reduce traffic accidents. However, there are still many challenges in pedestrian orientation recognition. First, due to the irregular appearance of pedestrians, it is difficult for general Convolutional Neural Networks (CNNs) to extract discriminative features. In addition, more features of body parts help to judge the orientation of pedestrians. For example, head, arms and legs. However, they are usually small and not conducive to feature extraction. Therefore, in this work, we use several discrete values to define the orientation of pedestrians, and propose a Gated Graph Neural Network (GGNN)-based Graph Recurrent Attention Network (GRAN) to classify the orientation of pedestrians. The contributions are as follows: (1) We construct a body parts graph consisting of head, arms and legs on the feature maps output by the CNN backbone. (2) Mining the dependencies between body parts on the graph via the proposed GRAN, and utilizing the encoder–decoder to propagate features among graph nodes. (3) In this process, we propose an adjacency matrix with attention edge weights to dynamically represent graph node relationships, and the edge weights are learned during network training. To evaluate the proposed method, we conduct experiments on three different benchmarks (PDC, PDRD, and Cityscapes) with 8, 3, and 4 orientations, respectively. Note that the orientation labels for PDRD and Cityscapes are annotated by our hand. The proposed method achieves 97%, 91% and 90% classification accuracy on the three data sets, respectively. The results are all higher than current state-of-the-art methods, which demonstrate the effectiveness of the proposed method. © 2022, The Author(s).",TextMining
"Background: Imaging findings of both anterior cruciate ligament (ACL) sprain and mucoid degeneration overlap in some cases, which may cause errors in magnetic resonance imaging (MRI) evaluation. Purpose: To determine the ancillary findings on MRI in distinguishing between ACL sprain and mucoid degeneration, and also to obtain a diagnostic scheme. Material and Methods: MRI scans of 77 patients with ACL mucoid degeneration and 77 cases with ACL sprain were retrospectively evaluated to compare with regard to parameters of age, sex, side, the status of posterior cruciate ligament – medial collateral ligament – lateral collateral ligament, bone marrow edema, intraosseous cyst, subchondral sclerosis, chondromalacia, meniscus tear, effusion, and osteochondral body. A decision tree algorithm was created to predict pathology in ACL, whether it was a sprain or mucoid degeneration. Results: The prevalence of female sex, femoral intraosseous cyst, tibial intraosseous cyst, subchondral sclerosis, femoral chondromalacia, tibial chondromalacia, medial meniscus tear, and lateral meniscus tear were significantly higher in the ACL mucoid degeneration group (P < 0.001, P = 0.016, P < 0.001, P = 0.003, P < 0.001, P < 0.001, P < 0.001, and P < 0.001, respectively). The probability of being mucoid degeneration increased 41.2 times (95% confidence interval [CI] = 5.296–321.132) in cases with tibial intraosseous cyst and increased 1.05 times (95% CI = 1.010–1.080) with each one-year increase in age (P < 0.001 and P = 0.011, respectively). The decision tree algorithm had an overall accuracy of 79.2%. Conclusion: Ancillary findings are helpful in the diagnosis of suspicious cases for ACL mucoid degeneration and ACL sprain. The decision tree algorithm offers a practical and successful approach to this issue. © The Foundation Acta Radiologica 2022.",TextMining
"Cerebrovascular segmentation from Time-of-flight magnetic resonance angiography (TOF-MRA) is a critical step in computer-aided diagnosis. In recent years, deep learning models have proved its powerful feature extraction for cerebrovascular segmentation. However, they require many labeled datasets to implement effective driving, which are expensive and professional. In this paper, we propose a generative consistency for semi-supervised (GCS) model. Considering the rich information contained in the feature map, the GCS model utilizes the generation results to constrain the segmentation model. The generated data comes from labeled data, unlabeled data, and unlabeled data after perturbation, respectively. The GCS model also calculates the consistency of the perturbed data to improve the feature mining ability. Subsequently, we propose a new model as the backbone of the GSC model. It transfers TOF-MRA into graph space and establishes correlation using Transformer. We demonstrated the effectiveness of the proposed model on TOF-MRA representations, and tested the GCS model with state-of-the-art semi-supervised methods using the proposed model as backbone. The experiments prove the important role of the GCS model in cerebrovascular segmentation. Code is available at https://github.com/MontaEllis/SSL-For-Medical-Segmentation.  © 1982-2012 IEEE.",TextMining
"With appearing of adversarial examples which are able to fool deep neural networks, some defense methods are developed to recognize adversarial images. This paper focuses on a new kind of detection on adversarial examples, which aims to find the abnormal user who utilized adversarial examples among a number of normal users. Due to the utilization of adversarial images, the abnormal user is significantly deviated from the majority normal users. Based on this, we propose a straightforward method to extract abnormity information, and design a pooled detection scheme to identify the abnormal user by hierarchical clustering. Experimental results show that our scheme is able to identify the utilization of popular adversarial example methods, and achieve low computational complexity.  © 2017 IEEE.",TextMining
"Abstract: In the past 10 years, how to visualize human emotions in communication has become an important topic. For providing personalized customer service for enterprises from self-reflection in psychology to opinion mining, emotional visualization uses coded emotional computing results to make various basic charts, and some novel visual analysis systems for all-round analysis which intuitively reveal personal views and emotional styles. Emotion visualization uses coded emotion computing results to reflect the emotion analysis tasks, such as self-reflection in psychology or social media opinion mining results. With the help of various basic charts, infographics, and some novel visual analysis systems, it makes all directions’ analysis and intuitively reveals personal opinions and emotional styles. At present, emotional visualization has developed to use different platforms or multiple platforms to analyze various complex data, including text, sound, image, video, physiological signal or any mixed data. In this paper, we discuss a total of 75 approaches from four different categories: data source type, emotional computing, visual coding and visualization and visual analysis tasks, and 15 subcategories, including visual works mentioned in published paper and interactive visual works published on the Internet. Then, we discuss the further research approaches of emotional visualization and the prospects of emotional visualization under multidimensional data collaboration. We expect that this survey can help researchers interested in emotional visualization of varied data to find a more suitable visualization method for their data and projects. Graphical abstract: [Figure not available: see fulltext.]. © 2022, The Visualization Society of Japan.",TextMining
"Bone tumor is a kind of rare cancer, the location of which is mainly in bone tissue as well as cartilage tissue. Bone tumor is mainly classified into benign and malignant types. The survival rate of patients with bone tumors can be considerably improved by early detection, and the danger of amputation caused by bone tumors can be greatly reduced. In this study, we first screened the top 25% serum miRNAs with the greatest variance in patients with malignant and benign bone tumor and healthy individuals. The expression of serum miRNAs in patients with bone tumor was then examined using unsupervised clustering and PCA, and the results revealed that the overall expression of serum miRNAs was ineffective in distinguishing patients with benign/malignant bone tumors. Subsequently, we screened 19 miRNA biomarkers that could be used to determine the benign/malignant bone tumor of patients by LASSO logistic regression. These genes were validated using ROC curves. Results showed that there were 11 miRNAs that could accurately distinguish benign/malignant bone tumor alone. These 11 miRNAs were, namely, hsa-miR-192-5p, hsa-miR-137, hsa-miR-142-3p, hsa-miR-155-3p, hsa-miR-1205, hsa-miR-1273a, hsa-miR-3187-3p, hsa-miR-1255b-2-3p, hsa-miR-1288-5p, hsa-miR-6836-5p, and hsa-miR-6862-5p. Next, we established a diagnostic model using logistic regression and validated the diagnostic model using ROC curves; the result of which showed that the model had good diagnostic efficacy. Then, we also verified that the diagnostic model established by these 11 miRNAs could distinguish patients with benign/malignant bone tumor using unsupervised clustering as well as PCA. Finally, by using qPCR, we validated the expression of 11 miRNAs in the serum of patients with malignant and benign bone tumors, as well as healthy volunteers. The results were consistent with the trend of miRNAs expression in public databases. In summary, we examined the differential expression of serum miRNAs in individuals with benign and malignant bone tumors and discovered 11 miRNA biomarkers that could be utilized to discriminate between the two. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Graph-based semi-supervised learning methods have been used in a wide range of real-world applications, e.g., from social relationship mining to multimedia classification and retrieval. However, existing methods are limited along with high computational complexity or not facilitating incremental learning, which may not be powerful to deal with large-scale data, whose scale may continuously increase, in real world. This paper proposes a new method called Data Distribution Based Graph Learning (DDGL) for semi-supervised learning on large-scale data. This method can achieve a fast and effective label propagation and supports incremental learning. The key motivation is to propagate the labels along smaller-scale data distribution model parameters, rather than directly dealing with the raw data as previous methods, which accelerate the data propagation significantly. It also improves the prediction accuracy since the loss of structure information can be alleviated in this way. To enable incremental learning, we propose an adaptive graph updating strategy which can update the model when there is distribution bias between new data and the already seen data. We have conducted comprehensive experiments on multiple datasets with sample sizes increasing from seven thousand to five million. Experimental results on the classification task on large-scale data demonstrate that our proposed DDGL method improves the classification accuracy by a large margin while consuming much less time compared to state-of-the-art methods.  © 1979-2012 IEEE.",TextMining
"Data mining was introduced and 178 sets of alternating current (AC) corrosion data were collected from published data and our research group. The AC current density (JAC), direct current (DC), current density (JDC), the ratio of AC/DC current density (JAC/JDC), and cathodic protection potential (IR-free potential, EIR-free) were defined as the input feature and the priority of feature subset was ranked as (JAC, JDC) > (JDC, JAC/JDC) > (JAC, EIR-free) >JAC > (JAC/JDC, EIR-free) > JAC/JDC. Then, based on the different feature subsets, the AC corrosion rate model was established by the random forest algorithm, and the generalization ability of the model was verified on the test data respectively. Finally, the mapping relationship between AC, DC parameters, and corrosion rates was presented and the limiting values of (JAC, JDC) and (JDC, JAC/JDC) were given. © 2022 Wiley-VCH GmbH.",TextMining
"Purpose: We aimed to improve OR efficiency using machine learning (ML) to find relevant metrics influencing surgery time success and team performance on efficiency to create a model which incorporated team, patient, and surgery-related factors. Methods: From 2012 to 2020, five surgeons, 44 nurses, and 152 anesthesiologists participated in 1199 four joint days (4796 cases): 1461 THA, 1496 TKA, 652 HR, 242 UKA, and 945 others. Patients were 2461f:2335 m; age, 64.1; BMI, 29.93; and ASA, 2.45. Surgical Success was defined as completing four joints within an eight hour shift using one OR. Time data was recorded prospectively using Surgical Information Management Systems. Hospital records provided team, patient demographics, adverse events, and anesthetic. Data mining identified patterns and relationships in higher dimensions. Predictive analytics used ML ranking algorithm to identify important metrics and created decision tree models for benchmarks and success probability. Results: Five variables predicted success: anaesthesia preparation time, surgical preparation time, time of procedure, anesthesia finish time, and type of joint replacement. The model determined success rate with accuracy of 72% and AUC = 0.72. Probability of success based on mean performance was 77–89% (mean-median) if APT 14–15 minutes, PT 68–70 minutes, AFT four to five minutes, and turnover 25–27 minutes. With the above benchmarks maintained, success rate was 59% if surgeon exceeded 71.5-minutes PT or 89% if 64-minutes procedure time or 66% when anesthesiologist spent 17–19.5 minutes on APT. Conclusion: AI-ML predicted OR success without increasing resources. Benchmarks track OR performance, demonstrate effects of strategic changes, guide decisions, and provide teamwork improvement opportunities. © 2022, The Author(s) under exclusive licence to SICOT aisbl.",TextMining
"Recent interest by governmental, non-governmental and civil society organisations in monitoring, tracing, tracking and flushing out illegal mining activities in Ghana has intensified due to the fact that large tracts of arable lands, forests and water resources are destroyed by this group of illegal miners. Yet, the scale of operation, types, characteristics and spatial distribution of illegal mining activities across the 16 regions of Ghana remain inadequate in the scientific literature. This study investigates the types, characteristics and spatial distribution of galamsey activities in Upper West Region. Cross-sectional spatial data were sourced using Garmin GPS extre 30 and corroborated with key informant interviews in Wa East, Wa West and Nadowli-Kaleo Districts. From the results, a total of 2505 individual sightings under 6 major galamsey types (underground pit, dig and check, dig and wash, chamfi, mill house and shormp) were uncovered. The results showed that Wa West District is dominated by the dig and check galamsey while Wa East District hosts the large majority of the underground pits. In addition, Nadowli-Kaleo District is dominated by the underground pit galamsey. Wa East District was the hotspot of illegal mining activities (1644 sightings) in the region. Based on the characterisation, this study, argued that galamsey activities in Upper West Region are still at the rudimentary stage as compared to other geographies in Ghana. Constant monitoring of the where and how ASM activities are being carried out in the region is pertinent in eradicating and reclaiming galamsey degraded lands. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.",TextMining
"Background: Select and enact appropriate learning tactics that advance learning has been considered a critical set of skills to successfully complete highly flexible online courses, such as Massive open online courses (MOOCs). However, limited by analytic methods that have been used in the past, such as frequency distribution, sequence mining and process mining, we lack a deep, complete and detailed understanding of the learning tactics used by MOOC learners. Objectives: In the present study, we proposed four major dimensions to better interpret and understand learning tactics, which are frequency, continuity, sequentiality and role of learning actions within tactics. The aim of this study was to examine to what extent can a new analytic technique, the ordered network analysis (ONA), deepen the understanding of MOOC learning tactics compared to using other methods. Methods: In particular, we performed a fine-grained analysis of learning tactics detected from more than 4 million learning events in the behavioural trace data of 8788 learners who participated in a large-scale MOOC ‘Flipped Classroom’. Results and Conclusions: We detected eight learning tactics, and then chose one typical tactic as an example to demonstrate how the ONA technique revealed all four dimensions and provided deeper insights into this MOOC learning tactic. Most importantly, based on the comparison with different methods such as process mining, we found that the ONA method provided a unique opportunity and novel insight into the roles of different learning actions in tactics which was neglected in the past. Takeaway: In summary, we conclude that ONA is a promising technique that can benefit the research on learning tactics, and ultimately benefit MOOC learners by strengthening the strategic support. © 2022 The Authors. Journal of Computer Assisted Learning published by John Wiley & Sons Ltd.",TextMining
"High-speed train delay prediction has always been one of the important research issues in the railway dispatching. Accurate and interpretable delay prediction can enable staff to implement preventive measures and scheduling decisions in advance, and guide relevant departments to cooperate in completing complex transportation tasks, so as to improve rail transit operations, service quality, and the efficiency of train operation. This article proposes a new interpretable model based on graph community neural network and time-series fuzzy decision tree. This model can well capture the influence of spatiotemporal characteristics, train community structure, and multifactor in high-speed train station delay prediction. Besides, the time series fuzzy decision tree based on multiobjective optimization and reduced error pruning can mine potential decision rules to improve the model's interpretability, transparency, and high reliability. Finally, we prove that the prediction effect of the proposed model is superior than the other seven state-of-the-art models and our model is interpretable.  © 1993-2012 IEEE.",TextMining
"Machine learning (ML) based malicious traffic detection is an emerging security paradigm, particularly for zero-day attack detection, which is complementary to existing rule based detection. However, the existing ML based detection achieves low detection accuracy and low throughput incurred by inefficient traffic features extraction. Thus, they cannot detect attacks in realtime, especially in high throughput networks. Particularly, these detection systems similar to the existing rule based detection can be easily evaded by sophisticated attacks. To this end, we propose Whisper, a realtime ML based malicious traffic detection system that achieves both high accuracy and high throughput by utilizing frequency domain features. It utilizes sequential information represented by the frequency domain features to achieve bounded information loss, which ensures high detection accuracy, and meanwhile constrains the scale of features to achieve high detection throughput. In particular, attackers cannot easily interfere with the frequency domain features and thus Whisper is robust against various evasion attacks. Our experiments with 74 types of attacks demonstrate that, compared with the state-of-the-art systems, Whisper can accurately detect various sophisticated and stealthy attacks, achieving at most 18.36% improvement of AUC, while achieving two orders of magnitude throughput. Even under various evasion attacks, Whisper is still able to maintain around 90% detection accuracy.  © 1993-2012 IEEE.",TextMining
"Purpose: It is a priority of the US Food and Drug Administration (FDA) to monitor the safety of medications used during pregnancy. Pregnancy exposure registries and cohort studies utilizing electronic health record data are primary sources of information but are limited by small sample sizes and limited outcome assessment. TreeScan™, a statistical data mining tool, can be applied within the FDA Sentinel System to simultaneously identify multiple potential adverse neonatal and infant outcomes after maternal medication exposure. Methods: We implemented TreeScan using the Sentinel analytic tools in a cohort of linked live birth deliveries and infants nested in the IBM MarketScan® Research Database. As a case study, we compared first trimester fluoroquinolone use and cephalosporin use. We used the Bernoulli and Poisson TreeScan statistics with compatible propensity score-based study designs for confounding control (matching and stratification) and used multiple propensity score models with various strategies for confounding control to inform best practices. We developed a hierarchical outcome tree including major congenital malformations and outcomes of gestational length and birth weight. Results: A total of 1791 fluoroquinolone-exposed and 8739 cephalosporin-exposed mother-infant pairs were eligible for analysis. Both TreeScan analysis methods resulted in single alerts that were deemed to be due to uncontrolled confounding or otherwise not warranting follow-up. Conclusions: In this implementation of TreeScan using Sentinel analytic tools, we did not observe any new safety signals for fluoroquinolone use in the first trimester. TreeScan, with tailored or high-dimensional propensity scores for confounding control, is a valuable tool in addition to current safety surveillance methods for medications used during pregnancy. © 2022 John Wiley & Sons Ltd.",TextMining
"An accurate prediction of the machining tool condition during the cutting process is crucial for enhancing the tool life, improving the production quality and productivity, optimizing the labor and maintenance costs, and reducing workplace accidents. Currently, tool condition monitoring is usually based on machine learning algorithms, especially deep learning algorithms, to establish the relationship between sensor signals and tool wear. However, deep mining of feature and fusion information of multi-sensor signals, which are strongly related to the tool wear, is a critical challenge. To address this issue, in this study, an integrated prediction scheme is proposed based on deep learning algorithms. The scheme first extracts the local features of a single sequence and a multi-dimensional sequence from DenseNet incorporating a heterogeneous asymmetric convolution kernel. To obtain more perceptual historical data, a “dilation” scheme is used to extract features from a single sequence, and one-dimensional dilated convolution kernels with different dilation rates are utilized to obtain the differential features. At the same time, asymmetric one-dimensional and two-dimensional convolution kernels are employed to extract the features of the multi-dimensional signal. Ultimately, all the features are fused. Then, the time-series features hidden in the sequence are extracted by establishing a depth-gated recurrent unit. Finally, the extracted in-depth features are fed to the deep fully connected layer to achieve the mapping between features and tool wear values through linear regression. The results indicate that the average errors of the proposed model are less than 8%, and this model outperforms the other tool wear prediction models in terms of both accuracy and generalization. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Using massive text data, building a knowledge graph to implement in-depth association analysis and mining can help identify entities and make decisions. The accuracy of traditional Chinese Named Entity Recognition methods is low, and traditional frequent itemset mining methods are also difficult to obtain different types of categories, and their novelty is not high. In this paper, we propose an association rule mining method based on named entity recognition and text classification (ARMTNER). First, the TextCNN model is used to extract the word vector information of the text data; secondly, bidirectional LSTM is used the model extracts the contextual features of the text; then the neural network model is used to automatically extract the word features and the global features of the text for text classification; finally, the text sequence labeling and entity recognition are performed. Then the association rules be used to mine frequent itemsets through two-level classification of text classification and entity classification. The experimental results showed that, our method can achieve an F1-score of 97.3% on the public data set in Chinese Named Entity Recognition, and the novelty of frequent itemsets increased by 0.279%. © 2022, King Fahd University of Petroleum & Minerals.",TextMining
"Unsupervised domain adaptation (UDA)-based methods have made great progress in bearing fault diagnosis under variable working conditions. However, most existing UDA-based methods focus only on minimizing the discrepancy of two working conditions. The similarity of fault features extracted from the bearing vibration signal is ignored. The samples near the distribution boundaries learned by the network might be misclassified. As a result, even if the marginal distributions is aligned well, the diagnosis result may not be satisfactorily. Therefore, this paper proposes a domain adaptation network base on contrastive learning (DACL) to achieve the aim of bearing fault diagnosis cross different working conditions and reduce the probability of samples being classified near or on the boundary of each class to improve diagnosis accuracy. The method is made up of a feature mining module and an adversarial domain adaptation module. In the feature mining module, a one-dimensional Convolutional Neural Network (1-D CNN) is utilized to extract features from raw vibration signals. The adversarial domain adaptation module followed is designed to learn domain-shared discriminant features for aligning marginal distribution. Meanwhile, the contrastive estimation term is designed to quantize the similarity of data distribution and increase the distance between samples of different health conditions, declining the probability of samples near the boundary and improving diagnosis performance. At last, an adaptive factor is introduced to measure the relative importance of transferring and discriminating abilities of the method. The effectiveness of the proposed method is confirmed by examining various fault diagnosis scenarios with domain discrepancies across the source and target domains, using experimental data from two bearing systems. © 2022 Elsevier Ltd",TextMining
"Dimensionality reduction plays an important role in image recognition and data mining. Traditional methods extract features from data itself and ignore the structure information of data even though it is crucial for effective representation. Considering graph embedding method can capture and model the complicated relationships among data, therefore, we consider to incorporate graph convolution learning into principal component analysis (GCPCA) to abstract more effective features in this paper. The key idea of the proposed model is embedding graph convolutional to realize linear representation by fusing the relationship of data points. Then PCA is operated on projected data to extract effective features. The model can be solved to obtain a globally optimal closed-form solution, which is convenient for implementation and practical application. Experiments on some publicly available datasets demonstrate that the proposed GCPCA model show the better performance than the existing classical algorithms in terms of classification accuracy. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Learner satisfaction is the degree of consistency between learners’ perception and expectation of learning experience. In massive online open courses, analyzing the influencing factors of learner satisfaction is of great significance to improving the quality of course development and learning experience. Taking the open course reviews as data source, the paper adopted topic sentiment analysis and intermediary hierarchical linear modelling to analyze the impact of different student and course level features on learner satisfaction. The data analysis shows that the schedule, workload and completion status, as well as the video, instructor, content and evaluation topics play significant roles in explaining learner satisfaction; However, perceived difficulty, structure and interaction are not related to learner satisfaction; Meanwhile, sentiment-mediated analysis found that, teachers and evaluation topics have significant mediating effect on schedule; Video topic has a significant mediating effect on workload. Based on the above analysis, enlightenment to curriculum designers and developers are also provided. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Climate data consists of multiple high-dimensional time series and multiple-dimensional space series with unknown series. These unknown series in climate data hide the complex co-variation relation patterns. By exploring these co-variation relation patterns, we can further reveal the complex representations between time series and space series in climate data. Therefore, it is a tough task to explore what kinds of relation patterns from high-dimensional climate data containing unknown complicated multi-variables. To address this, we proposed neural networks with three layers according to Brenier’s theorem. Brenier’s theorem rigorously proves that the data distribution in the background space is consistent with the data distribution in the reconstructed feature space with greatest probability, thereby ensuring that the relation patterns extracted by the proposed model are as close as possible to the original relation patterns. For the three series sets (i.e., a time series set, a spatial series set containing longitude, and a spatial series set containing latitude) in the climate dataset, we adopted the compact coding manner that one layer encodes a series set correspondingly, in order to maintain the consistency between a time series and two spatial series. Results on the ECMWF climate datasets show that the proposed method gains deeper relation patterns than competitors, i.e., the relation patterns captured by our method outperforms competitors in terms of regularity (for spatial series) and periodicity (for time series). We demonstrate that by this compact coding manner, neural networks capture deeper relation patterns from high-dimensional data containing complicated multiple variables due to this coding manner can accurately filter out more non-eigenvalue information from those complicated data. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"This paper provides an in-depth analysis and study of the simulation of 3D human animation visualization techniques by enhancing machine learning algorithms. Based on the statistical analysis of the data obtained from different measurement methods, the extraction of human body feature parameters based on millimeter-wave point cloud data is realized, and the 3D reconstruction and simulation of the human body are realized using parametric human modeling software. In video-based action recognition, most methods are data-driven and use deep networks to automatically learn features of the entire video image. In this process, specific research on human actions is not included or reflected. However, human action recognition is a processing of the semantic level of video content. Realizing universal human action recognition requires a semantic understanding of human behavior. Firstly, the geometric feature analysis of the 3D scanned human model is performed to extract the human body shape characteristic parameters, and the research on the analysis and estimation methods of body shape characteristic parameters is carried out to establish the human body shape parameter relationship model; then, the millimeter-wave point cloud is calculated and measured, the Li group features extracted using the group skeletal representation model with high data dimensionality, to be able to process the high-dimensional data, while reducing the complexity of the recognition process and speeding up the computation, feature learning and classification are performed with convolutional neural networks. To verify the better library portability and robustness of the method in this paper, the method was tested on a self-built human action database in the laboratory, and an average recognition rate of 97.26% was achieved. Meanwhile, this paper investigates the natural interaction application of virtual characters in a virtual learning environment based on human action recognition. Four testers tested the virtual human–computer interaction system of this paper, respectively, and the final test results show that the system has flexibility and stability. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",TextMining
"Object-centric process mining is a novel branch of process mining that aims to analyze event data from mainstream information systems (such as SAP) more naturally, without being forced to form mutually exclusive groups of events with the specification of a case notion. The development of object-centric process mining is related to exploiting object-centric event logs, which includes exploring and filtering the behavior contained in the logs and constructing process models which can encode the behavior of different classes of objects and their interactions (which can be discovered from object-centric event logs). This paper aims to provide a broad look at the exploration and processing of object-centric event logs to discover information related to the lifecycle of the different objects composing the event log. Also, comprehensive tool support (OC-PM) implementing the proposed techniques is described in the paper. © 2022, The Author(s).",TextMining
"The Internet of Things (IoT) is a modern age technology, designed with the vision to connect and also interconnect all the objects everywhere. Technological progressions provide businesses with many comforts as well as helps the attackers and intruders to crack the IoT networks’ security. Numerous Intrusion Detection Systems (IDSs) are created aimed to attack prevention systems. Frequently, security stays to be challenging in the IoT networks. The work addressed here presents the new effective secured IDS aimed at IoT environment, which sustains the data’s confidentiality, integrity, together with its availability. At first, the data has been pre-processed, which helps in acquiring a clear vision about any attack that is about to occur. The methods are handling of missing and Nan values, date and time variables, categorical features and with scaling of data. Next, aimed at acquiring the data’s knowledge, this work has established an Improved Pearson Correlation Coefficient (IPCC), Feature Extraction (FE) method that presents the relation amidst the data by pondering the causative. The features’ extraction is next followed by the relevant features’ selection aimed at maintaining an efficient computational time and also accuracy utilizing Explorated Particle Swarm Optimization (PSO) centred Sea Turtle Foraging Algorithm (EXPSO-STFA). At last, the feature chosen has been trained and then examined over the Look Ahead Artificial Neural Network (LAANN) classification aimed at identifying the attacks. The LAANN method offers lesser error rate and also evades False Alarm Rate’s (FAR’s) chances and also locates the attack much effectively and also reliably. Moreover, the work administers the malicious attacks’ and random behaviour, and also yields an accurate outcome with the help of evaluation parameters such as Accuracy, Specificity, Sensitivity, Precision, F-Measures, FPR, FNR and MCC. Experiential examination exhibits that the work yields 95.65% accuracy, and also attains 98.16% average Attack Detection Rate (ADR), and the work stays to be much scalable and also secured analogized to the existent top-notch techniques. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Based on the distributed decision tree algorithm, this paper first proposes a method of vertically partitioning datasets and synchronously updating the hash table to establish an information-based mass data retrieval method in a heterogeneous distributed environment, as well as using interval segmentation and interval filtering technologies for improved algorithm of distributed decision tree. The distributed decision tree algorithm uses the attribute histogram data structure to merge the category list into each attribute list, reducing the amount of data that needs to reside in the memory. Second, we adopt the strategy of vertically dividing the dataset and synchronously updating the hash table, select the hash table entries that can be used to update according to the minimum Gini value, modify the corresponding entries and use the hash table to record and control each sub-site. In the case of node splitting, it has a high accuracy rate. In addition, for classification problems that meet monotonic constraints in a distributed environment, this paper will extend the idea of building a monotonic decision tree in a distributed environment, supplementing the distributed decision tree algorithm, adding a modification rule and modifying the generated nonmonotonic decision tree to monotonicity. In order to solve the high load problem of the privacy-protected data stream classification mining algorithm under a single node, a Storm platform for the parallel algorithm PPFDT_P based on the distributed decision tree algorithm is designed and implemented. At the same time, considering that the word vector model improves the deep representation of features and solves the problem of feature high-dimensional sparseness, and the iterative decision tree algorithm GBDT model is more suitable for non-high-dimensional dense features, the iterative decision tree algorithm will be integrated into the word vector model (GBDT) in the data retrieval application, using the distributed representation of words, namely word vectors, to classify short messages on the GBDT model. Experimental results show that the distributed decision tree algorithm has high efficiency, good speed-up and good scalability, so that there is no need to increase the number of datasets at each sub-site at any time. Only a small number of data items are inserted. By splitting some leaf nodes, a small amount is added by branching to achieve a monotonic decision tree. The proposed system achieves a massive data ratio of 54.1% while compared with other networks of massive data ratio. © 2023 World Scientific Publishing Company.",TextMining
"The diversity and advance of information, communication, and analytical technologies and their increasing adoption to assist instruction and learning give rise to various technology-driven conferences (e.g., artificial intelligence in education) in educational technology. Previous reviews on educational technology commonly focused on journal articles while seldom including mainstream conference papers which also contribute to an important part of scientific output in computer science and emerging disciplines like educational technology and are equally and even more important than articles in knowledge transmission. Hence, conference papers should also be included in bibliometric studies to produce a complete and precise picture of scientific production concerning educational technology. This study, therefore, uses bibliometrics and topic modeling to analyze papers from mainstream conferences, including Artificial Intelligence in Education, Learning Analytics and Knowledge, Educational Data Mining, Intelligent Tutoring System, and Learning at Scale, focusing on contributors, collaborations, and particularly research topics and topic evolutions to inform relevant stakeholders about educational technology’s development and its future. Results indicate promising areas like affective computing and behavior mining for adaptive instruction, recommender systems in personalized learning recommendations, eye-tracking for cognitive process diagnosis, videos for feedback provision, and natural language processing in discourse analysis and language education. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"In the field of data mining, how to deal with high-dimensional data is a fundamental problem. If they are used directly, it is not only computationally expensive but also difficult to obtain satisfactory results. Unsupervised feature selection is designed to reduce the dimension of data by finding a subset of features in the absence of labels. Many unsupervised methods perform feature selection by exploring spectral analysis and manifold learning, such that the intrinsic structure of data can be preserved. However, most of these methods ignore a fact: due to the existence of noise features, the intrinsic structure directly built from original data may be unreliable. To solve this problem, a new unsupervised feature selection model is proposed. The graph structure, feature weights, and projection matrix are learned simultaneously, such that the intrinsic structure is constructed by the data that have been feature weighted and projected. For each data point, its nearest neighbors are acquired in the process of graph construction. Therefore, we call them adaptive neighbors. Besides, an additional constraint is added to the proposed model. It requires that a graph, corresponding to a similarity matrix, should contain exactly c connected components. Then, we present an optimization algorithm to solve the proposed model. Next, we discuss the method of determining the regularization parameter γ in our proposed method and analyze the computational complexity of the optimization algorithm. Finally, experiments are implemented on both synthetic and real-world datasets to demonstrate the effectiveness of the proposed method.  © 2022 IEEE.",TextMining
"Wireless networks can be designed with infrastructure-less to help enhance machine learning (ML)to meet potential requirements. This thesis explains how neural network-based data mining techniques can address different forms of wireless networking issues. We first introduce various types of Artificial Neural Networks (ANNs) with a view of wireless communication networks. Each type of artificial neural network is provided with a specific architecture and examples for design use. There are a variety of other technical alternatives to memory and circumstance. We will offer a comprehensive overview of the various forms of wireless networking discussed across multiple use cases. For each use case situation, we explain the key reason for implementing ANNs along with the related difficulties. At the same time, we include a comprehensive sample implementation besides outline everything that could be tackled through ANNs. This study highlights the advancement of ANN-based machine learning approaches responsive to the requirements of wireless communications. © 2023 American Institute of Physics Inc.. All rights reserved.",TextMining
"Purpose: The underlying purpose of this paper is to propose a comprehensive framework evaluating the performance of business units of an organization with a process perspective, identifying the most influential performance indicators, enabling managers to make more informed decisions based on data recording every day in their operational information systems. Design/methodology/approach: For proposing the conceptual framework of performance evaluation a synchronized analysis of selected process' data, obtained from an integrated information system of an Iranian chain store, was performed. Findings: The superiority of the proposed framework results is demonstrated in comparison to applying the process mining solely; principal component analysis was identified as an efficient link between process mining and data envelopment analysis. Also, based on the final data analytics, the units' throughput times and the variety of brands and suppliers had the most impact on their performances. Research limitations/implications: The data of abundant business units and performance indicators, which would have allowed adding data prediction and other data analytics techniques for more insight, was not able to be accessed. Practical implications: Organizations' managers can use the framework to evaluate their business units' current status and then prioritize their resources based on the most influential performance indicators for overall improvement. Originality/value: The study contributes to the research on performance management and process mining by presenting a comprehensive framework with two levels of data analytics. It stresses discovering what is happening in business units, and how to prioritize their improvement opportunities learning the significant correlations between performance indicators and units' performance. © 2021, Emerald Publishing Limited.",TextMining
"In the starting of year 2020, WHO identified COVID-19 as a new pandemic and issued a statement to that effect. This fatal virus was able to disperse and propagate over several nations all over the globe. During the course of the epidemic, social media platforms like Twitter generated significant and substantial volumes of data that helped improve the quality of decisions pertaining to health care. As a result, we suggest that the opinion expressed by users might be analysed via the use of efficient Supervised Machine Learning (SML) algorithms to forecast the occurrence of illness and offer early warnings. In this paper we proposed a text mining classifier for generate the summarized text using machine learning techniques. After collecting the tweets, we got them ready for pre-processing and generate the class label for all instances such as correct, incorrect and neutral etc. In the second phase, numerous features are extracted from text by using a number of frequently used approaches, such as TF-IDF, co-relational, NLP and relational dependency features are extracted to generate the feature vector. As classification module we used one binary classification algorithm and five machine learning algorithms for evaluation of proposed model. NLP-SVM and TFIDF-SVM produces higher accuracy 95.10% and 93.50% classification accuracy respectively. This demonstrates the proposed model is effective for classification of large text for COVID-19 on tweet data. © 2023, Ismail Saritas. All rights reserved.",TextMining
"The design and analysis of experimental research in Data Mining (DM) is anchored in a correct choice of the type of task addressed (clustering, classification, regression, etc.). However, although DM is a relatively mature discipline, there is no consensus yet about what is the taxonomy of DM tasks, which are their formal characteristics, and their corresponding metrics. In this paper, we formalize DM tasks in terms of Measurement Theory, which is a cornerstone of quantitative research in many disciplines, but has not yet been incorporated (in a consensual way) into some areas of Computer Science, including DM. The proposed formal framework provides a methodology to precisely define DM tasks for any given scenario and identify appropriate metrics. We validate this framework via (i) its coverage of existing DM tasks, (ii) its capability to group existing metrics into families, and (iii) its coverage of actual DM research problems, using about 250 papers from ACM KDD 2019 and IEEE ICDM 2019 conferences as reference sample.  © 1989-2012 IEEE.",TextMining
"This paper proposes a new Quantum Spatial Graph Convolutional Neural Network (QSGCNN) model that can directly learn a classification function for graphs of arbitrary sizes. Unlike state-of-the-art Graph Convolutional Neural Network (GCNN) models, the proposed QSGCNN model incorporates the process of identifying transitive aligned vertices between graphs and transforms arbitrary sized graphs into fixed-sized aligned vertex grid structures. In order to learn representative graph characteristics, a new quantum spatial graph convolution is proposed and employed to extract multi-scale vertex features, in terms of quantum information propagation between grid vertices of each graph. Since the quantum spatial convolution preserves the grid structures of the input vertices (i.e., the convolution layer does not alter the original spatial position of vertices), the proposed QSGCNN model allows to directly employ the traditional convolutional neural network architecture to further learn from the global graph topology, providing an end-to-end deep learning architecture that integrates the graph representation and learning in the quantum spatial graph convolution layer and the traditional convolutional layer for graph classifications. We indicate the effectiveness of the proposed QSGCNN model in relation to existing state-of-the-art methods. Experiments on benchmark graph classification datasets demonstrate the effectiveness of the proposed QSGCNN model.  © 1989-2012 IEEE.",TextMining
"Urban hotspots reflect the degree of residents' travel gathering. The study of urban hotspots has important values for urban infrastructure planning, public security and other aspects. In existing researches, single-source location data and density-based clustering algorithms are used to mine hotspots. Due to the one-sidedness of using the single-source data, the mining of hotspots based on multi-source location data fusion has become a hot topic. Multi-source location data fusion requires a quantity balance between the data set to be fused, because several famous clustering algorithms cannot handle multi-source imbalanced data set. To solve this problem, we propose a novel framework to mine urban hotspots. First, we construct a data imputation model for the sparse data set so that reducing the difference in quantity between two types of data set. Then, a clustering algorithm for imbalanced data set is proposed, and a novel evaluation metric is designed to verify the effectiveness of clustering results. The experiment uses real data set including POI data, check-in data and GPS trajectory data. The results show that the proposed method discovers more than 90% of urban hotspots formed by fused imbalanced data set, and it is more accurate and efficient than the state-of-the-art algorithms.  © 1989-2012 IEEE.",TextMining
"Feature selection is an essential part of the data pre-processing phase after obtaining key data, and fields such as machine learning, natural language processing and data mining rely on the model's feature selection results and classification accuracy. In the study of feature selection algorithms based on information theory, the problems of feature and label mutual information maximization, minimum redundancy, joint mutual information, and conditional mutual information have been analyzed and verified. However, there is still a weak classification ability of the optimal subset and difficulty in quantifying the degree of feature redundancy. Therefore, a feature selection method based on interval quantile maximum mutual information is proposed in this paper. The method can further enhance the mutual information of selected features and label values, and also quantify the redundancy degree of selected features. To demonstrate the superiority of the method, the method is compared and analyzed with various mutual information filtering methods applied to guided bomb data, and the effectiveness of the method is verified on several public data sets. © 2023 ACM.",TextMining
"Fauxtography is a category of multi-modal posts that spread misleading information on various big data online social platforms that generate billions of posts on a daily basis (e.g., Facebook, Twitter, Reddit). A fauxtography post usually consists of an image, a text description and comments from its readers. In this paper, we focus on explaining fauxtography posts by identifying what specific component and why that component of a post leads to the fauxtography (i.e., duo explanations). This problem is motivated by the limitations of current fauxtography detection solutions that only focus on the detection but ignore the important explanation aspect of their results. Two critical challenges exist in solving our problem: i) it is difficult to accurately identify the 'guilty' component of a fauxtography post given the fact that different components of the post and their associations could all lead to the fauxtography; ii) it is expensive and time-consuming to obtain a good training set with fine-grained labels of fauxtography posts in terms of explainability, making it challenging to develop fully supervised explainable solutions. To address the above challenges, we develop a Duo Explainable Fauxtography Detection Framework under a Constrained Supervision (DExFC) to generate duo explanations from both content and comment parts of fauxtography posts. We evaluate the DExFC by creating real-world datasets from different online social media platforms (Twitter and Reddit). The results show that DExFC not only detects the fauxtography posts more accurately than the state-of-the-art solutions but also provides well-justified explanations to its results without the full supervision. © 2015 IEEE.",TextMining
"The abundance of user usage data has gained exponential dimensions as a result of the ongoing expansion and spread of Web applications and Web-based systems. Web user usage extraction is used to analyze the browsing data and investigate the web user's visiting interests or patterns. To enhance operational performance, web miners must employ predictive machine learning techniques integrated with reinforced Markov decision process. Especially, Higher order Markov decision frameworks promise the stronger predictive performance and penetration than single-order Markov decision, but they have a large state computational complexity. As a result, a selective Markov decision framework is formulated to considerably increase operating efficiency and prediction accuracy. Towards that the researchers introduced An Optimal Machine Learning Model Integrating with Selective Reinforced Markov Decision process (MLSRM). To efficiently collect and store web browsing data, the MLSRM makes use of the distributed HDFS-Spark parallel computing architecture. It then goes through the necessary pre-processing procedures to get the data ready for the Markov decision process. Later, MLSRM developed a reinforcement strategy to derive actionable knowledge so as to understand online user browsing habits with reduced state complexity and improved forecasting performance by intelligently selecting and integrating several Markov decision processes. Despite of compromising the overall accuracy and proposed model integrity, the suggested methodology eliminates lower Markov support states, examines the awarded probability, and quantifies the error at each Markov state. The proposed prediction Markov decision process was put to several tests, and the results are reported in this article. © 2023 Little Lion Scientific.",TextMining
"The sentiment analysis has gained its importance in recent years. People had improved their way of expressing their opinions about products, services, celebrities, and current topics in internet portals, blogs and social networks. The social network websites like Face book, Twitter, WhatsApp, LinkedIn and Hike messenger, providing the users to express their feelings by using the different symbols like smiley’s, funny faces, etc., These social media websites provide a platform to display peoples’ opinions on topics like movies, products, fashion trends, politics, technologies were expressed. The E-Commerce portals like Amazon, Flip Kart, Snap deal etc., help the people to express their opinions on products. A framework is proposed in this work to find the scores of the opinions and derive conclusions. The classification of opinions is called opinion mining, whereas deriving the scores for those opinions are called sentiment analysis. Here the Classification techniques are used for opinion mining and the scores to those opinions are given by taking a scale from –5 to +5.In this work, a movie review data set has been collected from the twitter reviews (http://ai.stanford.edu/~amaas/data/sentiment/) between the years 2003 and 2012. The Word net lexicon dictionary is used to compare the emotions for obtaining the score. In this paper, the proposed improved RBF kernel of SVM-performed with 98.8% of accuracy when compared with the existing SVM-RBF classifier and other models. © 2020, Bharati Vidyapeeth's Institute of Computer Applications and Management.",TextMining
"Graph Convolutional Network (GCN) has achieved extraordinary success in learning representations of nodes in graphs. However, regarding Heterogeneous Information Network (HIN), existing HIN-oriented GCN methods still suffer from two deficiencies: (1) they cannot flexibly explore all possible meta-paths and extract the most useful ones for each target object, which hinders both effectiveness and interpretability; (2) before performing aggregation, they often require some additional time-consuming pre-processing operations, which increase the computational complexity. To address the above issues, we propose an interpretable and efficient Heterogeneous Graph Convolutional Network (ie-HGCN) to learn the representations of objects in HINs. It is designed as a hierarchical aggregation architecture, i.e., object-level aggregation and type-level aggregation. The new architecture can automatically evaluate all possible meta-paths within a length limit, and discover and exploit the most useful ones for each target object, i.e., at fine granularity. It also reduces the computational cost by avoiding additional time-consuming pre-processing operations. Theoretical analysis shows its ability to evaluate the usefulness of all possible meta-paths, its connection to the spectral graph convolution on HINs, and its quasi-linear time complexity. Extensive experiments on four real network datasets demonstrate its interpretability, efficiency as well as its superiority against thirteen baselines.  © 1989-2012 IEEE.",TextMining
"The high diversity and endemism of benthic species on seamounts are extensively documented. Although the number of squat lobster species from seamount habitats has increased, species from the Central Indian Ridge (CIR) and Southwest Indian Ridge (SWIR) systems remain largely unknown. The hydrothermally active Indian Ridge system harbours potential sites for future Seafloor Massive Sulphides (SMS) mining. Since seabed mining may create a long-lasting impact on the deep-sea ecosystems, it could harm the unique deep-sea life associated with mineral deposits. This study identified two undescribed squat lobster specimens: one from the genus Munidopsis Whiteaves, 1874 from the CIR system in water depths ranging from 1981 to 2033 m, and one from the genus Typhlonida Macpherson & Baba in Machordom, Ahyong, Andreakis, Baba, Buckley, Garcia-Jimenez, McCallum, Rodriguez-Flores & Macpherson, 2022 from the SWIR system in depths ranging from 2070 to 2404 m. Both new species may be distinguished morphologically and genetically based on the partial mitochondrial (mtCOI) gene. To generate baseline environmental and biodiversity data, efforts for accurate sampling and correct identification of biological species are required. Copyright © 2023 Magnolia Press.",TextMining
"With the growing size of data sets, feature selection becomes increasingly important. Taking interactions of original features into consideration will lead to extremely high dimension, especially when the features are categorical and one-hot encoding is applied. This makes it more worthwhile mining useful features as well as their interactions. Association rule mining aims to extract interesting correlations between items, but it is difficult to use rules as a qualified classifier themselves. Drawing inspiration from association rule mining, we come up with a method that uses association rules to select features and their interactions, then modify the algorithm for several practical concerns. We analyze the computational complexity of the proposed algorithm to show its efficiency. And the results of a series of experiments verify the effectiveness of the algorithm.  © 1989-2012 IEEE.",TextMining
"In recent days, Breast malignancy has been considered the main real for death in ladies when contrasted with any remaining diseases. Bosom malignant growth has turned into the most unsafe sort of disease among ladies on the planet. Early discovery of bosom malignant change is fundamental in diminishing life misfortunes. This paper intends to present a hybrid data mining strategy that incorporates K-Nearest Neighbour (KNN) and Support Vector Machine SVM to build up a precise arrangement model for Breast malignant growth forecast, to utilize the important data in clinical information, particularly which is typically overlooked by a large portion of the current techniques when they focus on high expectation exactness's. We have done trials on WBC information. Examination results show that the proposed hybrid information mining strategy has higher expectation exactness than those techniques. Various strategies for bosom disease location are investigated, and their exactness is thought about. We induce that the SVM-based hybrid methods are more appropriate in addressing bosom disease expectations with these outcomes. We suggest utilizing these methodologies with incomparable arrangement issues. © 2023 American Institute of Physics Inc.. All rights reserved.",TextMining
"Recommendation systems are shrewd applications for knowledge mining that profoundly handle the problem of data overload. Various literature explores different philosophies to create ideas and recommends different strategies according to the needs of customers. Most of the work in the suggested structure space focuses on extending the accuracy of the recommendation by using a few possible methods where the principle purpose remains to improve the accuracy of suggestions while avoiding other plan objectives, such as the particular situation of a client. By using appropriate customer rating data, the biggest test for a suggested system is to generate substantial proposals. A setting is an enormous concept that can think of numerous points of view: for example, the community of friends of a client, time, mindset, environment, organization, type of day, classification of an item, description of the object, place, and language. The rating behavior of customers typically varies in different environments. We have proposed a new review-based contextual recommender (RBCR) system application from this line of analysis, in particular a novel recommender system, which is an adaptable, quick, and accurate piece planning framework that perceives the significance of setting and fuses the logical data using piece stunt while making expectations. We have contrasted our suggested calculation with pre- and post-sifting methods as they have been the most common methodologies in writing to illuminate the issue of setting conscious suggestion. Our studies show that considering the logical data, the display of a system will increase and provide better, appropriate and important results on various evaluation measurements. © 2023 World Scientific Publishing Company.",TextMining
"Coronavirus, Corona Virus Disease-2019, brought about by an original Severe Acute Respiratory Syndrome Corona Virus 2 (SARS-CoV-2). A compelling screening of this infection can empower speedy and proficient finding of COVID-19 can diminish the weight on the medical care framework. A nitty gritty examination gave dataset can assemble unique and different kinds of AI calculations, which their exhibition could be processed and further assessed. This paper proposed a mixture information mining method that coordinated Random Forest with SVM (Support Vector Machines). The accompanying case proposed model is to beat the wide range of various Machine Learning models like SVM, Decision Tree, KNN and Logistic Regression. © 2023 American Institute of Physics Inc.. All rights reserved.",TextMining
"Road transportation is a statutory organ in a modern society; however it costs the global economy over a million lives and billions of dollars each year due to increase in road accidents. Researchers make use of machine learning to detect and predict road accidents by incorporating the social media which has an enormous corpus of geo-tagged data. Twitter, for example, has become an increasingly vital source of information in many aspects of smart societies. Twitter data mining for detection and prediction of road accidents is one such topic with several applications and immense promise, although there exist challenges related to huge data management. In recent years, various approaches to the issue have been offered, but the techniques and conclusions are still in their infancy. This paper proposes a deep learning accident prediction model that combines information extracted from tweet messages with extended features like sentiment analysis, emotions, weather, geo-coded locations, and time information. The results obtained show that the accuracy is increased by 8% for accident detection, making test accuracy reach 94%. In comparison with the existing state-of-the-art approaches, the proposed algorithm outperformed by achieving an increase in the accuracy by 2% and 3% respectively making the accuracy reach 97.5% and 90%. Our solution also resolved high-performance computing limitations induced by detector-based accident detection which involved huge data computation. The results achieved has further strengthened confidence that using advanced features aid in the better detection and prediction of traffic accidents. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"In order to explore the impact of human activities on the habitats within the ecological conservation redline, improve the supervision ability of the ecological conservation redline and provide scientific support for improving the supervisory system of the ecological edprotection red line. Taking Zhenlai County of Jilin Province as an example, the high-resolution remote sensing images and related human activity data were used to assess the habitat risk of the area of ecological conservation redline form grid scale based on InVEST model and the spatial analysis capability of GIS. The results showed that: The total habitat risk value in the study area ranges from 0.00 to 1.32. High, medium and low habitat risk areas respectively accounted for 2.31%, 3.26% and 22.12% of the ecological conservation redline area. The impact of human activities disturbance on the habitat in the entire assessment area was dominated by low habitat risk. Among various habitats, the average habitat risk value of forest land was the highest, among which the average habitat risk values of arbor forest land, shrub forest land and other forest land were 0.58, 0.88 and 0.79 respectively, and the highest habitat risk value (shrub forest land) also appeared in the forest land habitat. Compared with other human activities, the cumulative habitat risk values and average habitat risk values of urban village and industrial and mining land were the highest, which were 2 933 161.90 and 1.24 respectively, followed by highway land, which were 1 086 264.68 and 1.19 respectively. Human activities such as dryland, paddy field and fishery had limited impacts on the habitat. © 2023, Science Press. All right reserved.",TextMining
"In this paper, we present DendroMap, a novel approach to interactively exploring large-scale image datasets for machine learning (ML). ML practitioners often explore image datasets by generating a grid of images or projecting high-dimensional representations of images into 2-D using dimensionality reduction techniques (e.g., t-SNE). However, neither approach effectively scales to large datasets because images are ineffectively organized and interactions are insufficiently supported. To address these challenges, we develop DendroMap by adapting Treemaps, a well-known visualization technique. DendroMap effectively organizes images by extracting hierarchical cluster structures from high-dimensional representations of images. It enables users to make sense of the overall distributions of datasets and interactively zoom into specific areas of interests at multiple levels of abstraction. Our case studies with widely-used image datasets for deep learning demonstrate that users can discover insights about datasets and trained models by examining the diversity of images, identifying underperforming subgroups, and analyzing classification errors. We conducted a user study that evaluates the effectiveness of DendroMap in grouping and searching tasks by comparing it with a gridified version of t-SNE and found that participants preferred DendroMap.  © 2022 IEEE.",TextMining
"The Internet is an important component of human settlements, the current research on reality human settlements is far from satisfying the theory and practice development in the Sciences of Human Settlements in information era, it is necessary to introduce pseudo human settlements (PHSs), and the three provinces of Northeast China (TPNC) are a typical area of “unbalanced development.” It is obviously inappropriate to use the traditional geographical concept of man–land to recognize the new man–land Relationship, cognizing and studying the spatiotemporal evolution of TPNC’s PHSs make a beneficial supplement to the theoretical exploration of the Sciences of Human Settlements and the revitalization of TPNC. Data mining technology is used to establish the PHSs database, entropy weight method is used to study the time course, and the spatial analysis function of ArcGIS 10.2 carries out spatial analysis, type analysis, pattern analysis and visualization of corresponding maps of the urban PHSs. Two processes of PHSs change: development and shrinkage were considered, and several conclusions were arrived at after studying its hierarchical system, temporal processes, spatial patterns and special effects. (1). The hierarchical system has significance, with the urban PHSs in 2011–2018 presenting obvious hierarchical differences and the characteristic of primacy. Specifically, the hierarchical system is jointly formed by the regional centers, regional subcenters, urban centers and nodes, Shenyang and Dalian form a dual core, while Changchun and Harbin are single centers, which constitute the contextual framework of the TPNC’ PHSs. (2). The overall trend of urban PHSs is development in the temporal processes; at the same time, there are both continuous development periods and isolated shrinkage points in 2011–2018; the years with high degrees of development and shrinkage are 2016 and 2018, respectively. The two main temporal categories are development and shrinkage, development is divided into three sub-categories and shrinkage is divided into two sub-categories. (3) The spatial patterns of urban PHSs presents obvious typical characteristics in geographical space, which can be divided into five categories. Even though the spatial patterns contain shrinkages, the dominant trend is still development. The overall characteristic of the spatiotemporal evolution is “evolving from shrinkage to development and then to shrinkage, specifically, from mild shrinkage to general development and then to mild shrinkage.” (4). The special effects of urban PHSs mainly three types, including “double eleven effect,” “precursor effect” and “Friday and Saturday effect”; in essence, these effects represent the spatiotemporal evolution trend of geographical phenomena such as the development and shrinkage of PHSs in a certain time and space. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.",TextMining
"With the increase in the scale of mining in horizontal and highly deviated wells, electromagnetic boundary detection while drilling plays an important role in boundary detection. This paper examines three types of antenna structures commonly used in electromagnetic boundary detection and measurement methods and also performs a numerical simulation of the edge detection capability of the three structures in horizontal wells. The simulation experiment analyzes the influence of formation resistivity contrast, frequency, spacing, and other factors on the capability of edge detection and provides data that supports the design of instrument antenna parameters. The numerical simulation shows that the tilted and orthogonal receiving antennas demonstrate improved performance both in detecting the interface when approaching from high-resistance layers and low-resistance layers. In addition, the capability of boundary detection can be improved by decreasing the frequency and increasing the spacing between the transmitter and receiver. Copyright © 2023 Tian, Zhu, Die, Liu, Yue, Wang and Zhu.",TextMining
"Linfen mining area is one of the main coalbed methane industrial bases in the eastern margin of Ordos Basin, China. However, there are few studies on the hydrogeochemical characteristics of coalbed-produced water in the area. This article collected water samples from 14 coalbed methane drainage wells and analyzed the ionic concentrations, hydrogen and oxygen isotopes, dissolved inorganic carbon isotopes (δ13CDIC) and trace elements. The results showed that the water of Nos. Five and eight coal seams are both Cl-Na type. The total dissolved solids content was high, ranging from 5011.45 mg/L to 23405.39 mg/L. Hydrogen and oxygen isotope data indicated that the coalbed-produced water in the study area is recharged from atmospheric precipitation. In addition, the HCO3− in the produced water of No. Five coal seam and No. Eight coal seam was negatively correlated with δ13CDIC. The value δ13CDIC in the produced water of No. Five coal seam was heavier than that of No. Eight coal seam. These indicate that microbial degradation occurred more strongly in No. Five coal seam than in No. Eight coal seam. The water-rock interaction in the study area was found to be dominated by cation exchange and dissolution filtration through the relationships between anion and cation. Copyright © 2023 Guo, Bao, Wang, Yuan, Li, Wang, Xia, Liu and Ma.",TextMining
"In order to stimulate research and development in their companies, managers, and technical experts might aim at identifying frugal patents from third parties by means of advanced text mining techniques. The same may be true for scientists who wish to improve their understanding of frugal inventions. For this purpose, we present a process model in four steps, and particularly analyze the evaluation step by applying different text-mining methods, namely search string refinement and topic modeling. Testing the process model in the technological field of white goods, we find that the process model as a whole as well as both evaluation methods are able to detect frugal patent candidates. Nevertheless, both methods have different profiles in terms of precision and recall. As a theoretical contribution, we suggest differentiating between two types of frugal invention namely those with frugal attributes concentrated in parts of the description and those with frugal attributes distributed throughout the description. As a managerial contribution, we show that a hybrid solution may be effective in identifying frugal patent candidates while reducing manual efforts for evaluation at the same time.  © 2022 IEEE.",TextMining
"This article proposes a heuristic model for sentiment analysis on luxury hotel reviews to analyse and explore marketing insights from attitudes and emotions expressed in reviews. We make several significant contributions to visual and multimedia analytics. This research will develop the practical application of visual and multimedia analytics as the research foundation is based on information analytics, geospatial analytics, statistical analytics and data management. Large amounts of data are generated by hotel customers on the Internet, which provides a good opportunity for managers and analysts to explore the hidden information. The analysis of luxury hotels involves different types of data, including real-world scale data, high-dimensional data and geospatial data. The diversity of data increases the difficulty of processing computational visual analytics. It leads to that some classical classification methods, which cost too much time and have high requirements for hardware, are excluded. The goal is to achieve a compromise between performance and cost. An experiment of this model is operated using data extracted from Booking.com. The entire framework of this experiment includes data collection, data preprocessing, feature engineering consisting of term frequency-inverse document frequency and Doc2Vec based feature generation and feature selection, Random Forest classification, data analysis and data visualization. The whole process combines statistical analysis, review sentiment analysis and visual analysis to make full use of this dataset and gain more decision-making information to improve luxury hotels' service quality. Compared with simple sentiment analysis, this integrated analytics in social media is expected to be used in practice to gain more insights. The result shows that luxury hotels should focus on staff training, cleanness of rooms and location choice to improve customer satisfaction. The sentiment distribution shows that scores are consistent with the emotion they show in reviews. Hotels in Spain have a much better average score than hotels in the other five countries. In the experiment, the sentiment analysis model is evaluated by receiver operating characteristic and precision-recall curve. It is proved that this model performs well. Twenty most essential features have been listed for future adjustments to the model. © 2020 John Wiley & Sons, Ltd.",TextMining
"Introduction Relevant clinical information is vital to inform the analytical and interpretative phases of most investigations. The aim of this study is to evaluate the impact of implementation of computerised provider order entry (CPOE), featuring order-specific electronic order entry forms (eOEFs), on the quality and quantity of clinical information included with investigation requests. Methods The CPOE module of a commercially available electronic health record (Cerner Millennium) was implemented at a large, tertiary care centre. The laboratory information management system was interrogated to collect data on specimens sent for microbiological culture 1 year before implementation of CPOE (2018), immediately post implementation (2019) and 6 months post implementation (2020). An interrupted time series analysis was performed, using text mining, to evaluate the quality and quantity of free-text clinical information. Results In total, 39 919 specimens were collected from 16 458 patients. eOEFs were used to place 10 071 out of 13 735 orders in 2019 (73.3%), and 9155 out of 12 229 orders in 2020 (74.9%). No clinical details were included with 653 out of 39 919 specimens (1.6%), of which 22 (3.4%) were ordered using eOEFs. The median character count increased from 14 in 2018, to 41 in 2019, and 38 in 2020. An anti-infective agent was specified in 581 out of 13 955 requests (4.2%) in 2018; 5545 out of 13 735 requests (40.4%) in 2019; and 5215 out of 12 229 requests (42.6%) in 2020. Ciprofloxacin or piperacillin-tazobactam (Tazocin) were mentioned in the clinical details included with 421 out of 15 335 urine culture requests (2.7%), of which 406 (96.3%) were ordered using eOEFs. Subsequent detection of in vitro non-susceptibility led to a change in anti-infective therapy for five patients. Conclusions Implementation of CPOE, featuring order-specific eOEFs, significantly and sustainably improves the quality and quantity of clinical information included with investigation requests, resulting in changes to patient management that would not otherwise have occurred.  © 2023 Author(s). Published by BMJ.",TextMining
"Purpose: This study aims to explore how corporate social responsibility (CSR) has assumed a new meaning today, with the COVID-19 pandemic. This, in turn, has changed the way companies now view the impact of their activities on the environment, customers, employees, community and other stakeholders. Design/methodology/approach: This paper uses a qualitative case study approach and draws a critical lens to document the complex interplay between dimensions of CSR, business sustainability and social issues, applying theoretical tools such as social capital theory and stakeholder theory to elucidate the nature of collaborative managerial responses to the organisation’s challenges during the pandemic. This is a case study paper. This paper applies multi method approach to develop a case study analysis through participant observation and report analysis to investigate the CSR approaches undertaken in India by Infosys Genesis, a global leader in technology services and consulting, and Akshaya Patra Foundation, a non-governmental organisation (NGO), which operates the world’s largest lunch school program. This was an appropriate methodology since the focus was on an area that was little understood, while the analysis required an in-depth understanding of a complex phenomenon through observation and a case study. In addition, case study research has been recommended for how, why and what type of research questions that focus on contemporary events (Saunders et al., 2003; Yin, 1994), such as CSR participation in the existing business environment. Furthermore, the issue under investigation is a real-life situation where the limitations between the phenomenon and the body of knowledge are unclear (Yin, 1994). This was the case because CSR has been probed by numerous disciplines through the application of various theoretical frameworks, each interpreting the context from their own perspective. Leximancer was used for the analysis (a text-mining software for visualising the structure of concepts and themes across case studies). This process differs from the traditional content analysis in that specific word strings are not needed; instead, Leximancer recognises what concepts are present in a set of texts, permitting concepts to be automatically coded in a grounded fashion (Cretchley et al., 2010, p. 2). The paper will be looked at from three levels comprising themes, concepts and concept profiling to create rich and reliable dimensions of a theoretical model (Myers, 2008). The themes are created in Leximancer software and are built on an algorithm that looks for hidden repeated patterns in interactions. The concepts add a layer and discover which concepts are shared by actors. The concept profiling allows to discover additional concepts and allows to do a discriminant analysis on prior concepts (Cretchley et al., 2010). Words that come up frequently are treated as concepts. Although the limited number of cases does not represent the entire sector, it enabled collection of rich data through quotes revealing some of the most crucial aspects of large organisations and non-profits in India. Findings: The findings demonstrate how these robust, innovative, collaborative CSR initiatives between a multinational firm and an NGO have been leveraged to combat manifold issues of education, employment and hunger during the pandemic. Research limitations/implications: Despite significant implications, this study has limitations. A response from only two companies is investigated to the COVID-19 pandemic. The scope of this study is only India, a developing nation, thereby, cross country research is recommended. A comparative study between developed and developing countries may be conducted. A quantitative approach may be used to get empirical findings of the COVID-19 pandemic and post-pandemic policies of companies from an international perspective. Hence, there is ample opportunity to research organisations’ response to the pandemic and CSR as a strong arm to deal with critical disasters. Practical implications: The paper offers new insights into exploring research and praxis agenda for collaborative potentials towards the evolution of CSR and sustainability. Social implications: The findings develop new initiatives and combat manifold issues of education, employment and hunger during the pandemic to provide quick relief. Originality/value: The paper offers new insights into how companies are considering issues related to the crisis, including avoidance of layoffs and maintaining wage payments, and may be in a better position to access fresh capital, relief programs and emergency funds. Taking proactive health and safety measures may avert legal risks to the company. It is likely that the way in which companies are responding to the crises is a real-life test on resilience and adaptation. © 2022, Emerald Publishing Limited.",TextMining
"Purpose: The border between the State of Amapa, Brazil, and French Guiana is mostly primary forest. In the Oyapock basin, socioeconomic circumstances have fueled sex work, gold mining and the circulation of sexually transmitted infections. Given the lack of comprehensive data on this border area, we describe the different sexually transmitted infections along the Brazil/French Guiana border and the testing and care activity. Methods: We conducted a review of the available scientific and technical literature on sexually transmitted infections in this complex border area. Temporal trends were graphed and for Human Immunodeficiency Virus (HIV) we estimated incidence using the European Center for prevention and Disease Control modeling tool. Results: Until 2019, 26 of the 46 HIV-infected patients followed and treated in Saint Georges de l'Oyapock were residing on the Brazilian side in Oiapoque. Virological suppression was only achieved for 75% of treated patients; but dropped to 62% during the COVID-19 epidemic. In 2019, cooperation efforts allowed HIV care in Oiapoque, resulting in the transfer of Brazilian patients previously followed on the French side and a substantial increase in the number of patients followed in Oiapoque. The average yearly HIV serological testing activity at the health center in Saint Georges was 16 tests per 100 inhabitants per year; in Camopi it was 12.2 per 100 inhabitants. Modeling estimated the number of persons living with HIV around 170 persons, corresponding to a prevalence of 0.54% and about 40 undiagnosed infections. The model also suggested that there were about 12 new infections per year in Saint Georges and Oiapoque, representing an HIV incidence rate of 3.8 cases per 10,000 per year. HPV prevalence in Saint Georges ranges between 25 and 30% and between 35 and 40% in Camopi. Testing activity for other sexually transmitted infections markedly increased in the past 5 years; the introduction of PCR for chlamydiasis and gonorrhea also had a substantial impact on the number of diagnoses. Conclusions: The ongoing cooperation between multiple partners on both sides of the border has led to remarkable progress in primary prevention, in testing efforts, in treatment and retention on both sides of the border. In a region with intense health professional turnover, nurturing cooperation and providing accurate assessments of the burden of sexually transmitted infections is essential to tackle a problem that is shared on both sides of the border. Copyright © 2023 Nacher, Divino, Leborgne, Correa, Rabier, Lucarelli, Rhodes, Gaillet, Malafaia, Rousseau, Sanna, Gomes, Adenis, Peiter and Michaud.",TextMining
"In this paper, we propose a novel DynAttGraph2Seq framework to model complex dynamic transitions of an individual user's activities and the textual information of the posts over time in online health forums and learning how these correspond to his/her health stage. To achieve this, we first formulate the transition of user activities as a dynamic attributed graph with multi-attributed nodes that evolves over time, then formalize the health stage inference task as a dynamic attributed graph to sequence learning problem. Our proposed model consists of a novel dynamic graph encoder along with a two-level sequential encoder to capture the semantic features from user posts and an interpretable sequence decoder that learn the mapping between a sequence of time-evolving user activity graphs as well as user posts to a sequence of target health stages. We go on to propose new dynamic graph regularization and dynamic graph hierarchical attention mechanisms to facilitate the necessary multi-level interpretability. A comprehensive experimental analysis of its use for a health stage prediction task demonstrates both the effectiveness and the interpretability of the proposed models. © 1989-2012 IEEE.",TextMining
"Mercury is considered to be one of the most toxic elements to humans. Due to pollution from industry and artisanal gold mining, mercury species are present globally in waters used for agriculture, aquaculture, and drinking water. This review summarises methods reported for preserving mercury species in water samples and highlights the associated hazards and issues with each. This includes the handling of acids in an uncontrolled environment, breakage of sample containers, and the collection and transport of sample volumes in excess of 1 L, all of which pose difficulties for both in situ collection and transportation. Literature related to aqueous mercury preservation from 2000-2021 was reviewed, as well as any commonly cited and relevant references. Amongst others, solid-phase extraction techniques were explored for preservation and preconcentration of total and speciated mercury in water samples. Additionally, the potential as a safe, in situ preservation and storage method for mercury species were summarised. The review highlighted that the stability of mercury is increased when adsorbed on a solid-phase and therefore the metal and its species can be preserved without the need for hazardous reagents or materials in the field. The mercury species can then be eluted upon return to a laboratory, where sensitive analytical detection and speciation methods can be better applied. Developments in solid phase extraction as a preservation method for unstable metals such as mercury will improve the quality of representative environmental data, and further improve toxicology and environmental monitoring studies. © 2023 The Royal Society of Chemistry.",TextMining
"The cold-start issue is a fundamental challenge in Recommender Systems. The recent self-supervised learning (SSL) on Graph Neural Networks (GNNs) model, PT-GNN, pre-trains the GNN model to reconstruct the cold-start embeddings and has shown great potential for cold-start recommendation. However, due to the over-smoothing problem, PT-GNN can only capture up to 3-order relation, which cannot provide much useful auxiliary information to depict the target cold-start user or item. Besides, the embedding reconstruction task only considers the intra-correlations within the subgraph of users and items, while ignoring the inter-correlations across different subgraphs. To solve the above challenges, we propose a multi-strategy-based pre-training method for cold-start recommendation (MPT), which extends PT-GNN from the perspective of model architecture and pretext tasks to improve the cold-start recommendation performance.1 Specifically, in terms of the model architecture, in addition to the short-range dependencies of users and items captured by the GNN encoder, we introduce a Transformer encoder to capture long-range dependencies. In terms of the pretext task, in addition to considering the intra-correlations of users and items by the embedding reconstruction task, we add an embedding contrastive learning task to capture inter-correlations of users and items. We train the GNN and Transformer encoders on these pretext tasks under the meta-learning setting to simulate the real cold-start scenario, making the model able to be easily and rapidly adapted to new cold-start users and items. Experiments on three public recommendation datasets show the superiority of the proposed MPT model against the vanilla GNN models, the pre-training GNN model on user/item embedding inference, and the recommendation task.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",TextMining
"In common with other important coal bases in northwestern China, the hydrology and ecology and environment of Ordos, northern Shaanxi (Shanbei), and Shanxi Provinces have much. Terrestrial water storage anomaly (TWSA), soil moisture anomaly (SMA), and groundwater storage anomaly (GWSA), are important water storage qualities that play a critical role in the distribution and growth of vegetation. In this paper, multi-source remote sensing data were used to analyze the spatial–temporal changes and relationships of water storage, ecology and environment from 2002 to 2020. The numerical results showed the TWSA and GWSA in the study area had a declining trend and the rates were −7.512 mm yr-1 and −8.268 mm yr-1, respectively. On the contrary, the SMS showed an increasing trend, and the rate was 0.840 mm yr-1. By trend variation and correlation analysis, we found GWSA is the main part in the variation of TWSA. By further analysis, it was found that the climate factors are not the major factors causing the variation of GWSA, but coal mining and artificial irrigation activities, which are especially clear in the Taihang Mountains in eastern Shanxi Province. The ecology and environment have been improving, and water storage and climate factors have played a different role in different regions. The warm climate conditions and the increased 0–40 cm of soil water have promoted the growth of vegetation and the improvement of the ecology and environment. The research results are helpful to understand the impacts of water storage on the ecology and environment in high-intensity coal mining areas. © 2022 John Wiley & Sons Ltd.",TextMining
"Formal concept analysis is a powerful tool for data processing and knowledge discovery. However, only using the traditional methods in formal concept analysis cannot meet the needs of big data environment since most data not only contain object-attribute information but also the structure information between objects. As a result, it is an important research topic to extend formal concept analysis for data processing and knowledge discovery. Based on the above analysis, this paper puts forward the notion of a formal context with object structure information. And then, the global structural information and local structural information formal concepts are proposed (collectively called structural information formal concepts) by combining with connectivity. Meanwhile, the problem of knowledge discovery on the basis of structural information formal concepts is discussed. Considering the fact that the dynamic changes of data and the dissemination or diffusion of information in our daily life are inevitable, we further explore the evolution rules of structural information formal concepts when a formal context with object structure information is updated gradually. Algorithms are developed for updating different structural information formal concepts when object structure matrix or connection matrix changes, and their time complexity are also analyzed. In addition, we conduct some experiments to show the feasibility and effectiveness of the proposed structural information formal concept updating methods. © 2023 Chinese Institute of Electronics. All rights reserved.",TextMining
"This paper proposes Khuzdul, a distributed execution engine with a well-defined abstraction that can be integrated with existing single-machine graph pattern mining (GPM) systems to provide efficiency and scalability at the same time. The key novelty is the extendable embedding abstraction which can express pattern enumeration algorithms, allow fine-grained task scheduling, and enable low-cost GPM-specific data reuse to reduce communication cost. The effective BFS-DFS hybrid exploration generates sufficient concurrent tasks for communication-computation overlapping with bounded memory consumption. Two scalable distributed GPM systems are implemented by porting Automine and GraphPi on Khuzdul. Our evaluation shows that Khuzdul based systems significantly outperform state-of-the-art distributed GPM systems with partitioned graphs by up to 75.5× (on average 19.0×), achieve similar or even better performance compared with the fastest distributed GPM systems with replicated graph, and scale to massive graphs with more than one hundred billion edges with a commodity cluster.  © 2023 Owner/Author.",TextMining
"Non-Communicable Diseases (NCD) has been drastically increased across the world in the recent years. Diseases that are not transmissible from one person to another are known as Non-Communicable Diseases (NCDs). Parkinson's disease, Autoimmune Disorders, Strokes, Heart Diseases, Cancers, Diabetes are examples of NCDs. It is found that certain Non-Communicable Diseases are believed to be exacerbated by lifestyle and climate which cause of death in the world. Many Machine Learning methods such as Nave Bayes, Support Vector Machine have been applied to predict NCDs. The aim of this paper is to predict the Non-Communicable Diseases (NCDs) and evaluate the performance of the key classifiers in terms of Prediction accuracy, Kappa and F-Measure. The progress in computer training and AI can remarkably help the analysis of Non-Communicable Diseases (NCDs). Nevertheless, the intrinsic complication of black-box samples controls the understanding of the sample. Consequently, likely regulative concerns arise. Furthermore, the lack of faith inside the therapeutic society is obvious due to the absence of understanding of how and why a sample prophesies. This research illustrates how sample-cynical ways of explainable AI (XAI) can assist give descriptions to assume black-box samples on NCDs information collection better. © 2023 American Institute of Physics Inc.. All rights reserved.",TextMining
"Nonoccurring behavior (NOB) studies have attracted the growing attention of scholars as a crucial part of behavioral science. As an effective method to discover both NOB and occurring behaviors (OB), negative sequential pattern (NSP) mining is successfully used in analyzing medical treatment and abnormal behavior patterns. At this time, NSP mining is still an active and challenging research domain. Most of the algorithms are inefficient in practice. Briefly, the key weaknesses of NSP mining are: 1) an inefficient positive sequential pattern (PSP) mining process, 2) a strict constraint of negative containment, and 3) the lack of an effective Negative Sequential Candidate (NSC) generation method. To address these weaknesses, we propose a highly efficient algorithm with improved techniques, named sc-NSP, to mine NSP efficiently. We first propose an improved PrefixSpan algorithm in the PSP mining process, which connects to a bitmap storage structure instead of the original structure. Second, sc-NSP loosens the frequency constraint and exploits the NSC generation method of positive and negative sequential patterns mining (PNSP) (a classic NSP mining method). Furthermore, a novel pruning strategy is designed to reduce the computational complexity of sc-NSP. Finally, sc-NSP obtains the support of NSC by using the most efficient bitwise-based calculation operation. Theoretical analyses show that sc-NSP performs particularly well on data sets with a large number of elements and items in sequence. Comparison and extensive experiments along with case studies on health data show that sc-NSP is 10 times more efficient than other state-of-the-art methods, and the number of NSPs obtained is 5 times greater than other methods. © 2020 IEEE.",TextMining
"The Editor-in-Chief and the publisher have retracted this article. The article was submitted to be part of a guest-edited issue. An investigation by the publisher found a number of articles, including this one, with a number of concerns, including but not limited to compromised editorial handling and peer review process, inappropriate or irrelevant references or not being in scope of the journal or guest-edited issue. Based on the investigation's findings the Editor-in- Chief therefore no longer has confidence in the results and conclusions of this article. Authors He Sun, Lichen Wang and Jian Xie have not responded to correspondence regarding this retraction. The Publisher has not been able to obtain a current email address for author Zhenglong Yang. © 2021 King Fahd University of Petroleum & Minerals.",TextMining
"At present, mental issues have become the main factor leading to college students' suicide, crime and other malignant events. As the key process in mental health education, it is vital to utilize technology to predict psychological problems in advance for the healthy growth of college students. In the past, the commonly used psychological crisis screening methods only consider individual psychological scale, a great quantity of data from social network has not been analyzed in depth. Thanks to data mining technologies, it is possible to build psychological portrait for each student to deeply excavate some hidden information and knowledge. Based on the survey and behavior research of college students' Internet social networking in the era of Internet plus, this paper analyses the influence of social network on college students' mental health according to the law of college students' psychological development. Moreover, this paper also explores the mental health education strategy in the behavior guidance of social network, providing theoretical support for the research and work of ideological and political education in colleges and universities. © 2023 ACM.",TextMining
"The recent emergence of nanotechnology has led to the rapid increase of intentional and unintentional exposure to engineered nanoparticles (NPs), raising concerns over their impact on humans, animals and ecosystems. The demanding experimental assessment of toxicity, compared with NP innovation and time to market, has led to the extensive development of in silico methods, such as SAR models, aiming at providing a more rapid toxicity screening of such NPs. However, such models are usually built upon a limited number of data, making the different approaches case-sensitive. Furthermore, the focus on the predictive capabilities of the models, deem the extraction of scientific knowledge secondary, hindering the mechanistic understanding of toxicity mechanisms. In this paper, we instead shift the focus by using the models as a first step towards induction and extraction of valuable mechanistic information, once the predictive ability of the model has been validated. For this reason, we use a large dataset consisting of 935 toxicity measurements for 45 metal and metal oxide NPs, to build classification nano-SAR models. To the best of the authors' knowledge, this is the largest dataset of individual toxicity measurements for such NPs. Although the dataset is heterogeneous, the models developed are able to accurately classify the NPs based on their toxicity towards a variety of cells and organisms, using the same descriptors. Based on the quality of the results, the potential mechanisms of toxicity are identified and discussed in depth, providing a more holistic approach towards metal and metal oxide NP toxicity. The presented approach aims to trigger a discussion regarding information that could be derived from nano-SAR models, that could pave the way towards a more knowledge-based risk assessment of NPs and guide researchers towards the synthesis of safe-by-design NPs. © 2023 The Royal Society of Chemistry.",TextMining
"Urban housing price is widely accepted as an economic indicator which is of both business and research interest in urban computing. However, due to the complex nature of influencing factors and the sparse property of transaction records, to implement such a model is still challenging. To address these challenges, in this work, we study an effective and fine-grained model for urban subregion housing price predictions. Compared to existing works, our proposal improves the forecasting granularity from city-level to mile-level, with only publicly released transaction data. We employ a feature selection mechanism to select more relevant features. Then, we propose an integrated model, JGCMMN (Joint Gated Co-attention Based Multi-modal Network), to learn all-level features and capture spatiotemporal correlations in all-time stages with a modified densely connected convolutional network as well as current ingredients and future expectations. Next, we devise a novel JGC based fusion method to better fuse the heterogeneous data of multi-stage models by considering their interactions in temporal dimension. Finally, extensive empirical studies on real datasets demonstrate the effectiveness of our proposal, and this fine-grained housing price forecasting has the potential to support a broad scope of applications, ranging from urban planning to housing market recommendations. © 1989-2012 IEEE.",TextMining
"From exchanging budgetary instruments to tracking individual spending plans to detail a business's profit, money-related organisations utilise computational innovation day by day. Here in this paper, we focus on the significance of innovation in accounts such as financial risk management and stock prediction. We discuss two significant algorithms that have a notable role in stock forecasting. Artificial Neural Networks (ANN), as absenteeism of some data points, does not hamper the network functioning. Secondly, Support Vector Machines (SVM) has several features, and due to simple decision boundaries, it avoids over-fitting. The paper first looks at the different technologies applied in stock market prediction. It examines how sentimental analysis, decision trees, moving average algorithm, and data mining is applied in various stock prediction scenarios. The paper covers the recent past studies to explore the concepts and methodologies through which ANN's and SVM's have been used. Additionally, the paper incorporates significant aspects of novel methods and technologies in which ANN as a hybrid model like ANN-MLP, GARCH-MLP, a combination of the Backpropagation algorithm and Multilayer Feed-forward network, yields better results. Simultaneously, SVM's have been successfully applied in stock prediction, giving an accuracy of about 60%–70% for simple SVM, which is further improved by combining methods like Random Forest, Genetic Algorithm more accurate outcomes. Further, we present our thoughts on where SVM's and ANN's stand as prediction algorithms and challenges like the time constraint, current scenarios, data limitation, and cold start problems were raised. Conclusively SVM and ANN played prominent roles in tackling these issue to an extent and can further be enhanced with their integration with other novel techniques resulting in hybrid methodologies. It will lead students, researchers and financial enthusiasts to more potent approaches for Stock forecasting. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TextMining
"The tagging system has become the basis of various systems, e.g., geo-social system, marketing system. Understanding the structure among the tags is one of the crucial tasks to the performance of various downstream marketing tasks, such as user behavior understanding, advertising, and recommendation. However, most of the existing methods mainly focus on the association among the tags, which usually results in false intervention suggestions, e.g., recommending a similar item after having bought one. To address this problem, we propose an Iterative Causal Structure Search (ICSS in short) algorithm for the high-dimensional social tags. In each iteration of the proposed approach, we first employ the constraint-based method to discover the skeleton of the causal structure and further employ the additive noise assumption to infer the edges whose directions are unknown in the previous stage. The proposed approach not only benefits from the good scalability of the constraint-based approach but also avoids the Markov equivalence class problem with the help of the additive noise assumption. We also theoretically show the correctness of the proposed algorithm. We test the ICSS and the baselines on both the simulated data and real-world data, further discover some interesting causal structures among the tags in a real-world marketing system. © 2021, Springer-Verlag London Ltd., part of Springer Nature.",TextMining
"Signed network embedding is an approach to learning low-dimensional representations of nodes in signed networks with both positive and negative links, which facilitates downstream tasks such as link prediction with general data mining frameworks. Due to the distinct properties and significant added value of negative links, existing signed network embedding methods usually design dedicated methods based on social theories such as balance theory and status theory. However, existing signed network embedding methods ignore the characteristics of multiple facets of each node and mix them up in one single representation, which limits the ability to capture the fine-grained attentions between node pairs. In this paper, we propose MUSE, a MUlti-faceted attention-based Signed network Embedding framework to tackle this problem. Specifically, a joint intra- and inter-facet attention mechanism is introduced to aggregate fine-grained information from neighbor nodes. Moreover, balance theory is also utilized to guide information aggregation from multi-order balanced and unbalanced neighbors. Experimental results on four real-world signed network datasets demonstrate the effectiveness of our proposed framework. © 2022 Elsevier B.V.",TextMining
"Stock is a financial instrument that has a high variation. One way to determine the risk of a stock is to estimate the Value at Risk. However, Value at Risk cases tend to have fluctuating variations over time and are difficult to model because they are hypothesized to be non-linear. To capture this, modeling is carried out with Generalized Autoregressive Conditional Heteroscedasticity (GARCH). Meanwhile, identification of non-linear models can be solved using machine learning methods, one of which is Support Vector Regression (SVR) which is sensitive to over fitting cases. To produce an optimal model, reinforced with Kernel Density Estimation (KDE). By using this combination, the hybrid SVR-GARCH-KDE method is obtained. The results of this method can show that the Hybrid-SVR-GARCH-KDE method is good for estimating the Value at Risk on return of LQ45 stock price data for the period January 2018 to March 2021 which has the smallest PEB and PBV. From this method, portfolio optimization was carried out and resulted in a decision that investments in the Trade, Services, and Investment sectors as well as mining were profitable for investors. © 2023 American Institute of Physics Inc.. All rights reserved.",TextMining
"In industry 4.0 and digital transformation scenarios, manufacturing companies face the challenges of the exponential growth in the volume of data. A considerable part of the data that enterprises generate in large quantities, at a high speed, and in different forms can be defined as dark data. Companies are not able to extract their potential value for data management, storage, and maintenance issues, and, due to their unstructured form, they become unknown together with their informative value. Some researchers and professionals have addressed the issue of dark data but none of them have focused on the specificity of the manufacturing industry or on the data generated in it. Based on a lack in the literature, in this article, we explore the dark data through a systematic literature review and three focus groups with manufacturing companies. This article fills the gap and provides a valuable support for manufacturing companies to be aware of the presence of dark data in their scenarios, to identify them, and to stimulate initiatives for dark data exploitation. Furthermore, the study provides for the academic audience a reference paper for addressing future exploration in the field of data management in the companies for improving their innovative and operative capabilities.  © 2022 IEEE.",TextMining
"Malignancy is one of the dangerous sicknesses across numerous nations. In any case, malignant growth can be restored whenever recognized at a beginning phase. Analysts are dealing with medical care for early identification and avoidance of malignant growth. Clinical information has arrived at its most revolutionary potential by giving specialists enormous informational indexes gathered from everywhere the globe. In the current situation, Machine Learning has been broadly utilized in malignancy analysis and guess space. Endurance examination might help the expectation of the beginning stage of sickness, backslide, pre-event of infections, and biomarker recognizable proof. Uses of ML and data mining strategies in the clinical field are the broadest in disease recognition and endurance examination. In this paper, various approaches to distinguish and foresee cellular breakdown in the lungs utilize hybrid Machine learning calculations that incorporate Support Vector Machine and ANN (Artificial Neural Networks). Near investigation of different ML procedures and advances has been done over various kinds of information like clinical information, omics information, picture information, and so forth. © 2023 American Institute of Physics Inc.. All rights reserved.",TextMining
"The purpose is to improve the monitoring and evaluation of the teaching quality of higher education based on the 6G IoT (Internet of Things) communication, and study the application of data mining technology in the management of teaching systems. First, a series of methods and the theoretical basis of IoT communication and data mining technology are displayed, and the data of higher education and teaching quality are collected, sorted, processed, and analyzed. Second, combined with the relevant data and survey results, the problems existing in the current teaching quality evaluation system in colleges and universities are explored, and the corresponding solutions are put forward. Finally, an experiment is carried out, and Shaanxi University of science and technology is taken as the research object to study the teaching quality evaluation system based on data mining. The results show that the embedded system in 6G IoT can transmit the data collected by the sensor layer to the network layer, realize the docking interaction between the sensor and the Internet, and accurately record students' learning behaviors. The application of data mining to the data analysis can evaluate students' learning status and teaching quality clearly and manage classroom resources. Therefore, IoT is combined with data mining technology to monitor and evaluate the teaching quality in colleges and universities. © 2021, The Society for Reliability Engineering, Quality and Operations Management (SREQOM), India and The Division of Operation and Maintenance, Lulea University of Technology, Sweden.",TextMining
"Today, semantic web services are rapidly evolving and updating. The discovery of semantic web services is an important concept for the comprehensiveness of individual web services in creating new intelligent systems that meet the complex needs of users and is an important technology in the domain of web services. One of its main goals is to reuse existing web services and combine them in a process that has attracted a lot of attention from different communities like the Internet of Things (IoT). Currently, the discovery of web services in the most common category includes four main methods and a set of sub-methods. Most semantic web service discovery methods are done using semantic descriptions of web services using ontology based on existing pattern recognition approaches. In this research, a new approach is presented that in the first step, the web services description language (WSDL) is scanned and the infrastructure is examined. In the second step, by adding the technique of extracting background information that can be received from the WSDL, the field limitations and existing patterns are considered and detected by semantic spacing on the discovering web services. Also, web services whose parameters contain synonymous synonyms, irregular composite fragments, and similar abbreviations with high accuracy in a cluster contract. The proposed approach is based on a semantic pattern recognition using data mining and finally, the output of the proposed method is single and combined services that have high accuracy and speed of the proposed algorithm in web service discussions. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TextMining
"High Utility Item-set Mining (HUIM) is the futuristic remodel version of Frequent Item-set Mining (FIM). It discovers customer purchase trends in the retail market. This knowledge is useful to retailers to incorporate various innovative schemes in their businesses to attract the customers such as discounts, cross-marketing, seasonal sale offers…etc. Even though many HUIM algorithms are available to detect profitable patterns, most of them cannot apply to all kinds of retail market data sets due to certain assumptions. The first assumption is that the items always produce a positive profit. Even though purchased items’ overall profit could be positive, few items may have negative profit. Another assumption is they are built for static transactional data. The data is gathered up to the point of time and is used for analysis. It is helpful to make decisions at some intervals like quarterly, half-yearly, yearly. But, to take decisions at any time by analyzing the present sales trend, it is required to process the data stream. This paper presents an innovative idea named Extended Global Utility Item-sets Tree(EGUI-tree) to extract High utility item-sets in the retail market data stream with positive and negative profit items. The sliding window-based technique is applied to the data stream to pick up the very recent data to process. An experimental study on real-world datasets shows that the proposed EGUI-tree algorithm is faster and scalable. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TextMining
"Predicting and understanding student learning performance has been a long-standing task in learning science, which can benefit personalized teaching and learning. This study shows that the progress towards this task can be accelerated by using learning record data to feed a deep learning model that considers the intrinsic course association and the structured features. We proposed a multi-source sparse attention convolutional neural network (MsaCNN) to predict the course grades in a general formulation. MsaCNN adopts multi-scale convolution kernels on student grade records to capture structured features, a global attention strategy to discover the relationship between courses, and multiple input-heads to integrate multi-source features. All achieved features are then poured into a softmax classifier towards an end-to-end supervised deep learning model. Conducting insights into higher education on real-world university datasets, the results show that MsaCNN achieves better performance than traditional methods and delivers an interpretation of student performance by virtue of the resulted course relationships. Inspired by this interpretation, we created an association map for all mentioned courses, followed by evaluating the map with a questionnaire survey. This study provides computer-aided system tools and discovers the course-space map from the educational data, potentially facilitating the personalized learning progress. © 2015 IEEE.",TextMining
"Deriving relevant features from historic financial data and forecasting it accurately and impartially is an emerging and predominant field of research in the vast domain of finance. Mutual fund is a structured investment instrument in economic market and the measuring instrument required to price it is called as Net Asset Value (NAV). For NAV prediction, Artificial Neural Network has been immensely utilized in the past due to its adaptive learning, robustness and great ability to identify and handle hidden nonlinear patterns. In this study, a Chebyshev Polynomial Neural Network (CPNN) has been proposed for one day ahead prediction of three different NAV data set belonging to three leading Indian financial houses. The controlling parameters of the network are estimated by a computationally intelligent meta-heuristic algorithm known as Flower Pollination Algorithm (FPA). It is a nature inspired algorithm, motivated by the pollination process of flowering plants with very few control parameters and rapid convergence rate. The efficacy of the proposed forecasting model is also examined by a comparative analysis of training of CPNN with other optimizing algorithms like Differential Evolution and Particle Swarm Optimization (PSO) on the same set of data collected over the same period of time. The convergence plots obtained during the training of the models and the different error metrics values calculated during their testing phase of the study showcase that the proposed CPNN-FPA model clearly outperforms the other two experimented predictive models. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TextMining
"Dynamic relation repair aims to efficiently validate and repair the instances for knowledge graph enhancement (KGE), where KGE captures missing relations from unstructured data and leads to noisy facts to the knowledge graph. With the prosperity of unstructured data, an online approach is asked to clean the new RDF tuples before adding them to the knowledge base. To clean the noisy RDF tuples, graph constraint processing is a common but intractable approach. Plus, when adding new tuples to the knowledge graph, new graph patterns would be created, whereas the explicit discovery of graph constraints is also intractable. Therefore, although the dynamic relation repair has an unfortunate hardness, it is a necessary approach for enhancing knowledge graphs effectively under the fast-growing unstructured data. Motivated by this, we establish a dynamic repairing and enhancing structure to analyze its hardness on basic operations. To ensure dynamic repair and validation, we introduce implicit graph constraints, approximate graph matching, and linkage prediction based on localized graph patterns. To validate and repair the RDF tuples efficiently, we further study the cold start problems for graph constraint processing. Experimental results on real datasets demonstrate that our proposed approach can capture and repair instances with wrong relation labels dynamically and effectively. © 1989-2012 IEEE.",TextMining
"Shortened time to knowledge discovery and adapting prior domain knowledge is a challenge for computational and data-intensive communities such as e.g., bioinformatics and neuroscience. The challenge for a domain scientist lies in the actions to obtain guidance through query of massive information from diverse text corpus comprising of a wide-ranging set of topics when: investigating new methods, developing new tools, or integrating datasets. In this paper, we propose a novel 'domain-specific topic model' (DSTM) to discover latent knowledge patterns about relationships among research topics, tools and datasets from exemplary scientific domains. Our DSTM is a generative model that extends the Latent Dirichlet Allocation (LDA) model and uses the Markov chain Monte Carlo (MCMC) algorithm to infer latent patterns within a specific domain in an unsupervised manner. We apply our DSTM to large collections of data from bioinformatics and neuroscience domains that include more than 25,000 of papers over the last ten years, featuring hundreds of tools and datasets that are commonly used in relevant studies. Evaluation experiments based on generalization and information retrieval metrics show that our model has better performance than the state-of-the-art baseline models for discovering highly-specific latent topics within a domain. Lastly, we demonstrate applications that benefit from our DSTM to discover intra-domain, cross-domain and trend knowledge patterns. © 1989-2012 IEEE.",TextMining
"Sentiment Analysis is a strategy for deciding some- one's emotion or feeling for a particular thing. It is used to perceive and organize the assessments imparted in works. The online per-son-to-person communication destinations like Twitter attract countless fewer online customers to give their bits of knowledge as tweets or remarks. The tweets can be then ordered into positive, negative, or nonpartisan. The proposed work utilizes calculated relapse order as a classifier and unigram as a component vector. For precision, k overlay cross approval information mining system is utilized. For picking the exact preparing test, tweet subjectivity is used. The possibility of the Effective Word Score heuristic is similarly introduced to discover the extremity score of words that are much of the time utilized. This extra heuristic can accelerate the order procedure of estimations with standard machine learning draws near. A notion is characterized as a view or assessment that is communicated. It is an inclination of somebody that he/she communicates either in literary or verbal structure. An assumption can be characterized as an individual positive or negative feeling. © 2023 American Institute of Physics Inc.. All rights reserved.",TextMining
"The Qianyingzi Coal Mine is located in the west of the Suxian Mining District of the Huaibei Coalfield, eastern China. The study on structural development patterns and genetic mechanisms in this mine lays an important foundation for safe and efficiently underground mining, and is also the key to understanding the regional tectonic evolution. In this study, based on the analysis of three-dimensional seismic, drilling and underground measured data and regional tectonic correlation, the structures, evolution history and dynamic background of the Qianyingzi Coal Mine are discussed. The Carboniferous-Permian coal measure strata in the mine are generally a gentle syncline with a NNE-trending axis, and cut by a series of faults. The faults developed in this mine are mainly medium- and small-sized with a throw of less than 20 m, and the number of reverse faults is significantly greater than that of normal faults. The strikes of reverse and normal faults are both mainly NE, followed by NNE and nearly N‒S. According to the characteristics of structural geometry, tectonic association, fault property and cross-cutting relation, the structural deformation of coal measure strata in the Qianyingzi Coal Mine can be divided into five stages, and the corresponding tectonic stress fields are NWW‒SEE compressive stress, nearly E‒W compressive stress, NW‒SE compressive stress, nearly E‒W and NW‒SE extensional stresses, respectively. It developed the Fengjia Syncline with a NNE-trending axis in the first stage and nearly N‒S-striking reverse faults in the second stage, which were the results of foreland deformation and subsequent continent-continent collision during the convergence of the North China Craton and South China Plate in the Indosinian period. The NNE-striking reverse sinistral faults and NE-striking reverse faults developed in the third stage is related to the rapid oblique subduction of the Izanagi Plate toward the East Asian continental margin at the beginning of the Early Cretaceous in the western Pacific region. Later, the fourth and fifth stages of the nearly N‒S- and NE-SW-striking normal faults were developed under the backarc extensional background in eastern China during the Early Cretaceous. These new results can be used to guide the rational arrangement for underground mining and also provide a new understanding for regional tectonic evolution of the Huaibei Coalfield. Copyright © 2023 Gu, Zhai, Wu, Li, Wang, Tan and Hao.",TextMining
"In self-determination theory (SDT), multiple conceptual regulations of motivation are posited. These forms of motivation are especially qualitatively viewed by SDT researchers, and there are situations in which combinations of these regulations occur. In this article, instead of the commonly used numerical approach, this is modeled more versatilely by sets and relations. We discuss discrete mathematical models from the theory of knowledge spaces for the combinatorial conceptualization of motivation. Thereby, we constructively add insight into a dispute of opinions on the unidimensionality vs. multidimensionality of motivation in SDT literature. The motivation order derived in our example, albeit doubly branched, was approximately a chain, and we could quantify the combinatorial details of that approximation. Essentially, two combinatorial dimensions reducible to one were observed, which could be studied in other more popular scales as well. This approach allows us to define the distinct, including even equally informative, gradations of any regulation type. Thus, we may identify specific forms of motivation that may otherwise be difficult to measure or not be separable empirically. This could help to dissolve possible inconsistencies that may arise in applications of the theory in distinguishing the different regulation types. How to obtain the motivation structures in practice is demonstrated by relational data mining. The technique applied is an inductive item tree analysis, an established method of Boolean analysis of questionnaires. For a data set on learning motivation, the motivation spaces and co-occurrence relations for the gradations of the basic regulation types are extracted, thus, enumerating their potential subforms. In that empirical application, the underlying models were computed within each of the intrinsic, identified, introjected, and external regulations, in autonomous and controlled motivations, and the entire motivation domain. In future studies, the approach of this article could be employed to develop adaptive assessment and training procedures in SDT contexts and for dynamical extensions of the theory, if motivational behavior can go in time. Copyright © 2023 Ünlü.",TextMining
"Background: Rhabdomyosarcoma (RMS) is a soft tissue sarcoma usually originated from skeletal muscle. Currently, RMS classification based on PAX–FOXO1 fusion is widely adopted. However, compared to relatively clear understanding of the tumorigenesis in the fusion-positive RMS, little is known for that in fusion-negative RMS (FN-RMS). Methods: We explored the molecular mechanisms and the driver genes of FN-RMS through frequent gene co-expression network mining (fGCN), differential copy number (CN) and differential expression analyses on multiple RMS transcriptomic datasets. Results: We obtained 50 fGCN modules, among which five are differentially expressed between different fusion status. A closer look showed 23% of Module 2 genes are concentrated on several cytobands of chromosome 8. Upstream regulators such as MYC, YAP1, TWIST1 were identified for the fGCN modules. Using in a separate dataset we confirmed that, comparing to FP-RMS, 59 Module 2 genes show consistent CN amplification and mRNA overexpression, among which 28 are on the identified chr8 cytobands. Such CN amplification and nearby MYC (also resides on one of the above cytobands) and other upstream regulators (YAP1, TWIST1) may work together to drive FN-RMS tumorigenesis and progression. Up to 43.1% downstream targets of Yap1 and 45.8% of the targets of Myc are differentially expressed in FN-RMS vs. normal comparisons, which also confirmed the driving force of these regulators. Discussion: We discovered that copy number amplification of specific cytobands on chr8 and the upstream regulators MYC, YAP1 and TWIST1 work together to affect the downstream gene co-expression and promote FN-RMS tumorigenesis and progression. Our findings provide new insights for FN-RMS tumorigenesis and offer promising targets for precision therapy. Experimental investigation about the functions of identified potential drivers in FN-RMS are in progress. Copyright © 2023 Zhan, Liu, Jannu, Huang, Ye, Wei, Pandya, Ye, Pollok, Renbarger, Huang and Zhang.",TextMining
"The current medication produces a lot of data put away in the clinical information base. Extricating valuable information and settling on a logical choice for determining and treating illness from the data set progressively becomes fundamental. In this suggested effort, a framework should be developed for the anticipation of brain infection to be used to get meaningful data based on adverse effects. The data cannot be successfully retrieved because of the accessibility of huge unstructured measurements on numerous diseases. The secret relationship between various infections and their causes is difficult to remove from 'unstructured data. We propose Brain infections Prediction System for the general public to forestall the reason for the demise. So we examine brain sickness patients to recognize which therapy is the best one and give a better outcome. The prescient exactness dictated by Naive Bayes, Support Vector Machine, and Hybrid calculations are estimated, and tracks down that crossbreed furnish the best outcome while contrasting and others. © 2023 American Institute of Physics Inc.. All rights reserved.",TextMining
"Information extraction from computer-generated holograms using learning-based methods is a topic that has not received much research attention. In this article, we propose and study two learning-based methods to extract the depth information from a hologram and compare their performance with that of classical depth from focus (DFF) methods. We discuss the main characteristics of a hologram and how these characteristics can affect model training. The obtained results show that it is possible to extract depth information from a hologram if the problem formulation is well-posed. The proposed methods are faster and more accurate than state-of-the-art DFF methods. © 2023 Optica Publishing Group under the terms of the Optica Open Access Publishing Agreement.",TextMining
"A clinical process contains a treatment pathway for a well-defined patient group that aims to improve patient outcomes. Electronic Health Records (EHRs) have become popular with the rapid development of healthcare information systems. Process mining utilises event logs extracted from EHRs and aims to discover systematic clinical processes automatically. Hence, the validity of the discovered clinical process becomes a critical issue for stakeholders. Existing methods mainly focus on evaluating the performance of the discovery algorithms (the conformance between the discovered process and the event log) while ignoring the validity of the discovered clinical process. Therefore, we propose a data-driven framework that can test the validity of the process by correlating selected patient outcomes with the discovered clinical process. A valid and effective clinical process should positively impact patient outcomes and can potentially assist in developing evidence-based guidelines for future treatments. The data-driven framework adopts the triangulation method combined with the statistical test model consisting of propensity score matching and difference-in-difference regression to overcome the limitations of existing methods. A use case scenario is presented to discover the clinical process for patients with suspected acute coronary syndrome.  © 2023 ACM.",TextMining
"Purpose: This paper aims to use the concept of machine learning to enable people and machines to interact more certainly to extend and expand human expertise and cognition. Design/methodology/approach: Intelligent code reuse recommendations based on code big data analysis, mining and learning can effectively improve the efficiency and quality of software reuse, including common code units in a specific field and common code units that are not related to the field. Findings: Focusing on the topic of context-based intelligent code reuse recommendation, this paper expounds the research work in two aspects mainly in practical applications of smart decision support and cognitive adaptive systems: code reuse recommendation based on template mining and code reuse recommendation based on deep learning. Originality/value: On this basis, the future development direction of intelligent code reuse recommendation based on context has prospected. © 2021, Emerald Publishing Limited.",TextMining
"Graph Neural Network (GNN) is capable of applying deep neural networks to graph domains. Recently, Message Passing Neural Networks (MPNNs) have been proposed to generalize several existing graph neural networks into a unified framework. For graph representation learning, MPNNs first generate discriminative node representations using the message passing function and then read from the node representation space to generate a graph representation using the readout function. In this paper, we analyze the representation capacity of the MPNNs for aggregating graph information and observe that the existing approaches ignore the self-loop for graph representation learning, leading to limited representation capacity. To alleviate this issue, we introduce a simple yet effective propagation enhanced extension, Self-Connected Neural Message Passing (SC-NMP), which aggregates the node representations of the current step and the graph representation of the previous step. To further improve the information flow, we also propose a Densely Self-Connected Neural Message Passing (DSC-NMP) that connects each layer to every other layer in a feed-forward fashion. Both proposed architectures are applied at each layer and the graph representation can then be used as input into all subsequent layers. Remarkably, combining these two architectures with existing GNN variants can improve these models' performance for graph representation learning. Extensive experiments on various benchmark datasets strongly demonstrate the effectiveness, leading to superior performance for graph classification and regression tasks.  © 1989-2012 IEEE.",TextMining
"We propose methods for extracting triples from Wikipedia's HTML tables using a reference knowledge graph. Our methods use a distant-supervision approach to find existing triples in the knowledge graph for pairs of entities on the same row of a table, postulating the corresponding relation for pairs of entities from other rows in the corresponding columns, thus extracting novel candidate triples. Binary classifiers are applied on these candidates to detect correct triples and thus increase the precision of the output triples. We extend this approach with a preliminary step where we first group and merge similar tables, thereafter applying extraction on the larger merged tables. More specifically, we propose an observed schema for individual tables, which is used to group and merge tables. We compare the precision and number of triples extracted with and without table merging, where we show that with merging, we can extract a larger number of triples at a similar precision. Ultimately, from the tables of English Wikipedia, we extract 5.9 million novel and unique triples for Wikidata at an estimated precision of 0.718.  © 1989-2012 IEEE.",TextMining
"The Editor-in-Chief and the publisher have retracted this article. The article was submitted to be part of a guest-edited issue. An investigation by the publisher found a number of articles, including this one, with a number of concerns, including but not limited to compromised editorial handling and peer review process, inappropriate or irrelevant references or not being in scope of the journal or guest-editedissue. Based on the investigation’s findings the Editor-in- Chief therefore no longer has confidence in the results and conclusions of this article. The author has not responded to correspondence regardingthis retraction. © 2021 King Fahd University of Petroleum & Minerals.",TextMining
"Cognitive diagnosis is an intelligent assessment technique of mining learners′ cognitive state based on learning data. Concepts in learning tasks are regarded as equally important by most cognitive diagnosis deep model. Without the consideration of the interaction between concepts, diagnosis accuracy is affected and interpretability is insufficient. To solve the problems, a concept interaction-based cognitive diagnosis deep model is proposed to realize the unified representation of students′ cognitive state and concept weights. In the meanwhile, an algorithm of ideal response calculation based on the Choquet integral is implemented. Finally, a deep neural network based on fuzzy measures is proposed to predict learners′ response performance. Experiments show that the proposed model holds advantages in prediction results and the explanation at the concept interaction level provided for prediction results. © 2023 Journal of Pattern Recognition and Artificial Intelligence. All rights reserved.",TextMining
"Existing aspect-based/category sentiment analysis methods have shown great success in detecting sentiment polarity toward a given aspect in a sentence with supervised learning, where the training and inference stages share the same pre-defined set of aspects. However, in practice, the aspect categories are changing rather than keeping fixed over time. Dealing with unseen aspect categories is under-explored in existing methods. In this article, we formulate a new few-shot aspect category sentiment analysis (FSACSA) task, which aims to effectively predict the sentiment polarity of previously unseen aspect categories. To this end, we propose a novel Aspect-Focused Meta-Learning (AFML) framework that constructs aspect-Aware and aspect-contrastive representations from external knowledge to match the target aspect with aspects in the training set. Concretely, we first construct two auxiliary contrastive sentences for a given sentence with the incorporation of external knowledge, enabling the learning of sentence representations with a better generalization. Then, we devise an aspect-focused induction network to leverage the contextual sentiment toward a given aspect to refine the label vectors. Furthermore, we employ the episode-based meta-learning algorithm to train the whole network, so as to learn to generalize to novel aspects. Extensive experiments on multiple real-life datasets show that our proposed AFML framework achieves the state-of-The-Art results for the FSACSA task. © 2023 Association for Computing Machinery.",TextMining
"Detection rates of non-compliant activity in Australian provider medical claims are below international benchmarks, and new methods are required. Since the Department of Health requires interpretability and incorporation of expert feedback as key components of its decision support systems many existing fraud detection techniques are unsuitable. As part of an Industry PhD project we have developed several new anomaly detection techniques which have been implemented in a prototype software system for the Australian Government Department of Health. We discuss the goals of the project and outline our approach to rapid prototyping and implementing processes to achieve expert-validated improvements in detection rates.  © 2023 ACM.",TextMining
"Due to the gradual depletion of shallow mineral resources at present, mines are now gradually entering the deep mining stage. To promote the safe and efficient green mining of deep coal resources and sustainable energy development, and to improve the production efficiency of paste filling mining, the research group has performed this study on the green filling mining technology and application of the working face. Taking working face 1241 (3) of the Xieqiao coal mine as the engineering background, the selection and experiment of filling materials were carried out, and the gangue, fly ash and cement produced by the Xieqiao coal mine were used as the filling aggregate. Next, the strength changes before and after paste filling was obtained by theoretical calculation. The strength at the early stage of filling was no less than 0.13 MPa, and that at the late stage of filling was no less than 2 MPa. Based on previous experimental research and theoretical calculation, the mixing pumping process of paste material ratio and the gangue crushing process were determined, and the filling pipeline system was designed. Then, based on the traditional coal mining technology, a filling mining technology of working face was designed and optimized. The field application of the research results shows that after the goaf of the working face had been filled, the ground pressure behavior of the coal wall of the working face was significantly weakened, and the stability of the surrounding rock of the working face was effectively controlled. Therefore, the method achieved good results, effectively controlled the stability of surrounding rock in goaf, and provided a theoretical basis and data support for realizing safe, efficient and green mining of deep coal resources. The results of this study bear important significance and application value. Copyright © 2023 Hou, Li, Yuan, Li and Liu.",TextMining
"Adverse drug events have been a significant concern in medication development as this issue has resulted in comparatively high risks of hospital admissions and death rates worldwide. Traditionally, these risks should have been identified through clinical trials, which could be time-consuming and cost-inefficient. At the same time, it still leaves some adverse drug events unknown due to limited samples in labs during the early phases of drug development. Therefore, various machine-learning techniques have been used in this field of study to support the discovery of adverse drug events as early as possible. This paper presents a state-of-the-art network-based approach to model each patient as a subgraph that consists of nodes of ICD-10 codes and directed edges showing the progression of their diseases. With the help of four Graph Neural Network variants, we could address three research questions 1) whether, 2) when, and 3) which ADEs would occur for a particular patient. In this short paper, we analysed the first question - how this method could be used in identifying cohorts associated with adverse drug events. The experiment showed that the GraphSage method employed on our suggested graph provided the highest accuracy - 0.8863 and the highest recall - 0.9128 for this research question. The same GNN-based framework could also be applied to the remaining research questions.  © 2023 ACM.",TextMining
"Analyzing the urban trajectory in cities has become an important topic in data mining. How can we model the human mobility consisting of stay and travel states from the raw trajectory data? How can we infer these mobility states from a single user's trajectory information? How can we further generalize the mobility inference to the real-world trajectory data that span multiple users and are sparsely sampled over time?In this article, based on formal and rigid definitions of the stay/travel mobility, we propose a single trajectory inference algorithm that utilizes a generic long-tailed sparsity pattern in the large-scale trajectory data. The algorithm guarantees a 100% precision in the stay/travel inference with a provable lower bound in the recall metric. Furthermore, we design a transformer-like deep learning architecture on the problem of mobility inference from multiple sparse trajectories. Several adaptations from the standard transformer network structure are introduced, including the singleton design to avoid the negative effect of sparse labels in the decoder side, the customized space-time embedding on features of location records, and the mask apparatus at the output side for loss function correction. Evaluations on three trajectory datasets of 40 million urban users validate the performance guarantees of the proposed inference algorithm and demonstrate the superiority of our deep learning model, in comparison to sequence learning methods in the literature. On extremely sparse trajectories, the deep learning model improves from the single trajectory inference algorithm with more than two times of overall and F1 accuracy. The model also generalizes to large-scale trajectory data from different sources with good scalability. © 2023 Association for Computing Machinery.",TextMining
"Recent years have witnessed the booming data of drugs and their associated adverse drug reactions (ADRs), resulting in a comparatively high hospitalization rate worldwide. Therefore, a tremendous amount of research has been done to predict ADRs to keep the risks at a minimum. Due to the nature of the lab experiments being costly and time-consuming, researchers are looking forward to more extensive use of data mining and machine learning techniques in this field. This paper constructs a weighted drug-drug network based on an integration of various data sources. The network presents underlying relationships between drugs by creating connections between them according to their common ADRs. Then multiple node-level and graph-level network features are extracted from this network, e.g. weighted degree centrality, weighted PageRanks etc. By concatenating these features to the original drug features, it could be made possible to train and test seven classical machine learning algorithms, e.g. Logistic Regression, Random Forest, Support Vector Machine, etc. The experiments conclude that all the tested machine learning methods would benefit from adding those network measures, and the logistic regression (LR) model provides the highest mean AUROC score (0.821) across all ADRs in the experiment. Weighted degree centrality and weighted PageRanks are identified to be the most important network features in the LR classifier. These shreds of evidence strongly support that the network approach could be fundamental in future ADR prediction, and the network edge weights are important in the logistic regression model.  © 2023 ACM.",TextMining
"Urban flow analysis is an essential research for smart city construction, in which urban flow pattern analysis focuses on the continuous state of urban flow. How to mine, store and reuse traffic patterns from urban multi-source heterogeneous big data is challenging. Therefore, this paper proposes a knowledge mining network for regional flow pattern to mine and store the urban flow pattern. The proposed model consists of two modules. In the first module, the features of the region and its flow pattern are extracted as the entity and relation, respectively. In the second module, POI features are modeled to enhance the embedding representation of relation and entity. Based on the translation distance method, the knowledge triplets of regional flow patterns are mined. Finally, the proposed model is compared with some benchmark methods using Chengdu Didi order and POI datasets. Experimental results show that the proposed model is effective. In addition, the knowledge triplets are visualized and some application examples are introduced. © 1989-2012 IEEE.",TextMining
"The Internet-of-Things (IoT) technologies are essential in deploying successful IoT-based services, especially in the financial services sector in recent years. Stock market prediction, which could also be an IoT-based service, is a very attractive topic that has inspired countless studies. Using financial news articles to forecast the effect of certain events, understand investors' emotions, and react accordingly has been proved viable in the existing pieces of the literature. In this study, we utilized Chinese financial news in an attempt to predict the stock price movement and to derive a trading strategy based on news factors and technical indicators. First, the stock trend prediction (STP) approach is proposed. It first extracts keywords from the given articles. Then, the 2-word combination is employed to generate more meaningful keywords. The feature extraction and selection are followed to obtain important attributes for building a trading signal prediction model. Also, to make the trading signal more reliable, the technical indicators are considered to confirm the trading signal. Because the hyperparameters for the STP and technical indicators will have influenced the final results, an enhanced approach, namely, the genetic algorithm (GA)-based STP (GASTP) approach, is then proposed to find hyperparameters automatically for constructing a better prediction model. Experiments on real data sets were also made to show the effectiveness of the proposed algorithms. The results show that the GASTP performs better than the buy-and-hold strategy as well as the STP.  © 2014 IEEE.",TextMining
"Healthcare Informatics is a phenomenon being talked about from the early 21st century in the era in which we are living. With evolution of new computing technologies huge amount of data in healthcare is produced opening several research areas. Managing the massiveness of this data is required while extracting knowledge for decision making is the main concern of today. For this task researchers are doing explorations in big data analytics, deep learning (advanced form of machine learning known as deep neural nets), predictive analytics and various other algorithms to bring innovation in healthcare. Through all these innovations happening it is not wrong to establish that disease prediction with anticipation of its cure is no longer unrealistic. First, Dengue Fever (DF) and then Covid-19 likewise are new outbreak in infectious lethal diseases and diagnosing at all stages is crucial to decrease mortality rate. In case of Diabetes, clinicians and experts are finding challenging the timely diagnosis and analyzing the chances of developing underlying diseases. In this paper, Louvain Mani-Hierarchical Fold Learning healthcare analytics, a hybrid deep learning technique is proposed for medical diagnostics and is tested and validated using real-time dataset of 104 instances of patients with dengue fever made available by Holy Family Hospital, Pakistan and 810 instances found for infectious diseases including prognosis of; Covid-19, SARS, ARDS, Pneumocystis, Streptococcus, Chlamydophila, Klebsiella, Legionella, Lipoid, etc. on GitHub. Louvain Mani-Hierarchical Fold Learning healthcare analytics showed maximum 0.952 correlations between two clusters with Spearman when applied on 240 instances extracted from comorbidities diagnostic data model derived from 15696 endocrine records of multiple visits of 100 patients identified by a unique ID. Accuracy for induced rules is evaluated by Laplace (Fig. 8) as 0.727, 0.701 and 0.203 for 41, 18 and 24 rules, respectively. Endocrine diagnostic data is made available by Shifa International Hospital, Islamabad, Pakistan. Our results show that in future this algorithm may be tested for diagnostics on healthcare big data. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.",TextMining
"Time series modeling has attracted great research interests in the last decades. Among the literature, shapelet-based models aim to extract representative subsequences, and could offer explanatory insights in the downstream tasks. But most of those works ignore the seasonal effects on the subsequences, as well as the evolutionary characteristics of shapelets. In order to capture the shapelet dynamics and evolutions, in this paper, we propose a novel framework of bridging time series representation learning and graph modeling, with two different implementations. We first formulate the process of extracting time-aware shapelets by directly adding time-level attentions, then introduce the key idea of transforming time series data into shapelet evolution graphs, to model the shapelet evolutionary patterns. A straightforward solution is to enumerate all possible shapelet transitions among adjacent time series segments, and apply a random-walk-based graph embedding algorithm to learn time series representations (Time2Graph). We further extend Time2Graph by adopting graph attention mechanism to refine the procedure of modeling shapelet evolutions, namely Time2Graph+. Specifically, we transform each time series data into a unique unweighted shapelet graph, and use GAT to automatically capture the correlations between shapelets. Experimental results on three real-world datasets show the significant improvements of Time2Graph+ over Time2Graph and 17 baseline methods, and observational analysis demonstrates the effectiveness and interpretability brought by both time-level and graph-level attentions. Furthermore, the success of online deployment of Time2Graph+ model in State Grid of China validates the whole framework in the real-world application. Codes and documentations are available at https://github.com/petecheng/Time2GraphPlus.  © 1989-2012 IEEE.",TextMining
"Satellites are widely used for remote sensing applications. High resolution images are used for different geographical applications. Using geographical objects or spatial objects for analysis became prevalent in the contemporary era. Many supervised classification techniques came into existence to have efficient classification of high-resolution imagery. There are many factors that may affect classification of geographic images. They include the presence of mixed objects, feature selection, size of training set and segmentation scale. When these factors are considered for a systematic mining of images with high resolution, it results in improved performance. Especially in agricultural environments, it is essential to have such study to ascertain which supervised learning mechanism can best deal with the factors aforementioned. An algorithm named Feature Subset Selection (FSS) is defined to enhance classification accuracy. Different classification techniques such as Support Vector Machine (SVM), Random Forest (RF), Naïve Bayes, k-Nearest Neighbour (KNN), Adaboost.M1 and Decision Table (DT) are used for the empirical study with spatial data mining. Useful analysis of the techniques is made and thus this paper provides valuable insights on mining images of high spatial resolution in agricultural environments. © 2021, King Abdulaziz City for Science and Technology.",TextMining
"With the rapid development of internet technology and mobile devices, massive streaming data of spatiotemporal information is available for real-time data mining. Outlier detection is playing as one of the most important analysis tasks for trajectory stream processing, such as traffic control and urban planning. Existing work about this issue can be divided into two main categories: individual outlier detection (IOD) and group outlier detection (GOD). IOD focuses on detecting an individual trajectory outlier generated by a single moving object (e.g., an over-speeding car), while GOD aims to detect a group outlier generated by various moving objects (e.g., a group of cars influenced by a traffic jam). However, existing studies only support one of them and cannot comprehensively understand the traffic conditions by combining both of them. To this end, we propose a novel framework for real-time urban traffic outlier detection (RUTOD) in this paper. RUTOD contains IOD based on current traffic conditions and GOD according to historical data. In addition, we adopt a street-based trajectory division to accelerate investigation. Experimental results show that our proposal is not only effective but also efficient for detecting both individual outliers and group outliers in real-time scenario. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",TextMining
"Graph classification has been widely used for knowledge discovery in numerous practical application scenarios, such as social networks and protein-protein interaction networks. Recently, Graph Neural Networks (GNNs), which generalize deep neural networks to graph-structured data, have drawn considerable attention and achieved state-of-the-art performance in graph classification. However, existing GNN models mainly focus on capturing the information of immediate or first-order neighboring nodes within a single layer. The graph substructure and substructure interaction, which plays an important role in learning graph representations, are usually overlooked. In this paper, we propose a Substructure Assembling Graph Attention Network (SA-GAT) to extract graph features and improve the performance of graph classification. SA-GAT is able to fully explore higher-order substructure information hidden in graphs by a core module called Substructure Interaction Attention (SIA), which takes both the information of neighbors' substructures and the interaction information among them into account during aggregation process. Theoretically, we have also proved that SA-GAT satisfies the graph isomorphism theory of graph neural network design, which is that the network should map isomorphic graphs to the same representation and output the same prediction. Extensive experimental results on multiple real-world graph classification datasets demonstrate that the proposed SA-GAT outperforms the state-of-the-art methods including graph kernels and graph neural networks.  © 1989-2012 IEEE.",TextMining
"Cohesive subgraph mining is a fundamental problem in the field of graph data analysis. Many existing cohesive graph mining algorithms are mainly tailored to deterministic graphs. Real-world graphs, however, are often not deterministic, but uncertain in nature. Applications of such uncertain graphs include protein-protein interactions networks with experimentally inferred links and sensor networks with uncertain connectivity links. In this article, we study the problem of mining cohesive subgraphs from an uncertain graph. Specifically, we introduce a new (α,γ)-quasi-clique model to model the cohesive subgraphs in an uncertain graph, and propose a basic enumeration algorithm to find all maximal (α,γ)-quasi-cliques. We also develop an advanced enumeration algorithm based on several novel pruning rules, including early termination and candidate set reduction. To further improve the efficiency, we propose several optimization techniques. Extensive experiments on five real-world datasets demonstrate that our solutions are almost three times faster than the baseline approach.  © 2022 IEEE.",TextMining
"Introduction: Medical equipment is an indispensable part of hospitals. It is the basic condition and guarantee for the hospital to carry out medical services, scientific research, teaching, and other activities, and it plays an irreplaceable role in the entire medical process of the hospital. Therefore, the maintenance management of equipment is also the focus of our attention. In the past, traditional management methods such as paper were mainly used for equipment maintenance management, and it was difficult to share data. Methods: In today’s era of rapid development of information technology, we will use information technology to maintain and manage medical equipment. Through big data analysis and other technologies, the drawbacks of the existing traditional management methods are improved, so that medical equipment can be managed scientifically. By maximizing its functions, it can ensure the normal operation of medical facilities, improve the utilization rate and integrity rate of equipment, and reduce maintenance costs and unnecessary losses. Results: According to the research findings, based on the background of big data, a de-Bayesian network is used for data mining to build a medical equipment maintenance platform. Through the data in the platform, we can better discover the distribution and reasons of equipment maintenance, and at the same time conduct an analysis to provide reference for the formulation of preventive maintenance plans, reduce equipment failure rate and maintenance costs and improve equipment utilization. Through the survey of medical staff, we can also find that at least 40% of the people feel that the work distribution is more reasonable, and 45% of the people feel that the equipment failure rate and the time required for maintenance have been greatly reduced. Discussion: We can see that the network platform for medical equipment maintenance management built through big data is very feasible, which can help us work more effectively and improve work efficiency. Copyright © 2023 Li, Mao and Zhang.",TextMining
"Artificial intelligence is a future and valuable tool for early disease recognition and support in patient condition monitoring. It can increase the reliability of the cure and decision making by developing useful systems and algorithms. Healthcare workers, especially nurses and physicians, are overworked due to a massive and unexpected increase in the number of patients during the coronavirus pandemic. In such situations, artificial intelligence techniques could be used to diagnose a patient with life-threatening illnesses. In particular, diseases that increase the risk of hospitalization and death in coronavirus patients, such as high blood pressure, heart disease and diabetes, should be diagnosed at an early stage. This article focuses on diagnosing a diabetic patient through data mining techniques. If we are able to diagnose diabetes in the early stages of the disease, we can force patients to stay home and care for their health, so the risk of being infected with the coronavirus would be reduced. The proposed method has three steps: preprocessing, feature selection and classification. Several combinations of Harmony search algorithm, genetic algorithm, and particle swarm optimization algorithm are examined with K-means for feature selection. The combinations have not examined before for diabetes diagnosis applications. K-nearest neighbor is used for classification of the diabetes dataset. Sensitivity, specificity, and accuracy have been measured to evaluate the results. The results achieved indicate that the proposed method with an accuracy of 91.65% outperformed the results of the earlier methods examined in this article. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Ethnopharmacological relevance: Xinfeng capsule is a traditional Chinese medicine compound, which has been clinically used for more than 20 years in the treatment of rheumatoid arthritis (RA), ankylosing spondylitis, osteoarthritis and its extracurricular lesions. However, the molecular role of XFC in the treatment of RA remains unclear. Objective: This study aims to explore the efficacy and potential mechanism of XFC through retrospective data mining analysis, animal experiments and cell experiments. Methods: The effect of XFC on clinical laboratory indexes of RA patients was observed using data mining techniques combined with association rule analysis and a random walk model. Afterwards, a rat model of adjuvant arthritis (AA) was established with Freund's complete adjuvant, followed by the observation of pathological changes in synovial tissues and the ultrastructure of synoviocytes. A RA cell model was constructed by inducing fibroblast-like synoviocytes (FLSs) with tumor necrosis factor-alpha (TNF-α) to assess the effects of XFC-containing serum on inflammation and oxidative stress through long non-coding RNA LINC00638. Results: In retrospective data mining, XFC effectively reduced immune inflammation and increase the level of antioxidant enzymes in RA patients. Subsequently, animal experiments showed that XFC significantly repressed immune inflammation, oxidative stress, synovial hyperplasia, and cartilage destruction, while improving the ultrastructure of synoviocytes in AA rats. XFC-containing serum diminished the proliferation of TNF-α-induced RA-FLSs, increased LINC00638 expression (P＜0.01), decreased interleukin-6 (IL-6), IL-17, reactive oxygen species (ROS) and reactive nitrogen species (RNS) levels (P＜0.01), and increased the protein expression of nuclear factor erythrocyte 2-related factor 2 (Nrf2), heme oxygenase 1 (HO-1), and superoxide dismutase 2 (SOD2) (P＜0.01). Furthermore, rescue experiments manifested that XFC-containing serum reversed the effects of silencing LINC00638 on inflammation and oxidative stress in RA-FLSs. Conclusion: XFC inhibits inflammation and oxidative stress in RA by up-regulating LINC00638 and activating Nrf2/HO-1 pathway. © 2022 The Authors",TextMining
"The children's gut microbiota, associated with the development of obesity, is in maturation. The impact of obesity on the gut microbiota in childhood could have a more significant effect than on adulthood and eventually be lifelong lasting, but it has been rarely studied. Aimed to discover the difference in gut microbiota between children and adults with obesity, we collected published amplicon sequencing data from National Center for Biotechnology Information (NCBI) and re-analyzed them using a uniform bioinformatic pipeline, as well as predicted the obesity using gut microbiota based on the random forest model. Summarizing common points among these cohorts, we found that the gut microbiota had a significant difference between children with and without obesity, but this difference was not observed in adult cohorts. Based on the random forest model, it was more challenging to predict childhood obesity using gut microbiota than adulthood obesity. Our results suggest that gut microbiota in childhood is more easily affected than in adulthood. Early intervention for childhood obesity is essential to improve children's health and lifelong gut microbiota-related health. 2023 Yu, Yu, Zhao, Su and Ren.",TextMining
"This article revisits the bilinear attention networks (BANs) in the visual question answering task from a graph perspective. The classical BANs build a bilinear attention map to extract the joint representation of words in the question and objects in the image but lack fully exploring the relationship between words for complex reasoning. In contrast, we develop bilinear graph networks to model the context of the joint embeddings of words and objects. Two kinds of graphs are investigated, namely, image-graph and question-graph. The image-graph transfers features of the detected objects to their related query words, enabling the output nodes to have both semantic and factual information. The question-graph exchanges information between these output nodes from image-graph to amplify the implicit yet important relationship between objects. These two kinds of graphs cooperate with each other, and thus, our resulting model can build the relationship and dependency between objects, which leads to the realization of multistep reasoning. Experimental results on the VQA v2.0 validation dataset demonstrate the ability of our method to handle complex questions. On the test-std set, our best single model achieves state-of-the-art performance, boosting the overall accuracy to 72.56%, and we are one of the top-two entries in the VQA Challenge 2020.  © 2022 IEEE.",TextMining
"The current medication produces a lot of data put away in the clinical information base. Extricating valuable information and settling on a logical choice for determining and treating illness from the data set progressively becomes fundamental. This hybrid technique of computation of the decision table saves the information based on the preferred arrangement of features and uses the model as a query table during the preparation of information predictions. This paper proposes a Liver infections Prediction framework for the general public to forestall the reason for the demise. Compared with other current frameworks, the suggested framework produces superior results for liver disease prediction. For future examination, the best and most effective treatment will also be assessed by a liver infection patient based on the given therapy and drugs provided by physicians for the dangerous patient. The proposed framework easily recognizes liver disease, recommends which therapy is the best, and gives a better outcome. © 2023 American Institute of Physics Inc.. All rights reserved.",TextMining
"Introduction: Impressive advances in immunotherapy especially immune checkpoint inhibitors have made great progress in treating multiple cancers but can also cause serious even incurable immune-related adverse events, mostly found in colitis, dermatitis, hepatitis, and thyroiditis patients. Rare autoimmune hematologic toxicities have been reported in the literature, but are poorly described. Aplastic anaemia induced by immune checkpoint inhibitors is a life-threatening autoimmune disease; however, only a few cases have been reported in the literature. Objective: To characterize and evaluate Aplastic anaemia associated with different ICI regimens in public database and review the literature. Methods: We described a case series of patients experiencing Aplastic anaemia while on immune checkpoint inhibitors. We also mined the Food and Drug Administration’s Adverse Event Reporting System and used reporting odds ratio, the proportional reporting ratio, the Bayesian confidence propagation neural network and the multi-item gamma Poisson shrinker algorithms to achieve the data of the suspected adverse events of Aplastic anaemia-induced by immune checkpoint inhibitors between January 2011 and June 2022. Results: Thirteen patients with Aplastic anaemia events while on immune checkpoint inhibitors were included in our case series, and seven of them had a fatal outcome. In FAERS, a total of 38 individual case safety reports (immune checkpoint inhibitors) with different ICI regimens were retrieved, of which 25 (65.79%) were reported as monotherapy and 13 (34.2%) had a fatal outcome. The reporting odds ratio was significant for nivolumab (reporting odds ratio 3.05, 95%CI 1.73–5.38), pembrolizumab (reporting odds ratio 2.33, 95%CI 1.16–4.67), avelumab (reporting odds ratio 12.63, 95%CI 3.15–50.62) and ipilimumab/nivolumab (ROR 2.57, 95%CI 1.15–5.72). Conclusion: There is a significant reporting signal of Aplastic anaemia with several ICI agents. Clinicians should raise awareness and monitor this potentially fatal adverse event. Copyright © 2023 Guo, Zhao, Liu, Gao, Guo and Cheng.",TextMining
"Accurate and timely warning is vital for the prevention and control of mountain flash flood disasters in small-and medium-sized basins, but it is the most challenging task. Focusing on the key issues of mountain flash flood warning, this study conducted a review on the spatial differences of mountain flash flood disaster characteristics in China, techniques and methods for flash flood warning, and development of probabilistic warning methods for mountain flash flood control. The review indicated that the temporal and spatial differences of the characteristics of mountain flash flood disasters are clear across China, thus it is necessary to develop suitable early warning systems in specific areas based on their special characteristics. The indicator of critical rainfall is an important basis of mountain flash flood warning in China. A fixed critical rainfall estimated by statistical methods or hydrological models, as commonly done in practice, cannot meet the needs because it does not perform well sometimes and cannot adequately address the uncertainty of warning results. Alternatively, probabilistic warning of mountain flash flood disasters, which can quantitatively evaluate the uncertainty of warning results, has theoretical advantages and potentially wide applications, and thus could be a more adaptive approach. In order to develop the probabilistic warning methods of mountain flash flood disasters, the following key issues should be addressed: 1) Mining detailed information from different sources of rainstorm and flash floods data, and developing effective methods for the probabilistic warning of mountain flash flood disasters. 2) Dealing with the nonstationarity issue commonly encountered in hydrological studies, and exploring its influences on the estimation of critical rainfall and the accuracy of probabilistic warning results. 3) Establishing an integrated flash flood warning system by considering both the occurrence probability of critical rainfall and its resulting probability of mountain flash flood disasters for the practical prevention and control of mountain flash flood disasters. © 2023, Editorial office of PROGRESS IN GEOGRAPHY. All rights reserved.",TextMining
"The dynamic property and increasing complexity are the key challenges for modeling financial technology (FinTech)-related applications such as stock markets. Over the years, a lot of inflexible predictive strategies have been proposed for predicting stock price movements that failed to achieve satisfactory results especially when a market crash occurs. To cope with this challenge, we propose a prediction framework based on an adversarial training strategy using reinforcement learning for the said FinTech application. The framework uses a heterogeneous knowledge base, including stock prices, tweets, and global indicators. We propose a modified newton-divided difference polynomial (NDDP) for missing data imputation. The informative patterns representing the intrinsic characteristics of financial markets were extracted using long short-term memory networks (LSTM). The two adversarial networks are heterogeneous data fusion representing market crash (HDFM) Q -learning and confrontational Q -learning network. Both networks are trained in an adversarial fashion to increase the effectiveness of prediction even when the financial market is volatile. The experimental results show the importance of global indicators and the proposed adversarial learning network (ALN) for improving the predictive performance in comparison with the existing state-of-the-art works.  © 2014 IEEE.",TextMining
"Social e-commerce, as a new concept of e-commerce, uses social media as a new prevalent platform for online shopping. Users are now able to view, add to cart, and buy products within a single social media app. In this paper, we address the problem of cross-platform recommendation for social e-commerce, i.e., recommending products to users when they are shopping through social media. To the best of our knowledge, this is a new and important problem for all e-commerce companies (e.g., Amazon, Alibaba), but it has never been studied before. Existing cross-platform and social-related recommendation methods cannot be applied directly to this problem since they do not co-consider the social information and the cross-platform characteristics together. To study this problem, we collect two real-world datasets from social e-commerce services. We first investigate the heterogeneous shopping behaviors between traditional e-commerce app and social media. Based on these observations from data, we propose CROSS (Cross-platform Recommendation for Online Shopping in Social Media), a recommendation framework utilizing not only user-item interaction data on both platforms, but also social relation data on social media. The framework is general, and we propose two variants, CROSS-MF and CROSS-NCF. Extensive experiments on two real-world social e-commerce datasets demonstrate that our proposed CROSS significantly outperforms existing state-of-the-art methods. © 1989-2012 IEEE.",TextMining
"Today, emerging technologies such as 5G Internet of things (IoT), virtual reality and cloud-edge computing have enhanced and upgraded higher education environments in universities, colleagues and research centers. Computer-assisted learning systems with aggregating IoT applications and smart devices have improved the e-learning systems by enabling remote monitoring and screening of the behavioral aspects of teaching and education scores of students. On the other side, educational data mining has improved the higher education systems by predicting and analyzing the behavioral aspects of teaching and education scores of students. Due to an unexpected and huge increase in the number of patients during coronavirus (COVID-19) pandemic, all universities, campuses, schools, research centers, many scientific collaborations and meetings have closed and forced to initiate online teaching, e-learning and virtual meeting. Due to importance of behavioral aspects of teaching and education between lecturers and students, prediction of quality of experience (QoE) in virtual education systems is a critical issue. This paper presents a new prediction model to detect technical aspects of teaching and e-learning in virtual education systems using data mining. Association rules mining and supervised techniques are applied to detect efficient QoE factors on virtual education systems. The experimental results described that the suggested prediction model meets the proper accuracy, precision and recall factors for predicting the behavioral aspects of teaching and e-learning for students in virtual education systems. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TextMining
"Non-Euclidean property of graph structures has faced interesting challenges when deep learning methods are applied. Graph convolutional networks (GCNs) can be regarded as one of the successful approaches to classification tasks on graph data, although the structure of this approach limits its performance. In this work, a novel representation learning approach is introduced based on spectral convolutions on graph-structured data in a semisupervised learning setting. Our proposed method, COnvOlving cLiques (COOL), is constructed as a neighborhood aggregation approach for learning node representations using established GCN architectures. This approach relies on aggregating local information by finding maximal cliques. Unlike the existing graph neural networks which follow a traditional neighborhood averaging scheme, COOL allows for aggregation of densely connected neighboring nodes of potentially differing locality. This leads to substantial improvements on multiple transductive node classification tasks.  © 2022 IEEE.",TextMining
"The Coronavirus disease or COVID-19 is a viral disease caused by SARS-CoV-2, and by March 11, 2020, it was declared a pandemic by the World Health Organization (WHO). The COVID-19 pandemic did not only cause stress due to the illness itself, but it has also brought in severe and complex issues when it comes to quality of life. Passed studies have shown that Twitter was used in public health research, where most focused on evaluating the contents of the tweets. With that being said, during the COVID-19 pandemic, multiple research papers have used Twitter to create datasets pertaining to tweets related to COVID-19. In this study, data from an existing dataset was analyzed. After applying data scraping and identifying the frequencies of concerning variables, the study's main findings show that the most dominant sentiment category from March 2020 to December 2021 was the NEGATIVE category, while the most dominant emotion category was the JOY category. Regarding topics, Topic 1, Topic 2, and Topic 3 were the three most dominant topics throughout the considered time period. Lastly, most of the identified users were Male, and the keyword 'covid' was the most used keyword in the gathered tweets. © 2023 ACM.",TextMining
"Despite the blockchain's considerable potential to solve traditional supply chain problems, research on its deployment in pharmaceutical supply chains (PSC) is sparse. Therefore, the objective of this paper is to provide a conceptual framework for blockchain implementation within the pharmaceutical supply chain. To document the twelve-year research’s, 78 transdisciplinary publications published between 2010 and 2022 were examined using a comprehensive literature review and text mining method. Descriptive and thematic research highlights emerging Blockchain trends in pharmaceutical supply chain. Future research will primarily focus on the use of Blockchain for drug counterfeiting and recall issues, as well as other sector-specific challenges like patient health data sharing, compliance, and clinical trials. The arguments and obstacles for technology acceptance, implementation steps and applications highlighted through the thematic analysis will help build the orientation for the research. Compared to other industries, research on blockchain for PSC has lagged, but it has picked up speed since the Covid-19 pandemic. Researchers and professionals will be guided by the identified influencing factors and implementation roadmap for adopting Blockchain in the pharmaceutical business. The suggested framework is original and offers manufacturers, ministry of health, and private sectors helpful guidelines to Leverage the power of blockchain technology. © 2023 Little Lion Scientific.",TextMining
"Relation Extraction (RE) is a vital step to complete Knowledge Graph (KG) by extracting entity relations from texts. However, it usually suffers from the long-tail issue. The training data mainly concentrates on a few types of relations, leading to the lack of sufficient annotations for the remaining types of relations. In this paper, we propose a general approach to learn relation prototypes from unlabeled texts, to facilitate the long-tail relation extraction by transferring knowledge from the relation types with sufficient training data. We learn relation prototypes as an implicit factor between entities, which reflects the meanings of relations as well as their proximities for transfer learning. Specifically, we construct a co-occurrence graph from texts, and capture both first-order and second-order entity proximities for embedding learning. Based on this, we further optimize the distance from entity pairs to corresponding prototypes, which can be easily adapted to almost arbitrary RE frameworks. Thus, the learning of infrequent or even unseen relation types will benefit from semantically proximate relations through pairs of entities and large-scale textual information. We have conducted extensive experiments on two publicly available datasets: New York Times and Google Distant Supervision. Compared with eight state-of-the-art baselines, our proposed model achieves significant improvements (4.1 percent F1 on average). Further results on long-tail relations demonstrate the effectiveness of the learned relation prototypes. We further conduct an ablation study to investigate the impacts of varying components, and apply it to four basic relation extraction models to verify the generalization ability. Finally, we analyze several example cases to give intuitive impressions as qualitative analysis. Our codes and data can be found in https://github.com/CrisJk/PA-TRP. © 1989-2012 IEEE.",TextMining
"These days, health-related diseases are increasing day by day due to lifestyle and genetics. Especially these days, heart disease is so common that people's lives are at risk. Blood pressure, cholesterol and pulse rate vary from person to person. However, according to proven clinical results, normal blood pressure is 90/120 and cholesterol is 129-100 mg/dL, Pulse 72, fasting blood glucose 100 mg/dL, heart rate 100-60 bpm, normal ECG, main vessel width 25 mm (1 inch) in the aorta only 8 μm in the capillaries. This article looks at the different classification techniques used to predict each person's risk level based on age and gender. Blood pressure, cholesterol, heart rate. A ""disease prediction"" system based on predictive modeling predicts a user's disease based on the symptoms the user enters into the system. The system analyzes the symptoms that the user provides as inputs and provides disease probabilities as outputs. Disease prediction is done by applying techniques like KNN, Decision tree classifiers, random forest algorithms, and more. This technique calculates the probability of a disease. Therefore, we obtain an average prediction accuracy probability of 86.48%. © 2023, Ismail Saritas. All rights reserved.",TextMining
"In pattern classification, there may not exist labeled patterns in the target domain to train a classifier. Domain adaptation (DA) techniques can transfer the knowledge from the source domain with massive labeled patterns to the target domain for learning a classification model. In practice, some objects in the target domain are easily classified by this classification model, and these objects usually can provide more or less useful information for classifying the other objects in the target domain. So a new method called distribution adaptation based on evidence theory (DAET) is proposed to improve the classification accuracy by combining the complementary information derived from both the source and target domains. In DAET, the objects that are easy to classify are first selected as easy-target objects, and the other objects are regarded as hard-target objects. For each hard-target object, we can obtain one classification result with the assistance of massive labeled patterns in the source domain, and another classification result can be acquired based on the easy-target objects with confidently predicted (pseudo) labels. However, the weights of these classification results may vary because the reliabilities of the used information sources are different. The weights are estimated by mean difference reflecting the information source quality. Then, we discount the classification results with the corresponding weights under the framework of the evidence theory, which is expert at dealing with uncertain information. These discounted classification results are combined by an evidential combination rule for making the final class decision. The effectiveness of DAET for cross-domain pattern classification is evaluated with respect to some advanced DA methods, and the experiment results show DAET can significantly improve the classification accuracy.  © 2013 IEEE.",TextMining
"Label distribution learning (LDL) is a novel machine learning paradigm that can be seen as an extension of multi-label learning (MLL). Compared with MLL, the advantages of LDL are reflected in the following perspectives: (1) the label distribution gives the relevance description of each label to unknown instances in quantitative terms; (2) the distribution implicitly gives the relevance intensities relation of different labels to a particular instance in qualitative terms, i.e., the label ranking relation. All existing LDL models aim to fit the ground-truth label distribution by quantitatively minimizing the distance between distributions or maximizing the similarity between distributions, which only uses the first advantage of the label distribution but ignores the label ranking relation, which may lose some useful semantic information implied in the label distribution, thus reducing the performance of LDL. Therefore, we propose a novel algorithm to solve this problem by introducing the ranking loss function to LDL. In addition, in order to evaluate the LDL algorithms more comprehensively and verify that the ranking loss is beneficial for keeping the label ranking relation, we also introduce two popular ranking evaluation metrics for LDL. The experimental results on 13 real-world datasets validate the effectiveness of our method. © 1989-2012 IEEE.",TextMining
"Tensor program tuning is a non-convex objective optimization problem, to which search-based approaches have proven to be effective. At the core of the search-based approaches lies the design of the cost model. Though deep learning-based cost models perform significantly better than other methods, they still fall short and suffer from the following problems. First, their feature extraction heavily relies on expert-level domain knowledge in hardware architectures. Even so, the extracted features are often unsatisfactory and require separate considerations for CPUs and GPUs. Second, a cost model trained on one hardware platform usually performs poorly on another, a problem we call cross-hardware unavailability. In order to address these problems, we propose TLP and MTL-TLP. TLP is a deep learning-based cost model that facilitates tensor program tuning. Instead of extracting features from the tensor program itself, TLP extracts features from the schedule primitives. We treat schedule primitives as tensor languages. TLP is thus a Tensor Language Processing task. In this way, the task of predicting the tensor program latency through the cost model is transformed into a natural language processing (NLP) regression task. MTL-TLP combines Multi-Task Learning and TLP to cope with the cross-hardware unavailability problem. We incorporate these techniques into the Ansor framework and conduct detailed experiments. Results show that TLP can speed up the average search time by 9.1× and 3.0× on CPU and GPU workloads, respectively, compared to the state-of-the-art implementation. MTL-TLP can achieve a speed-up of 4.7× and 2.9× on CPU and GPU workloads, respectively, using only 7% of the target hardware data. To the best of our knowledge, TLP is the first tensor program cost model to extract features directly from schedule primitives, and MTL-TLP is the first open-sourced work that effectively addresses the cross-platform unavailability problem. The code is available at https://github.com/zhaiyi000/tlp.  © 2023 ACM.",TextMining
"Nowadays, couriers are still the main solution to address the 'last mile' problem in logistics. They are usually required to record the delivery time of each parcel manually, which is essential for delivery insurances, delivery performance evaluations, and customer available time discovery. Stay points extracted from couriers' trajectories provide a chance to fill the delivery time automatically to ease their burdens. However, it is challenging due to inaccurate delivery locations and various stay scenarios. To this end, we propose the improved Delivery Time Inference (DTInf+), to infer the delivery time of waybills based on their trajectories. DTInf+ is composed of three steps: 1) Data Pre-processing, which organizes waybills and stay points by delivery trips, 2) Delivery Location Mining, which obtains the delivery location for each address and each Geocoded waybill location by mining historical delivery caused stay points, and 3) Delivery Event-based Matching, which infers the delivery caused stay point for waybills at the same delivery location based on a pointer network-like model SPSelector to obtain the delivery time. Extensive experiments and case studies based on real-world datasets from JD Logistics confirm the effectiveness of our approach. Finally, a system is deployed in JD Logistics.  © 1989-2012 IEEE.",TextMining
"Nowadays, chronic kidney illness (CKD) is one of the significant reasons for mortality, and it has a drawn-out handicap. The inclining factors for CKD incorporate hypertension, cardiovascular sicknesses, diabetes mellitus, and innate kidney issues. Renal substitution treatment is the treatment of decision for CKD. Information mining is an exact strategy that assists with anticipating the illness utilizing different techniques incorporate calculated relapse, Naive Bayes order, k-closest neighbours, and backing vector machine. Aside from these past procedures, it was essential to use an arrangement strategy for information division as indicated by their determination and relapse technique for discovering hazard factors.The results of the study reveal that the RNN computations show ""91.75%"" accuracy, and that IPM offers ""96.75%"" accuracy. This connection has the benefit that the interplay between expectations is less powerful. It will help experts to initiate treatments for persistent patients on time and will help to detect more individuals within a shorter period of time. In this current review, information is ordered utilizing proposed Identification of Pattern Mining, Recurrent Neural Network strategies, and Regression procedures to help diagnose a patient with CKD. © 2023 American Institute of Physics Inc.. All rights reserved.",TextMining
"Self-regulated learning (SRL) plays a critical role in asynchronous online courses. In recent years, attention has been focused on identifying student subgroups with different patterns of online SRL behaviors and comparing their learning performance. However, there is limited research leveraging traces of SRL behaviors to detect student subgroups and examine the subgroup differences in cognitive load and student engagement. The current study tracked the engagement of 101 graduate students with SRL-enabling tools integrated into an asynchronous online course. According to the recorded SRL behaviors, this study identified two distinct student subgroups, using sequence analysis and cluster analysis: high SRL (H-SRL) and low SRL (L-SRL) groups. The H-SRL group showed lower extraneous cognitive load and higher learning performance, germane cognitive load, and cognitive engagement than the L-SRL group did. Additionally, this study articulated and compared temporal patterns of online SRL behaviors between the student subgroups combining lag sequential analysis and epistemic network analysis. The results revealed that both groups followed three phases of self-regulation but performed off-task behaviors. Additionally, the H-SRL group preferred activating mastery learning goals to improve ethical knowledge, whereas the L-SRL group preferred choosing performance-avoidance learning goals to pass the unit tests. The H-SRL group invested more in time management and notetaking, whereas the L-SRL group engaged more in surface learning approaches. This study offers researchers both theoretical and methodological insights. Additionally, our research findings help inform practitioners about how to design and deploy personalized SRL interventions in asynchronous online courses. Copyright © 2023 Sun, Liu, Lin and Hu.",TextMining
"Purpose: Studies on mining text and generating intelligence on human resource documents are rare. This research aims to use artificial intelligence and machine learning techniques to facilitate the employee selection process through latent semantic analysis (LSA), bidirectional encoder representations from transformers (BERT) and support vector machines (SVM). The research also compares the performance of different machine learning, text vectorization and sampling approaches on the human resource (HR) resume data. Design/methodology/approach: LSA and BERT are used to discover and understand the hidden patterns from a textual resume dataset, and SVM is applied to build the screening model and improve performance. Findings: Based on the results of this study, LSA and BERT are proved useful in retrieving critical topics, and SVM can optimize the prediction model performance with the help of cross-validation and variable selection strategies. Research limitations/implications: The technique and its empirical conclusions provide a practical, theoretical basis and reference for HR research. Practical implications: The novel methods proposed in the study can assist HR practitioners in designing and improving their existing recruitment process. The topic detection techniques used in the study provide HR practitioners insights to identify the skill set of a particular recruiting position. Originality/value: To the best of the authors’ knowledge, this research is the first study that uses LSA, BERT, SVM and other machine learning models in human resource management and resume classification. Compared with the existing machine learning-based resume screening system, the proposed system can provide more interpretable insights for HR professionals to understand the recommendation results through the topics extracted from the resumes. The findings of this study can also help organizations to find a better and effective approach for resume screening and evaluation. © 2022, Emerald Publishing Limited.",TextMining
"We propose, test and apply a methodology integrating 1D magnetotelluric (MT) and magnetic data inversion, with a focus on the characterisation of the cover-basement interface. It consists of a cooperative inversion workflow relying on standalone inversion codes. Probabilistic information about the presence of rock units is derived from MT and passed on to magnetic inversion through constraints combining structural constraints with petrophysical prior information. First, we perform the 1D probabilistic inversion of MT data for all sites and recover the respective probabilities of observing the cover-basement interface, which we interpolate to the rest of the study area. We then calculate the probabilities of observing the different rock units and partition the model into domains defined by combinations of rock units with non-zero probabilities. Third, we combine these domains with petrophysical information to apply spatially varying, disjoint interval bound constraints (DIBC) to least-squares magnetic data inversion using the alternating direction method of multipliers (or ADMM). We demonstrate the proof-of-concept using a realistic synthetic model reproducing features from the Mansfield area (Victoria, Australia) using a series of uncertainty indicators. We then apply the workflow to field data from the prospective mining region of Cloncurry (Queensland, Australia). Results indicate that our integration methodology efficiently leverages the complementarity between separate MT and magnetic data modelling approaches and can improve our capability to image the cover-basement interface. In the field application case, our findings also suggest that the proposed workflow may be useful to refine existing geological interpretations and to infer lateral variations within the basement.  © 2023 Jérémie Giraud et al.",TextMining
"Social media commerce rapidly grew during the world-changing of covid 19. The long duration of using social media provokes users to make purchases online through social media. TikTok - the most popular social media downloaded - provides their user a social media commerce experience, namely TikTokShop. The TikTok shop opened the window of opportunity for small business growth. Small business owners could maximize the potential use of TikTok shops by understanding more about TikTokShop. This research is concern to analyze the strengths and weaknesses of TikTok shop as a social media commerce platform by applying data mining. Opinion data is collected from Twitter and processed using the Naïve Bayes algorithm to test the sentiment of TikTok shop users. These positive and negative opinions are then classified and transformed with a SWOT analysis to find out the strengths and weaknesses of Tiktok Shop. This research contributes to analyzing the strengths and weaknesses of the social media commerce platform Tiktok Shop as a reference for users and platform developers. Users can see and position themselves using the platform to get optimal benefits. For platform developers, the results of this research contribute to providing insights for maximizing the features that meet the user’s expectations. © 2023 Little Lion Scientific.",TextMining
"We investigate distantly supervised relation extraction with knowledge-guided latent graphs and an iterative graph learner. For the relation extraction tasks, we assume that the input sentences contain latent graphs with useful structural information between mentions and relations of the distantly supervised data. We first embed input sentences with default initialized graphs to utilize this information. We also used the pre-trained Knowledge Bases (KB) to guide the latent space of a Variational Graph Auto-Encoders (VGAE) module. Then the VGAE applies the re-parameterization mechanism to reconstruct the initial graph, injecting extra knowledge into the initial latent graph and reducing its unsteadiness. Subsequently, we optimize the latent graph structures and their corresponding node embeddings simultaneously by the iterative graph learner, and the better latent graphs can improve the downstream relation extraction task. Experiment results on three datasets (NYT10, WIKIDISTANT and GIDS) show that latent graph learning helps our model perform better than previous works. © 2022 Elsevier B.V.",TextMining
"Through a data-mining and high-throughput density functional theory approach, we identify a diverse range of metallic compounds that are predicted to have transition metals with “free-atom-like” d states that are highly localized in terms of their energetic distribution. Design principles that favor the formation of localized d states are uncovered, among which we note that site isolation is often necessary but that the dilute limit, as in most single-atom alloys, is not a pre-requisite. Additionally, the majority of localized d state transition metals identified from the computational screening study exhibit partial anionic character due to charge transfer from neighboring metal species. Using CO as a representative probe molecule, we show that localized d states for Rh, Ir, Pd, and Pt tend to reduce the binding strength of CO compared to their pure elemental analogues, whereas this does not occur as consistently for the Cu binding sites. These trends are rationalized through the d-band model, which suggests that the significantly reduced d-band width results in an increased orthogonalization energy penalty upon CO chemisorption. With the multitude of inorganic solids that are predicted to have highly localized d states, the results of the screening study are likely to result in new avenues for heterogeneous catalyst design from an electronic structure perspective. © 2023 The Royal Society of Chemistry.",TextMining
"Oceans at a depth ranging from ~100 to ~1000-m (defined as the intermediate water here), though poorly understood compared to the sea surface, is a critical layer of the Earth system where many important oceanographic processes take place. Advances in ocean observation and computer technology have allowed ocean science to enter the era of big data (to be precise, big data for the surface layer, small data for the bottom layer, and the intermediate layer sits in between) and greatly promoted our understanding of near-surface ocean phenomena. During the past few decades, however, the intermediate ocean is also undergoing profound changes because of global warming, the research and prediction of which are of intensive concern. Due to the lack of three-dimensional ocean theories and field observations, how to remotely sense the intermediate ocean from space becomes a very attractive but challenging scientific issue. With the rapid development of the next generation of information technology, artificial intelligence (AI) has built a new bridge from data science to marine science (called Deep Blue AI, DBAI), which acts as a powerful weapon to extend the paradigm of modern oceanography in the era of the metaverse. This review first introduces the basic prior knowledge of water movement in the ~100 m ocean and vertical stratification within the ~1000-m depths as well as the data resources provided by satellite remote sensing, field observation, and model reanalysis for DBAI. Then, three universal DBAI methodologies, namely, associative statistical, physically informed, and mathematically driven neural networks, are elucidated in the context of intermediate ocean remote sensing. Finally, the unique advantages and potentials of DBAI in data mining and knowledge discovery are demonstrated in a top-down way of “surface-to-interior” via several typical examples in physical and biological oceanography. Copyright © 2023 Chen, Huang, Yang, Radenkovic, Ge, Cao, Chen, Xia, Han and Ma.",TextMining
"Amid the current climate emergency and global energy crisis, regulators have started to consider their options to limit the power demand of cryptocurrency networks. One specific way crypto-asset communities can limit their environmental impact is by avoiding or replacing the energy-intensive proof-of-work (PoW) mining mechanism. Ethereum, the second largest crypto-asset by market capitalization, had its PoW replaced with an alternative known as proof-of-stake during an event called The Merge on September 15, 2022. In this perspective, the likely range of electricity saved due to this change is estimated, while the limitations in assessing these figures are highlighted. Lastly, the challenges and opportunities in replicating The Merge on other cryptocurrencies such as Bitcoin are discussed. © 2022 The Author(s)",TextMining
"Background: Psoriasis is a chronic, inflammatory, autoimmune skin disease. The aim of this review is to systematically evaluate the efficacy and safety of integrative medicine (East Asian herbal medicine combined with conventional medicine) used to treat inflammatory skin lesions of psoriasis. Methods: A comprehensive literature search will be conducted in 3 English databases (PubMed, Cochrane Library, and Embase), 4 Korean databases (Korean Studies Information Service System, Research Information Service System, Oriental Medicine Advanced Searching Integrated System, and Korea Citation Index), 2 Chinese databases (Chinese National Knowledge Infrastructure Database and Wanfang data), and 1 Japanese database (Citation Information by National Institute of Informatics) for randomized controlled trials from their inception until July 29, 2021. Statistical analysis will be performed using R version 4.1.2 and the R studio program using the default settings of the ""meta""and ""metafor""packages. The primary outcome will be an improvement in the psoriasis area severity index. All outcomes will be analyzed using a random-effects model to produce more statistically conservative results. If heterogeneity is detected in the study, the cause will be identified through sensitivity, meta-regression, and subgroup analyses. Methodological quality will be assessed independently using the revised tool for the risk of bias in randomized trials, version 2.0. The overall quality of evidence will be evaluated according to the Grading of Recommendations Assessment, Development, and Evaluation pro framework. Results: This study will review all available trials on the same subject and arrive at a more statistically robust conclusion based on a sufficient sample size of participants and additional analysis using data mining techniques will be performed on intervention prescription information in clinical studies collected according to rigorous criteria. Conclusion: We believe that this study will provide useful knowledge on managing inflammatory skin lesions of psoriasis vulgaris using integrative medicine using East Asian herbal medicine.  © 2023 the Author(s). Published by Wolters Kluwer Health, Inc.",TextMining
"Static models, segmentation models and dynamic models for soft sensing of SO2 emission were developed based on the Ordinary Least Squares, Support Vector Regression, eXtreme Gradient Boosting, Random Forest and Neural Network algorithms with real operational data from a 1000 MW coal-fired power plant with ultra-low emission systems. The prediction results of test set show that static models are not suitable for modeling the desulfurization systems with complex condition and time-delay process. Thus, segmentation models and dynamic models were used to optimize the prediction accuracy. All the prediction performance of the nonlinear models was improved significantly with dynamic model, while the prediction performance of the linear model was improved with segmentation model. The dynamic Neural Network model with one hidden layer achieves the most accurate regression result (R2 = 70.4 %, RMSE = 1.95 mg/m3, MAE = 1.53 mg/m3). The results show the superiority of the dynamic Neural Network model over the other and the dynamic Support Vector Regression model perform second-best. © 2022 Elsevier Ltd",TextMining
"Purpose: It has always been a hot topic for online retailers to obtain consumers’ product evaluations from massive online reviews. In the process of online shopping, there is no face-to-face interaction between online retailers and customers. After collecting online reviews left by customers, online retailers are eager to acquire answers to some questions. For example, which product attributes will attract consumers? Or which step brings a better experience to consumers during the process of shopping? This paper aims to associate the latent Dirichlet allocation (LDA) model with the consumers’ attitude and provides a method to calculate the numerical measure of consumers’ product evaluation expressed in each word. Design/methodology/approach: First, all possible pairs of reviews are organized as a document to build the corpus. After that, latent topics of the traditional LDA model noted as the standard LDA model, are separated into shared and differential topics. Then, the authors associate the model with consumers’ attitudes toward each review which is distinguished as positive review and non-positive review. The product evaluation reflected in consumers’ binary attitude is expanded to each word that appeared in the corpus. Finally, a variational optimization is introduced to calculate parameters mentioned in the expanded LDA model. Findings: The experiment’s result illustrates that the LDA model in the research noted as an expanded LDA model, can successfully assign sufficient probability with words related to products attributes or consumers’ product evaluation. Compared with the standard LDA model, the expanded model intended to assign higher probability with words, which have a higher ranking within each topic. Besides, the expanded model also has higher precision on the prediction set, which shows that breaking down the topics into two categories fits better on the data set than the standard LDA model. The product evaluation of each word is calculated by the expanded model and depicted at the end of the experiment. Originality/value: This research provides a new method to calculate consumers’ product evaluation from reviews in the level of words. Words may be used to describe product attributes or consumers’ experiences in reviews. Assigning words with numerical measures can analyze consumers’ products evaluation quantitatively. Besides, words are labeled themselves, they can also be ranked if a numerical measure is given. Online retailers can benefit from the result for label choosing, advertising or product recommendation. © 2021, Emerald Publishing Limited.",TextMining
"Daily activity monitoring is essential to healthy lifestyle assessment and personal healthcare, among which Wi-Fi-based solutions have attracted increasing attention due to their no-intrusive and privacy-protected characters. However, related researches are based on the assumption that there is an interval between two activities, during which the target is thought to be static. This assumption falls short of reality as human activities are performed continuously in daily life. Therefore, this article aims to design a nonintrusive and privacy-protected system, namely, Wi-Monitor, to monitor human activities in daily life. In Wi-Monitor, we first fragmentize Wi-Fi channel state information (CSI) streams into CSI bins and design a feature extraction network to extract activity fragmentation features (AFFs) from these CSI bins. From the extracted AFFs, a temporal convolutional network (TCN) is further used to capture activity continuity features (ACFs), which are used as distinguishing characteristics of continuous activities. Finally, Wi-Monitor utilizes these distinguishing characteristics to segment and recognize human activities in daily life simultaneously to achieve daily activity monitoring. In addition, we design an over-segmentation suppression mechanism with two training stages in Wi-Monitor to overcome the over-segmentation issue and enhance the activity monitoring accuracy. Intensive experiments are conducted in three different scenarios and the results demonstrate the effectiveness and practicality of Wi-Monitor for daily activity monitoring.  © 2014 IEEE.",TextMining
"Redescription mining aims at finding subsets of instances that can be re-described, characterized in multiple ways, using one or more disjoint sets of attributes that describe some set of instances. Current redescription mining algorithms either work with tabular data or with relational data — where binary relations between objects are used which allow representing descriptions as graphs. In this work, we propose novel type of redescription mining methodology that allows using tabular data in combination with background network information, where nodes of a network are instances in the tabular data. Background information is used to locate subsets of instances with some desired network property whereas tabular data are used to re-describe such interesting subsets. Methodology can be classified as constraint-based redescription mining, where we allow for a large variety of complex network-based soft constraints. The proposed framework is extensible, thus any network-related measure can be used to localize subsets of instances of interest. In addition, different types of network such as undirected, directed graphs, graph sequences or multiplex can be used as a background information. We demonstrate the applicability of the proposed framework on three use-case datasets involving country trade networks, biological (gene spatial) networks and social networks. The experimental evaluation demonstrates that the proposed approach outperforms existing, general redescription mining approaches with respect to intensity of network properties of the re-described instances without loss of accuracy, mostly even improving redescription accuracy. © 2022 The Author(s)",TextMining
"The existing meta-heuristic distribution network reconfiguration (DNR) algorithm has excellent optimization ability through iteration. However, it is difficult to realize the large-scale fast calculation and online real-time response of DNR solution. In order to improve the security and low-carbon economy of distribution network, this paper proposes a fast reconfiguration method of distribution network based on convolutional neural network (CNN). Taking IEEE 33 system and 185 node system as examples, the effectiveness of the proposed method is verified. The reasons why the proposed method can achieve better results are as follows: By mining the historical data of distribution network, the corresponding relationship between load mode (LM) and its optimal topology is established. For a load mode in actual operation, the reconfiguration scheme can be quickly obtained according to the established corresponding relationship. Thus, iterative calculation is avoided and computational efficiency is improved. A multi-branch CNN model is established based on the distribution network structure, and an inception module is introduced into CNN to improve the ability of CNN to extract data features. This model can reduce the dependence on the specific distribution network structure and is easy to expand. Copyright © 2023 Yu, Yang, Zhang, Ye, Ji and Li.",TextMining
"The Internet of Things (IoT) aims to enable a scenario where smart objects, inserted into information networks, supply smart services for human beings. The introduction of edge computing in IoT can reduce the decision-making latency, save bandwidth resources, and expand the cloud services to be allocated at the network's edge. However, edge-based IoT systems currently face challenges in their decentralized trust management. Trust management is essential to obtain reliable mining and data fusion, improved user privacy and data security, and provisioning of services with context-awareness. In this survey, we first examine the edge-based IoT architectures currently reported in the literature. Then a complete review of trust requirements in edge-based IoT systems is produced. Also, we discuss about blockchain as a solution to solve several trust problems in IoT and analyze in detail the correlation between blockchain and edge computing. Finally, we provide a detailed analysis of performance aspects of trusted edge-based IoT systems and recommend promising research directions.  © 2023 Association for Computing Machinery.",TextMining
"Medicago polymorpha L. (bur clover), an invasive plant species of the genus Medicago, has been traditionally used in China as an edible vegetable crop because of its high nutritive value. However, few molecular markers for M. polymorpha have been identified. Using the recently published high-quality reference genome of M. polymorpha, we performed a specific-locus amplified fragment sequencing (SLAF-seq) analysis of 10 M. polymorpha accessions to identify molecular markers and explore genetic diversity. A total of 52,237 high-quality single nucleotide polymorphisms (SNPs) were developed. These SNPs were mostly distributed on pseudochromosome 3, least distributed on pseudochromosome 7, and relatively evenly distributed on five other pseudochromosomes of M. polymorpha. Phenotypic analysis showed that there was a great difference in phenotypic traits among different M. polymorpha accessions. Moreover, clustering all M. polymorpha accessions based on their phenotypic traits revealed three groups. Both phylogenetic analysis and principal component analysis (PCA) of all M. polymorpha accessions based on SNP markers consistently indicated that all M. polymorpha accessions could be divided into three distinct groups (I, II, and III). Subsequent genetic diversity analysis for the 10 M. polymorpha accessions validated the effectiveness of the M. polymorpha germplasm molecular markers in China. Additionally, SSR mining analysis was also performed to identify polymorphic SSR motifs, which could provide valuable candidate markers for the further breeding of M. polymorpha. Since M. polymorpha genetics have not been actively studied, the molecular markers generated from our research will be useful for further research on M. polymorpha resource utilization and marker-assisted breeding. Copyright 2023 Ren et al.",TextMining
"Due to the diversity of contexts in which biological computation is performed, a major problem is the selection of functional-oriented techniques for the analysis of biological sequences in a huge environment. The performances of various sequences in biocomputational algorithms are evaluated with variant features to prove their efficiency in real-time environments. Structural and Functional Aspects of Biocomputing Systems for Data Processing provides insight into the structural and functional aspects of biological sequences and the pattern recognition they embed into the data processingcepts, methodologies, and empirical research advances of various biological data mining systems through machine learning approaches. Covering topics such as DNA sequencing, high-speed architecture, and medical image processing, this premier reference source is an essential resource for healthcare professionals, biological systems in biocomputing systems. It extends recent con specialists, industrial professionals, PCR testing professionals, scientists, bioinformaticians, students and educators of higher education, librarians, researchers, and academicians. © 2023 by IGI Global. All rights reserved.",TextMining
"Background: Patients with diabetic kidney disease (DKD) often have gastrointestinal dysfunction such as inflammatory bowel disease (IBD). This study aims to investigate the genetic mechanism leading to IBD in DKD patients through data mining and bioinformatics analysis. Methods: The disease-related genes of DKD and IBD were searched from the five databases of OMIM, GeneCards, PharmGkb, TTD, and DrugBank, and the intersection part of the two diseases were taken to obtain the risk genes of DKD complicated with IBD. A protein–protein interaction (PPI) network analysis was performed on risk genes, and three topological parameters of degree, betweenness, and closeness of nodes in the network were used to identify key risk genes. Finally, Gene Ontology (GO) analysis and Kyoto Encyclopedia of Genes and Genomes (KEGG) analysis were performed on the risk genes to explore the related mechanism of DKD merging IBD. Results: This study identified 495 risk genes for DKD complicated with IBD. After constructing a protein–protein interaction network and screening for three times, six key risk genes were obtained, including matrix metalloproteinase 2 (MMP2), hepatocyte growth factor (HGF), fibroblast growth factor 2 (FGF2), interleukin (IL)-18, IL-13, and C–C motif chemokine ligand 5 (CCL5). Based on GO enrichment analysis, we found that DKD genes complicated with IBD were associated with 3,646 biological processes such as inflammatory response regulation, 121 cellular components such as cytoplasmic vesicles, and 276 molecular functions such as G-protein-coupled receptor binding. Based on KEGG enrichment analysis, we found that the risk genes of DKD combined with IBD were associated with 181 pathways, such as the PI3K-Akt signaling pathway, advanced glycation end product–receptor for AGE (AGE-RAGE) signaling pathway and hypoxia-inducible factor (HIF)-1 signaling pathway. Conclusion: There is a genetic mechanism for the complication of IBD in patients with CKD. Oxidative stress, chronic inflammatory response, and immune dysfunction were possible mechanisms for DKD complicated with IBD. Copyright © 2023 Zhang, Xiao, Fu, Yu, Cheng and Jiang.",TextMining
"Maritime traffic route extraction is essential for analyzing dynamic ship navigational information in vast sea areas. However, maritime traffic route extraction is still challenging due to the high frequency and freedom of ship navigation. Thus, our study proposes a maritime traffic route extraction method based on automatic identification system (AIS) data and the multi-dimensional density-based spatial clustering of applications with noise (MD-DBSCAN) data. In the first part of the method, the Douglas–Peucker (DP) algorithm is used to compress massive ship trajectories, and a new indicator (the average compression score (ACS)) is used to determine the optimal compression threshold. In the second part, with the measure of similarity between ship trajectories by two similarity measure indicators, including the spatial distance and the difference of the course over ground (COG) of the key turning points of the ship trajectories, the ship trajectories are clustered by the MD-DBSCAN algorithm. In the third part, the centerlines of each cluster are extracted with the triangular network center method. Numerical experiments are conducted based on massive AIS data in the South China Sea. The experimental results show that our method dramatically influences the recognition of noise and normal trajectories and can effectively extract maritime traffic routes. © 2022 Elsevier Ltd",TextMining
"Papers and patents can respectively present the latest progress of scientific research and technological development. Combining the two for correlation analysis has certain reference significance for technology opportunity discovery. Therefore, this paper proposes a method for technology opportunity discovery of proton exchange membrane fuel cell from the perspective of papers-patents correlation analysis. Firstly, papers and patent data are collected from papers and patent databases and the LDA model is applied to extract paper and patent topics. Secondly, the indicators of topic heat and novelty are calculated to select high-value paper topics. After that, the similarity analysis between high-value paper topics and all patent topics is considered to select the patent topics with development potential. Finally, the patent texts with high relevance to these patent topics with development potential are positioned. The technical keywords in them are extracted by text mining tool and classified into innovation dimensions according to their attributes and the TEMPEST model. After that, the innovation rules in the SCAMPER model are introduced to combine with the technical keywords in each innovation dimension to identify specific technology opportunities. An empirical study on the technology of proton exchange membrane fuel cell provides sufficient evidence of the method’s ability to discover technology opportunities. This paper contributes by generating four specific technology opportunities, which can make up for the existing defects of proton exchange membrane fuel cells and provide useful guidance for companies to carry out technological innovation. Copyright © 2023 Feng, Liu, Wang, Lin, Zhang and Zhang.",TextMining
"Purpose: This study aimed to present the methodology of the text data analysis to establish marketing strategies for fintech companies in a practical way. Specifically, the methodology was presented to convert customers' review data, which consisted of the text data (unstructured data), to the numerical data (structured data) by using a text mining algorithm “Global Vectors for Word Representation,” abbreviated as “GloVe”; additionally, the authors presented the methodology to deploy the numerical data for marketing strategies with eliminate-reduce-raise-create (ERRC) value factor analytics. Design/methodology/approach: First, the authors defined the background, features and contents of fintech services based on a review of related literature review. Additionally, they examined business strategies, the importance of social media for fintech services and fintech technology trends based on the literature review. Next, they analyzed the similarity between fintech-related keywords, which represent the trends in fintech services, and the text data related to fintech corporations and their services posted on Facebook and Twitter, which are two of the most popular social media globally, during the period 2017–2019. The similarity was then quantified and categorized in terms of the representative global fintech companies and the status of each fintech service sector. Furthermore, the similarity was visualized, and value elements were rebuilt using ERRC strategy analytics. Findings: This study is meaningful in that it quantifies the degree of similarity between customers' responses, experiences and expectations regarding the rapidly growing global fintech firms' services and trends in fintech services. Originality/value: This study suggests a practical way to apply in business by providing a method for transforming unstructured text data into structured numerical data it is measurable. It is expected that this study can be used as the basis for exploring sustainable development strategies for the fintech industry. © 2022, Emerald Publishing Limited.",TextMining
"After entering the 21st century, various fields knew significant transformation, like medicine, engineering, etc., due to the fast advancement of artificial intelligence (AI) and the arrival of the big data era. The application of AI techniques in marketing became necessary to improve the marketing strategy for guaranteeing a company's long-term growth. Based on recorded data and appropriate training, artificial intelligence can forecast consumer preferences and make recommendations to accomplish precision marketing. Precision marketing based on AI techniques can provide personalized communication between customers and companies, attract prospective clients, build targeted marketing recommendations for high-value clients, and reduces marketing costs. Therefore, this paper presents a survey on the current trends of AI applications in precision marketing. This survey will introduce and review the artificial intelligence approaches applied to precision marketing in the literature, which can be divided into three categories: ma-chine learning, data mining, and recommendation systems. In this study, we have studied and applied a meta-analysis to pick up the more used methods. Consequently, we find that RF, SVM, and NN, for machine learning, K-means, Naïve Bayes, and CHAID Decision Tree for data mining, and collaborative filtering for recommendation systems provide better results in the literature. This article aims to review these methods based on their algorithms and strategies and discuss their strengths and weaknesses. This study provides a reference for searchers in this domain.  © 2023 IEEE.",TextMining
"The existence of various financial statement scandals has made users of financial statements doubt the quality of the audit and demand auditor to provide an audit with better audit quality. Currently, the level of difficulty to meet these demands is becoming higher as the client's business becomes more complex. Information and data provided by clients are also increasingly diverse, including various kinds of electronic information and data. Thus, currently auditors must use a data-driven approach. Therefore, based on this phenomenon, we as researchers want to examine the effect of data processing technology on audit quality. We gathered primary data from external auditors through questionnaire to obtain empirical data that can verify our research model. As the results, we found that data mining and data visualization significantly affect big data analytics. While data mining, big data analytics, and data visualization do not significantly affect audit quality. These results are based on our sample which is external auditors in Indonesia. This research can be used as a reference for further study development. Future researchers can also conduct the same research in developed country.  © 2023 ACM.",TextMining
"Purpose: This study aims to examine the socio-economic and environmental impacts of mining activities as perceived by communities in Ghana, with data being drawn from primary and secondary sources. Design/methodology/approach: A total of 90 community residents were interviewed, with 15 from each of the six selected different communities. Findings: The findings revealed a positive perception that corporate social responsibility (CSR) practices of mining companies contribute to the development of mining communities in Ghana by creating jobs and generating income. However, it became clear that mining activities, particularly small-scale mining, create many social and environmental challenges as well. This includes land degradation, which reduces the fertility of community-owned land suitable for agricultural use. In addition, pollution of waterways and streams intensifies the plight of community residents living in mining areas. Originality/value: Since 2011, the mining industry has invested between US$12m (in 2013) and US$44m (in 2011) in Ghana’s communities. The amount spent in 2019 was US$24m. The funds were spent by the industry in areas such as roads, education, health and electricity, among others. Still, it seems more effort is needed by the mining companies to harmonise the CSR practice and gain better impression by local people. In spite of the mining industry’s investment levels, more than half of the community respondents said it was insufficient. One-third of the respondents went as far as suggesting the mining companies had a negative impact on infrastructure improvement and community development. © 2022, Emerald Publishing Limited.",TextMining
"Breast Cancer is the uncontrollable growth of cells by abnormal activities of genes. 2 in 10 women in world will be identified with breast cancer in her lifetime. On average, every 5 minutes a woman is identified with breast cancer in the world. So, there is a huge need for intelligent early prediction methods to support a health care peoples for increasing the survival rate of the patients. Recently, data mining approach of Deep Learning (DL) and machine learning (ML) contributes beneficial role in medical field for detection and classifications of diseases. The accuracy of prediction is reduced due to the imbalanced nature of data with unequal distribution of the positive and negative classes. To overcome this issue, the breast cancer prediction is presented by using a Hybrid algorithm such as Linear Discriminant Analysis (LDA), Wild Horse Optimization (WHO) and Advanced Elman Recurrent Neural Network (AERNN) methods in this work. A LDA model is used to remove a features, WHO model is used for feature reduction and tuning a AERNN’s hyper parameters and Optimized AERNN model for classifications. The proposed method has outperformed by achieving a result of Precision (98.51%), Recall (98.65%), Accuracy (97.88%) and F1 score (98.32%) and also in the performances of error evaluation of RMSE (1.006) and MAE (1.986) than the prior methods respectively. © Ismail Saritas. All rights reserved.",TextMining
"With the development of remote sensing technology, significant progress has been made in the evaluation of the eco-environment. The remote sensing ecological index (RSEI) is one of the most widely used indices for the comprehensive evaluation of eco-environmental quality. This index is entirely based on remote sensing data and can monitor eco-environmental aspects quickly for a large area. However, the use of RSEI has some limitations. For example, its application is generally not uniform, the obtained results are stochastic in nature, and its calculation process cannot consider all ecological elements (especially the water element). In spite of the widespread application of the RSEI, improvements to its limitations are scarce. In this paper, we propose a new index named the remote sensing ecological index considering full elements (RSEIFE). The proposed RSEIFE is compared with commonly used evaluation models such as RSEI and RSEILA (Remote Sensing Ecological Index with Local Adaptability) in several types of study areas to assess the stability and accuracy of our model. The results show that the calculation process of RSEIFE is more stable than those of RSEI and RSEILA, and the results of RSEIFE are consistent with the real eco-environment surface and reveal more details about its features. Meanwhile, compared with RSEI and RSEILA, the results of RSEIFE effectively reveal the ecological benefits of both water bodies themselves and their surrounding environments, which lead to more accurate and comprehensive basis for the implementation of environmental protection policies. © 2022 Elsevier Ltd",TextMining
"Redescription mining is an important data mining task with the main goals of discovering subsets of instances that can be characterized in multiple ways and constructing the appropriate characterizations. Such characterizations, presented in a form of tuples of logical formulae, are understandable to the domain experts and offer unique insights in different interactions between relevant, presented attributes. In this work, we analyse variants of this task where the input data consists of one or more views – disjoint sets of attributes. The goal of this work is to formally define decision variants of redescription mining tasks with several sets of constraints and to provide corresponding proofs that the decision variants of these tasks are NP-complete. Proofs are realized by reductions from well known decision variants of CLIQUE and Set cover NP-complete problems. We also show that the enumeration variant of the task is NP-hard. © 2022 Elsevier B.V.",TextMining
"Introduction: USA300 has remained the dominant community and healthcare associated methicillin-resistant Staphylococcus aureus (MRSA) clone in the United States and in northern South America for at least the past 20 years. In this time, it has experienced epidemic spread in both of these locations. However, its pre-epidemic evolutionary history and origins are incompletely understood. Large sequencing databases, such as NCBI, PATRIC, and Staphopia, contain clues to the early evolution of USA300 in the form of sequenced genomes of USA300 isolates that are representative of lineages that diverged prior to the establishment of the South American epidemic (SAE) clade and North American epidemic (NAE) clade. In addition, historical isolates collected prior to the emergence of epidemics can help reconstruct early events in the history of this lineage. Methods: Here, we take advantage of the accrued, publicly available data, as well as two newly sequenced pre-epidemic historical isolates from 1996, and a very early diverging ACME-negative NAE genome, to understand the pre-epidemic evolution of USA300. We use database mining techniques to emphasize genomes similar to pre-epidemic isolates, with the goal of reconstructing the early molecular evolution of the USA300 lineage. Results: Phylogenetic analysis with these genomes confirms that the NAE and SAE USA300 lineages diverged from a most recent common ancestor around 1970 with high confidence, and it also pinpoints the independent acquisition events of the of the ACME and COMER loci with greater precision than in previous studies. We provide evidence for a North American origin of the USA300 lineage and identify multiple introductions of USA300 into South and North America. Notably, we describe a third major USA300 clade (the pre-epidemic branching clade; PEB1) consisting of both MSSA and MRSA isolates circulating around the world that diverged from the USA300 lineage prior to the establishment of the South and North American epidemics. We present a detailed analysis of specific sequence characteristics of each of the major clades, and present diagnostic positions that can be used to classify new genomes. Copyright © 2023 Bianco, Moustafa, O’Brien, Martin, Read, Kreiswirth and Planet.",TextMining
"In the context of national archaeological park construction, tourists' cultural perception has an important impact on the formation of local identity. It is an important factor in the protection and development of the National Archaeological Site Park. The purpose of this paper is to understand the attitudes of visitors to the National Archaeological Site Park, and to analyze their cultural perception of archaeological site park. This paper uses network text mining method to explore cultural perception. The author took public comments on Ctrip as sample data, then, obtained high-frequency words through ROST Content Mining software, conducted network semantic and sentiment analysis. Through the discussion of the cultural perception and experience of tourists in National Archaeological Site Park, the author concluded that: 1. Tourists' cultural perception of National Archaeological Site Park includes overall experience perception, cultural content perception and cultural form perception; 2. The cultural content of the National Archaeological Site Park shows a three-level structure of 'core, transition, edge'; 3. Tourists show certain preferences in the content, form and means of experience in the archaeological site park. On this basis, the author proposed suggestions to improve visitor experience of archaeological site parks based on cultural perception.  © 2023 The authors and IOS Press.",TextMining
"Optimizing Building energy consumption is a key solution to reducing their environmental impact. In this context, Information Technology can be harnessed by deploying sensors inside buildings, to collect relevant data about both energy consumed and occupant behavior, since occupants influence building appliances, such as HVAC, lights, and hot water tanks. Predicting room occupancy can be a solution to heat/cool rooms for instance. But, as prediction models are not often accurate, we may face situations where HVAC is activated while the rooms are empty or vice-versa, leading to either a waste of energy or a lack of occupants’ comfort. To predict user behavior, detect prediction errors, and correct the model, we introduce a graph mining-based optimization method that combines an occupant behavior prediction model and a selective reinforcement learning method, where error detection relies on sensors that detect real-time occupancy of rooms. We experimented with our approach on simulated data and results showed that, compared to conventional HVAC management, our model can reduce up to 57.8% of HVAC energy consumption, and provide up to 94.3% of occupants’ comfort when using the prediction method only, and up to 80.1% of HVAC energy consumption, and provide up to 97% of occupants’ comfort when using the reinforcement method to correct prediction errors. © 2022 Elsevier Ltd",TextMining
"It is significant to detect, estimate and predict 'Human-health situations' and 'a spread of transmitted disease' with past and current information of health-related phenomena. Temporal-Transition and differential computing realizes semantic interpretations for situation changes in two phenomena with 'temporal-length' in 'specific situation'. The 'temporal-length' in 'specific situation' is used to compare two phenomena in multiple contexts in semantics. We present a new Temporal-Transition Differential Computing Model for detecting, estimating and predicting 'Human-health situations' and 'a spread of transmitted disease.' This model defines 'temporal-Transition data structure' for expressing past and current information of health-related phenomena with temporal-Axis, and two processes for Human-Health Semantic Space Creation and Semantic Computing with dimensional control mechanism. © 2023 The authors and IOS Press.",TextMining
"Objective Cardiac therapy drugs are widely used in the treatment of heart disease. However, the concern regarding adverse events (AEs) of cardiac therapy drugs have been rising. This study aimed to analyse cardiac therapy drug-related AEs using the Jinan adverse event reporting system (JAERS) database mining and conduct a comprehensive evaluation to provide safe medication information for patients. Design Retrospective observational study. Setting In this study, cardiac therapy drug-related AEs were detected using the JAERS database from January 2000 to March 2022. Methods Reports of cardiac therapy drug-related AEs were extracted from JAERS database, and the basic information of patients, reports and common AEs were analysed. Four disproportionality analysis methods, proportional reporting ratio (PRR), reporting odds ratio (ROR), Bayesian Confidence Propagation Neural Network (BCPNN), Medicines and Healthcare products Regulatory Agency (MHRA), were used to detect cardiac therapy drug-related signals. We further checked whether the detected signals exist on drug labels in China and two developed countries, the USA and Japan. Results In total, 168 314 AEs were reported, of which 4788 were associated with cardiac therapy drugs. Using the PRR, ROR, MHRA and BCPNN method, we detected 52 signals, 52 signals, 33 signals and 43 signals, respectively. Among the 52 signals, 14 were not included on the drug labels of China. One (isosorbide mononitrate-head bilges) was not included on the drug labels of the three countries. Conclusion We identified 14 new cardiac therapy drug signals that did not appear on drug labels in China and 1 new signal that did not appear on drug labels in 3 counties. A causal link between cardiac therapy drugs and AEs should be evaluated in further studies.  © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.",TextMining
"In recent years, with the development of new energy technology and the country’s strong support for electric vehicles, there is a lack of effective electric vehicle charging fault analysis and diagnosis methods at this stage. A comprehensive analysis of the working principle of the charging process of electric vehicles, based on the clarification of the failure mechanism of the power battery and charging equipment, analyzes the fault-related factors affecting the power battery and charging equipment from multiple angles, and summarizes the relationship between the power battery and charging equipment. The feature parameters related to equipment failure are discretized by the k-means clustering algorithm. Using the optimized FP-Growth algorithm based on weights, the association rules between the power battery and charging equipment failures and the characteristic parameters of the failure factors are mined, and the correlation of the failures is analyzed based on the association rules, and the correlation between the failure factors and the failures is obtained relevant level. Copyright © 2023 Zhu, Hu, He, Chi and Xu.",TextMining
"Person re-identification (ReID) aims to associate the same person across non-overlapping cameras. However, most of existing works neglect the issue of camera-imbalanced data distribution. Consequently, pedestrian representation learning gives preference to the head cameras, which have comparatively more training data, and disregards the tail cameras, which have relatively less training data. In this paper, we propose a novel framework for camera-aware representation learning to overcome this issue, named CARL. On the proxy level representation learning, CARL presents a multiple-center softmax loss to correct the head camera bias and presents a hard sub-center mining strategy to improve the discrimination of tail camera samples. On the pair-wise level representation learning, CARL builds a camera-balanced memory bank (CBM) to re-balance the sample pair distribution and proposes a camera-paired loss for pair-wise metric learning. Extensive experiments and ablation studies on MSMT17, the current largest ReID dataset with massive camera-imbalanced data distribution, demonstrate that our CARL is superior to previous metric learning based ReID methods and achieves state-of-the-art performance. © 2022 Elsevier B.V.",TextMining
"Over the past decade, enterprises have broadly adopted data warehousing in various activities. Today, abundant information is available on websites in the form of tables or spreadsheets. This huge amount of data cannot be processed directly because of its complexity, heterogeneity, and gap between user requirements. In this work, an automatic approach is proposed to build the multi-dimensional structure (MDS) of heterogeneous tabular data format for intelligent decision-making. The proposed MDS is generated by identifying components such as dimensions and hierarchies. It automatically extracts measures based on the spatial characteristics of data dimensions like region, time as well as their hierarchies. This proposed approach automatically generates a multi-dimensional model for BI tools without complicated ETL (Extraction, Transformation and Loading) process and helps to solve several business queries, like “Top 5 states in India based on Irrigated area in 2009”. Moreover, the proposed method reduces the time and cost of building multi-dimensional models to a very large extent. The correctness of proposed method is tested with the synthetic and economic datasets of Government websites where information is stored in tabular formats and various heterogeneous setups where the proposed method saved approximately 4000 to 5000 computing hours of the ETL process. © 2022 John Wiley & Sons, Ltd.",TextMining
"In this paper, taking the shale of Chang 7-Chang 9 oil formation in Yanchang Formation in the southeastern Ordos Basin as an example, through the study of shale heterogeneity characteristics, starting from the preprocessing of supervision data set, a logging interpretation method of total organic carbon content (TOC) on the lithofacies-based Categorical regression model (LBCRM) is proposed. It is show that: 1) Based on core observation, and Differences of sedimentation and structure, five lithofacies developed in the Yanchang Formation: shale shale facies, siltstone/ultrafine sandstone facies, tuff facies, argillaceous shale facies with silty lamina and argillaceous shale facies with tuff lamina. 2) The strong heterogeneity of shale makes it difficult to accurately explain the TOC distribution of shale intervals in the application of model-based interpretation methods. The LBCRM interpretation method based on the understanding of shale heterogeneity can effectively reduce the influence of formation factors other than TOC on the prediction accuracy by studying the characteristics of shale heterogeneity and constructing a TOC interpretation model for each lithofacies category. At the same time, the degree of unbalanced distribution of data is reduced, so that the data mining algorithm achieves better prediction effect. 3) The interpretability of lithofacies logging ensures the wellsite application based on the classification and regression model of lithofacies. Compared with the traditional homogeneous regression model, the prediction performance has been greatly improved, TOC segment prediction is more accurate. 4) The LBCRM method based on shale heterogeneity can better understand the reasons for the deviation of the traditional model-based interpretation method. After being combined with the latter, it can make logging data provide more useful information. Copyright © 2023 Yin, Gao, Cheng, Liang, Xue, Hao and Zhao.",TextMining
"Parasitic diseases caused by kinetoplastid parasites are a burden to public health through-out tropical and subtropical regions of the world. TriTrypDB (https://tritrypdb.org) is a free online resource for data mining of genomic and functional data from these kinetoplastid parasites and is part of the VEuPathDB Bioinformatics Resource Center (https://veupathdb. org). As of release 59, TriTrypDB hosts 83 kinetoplastid genomes, nine of which, including Trypanosoma brucei brucei TREU927, Trypanosoma cruzi CL Brener and Leishmania major Friedlin, undergo manual curation by integrating information from scientific publications, high-throughput assays and user submitted comments. TriTrypDB also integrates transcriptomic, proteomic, epigenomic, population-level and isolate data, functional information from genome-wide RNAi knock-down and fluorescent tagging, and results from automated bioinformatics analysis pipelines. TriTrypDB offers a user-friendly web interface embedded with a genome browser, search strategy system and bioinformatics tools to support custom in silico experiments that leverage integrated data. A Galaxy workspace enables users to analyze their private data (e.g., RNA-sequencing, variant calling, etc.) and explore their results privately in the context of publicly available information in the database. The recent addition of an annotation platform based on Apollo enables users to provide both functional and structural changes that will appear as ‘community annotations’ immediately and, pending curatorial review, will be integrated into the official genome annotation. © 2023 Shanmugasundram et al.",TextMining
"For imbalanced classification, data-level methods can achieve inter-class balance, but the samples generated do not contain new information and cannot avoid the problem of introducing noise. Algorithm-level methods may lead to overfitting of the model, and its classification effect is more dependent on the specific dataset and classification task, which means they lack universality. In addition, how to deeply mine the differences in the distribution of data overlap areas, and how to effectively mine the differences between categories when the absolute number of minority samples is small, are also important challenges in imbalanced classification. This paper proposes an imbalanced binary classification method using multi-label confidence comparisons based on contrastive learning. Different from the previous idea of directly learning its distribution characteristics from minority samples, combined with the idea of contrastive learning, the classification task is redefined as the multi-label matching task by mining the deep features that can represent the commonality and difference between the neighboring samples. Multiple differentiated contrastive sample groups are obtained through random sampling in its neighbor sample pool for each sample. This sample is combined with its contrastive sample groups to form multiple sample-neighbor pairs as training samples in the multi-label matching task. The original dataset is multiplied without introducing noise, laying a foundation for the effective mining of class differences when the absolute number of minority class samples is small. Based on the corresponding reconstruction error generated by Variational AutoEncoder (VAE), for sample-neighbor pairs, a multi-label matching loss between target samples and contrastive sample groups that integrates the idea of contrastive learning is designed. a robust classifier is obtained through simultaneous iterative learning of reconstruction error and multi-label matching loss, which can better mine the distribution differences of overlapping regions. In the testing phase, multiple different contrastive sample groups and the corresponding prediction results of the samples to be classified are obtained, which categories can be judged by integrating the predictions of each group for reverse reasoning. Experimental results on 38 public datasets show that the method outperforms typical imbalanced classification methods in both F1-measure and G-mean. © 2022 Elsevier B.V.",TextMining
"Electricity theft becomes a major concern for utilities in this new era of high tech, self-sufficient dwellings. Finding and reducing energy losses or theft has proven challenging due to insufficient inspection methods. In terms of energy, both technical and non-technical losses (NTL) are included in distribution. Energy theft is a significant factor in NTL that can strain the finances of service providers. Wireless data transmission is used in modern smart metres. It follows that hi-tech dwellings can be easily hacked to steal power. Many new technologies have been implemented into Advance Metering Infrastructure (AMI) to combat energy theft. It is necessary to derive the consumption pattern in order to identify illegal energy customers. Using data mining methods, a computational system is designed for examining and identifying energy consumption patterns. Through the use of machine learning, we are able to improve our customers' energy consumption statistics and provide them with early warning of any irregularities. Multiple supervised learning techniques are examined and contrasted in relation to their predictive accuracy, recall, precision, AUC as well as F1 score. These include the decision tree (DT), ANN, Deep ANN, Modified ANN and AdaBoost. Based on the results of the study, MDANN is superior to alternative classifiers for supervised learning including ANN AdaBoost as well as DT according to recall, F1 Score along with AUC. The upcoming research should focus on testing different supervised learning algorithms using various datasets and including appropriate pre-processing procedures to boost performance. © Ismail Saritas. All rights reserved.",TextMining
"In natural scene classification, it is common that one natural scene image may belong to multiple categories concurrently; as a result, multi-label learning has become a research hotspot. Despite recent rapid developments in multi-label learning, the increasing amount of high-dimensional data poses great challenges—such as redundant features and high computational costs—to conventional multi-label learning models. Most contemporary strategies for dealing with this issue depend on forcing feature learning into multi-label models. Notably, however, these approaches seldom pay attention to the label correlation and propagation in the feature subspace. To address this issue, we introduce an alternative multi-label feature learning solution that incorporates both labeled and unlabeled information. Unlike existing multi-label learning models, which rely on clean and trustworthy training datasets, we argue that in semi-supervised learning scenarios, the unlabeled data can be easily corrupted by noise or outliers, which causes the model performance to degrade. We next extract the label correlation and propagate the label information to discover the noise or outliers. Subsequently, our model adaptively searches the optimal feature subspace to reduce the influence of redundant features for high-dimensional data. The effectiveness of the proposed model is demonstrated by experimental observations on artificial and real-world datasets. © 2022 Elsevier B.V.",TextMining
"目的：运用数据挖掘技术探析针灸治疗变应性鼻炎(AR)的选穴规律并对比不同取穴方式的疗效。方法：检索近20年针灸治疗AR的相关文献，根据纳入、排除标准筛选文献并建立AR数据库。分别统计高频腧穴与特定穴信息，对比不同取穴方式的疗效，应用SPSS26.0软件进行因子分析、聚类分析及QUEST决策树模型识别。结果：共纳入289篇文献，收录384条针灸处方。涉及腧穴99个，总频次为2 430次，迎香、印堂与合谷为频次排前3位的腧穴。经脉以足太阳膀胱经、手阳明大肠经和督脉为主，交会穴是应用频次最高的特定穴。单穴、局部选穴及循经配伍治疗AR总有效率均较高，迎香是最主要的单穴处方。因子分析提取出9个腧穴配伍单元公因子，聚类分析得到2类腧穴配伍关联聚类处方，以迎香为因变量的决策树模拟出3条精简选穴决策路径。结论：针灸治疗AR以局部选穴与循经配伍为主，注重祛邪和扶正相结合的选穴原则，并提倡配穴方式的多样化，因子分析、聚类分析与QUEST决策树的联合应用为AR的临床选穴提供了3种方向, 助力转化医学的枢纽作用。.; OBJECTIVE: To explore the rules of acupoints selection of acupuncture and moxibustion in the treatment of allergic rhinitis (AR) by using data mining technology, as well as to compare the efficacy of different acupoints selection methods. METHODS: Papers about acupuncture and moxibustion for treating AR published from January 2002 to August 2022 was retrieved from Chinese and English databases including CNKI, Wanfang, VIP, SinoMed and PubMed by using keywords of ""acupuncture"", ""moxibustion"" and ""allergic rhinitis"". According to the inclusion and exclusion criteria, the collected literature was screened to establish the AR database. Frequency statistic analysis was conducted for detecting high-frequency acupoints and specific acupoints frequency, and the curative effects of different acupoints selection methods were compared. SPSS26.0 software was used for factor analysis, cluster analysis and QUEST decision tree model identification. RESULTS: A total of 289 papers were included, with 384 acupuncture prescriptions extracted. A total of 99 acupoints were involved with the application frequency of 2 430 times. Among them, the application frequency of Yingxiang (LI20) is the highest (296 times, 12.18%), followed by Yintang (GV24+) and Hegu (LI4), etc. The main invloved meridians are the Bladder Meridian of Foot-Taiyang, the Large Intestine Meridian of Hand-Yangming and the Governor Vessel. The involved specific acupoints with the highest frequency of application is the crossing acupoints. Nine common factors of acupoints combinations units were extracted by factor analysis, and two cluster prescriptions of acupoints combinations correlation were obtained by cluster analysis. Three decision paths of simplified acupoints selection were simulated by the decision tree, with LI20 as the dependent variable. CONCLUSION: In the treatment of AR with acupuncture and moxibustion, the regularities and characteristics of acupoints selection are as follows: 1) often selecting local acupoints and acupoint combinations along meridians, 2) focusing on combination of dispelling pathogenic factors with strengthening vital energy, 3) advocating diversification of acupoint matching methods. The combination of factor analysis, cluster analysis and QUEST decision tree application provides three directions for clinical acupoints selection of AR.",TextMining
"Corrosion problems have threatened long-term safe and stable operation of refining units. At present, refining enterprises mainly use corrosion monitoring and detection to identify equipment corrosion states, which has the shortcomings of narrow identification scope and high cost. The data-driven method avoids these problems, and has the advantage of efficiently predicting corrosion states to support corrosion management decisions. This paper, based on multi-source data, proposes a method focusing on the prediction about key corrosion parameters and establishes prediction models on critical parts of refining unit. Firstly, the application of demand-oriented corrosion prediction method is proposed. Then, according to the process operation parameters and medium analysis data of atmospheric tower overhead circuit, the regression prediction models based on RF are established. Meanwhile, after outlier detection by iForest, the model's parameters are optimized by SOS. In the limited real data, the optimized model achieves the best prediction with RMSE of 0.00611, MAE of 0.00513, and R2 of 0.918, and realizes the mining of corrosion parameter sensitivity. Finally, a variety of models are compared. The prediction method proposes in this paper have generalization performance, which can serve as an instruction for equipment safety management and hidden dangers identification. © 2022 Elsevier Ltd",TextMining
"Understanding job requirements is essential for establishing and optimizing employability-oriented education programs. Most relevant research focus on clarifying the skill requirement of an occupational field. In this research, we argue that job tasks serve as a bridge between a job and the required skills, and we provide a method for investigating the job-task-skill pattern of job requirements using text mining on publicly available job advertisements. To provide this, we: 1) collect data on thousands of job advertisements through web crawling and scraping; 2) categorize the jobs through title analysis; 3) identify the topic of both tasks and skills through word co-occurrence network clustering; and 4) systematically analyze the characteristics and internal relationships between job roles, tasks, and the required skills. A test case was conducted in the context of China's big data sector, and the findings show that the proposed strategy is viable, practical, and instructive.  © 2023 ACM.",TextMining
"Monitoring respiration is vital for personal diagnosis of chronic diseases. However, the existing respiratory sensors have severe limitations, such as single function, finite detection parameters, and lack of smart signal analysis. Here, we present an integrated wearable and low-cost smart respiratory monitoring sensor (RMS) system with artificial intelligence (AI)-assisted diagnosis of respiratory abnormality by detecting multi-parameters of human respiration. Coupling with intelligent analysis and data mining algorithms embedded in a phone app, the lighter system of 7.3 g can acquire real-time self-calibrated parameters, including breathing frequency, apnea hypopnea index (AHI), vital capacity (VC), peak expiratory flow (PEF), and other respiratory indexes with an accuracy >95.21%. The data can be wirelessly transferred to the user's data cloud terminal. The RMS system enables comprehensive multi-physiological parameters analysis for auxiliary diagnosing and classifying diseases, including sleep apnea, rhinitis, and chronic lung diseases, as well as rehabilitation of COVID-19, and exhibits advantages of portable healthcare. © 2022 The Authors",TextMining
"Based on global cobalt technology patents, this paper uses patent data mining and co-occurrence methods to identify technology application trends, key technology areas, key technology layouts, and technology roadmap. According to the development trend, the development of co-cobalt technology is divided into slow and rapid development stages. The conclusion are: 1) In terms of key technologies, E35-V (Cobalt compound) is the long-term R&D focus in the field of cobalt, and X16-B01F1 (Lithium-based) is the most important key technology area at present. 2) China, Japan, the United States, and South Korea are the main contributors to key cobalt technologies, mainly focusing on the R&D layout of L03-E01B5B (Lithium electrode) technology in the field of X16-B01F1 (Lithium-based). 3) Regarding the cooperation relationship between patent applicants, cooperation between groups is relatively close, cooperation between different countries is less, and transnational cooperation is mainly concentrated in developed countries, among which the United States has the most transnational partners. 4) In the field of cobalt’s most important electrode material technology LG Chemical Co., Ltd. (Korea) and Sumitomo Metal Mining Corporation (Japan) are the two companies with clear technology lines, while Univ Cent South (China) has a late technology development. Finally, we make suggestions for the development of cobalt technology: focus on core technology for R&D and innovation, actively study the technology status and innovation mode of leading companies, and strengthen the cooperation among different R&D institutions. Copyright © 2023 Hua and Dai.",TextMining
"Providing pay-as-you-go storage and computing services have contributed to the widespread adoption of cloud computing. Using virtualization technology, cloud service providers can execute several instances on a single physical server, maximizing resource utilization. A challenging issue in cloud data centers is that available resources are rarely fully utilized. The server utilization rate is poor and often below 30%. An accurate host workload prediction enhances resource allocation resulting in more efficient resource utilization. Recently, numerous methods based on deep learning for predicting cloud computing workload have been developed. An efficient strategy must predict long-term dependencies on nonstationary host workload data and be quick enough to respond to incoming requests. This study employs a Bidirectional Gated-Recurrent Unit (BiGRU), Discrete Wavelet Transformation (DWT), and an attention mechanism to improve the host load prediction accuracy. DWT is used to decompose input data into sub-bands with different frequencies and to extract patterns from nonlinear and nonstationary data in order to improve prediction accuracy. The extracted features are fed into BiGRu to predict future workload. The attention mechanism is used in order to extract the temporal correlation features. This hybrid model was evaluated with cluster data sets from Google and Alibaba. Experimental results reveal that our method improves prediction accuracy by 3% to 56% compared to a variety of state-of-the-art methods. © 2022 Elsevier B.V.",TextMining
"The increasing demand for considering multisensor data fusion technology has drawn attention for precise human activity recognition (HAR) over standalone technology due to its reliability and robustness. This article presents a framework that fuses data from multiple sensing systems and applies neuromorphic computing to sense and classify human activities. The data is collected by utilizing inertial measurement unit (IMU) sensors, software-defined radios, and radars, and feature extraction and selection are performed on the data. For each of the actions, such as sitting and standing, an activity matrix is generated, which is then fed into a discrete Hopfield neural network as a binary feature pattern for one-shot learning. Following the Hopfield network neurons' feedback output, the conformity to the standard activity feature pattern is also determined. Following the Hopfield network neurons' feedback output, the training of neurons is completed after two steps under the Hebbian learning law, and the conformity to the standard activity feature pattern is also determined. According to the probabilistic statistics on inference predictions, the proposed method, that is the neuromorphic computing of the three data fused framework, achieved the box plot for the highest lower quartile output of 95.34%, while the confusion matrix classification accuracy of the two activities was 98.98%. The results have shown that neuromorphic computing is most capable of multisensor data-fusion-based HAR. Furthermore, the proposed method can be enhanced by incorporating additional hardware signal processing in the system to enable the flexible integration of human activity data.  © 2014 IEEE.",TextMining
"Feature selection is an important preprocessing technique in the fields of data mining and machine learning. With the promotion of privacy protection awareness, recently it becomes a very practical and challenging issue to select high-quality feature subsets while ensuring the privacy of all participants. However, there is a lack of research results on this issue, i.e., feature selection under privacy protection. Aiming at the issue, this paper proposes a federated feature selection framework for the first time. In the framework, inspiring by the idea of federated learning, a credible third participant is introduced to process and integrate optimal feature subsets from multiple participants. On the basis of the framework, a federated evolutionary feature selection algorithm based on particle swarm optimization is proposed to effectively solve feature selection problems with multiple participants under privacy protection. Two new operators satisfying the requirement of privacy protection, i.e., the feature assembling strategy with multi-participant cooperation and the swarm initialization strategy guided by assembling solution, are designed to improve the ability of the proposed algorithm. Compared with several typical assembling feature selection algorithms on 15 data sets, experimental results show that the proposed algorithm can significantly improve the classification accuracy of the feature subset selected by each participant, while protecting the privacy of data. © 2022 Elsevier B.V.",TextMining
"Head-on (HO) collisions between the DNA replication machinery and RNA polymerase over R-loop forming sequences (RLFS) are genotoxic, leading to replication fork blockage and DNA breaks. Current models suggest that HO collisions are avoided through replication initiation site (RIS) positioning upstream of active genes, ensuring co-orientation of replication fork movement and genic transcription. However, this model does not account for pervasive transcription, or intragenic RIS. Moreover, pervasive transcription initiation and CG-rich DNA is a feature of RIS, suggesting that HO transcription units (HO TUs) capable of forming R-loops might occur. Through mining phased GRO-seq data, and developing an informatics strategy to stringently identify RIS, we demonstrate that HO TUs containing RLFS occur at RIS in MCF-7 cells, and are downregulated at the G1/S phase boundary. Our analysis reveals a novel spatiotemporal relationship between transcription and replication, and supports the idea that HO collisions are avoided through transcriptional regulatory mechanisms. © 2022 The Authors",TextMining
"Using genome mining and heterologous expression, we report the discovery and production of a new antimicrobial lasso peptide from species related to the Enterobacter cloacae complex. Using NMR and mass spectrometric analysis, we show that this lasso peptide, named cloacaenodin, employs a threaded lasso fold which imparts proteolytic resistance that its unthreaded counterpart lacks. Cloacaenodin has selective, low micromolar, antimicrobial activity against species related to the E. cloacae complex, including species implicated in nosocomial infections and against clinical isolates of carbapenem-resistant Enterobacterales. We further used site-directed mutagenesis to probe the importance of specific residues to the peptide’s biosynthesis, stability, and bioactivity. © 2022 American Chemical Society.",TextMining
"Supply chain interruptions have been identified as a key risk factor. Supply chain risk management has been driven by technological advancements, an increase in information overload, and a greater exposure to risk. Data mining uses a variety of analytical methods to make intelligent and fast decisions; yet, its utility in supply chain risk management has yet to be fully realized. The risk in the supply chain is prioritized using machine learning techniques. The majority of supply chain studies, on the other hand, focus on prediction efficiency and ignore the significance of interpretability, which helps experts to mitigate or avoid risks. The goal of this study is to develop a data mining-based cuckoo search support vector machine supply chain risk management (DM-CSVM SCRM) for predicting hazards in supply chains, as well as identifying, assessing, and mitigating them. A supply chain risk prediction is done by using a machine learning algorithm in this project. A holistic approach to risk management combines risk management and DM operations into a single structure for efficient management of risk. Based on discussions, focus group interviews, and semi-structured interviews the framework is tested in this study. The research shows how DM can help you find unseen and relevant data in unstructured risk data so you can make better risk decisions. © 2023 Little Lion Scientific.",TextMining
"Incorporating knowledge graphs (KGs) into recommender systems to provide explainable recommendation has attracted much attention recently. The multi-hop paths in KGs can provide auxiliary facts for improving recommendation performance as well as explainability. However, existing studies may suffer from two major challenges: error propagation and weak explainability. Considering all paths between every user-item pair might involve irrelevant ones, which leads to error propagation of user preferences. Defining meta-paths might alleviate the error propagation, but the recommendation performance would heavily depend on the pre-defined meta-paths. Some recent methods based on graph convolution network (GCN) achieve better recommendation performance, but fail to provide explainability. To tackle the above problems, we propose a novel method named Knowledge-aware Reasoning with Graph Convolution Network (KR-GCN). Specifically, to alleviate the effect of error propagation, we design a transition-based method to determine the triple-level scores and utilize nucleus sampling to select triples within the paths between every user-item pair adaptively. To improve the recommendation performance and guarantee the diversity of explanations, user-item interactions and knowledge graphs are integrated into a heterogeneous graph, which is performed with the graph convolution network. A path-level self-attention mechanism is adopted to discriminate the contributions of different selected paths and predict the interaction probability, which improves the relevance of the final explanation. Extensive experiments conducted on three real-world datasets show that KR-GCN consistently outperforms several state-of-the-art baselines. And human evaluation proves the superiority of KR-GCN on explainability. © 2023 Association for Computing Machinery.",TextMining
"The study of disease-gene associations is an important topic in the field of computational biology. The accumulation of massive amounts of biomedical data provides new possibilities for exploring potential relations between diseases and genes through computational strategy, but how to extract valuable information from the data to predict pathogenic genes accurately and rapidly is currently a challenging and meaningful task. Therefore, we present a novel computational method called PGAGP for inferring potential pathogenic genes based on an adaptive network embedding algorithm. The PGAGP algorithm is to first extract initial features of nodes from a heterogeneous network of diseases and genes efficiently and effectively by Gaussian random projection and then optimize the features of nodes by an adaptive refining process. These low-dimensional features are used to improve the disease-gene heterogenous network, and we apply network propagation to the improved heterogenous network to predict pathogenic genes more effectively. By a series of experiments, we study the effect of PGAGP’s parameters and integrated strategies on predictive performance and confirm that PGAGP is better than the state-of-the-art algorithms. Case studies show that many of the predicted candidate genes for specific diseases have been implied to be related to these diseases by literature verification and enrichment analysis, which further verifies the effectiveness of PGAGP. Overall, this work provides a useful solution for mining disease-gene heterogeneous network to predict pathogenic genes more effectively. Copyright © 2023 Zhang, Xiang, Tang, Yang and Li.",TextMining
"Purpose: Casting is one of the well-known manufacturing processes to make durable parts of goods and machinery. However, the quality of the casting parts depends on the proper choice of process variables related to properties of the materials used in making a mold and the product itself; hence, variables related to product/process designs are taken into consideration. Understanding casting techniques considering significant process variables is critical to achieving better quality castings and helps to improve the productivity of the casting processes. This study aims to understand the computational models developed for achieving better quality castings using various casting techniques. Design/methodology/approach: A systematic literature review is conducted in the field of casting considering the period 2000–2020. The keyword co-occurrence network and word cloud from the bibliometric analysis and text mining of the articles reveal that optimization and simulation models are extensively developed for various casting techniques, including sand casting, investment casting, die casting and squeeze casting, to improve quality aspects of the casting's product. This study further investigates the optimization and simulation models and has identified various process variables involved in each casting technique that are significantly affecting the outcomes of the processes in terms of defects, mechanical properties, yield, dimensional accuracy and emissions. Findings: This study has drawn out the need for developing smart casting environments with data-driven modeling that will enable dynamic fine-tuning of the casting processes and help in achieving desired outcomes in today's competitive markets. This study highlights the possible technology interventions across the metal casting processes, which can further enhance the quality of the metal casting products and productivity of the casting processes, which show the future scope of this field. Research limitations/implications: This paper investigates the body of literature on the contributions of various researchers in producing high-quality casting parts and performs bibliometric analysis on the articles. However, research articles from high-quality journals are considered for the literature analysis in identifying the critical parameters influencing quality of metal castings. Originality/value: The systematic literature review reveals the analytical models developed using simulation and optimization techniques and the important quality characteristics of the casting products. Further, the study also explores critical influencing parameters involved in every casting process that significantly affects the quality characteristics of the metal castings. © 2021, Emerald Publishing Limited.",TextMining
"In the field of intelligent transportation, the instant discovery of companions has become a research hotspot. This technique can be applied to traffic management and public security governance. This study provides an incremental and distributed approach for discovering traveling companion instantly and continuously based on a data stream of automatic number plate recognition(ANPR). First, a parallelized incremental mining algorithm is designed and implemented in Spark on the basis of traffic-monitoring streaming data. Second, an adjustable data structure DF-tree is proposed that considers the characteristics of companion vehicles with the original ANPR data stream changing dynamically. On the basis of the DF-tree, the system can discover companions without reconstructing the data tree. In addition, we introduce a time decay mechanism to satisfy the spatio-temporal constraints of companion vehicles discovery. Finally, we realize the real-time discovery of companion vehicles based on large-scale ANPR data. The proposed methods are evaluated with extensive experiments on real datasets. The experimental results show that our proposed DF-tree-based approach is faster than the existing methods for companion discovery and it can detect companion vehicles groups in real time. © 2022 Elsevier B.V.",TextMining
"The high impedance faults (HIFs) detection in the micro-grid is very difficult for over-current protection owing to the less fault magnitude. As this is a practical problem in the distribution feeder, the detection of HIFs plays a vital role in industry 4.0. A dual-tree complex wavelet transform(DT-CWT) and data mining approaches have been used for fault detection and fault classification. For the extraction of wavelet features by DT-CWT, the residual voltage is used as input and fed to various data mining approaches to separate the HIF events and the created confusion matrix gives the best results. The correctness of the method implemented is investigated with other data mining approaches like support vector machine(SVM), k-nearest neighbor(KNN), and ensemble classifiers. As correlated to further methods, the proposed technique is 100% accurate. To execute the proposed method, the interconnection of DG with a wind-integrated micro-grid system is designed using Power System Computer-Aided Design (PSCAD) software.  © 2022 The Authors. Published by ELSEVIER B.V.",TextMining
"Understanding energy consumption patterns is crucial for energy demand-side management. Unlike traditional data mining or machine learning-based methods, this paper presents visual analysis methods for exploring energy consumption data from spatial, temporal, and spatiotemporal dimensions, including variability, segmentation, and energy demand shifts. To support the proposed methods, we develop a visual analysis tool that allows users to explore consumption data and validate their hypotheses based on visual results through human–client–server interactions. In particular, we propose a novel potential flow-based method to model energy demand shift patterns and have integrated it into the proposed analysis tool. We comprehensively evaluate the proposed methods and the tool using real-world electricity consumption data from the Shanghai Pudong district, and compare with traditional data mining methods. The results demonstrated the effectiveness and superiority of the proposed visual analysis methods, including its ability to discover the spatiotemporal variability of energy demand, customer groups, and demand shift patterns across different geographical areas and time horizons. All results can be well explained by knowledge of the energy consumption in the study region. © 2022 The Author(s)",TextMining
"Ribosomally synthesized and post-translationally modified peptides (RiPPs) are natural products with remarkable chemical and functional diversities. These peptides are often synthesized as signals or antibiotics and frequently associated with quorum sensing (QS) systems. With the increasing number of available genomes, many hitherto unseen RiPP biosynthetic pathways have been mined, providing new resources for novel bioactive compounds. Herein, we investigated the underexplored biosynthetic potential of Streptococci, prevalent bacteria in mammal-microbiomes that include pathogenic, mutualistic, and commensal members. Using the transcription factor-centric genome mining strategy, we discovered a new family of lanthipeptide biosynthetic loci under the control of potential QS. By in vitro studies, we investigated the reaction of one of these lanthipeptide synthetases and found that it installs only one lanthionine moiety onto its short precursor peptide by connecting a conserved TxxC region. Bioinformatics and in vitro studies revealed that these lanthipeptide synthetases (class VI) are novel lanthipeptide synthetases with a truncated lyase, a kinase, and a truncated cyclase domain. Our data provide important insights into the processing and evolution of lanthipeptide synthetase to tailor smaller substrates. The data are important for obtaining a mechanistic understanding of the post-translational biosynthesis machinery of the growing variety of lanthipeptides. © 2022 American Chemical Society.",TextMining
"The main purpose of this study is to analyze the main influencing factors of the landslide in the coal mine area and, on this basis, establish the sensitivity zoning model of the landslide. Considering the difficulty to obtain the expected results by using machine learning under the condition of lacking data, the typical landslide is used as the data basis, that is, the Fenxi coal mine and Xishan Bujiu coal mine are selected as the coal mining landslide points. Various factors, such as goaf, land subsidence, slope structure, formation lithology, and various indicators are used as input data sources, and artificial neural network (ANN) datasets are used for training to establish a pre-training model. Using the pre-training model, the mining landslide sensitivity evaluation model based on transfer learning is established. In order to demonstrate the performance of transfer learning more intuitively, the neural network is introduced to evaluate the evaluation model. The test results show that transfer learning can achieve a transfer effect higher than 0.95, and the regional distributions of highest landslide sensitivity calculated based on self-transfer learning, direct push transfer learning, and inductive transfer learning are 31.33, 35.50, and 33.75%, respectively, which further deduced that inductive transfer learning can be used for evaluating an LSP model. Copyright © 2023 Zhang, Yang, Zhang and Wang.",TextMining
"In great metropoles, there is a need for a better understanding of the spread of COVID-19 in an outdoor context with environmental parameters. Many studies on this topic have been carried out worldwide. However, there is conflicting evidence regarding the influence of environmental variables on the transmission, hospitalizations and deaths from COVID-19, even though there are plausible scientific explanations that support this, especially air quality and meteorological factors. Different urban contexts, methodological approaches and even the limitations of ecological studies are some possible explanations for this issue. That is why methodological experimentations in different regions of the world are important so that scientific knowledge can advance in this aspect. This research analyses the relationship between air pollution, meteorological factors and COVID-19 in the Brussels Capital Region. We use a data mining approach that is capable of extracting patterns in large databases with diverse taxonomies. Data on air pollution, meteorological, and epidemiological variables were processed in time series for the multivariate analysis and the classification based on association. The environmental variables associated with COVID-19-related deaths, cases and hospitalization were PM2.5, O3, NO2, black carbon, radiation, air pressure, wind speed, dew point, temperature and precipitation. These environmental variables combined with epidemiological factors were able to predict intervals of hospitalization, cases and deaths from COVID-19. These findings confirm the influence of meteorological and air quality variables in the Brussels region on deaths and cases of COVID-19 and can guide public policies and provide useful insights for high-level governmental decision-making concerning COVID-19. However, it is necessary to consider intrinsic elements of this study that may have influenced our results, such as the use of air quality aggregated data, ecological fallacy, focus on acute effects in the time-series study, the underreporting of COVID-19, and the lack of behavioral factors. © 2022 Elsevier B.V.",TextMining
"Medical data mining models are predominant in medical data analysis. In our paper, we have applied the different classifier algorithm; along with a new improved feature selection method is applied, towards an accurate detection of breast cancer, in its early stages. Performance of the classifiers was seen to be noticeably enhanced when irrelevant features were screened out from the modeling process. © Grenze Scientific Society, 2023.",TextMining
"Peak detection of untargeted liquid chromatography-high resolution mass spectrometry (LC-HRMS) data is a key step to identify the metabolic status of the drugable chemicals and extracts from functional foods or herbs. Nevertheless, the existing approaches are difficult to obtain ideal results with low false positives and false negatives. In this paper, we proposed an automatic method based on convolutional neural network (CNN) for image classification and Faster R–CNN for peak location/classification in untargeted LC-HRMS data, and named it Peak_CF. It can achieve detection of target peaks with high accuracy and high recall (both >90%) as verified by an evaluation data-set. In terms of detecting the m/z peaks of known compounds, Peak_CF is better than Peakonly, and it can effectively have an overall peak shape judgment of split peaks. For the same evaluation data, the recall of MZmine2 (ADAP) is slightly higher than that of Peak_CF, however, the F1 score of Peak_CF is higher, indicating that it has higher accuracy. In addition, the Peak_ CF training model with strong generalization ability can be achieved and verified. At last, Peak_CF was applied in real metabolic fingerprints of total flavonoids from Glycyrrhiza uralensis Fisch, also a contrast was conducted based on 40 m/z peaks of 40 prototypes in serum data-set. The result showed that the recall rate of Peak_CF and Peakonly all reached 95%, higher than 70% of MZmine2 (ADAP), and Peak_CF is more accurate when detecting EIC that has serious drifts. In conclusion, Peak_CF provides a new route for data mining of LC-HRMS datasets of drug (or herbs, or functional foods) metabolites. © 2022 Elsevier B.V.",TextMining
"Due to the equipment failure and inappropriate operation strategy, it is often difficult to achieve energy-efficient building. Anomaly detection of building energy consumption is one of the important approaches to improve building energy-saving. The great amounts of energy consumption data collected by building energy monitoring platforms (BEMS) provides potentials in using data mining technology for anomaly detection. This study proposes a dynamic anomaly detection algorithm for building energy consumption data, which realizes the dynamic detection of point anomalies and collective anomalies. The algorithm integrates unsupervised clustering algorithm with supervised algorithm to establish a semi-supervised matching mechanism, which avoids the influence of error label and improves the efficiency of anomaly detection. A particle swarm optimization (PSO) is used to optimize the unsupervised clustering algorithm. This investigation tests the effectiveness of the proposed algorithm and evaluates the performance of the energy consumption clustering algorithm by using the annual electricity consumption data of an experimental building in a university. The results show that the clustering accuracy of the algorithm can reach more than 80%, and it can effectively detect the building energy consumption data of two different forms of outliers. It can provide reliable data support for adjusting building management strategies. © 2022 The Authors",TextMining
"Cellulose ethers (CEs) are semi-synthetic polymers produced by derivatization of natural cellulose, yielding highly substituted products such as ethyl hydroxyethyl cellulose (EHEC) or methyl ethyl hydroxyethyl cellulose (MEHEC). CEs are commonly applied as pharmaceutical excipients and thickening agents in paints and drymix mortars. CE properties, such as high viscosity in solution, solubility, and bio-stability are of high interest to achieve required product qualities, which may be strongly affected by the substitution pattern obtained after derivatization. The average and molar degree of substitution often cannot explain functional differences observed among CE batches, and more in-depth analysis is needed. In this work, a new method was developed for the comprehensive mapping of the substitution degree and composition of β-glucose monomers of CE samples. To this end, CEs were acid-hydrolyzed and then analyzed by gradient reversed-phase liquid chromatography-mass spectrometry (LC-MS) using an acid-stable LC column and time-of-flight (TOF) mass spectrometer. LC-MS provided monomer resolution based on ethylene oxide, hydroxyl, and terminating methyl/ethyl content, allowing the assignment of detailed compositional distributions. An essential further distinction of constitutional isomer distributions was achieved using an in-house developed probability-based deconvolution algorithm. Aided by differential heat maps for visualization and straightforward interpretation of the measured LC-MS data, compositional variation between bio-stable and non-bio-stable CEs could be identified using this new approach. Moreover, it disclosed unexpected methylations in EHEC samples. Overall, the obtained molecular information on relevant CE samples demonstrated the method's potential for the study of CE structure-property relationships. © 2022 The Authors",TextMining
"Study Design. Retrospective study of data collected prospectively. Objective. The goal of this study is to create a predictive model of preoperative bone health status in adult patients undergoing adult spinal reconstructive (ASR) surgery using machine learning (ML). Summary of Background Data. Despite understanding that bone health impacts spine surgery outcomes, spine surgeons lack the tools to risk stratify patients preoperatively to determine who should undergo bone health screening. An ML approach mines patterns in data to determine the risk for poor bone health in ASR patients. Materials and Methods. Two hundred and eleven subjects over the age of 30 with dual energy X-ray absorptiometry scans, who underwent spinal reconstructive surgery were reviewed. Data was collected by manual and automated collection from the electronic health records. The Weka software was used to develop predictive models for multiclass classification of healthy, osteopenia, and osteoporosis (OPO) bone status. Bone status was labeled according to the World Health Organization (WHO) criteria using dual energy X-ray absorptiometry T scores. The accuracy, sensitivity, specificity, and area under the receiver operating curve (AUC) were calculated. The model was evaluated on a test set of unseen data for generalizability. Results. The prevalence of OPO was 23.22% and osteopenia was 52.61%. The random forest model achieved optimal performance with an average sensitivity of 0.81, specificity of 0.95, and AUC of 0.96 on the training set. The model yielded an averaged sensitivity of 0.64, specificity of 0.78, and AUC of 0.69 on the test set. The model was best at predicting OPO in patients. Numerous patient features exhibited predictive value, such as body mass index, insurance type, serum sodium level, serum creatinine level, history of bariatric surgery, and the use of medications such as selective serotonin reuptake inhibitors. Conclusion. Predicting bone health status in ASR patients is possible with an ML approach. Additionally, data mining using ML can find unrecognized risk factors for bone health in ASR surgery patients. © 2023 Lippincott Williams and Wilkins. All rights reserved.",TextMining
"For a data-driven bus line energy consumption prediction model, building it with statistical indicators on some variables appeared in the whole bus route, such as average speed, maximum acceleration, etc., always decreases its prediction accuracy due to the discarding of the hidden information in the variable change process. To deal with this problem, a frequency item mining based energy consumption prediction method was proposed, in which the useful prediction information hidden in the process of change is mined by frequency item statistics algorithm and stepwise regression algorithm is used to find the optimal combination of input variables. Simulation and experimental analysis show that with multi-dimensions frequency items, the proposed algorithm can describe and reflect the correlation between different input variables appeared in the process. At the same time, a lot of hardware and software computing costs are saved. © 2022 Elsevier Ltd",TextMining
"Fuzzy formal concept analysis (FFCA) is generally used to describe the processes of concept-cognitive learning (CCL). However, for fuzzy formal contexts, each attribute has the same weight (i.e, the same degree of importance) before constructing fuzzy concepts, which limits mining interesting knowledge and affects its application promotion. On the other hand, this model is hard to resist the influence of noise hidden in data, which results in poor classification learning. Moreover, the existing incremental CCL algorithms still face some challenges that the previously acquired knowledge is not fully utilized to improve the classification accuracies for dynamic data. To address these issues, we introduce different weights into fuzzy formal contexts and propose a novel incremental CCL mechanism in dynamic environment. Firstly, weight values of attributes from different decisions based on fuzzy entropy are established to measure the significant degree of attributes. Then, to comprehensively explicate the hierarchical relationships of fuzzy concepts, we construct the weighted fuzzy concept lattice and the weighted fuzzy concept space. Secondly, we design an algorithm to update the weighted fuzzy concepts for facilitating concept classification. To overcome the individual cognitive limitation, we put forward the progressive weighted fuzzy concept to remove repeated information. Furthermore, the classification prediction label and dynamic updating mechanism after adding objects are systematically discussed. Finally, we perform an experimental evaluation on ten data sets which explicate the feasibility and efficiency of our proposed approach. © 2022 Elsevier B.V.",TextMining
"Purpose: The K-means (KM) clustering algorithm is extremely responsive to the selection of initial centroids since the initial centroid of clusters determines computational effectiveness, efficiency and local optima issues. Numerous initialization strategies are to overcome these problems through the random and deterministic selection of initial centroids. The random initialization strategy suffers from local optimization issues with the worst clustering performance, while the deterministic initialization strategy achieves high computational cost. Big data clustering aims to reduce computation costs and improve cluster efficiency. The objective of this study is to achieve a better initial centroid for big data clustering on business management data without using random and deterministic initialization that avoids local optima and improves clustering efficiency with effectiveness in terms of cluster quality, computation cost, data comparisons and iterations on a single machine. Design/methodology/approach: This study presents the Normal Distribution Probability Density (NDPD) algorithm for big data clustering on a single machine to solve business management-related clustering issues. The NDPDKM algorithm resolves the KM clustering problem by probability density of each data point. The NDPDKM algorithm first identifies the most probable density data points by using the mean and standard deviation of the datasets through normal probability density. Thereafter, the NDPDKM determines K initial centroid by using sorting and linear systematic sampling heuristics. Findings: The performance of the proposed algorithm is compared with KM, KM++, Var-Part, Murat-KM, Mean-KM and Sort-KM algorithms through Davies Bouldin score, Silhouette coefficient, SD Validity, S_Dbw Validity, Number of Iterations and CPU time validation indices on eight real business datasets. The experimental evaluation demonstrates that the NDPDKM algorithm reduces iterations, local optima, computing costs, and improves cluster performance, effectiveness, efficiency with stable convergence as compared to other algorithms. The NDPDKM algorithm minimizes the average computing time up to 34.83%, 90.28%, 71.83%, 92.67%, 69.53% and 76.03%, and reduces the average iterations up to 40.32%, 44.06%, 32.02%, 62.78%, 19.07% and 36.74% with reference to KM, KM++, Var-Part, Murat-KM, Mean-KM and Sort-KM algorithms. Originality/value: The KM algorithm is the most widely used partitional clustering approach in data mining techniques that extract hidden knowledge, patterns and trends for decision-making strategies in business data. Business analytics is one of the applications of big data clustering where KM clustering is useful for the various subcategories of business analytics such as customer segmentation analysis, employee salary and performance analysis, document searching, delivery optimization, discount and offer analysis, chaplain management, manufacturing analysis, productivity analysis, specialized employee and investor searching and other decision-making strategies in business. © 2022, Emerald Publishing Limited.",TextMining
"Current extensive seismicity in southern Sichuan Basin is ascribed to the reactivation of pre-existing faults, as a result of prolonged fluid injection for salt mining and shale gas development, respectively. However, the structural framework of the region remains poorly understood. Here, we apply Vp/Vs consistency-constrained double-difference seismic tomography to high quality phase data from 36,314 earthquakes jointly recorded by our local array and a regional seismic network to determine high-resolution velocity models. Earthquake relocations reveal shallow hypocenters for the Ms>5.0 earthquakes and two distinct seismogenic zones corresponding to the salt mine and shale gas regions, with most induced seismic events forming widespread lineaments some of which extend to the basement and are remarkably similar to the fault and fracture trends interpreted on reflection seismic and outcrops, respectively. Our 3-D crustal velocity analyses show that seismicity beneath the Changing salt mining area is associated with a combination of relatively low Vp/Vs (1.6–1.74) and high Vp/Vs (1.75–1.86) expressions, while most of small earthquakes within the Xingwen shale gas block are associated with relatively high Vp/Vs values (1.77–1.87), indicating the earthquakes in these two areas are caused by unique inducing mechanisms. The two moderately strong 2018 Xingwen Ms5.7 and 2019 Gongxian Ms5.3 earthquakes in the Xingwen shale gas block are located around low Vp/Vs. zones, suggesting they could be structurally controlled. In comparison, the 2019 Changning Ms6.0 earthquake in the Changning salt mining area is associated with high Vp/Vs. expression, suggesting its occurrence is related to fluid injections. In addition, top of the crystalline early Neoproterozoic (pre-Sinian) Sichuan basement is characterized by the 6.5 km/s Vp contour, which is new for earthquake tomographic studies in the region. Combined with outcrop analysis, we are able to construct a structural framework for induced seismicity in southern Sichuan basin, which unravels the structural architecture of induced seismicity. Copyright © 2023 Anyiam, Zhang, Tan, Qian, Gao, Liu, Zuo and Zhao.",TextMining
"In reality, all homosapiens species benefit greatly from the function of ATP-binding cassette (ABC) transporter proteins. Many studies have focused specifically on the drug transporter prediction because to the recent advancements in biology. Machine learning and soft computing with data mining methodologies have been used to identify valid motif sequences from biological datasets in general. In this work, the authors analysed the research on the ABC transporter with the prediction of cellular cholesterol. This research is focused on this new area, as ABC transporters are frequently employed as pharmacological targets. In this instance, the authors have focused on the ABC transporter's legitimate signature motif involving plasma membrane cholesterol. The authors used an unique hybrid model that is rough set with random forest for the prediction of motif structure that has clinical significance for predicting relevant motif sequences. © 2023, IGI Global. All rights reserved.",TextMining
"Despite large investment cancer continues to be a major source of mortality and morbidity throughout the world. Traditional methods of detection and diagnosis such as biopsy and imaging, tend to be expensive and have risks of complications. As data becomes more abundant and machine learning continues advancing, it is natural to ask how they can help solve some of these problems. In this paper we show that using a person's personal health data it is possible to predict their risk for a wide variety of cancers. We dub this process a “statistical biopsy.” Specifically, we train two neural networks, one predicting risk for 16 different cancer types in females and the other predicting risk for 15 different cancer types in males. The networks were trained as binary classifiers identifying individuals that were diagnosed with the different cancer types within 5 years of joining the PLOC trial. However, rather than use the binary output of the classifiers we show that the continuous output can instead be used as a cancer risk allowing a holistic look at an individual's cancer risks. We tested our multi-cancer model on the UK Biobank dataset showing that for most cancers the predictions generalized well and that looking at multiple cancer risks at once from personal health data is a possibility. While the statistical biopsy will not be able to replace traditional biopsies for diagnosing cancers, we hope there can be a shift of paradigm in how statistical models are used in cancer detection moving to something more powerful and more personalized than general population screening guidelines. Copyright © 2023 Hart, Yan, Nartowt, Roffman, Stark, Muhammad and Deng.",TextMining
"Due to the enormous building stock and high energy consumption of the construction sector, green retrofitting of existing buildings has recently become a critical issue. China has implemented building retrofitting on a large scale based on various norms and standards. In practice, however, the effectiveness of the whole building retrofit program is often jeopardized because some decision-makers are limited by their experience and fail to evaluate the program in its entirety. To overcome this problem, this study offers an intelligent decision support model considering tacit knowledge for program decision-making with conflicting objectives. By comparing several data mining approaches and using 152 retrofitted existing buildings as examples, a tacit knowledge mining model based on the XGBoost algorithm with an accuracy of 73.91% is constructed. The predicted results of the knowledge mining model can be used as the input of the multi-objective decision-making model. In addition, the retrofit cost, thermal insulation requirement, and total retrofit area are chosen as the objectives of the multi-objective decision-making model. Then, the model's applicability to building retrofit programs is tested using five buildings as examples. Finally, the results demonstrate that the proposed model can partially replace experts in supporting policymakers and owners throughout the planning stage. © 2022",TextMining
"The upstream and downstream dependence of air traffic flow networks (ATFN) is a key step in identifying the changing characteristics and interaction patterns of air traffic flow. This requires mining the flow state and operation information of en route flights from multiple angles. However there have been challenges in terms of methodology and practical application. In this study, we propose a hybrid model which combines fuzzy c-means (FCM) and graph convolution network (GCN) for air traffic dependence. Practice has proven that the ATFN graph structure generated by clustering trajectory data using FCM can clearly reflect crossing points and mainstream paths. The GCN is used to detect the trajectory deviation, time delay, and tolerance of the ATFN at different times or paths and visualise the output characteristic layer, which can effectively identify the temporal and spatial correlation of the flow state. Experimental results on real data show that FCM-GCN is significantly better than other baseline models in medium- and long-term traffic prediction tasks. It achieved its best performance in the 60-min traffic prediction compared with existing methods. The experimental results in the selected case area propose a general research framework on the upstream and downstream dependence of ATFN and reflect the efficiency of the organisation and differentiation of ATFN. Its integration with air traffic flow management is conducive to the optimisation of highly interconnected and interdependent flow networks. © 2022 Elsevier B.V.",TextMining
As the arteries of urban power transmission network，safe and stable operation of high voltage cable has very important engineering significance and economic benefits. With the continuous development of power Internet of things，safe and stable operation of high voltage cable will be guaranteed by state holographic technology. In this paper，the digital twin（DT）technology is introduced in the field of high voltage cable for organic integration and value mining of the massive data of holographic perception. In this paper，the multiple application of digital twin technology in the field of high voltage cable is explored on the basis of technical contents of the digital twin technology，technical system and model factor. The frame of design and manufacturing technology driven by the digital twin and the involvement of the digital twin in the operation and maintenance of high voltage cable are described. Moreover，the key points to achieve digital twin of high voltage cable based on the existing condition is proposed. © 2023 Xi'an High Voltage Apparatus Research Institute. All rights reserved.,TextMining
"Fuel consumption is one of the key parameters in mechanised forest operations, particularly on lower bearing capacity soils, as wheel chains or bogie tracks can have a strong effect on it. This study aims to analyse the fuel consumption of several individual wheeled cut-to-length forwarder set-ups with different types of bogie tracks on peatland using automatic recording of data bus information. Two types of forwarders, 8-wheeled and 10-wheeled, and three types of tracks were tested on peatland in Eastern Finland. A mixed-model approach is the basis to study the fuel consumption as a function of the soil bearing capacity, the number of passes of the machine on the same soil, the section (curve or straight) and other variables related to the machine performance and set-up, for a total of N=27,928 fuel observations on three machines in 33 plots (trail segments). The model results in an R2=0.78; the number of passes increases the fuel consumption significantly, while the soil bearing capacity did not affect the fuel consumption. There are, however, important differences between the machines performance, which are addressed in the model. By contributing to the knowledge on the connection between operational conditions and fuel consumption, the study can contribute to the aim towards a sustainable forest operation through minimizing negative environmental impacts and providing the necessary tools for further research efforts. © 2023, University of Zagreb, Faculty of Mining, Geology and Petroleum Engineering. All rights reserved.",TextMining
"In this paper, we show textual data from firm-related events in news articles can effectively predict various firm financial ratios, with or without historical financial ratios. We exploit state-of-the-art neural architectures, including pseudo-event embeddings, Long Short-Term Memory Networks, and attention mechanisms. Our news-powered deep learning models are shown to outperform standard econometric models operating on precise accounting historical data. We also observe forecasting quality improvement when integrating textual and numerical data streams. In addition, we provide in-depth case studies for model explainability and transparency. Our forecasting models, model attention maps, and firm embeddings benefit various stakeholders with quality predictions and explainable insights. Our proposed models can be applied both when numerically historical data is or is not available.  © 2023 Association for Computing Machinery.",TextMining
"The combination of convolutional and recurrent neural networks is a promising framework. This arrangement allows the extraction of high-quality spatio-temporal features together with their temporal dependencies. This fact is key for time series prediction problems such as forecasting, classification or anomaly detection, amongst others. In this paper, the TSFEDL library is introduced. It compiles 22 state-of-the-art methods for both time series feature extraction and prediction, employing convolutional and recurrent deep neural networks for its use in several data mining tasks. The library is built upon a set of Tensorflow + Keras and PyTorch modules under the AGPLv3 license. The performance validation of the architectures included in this proposal confirms the usefulness of this Python package. © 2022 Elsevier B.V.",TextMining
"The provision of physical healthcare services during the isolation phase is one of the major challenges associated with the current COVID-19 pandemic. Smart healthcare services face a major challenge in the form of human behavior, which is based on human activities, complex patterns, and subjective nature. Although the advancement in portable sensors and artificial intelligence has led to unobtrusive activity recognition systems, very few studies deal with behavior tracking for addressing the problem of variability and behavior dynamics. In this regard, we propose the fusion of PRocess mining and Paravector Tensor (PROMPT)-based physical health monitoring framework that not only tracks subjective human behavior, but also deals with the intensity variations associated with inertial measurement units. Our experimental analysis of a publicly available dataset shows that the proposed method achieves 14.56% better accuracy in comparison to existing works. We also propose a generalized framework for healthcare applications using wearable sensors and the PROMPT method for its triage with physical health monitoring systems in the real world. © 2001-2012 IEEE.",TextMining
"The work is devoted to the problems of efficiency of bitcoins, especially power inputs due to generating of this cryptocurrency. Nowadays the problems of mining power input efficiency seem to have passed from a comparative problem to the problem of existence of this blockchain technology, requiring a different engineering policy or different managerial decisions. The comparative analysis of bitcoins generating power input and the world's power input has shown that there are almost no trustworthy methods of evaluating input power for blockchain technologies. This problem is solved by application of contemporary methods by setting up big mining companies, located in areas with cheap electric energy and free power balance, possessing their own technological resources and thinking of creating alternative power capacities for mining objectives. At that the state systems start to introduce various limitations for power capacities used for cryptocurrencies including quotas and price privileges. Represented are the results of the analyses of the dynamics of alternation of the main parameters, influencing power consumption at generation of bitcoins on the basis of available literary data and own investigation. Given are the results of calculations regarding bitcoins generation, the costs of consumed electric power per mining of one bitcoin. A more objective index of bitcoin power consumption is suggested, it being correlated with its unit and the unit of heshrate eh showing that Nbtc·LgH duplex is constantly growing despite a decrease in general mass of generated bitcoins, while the relative bitcoin energy consumption decreases with time, still such decrease happens slower than the growth of its market value. © 2023 The authors and IOS Press.",TextMining
"Introduction: Marine metal contamination caused by deep-sea mining activities has elicited great concern from both social and scientific communities. Among the various metals deep-sea organisms might encounter, cadmium (Cd) is a widely detected metal that in very small amounts is nonetheless capable of severe toxicity. Yet due to both remoteness and technical challenges, insights into the effects of metal exposure resulting from mining activities upon deep-sea organisms are limited. Methods: Here, we investigated Cd’s toxicological effects on deep-sea mussels of Gigantidas platifrons exposed to 100 or 1000 g/L of Cd for 7 days; an integrated approach was used that incorporated proteomics and metabolomics along with traditional approaches (metal concentrations, metal subcellular distribution, and anti-oxidative and immune-related biochemical indexes). Results and Discussion: Results showed that Cd exposure caused significant Cd’s accumulation in mussel gills and redistribution of Cd among subcellular compartments, with cellular debris being the primary binding site. Although anti-oxidative enzymes activities (superoxide dismutase and catalase) were not significantly altered in mussel gills of both exposed groups, the markedly increased level of glutathione S-transferase detected via proteomic technique clearly evinced that deep-sea mussels suffered from oxidative stress under Cd exposure. Besides, altered activities of acid phosphatase and alkaline phosphatase assayed by traditional methods along with the predominant presence of largely altered immune-related proteins detected by proteomic data strongly revealed an immune response of deep-sea mussels elicited by Cd. In addition, results of proteomics combined with those of non-targeted metabolomics demonstrated that Cd could exert toxicity by disrupting cytoskeleton structure, ion homeostasis, and primary metabolisms of energy, lipid, and nucleotide in deep-sea mussels. As demonstrated in this study, proteomics and metabolomics can be used in tandem to provide valuable insights into the molecular mechanisms of deep-sea organisms’ response to Cd exposure and for helping to discover potential biomarkers for application during deep-sea mining assessments. Copyright © 2023 Zhou, Li, Zhong, Chen, Wang, Lian, Wang, Zhang, Cao and Li.",TextMining
"Purpose: Globally, rapid urbanisation characterised by increasing demand for housing and infrastructure needs has resulted in sand mining. In Ghana, sand mining can create or destroy the livelihoods of people in urban and rural areas. This paper examines the interaction between sand mining and land-based livelihood security in Awutu Senya District (ASD) and Awutu Senya East Municipality (ASEM). Design/methodology/approach: Based on pragmatism philosophy, the study used a mixed methods approach to collect quantitative data and qualitative data from 431 household heads, ten core staff of the Assemblies, five traditional leaders, two tipper truck drivers' associations and ten farmer groups. Statistical Product and Service Solutions, version 21 and NVivo 12 facilitated quantitative data analysis and qualitative data analysis, respectively. Findings: The study revealed that sand mining had different consequences on land-based livelihood security. Some block makers and truck drivers acknowledged positive effects of sand mining on their livelihoods while the majority of the household respondents and other key informants claimed that sand mining had negative effects on their livelihoods. Research limitations/implications: This paper focuses on two selected local government areas in Ghana. Therefore, the results may be generalised on the country with caution because local government areas have different characteristics. Further research is needed to contact the customers of sand in Accra. Originality/value: This study provides new insight into the connections between sand mining and people's livelihood security in two local government areas. It also introduces a novel idea of collaboration among stakeholders to address negative effects associated with unsustainable sand mining. © 2022, Emerald Publishing Limited.",TextMining
"Background: Except for spontaneous reporting systems, vaccine safety monitoring generally involves pre-specifying health outcomes and post-vaccination risk windows of concern. Instead, we used tree-based data-mining to look more broadly for possible adverse events after Pfizer-BioNTech, Moderna, and Janssen COVID-19 vaccination. Methods: Vaccine Safety Datalink enrollees receiving ≥1 dose of COVID-19 vaccine in 2020–2021 were followed for 70 days after Pfizer-BioNTech or Moderna and 56 days after Janssen vaccination. Incident diagnoses in inpatient or emergency department settings were analyzed for clustering within both the hierarchical ICD-10-CM code structure and the post-vaccination follow-up period. We used the self-controlled tree-temporal scan statistic and TreeScan software. Monte Carlo simulation was used to estimate p-values; p = 0.01 was the pre-specified cut-off for statistical significance of a cluster. Results: There were 4.1, 2.6, and 0.4 million Pfizer-BioNTech, Moderna, and Janssen vaccinees, respectively. Clusters after Pfizer-BioNTech vaccination included: (1) unspecified adverse effects, (2) common vaccine reactions, such as fever, myalgia, and headache, (3) myocarditis/pericarditis, and (4) less specific cardiac or respiratory symptoms, all with the strongest clusters generally after Dose 2; and (5) COVID-19/viral pneumonia/sepsis/respiratory failure in the first 3 weeks after Dose 1. Moderna results were similar but without a significant myocarditis/pericarditis cluster. Further investigation suggested the fifth signal group was a manifestation of mRNA vaccine effectiveness after the first 3 weeks. Janssen vaccinees had clusters of unspecified or common vaccine reactions, gait/mobility abnormalities, and muscle weakness. The latter two were deemed to have arisen from confounding related to practices at one site. Conclusions: We detected post-vaccination clusters of unspecified adverse effects, common vaccine reactions, and, for the mRNA vaccines, chest pain and palpitations, as well as myocarditis/pericarditis after Pfizer-BioNTech Dose 2. Unique advantages of this data mining are its untargeted nature and its inherent adjustment for the multiplicity of diagnoses and risk intervals scanned. © 2022 The Author(s)",TextMining
"In integrated circuit manufacturing, optical critical dimension measurement is an efficient and non-destructive metrology method. It is also a model-based metrology in which a numerical model of the target device is formed to simulate the optical spectrum. The result is then reconstructed by fitting the simulated spectrum to the experimentally measured optical spectrum. Normally, the measured optical spectrum contains a great deal of data points that consume the storage space, and increase the fitting time. Therefore, it is worth finding an appropriate approach to downsample these data points without losing much accuracy. To quickly and accurately extract critical data with high sensitivity, we propose a Laplace sensitivity operator that is widely used for feature extraction. Compared with traditional sensitivity calculation, the Laplace sensitivity operator focuses more on the correlation and coupling between multiple parameters. Thus, the sensitivity can be properly analyzed from different dimensions. To test the feasibility and correctness of the proposed method, three basic structures were used for single-parameter verification: thin film, one-dimensional grating, and two-dimensional grating, and a vertical gate-all-around device used for multi-parameter analysis. Using the Laplace sensitivity operator, the extracted data showed better results in most cases than those achieved by the traditional sensitivity calculation method. The data volume was compressed by approximately 70%, the result matching loss was not significantly increase in terms of the root mean square error, and the calculation speed was increased by a factor of 2.4. Compared to the traditional sensitivity operator, the Laplace sensitivity operator was able to reduce the RMSE by up to 50%. © 2023 Optica Publishing Group under the terms of the Optica Open Access Publishing Agreement.",TextMining
"The cessation of dewatering following coalfield abandonment results in the rise of minewater, which can create significant changes in the local and regional hydrogeological regime. Monitoring such change is challenging but essential to avoiding detrimental consequences such as groundwater contamination and surface flooding. Inverse modelling methods using satellite radar interferometry (InSAR) have proven capable for retrospectively mapping minewater level changes, however, there is a need for the capability to remotely monitor changes as they occur. In this study, ground deformation measurements obtained from InSAR are used to develop a method to remotely monitor the spatio-temporal rise of minewater, which could be implemented in near real-time. The approach is demonstrated over the Horlivka mining agglomeration, Ukraine, where there is no other feasible approach possible due to a lack of safe ground access. The results were blindly validated against in-situ measurements before being used to forecast the time until minewater will reach the natural water table and Earth's surface. The findings reveal that, as a result of military conflict in Donbas, an environmental catastrophe could occur where potentially radioactive minewater is forecast to reach the natural water table between May and August of 2024. © 2022 Elsevier B.V.",TextMining
"Data collection under local differential privacy (LDP) has been gradually on the stage. Compared with the implementation of LDP on the single attribute data collection, that on multi-dimensional data faces great challenges as follows: (1) Communication cost. Multivariate data collection needs to retain the correlations between attributes, which means that more complex privatization mechanisms will result in more communication costs. (2) Noise scale. More attributes have to share the privacy budget limited by data utility and privacy-preserving level, which means that less privacy budget can be allocated to each of them, resulting in more noise added to the data. In this work, we innovatively reverse the complex multi-dimensional attributes, i.e., the major negative factor that leads to the above difficulties, to act as a beneficial factor to improve the efficiency of privacy budget allocation, so as to realize a multi-dimensional data collection under LDP with high comprehensive performance. Specifically, we first present a Multivariate k-ary Randomized Response (kRR) mechanism, called Multi-kRR. It applies the RR directly to each attribute to reduce the communication cost. To deal with the impact of a large amount of noise, we propose a Markov-based dynamic privacy budget allocation mechanism Markov-kRR, which determines the present privacy budget (flipping probability) of an attribute related to the state of the previous attributes. Then, we fix the threshold of flipping times in Markov-kRR and propose an improved mechanism called MarkFixed-kRR, which can obtain more optimized utility by choosing the suitable threshold. Finally, extensive experiments demonstrate the efficiency and effectiveness of our proposed methods.  © 2023 Association for Computing Machinery.",TextMining
"IOTA blockchain system is lightweight without heavy proof-of-work mining phases, which is considered a promising service platform of Internet of Things applications. IOTA organizes ledger data in a directed acyclic graph (DAG), called Tangle, rather a chain structure as in traditional blockchains. With arriving messages, IOTA tangle grows in a special way, as multiple messages can be attached to the tangle at different locations in parallel. Hence, the network dynamics of an operational IOTA system would justify a thorough study, which is currently unexplored in the literature. In this article, we present the first theoretical modeling for the evolving IOTA tangle based on stochastic analysis. After analyzing snapshots of the real-world IOTA ledger data, our key finding suggests that IOTA tangle follows a rather atypical double Pareto Lognormal (dPLN) degree distribution. In contrast, typical power-law and exponential distributions do not accurately reflect the fact. For model parameter estimation, we further realize that using generic optimization solvers cannot yield quality fitting results. Thus, we design an alternative algorithm based on expectation-maximization (EM) framework. We evaluate the proposed model and fitting algorithm with official data provided by the IOTA Foundation. Quantitative comparisons confirm the fitting quality of our proposed model and algorithm. The whole analysis reveals a deeper understanding of the internal mechanism of the IOTA network.  © 2014 IEEE.",TextMining
"In various studies trees have been extracted and their conditions have been examined through different detection algorithms from two main data sources including (a) point cloud and (b) raster data. The output of tree extraction is the input of the next processing steps, and the importance of these outputs is proved more than before. Tree Extraction (TE) has many applications in biomass estimation, CHM extraction, etc. All of which require high accuracy and the correct position of the trees. therefore, in this study, a comparison between tree extraction algorithms in two common sources of data has been conducted. As for the raster data, all bands are first co-registered. Afterward, the trees are separated from the background by using image processing techniques such as changing the image color space and weighted averaging on different bands. Finally, TE algorithms such as watershed segmentation, valley following, local maxima, and image binarization were applied. As for the point cloud data, TE can be conducted in the object space to compensate for the methods used in the raster space with object detection algorithms e.g., the coherence between the two trees, etc. which have been discussed in detail in this paper. In the object space, three algorithms, region-based, surface normal, and Euclidean segmentation, were implemented and discussed on the same raster data set in the photogrammetric point cloud. The results show the higher accuracy of the region-based algorithm in object-space by more than 26% in comparison with the valley following algorithm in image space. © Author(s) 2023. CC BY 4.0 License.",TextMining
"The paper is aimed at a critical review of the literature dealing with text mining and sentiment analysis for stock market prediction. The aim of this work is to create a critical review of the literature, especially with regard to the latest findings of research articles in the selected topic strictly focused on stock markets represented by stock indices or stock titles. This requires examin-ing and critically analyzing the methods used in the analysis of sentiment from textual data, with special regard to the possibility of generalization and transferability of research results. For this reason, an analytical approach is also used in working with the literature and a critical approach in its organization, especially for completeness, coherence, and consistency. Based on the selected criteria, 260 articles corresponding to the subject area are selected from the world databases of Web of Science and Scopus. These studies are graphically captured through bibliometric analysis. Subsequently, the selection of articles was narrowed to 49. The outputs are synthesized and the main findings and limits of the current state of research are highlighted with possible future directions of subsequent research. © 2023 The Author(s). Published by Vilnius Gediminas Technical Univers.",TextMining
[No abstract available],TextMining
"The short-term prediction of air-conditioning (AC) energy consumption is a crucial part of building operation optimization and demand-response strategies. However, the AC energy consumption in some types of buildings can be highly stochastic due to arbitrary occupants' behavior of AC usage, which make it had to predict. Currently, very few prediction models considered the impacts of stochasticity related to occupants’ behavior of AC, which leads to less accuracy. To predict the AC energy consumption under stochastic energy use scenarios, this study proposes a behavior-orientated prediction method for short-term AC energy consumption with a case study on teaching building blocks. Firstly, cluster analysis is employed to identify typical patterns to quantify stochastic AC energy use. Then, the AC usage rate is predicted based on weighted k-Nearest-Neighbors method, which can provide a precise prediction of stochastic AC usage rate. Based on these, RandomForest method is used to develop a basic prediction model of AC energy consumption. The importance of each variable is also evaluated. Finally, an enhanced part of prediction is implemented by support vector machine to achieve higher accuracy under stochastic AC energy use scenarios. The results show that both proposed models can accurately predict the AC energy consumption, while the proposed enhanced model can reap significant accuracy improvement under the more stochastic scenarios. This study provides a new approach to predict AC energy consumption in buildings with stochastic AC energy use, which can match the real-time amount with good accuracy. The proposed model can provide an accuracy reference for the demand response strategies and optimization of AC systems operation. © 2022 Elsevier Ltd",TextMining
"Depth estimation from images is an important task using scene understanding and reconstruction. Recently, encoder-decoder type fully convolutional architectures have gained great success in the area of depth estimation. Depth extraction from aerial and satellite images is one of the important topics in photogrammetry and remote sensing. This is usually done using image pairs, or more than two images. Solving this problem using a single image is still a challenging problem and has not been completely solved. Several convolutional neural networks have been proposed to extract depth from a single image, which act as encoders and decoders. In this article, we use one of these networks, which has performed well for depth estimation, in order to extract height from aerial and satellite images. Our main goal is to investigate the performance of Google Earth satellite data in order to produce a digital elevation model. At first, we extracted the digital model of the target area using ISPRS benchmark data, then we did the same thing using Google Earth satellite images. The paper presents a convolutional neural network for computing a high-resolution depth map given a single RGB Google Earth image. The results show the proper performance of Google Earth satellite images for height extraction. We achieved values of 2.07 m and 0.36 m for the RMS and REL metrics, respectively, which are very comparable and acceptable to the values of 2.04 m and 0.39 m obtained from the ISPRS benchmark images. © Author(s) 2023. CC BY 4.0 License.",TextMining
"Tree augmented naïve Bayes classifier (TAN) has been widely used in machine learning and data mining. To improve the flexibility and classification performance of TAN, this paper proposes a Flexible Tree Augmented Naïve Bayes classifier (FTAN). In the FTAN, the mutual information contribution rate is used to measure the dependencies between attributes in the process of building the maximum weighted spanning tree. Then, a flexible filtering method is adopted to filter out edges with weak dependencies between attributes by dynamically adjusting the threshold. A range of experiments on UCI datasets reveals that the FTAN exhibits considerable advantages over other popular algorithms in terms of the 0-1 loss and class probability root mean square error. The FTAN is used to solve the problem of favourable distribution area prediction for the remaining oil and gas resources of the Jurassic Sangonghe Formation in the Junggar Basin. The application results show the effectiveness and superiority of the FTAN method, favourable areas of oil and gas resources are selected based on the FTAN prediction results. This provides a decision-making basis for optimising drilling strategies and oil and gas exploration targets. © 2022 Elsevier B.V.",TextMining
"Nowadays, adolescents would like to share their daily lives via social media platforms, which presents an excellent opportunity for us to leverage these data to develop techniques to measure their mental health status, such as depression. Previous researches focus on the more accurate detection of depression through statistical learning and ignore psychological understanding of depression. However, psychologists have given lots of theoretical evidence for depression. Such as according to cognitive psychology research, cognitive distortions will result in depression. Thus, in this study, we propose a new task, explainable depression detection, to not only automatically detect depression but also try to give clues to depression based on cognitive distortion theory. For this purpose, we construct a multi-task learning model based on a pre-trained model to detect depression and identify cognitive distortion. And we use many analytical means including word clouds for data analysis to draw our conclusion. Previous social media users' depression corpus and our cognitive distortion corpus are utilized for analysis and experiment. Our experimental results outperform the baseline results and interesting conclusions about adolescent depression are drawn. Copyright © 2023 Wang, Zhao, Lu and Qin.",TextMining
"Introduction: The uncoupling proteins (UCPs) are involved in lipid metabolism and belong to a family of mitochondrial anionic transporters. In poultry, only one UCP homologue has been identified and experimentally shown to be associated with growth, feed conversion ratio, and abdominal fat according to its predominant expression in bird muscles. In endotherm birds, cell metabolic efficiency can be tuned by the rate of mitochondrial coupling. Thus, avUCP may be a key contributor to controlling metabolic rate during particular environmental changes. Methods: This study aimed to perform a set of in-silico investigations primarily focused on the structural, biological, and biomimetic functions of avUCP. Thereby, using in silico genome analyses among 8 avian species (chicken, turkey, swallow, manakin, sparrow, wagtail, pigeon, and mallard) and a series of bioinformatic approaches, we provide phylogenetic inference and comparative genomics of avUCPs and investigate whether sequence variation can alter coding sequence characteristics, the protein structure, and its biological features. Complementarily, a combination of literature mining and prediction approaches was also applied to predict the gene networks of avUCP to identify genes, pathways, and biological crosstalk associated with avUCP function. Results: The results showed the evolutionary alteration of UCP proteins in different avian species. Uncoupling proteins in avian species are highly conserved trans membrane proteins as seen by sequence alignment, physio-chemical parameters, and predicted protein structures. Taken together, avUCP has the potential to be considered a functional marker for the identification of cell metabolic state, thermogenesis, and oxidative stress caused by cold, heat, fasting, transfer, and other chemical stimuli stresses in birds. It can also be deduced that avUCP, in migrant or domestic birds, may increase heat stress resistance by reducing fatty acid transport/b-oxidation and thermoregulation alongside antioxidant defense mechanisms. The predicted gene network for avUCP highlighted a cluster of 21 genes involved in response to stress and 28 genes related to lipid metabolism and the proton buffering system. Finally, among 11 enriched pathways, crosstalk of 5 signaling pathways including MAPK, adipocytokine, mTOR, insulin, ErbB, and GnRH was predicted, indicating a possible combination of positive or negative feedback among pathways to regulate avUCP functions. Discussion: Genetic selection for fast-growing commercial poultry has unintentionally increased susceptibility to many kinds of oxidative stress, and so avUCP could be considered as a potential candidate gene for balancing energy expenditure and reactive oxygen species production, especially in breeding programs. In conclusion, avUCP can be introduced as a pleiotropic gene that requires the contribution of regulatory genes, hormones, pathways, and genetic crosstalk to allow its finely-tuned function. Copyright © 2023 Davoodi, Ghaderi-Zefrehei, Dolatabady, Razmkabir, Kianpour, Esfahani and Smith.",TextMining
"Purpose: Data-driven quality management systems, brought about by the implementation of digitisation and digital technologies, is an integral part of improving supply chain management performance. The purpose of this study is to determine a methodology to aid the implementation of digital technologies and digitisation of the supply chain to enable data-driven quality management and the reduction of waste from manufacturing processes. Design/methodology/approach: Methodologies from both the quality management and data science disciplines were implemented together to test their effectiveness in digitalising a manufacturing process to improve supply chain management performance. The hybrid digitisation approach to process improvement (HyDAPI) methodology was developed using findings from the industrial use case. Findings: Upon assessment of the existing methodologies, Six Sigma and CRISP-DM were found to be the most suitable process improvement and data mining methodologies, respectively. The case study revealed gaps in the implementation of both the Six Sigma and CRISP-DM methodologies in relation to digitisation of the manufacturing process. Practical implications: Valuable practical learnings borne out of the implementation of these methodologies were used to develop the HyDAPI methodology. This methodology offers a pragmatic step by step approach for industrial practitioners to digitally transform their traditional manufacturing processes to enable data-driven quality management and improved supply chain management performance. Originality/value: This study proposes the HyDAPI methodology that utilises key elements of the Six Sigma DMAIC and the CRISP-DM methodologies along with additions proposed by the author, to aid with the digitisation of manufacturing processes leading to data-driven quality management of operations within the supply chain. © 2021, Rose Clancy, Dominic O'Sullivan and Ken Bruton.",TextMining
"Starting in early 2017, flualprazolam was detected in toxicology and seized drug cases across the USA. Due to the addition of fluorine to alprazolam, flualprazolam's chemistry was enough to bypass targeted toxicology confirmations, and it has become increasingly available for purchase both on the dark web and in counterfeit pills. Flualprazolam was added to the exact mass screening regiment of the Orange County forensic laboratory in December 2018. Through data mining of previously analyzed cases, data were evaluated beginning from August 2018. Flualprazolam was subsequently added to the laboratory's validated quantitative liquid chromatography dual mass spectrometry method in the summer of 2020, and all driving cases from August 2018 to June 2020 were re-analyzed to obtain concentrations. The police and drug recognition evaluation (if available) reports were collected and reviewed for all cases where flualprazolam was detected. Of the 203 cases containing quantifiable drug, the average flualprazolam concentration (median, range) was 22.8 ng/mL (15.4 ng/mL, 4.0-133.3 ng/mL). Only two cases had flualprazolam detected with no other drugs. The other most common drugs detected were cannabinoids (62%), ethanol (20%) and cocaine and/or methamphetamine (32%). The most common reason for the police investigation was an accident/collision (50%), and the most common time of officer contact was evening (18:00 to 23:59). The field sobriety test (FST) results were evaluated and showed a higher frequency of impaired performance in cases of flualprazolam in combination with other drugs. No conclusion could be made regarding the effect of flualprazolam alone on FST performance. © The Author(s) 2022. Published by Oxford University Press. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com.",TextMining
"Floods are one of the most dangerous crises that cause a lot of damage in various fields, including economic and human lives. Therefore, preparation for prevention and damage assessment in order to manage this crisis is essential. In the meantime, providing methods with high speed and accuracy together can be helpful. In this study, using the Google Earth engine system and various sources of remote sensing data, the flooded areas of 2019 in Khuzestan province of Iran were extracted and the area of damaged agricultural lands was estimated. The general method was to first use the Sentinel 1 images, which are independent of the cloud, and the JRC global surface water mapping data to obtain flooded areas. After that, with the help of Sentinel 2 images and extracting various features from its bands and implementing an automated method, a map of damaged agricultural lands was also prepared. In order to approximate the affected population, WorldPop Global Project Population data has been used to take advantage of the maximum capacity of various remote sensing sources. The resulting flood map was evaluated by a ground truth map to prove the efficiency of the method. The overall accuracy of the map was 96.30 and its kappa coefficient was 80.03, which is quantitatively appropriate. The proposed method and the system used, due to their simplicity, can be generalized at high speed to other areas. © Author(s) 2023. CC BY 4.0 License.",TextMining
"Complete and accurate accounting of greenhouse gas (GHG) emissions from coal mines in China is a critical basis for identifying mitigation potential and making reduction strategies. Previous studies based on the emission factor method and life cycle assessment are limited in accounting scope completeness, data reliability, or result applicability at multiple scales and benchmarks. The objective of this study was to carry out a multi-scale multi-benchmark GHG accounting of Chinese coal mines to build a shared understanding and facilitate discussion on this topic. We established a complete accounting model to cover upstream indirect, direct, and downstream indirect GHG emissions related to coal mining. A total of 1151 operating coal mines were investigated to model site-level carbon emissions based on mass and energy benchmarks and then aggregated to 99 cities, 19 provinces, and the country for accounting. The results showed an over 14-fold variation in mass-based site-level accounting, with the highest uncertainty of less than 15%. This variability performed almost the same at city-level aggregating, whereas narrowed to over twofold at the provincial level. Energy-based accounting presented an over 17-fold variation at the site-level with a similar uncertainty to mass-based accounting. Such variability was narrowed to over sevenfold and approximately threefold in the city- and province-level aggregations, respectively. The national average mass- and energy-based carbon footprint of coal mining were 0.39 kg CO2-eq/kg and 0.0185 kg CO2-eq/MJ, respectively, in which approximately 36% of the total GHG emissions were omitted if mining methane escape was reported only. These results suggest improving the methane utilization rate and optimizing coal production and consumption patterns, which implicates cleaner production and sustainable development strategies for the coal industry in China. The conclusions are helpful to identify individual carbon emission gaps, clarify regional emission responsibilities, coordinate the national carbon neutrality process, and promote a low-carbon coal supply system. © 2022 Elsevier Ltd",TextMining
"A dynamic optimization method was created to address the production schedule issue in an open-pit coal mine while taking into account the characteristics of the fuzzy structured element. The fuzzy mining capacities of all “geologically optimal push-back bodies” were then examined using the moving cove method. One of the most crucial elements in the process of open-pit coal mine production scheduling optimization is coal pricing. As a result, this work also presents a dynamic optimization technique for production scheduling that incorporates the prediction of economic time series and the generation of dynamic economic indices. An appropriate time series model is created to forecast the future coal price based on previous data on coal prices. The prediction results are used in the calculation of optimal mining body generation to dynamically obtain the optimal production scheduling model. The Baorixile Open-pit Coal Mine in China’s Inner Mongolia Autonomous Region is using this method. The Autoregressive Integrated Moving Average Model ARIMA is constructed to anticipate the coal price in the future 23 years by evaluating and processing the coal price from 2009 to 2022, and the ideal production scheduling scheme of the mine economics is afterwards identified. The ideal fuzzy coal mining volume, the potential production life, and the fuzzy total net present value (NPV) of the annual production scheduling are all provided at the same time. The optimization findings can better give fundamental support for mine design and future production since the fuzzy problem is accurately expressed by correct formulations. Copyright © 2023 Liu, Guo, Fu, Yang and Li.",TextMining
"Purpose: The current study aims to predict consumer complaint status (complainers or non-complainers) based on socio-demographic and psychographic factors and further to discern the differences in behavior disposition of consumer groups concerning determinants of consumer's tendency to exit (TE). Design/methodology/approach: The research used survey-based data of 600 Indian consumers of three service sectors (hotel and hospitality, automobile service centers and organized retail stores). Chi-square automatic interaction detector (CHAID) decision tree analysis was used to profile consumers. Findings: The results indicated that occupation; income; education; industry and attitude toward complaining were significant factors in profiling consumers as complainers or non-complainers. Further, determinants of TE (discouraging subjective norms, perceived likelihood of successful complaint, lower perceived switching cost, poor employee response, negative past experience and ease of complaint process) vary significantly across the groups of complainers and non-complainers. Research limitations/implications: The research questions in this study were tested with three service sectors consumers in India, so due care should be exercised in generalizing these findings to other sectors and countries. Study replication across other service sectors and countries is recommended to improve the generalizability of these findings with wider socio-demographic samples. Practical implications: Firms striving for consumer retention and aim to extend their consumer life cycle can greatly benefit from the results of this study to understand the customer complaint behavior (CCB) specific to non-complaining (exit) behavior. The future researcher may benefit from replicating and extending the model in different industries for further contribution to the CCB literature. Originality/value: To the best of the author's knowledge, there is no evidence of consumer segmentation based on their complaining behavior or socio-demographic and psychographic factors by employing CHAID decision tree analysis. In addition to illustrating the use of data mining techniques such as CHAID in the field of CCB, it also contributes to the extant literature by researching in a non-Western setting like India. © 2022, Emerald Publishing Limited.",TextMining
"Capacitive Voltage Transformer (CVT) is widely used in power system as a voltage measuring component. For a long time, the insulation supervision has been realized by means of uninterrupted infrared temperature measurement and periodic power failure preventive test. In this study, the relationship between common faults of capacitive voltage transformer and secondary voltage is analyzed first. On this basis, by adopting the data mining technology, only the existing EMS system data are used to make reasonable judgment strategies without increasing the hardware investment of the primary system of the power grid. The quasi-real-Time on-line monitoring of CVT is realized through the change law of secondary voltage. Based on this, the faults in the running of CVT can be found in time, thus avoiding the aggravation of CVT faults, and improving the reliability of power system operation.  © 2023 ACM.",TextMining
The proceedings contain 68 papers. The topics discussed include: customer informatics by embedding SMS headers; efficient depth-first search approach for mining injective general episodes; Retro-KD: leveraging past states for regularizing targets in teacher-student learning; neural networks at a fraction with pruned quaternions; gradient perturbation-based efficient deep ensembles; LCM: a surprisingly effective framework for supervised cross-modal retrieval; query-focused re-ranking to enhance the performance of text entailment and question answering; aspect-sentiment-based opinion summarization using multiple information sources; BRR-QA: boosting ranking and reading in open-domain question answering; active feature acquisition via human interaction in relational domains; generalized structured low-rank tensor learning; solving age-word problems using domain ontology and BERT; and using contrastive samples for identifying and leveraging possible causal relationships in reinforcement learning.,TextMining
"The protective role of Natural Killer (NK) cell tumour immunosurveillance has long been recognised in colorectal cancer (CRC). However, as most patients show limited intra-tumoral NK cell infiltration, improving our ability to identify those with high NK cell activity might aid in dissecting the molecular features which underlie NK cell sensitivity. Here, a novel CRC-specific NK cell gene signature that infers NK cell load in primary tissue samples was derived and validated in multiple patient CRC cohorts. In contrast with other NK cell gene signatures that have several overlapping genes across different immune cell types, our NK cell signature has been extensively refined to be specific for CRC-infiltrating NK cells. The specificity of the signature is substantiated in tumour-infiltrating NK cells from primary CRC tumours at the single cell level, and the signature includes genes representative of NK cells of different maturation states, activation status and anatomical origin. Our signature also accurately discriminates murine NK cells, demonstrating the applicability of this geneset when mining datasets generated from preclinical studies. Differential gene expression analysis revealed tumour-intrinsic features associated with NK cell inclusion versus exclusion in CRC patients, with those tumours with predicted high NK activity showing strong evidence of enhanced chemotactic and cytotoxic transcriptional programs. Furthermore, survival modelling indicated that NK signature expression is associated with improved survival outcomes in CRC patients. Thus, scoring CRC samples with this refined NK cell signature might aid in identifying patients with high NK cell activity who could be prime candidates for NK cell directed immunotherapies. Copyright © 2023 Shembrey, Foroutan and Hollande.",TextMining
"The sequential recommendation (also known as the next-item recommendation), which aims to predict the following item to recommend in a session according to users' historical behavior, plays a critical role in improving session-based recommender systems. Most of the existing deep learning-based approaches utilize the recurrent neural network architecture or self-Attention to model the sequential patterns and temporal influence among a user's historical behavior and learn the user's preference at a specific time. However, these methods have two main drawbacks. First, they focus on modeling users' dynamic states from a user-centric perspective and always neglect the dynamics of items over time. Second, most of them deal with only the first-order user-item interactions and do not consider the high-order connectivity between users and items, which has recently been proved helpful for the sequential recommendation. To address the above problems, in this article, we attempt to model user-item interactions by a bipartite graph structure and propose a new recommendation approach based on a Position-enhanced and Time-Aware Graph Convolutional Network (PTGCN) for the sequential recommendation. PTGCN models the sequential patterns and temporal dynamics between user-item interactions by defining a position-enhanced and time-Aware graph convolution operation and learning the dynamic representations of users and items simultaneously on the bipartite graph with a self-Attention aggregator. Also, it realizes the high-order connectivity between users and items by stacking multi-layer graph convolutions. To demonstrate the effectiveness of PTGCN, we carried out a comprehensive evaluation of PTGCN on three real-world datasets of different sizes compared with a few competitive baselines. Experimental results indicate that PTGCN outperforms several state-of-The-Art sequential recommendation models in terms of two commonly-used evaluation metrics for ranking. In particular, it can make a better trade-off between recommendation performance and model training efficiency, which holds great potential for online session-based recommendation scenarios in the future. © 2023 Association for Computing Machinery.",TextMining
"The development of electric vehicles (EVs) is a sure way for China to achieve the ""double carbon"" goal and move from a large-scale to a powerful automobile country. Electric vehicles have transformed from simple vehicles to energy storage units, intelligent mobile terminals, and digital spaces. Furthermore, autonomous driving is becoming an important technology to promote the reform of transportation modes, making wireless charging an inevitable choice for intelligent driverless and shared EVs in the future. However, the existing vehicle and network information interaction mode is challenging to conduct multi-level information fusion and decision-making for future scenarios. It is inseparable from the construction of intelligent wireless charging cloud networks to achieve and ensure the interconnection of energy and information. How to use advanced technologies such as cloud computing, big data, internet of things, artificial intelligence, and blockchain to build an intelligent wireless EV charging cloud network, to realize the closed-loop of vehicle, network, road, and cloud data, and form an efficient collaboration and resource optimization and matching among various elements, are critical problems. Therefore, there are vital issues to be considered and explored. This paper addresses the motivations for constructing an intelligent wireless power transmission cloud network for EVs. Critical challenges and suggestions for cloud network construction are outlined in the rest of the paper. Firstly, the natural energy storage attribute of massive numbers of electric vehicles is highlighted. The power exchange between the vehicle and grid (V2G) is reviewed from state-of-the-art and developing trends. Wireless V2G is discussed under the background of EV development. Establishing real-time electricity prices brings economic benefits to both car owners and charging operators. The combination of the electricity economy and V2G gives prominence to excellent business potential. Wireless vehicle-to-vehicle (V2V) emerges under this trend. With the increasing number of electric vehicles, it will generate considerable storage and better use of electric vehicles' energy. Participating in the vehicle network interaction can improve the distribution and mobility of the energy storage unit and enhance the electrical. The stability of the force system has practical significance. Secondly, the planning of the intelligent wireless power transmission cloud network for EVs is proposed. The cloud network platform aims to build a service platform for the Internet of Vehicles and provide a more efficient, convenient, and safe service guarantee for the travel of electric vehicles. According to the degree of automation of electric vehicles, electric vehicles can be categorized into crewed electric vehicles, hybrid (semi-automatic) electric vehicles, and autonomous electric vehicles. Different types of electric vehicles have different functional requirements for the cloud platform. The platform has great potential to support highly efficient energy exchange between the grid and vehicles. Traffic efficiency and traveling sharing can be improved based on the platform. Relevant departments should make overall arrangements, actively respond to the needs of cloud network construction, and play a leading role in policy guidance. Finally, critical problems need to be concerned during the construction. Floor planning needs to be considered from the view of land, transportation, construction, and other aspects. Diversified charging scenarios are to be discovered to meet the growing development. Digital security issues are to be ensured, and third-party platform construction and supervision are suggested. How to achieve efficient cloud information management is also critical for power exchange. New technologies such as big data, data mining, blockchain, and intelligent algorithms are to be adopted to unite the cloud network. Operation and profit models are essential factors to support the cloud network. Space electromagnetic safety problems are another vital issue to be considered both from the electromagnetic compatibility and bio-safety aspects. Establishing an intelligent wireless EV charging cloud network will be of great practical significance to transforming EV form, transportation mode, and energy consumption structure. It greatly meets people's pursuit of easy traffic. © 2023 Chinese Machine Press. All rights reserved.",TextMining
"Objective: This study aimed to understand the noise exposure of non-coal mines in China to take appropriate controls to protect workers' health. Methods: An assessment of non-coal miners' noise exposures was conducted in four provinces in China. Individual noise exposure levels were measured, and the survey on the hearing protector device (HPD) equipment was administered. Results: 423 noise dosimeter measurements were obtained, including drilling, blasting, ore drawing, transportation, winching, crushing, screening and ball milling, and auxiliary (air pressure, pump, and maintenance). A total of 31.9% of the individual noise levels (LEX,8h) exceeded 85 dB(A), and the median dosages of non-coal miners with high noise exposure were: excavation workers-89.1 dB(A), mill operators-88.7 dB(A), and crusher operators-87.0 dB(A). The noise dose of underground mine workers is higher than that of surface mine workers (P < 0.001). A total of 53.7% of non-coal mining enterprises are not equipped with HPD for workers, mainly small and micro enterprises. Conclusions: High levels of hazardous noise exposure are typical in non-coal mines. Noise exposure data can help to develop more feasible noise controls. Copyright © 2023 Wang, Kang, Dong, Liu, Ning, Bian, Han, Chen and Ye.",TextMining
"Medicago ruthenica, important forage in the legume family, possesses high nutritional value and carries abundant tolerance genes. This study used whole-genome data of M. ruthenica to perform a genome-wide analysis of the nucleotide-binding site-leucine-rich repeat receptor (NLR) gene family, which is the largest family of plant disease resistance genes (R genes). A total of 338 NLR genes were identified in the M. ruthenica genome, including 160 typical genes that contained 80 coiled-coil (CC)-NBS-LRR (CNL) genes, 76 toll/interleukin-1 receptor (TIR)-NBS-LRR (TNL) genes, four resistance to powdery mildew 8 (RPW8)-NBS-LRR (RNL) subclass genes, and 178 atypical NLR genes encoding proteins without at least one important domain. Among its eight chromosomes, M. ruthenica chromosomes 3 and 8 contained most of the NLR genes. More than 40% of all NLR genes were located on these two chromosomes, mainly in multigene clusters. The NLR proteins of M. ruthenica had six highly conserved motifs: P-loop, GLPL, RNBS-D, kinase-2, RNBS-C, and MHDV. Phylogenetic analysis revealed that the NLR genes of M. ruthenica formed three deeply separated clades according to the N-terminal domain of the proteins encoded by these genes. Gene duplication and syntenic analysis suggested four gene duplication types in the NLR genes of M. ruthenica, namely, tandem, proximal, dispersed, and segmental duplicates, which involved 189, 49, 59, and 41 genes, respectively. A total of 41 segmental duplication genes formed 23 NLR gene pairs located on syntenic chromosomal blocks mainly between chromosomes 6 and 7. In addition, syntenic analysis between M. truncatula and M. ruthenica revealed 193 gene pairs located on syntenic chromosomal blocks of the two species. The expression analysis of M. ruthenica NLR genes showed that 303 (89.6%) of the NLR genes were expressed in different varieties. Overall, this study described the full NLR profile of the M. ruthenica genome to provide an important resource for mining disease-resistant genes and disease-resistant breeding. Copyright © 2023 Tong, Zhang and Shi.",TextMining
"The extensive application of power electronic equipment and the increasing penetration of renewable energy generation gradually strengthen the nonlinear and modal-coupling characteristics of electromechanical oscillation of modern power systems. In this study, a data-driven method based on improved blind source separation (IBSS) combined with sparse component analysis (SCA) is proposed to extract electromechanical mode (oscillation frequency, damping ratio and mode shape) from synchrophasor measurements. First, short time Fourier transform is used to convert the modal-coupling oscillation signal to sparse domain, then, on the basis of time-frequency point clustering characteristics of source signals, the mixture matrix A is estimated by frequency energy peak point algorithm, and L1 norm is utilized to separate each mode from mixture matrix A. Finally, the Hilbert identification algorithm is applied to extract the oscillation parameters. The performance of the proposed IBSS method for the mode extraction is verified using the test signal, the simulation signal, and the measured data. Copyright © 2023 Wang, Lyu, Li, Zhang and Wang.",TextMining
"An updated LncTarD 2.0 database provides a comprehensive resource on key lncRNA–target regulations, their influenced functions and lncRNA-mediated regulatory mechanisms in human diseases. LncTarD 2.0 is freely available at (http://bio-bigdata.hrbmu.edu.cn/LncTarD or https://lnctard.bio-database.com/). LncTarD 2.0 was updated with several new features, including (i) an increased number of disease-associated lncRNA entries, where the current release provides 8360 key lncRNA–target regulations, with 419 disease subtypes and 1355 lncRNAs; (ii) predicted 3312 out of 8360 lncRNA–target regulations as potential diagnostic or therapeutic biomarkers in circulating tumor cells (CTCs); (iii) addition of 536 new, experimentally supported lncRNA–target regulations that modulate properties of cancer stem cells; (iv) addition of an experimentally supported clinical application section of 2894 lncRNA–target regulations for potential clinical application. Importantly, LncTarD 2.0 provides RNA-seq/microarray and single-cell web tools for customizable analysis and visualization of lncRNA–target regulations in diseases. RNA-seq/microarray web tool was used to mining lncRNA–target regulations in both disease tissue samples and CTCs blood samples. The single-cell web tools provide single-cell lncRNA–target annotation from the perspectives of pan-cancer analysis and cancer-specific analysis at the single-cell level. LncTarD 2.0 will be a useful resource and mining tool for the investigation of the functions and mechanisms of lncRNA deregulation in human disease. © The Author(s) 2022. Published by Oxford University Press on behalf of Nucleic Acids Research.",TextMining
"Pangolins are scaly and toothless mammals which are distributed across Africa and Asia. Currently, the Malayan, Chinese and Philippine pangolins are designated as critically endangered species. Although few pangolin viruses have been described, their viromes have received more attention following the discovery that they harbour sarbecoviruses related to SARSCoV-2. Using large-scale genome mining, we discovered novel lineages of papillomaviruses infecting the Malayan and Chinese pangolins. We were able to assemble three complete circular papillomavirus genomes with an intact coding capacity and five additional L1 genes encoding the major capsid protein. Phylogenetic analysis revealed that seven out of eight L1 sequences formed a monophyletic group which is the sister lineage to the Tupaia belangeri papillomavirus 1, isolated from Yunnan province in China. Additionally, a single L1 sequence assembled from a Chinese pangolin was placed in a clade closer to Alphapapillomavirus and Omegapapillomavirus. Examination of the SRA data from 95 re-sequenced genomes revealed that 49.3% of Malayan pangolins and 50% of Chinese pangolins were positive for papillomavirus reads. Our results indicate that pangolins in South-East Asia are the hosts of diverse and highly prevalent papillomaviruses, and highlight the value of in silico mining of host sequencing data for the discovery of novel viruses. © 2023 The Authors.",TextMining
"Using data mining to improve the efficiency of government governance in the context of carbon neutrality is an important way to achieve the modernization of the national governance system. This study starts with the logic of carbon neutral issues, analyzes the factors and indicators that affect the effectiveness of social governance, and constructs the evaluation index system of government social governance efficiency based on data mining application under the background of carbon neutral, including per capita GDP, per capita domestic power consumption of residents, per capita CO2 emissions, per capita green area, industrial waste gas treatment rate, industrial wastewater discharge compliance rate and other indicators, which includes 4 first-class indicators, 19 second-class indicators and 38 third class indicators. Then, the CV-CRITICAL (coefficient of variation critical) index weight determination algorithm is used to determine the index weight. The Pearson correlation coefficient method is used to evaluate the correlation between the two vectors, and then the rationality of the government social governance efficiency evaluation index system based on data mining applications is evaluated. The evaluation results show that the level of social governance effectiveness of the Chinese government is on the rise from 2016 to 2021. This study promotes the application of improving the efficiency of government social governance in the context of carbon neutrality, and provides tools for relevant assessment through data mining technology. This research can not only deepen the theoretical connotation of government governance effectiveness, but also help promote the application of big data in government governance practice. Copyright © 2023 Feng and Pi.",TextMining
"By using the PoW protocol, mining pools compete to successfully mine blocks to pursue rewards. Generally, the reward from a mined block includes the fixed block subsidies and the time-varying transaction fees. The latter are offered by the senders whose transactions are packaged into blocks and are increasing with the block size being larger. However, the larger block size brings the longer latency, resulting in a smaller probability of successfully mining. Therefore, decision on the optimal block size of a block to trade off two factors above mentioned is a complex and crucial problem for the mining pools. In this paper, we model the repeated mining competition dynamics among mining pools as an evolutionary game, in which each mining pool has two strategies: following the upper bound of block size B¯, or selecting a block size smaller than B¯. Because of the bounded rationality, each mining pool pursues its evolutionary stable strategy (ESS) on block size by continuous learning and adjustments during the whole mining process. A framework is built for the general evolutionary game, based on which we then explore the existence and stability of the ESSs for a case of two mining pools. Numerical experiments using the real Bitcoin data are conducted to demonstrate the theoretical results in this paper. © 2022",TextMining
"Data mining is a growing domain. Wherever we are going, data mining Techniques are available to collect important information from the warehouse or from databases. In every sector, they need to keep data secure. Maintaining a balanced state of data is very crucial. Whenever a class tends to classify, the specimens in the class can be grouped as the majority group and the minority group. The majority group consists of higher number of data when compared with the data distributed in the minority group. This paper proposes the Randomized-Ensemble with Smote (RESMOTE) methodology to handle the class imbalance problem. This paper addresses imbalance issues and proposes a class imbalance solution using a sampling technique combined with certain classification metrics. © 2023 The authors and IOS Press.",TextMining
"The extracellular matrix (ECM) is a complex assembly of proteins that constitutes the scaffold organizing cells, tissues, and organs. Over the past decade, mass-spectrometry-based proteomics has become the method of choice to profile the composition of the ECM, or the matrisome, of tissues. To assist non-specialists with the reuse of ECM proteomic datasets, we released MatrisomeDB (https://matrisomedb.org) in 2020. Here, we report the expansion of the database to include 25 new curated studies on the ECM of 24 new tissues in addition to datasets on tissues previously included, more than doubling the size of the original database and achieving near-complete coverage of the in-silico predicted matrisome. We further enhanced data visualization by maps of peptides and post-translational-modifications detected onto domain-based representations and 3D structures of ECM proteins. We also referenced external resources to facilitate the design of targeted mass spectrometry assays. Last, we implemented an abstract-mining tool that generates an enrichment word cloud from abstracts of studies in which a queried protein is found with higher confidence and higher abundance relative to other studies in MatrisomeDB.  © 2023 The Author(s).",TextMining
"Various significant methodologies have been developed in classifying chronic kidney disease (CKD). But still, there emerge certain drawbacks, including high storage space requirements, increased diagnosis time, high cost of computation, and degraded accuracy. Hence in the proposed research work, Ebola deep wavelet extreme learning machine (EDWELM) is proposed for the precise classification of CKD and non-CKD. Initially, the accessed data are preprocessed by transforming categorical to numerical values and replacing missing values with median to remove unwanted distortions. In the feature selection process, the hybrid methodology of Darts game and Battle royale optimization called Darts Battle game optimizer is carried out to choose the most discriminative features for improving classification accuracy. The final step undertaken is the classification process, which is one of the important data mining applications for distinguishing the data classes. In the proposed EDWELM classification method, ELM based autoencoder, wavelet neural network, and Ebola optimization search algorithm are carried out for effective CKD classification. From the CKD dataset, the performance is analyzed to various terms like accuracy, F1 score, precision, recall, kappa, and balanced score. The accuracy of 99.83% is attained by the proposed EDWELM classification method, which is comparatively better than the existing approaches. © 2022 John Wiley & Sons, Ltd.",TextMining
"Background: Comorbid anxiety and depression are common and are associated with greater disease burden than either alone. Our recent efforts have identified an association between gut microbiota dysfunction and severity of anxiety and depression. In this follow-up, we applied Differential Co-Expression Analysis (DiffCoEx) to identify potential gut microbiota biomarker(s) candidates of treatment resistance among psychiatric inpatients. Methods: In a sample of convenience, 100 psychiatric inpatients provided clinical data at admission and discharge; fecal samples were collected early during the hospitalization. Whole genome shotgun sequencing methods were used to process samples. DiffCoEx was used to identify clusters of microbial features significantly different based on treatment resistance status. Once overlapping features were identified, a knowledge-mining tool was used to review the literature using a list of microbial species/pathways and a select number of medical subject headlines (MeSH) terms relevant for depression, anxiety, and brain-gut-axis dysregulation. Network analysis used overlapping features to identify microbial interactions that could impact treatment resistance. Results: DiffCoEx analyzed 10,403 bacterial features: 43/44 microbial features associated with depression treatment resistance overlapped with 43/114 microbial features associated with anxiety treatment resistance. Network analysis resulted in 8 biological interactions between 16 bacterial species. Clostridium perfringens evidenced the highest connection strength (0.95). Erysipelotrichaceae bacterium 6_1_45 has been most widely examined, is associated with inflammation and dysbiosis, but has not been associated with depression or anxiety. Conclusion: DiffCoEx potentially identified gut bacteria biomarker candidates of depression and anxiety treatment-resistance. Future efforts in psychiatric microbiology should examine the mechanistic relationship of identified pro-inflammatory species, potentially contributing to a biomarker-based algorithm for treatment resistance. © 2022 Elsevier Inc.",TextMining
"Detection of fraudulent financial stewardship in the cash flow section is an exciting thing and is rarely studiThis research empirically tests the discovery of fraudulent financial statements based on basic cash flow shenanigans. Thsample of this study amounted to 470 data mining companies in Indonesia, Malaysia, China, and Japan. The analysis metod used is a positive approach. The results show that all ratios used can predict fraudulent financial statements. Three ratiof cash flow shenanigans, namely change in receivable to cash flow operations, days payable outstanding, and change inventory to cash flow operations, significantly affect the F-Score. Meanwhile, the six cash flow shenanigans ratios, namcash flow operations to current liability, operating cash flow ratio, free cash flow, cash flow operations to total liability, dapayable outstanding, and change in inventory to cash flow operations, have a significant effect on the M-Score. © 2023 The Author(s). Published by Vilnius Gediminas Technical University.",TextMining
"Background: In recent years, hepatic arterial infusion chemotherapy (HAIC) has gained popularity in the treatment of hepatocellular carcinoma. Although several studies have been published, no bibliometric analysis have been conducted on this topic. Objectives: To understand the development status and future trends in the application of HAIC, we conducted bibliometric analysis to examine the cooperation and influence among countries, institutions, authors, and journals. Methods: All relevant articles and reviews on the use of HAIC in HCC treatment were retrieved from the Web of Science database. A bibliometric analysis of countries, institutions, journals, authors, and keywords related to this field was performed using R and VOSviewer software. The main aspects analyzed were the research status and key fields of HAIC in HCC treatment. Results: A total of 1026 articles published in 292 journals by 4937 authors from 959 institutions between 1974 and 2021 were retrieved. A rapid increase in articles published after 1990 was observed, which reached the peak in 2021. Japan had the most publications and citations. Yonsei University, Sun Yat-sen University, and Hiroshima University were the three leading institutions in research on this topic. Kwang-Hyub Han and Masatoshi Kudo have the greatest academic influence in this field. Most publications were made in the Hepato-Gastroenterology, whereas cancer had the most citations. The main aspects of HAIC treatment of HCC include HAIC and TACE, chemotherapy drug selection, HAIC and targeted therapy and immunotherapy, HAIC and surgery, and hepatotoxicity. Keywords such as FOLFOX, lenvatinib, hepatic arterial infusion chemotherapy are hot words in this field in recent years. Conclusion: The research on the use of HAIC in the treatment of HCC has been on the rise. Currently, HAIC combined with targeted therapy or immunotherapy has attracted significant attention. Copyright © 2023 Li, Zhang, He, Zhang, Lv, Wang, Xing and Yu.",TextMining
"Bibliometric Analysis on Privacy Preserving concept during the years 2014 to 2022 is performed on Scopus database. Total documents under study were 22887. The parameters used for the analysis include source, year, area, Country, University, author and funding agency. Other parameters used for Network analysis were Co-authorship, Co-occurrence, Citation, Co-citation and Bibliographic coupling. The tool supported this analysis was VOSviewer 1.6.16. All Tables and figures were taken from www.scopus.com, The analysis was carried on 08th October, 2021. © 2023 The authors and IOS Press.",TextMining
"Erno Tárkány Szücs was a prominent figure in Hungarian social ethnography between 1944 and 1984. His involvement in the movement for collecting legal folk customs began as a university student in 1941. Among his professors and mentors, he was particularly influenced by György Bónis, Károly Viski, and József Venczel. His first large-scale study, published in 1944, was a presentation of legal folklore from the village of Mártély. At the same time, he investigated the folk laws related to sheep farming and the legal customs with respect to inheritance in the Hungarian villages in Transylvania. He published two substantial volumes containing the wills of peasant citizens of Hódmezovásárhely written between 1730 and 1796, and later the testaments of serf farmers from the town of Makó. He published a data collection containing around 10,000 ownership certificates and an analytical study in German on the branding of horses and cattle, accompanied by illustrations. He carried out research on the legal customs associated with Hungarian mining in the 17th to 19th centuries and elaborated Hungary's draft mining law. His principal work - on Hungarian Legal Folk Customs - is a substantial, comprehensive, and incomparably rich corpus of legal ethnography and the history of law. His work also gained recognition abroad: he spoke at many international conferences and was elected as a member of several international organizations.  © 2022 The Author(s).",TextMining
"Purpose: This study aims to develop a hierarchical topic analysis tool (HTAT) based on hierarchical Latent Dirichelet allocation (hLDA) to support digital humanities research that is associated with the need of topic exploration on the Digital Humanities Platform for Mr. Lo Chia-Lun’s Writings (DHP-LCLW). HTAT can assist humanities scholars on distant reading with analysis of hierarchical text topics, through classifying time-stamped texts into multiple historical eras, conducting hierarchical topic modeling (HTM) according to the texts from different eras and presenting through visualization. The comparative network diagram is another function provided to assist humanities scholars in comparing the difference in the topics they wish to explore and to track how the concept of a topic changes over time from a particular perspective. In addition, HTAT can also provide humanities scholars with the feature to view source texts, thus having high potential to be applied in promoting the effectiveness of topic exploration due to simultaneously integrating both the topic exploration functions of distant reading and close reading. Design/methodology/approach: This study adopts a counterbalanced experimental design to examine whether there is significant differences in the effectiveness of topic inquiry, the number of relevant topics inquired and the time spent on them when research participants were alternately conducting text exploration using DHP-LCLW with HTAT or DHP-LCLW with Single-layer Topic Analysis Tool (SLTAT). A technology acceptance questionnaire and semi-structured interviews were also conducted to understand the research participants' perception and feelings toward using the two different tools to assist topic inquiry. Findings: The experimental results show that DHP-LCLW with HTAT could better assist the research participants, in comparison with DHP-LCLW with SLTAT, to grasp the topic context of the texts from two particular perspectives assigned by this study within a short period. In addition, the results of the interviews revealed that DHP-LCLW with HTAT, in comparison with SLTAT, was able to provide a topic terms that better met research participnats' expectations and needs, and effectively guided them to the corresponding texts for close reading. In the analysis of technology acceptance and interview data, it can be found that the research participants have a high and positive tendency toward using DHP-LCLW with HTAT to assist topic inquiry. Research limitations/implications: The Jieba Chinese word segmentation system was used in the Mr. Lo Chia-Lun’s Writings Database in this study, to perform word segmentation on Mr. Lo Chia-Lun’s writing texts for topic modeling based on hLDA. Since Jieba word segmentation system is a lexicon based word segmentation system, it cannot identify new words that have still not been collected in the lexicon well. In this case, the correctness of word segmentation on the target texts will affect the results of hLDA topic modeling, and the effectiveness of HTAT in assisting humanities scholars for topic inquiry. Practical implications: An HTAT was developed to support digital humanities research in this study. With HTAT, DHP-LCLW provides hmanities scholars with topic clues from different hierarchical perspectives for textual exploration, and with temporal and comparative network diagrams to assist humanities scholars in tracking the evolution of the topics of specific perspectives over time, to gain a more comprehensive understanding of the overall context of the texts. Originality/value: In recent years, topic analysis technology that can automatically extract key topic information from a large amount of texts has been developed rapidly, but the topics generated from traditional topic analysis models like LDA (Latent Dirichelet allocation) make it difficult for users to understand the differences in the topics of texts with different hierarchical levels. Thus, this study proposes HTAT which uses hLDA to build a hierarchical topic tree with a tree-like structure without the need to define the number of topics in advance, enabling humanities scholars to quickly grasp the concept of textual topics and use different hierarchical perspectives for further textual exploration. At the same time, it also provides a combination function of temporal division and comparative network diagram to assist humanities scholars in exploring topics and their changes in different eras, which helps them discover more useful research clues or findings. © 2022, Emerald Publishing Limited.",TextMining
"This chapter illustrates the basic concepts of fault localization using a data mining technique. It utilizes the Trityp program to illustrate the general method. Formal concept analysis and association rule are two well-known methods for symbolic data mining. In their original inception, they both consider data in the form of an object-attribute table. In their original inception, they both consider data in the form of an object-attribute table. The chapter considers a debugging process in which a program is tested against different test cases. Two attributes, PASS and FAIL, represent the issue of the test case. The chapter extends the analysis of data mining for fault localization for the multiple fault situations. It addresses how data mining can be further applied to fault localization for GUI components. Unlike traditional software, GUI test cases are usually event sequences, and each individual event has a unique corresponding event handler. © 2023 The Institute of Electrical and Electronics Engineers, Inc. All rights reserved.",TextMining
"Sand mining, which has tripled in the last two decades, is an emerging concern for global biodiversity. However, the paucity of sand mining data worldwide prevents understanding the extent of sand mining impacts and how it affects wildlife populations and ecosystems, which is critical for timely mitigation and conservation actions. Integrating remote sensing and field surveys over 14 years, we investigated mining impacts on the critically endangered Yangtze finless porpoise (Neophocaena asiaeorientalis asiaeorientalis) in Dongting Lake, China. We found that sand mining presented a consistent, widespread disturbance in Dongting Lake. Porpoises strongly avoided mining sites, especially those of higher mining intensity. The extensive sand mining significantly contracted the porpoise's range and restricted their habitat use in the lake. Water traffic for sand transportation further blocked the species's river-lake movements, affecting the population connectivity. In addition, mining-induced loss of near-shore habitats, a critical foraging and nursery ground for the porpoise, occurred in nearly 70% of the water channels of our study region. Our findings provide the first empirical evidence of the impacts of unregulated sand extractions on species distribution. Our spatio-temporally explicit approach and findings support regulation and conservation, yielding broader implications for sustainable sand mining worldwide.  © 2023 The Author(s)",TextMining
"Objectives: The study aimed to conduct a bibliometric analysis of publications concerning lumbar spondylolisthesis, as well as summarize its research topics and hotspot trends with machine-learning based text mining. Methods: The data were extracted from the Web of Science Core Collection (WoSCC) database and then analyzed in Rstudio1.3.1 and CiteSpace5.8. Annual publication production and the top-20 productive authors over time were obtained. Additionally, top-20 productive journals and top-20 influential journals were compared by spine-subspecialty or not. Similarly, top-20 productive countries/regions and top-20 influential countries/regions were compared by they were developed countries/regions or not. The collaborative relationship among countries and institutions were presented. The main topics of lumbar spondylolisthesis were classified by Latent Dirichlet allocation (LDA) analysis, and the hotspot trends were indicated by keywords with strongest citation bursts. Results: Up to 2021, a total number of 4,245 articles concerning lumbar spondylolisthesis were finally included for bibliometric analysis. Spine-subspecialty journals were found to be dominant in the productivity and the impact of the field, and SPINE, EUROPEAN SPINE JOURNAL and JOURNAL OF NEUROSURGERY-SPINE were the top-3 productive and the top-3 influential journals in this field. USA, Japan and China have contributed to over half of the publication productivity, but European countries seemed to publish more influential articles. It seemed that developed countries/regions tended to produce more articles and more influential articles, and international collaborations mainly occurred among USA, Europe and eastern Asia. Publications concerning surgical management was the major topic, followed by radiographic assessment and epidemiology for this field. Surgical management especially minimally invasive technique for lumbar spondylolisthesis were the recent hotspots over the past 5 years. Conclusions: The study successfully summarized the productivity and impact of different entities, which should benefit the journal selection and pursuit of international collaboration for researcher who were interested in the field of lumbar spondylolisthesis. Additionally, the current study may encourage more researchers joining in the field and somewhat inform their research direction in the future. 2023 Fan, Li, Yang, Qin, Huang, Liu, He and Liao.",TextMining
"Aiming at the problems that the current decision-making model of ship collision avoidance does not consider International Regulations for Preventing Collisions at Sea (COLREGS), ship maneuverability, and the need for a lot of training time, combined with the advantages of reinforcement learning and imitation learning, a ship intelligent collision avoidance decision-making model based on Generic Adversary Imitation Learning (GAIL) is proposed: Firstly, the collision avoidance data in Automatic Information System (AIS) data is extracted as expert data; Secondly, in the generator part, the environment model is established based on Mathematical Model Group (MMG) and S-57 chart rendering, and the state space, behaviour space and reward function of reinforcement learning are constructed. The deep deterministic policy gradient (DDPG) is used to interact with the environment model to generate ship trajectory data. At the same time, the generator can constantly learn expert data; Finally, a discriminator can distinguish the expert data from the data generated by the generator is constructed and trained. The model training is completed when the discriminator cannot distinguish the two. In order to verify the performance of the model, AIS data near the South China Sea is used to process and extract collision avoidance decision data, and a ship intelligent collision avoidance decision model based on GAIL is established. After the model converges, the final generated data is compared with the expert data. The experimental results verify that the model proposed in this paper can reproduce the expert collision avoidance trajectory and is a practical decision model of ship collision avoidance.  © 2023 ACM.",TextMining
"Big data facial image is an important identity information for people. However, facial image inpainting using existing deep learning methods has some problems such as insufficient feature mining and incomplete semantic expression, leading to output image artifacts or fuzzy textures. Therefore, it is of practical significance to study how to effectively restore an incomplete facial image. In this study, we proposed a facial image inpainting method using a multistage generative adversarial network (GAN) and the global attention mechanism (GAM). For the overall network structure, we used the GAN as the main body, then we established skip connections to optimize the network structure, and used the encoder–decoder structure to better capture the semantic information of the missing part of a facial image. A local refinement network has been proposed to enhance the local restoration effect and to weaken the influence of unsatisfactory results. Moreover, GAM is added to the network to magnify the interactive features of the global dimension while reducing information dispersion, which is more suitable for restoring human facial information. Comparative experiments on CelebA and CelebA-HQ big datasets show that the proposed method generates realistic inpainting results in both regular and irregular masks and achieves peak signal-to-noise ratio (PSNR) and structural similarity (SSIM), as well as other evaluation indicators that illustrate the performance and efficiency of the proposed model. Copyright © 2023 Lu, Lu, Zhao and Ma.",TextMining
"A major safety accident will be triggered when the A-annular pressure value of high pressure, high productivity and high sulfur gas well exceeded the maximum allowable value. The A-annular pressure value of high pressure high productivity and high sulfur gas well once exceeded the allowable value will trigger a major safety accident. Therefore, this paper proposed a data mining based the gas well early warning strategy by analyzing the annular pressure mechanism and the change in the pattern of instantaneous gas volume, well temperature, and annular pressure in various conditions. To summarize, the law of gas well abnormal A-annular pressure is aimed at constructing a gas well safety warning rule for gas well stable production stage and shutdown period where the initial parameters setting in the early warning rule and adjustment optimization mechanism is also determined. Lastly, with the use of historical abnormal samples, the gas well early warning strategy bought up in this paper was verified. The example shown that compared with the traditional DCS system warning strategy, the gas well safety early warning strategy can identify the abnormal A-annular pressure phenomenon 82 h in advance thus achieving production safety management. Copyright © 2023 Yan, Qi, Wu, Wang and Zhong.",TextMining
"We study how natural resource rents affect the selection and behavior of holders of public office. Using global price shocks to thirty-one minerals and nationwide geological and political data from India, we show that local mineral rent shocks cause the election of politicians charged with serious crimes. We also find a moral hazard effect: politicians commit more crimes and accumulate greater wealth when mineral prices rise during their terms in office. These politicians have direct influence over mining operations but no access to fiscal windfalls from mining; we thus isolate the direct political impacts of mining sector operations. © 2021 The President and Fellows of Harvard College and the Massachusetts Institute of Technology.",TextMining
"The evolution of high technology in recent years has allowed the biomedical science sector to improve many of its processes, devices and treatments. With the emergence and reinforcement of artificial intelligence, virtual reality, Big Data and the Internet of Things (IoT), they become allies which are representing a great improvement for these industrial sectors. Process sources may include databases, data warehouses, and other information repositories in the biomedical sciences. Thus, in the current context, the technologies called IoT have become a provider of information and data on a large scale. © GKA Ediciones, authors. All rights reserved.",TextMining
"Wind data from air pollutant observation networks and meteorological stations are used to analyze the characteristics of river-land breeze near Tongling city (a main mining city in the Yangtze River Delta). The inhomogeneous distribution of pollutant matters near Tongling city due to river-land breeze is also investigated. Our results show the following conclusions. 1) The river breeze during the daytime is stronger than the land breeze at night. And the speed of river-land breeze is increased rapidly from 7:00 and arrived at the maximum at 12:00. After 15:00, the speed is slowed rapidly. 2) The river-land breeze in city area (east of Yangtze River, speed is.07 m/s) is weaker than the natural area (west of Yangtze River, speed is 0.18 m/s). Furthermore, the seasonal variations of breeze both in the west and east sides are different. In west side, the breeze is strongest in spring. And in the east side, the breeze is strongest in summer. 3) Under a weak breeze (≤0.45 m/s), the PM10 is moved by the breeze within the region and causes the heterogeneity. While with a strong breeze (>0.45 m/s), the PM10 is transported out of the region, and the PM10 concentration becomes homogenous. 4) The river breeze leads to a reduction of the pollutant concentration near the Yangtze River, but an increase in the city due to the transportation of pollutant particles from coast to city at daytime. Copyright © 2023 Zhang, Wang, Hong, Wang and Huang.",TextMining
"In this article, it is aimed to classify research articles according to their subjects by using text mining method. The data set used for the study consists of research articles that are obtained by writing Python code with a state-of-the-art web mining method. The collection of texts includes articles from the “Medicine”, “Social Sciences”, “Basic Sciences” and “Engineering” topics on the DergiPark-Academic website. The data set consists of articles written in English and Turkish. In the first phase of text mining, text preprocessing and feature selection steps were applied to text data. Then the articles are classified according to their subject areas by employing Naive Bayes (NB), Random Forest (RF), and Support Vector Machine (SVM) algorithms. In the final phase of text mining, the performance of the algorithms is evaluated with respect to the machine learning performance criteria. The results show that the working times of the algorithms were close to each other. The fastest running algorithm is NB, while the slowest running algorithm is SVM. On the other hand, SVM dominates with the best accuracy results among others. Algorithm performances in both Turkish and English languages do not differ remarkably in terms of accuracy and speed. © 2022 John Wiley & Sons, Ltd.",TextMining
"Commensurate with economic globalization, the demand for mineral resources is increasing. With increased mining activity, problems related to ground subsidence and rock movement are becoming increasingly prominent, even affecting mining production activities. However, the physical mechanisms behind the ground subsidence phenomenon have been poorly studied, especially for metal mines with a steep dip. This paper applies the Interferometric Synthetic Aperture Radar (InSAR) technique and the numerical simulation method to deduce the characteristics of rock movement in the Xinli deposit of the steeply inclined Sanshandao gold mine. The InSAR results indicate that more subsidence has occurred in the southern part of the Xinli Village coastline area than in the northern part. This is also supported by the numerical simulation results obtained by the fast Lagrangian analysis of continua in three dimensions (FLAC3D). Notably, the range of ground subsidence obtained by numerical simulation shows an obvious asymmetry. The monitoring data of the No. 55 prospecting profile offer a plausible explanation for this, as the surrounding rock of the fault’s hanging wall has a wider range of rock movements. Furthermore, the sublevels of the No. 55 prospecting profile at different depths show different rock movement characteristics, and a logistic function can be well applied to the right part of the settlement curve; the parameter “a” in the function formula is very close to the maximum subsidence value for each sublevel. We defined the ratio “r” to measure the difference between the maximum subsidence value and the corresponding parameter “a” and found this value to be positively correlated with the fractal dimension value of deeper sublevels (−320 m, −400 m, −480 m, and −600 m) and negatively correlated with the fractal dimension value of lower sublevels (−200 m and −240 m). Copyright © 2023 Liu, Ma, Guo, Li, Song and Li.",TextMining
"Handbook of Software Fault Localization A comprehensive analysis of fault localization techniques and strategies In Handbook of Software Fault Localization: Foundations and Advances, distinguished computer scientists Prof. W. Eric Wong and Prof. T.H. Tse deliver a robust treatment of up-to-date techniques, tools, and essential issues in software fault localization. The authors offer collective discussions of fault localization strategies with an emphasis on the most important features of each approach. The book also explores critical aspects of software fault localization, like multiple bugs, successful and failed test cases, coincidental correctness, faults introduced by missing code, the combination of several fault localization techniques, ties within fault localization rankings, concurrency bugs, spreadsheet fault localization, and theoretical studies on fault localization. Readers will benefit from the authors' straightforward discussions of how to apply cost-effective techniques to a variety of specific environments common in the real world. They will also enjoy the in-depth explorations of recent research directions on this topic. Handbook of Software Fault Localization also includes: • A thorough introduction to the concepts of software testing and debugging, their importance, typical challenges, and the consequences of poor efforts • Comprehensive explorations of traditional fault localization techniques, including program logging, assertions, and breakpoints • Practical discussions of slicing-based, program spectrum-based, and statistics-based techniques • In-depth examinations of machine learning-, data mining-, and model-based techniques for software fault localization • Perfect for researchers, professors, and students studying and working in the field, Handbook of Software Fault Localization: Foundations and Advances is also an indispensable resource for software engineers, managers, and software project decision makers responsible for schedule and budget control. © 2023 by the IEEE Computer Society. All rights reserved.",TextMining
"The identification of unknown chemicals has emerged as a significant issue in untargeted metabolome analysis owing to the limited availability of purified standards for identification; this is a major bottleneck for the accumulation of reusable metabolome data in systems biology. Public resources for discovering and prioritizing the unknowns that should be subject to practical identification, as well as further detailed study of spending costs and the risks of misprediction, are lacking. As such a resource, we released databases, Food-, Plant- and Thing-Metabolome Repository (http://metabolites.in/foods, http://metabolites.in/plants, and http://metabolites.in/things, referred to as XMRs) in which the sample-specific localization of unknowns detected by liquid chromatography-mass spectrometry in a wide variety of samples can be examined, helping to discover and prioritize the unknowns. A set of application programming interfaces for the XMRs facilitates the use of metabolome data for large-scale analysis and data mining. Several applications of XMRs, including integrated metabolome and genome analyses, are presented. Expanding the concept of XMRs will accelerate the identification of unknowns and increase the discovery of new knowledge.  © 2023 The Author(s). Published by Oxford University Press on behalf of Nucleic Acids Research.",TextMining
"The Cucurbitaceae (cucurbit) family consists of about 1,000 species in 95 genera, including many economically important and popular fruit and vegetable crops. During the past several years, reference genomes have been generated for >20 cucurbit species, and variome and transcriptome profiling data have been rapidly accumulated for cucurbits. To efficiently mine, analyze and disseminate these large-scale datasets, we have developed an updated version of Cucurbit Genomics Database. The updated database, CuGenDBv2 (http: //cucurbitgenomics.org/v2), currently hosts 34 reference genomes from 27 cucurbit species/subspecies belonging to 10 different genera. Protein-coding genes from these genomes have been comprehensively annotated by comparing their protein sequences to various public protein and domain databases. A novel ‘Genotype’ module has been implemented to facilitate mining and analysis of the functionally annotated variome data including SNPs and small indels from large-scale genome sequencing projects. An updated ‘Expression’ module has been developed to provide a comprehensive gene expression atlas for cucurbits. Furthermore, synteny blocks between any two and within each of the 34 genomes, representing a total of 595 pair-wise genome comparisons, have been identified and can be explored and visualized in the database. © The Author(s) 2022. Published by Oxford University Press on behalf of Nucleic Acids Research.",TextMining
"Background: Quinolones are widely prescribed for the treatment or prevention of infectious diseases in children. To gain further insight into quinolone-associated adverse event (AE) in children and better protect pediatric patients, continued surveillance of safety data is essential. The purpose of this study was to characterize the safety profiles of quinolone-associated AEs in children by mining the FDA adverse event reporting system (FAERS). Methods: FAERS reports from quarter 1 of 2004 to quarter 1 of 2022 were included in the study. The Medical Dictionary for Regulatory Activities (MedDRA) was used to identify adverse events. Reporting odds ratios (ROR) corresponding 95% confidence intervals (CIs) and information component (IC) along with 95% CIs were calculated to detect drug–AE pairs with higher-than-expected reporting rates within the FAERS from System Organ Classes (SOCs) to Preferred Terms (PTs). Reports were considered as signals if the 95% conﬁdence interval did not contain the null value. Results: After inclusion criteria were applied, a total of 4,704 reports associated with quinolones were considered. Most FAERS reports associated with ciprofloxacin (N = 2,706) followed by levofloxacin (N = 1,191), moxifloxacin (N = 375), oflaxacin (N = 245) and ozenoxacin (N = 187). The most common age group was 12–18 years. The median weight was 39.0 kilogram. The adverse effects of quinolones emerging for SOCs primarily included Infections and infestations, gastrointestinal symptoms, blood and lymphatic system disorders, cardiac disorders, nervous system disorders, musculoskeletal and connective tissue disorders and psychiatric disorders. The most frequently AE signals at the PT level were pyrexia (N = 236), febrile neutropenia (N = 120), off label use (N = 48), drug resistance (N = 18) and cardiac arrest (N = 22) following the use of ciprofloxacin, levofloxacin, moxifloxacin, ofloxacin, and ozenoxacin, respectively. Serious oznoxacin-associated AE signals were found and have not been documented in the package insert. They included cardiac arrest (N = 22; ROR = 19.83; IC = 3.68), overdose (N = 21; ROR = 4.98; IC = 2.07), seizure (N = 16; ROR = 6.01; IC = 2.29), small for dates baby (N = 9; ROR = 14.7; IC = 3.05), completed suicide (N = 15, ROR = 18.87; IC = 3.51), asthma (N = 9; ROR = 6.69; IC = 2.24;) and hypotension (N = 9; ROR = 3.83; IC = 1.68). Conclusion: This study provided additional evidence with respect to quinolones-related AEs for children. Generally, the findings of this study are compatible with AEs recorded in package inserts. The unexpected signals of ozenoxacin justify active vigilance by clinicians and timely monitoring by pharmacovigilance experts. 2023 Kong, Mao, Zhang and Wu.",TextMining
"Objective: Invasive pituitary adenomas (IPAs) are common tumors of the nervous system tumors for which invasive growth can lead to difficult total resection and a high recurrence rate. The basement membrane (BM) is a special type of extracellular matrix and plays an important role in the invasion of pituitary adenomas (PAs). The aim of this study was to develop a risk model for predicting the invasiveness of PAs by analyzing the correlation between the expression of BM genes and immune infiltration. Methods: Four datasets, featuring samples IPAs and non-invasive pituitary adenomas (NIPAs), were obtained from the Gene Expression Omnibus database (GEO). R software was then used to identify differentially expressed genes (DEGs) and analyze their functional enrichment. Protein-protein interaction (PPI) network was used to screen BM genes, which were analyzed for immune infiltration; this led to the generation of a risk model based on the correlation between the expression of BM genes and immunity. A calibration curve and receiver operating characteristic (ROC) curve were used to evaluate and validate the model. Subsequently, the differential expression levels of BM genes between IPA and NIPA samples collected in surgery were verified by Quantitative Polymerase Chain Reaction (qPCR) and the prediction model was further evaluated. Finally, based on our analysis, we recommend potential drug targets for the treatment of IPAs. Results: The merged dataset identified 248 DEGs that were mainly enriching in signal transduction, the extracellular matrix and channel activity. The PPI network identified 11 BM genes from the DEGs: SPARCL1, GPC3, LAMA1, SDC4, GPC4, ADAMTS8, LAMA2, LAMC3, SMOC1, LUM and THBS2. Based on the complex correlation between these 11 genes and immune infiltration, a risk model was established to predict PAs invasiveness. Calibration curve and ROC curve analysis (area under the curve [AUC]: 0.7886194) confirmed the good predictive ability of the model. The consistency between the qPCR results and the bioinformatics results confirmed the reliability of data mining. Conclusion: Using a variety of bioinformatics methods, we developed a novel risk model to predict the probability of PAs invasion based on the correlation between 11 BM genes and immune infiltration. These findings may facilitate closer surveillance and early diagnosis to prevent or treat IPAs in patients and improve the clinical awareness of patients at high risk of IPAs. Copyright © 2023 Chen, Sun, Kang, Zhang, Jia, Liu and Zhu.",TextMining
"As a globally popular leafy vegetable and a representative plant of the Asteraceae family, lettuce has great economic and academic significance. In the last decade, high-throughput sequencing, phenotyping, and other multi-omics data in lettuce have accumulated on a large scale, thus increasing the demand for an integrative lettuce database. Here, we report the establishment of a comprehensive lettuce database, LettuceGDB (https://www.lettucegdb.com/). As an omics data hub, the current LettuceGDB includes two reference genomes with detailed annotations; re-sequencing data from over 1000 lettuce varieties; a collection of more than 1300 worldwide germplasms and millions of accompanying phenotypic records obtained with manual and cutting-edge phenomics technologies; re-analyses of 256 RNA sequencing datasets; a complete miRNAome; extensive metabolite information for representative varieties and wild relatives; epigenetic data on the genome-wide chromatin accessibility landscape; and various lettuce research papers published in the last decade. Five hierarchically accessible functions (Genome, Genotype, Germplasm, Phenotype, and O-Omics) have been developed with a user-friendly interface to enable convenient data access. Eight built-in tools (Assembly Converter, Search Gene, BLAST, JBrowse, Primer Design, Gene Annotation, Tissue Expression, Literature, and Data) are available for data downloading and browsing, functional gene exploration, and experimental practice. A community forum is also available for information sharing, and a summary of current research progress on different aspects of lettuce is included. We believe that LettuceGDB can be a comprehensive functional database amenable to data mining and database-driven exploration, useful for both scientific research and lettuce breeding. © 2022 The Author(s)",TextMining
"Safety begins in the human mind, and the individual’s need for psychological safety is the most fundamental need. This fundamental need takes psychological safety as the starting point for the gradual formation of a connection with the outside world. Graduates are the backbone of China’s economic development, and their healthy development is of great significance to the sustainable development of China’s economy and society. Excessive psychological pressure may bring pain to students in physical and psychological aspects, and even lead to suicide. If students with abnormal psychological pressure can be found in time, the school can provide help and intervention in time to relieve psychological pressure. This paper uses pressure sensor technology for data collection and data mining techniques for data analysis to assess and predict the psychological stress level of Higher Educational Institutions (HEIs) students. The results show that this method can accurately and objectively evaluate the psychological stress of the students, and the evaluation results of students’ psychological stress are stable, which can provide students with psychological stress assessment services. It implies that HEI’s policymakers should consider these techniques to assess the psychological stress of the students proactively. Copyright © 2023 Chen.",TextMining
"Data mining of medical imaging approaches makes it difficult to determine their value in the disease's insight, analysis, and diagnosis. Image classification presents a significant difficulty in image analysis and plays a vital part in computer-aided diagnosis. This task concerned the use of optimization techniques for the utilization of image processing, pattern recognition, and classification techniques, as well as the validation of image classification results in medical expert reports. The primary intention of this study is to analyze the performance of optimization techniques explored in the area of medical image analysis. For this motive, the optimization techniques employed in existing literature from 2012 to 2021 are reviewed in this study. The contribution of optimization-based medical image classification and segmentation utilized image modalities, data sets, and tradeoffs for each technique are also discussed in this review study. Finally, this review study provides the gap analysis of optimization techniques used in medical image analysis with the possible future research direction. © 2022 John Wiley & Sons, Ltd.",TextMining
"It is a dream for the most students to get placed in the process of fulfilling it we have come out with the application which predicts the placement of each student and also gets the data base of them. The system that could fore-cast the chances or the type of company which predicts the probability a semi-final year student to get placed is called a placement predictor. This prediction system helps an institution in the coming years in terms of academic planning. By using the emerging technologies like deep learning and data mining, a lot of predictor models were coming into picture by analyzing the dataset of passed out student. This project gives a method for using algorithm in deep learning to establish a placement prediction model for semi-final year graduates Unlike other methods in this approach we will try multiple methods and finalize the best method to predict the placements. © 2023 The authors and IOS Press.",TextMining
"Purpose: The purpose of this study is to investigate the impact of board secretaries’ characteristics on annual report readability using an original method that evaluates the readability of Chinese characters. Design/methodology/approach: The authors manually collect board secretaries’ characteristics from the China Securities Market and Accounting Research database and obtain annual reports from the China Information website. Ordinary least square regression is applied to evaluate the impact, and then robustness tests and additional regression analyses are conducted. Findings: Board secretaries’ legal-professional expertise, international expertise and role duality improve annual report readability. However, their political connections are negatively associated with it. The effect of expertise (role duality) is more pronounced for firms with lower ex ante litigation risk (board secretaries with equity holdings). Furthermore, higher readability increases the compensation of board secretaries, whereas lower readability increases their turnover. Finally, annual report readability is positively related to firm performance. Research limitations/implications: The authors only investigate listed firms in China from 2007 to 2017 because of the difficulties of obtaining data and text mining. Practical implications: The authors provide managerial insights for regulators aiming to establish an effective governance mechanism with Chinese characteristics. First, certain requirements for board secretaries’ expertise can improve annual report readability. Further, firms can consider appointing board members or senior executives as board secretaries to enhance disclosure quality. Originality/value: To the best of the authors’ knowledge, this study is the first to verify the effect of board secretaries’ characteristics on disclosure quality, especially annual report readability. Moreover, this study proposes a novel measure of annual report readability for Chinese texts. © 2022, Emerald Publishing Limited.",TextMining
"Information mining and semantic analysis have gained significant attention over recent years to obtain appropriate information from unstructured data. Several approaches have been introduced for web information mining. However, the expected accuracy is not reached by these approaches. Therefore, hybrid fuzzy clustering and enhanced latent Dirichlet allocation (ELDA) are proposed for the accuracy increment in this work. The information clustering process is performed using the hybrid fuzzy clustering algorithm called fuzzy-C-medoids optimized using improved whale algorithm. The clustering procedure entails grouping data points into more similar clusters than data points from other clusters. Finally, the context of the text is recognized by analyzing the semantic information with ELDA, which offers a suitable index for accurate and fast data extraction. PYTHON tool is used to develop the proposed web mining model, and the simulation analysis of the proposed model is carried out using the BibTex dataset and compared with baseline models. The performance of the proposed method is evaluated using purity, normalized mutual information, accuracy, and precision metrics. Also, it is compared with different existing algorithms. Thus, the analysis of the results proved that the proposed approach achieves better outcomes than the existing approaches. © 2022 John Wiley & Sons, Ltd.",TextMining
"Purpose: Most developing countries simply dump ferrochrome slag as waste which occupies huge areas of useful land. The purpose of this study is to underscore the significance of reusing ferrochrome slag as a sustainable and eco-friendly road aggregate material, with the added benefits of preventing possible environmental pollution and promoting sustainable mining of non-renewable construction materials. Design/methodology/approach: Physical-mechanical characteristics were investigated using various South African National Standards test procedures. Chemical and mineralogical characteristics were evaluated using the X-ray fluorescence and the X-ray diffraction techniques, respectively. The toxicity characteristic leaching procedure test was used to evaluate the slag’s environmental suitability. Using two cement types, cement proportions of 1%, 2% and 3% of the slag aggregate weight mixed with optimum moisture content of the non-treated compacted slag were used to make lightly cemented ferrochrome slag aggregate (LCFSA) composites, subsequently tested for compressive strength. Findings: Ferrochrome slag aggregates have excellent physical-mechanical characteristics that conform to international specifications for use in road base construction. The slag can be classified as non-hazardous solid waste. However, in acidic environments, some toxic elements may leach from the slag and pollute the environment. Optimum cement contents of 2.3% (CEM II) and 2.6% (CEM VB) can be mixed with the slag to produce LCFSA for road bases. Originality/value: No research was found in literature on the use of LCFSA in road bases. This research, therefore, presents new data on mix design and strength properties of LCFSA as well as some physical-chemical characteristics of coarse ferrochrome slag aggregate. © 2021, Emerald Publishing Limited.",TextMining
"Recent studies have suggested that dipeptidyl peptidase 4 (DPP4) inhibitors increase the risk of development of bullous pemphigoid (BP), which is the most common autoimmune blistering skin disease; however, the associated mechanisms remain unclear, and thus far, no therapeutic targets responsible for drug-induced BP have been identified. Therefore, we used clinical data mining to identify candidate drugs that can suppress DPP4 inhibitor-associated BP, and we experimentally examined the underlying molecular mechanisms using human peripheral blood mononuclear cells (hPBMCs). A search of the US Food and Drug Administration Adverse Event Reporting System and the IBM® MarketScan® Research databases indicated that DPP4 inhibitors increased the risk of BP, and that the concomitant use of lisinopril, an angiotensin-converting enzyme inhibitor, significantly decreased the incidence of BP in patients receiving DPP4 inhibitors. Additionally, in vitro experiments with hPBMCs showed that DPP4 inhibitors upregulated mRNA expression of MMP9 and ACE2, which are responsible for the pathophysiology of BP in monocytes/macrophages. Furthermore, lisinopril and Mas receptor (MasR) inhibitors suppressed DPP4 inhibitor-induced upregulation of MMP9. These findings suggest that the modulation of the renin-angiotensin system, especially the angiotensin1-7/MasR axis, is a therapeutic target in DPP4 inhibitor-associated BP. Copyright © 2023 Nozawa, Suzuki, Kayanuma, Yamamoto, Nagayasu, Shirakawa and Kaneko.",TextMining
"There is a great increase in the amount of information that is available at any given moment, and the internet is a significant source of information. Every day, more people are using the internet than there was the day before. Numerous research is being conducted to reduce the amount of time individuals spend browsing the internet. In the process known as Web usage mining, mining strategies are carried out on a dataset provided by a proxy server to identify the actions of web users. Clustering is an important technique that has many different uses, including the analysis of data from online logs, customer relationship management (CRM), advertising and marketing, scientific diagnostics, and computational biology, amongst many others. Clustering is the collection of data objects that are connected. The problem with clustering is the fact that there are multiple types of measurements that might determine whether or not two things are similar or unique. The paper presents the clustering and classification of web server log access. The clustering is performed using the grey wolf optimization algorithm and classification is performed using five classifiers i.e., support vector machine, random forest, k-NN, decision tree, and gradient boosting. The performance was also compared with existing state of art models and the proposed model has achieved better results. © Authors.",TextMining
"The objective of this chapter is to demonstrate that the combined use of data mining and machine learning (ML) in a high-performance computing (HPC) environment offers a significant contribution to the process of computing the effects of antibody stress under the effect of production parameters, determining monoclonal antibodies (mAbs) stress conditions, and predicting the values of parameters that influence the loss of function or structure of antibodies. Indeed, there is a relationship between the structure, activity, and loss of function and the stress undergone by the mAb during the manufacturing process. Structural deformation can lead to loss of function of the mAb and be one of the most probable causes of antibodies bio-resistance. In this chapter, we propose a new molecular dynamics calculation architecture integrating AI and data mining in an HPC environment to determine the conformations most prone to the aggregation of mAbs. From there, we speculate on the use of ML models to predict these conformations as well as the link between aggregation and loss of function. Finally, we determine how the loss of function can promote conditions for antibiotic resistance.Theconcrete use cases study is focused on Pembrolizumab, an antibody that is well documented in the scientific literature. © 2023 American Chemical Society. All rights reserved.",TextMining
"Frequent episode mining is useful for finding temporal patterns in sequential data. Episodes represent partially ordered sets of event-types and frequently occurring episodes can capture temporal dependencies in the data. There are many algorithms in the literature that find a subset of frequent episodes that best summarize the data using serial episodes (which are episodes with total order). But there are no such algorithms for the case of general episodes. An efficient Depth-First search (DFS) approach for mining general episodes would be a crucial tool and a necessary first step for generating a subset of general episodes that best represent the given temporal data. In this paper, we present an efficient algorithm to mine for general injective episodes in a DFS manner. Our algorithm uses both the apriori principle and the idea of bidirectional evidence to prune the search space and it returns closed frequent episodes. Through simulation studies, we show that the algorithm is quite effective and efficient when compared with the existing algorithms.  © 2023 ACM.",TextMining
"Melanoma tumors are highly metastatic partly due to the ability of melanoma cells to transition between invasive and proliferative states. However, the mechanisms underlying this plasticity are still not fully understood. To identify new epigenetic regulators of melanoma plasticity, we combined data mining, tumor models, proximity proteomics, and CUT&RUN sequencing. We focus on the druggable family of bromodomain epigenetic readers and identify TRIM28 as a new regulator of melanoma plasticity. We find that TRIM28 promotes the expression of pro-invasive genes and that TRIM28 controls the balance between invasiveness and growth of melanoma cells. We demonstrate that TRIM28 acts via the transcription factor JUNB that directly regulates the expression of pro-invasive and pro-growth genes. Mechanistically, TRIM28 controls the expression of JUNB by negatively regulating its transcriptional elongation by RNA polymerase II. In conclusion, our results demonstrate that a TRIM28–JUNB axis controls the balance between invasiveness and growth in melanoma tumors and suggest that the bromodomain protein TRIM28 could be targeted to reduce tumor spread. © 2022 The Authors. Published under the terms of the CC BY 4.0 license.",TextMining
"The human body has an immune system that functions to defend the body and prevent bacteria from entering it. However, a weak or vulnerable immune system can make the body susceptible to bacteria, for example, minor illnesses such as the flu or severe diseases, namely tuberculosis (TB). Tuberculosis is a disease that is caused by infection with the bacterium Mycobacterium tuberculosis which is contagious and deadly. In 2017, in Indonesia, TB patients increased to the third rank in the world. In the field of computing, the application of statistical science cannot be separated. One application of the field of computing is data mining which aims to find and explore or add knowledge based on data or information. This effort serves to reveal important information contained in the data. Aggregation queries are formulated using the simple SQL language that computes aggregation functions (such as MIN, MAX, COUNT, SUM, AVG). The distribution of TB patient data shows an increase every year with an average age of 46-65 years, which is dominated by men. © 2023 American Institute of Physics Inc.. All rights reserved.",TextMining
"Patescibacteria form a highly diverse and widespread superphylum of uncultured microorganisms representing a third of the global microbial diversity. Most of our knowledge on Patescibacteria putative physiology relies on metagenomic mining and metagenome-assembled genomes, but the in situ activities and the ecophysiology of these microorganisms have been rarely explored, leaving the role of Patescibacteria in ecosystems elusive. Using a genome-centric metatranscriptomic approach, we analyzed the diel and seasonal gene transcription profiles of 18 Patescibacteria populations in brackish microbial mats to test whether our understanding of Patescibacteria metabolism allows the extrapolation of their in situ activities. Although our results revealed a circadian cycle in Patescibacteria activities, a strong streamlined genetic expression characterized the Patescibacteria populations. This result has a major consequence for the extrapolation of their physiology and environmental function since most transcribed genes were uncharacterized, indicating that the ecophysiology of Patescibacteria cannot be yet reliably predicted from genomic data. Copyright © 2023 Vigneron, Cruaud, Guyoneaud and Goñi-Urriza.",TextMining
"Numerous investigations of the spatiotemporal patterns of infectious disease epidemics, their potential influences, and their driving mechanisms have greatly contributed to effective interventions in the recent years of increasing pandemic situations. However, systematic reviews of the spatiotemporal patterns of communicable diseases are rare. Using bibliometric analysis, combined with content analysis, this study aimed to summarize the number of publications and trends, the spectrum of infectious diseases, major research directions and data-methodological-theoretical characteristics, and academic communities in this field. Based on 851 relevant publications from the Web of Science core database, from January 1991 to September 2021, the study found that the increasing number of publications and the changes in the disease spectrum have been accompanied by serious outbreaks and pandemics over the past 30 years. Owing to the current pandemic of new, infectious diseases (e.g., COVID-19) and the ravages of old infectious diseases (e.g., dengue and influenza), illustrated by the disease spectrum, the number of publications in this field would continue to rise. Three logically rigorous research directions—the detection of spatiotemporal patterns, identification of potential influencing factors, and risk prediction and simulation—support the research paradigm framework in this field. The role of human mobility in the transmission of insect-borne infectious diseases (e.g., dengue) and scale effects must be extensively studied in the future. Developed countries, such as the USA and England, have stronger leadership in the field. Therefore, much more effort must be made by developing countries, such as China, to improve their contribution and role in international academic collaborations. Copyright © 2023 Lu and Ren.",TextMining
"Mining-induced ground subsidence is a commonly observed geo-hazard that leads to loss of life, property damage, and economic disruption. Monitoring subsidence over time is essential for predicting related geo-risks and mitigating future disasters. Machine-learning algorithms have been applied to develop predictive models to quantify future ground subsidence. However, machine-learning approaches are often difficult to interpret and reproduce, as they are largely used as “black-box” functions. In contrast, stochastic differential equations offer a more reliable and interpretable solution to this problem. In this study, we propose a stochastic differential equation modeling approach to predict short-term subsidence in the temporal domain. Mining-induced time-series data collected from the Global Navigation Satellite System (GNSS) in our case study area were utilized to conduct the analysis. Here, the mining-induced time-series data collected from GNSS system regarding our case study area in Miyi County, Sichuan Province, China between June 2019 and February 2022 has been utilized to conduct the case study. The proposed approach is capable of extracting the time-dependent structure of monitored subsidence data and deriving short-term subsidence forecasts. The predictive outcome and time-path trajectories were obtained by characterizing the parameters within the stochastic differential equations. Comparative analysis against the persistent model, autoregressive model, and other improved autoregressive time-series models is conducted in this study. The computational results validate the effectiveness and accuracy of the proposed approach. Copyright © 2023 Guo, Ma, Teng, Liao, Pei and Chen.",TextMining
"Relation ties, defined as the correlation and mutual exclusion between different relations, are critical for distant supervised relation extraction. Previous studies usually obtain this property by greedily learning the local connections between relations. However, they are essentially limited because of failing to capture the global topology structure of relation ties and may easily fall into a locally optimal solution. To address this issue, we propose a novel force-directed graph to comprehensively learn relation ties. Specifically, we first construct a graph according to the global co-occurrence of all relations. Then, we borrow the idea of Coulomb's law from physics and introduce the concept of attractive force and repulsive force into this graph to learn correlation and mutual exclusion between relations. Finally, the obtained relation representations are applied as an inter-dependent relation classifier. Extensive experimental results demonstrate that our method is capable of modeling global correlation and mutual exclusion between relations, and outperforms the state-of-The-Art baselines. In addition, the proposed force-directed graph can be used as a module to augment existing relation extraction systems and improve their performance. © 2023 Association for Computing Machinery.",TextMining
"Introduction: Recurrent implantation failure (RIF) is a distressing problem in assisted reproductive technology (ART). Immunity plays a vital role in recurrent implantation failure (RIF) occurrence and development, but its underlying mechanism still needs to be fully elucidated. Through bioinformatics analysis, this study aims to identify the RIF-associated immune cell types and immune-related genes. Methods: The differentially expressed genes (DEGs) were screened based on RIF-associated Gene Expression Omnibus (GEO) datasets. Then, the enrichment analysis and protein-protein interaction (PPI) analysis were conducted with the DEGs. The RIF-associated immune cell types were clarified by combining single sample gene set enrichment analysis (ssGSEA) and CIBERSORT. Differentially expressed immune cell types-related modules were identified by weighted gene co-expression network analysis (WGCNA) and local maximal quasi-clique merger (lmQCM) analysis. The overlapping genes between DEGs and genes contained by modules mentioned above were delineated as candidate hub genes and validated in another two external datasets. Finally, the microRNAs (miRNAs) and long non-coding RNAs (lncRNAs) that interacted with hub genes were predicted, and the competing endogenous RNA (ceRNA) regulatory network was structured. Results: In the present study, we collected 324 DEGs between RIF and the control group, which functions were mainly enriched in immune-related signaling pathways. Regarding differential cell types, the RIF group had a higher proportion of activated memory CD4 T cells and a lower proportion of γδ T cells in the endometrial tissue. Finally, three immune-related hub genes (ALOX5AP, SLC7A7, and PTGS2) were identified and verified to effectively discriminate RIF from control individuals with a specificity rate of 90.8% and a sensitivity rate of 90.8%. In addition, we constructed a key ceRNA network that is expected to mediate molecular mechanisms in RIF. Conclusion: Our study identified the intricate correlation between immune cell types and RIF and provided new immune-related hub genes that offer promising diagnostic and therapeutic targets for RIF. Copyright © 2023 Yu, Wang, Wang, Yan, Chen, Xu, Su and Wang.",TextMining
"Subnational disparities in most health systems often defy 'one-size-fits-all' approach in policy implementation. When local authorities implement a national policy in a decentralized context, they behave as a strategic policy actor in specifying the central mandates, selecting appropriate tools and setting key implementation parameters. Local policy discretion leads to diverse policy mixes across regions, thus complicating evidence-based evaluations of policy impacts. When measuring complex policy reforms, mainstream policy evaluation methodologies have tended to adopt simplified policy proxies that often disguise distinct policy choices across localities, leaving the heterogeneous effects of the same generic policy largely unknown. Using the emerging 'text-as-data' methodology and drawing from subnational policy documents, this study developed a novel approach to policy measurement through analysing policy big data. We applied this approach to examine the impacts of China's Urban Employee Basic Medical Insurance (UEBMI) on individuals' out-of-pocket (OOP) spending. We found substantial disparities in policy choices across prefectures when categorizing the UEBMI policy framework into benefit-expansion and cost-containment reforms. Overall, the UEBMI policies lowered enrollees' OOP spending in prefectures that embraced both benefit-expansion and cost-containment reforms. In contrast, the policies produced ill effects on OOP spending of UEBMI enrollees and uninsured workers in prefectures that carried out only benefit-expansion or cost-containment reforms. The micro-level impacts of UEBMI enrolment on OOP spending were conditional on whether prefectural benefit-expansion and cost-containment reforms were undertaken in concert. Only in prefectures that promulgated both types of reforms did UEBMI enrolment reduce OOP spending. These findings contribute to a comprehensive text-mining measurement approach to locally diverse policy efforts and an integration of macro-level policy analysis and micro-level individual analysis. Contextualizing policy measurements would improve the methodological rigour of health policy evaluations. This paper concludes with implications for health policymakers in China and beyond. © The Author(s) 2022. Published by Oxford University Press in association with The London School of Hygiene and Tropical Medicine.",TextMining
"Recent years have witnessed the rapid accumulation of massive electronic medical records, which highly support intelligent medical services such as drug recommendation. However, although there are multiple interaction types between drugs, e.g., synergism and antagonism, which can influence the effect of a drug package significantly, prior arts generally neglect the interaction between drugs or consider only a single type of interaction. Moreover, most existing studies generally formulate the problem of package recommendation as getting a personalized scoring function for users, despite the limits of discriminative models to achieve satisfactory performance in practical applications. To this end, in this article, we propose a novel end-To-end Drug Package Generation (DPG) framework, which develops a new generative model for drug package recommendation that considers the interaction effects between drugs that are affected by patient conditions. Specifically, we propose to formulate the drug package generation as a sequence generation process. Along this line, we first initialize the drug interaction graph based on medical records and domain knowledge. Then, we design a novel message-passing neural network to capture the drug interaction, as well as a drug package generator based on a recurrent neural network. In detail, a mask layer is utilized to capture the impact of patient condition, and the deep reinforcement learning technique is leveraged to reduce the dependence on the drug order. Finally, extensive experiments on a real-world dataset from a first-rate hospital demonstrate the effectiveness of our DPG framework compared with several competitive baseline methods. © 2023 Association for Computing Machinery.",TextMining
"Searching for new adjuvants of conventional chemotherapeutic approaches against colorectal cancer cells is extremely urgent. In current research, a non-targeted analytical approach was established by combining proton nuclear magnetic resonance spectroscopy with a chemometrics data mining tool to identify chemosensitizing agents from Rauvolfia vomitoria. This approach enabled the identification of potential active constituents in the initial fractionation process and provided their structural information. This strategy was validated by its application to Rauvolfia vomitoria extract exhibiting chemosensitizing activity on 5-fluorouracil against colorectal cancer cells. After the workflow, the biochemometrics analysis showed that at least 15 signals (Variable influence on projection (VIP) > 1) could have contributions in the differentiation of various fractions. Through systematic literature and database searches, we found that the most active fraction (fraction 7) exhibited the highest presence of sabazin-type and armaniline-type alkaloids, which were potential chemosensitizers as previously reported. To validate the results of the strategy, the effect of 5-FU and compounds isolated from fraction seven incubation on HCT-8 and LoVo cell vialibilty were evaluated. These results evidenced that compound β-carboline (3), 1-methyl-β-carboline (4), and lochnerine (6) could enhance the cytotoxicity of 5-fluorouracil against to Colorectal cancer cells. Besides, 21 compounds including two new compounds were isolated from Rauvolfia vomitoria. The experimental results verify the reliability of the method, and this approach provides a new and efficient tool to overcome some of the bottlenecks in natural products drug discovery. Copyright © 2023 Cui, Guo, Wang, Wang, Ji, Wang, Yang, Lin and Wang.",TextMining
"Objective Data mining technology was used to analyze the regulation of food therapy prescriptions in treating children′ s stagnation. Methods Collect the therapy prescriptions used for regulating children's stagnation in the Dictionary of Traditional Chinese Medicine Prescriptions, the Complete Record of Dietary Therapy Prescriptions of Traditional Chinese Medicine and the Dictionary of Chinese Medicinal Diet, extract the information of prescription name, composition, etc, and use SPSS 22.0 for frequency analysis, and use Weka for correlation analysis. Results A total of 99 dietary prescriptions for children with hysteria were included, involving a total of 62 foods, with a total use frequency of 224 times, among which the food with high use frequency were chicken gizzard, japonica rice, hawthorn, etc. The four characteristics of food were mainly concentrated in the flat, the five tastes were mainly concentrated in the sweet, the return channel was mainly concentrated in the spleen and stomach channel, and the effect was mainly concentrated in the absorption of food and tonic deficiency. The main symptoms of the therapeutic prescription for children's accumulation of stagnation were internal accumulation of milk and food and combination of spleen deficiency. The commonly used food combination for children's accumulation of stagnation of milk and food was ""fructus amomi - chicken gizzard"". The commonly used food combination of children with spleen deficiency and accumulation of stagnation was ""lentil bean- yam- japonica rice"" and ""millet- yam"". Conclusions Traditional Chinese medicine diet prescription for the treatment of children's accumulation of stagnation pay attention to harmony and regulation, sweet and slow tonifying, emphasizing the adjustment of the spleen and stomach, taking into account the regulation of lung, following the ""eliminating and supplementing both, according to the cause of treatment"" rule, advocate syndrome differentiation of food. © 2023 Chinese Medical Journals Publishing House Co.Ltd. All Rights Reserved.",TextMining
"Purpose: The recent surge in behavioral studies on the coordination mechanisms in supply chains (SCs) and advanced methods highlights the role of SC coordination (SCC) and behavioral issues associated with improving the performance of the operations. This study aims to critically review the behavioral aspect of channel coordination mechanisms. Design/methodology/approach: Following a systematic literature review methodology, the authors adopt a combination of bibliometric (to reflect the current state of the field), content (using Leximancer data mining software to develop thematic maps) and theory-oriented qualitative analyzes that provide a holistic conceptual framework to unify the literature’s critical concepts. Findings: The analysis confirms the plethora of risk-oriented publications, demonstrating that the second largest category of studies is concerned with social preferences theory. Most studies were based on experiments, followed by analytical modeling, revealing the impact of heuristics and individual preferences in SC decisions and suggesting promising managerial and theoretical avenues for future research. Originality/value: The study sheds light on behavioral decision theories applied to SC coordination by categorizing the literature based on the adopted theories. The methodological contributions include using automated content analysis and validating the outcome by interviewing leading scholars conducting active research on “behavioral operations management and SC contracts.” The authors also propose several directions for future research based on the research gaps. © 2021, Emerald Publishing Limited.",TextMining
"Noncoding RNAs (ncRNAs) play key regulatory roles in biological processes by interacting with other biomolecules. With the development of high-throughput sequencing and experimental technologies, extensive ncRNA interactions have been accumulated. Therefore, we updated the NPInter database to a fifth version to document these interactions. ncRNA interaction entries were doubled from 1 100 618 to 2 596 695 by manual literature mining and high-throughput data processing. We integrated global RNA-DNA interactions from iMARGI, ChAR-seq and GRID-seq, greatly expanding the number of RNA-DNA interactions (from 888 915 to 8 329 382). In addition, we collected different types of RNA interaction between SARS-CoV-2 virus and its host from recently published studies. Long noncoding RNA (lncRNA) expression specificity in different cell types from tumor single cell RNA-seq (scRNA-seq) data were also integrated to provide a cell-type level view of interactions. A new module named RBP was built to display the interactions of RNA-binding proteins with annotations of localization, binding domains and functions. In conclusion, NPInter v5.0 (http://bigdata.ibp.ac.cn/npinter5/) provides informative and valuable ncRNA interactions for biological researchers.  © 2023 The Author(s).",TextMining
"Background: The Centers for Disease Control and Prevention's Vaccine Safety Datalink (VSD) has been performing safety surveillance for COVID-19 vaccines since their earliest authorization in the United States. Complementing its real-time surveillance for pre-specified health outcomes using pre-specified risk intervals, the VSD conducts tree-based data-mining to look for clustering of a broad range of health outcomes after COVID-19 vaccination. This study's objective was to use this untargeted, hypothesis-generating approach to assess the safety of first booster doses of Pfizer-BioNTech (BNT162b2), Moderna (mRNA-1273), and Janssen (Ad26.COV2.S) COVID-19 vaccines. Methods: VSD enrollees receiving a first booster of COVID-19 vaccine through April 2, 2022 were followed for 56 days. Incident diagnoses in inpatient or emergency department settings were analyzed for clustering within both the hierarchical ICD-10-CM code structure and the follow-up period. The self-controlled tree-temporal scan statistic was used, conditioning on the total number of cases for each diagnosis. P-values were estimated by Monte Carlo simulation; p = 0.01 was pre-specified as the cut-off for statistical significance of clusters. Results: More than 2.4 and 1.8 million subjects received Pfizer-BioNTech and Moderna boosters after an mRNA primary series, respectively. Clusters of urticaria/allergy/rash were found during Days 10–15 after the Moderna booster (p = 0.0001). Other outcomes that clustered after mRNA boosters, mostly with p = 0.0001, included unspecified adverse effects, common vaccine-associated reactions like fever and myalgia, and COVID-19. COVID-19 clusters were in Days 1–10 after booster receipt, before boosters would have become effective. There were no noteworthy clusters after boosters following primary Janssen vaccination. Conclusions: In this untargeted data-mining study of COVID-19 booster vaccination, a cluster of delayed-onset urticaria/allergy/rash was detected after the Moderna booster, as has been reported after Moderna vaccination previously. Other clusters after mRNA boosters were of unspecified or common adverse effects and COVID-19, the latter evidently reflecting immunity to COVID-19 after 10 days. © 2022 The Author(s)",TextMining
"Next location prediction is helpful for service recommendation, public safety, intelligent transportation, and other location-based applications. Existing location prediction methods usually use sparse check-in trajectories and require massive historical data to capture complex spatial-temporal correlations. High spatial-temporal resolution trajectories have rich information. However, obtaining personal trajectories with long time series and high spatiotemporal resolution usually proves challenging. Herein, this paper proposes a two-stage Context-Aware Spatial-Temporal Location Embedding (CASTLE) model, a multi-modal pre-training model for sequence-to-sequence prediction tasks. The method is built in two steps. First, large-scale location datasets, which are sparse but easier to be acquired (i.e., check-in and anomalous navigation data), are used for pre-training location embedding to capture the multi-functional properties under different contexts. After that, the learned contextual embedding is used for downstream location prediction in small-scale but higher spatiotemporal resolution trajectory datasets. Specifically, the CASTLE model combines Bidirectional and Auto-Regressive Transformers to generate contextual embedding vectors rather than a fixed vector for each location. Furthermore, we introduce a location and time-aware encoder to reflect the spatial distances between locations and visit times. Experiments are conducted on two real trajectory datasets. The results show that the CASTLE model can pre-train beneficial location embedding and outperforms the model without pre-training by 4.6-7.1%. The proposed method is expected to improve the next location prediction accuracy without massive historical data, which will greatly drive the use of trajectory data. © Author(s) 2023.",TextMining
"Event extraction is an essential task in natural language processing. Although extensively studied, existing work shares issues in three aspects, including (1) the limitations of using original syntactic dependency structure, (2) insufficient consideration of the node level and type information in Graph Attention Network (GAT), and (3) insufficient joint exploitation of the node dependency type and part-of-speech (POS) encoding on the graph structure. To address these issues, we propose a novel framework for open event extraction in documents. Specifically, to obtain an enhanced dependency structure with powerful encoding ability, our model is capable of handling an enriched parallel structure with connected ellipsis nodes. Moreover, through a bidirectional dependency parsing graph, it considers the sequence of order structure and associates the ancestor and descendant nodes. Subsequently, we further exploit node information, such as the node level and type, to strengthen the aggregation of node features in our GAT. Finally, based on the coordination of triple-channel features (i.e., semantic, syntactic dependency and POS), the performance of event extraction is significantly improved. Extensive experiments are conducted to validate the effectiveness of our method, and the results confirm its superiority over the state-of-The-Art baselines. Furthermore, in-depth analyses are provided to explore the essential factors determining the extraction performance. © 2023 Association for Computing Machinery.",TextMining
"Introduction: DEF6 is a gene associated with the immune system and is thought to play a crucial role in autoimmunity. There are few DEF6-related studies in cancer, and it is assumed that DEF6 is a proto-oncogene. There is currently no pan-cancer analysis of DEF6, and we performed a systematic and comprehensive pan-cancer analysis of DEF6 in an attempt to reveal its role and function in cancer. Methods: The data were analyzed by mining databases available to the public and by using R software. Moreover, immunohistochemistry was used to validate the results. Results: Our results revealed that DEF6 is commonly aberrantly expressed in cancer and its expression is strongly correlated with survival prognosis in a variety of cancer types. Through correlation analysis we found that DEF6 was associated with multiple immune genes and was closely related to immune infiltration. In the enrichment analysis, DEF6 may have cross-talk with multiple cancer pathways and exert oncogenic or pro-cancer functions. In addition, we collected pathological samples from colorectal cancer patients for immunohistochemical analysis and found that patients with higher immunohistochemical scores had more lymph node metastases, higher CA199, and bigger tumor size. Discussion: Overall, DEF6 expression is closely related to cancers and has the potential to act as a cancer biomarker. Copyright © 2023 Yuan, Zhong, Hu, Zhang and Wang.",TextMining
"In this study, two top-down methods—mass balance and Gaussian footprint—were used to determine SO2 emissions rates via three airborne sampling studies over Korea's largest coal power plant in October 2019 and 2020. During the first two flights in October 2019, mass balance approaches significantly underestimated the SO2 emissions rates by 75 % and 28 %, respectively, as obtained from the real-time stack monitoring system. Notably, this large discrepancy accounted for the insufficient number of transects altitudes and high levels of background SO2 along the upwind side. Alternatively, the estimated SO2 emissions rates of the third flight (October 2020) displayed a difference of <10 % from rea-time monitoring data (630 vs. 690 kg·hr−1), owing to the enhanced vertical resolution with increased transects and lower background SO2 levels. In contrast to the mass balance method, Gaussian footprints offered significantly improved accuracy (relative error: 41 %, 32 %, and 2 % for Flights 1, 2, and 3, respectively). This relatively good performance was attributed to prior emissions knowledge via the Clean Air Policy Support System (CAPSS) emissions inventory and its unique ability to accurately estimate stack-level SO2 emissions rates. Theoretically, the Gaussian footprint was less prone to sparse transects and upwind background levels. However, it can be substantially influenced by atmospheric stability and consequently by effective stack heights and dispersion parameters; basically, all factors with minimal-to-no influence on the mass balance approach. Conversely, the mass balance method was the only plausible approach to estimate unidentified source emissions rates when well-defined prior emission information was unknown. Here, the footprint approach supplemented the mass balance method when the emission inventories were known, and employing both strategies approaches greatly enhanced the integrity of top-down emissions inventories from the power plant sources, thus, supporting their potential for ensuring operational compliance with SO2 emissions regulation. © 2022 Elsevier B.V.",TextMining
"As the world population is expected to touch 9.73 billion by 2050, according to the Food and Agriculture Organization (FAO), the demand for agricultural needs is increasing proportionately. Smart Agriculture is replacing conventional farming systems, employing advanced technologies such as the Internet of Things (IoT), Artificial Intelligence (AI), and Machine Learning (ML) to ensure higher productivity and precise agriculture management to overcome food demand. In recent years, there has been an increased interest in researchers within Smart Agriculture. Previous literature reviews have also conducted similar bibliometric analyses; however, there is a lack of research in Operations Research (OR) insights into Smart Agriculture. This paper conducts a Bibliometric Analysis of past research work in OR knowledge which has been done over the last two decades in Agriculture 4.0, to understand the trends and the gaps. Biblioshiny, an advanced data mining tool, was used in conducting bibliometric analysis on a total number of 1,305 articles collected from the Scopus database between the years 2000–2022. Researchers and decision makers will be able to visualize how newer advanced OR theories are being applied and how they can contribute toward some research gaps highlighted in this review paper. While governments and policymakers will benefit through understanding how Unmanned Aerial Vehicles (UAV) and robotic units are being used in farms to optimize resource allocation. Nations that have arid climate conditions would be informed how satellite imagery and mapping can assist them in detecting newer irrigation lands to assist their scarce agriculture resources. Copyright © 2023 Yousaf, Kayvanfar, Mazzoni and Elomri.",TextMining
"It is a challenge to efficiently integrate and present the tremendous amounts of single-cell data generated from multiple tissues of various species. Here, we create a new database named SPEED for single-cell pan-species atlas in the light of ecology and evolution for development and diseases (freely accessible at http://8.142.154.29 or http://speedatlas.net). SPEED is an online platform with 4 data modules, 7 function modules and 2 display modules. The 'Pan' module is applied for the interactive analysis of single cell sequencing datasets from 127 species, and the 'Evo', 'Devo', and 'Diz' modules provide comprehensive analysis of single-cell atlases on 18 evolution datasets, 28 development datasets, and 85 disease datasets. The 'C2C', 'G2G' and 'S2S' modules explore intercellular communications, genetic regulatory networks, and cross-species molecular evolution. The 'sSearch', 'sMarker', 'sUp', and 'sDown' modules allow users to retrieve specific data information, obtain common marker genes for cell types, freely upload, and download single-cell datasets, respectively. Two display modules ('HOME' and 'HELP') offer easier access to the SPEED database with informative statistics and detailed guidelines. All in all, SPEED is an integrated platform for single-cell RNA sequencing (scRNA-seq) and single-cell whole-genome sequencing (scWGS) datasets to assist the deep-mining and understanding of heterogeneity among cells, tissues, and species at multi-levels, angles, and orientations, as well as provide new insights into molecular mechanisms of biological development and pathogenesis. © 2023 The Author(s).",TextMining
"Background: With the widespread application of platinum drugs in antitumor therapy, the incidence of platinum drug adverse events (ADEs) is always severe. This study aimed to explore the adverse event signals of Cisplatin, Carboplatin and Oxaliplatin, three widely used platinum-containing drugs, and to provide a reference for rational individualized clinical drug use. Methods: The adverse event report data of the three platinum drugs from the first quarter of 2017 to the fourth quarter of 2021 were extracted from the FAERS database, and the data mining and risk factors for the relevant reports were carried out using the reporting odds ratio (ROR) method the proportional reporting ratio (PRR)and the comprehensive criteria (MHRA) method. Results: A total of 1853 effective adverse event signals were obtained for the three platinum agents, including 558 effective signals for Cisplatin, 896 effective signals for Carboplatin, and 399 effective signals for Oxaliplatin. The signals involve 23 effective different system organs (SOCs). The adverse events of Cisplatin are mainly fixed on blood and lymphatic system diseases, gastrointestinal diseases, systemic diseases and various reactions at the administration site. The adverse events of Carboplatin are mainly focused on blood and lymphatic system diseases, respiratory system, thoracic and mediastinal diseases, while the adverse events of Oxaliplatin are mainly concentrated in respiratory system, thoracic and mediastinal diseases, various nervous system diseases, and gastrointestinal system diseases. Conclusion: It was found that the main systems involved in common adverse events of platinum drugs are different, and the correlation strength of platinum drugs with the certain adverse events of each system is different. Copyright © 2023 Feng, Zhou, Chen, Li and Chen.",TextMining
"Resistance to drug treatment is a critical barrier in cancer therapy. There is an unmet need to explore cancer hallmarks that can be targeted to overcome this resistance for therapeutic gain. Over time, metabolic reprogramming has been recognised as one hallmark that can be used to prevent therapeutic resistance. With the advent of metabolomics, targeting metabolic alterations in cancer cells and host patients represents an emerging therapeutic strategy for overcoming cancer drug resistance. Driven by technological and methodological advances in mass spectrometry imaging, spatial metabolomics involves the profiling of all the metabolites (metabolomics) so that the spatial information is captured bona fide within the sample. Spatial metabolomics offers an opportunity to demonstrate the drug-resistant tumor profile with metabolic heterogeneity, and also poses a data-mining challenge to reveal meaningful insights from high-dimensional spatial information. In this review, we discuss the latest progress, with the focus on currently available bulk, single-cell and spatial metabolomics technologies and their successful applications in pre-clinical and translational studies on cancer drug resistance. We provide a summary of metabolic mechanisms underlying cancer drug resistance from different aspects; these include the Warburg effect, altered amino acid/lipid/drug metabolism, generation of drug-resistant cancer stem cells, and immunosuppressive metabolism. Furthermore, we propose solutions describing how to overcome cancer drug resistance; these include early detection during cancer initiation, monitoring of clinical drug response, novel anticancer drug and target metabolism, immunotherapy, and the emergence of spatial metabolomics. We conclude by describing the perspectives on how spatial omics approaches (integrating spatial metabolomics) could be further developed to improve the management of drug resistance in cancer patients. Copyright © 2023 Zhang, Bao, Jiang, Wang, Wang, Lu and Fang.",TextMining
"Autism Spectrum Disorder (ASD) has been identified as one of the most challenging and intriguing problems in neurodevelopment of children. Recent research suggest that conventional assessment on the basis of explicit behavior observations can be well complemented by evaluation of intrinsic neurophysiological states via analyses of brain imaging data such as electroencephalogram (EEG). However, before any more objective and comprehensive insights for a joint ASD assessment may be obtained, research challenges still remain: (1) how to characterize the interaction relationship of features rooted from recordings in different modalities; and at the same time (2) how to adapt to the individuality of subjects. This study develops a graph-based solution towards individualized assessment of ASD subjects via construction of the relationship of the dual-modal features of eye-tracking recordings and EEG: (1) Relationship Matrix Construction: A shallow encoding module as a variant of Multi-Level Perception (MLP) derives the initial intra- and inter-modal relationship matrix of the features in both modalities; and (2) Graph-based Relationship Learning: A model based on Deep Graph Convolutional Networks (D-GCN) fuses the global information of dual-modal features to learn the final relationship matrix, which is refined in the process of parameter optimization under the regulation of ASD classification. The resulted sample-specific matrices can then be exploited to address the individuality of subjects under examination. Experimental results indicate that: (1) the proposed method is superior to both the single-modal and multi-modal counterparts in ASD classification; (2) it excels in mining hidden connections among features in different modalities in comparison with mainstream methods for correlation measurement; and (3) it holds potentials in mitigating the uncertain variations brought by the individuality of subjects in ASD assessment. © 2022",TextMining
"microbioTA (http://bio-annotation.cn/microbiota) was constructed to provide a comprehensive, user-friendly resource for the application of microbiome data from diseased tissues, helping users improve their general knowledge and deep understanding of tissue-derived microbes. Various microbes have been found to colonize cancer tissues and play important roles in cancer diagnoses and outcomes, with many studies focusing on developing better cancer-related microbiome data. However, there are currently no independent, comprehensive open resources cataloguing cancer-related microbiome data, which limits the exploration of the relationship between these microbes and cancer progression. Given this, we propose a new strategy to re-align the existing next-generation sequencing data to facilitate the mining of hidden sequence data describing the microbiome to maximize available resources. To this end, we collected 417 publicly available datasets from 25 human and 14 mouse tissues from the Gene Expression Omnibus database and use these to develop a novel pipeline to re-align microbiome sequences facilitating in-depth analyses designed to reveal the microbial profile of various cancer tissues and their healthy controls. microbioTA is a user-friendly online platform which allows users to browse, search, visualize, and download microbial abundance data from various tissues along with corresponding analysis results, aimimg at providing a reference for cancer-related microbiome research. © The Author(s) 2022. Published by Oxford University Press on behalf of Nucleic Acids Research.",TextMining
"Invasive alien species are responsible for considerable biodiversity loss and environmental damage. Timely detection of new incursions is critical in preventing novel populations establishing. Citizen reports currently account for the majority of alien species detections, arising from the massive observation effort that the physical and digital 'eyes and ears' of citizens provide, in combination with crowd-sourced species identification. Because the reporting of alien species sightings is generally not mandatory, there is interest in whether mining social media data via image recognition and/or natural language processing can improve on existing passive citizen surveillance in a cost-effective manner. Here, we illustrate, using examples from Australia, how citizen surveillance for most vertebrate groups appears to currently be effective using existing voluntary reporting mechanisms. Where citizen surveillance is currently ineffective, for reasons of inadequate sampling, data mining of social media feeds will be similarly affected. We argue that mining citizens' social media data for evidence of invasive alien species needs to demonstrate not only that it will be an improvement on the business as usual case, but also that any gains achieved cannot be achieved by alternative approaches. We highlight the potential role of education in increasing the surveillance effectiveness of citizens for detecting and reporting sightings of alien species. Should data mining of social media platforms be pursued, we note that the scale of the task in terms of the potential number of exotic vertebrate species to be classified is very large. The expected number of false positive classifications would present a considerable workload to process, possibly undermining the efficiency rationale for the use of data mining. Hence, prioritisation is needed, and we illustrate how the number of species to be classified can be reduced considerably. If we are to deploy data mining and analysis of social media data to help with detecting introductions of invasive alien species, we need to conduct it in a manner where it adds value and is trusted.  © 2023 The Author(s) (or their employer(s)).",TextMining
"Much of the complexity within cells arises from functional and regulatory interactions among proteins. The core of these interactions is increasingly known, but novel interactions continue to be discovered, and the information remains scattered across different database resources, experimental modalities and levels of mechanistic detail. The STRING database (https://string-db.org/) systematically collects and integrates protein-protein interactions - both physical interactions as well as functional associations. The data originate from a number of sources: automated text mining of the scientific literature, computational interaction predictions from co-expression, conserved genomic context, databases of interaction experiments and known complexes/pathways from curated sources. All of these interactions are critically assessed, scored, and subsequently automatically transferred to less well-studied organisms using hierarchical orthology information. The data can be accessed via the website, but also programmatically and via bulk downloads. The most recent developments in STRING (version 12.0) are: (i) it is now possible to create, browse and analyze a full interaction network for any novel genome of interest, by submitting its complement of encoded proteins, (ii) the co-expression channel now uses variational auto-encoders to predict interactions, and it covers two new sources, single-cell RNA-seq and experimental proteomics data and (iii) the confidence in each experimentally derived interaction is now estimated based on the detection method used, and communicated to the user in the web-interface. Furthermore, STRING continues to enhance its facilities for functional enrichment analysis, which are now fully available also for user-submitted genomes.  © 2023 The Author(s).",TextMining
"Background and objective: Prediction of poststroke recovery can be expressed by prognostic biomarkers that are related to the pathophysiology of stroke at the cellular and molecular level as well as to the brain structural and functional reserve after stroke at the systems neuroscience level. This study aimed to review potential biomarkers that can predict poststroke functional recovery. Methods: A narrative review was conducted to qualitatively summarize the current evidence on biomarkers used to predict poststroke functional recovery. Results: Neurophysiological measurements and neuroimaging of the brain and a wide diversity of molecules had been used as prognostic biomarkers to predict stroke recovery. Neurophysiological studies using resting-state electroencephalography (EEG) revealed an interhemispheric asymmetry, driven by an increase in low-frequency oscillation and a decrease in high-frequency oscillation in the ipsilesional hemisphere relative to the contralesional side, which was indicative of individual recovery potential. The magnitude of somatosensory evoked potentials and event-related desynchronization elicited by movement in task-related EEG was positively associated with the quantity of recovery. Besides, transcranial magnetic stimulation (TMS) studies revealed the potential values of using motor-evoked potentials (MEP) and TMS-evoked EEG potentials from the ipsilesional motor cortex as prognostic biomarkers. Brain structures measured using magnetic resonance imaging (MRI) have been implicated in stroke outcome prediction. Specifically, the damage to the corticospinal tract (CST) and anatomical motor connections disrupted by stroke lesion predicted motor recovery. In addition, a wide variety of molecular, genetic, and epigenetic biomarkers, including hemostasis, inflammation, tissue remodeling, apoptosis, oxidative stress, infection, metabolism, brain-derived, neuroendocrine, and cardiac biomarkers, etc., were associated with poor functional outcomes after stroke. However, challenges such as mixed evidence and analytical concerns such as specificity and sensitivity have to be addressed before including molecular biomarkers in routine clinical practice. Conclusion: Potential biomarkers with prognostic values for the prediction of functional recovery after stroke have been identified; however, a multimodal approach of biomarkers for prognostic prediction has rarely been studied in the literature. Future studies may incorporate a combination of multiple biomarkers from big data and develop algorithms using data mining methods to predict the recovery potential of patients after stroke in a more precise way. Copyright © 2023 Zhang, Sánchez Vidaña, Chan, Hui, Lau, Wang, Lau, Fong.",TextMining
"Knowledge graph can effectively manage massive information and deal with complex and diverse relationships. At the same time, knowledge search and decision-making based on knowledge graph are more in line with human logic and enhance the interpretability of answers. Since the current power transformer operations mainly depends on traditional experience, and has accumulated the massive operations within the power system documentation and the accident report, it is an urgent need to solve the problem on how to read the vast amounts of data quickly and accurately extract the valuable information, so as to use data-driven approach to transformer intelligent operations. Therefore, this paper proposes an ALBERT based knowledge graph construction method for power transformer operation and maintenance. First of all, due to the small number of publicly available operation and maintenance documents and accident handling reports in the field of power transformer operation and maintenance, it is necessary to build a training dataset for the field of power transformer. The construction process of the dataset is divided into two parts. The first part is to generate samples of the obtained fault analysis report, anomaly detection report and other texts on basis of the method of regular matching rules. The second part is to clean the obtained literature texts and annotate the processed texts with BIO method. Then, the ALBERT-BiLSTM-CRF model was used to extract entities from the operation and maintenance texts of power transformers, and the ALBERT-BiLSTM-Attention model is used to extract relations from the operation and maintenance texts of power transformers. Finally, the Neo4j graph database is used to store and visualize the extracted triple. In the light of the constructed knowledge graph of power transformer operation and maintenance, the auxiliary decision-making function of power transformer operation and maintenance can be realized. The ALBERT-BiLSTM-CRF model and ALBERT-BiLSTM-Attention model are used to conduct relation extraction experiments on the operation and maintenance texts of power transformers respectively. The accuracy of entity extraction using the ALBERT-BiLSTM-CRF model can reach 94.4%. The F1 score can reach 94.2%, which is 9.1% and 7.9% higher than BiLSTM-CRF respectively. The accuracy of ALBERT-BiLSTM-Attention model can reach 94.1%, and the F1 score can reach 95.1%, which are improved by 3.2% and 2.5% compared with the BiLSTM-Attention model. From the experimental results, it shows that the ALBERT pre-trained model has a good adaptability to extract entities and relations for power transformer operation and maintenance, and can better complete the task of knowledge extraction. To sum up, this paper proposes a knowledge graph construction method of power transformer operation and maintenance based on ALBERT model. The main conclusions are as follows: ① A training dataset of power transformer operation and maintenance text is constructed based on Selenium framework and the sample generation method of regular matching, which effectively solves the difficult problem of obtaining data sets in the field of power transformer operation and maintenance. ② The ALBERT-BiLSTM-CRF model and ALBERT-BiLSTM-Attention model are used to extract entities and relations from the operation and maintenance texts of power transformers. Compared with the traditional deep learning model, ALBERT model can effectively overcome the problems in power transformer operation and maintenance texts, such as too many proper nouns, letters and symbols among Chinese characters. ③ Based on the constructed power transformer operation and maintenance knowledge graph, the operation and maintenance auxiliary decision-making function can be realized, which provides a new idea for the intelligent operation and maintenance of power transformers. © 2023 Chinese Machine Press. All rights reserved.",TextMining
"Personalized news recommendation is important for users to find interesting news information and alleviate information overload. Although it has been extensively studied over decades and has achieved notable success in improving user experience, there are still many problems and challenges that need to be further studied. To help researchers master the advances in personalized news recommendation, in this article, we present a comprehensive overview of personalized news recommendation. Instead of following the conventional taxonomy of news recommendation methods, in this article, we propose a novel perspective to understand personalized news recommendation based on its core problems and the associated techniques and challenges. We first review the techniques for tackling each core problem in a personalized news recommender system and the challenges they face. Next, we introduce the public datasets and evaluation methods for personalized news recommendation. We then discuss the key points on improving the responsibility of personalized news recommender systems. Finally, we raise several research directions that are worth investigating in the future. This article can provide up-To-date and comprehensive views on personalized news recommendation. We hope this article can facilitate research on personalized news recommendation as well as related fields in natural language processing and data mining. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",TextMining
"Objective: Identifying hypertension in children and providing treatment for it have a marked impact on the patients’ long-term cardiovascular outcomes. The global prevalence of childhood hypertension is increasing, yet its investigation has been rather sporadic in Eastern Europe. Therefore, our goal was to determine the prevalence of childhood hypertension and its concomitant metabolic abnormalities using data mining methods. Methods: We evaluated data from 3 to 18-year-old children who visited the University of Debrecen Clinical Center’s hospital throughout a 15-year study period (n = 92,198; boys/girls: 48/52%). Results: We identified a total of 3,687 children with hypertension (2,107 boys and 1,580 girls), with a 4% calculated prevalence of hypertension in the whole study population and a higher prevalence in boys (4.7%) as compared to girls (3.2%). Among boys we found an increasing prevalence in consecutive age groups in the study population, but among girls the highest prevalences are identified in the 12-15-year age group. Markedly higher BMI values were found in hypertensive children as compared to non-hypertensives in all age groups. Moreover, significantly higher total cholesterol (4.27 ± 0.95 vs. 4.17 ± 0.88 mmol/L), LDL-C (2.62 ± 0.79 vs. 2.44 ± 0.74 mmol/L) and triglyceride (1.2 (0.85-1.69) vs. 0.94 (0.7-1.33) mmol/L), and lower HDL-C (1.2 ± 0.3 vs. 1.42 ± 0.39 mmol/L) levels were found in hypertensive children. Furthermore, significantly higher serum uric acid levels were found in children with hypertension (299.2 ± 86.1 vs. 259.9 ± 73.3 μmol/L), while glucose levels did not differ significantly. Conclusion: Our data suggest that the calculated prevalence of childhood hypertension in our region is comparable to data from other European countries and is associated with early metabolic disturbances. Data mining is an effective method for identifying childhood hypertension and its metabolic consequences. Copyright © 2023 Kovács, Németh, Daróczy, Karányi, Maroda, Diószegi, Nádró, Szabó, Harangi and Páll.",TextMining
"The exploration of nucleoside changes in human biofluids has profound potential for cancer diagnosis. Herein, we developed a rapid methodology to quantify 17 nucleosides by UHPLC-MS/MS. Five pairs of isomers were successfully separated within 8 min. The ME was mostly eliminated by sample dilution folds of 1000 for urine and 40 for CCS. The optimized method was firstly applied to screen potential nucleoside biomarkers in CCS by comprising bladder cancer cell lines (5637 and T24) and normal human bladder cell line SV-HUC-1 together with student's t-test and OPLS-DA. Nucleosides with significant differences in the supernatant of urine samples were also uncovered comparing BCa with the non-tumor group, as well as a comparison of BCa recurrence group with the non-recurrence group. By intersecting the differential nucleosides in CCS and urine supernatant, and then further confirmed using validation sets, the combination of m3C and m1A with AUC of 0.775 was considered as a potential biomarker for bladder cancer diagnosis. A panel of m3C, m1A, m1G, and m22G was defined as potential biomarkers for bladder cancer prognosis with an AUC of 0.819. Above all, this method provided a new perspective for diagnosis and recurrence monitoring of bladder cancer. Significance: The exploration of nucleoside changes in body fluids has profound potential for the diagnosis and elucidation of the pathogenesis of cancer. In this study, we developed a rapid methodology for the simultaneous quantitative determination of 17 nucleosides in the supernatant of cells and urine samples using UHPLC-MS/MS to discover and validate bladder cancer related excreted nucleoside biomarkers. The results of this paper provide a new strategy for diagnosis and postoperative recurrence monitoring of bladder cancer and provide theoretical support for the exploration of its pathogenesis. © 2022",TextMining
"By predicting ERα bioactivity and mining the potential relationship between Absorption, Distribution, Metabolism, Excretion, Toxicity (ADMET) attributes in drug research and development, the development efficiency of specific drugs for breast cancer will be effectively improved and the misjudgment rate of R&D personnel will be reduced. The quantitative prediction model of ERα bioactivity and classification prediction model of Absorption, Distribution, Metabolism, Excretion, Toxicity properties were constructed. The prediction results of ERα bioactivity were compared by XGBoot, Light GBM, Random Forest and MLP neural network. Two models with high prediction accuracy were selected and fused to obtain ERα bioactivity prediction model from Mean absolute error (MAE), mean squared error (MSE) and R2. The data were further subjected to model-based feature selection and FDR/FPR-based feature selection, respectively, and the results were placed in a voting machine to obtain Absorption, Distribution, Metabolism, Excretion, Toxicity classification prediction model. In this study, 430 molecular descriptors were removed, and finally 20 molecular descriptors with the most significant effect on biological activity obtained by the dual feature screening combined optimization method were used to establish a compound molecular descriptor prediction model for ERα biological activity, and further classification and prediction of the Absorption, Distribution, Metabolism, Excretion, Toxicity properties of the drugs were made. Eighty variables were selected by the model ExtraTreesClassifier Classifie, and 40 variables were selected by the model GradientBoostingClassifier to complete the model-based feature selection. At the same time, the feature selection method based on FDR/FPR is also selected, and the three classification models obtained by the two methods are placed into the voting machine to obtain the final model. The experimental results showed that the model‘s evaluation indexes and roc diagram were excellent and could accurately predict ERα bioactivity and Absorption, Distribution, Metabolism, Excretion, Toxicity properties. The model constructed in this study has high accuracy, fast convergence and robustness, has a very high accuracy for Absorption, Distribution, Metabolism, Excretion, Toxicity and ERα classification prediction, has bright prospects in the biopharmaceutical field, and is an important method for energy conservation and yield increase in the future. Copyright © 2023 An, Chen, Chen, Ma, Wang and Zhao.",TextMining
"The network autonomous learning monitoring system is a subsystem of the learning quality monitoring system in the network education platform. Based on the training objectives of network education and the course learning objectives of learners, and on the basis of educational evaluation theory, it makes value judgments on learners' attitudes, knowledge and ability development level in the whole learning process. Through the planning, inspection, evaluation, feedback, control and adjustment of learners' learning activities, timely guide learners to correct their learning attitude, adjust their learning strategies, and effectively use learning resources and modern information technology means to carry out autonomous learning, so as to achieve the expected learning goals. The network self-learning monitoring system is based on the database created by SQL Server platform, supports C/S structure, has good scalability and usability, and is used to extract and analyze data. SVM algorithm is used to extract system features, which has the advantages of low system load, low response delay and good performance. An accurate network autonomous learning monitoring system model is constructed. After system test, the network autonomous learning monitoring system based on SVM algorithm has high data analysis ability, easy to understand, easy to maintain, reasonable structure and easy to use, which meets the needs of learners. Using SVM algorithm for feature extraction, the evaluation performance of the algorithm is improved by more than 3.2%. When learners learn in the system, the system load is small, the response delay is low, and the performance is good. It is an accurate network autonomous learning monitoring system.  © 2023 ACM.",TextMining
"Medicine recommendation systems target to recommend a set of medicines given a set of symptoms which play a crucial role in assisting doctors in their daily clinics. Existing approaches are either rule-based or supervised. However, the former heavily relies on expert labeling, which is time-consuming and costly to collect, and the latter suffers from the data sparse problem. To automate medicine recommendation on sparse data, we propose MedRec, which introduces two graphs in modeling: (1) a knowledge graph connecting diseases, medicines, symptoms, and examinations; (2) an attribute graph connecting medicines via shared attributes and molecular structures. These two graphs enhance the connectivity between symptoms and medicines, which thus alleviate the data sparse problem. By learning the interrelationship between diseases, medicines, symptoms and examinations and the inner relationship within medicine, we can acquire unified embedding representations of symptoms and medicines which can be used in medicine recommendation. The experimental results show that the proposed model outperforms state-of-the-art methods. In addition, we find that these two tasks: learning graph representation and medical recommendation can benefit each other. © 2023 Association for Computing Machinery.",TextMining
"The gateway of the thick coal seam working face in the Datong mining area was excavated along a small coal pillar, resulting in serious bolt (cable) breaking failure, strong surrounding rock deformation, serious ground pressure appearance, and difficulties surrounding rock control. So, the bolt (cable) breaking characteristics and corresponding causes of the 5106 return air gateway with a small coal pillar in Dongzhouyao coal mine (a mine in the Datong mining area) were analyzed through an on-site investigation, surrounding rock geotechnical parameters test, theoretical analysis, laboratory experiment, on-site engineering test, and other research means. The study carried out laboratory testing and analysis on the stress distribution characteristics and laws of the bolts, put forward the bolt (cable) breaking mechanism and prevention countermeasures, and completed the field industrial test of the surrounding rock pressure relief and support joint control technology in the gateway. The on-site tracking and data showed that the breaking conditions of the bolts (cables) were significantly reduced by improving the initial force of the bolts (cables), optimizing the supporting materials and components, canceling the pressure ring, and implementing the hydraulic fracturing top cutting and pressure relief + high prestressed full cable support technology. The displacement of the top and bottom plates was reduced by 51%, the displacement of the two sides was reduced by 46%, and the influence distance of the working face advance stress was reduced from 85 m to 30 m. The successful implementation of the study results in the small pillar gateway of the Dongzhouyao coal mine provided a reference for the promotion and application of similar gateway conditions in the Datong mining area. Copyright © 2023 Peng.",TextMining
"Mineral extraction areas represent an environmental, social, and also a food sovereignty challenge for several countries. Indigenous Peoples and local communities (IPLC) are particularly vulnerable to the impacts of mining activities, particularly those that affect their lands and waters. At the global level, scientific evidence on the impacts of mining on the food sovereignty of IPLC is meagre, scattered, and fragmented across disciplines and geographic regions. This study aims to assess whether factors such as mining, trace elements contamination, social inequality, lack of environmental deficitary environmental policy and practice, and socio-environmental conflicts directly impact the food sovereignty of IPLC worldwide. Through a comprehensive literature review of 403 articles, we mapped globally the impacts of mining activities on the food sovereignty of IPLC. Our results reveal that the combination of mining, social inequality and weak environmental strategies impinge negatively on the food sovereignty of IPLC. A hundred and six articles reviewed contained a detailed ecotoxicological analysis of food resources used by IPLC in mining areas. Of all documented species, 52.9 % were vascular plants, 40.3 % were fish and 6.8 % were mammals, presenting substantial scientific evidence of the contamination of food systems of IPLC as a direct result of mining. Given the magnitude of the evidence presented in this review, we propose strategic policy actions to address the impacts of mining on IPLC food sovereignty, such as the strengthening of social, cultural, and environmental safeguards in the mining sector, which should include provisions for the protection of the food systems of IPLC and their culturally-valued food resources, as well as monitoring of contaminant concentrations in the environment and in culturally-valued food resources. © 2022 Elsevier B.V.",TextMining
"Purpose: This study aims to explore the success factors of tourism performing arts (TPA) programs by analyzing a large data set of online reviews. Design/methodology/approach: A total of 195,230 reviews from Ctrip.com were collected and preprocessed. A deep learning method was leveraged to estimate the similarity between words. Then, regression analysis was conducted to determine success factors. Findings: This study extracted four positive and two negative factors affecting tourist satisfaction with tourism performance arts. The results demonstrate that the tourists paid the most attention to the traditional Chinese cultural aspects, audiovisual effects and the actors’ performing enthusiasm. Research limitations/implications: Despite this study’s large data set, the focused was only on Chinese reviews. It would be useful and interesting to compare the success factors of tourism performance arts programs offered in different countries. Practical implications: The study findings can contribute to the development of TPA programs to attract tourists to travel destinations. Originality/value: This study demonstrates that analyzing online reviews of TPA through text mining technology is an effective method of understanding tourist satisfaction. © 2022, Emerald Publishing Limited.",TextMining
"Introduction: The Abunabu antimony mining area is located between the Indus–Yarlung Tsangpo suture and the southern Tibetan detachment system. Ore deposits in the mining area provide an excellent opportunity to understand the nature and genesis of antimony mineralisation in the Tethys Himalayan metallogenic belt. Methods: In this study, we analysed the He–Ar and S isotopic compositions of stibnite-hosted fluid inclusions as a basis for investigating the sources of ore-forming fluids in the Abunabu mining area and the Tethys Himalayan metallogenic belt. Results: The analysed stibnites have 4He contents of 0.016 × 10−7–1.584 × 10–7 cm3 STP/g, 40Ar contents of 1.37 × 10−7–2.94 × 10–7 cm3 STP/g, 40Ar/36Ar ratios of 303.8–320.7, and 3He/4He (Ra) ratios of 0.021–0.351. These isotopic features indicate that the ore-forming fluids were primarily metamorphic fluids of crustal origin, with small amounts of magmatic-derived materials and modified air-saturated water with low 40Ar*/4He ratios. The δ34S values of stibnite vary within a narrow range of −4.9‰ to −3.5‰, with a mean value of −4.31‰, indicating a deep magmatic origin. Discussion: On the basis of these results and a compilation of data for sulphide deposits in the metallogenic belt, we infer that compositional variations in the He and Ar isotopes of the ore-forming fluids of each antimony deposit in the Tethys Himalayan metallogenic belt are independent of each other. This suggests that antimony deposits in the belt had similar ore-forming fluid sources and mixing processes and that differences in the metallogenic tectonic setting within the belt emerged only in the later stages of deposit evolution. Our new results and compiled data also show that antimony–gold deposits and lead–zinc–antimony polymetallic deposits in the Tethys Himalayan metallogenic belt differ in their sulphur isotopic compositions and that multiple sulphur sources were involved in each of these types of deposit. Copyright © 2023 Li, Wang, Li, Sun, Puchi, Zhang, Lamu and Yang.",TextMining
"The lifetime and performance of any engineering component, from nanoscale sensors to macroscopic structures, are strongly influenced by fracture processes. Fracture itself is a highly localized event; originating at the atomic scale by bond breaking between individual atoms close to the crack tip. These processes, however, interact with defects such as dislocations or grain boundaries and influence phenomena on much larger length scales, ultimately giving rise to macroscopic behavior and engineering-scale fracture properties. This complex interplay is the fundamental reason why identifying the atomistic structural and energetic processes occurring at a crack tip remains a longstanding and still unsolved challenge. We develop a new analysis approach for combining quantitative in-situ observations of nanoscale deformation processes at a crack tip with three-dimensional reconstruction of the dislocation structure and advanced computational analysis to address plasticity and fracture initiation in a ductile metal. Our combinatorial approach reveals details of dislocation nucleation, their interaction process, and the local internal stress state, all of which were previously inaccessible to experiments. This enables us to describe fracture processes based on local crack driving forces on a dislocation level with a high fidelity that paves the way towards a better understanding and control of local failure processes in materials. © 2022 The Authors",TextMining
"Numerous researchers have applied nature-inspired population-based metaheuristics for solving optimization problems including data clustering. However, the issues of premature convergence and slow convergence rate can still occur when these promising search methods are applied to complex and large data-clustering problems, including the evaporation-rate based water cycle algorithm, WCAER. In this paper, a recently proposed hybrid version of WCAER in conjunction with a local search method named Hookes and Jeeves method was further tested to perform data clustering for large dataset. The proposed hybrid algorithm is experimented on the gas turbine emission data that contains 36733 instances of 11 sensor measures aggregated over one hour, from a gas turbine in Turkey, available from the UCI machine-learning repository. The simulation results confirm the superiority of the hybrid method as an efficient and reliable algorithm to solve gas turbine clustering problem, in comparison to the original evaporation-rate based water cycle algorithm, in terms of solution quality as well as computational performance formulated from two applied objective functions namely the Euclidean distance and the Davies-Bouldin index. Thus, the outcome of the study generally provides some performance evaluation of WCAER for large dataset when applied in cluster analysis, a valuable data analysis and data mining technique. It is hoped that other metaheuristics could be applied to the 5 years span large dataset for performance comparison with other further considerations such as using various suitable objective functions and cluster validity indices. © 2023 American Institute of Physics Inc.. All rights reserved.",TextMining
"We present MediaDive (https://mediadive.dsmz.de), a comprehensive and expert-curated cultivation media database, which comprises recipes, instructions and molecular compositions of >3200 standardized cultivation media for >40 000 microbial strains from all domains of life. MediaDive is designed to enable broad range applications from every-day-use in research and diagnostic laboratories to knowledge-driven support of new media design and artificial intelligence-driven data mining. It offers a number of intuitive search functions and comparison tools, for example to identify media for related taxonomic groups and to integrate strain-specific modifications. Besides classical PDF archiving and printing, the state-of-the-art website allows paperless use of media recipes on mobile devices for convenient wet-lab use. In addition, data can be retrieved using a RESTful web service for large-scale data analyses. An internal editor interface ensures continuous extension and curation of media by cultivation experts from the Leibniz Institute DSMZ, which is interlinked with the growing microbial collections at DSMZ. External user engagement is covered by a dedicated media builder tool. The standardized and programmatically accessible data will foster new approaches for the design of cultivation media to target the vast majority of uncultured microorganisms. © The Author(s) 2022. Published by Oxford University Press on behalf of Nucleic Acids Research.",TextMining
"As the forefront of China' s marine economic development, the continental coastal zone of the East China Sea has a significant strategic position. Exploring the spatiotemporal variation characteristics and driving factors of the coastal zone under high-intensity development will help to reveal the evolution process and law of the development intensity of the coastal zone, and promote the development of coastal resources, environment and society. Sustainable and high-quality economic development. This study took the continental coast of the East China Sea as the research object, and used the coastline and land use data of the 7th period from 1990 to 2020 to reveal the characteristics of the development and utilization intensity of the continental coastline and coastal land use in the East China Sea, and explored the driving factors of high-intensity development by using the geodetector method. The results showed that: (1) The average moving speed of the coastline of the East China Sea was 32.34 m/ year, and the average moving speed of the coastline in the northern region (43.54 m/year) was higher than that in the south (20.23 m/year). The average moving speed of the coastline in the south bank of Hangzhou Bay was the fastest in many periods, while that in the Xiamen-Zhangzhou region was slower. In terms of spatial distribution, the areas with more dramatic coastline changes were mainly concentrated in estuaries, bays, and coastal areas with higher urban levels. (2) The area of farmland, forest, grassland, water area, sea area, etc. continued to decrease, and the area of urban construction and industrial and mining land continued to increase. The land development intensity in the southern and northern parts of the coastal zone was relatively high, while the land development intensity in the central region was relatively weak. (3) Natural factors established the macroscopic pattern of land development intensity in the continental coastal zone of the East China Sea, and social and economic factors played an important role in promoting it. © 2023, Science Press. All rights reserved.",TextMining
[No abstract available],TextMining
"Purpose: Zakat (Islamic almsgiving) plays a considerable role in dealing with the socioeconomic issues in times of COVID-19 pandemic, and such roles have been widely discussed in virtual events. This paper aims to discover knowledge of the current global zakat administration from virtual events of zakat (e.g. webinars) on YouTube and Zoom via text mining approach. Design/methodology/approach: The authors purposefully sampled 12 experts from four different virtual zakat events on YouTube and Zoom. The automated text transcription software is used to pull the information from the sampled videos into text documents. A qualitative analysis is operated using text mining approach via machine learning tool (i.e. Orange Data Mining). Four research questions are developed under the Word Cloud visualisation, hierarchal clustering, topic modelling and graph and network theory. Findings: The machine learning identifies the most important words, the relationship between the experts and their top words and discovers hidden themes from the sample. This finding is practically substantial for zakat stakeholders to understand the current issues of global zakat administration and to learn the applicable lessons from the current issues of zakat management worldwide. Research limitations/implications: This study does not establish a positivist generalisation from the findings because of the nature and objective of the study. Practical implications: A policy implication is drawn pertaining to the legislation of zakat as an Islamic financial policy instrument for combating poverty in Muslim society. Social implications: This work supports the notion of “socioeconomic zakat”, implying that zakat as a religious obligation is important in shaping the social and economic processes of a Muslim community. Originality/values: This work marks the novelty in making sense of the unstructured data from virtual events on YouTube and Zoom in the Islamic social finance research. © 2022, Emerald Publishing Limited.",TextMining
"Diabetic wound takes longer time to heal due to micro and macro-vascular ailment. This longer healing time can lead to infections and other health complications. Foot ulcers are one of the most common diabetic wounds. These are one of the leading cause of amputations. Medical science is continuously striving for improving quality of human life. A recent trend of amalgamation of knowledge, efforts and technological advancement of medical science experts and artificial intelligence researchers, has made tremendous success in diagnosis, prognosis and treatment of a variety of diseases. Diabetic wounds are no exception, as artificial intelligence experts are putting their research efforts to apply latest technological advancements in the field to help medical care personnel to deal with diabetic wounds in more effective manner. The presented study reviews the diagnostic and treatment research under the umbrella of Artificial Intelligence and computational science, for diabetic wound healing. Framework for diabetic wound assessment using artificial intelligence is presented. Moreover, this review is focused on existing and potential contribution of artificial intelligence to improve medical services for diabetic wound patients. The article also discusses the future directions for the betterment of the field that can lead to facilitate both, clinician and patients. © The Author(s) 2023. Published by Baishideng Publishing Group Inc. All rights reserved.",TextMining
"Maize is the second most important agricultural commodity after rice. In Indonesia, maize is an alternative complimentary food, even in some areas it is used as the main food. The future prospect, maize production was increased for national sufficient. However, there are obstacles for achieving it. One of them is the attack of pests and diseases. In this article, image classification on maize leaf diseases is presented. Image classification is a common task when performing image mining. However, classification without a visual explanation certainly makes it difficult for the user to understand the results. This article aims to classify as well as visually explanation the abnormality or emergence of maize leaf diseases. The research is divided into 2 steps: classification and visual explanation. Classification uses Convolutional Neural Network (CNN) Squeezenet while visual explanation uses Gradient-Weighted Class Activation Map (Grad-CAM). The data experiment used from PlantVillage dataset with 4 classes: healthy, blight, spots, and rust. The percentage of training, validation, and testing data was 60:20:20. Validation using 10 fold cross-validation. The novelty was apply the visual explanation using GradCAM on maize leaf diseases. Performance Measure for classification are 95.2%, 94.03%, and 94.28% for accuracy, precision and recall, respectively. © 2023 American Institute of Physics Inc.. All rights reserved.",TextMining
"The mechanical study of people's opinions, sentiments, attitudes, and emotions as they are expressed through communication is known as sentiment analysis or opinion mining. This one has recently been among the most popular analytical themes in text mining and Natural Language Processing. Its widespread popularity is due to two factors: The first factor is opinions are fundamental to practically all human endeavors and are significant determinants of a person's behavior. It has a wide range of applications. Second, it resolves several challenging analysis problems that were never even attempted. We employed Big Data Framework to solve the issue because traditional solutions cannot handle the exponential growth of Amazon's food data. In this study, we investigate various approaches to sentiment analysis for large datasets of Amazon Fine Food reviews using the Apache Spark data processing engine and utilizing MLlib, the machine learning package for Apache Spark, three techniques - Linear SVC, Logistic Regression, and Naive Bayes - with more than 80% accuracy rates. We find that linear SVC outperforms NB and logistic regression. Through empirical analysis, we find that sentiment analysis through a big data framework is more efficient in computation time compared to sentiment analysis without the map-reduce framework. © 2023 The authors and IOS Press.",TextMining
"Characterization of the specific expression and chromatin profiles of genes enables understanding how they contribute to tissue/organ development and the mechanisms leading to diseases. Whilst the number of single-cell sequencing studies is increasing dramatically; however, data mining and reanalysis remains challenging. Herein, we systematically curated the up-to-date and most comprehensive datasets of sequencing data originating from 2760 bulk samples and over 5.1 million single-cells from multiple developmental periods from humans and multiple model organisms. With unified and systematic analysis, we profiled the gene expression and chromatin accessibility among 481 cell-types, 79 tissue-types and 92 timepoints, and pinpointed cells with the co-expression of target genes. We also enabled the detection of gene(s) with a temporal and cell-type specific expression profile that is similar to or distinct from that of a target gene. Additionally, we illustrated the potential upstream and downstream gene−gene regulation interactions, particularly under the same biological process(es) or KEGG pathway(s). Thus, TEDD (Temporal Expression during Development Database), a value-added database with a user-friendly interface, not only enables researchers to identify cell-type/tissue-type specific and temporal gene expression and chromatin profiles but also facilitates the association of genes with undefined biological functions in development and diseases. The database URL is https://TEDD.obg.cuhk.edu.hk/. © The Author(s) 2022. Published by Oxford University Press on behalf of Nucleic Acids Research.",TextMining
"Introduction: Cancer is a primary public concern in the European continent. Due to the large case numbers and survival rates, a significant population is living with cancer needs. Consequently, health professionals must deal with complex treatment decision-making processes. In this context, a large quantity of data is collected during cancer care delivery. Once collected, these data are complex for health professionals to access to support clinical decision-making and performance review. There is a need for innovative tools that make clinical data more accessible to support cancer health professionals in these activities. Methods: Following a co-creation, an interactive approach thanks to the Interactive Process Mining paradigm, and data from a tertiary hospital, we developed an exploratory tool to present cancer patients' progress over time. Results: This work aims to collect and report the process of developing an exploratory analytical Interactive Process Mining tool with clinical relevance for healthcare professionals for monitoring cancer patients' care processes in the context of the LifeChamps project together with a graphical and navigable Process Indicator in the context of prostate cancer patients. Discussion: The tool presented includes Process Mining techniques to infer actual processes and present understandable results visually and navigable, looking for different types of patients, trajectories, and behaviors. Copyright © 2023 Valero-Ramon, Fernandez-Llatas, Collantes, Valdivieso, Billis, Bamidis and Traver.",TextMining
"Employment scams, such as scapegoat positions, clickbait and non-existing jobs, etc., are among the top five scams registered over online platforms.1 Generally, scam complaints contain heterogeneous information (money, location, employment type, organization, email, and phone number), which can provide critical insights for appropriate interventions to avoid scams. Despite substantial efforts to analyze employment scams, integrating relevant scam-related information in structured form remains unexplored. In this work, we extract this information and construct a large-scale Employment Scam Knowledge Graph consisting of 0.1M entities and 0.2M relationships. Our findings include discovering different modes of employment scams, entities, and relationships among entities to alert job seekers. We plan to extend this work by utilizing a knowledge graph to identify and avoid potential scams in the future.  © 2023 Owner/Author.",TextMining
"The demand for robust microbial cell factories that produce valuable biomaterials while resisting stresses imposed by current bioprocesses is rapidly growing. Rhodosporidium toruloides is an emerging host that presents desirable features for bioproduction, since it can grow in a wide range of substrates and tolerate a variety of toxic compounds. To explore R. toruloides suitability for application as a cell factory in biorefineries, we sought to understand the transcriptional responses of this yeast when growing under experimental settings that simulated those used in biofuels-related industries. Thus, we performed RNA sequencing of the oleaginous, carotenogenic yeast in different contexts. The first ones were stress-related: two conditions of high temperature (37 and 42°C) and two ethanol concentrations (2 and 4%), while the other used the inexpensive and abundant sugarcane juice as substrate. Differential expression and functional analysis were implemented using transcriptomic data to select differentially expressed genes and enriched pathways from each set-up. A reproducible bioinformatics workflow was developed for mining new regulatory elements. We then predicted, for the first time in this yeast, binding motifs for several transcription factors, including HAC1, ARG80, RPN4, ADR1, and DAL81. Most putative transcription factors uncovered here were involved in stress responses and found in the yeast genome. Our method for motif discovery provides a new realm of possibilities in studying gene regulatory networks, not only for the emerging host R. toruloides, but for other organisms of biotechnological importance. Copyright © 2023 Nora, Cassiano, Santana, Guazzaroni, Silva-Rocha and da Silva.",TextMining
"This chapter describes traditional and intuitive fault localization techniques, including program logging, assertions, breakpoints, and profiling. Many advanced fault localization techniques have surfaced recently using the idea of causality, which is related to philosophical theories with an objective to characterize the relationship between events/causes and a phenomenon/effect. The chapter aims to classify fault localization techniques into nine categories, including slicing-based, spectrum-based, statistics-based, machine learning-based, data mining-based, IR-based, model-based, spreadsheet-based techniques, and additional emerging techniques. It lists some of the popular subject programs that have been used in different case studies and discusses how these programs have evolved through the years. The chapter describes different evaluation metrics to assess the effectiveness of fault localization techniques. One challenge for many empirical studies on software fault localization is that they require appropriate tool support for automatic or semiautomatic data collection and suspiciousness computation. The chapter also presents an overview on the key concepts discussed in this book. © 2023 The Institute of Electrical and Electronics Engineers, Inc. All rights reserved.",TextMining
"The development of the automatic fare collection (AFC) systems provides significant support for predicting passenger flow on urban rail transit. This paper extracts passenger travel patterns using AFC data on urban rail transit in Chengdu, China, over a one-month period. Passengers are divided into two categories based on their travel habits and data mining models, and multinomial logit (MNL) models are separately used to predict their destinations. Furthermore, a two-way search algorithm is developed to search the optimal paths between origin-destination (OD) pairs by considering interchange constraints. Start a path search through the origin point and destination point, respectively, until the shortest path is found. The maximum effectiveness of a path is measured by travel time, interchange time, and the number of interchanges between the OD pairs. Finally, the validity of the proposed passenger flow path prediction method is verified by using the AFC data of Chengdu metropolitan rail transit from April 2018.  © 2023 Yu Wang et al.",TextMining
"Geomechanical characteristics such as Young's modulus, Poisson's ratio, and Lamé parameters may be estimated using a combination of compressive and shear velocities. The static characteristics of formations and in-situ stresses may be estimated using these parameters. Sonic logs aren't typically available, especially for older wellbores. Additionally, on several occasions where the sonic logs have been made accessible, they are usually P-waves, and shear wave velocities are not present. Unfortunately, because of the significant expense associated with this log, it is not extensively utilized. Obtaining the shear wave velocity of rocks in a more efficient and cost-effective manner is necessary. Since well logs are vital in the reservoir characterization and development process, methods for approximating missing log information are essential. According to the literature, there is no specific straightforward correlation that could be utilized to accurately determine shear wave travel times based on well log data. The primary objective of this study is to predict shear wave velocity logs from conventional wire-line logs at the Wellington oil field in south central Kansas. This leads to the study's main idea. This research focuses on establishing a meaningful correlation between conventional logs and shear wave velocity in a cost-effective manner utilizing various approaches and data mining. The Wellington oil field, located in south central Kansas, is the subject of this research. Empirical correlations, linear regression, and neural networks were used initially to predict shear wave velocity. Ultimately, the data-driven model developed using standard well logs accurately predicts shear wave velocity in the Wellington oil field, demonstrating its reliability and effectiveness. Therefore, while direct measurement of shear wave sonic velocities is preferable, derived values can still provide useful insights when direct measurements are not possible or practical. © 2023 57th US Rock Mechanics/Geomechanics Symposium. All Rights Reserved.",TextMining
"Nowadays, driving fast is an emergency state in many countries in the world and Vietnam in particular, and the consequence is really cruel when an accident occurs. Therefore, it is very important to control the speed of vehicles. Motorcycle license plate recognition (MLPR) is one of many methods. If any motorcycle drives above the speed limit on the road that has a speed camera, a ticket will be sent to your living address. This research proposes a method that can automatically detect license plates (LP) and extract their data. The highest mAP achieved after three hundred epochs is 93% with Yolov8. There are three stages to extracting the LP’s data, the first is detecting the motorcycle, the second is detecting the LP in the motorcycle’s bounding box, and the third is LP recognition using Yolov8 also. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.",TextMining
"Purpose – To use Natural Language Processing (NLP) to explore how people feel and what they share online about their experiences with food. In addition, to learn how these experiences have evolved recently, differences before and during the crisis COVID-19 will be explored. Methodology/Design/Approach – A total of 35,001 reviews of restaurants and local cuisine establishments near tourist attractions in the city of Ayutthaya, Thailand, were extracted from the Google Local Guide platform. Several NLP techniques were used to analyse the text data, including sentiment analysis, word cloud analysis, and the N-gramme model. Findings – The results reveal travellers’ hidden sentiments toward dining experiences. Key attributes of experience sharing related to food activities in online reviews were identified both before and after COVID-19. From a theoretical perspective, the findings are relevant for researchers to recognise tourists’ behaviour in sharing local food experiences. From a practical perspective, decision makers will have a better understanding of tourist behaviour to develop and implement appropriate strategies. Originality of the research – This study is the first to analyse and interpret online reviews on Google Maps platform by applying text mining and sentiment analysis in gastronomic tourism research, especially in the context of COVID-19. © 2023, University of Rijeka. All rights reserved.",TextMining
"Seismicity can be induced by rock failures or slips along geologic structures around mine workings. Depending on their intensity and proximity to the working area, seismic events may raise safety concerns in underground mining operations. However, the geological and mining parameters leading to destructive seismic events are poorly understood. Monitoring seismic events coupled with geomechanical modeling can be useful tools for understanding underlying mechanisms and main factors causing destructive seismic events. This paper reviews seismic events recorded in a deep longwall mine (>450 m) in Virginia and evaluates the geologic conditions that lead to areas with high seismic event activities (> 1 ML) during mining of longwall panels. Two pseudo two-dimensional models of areas with high and low seismic event activities are constructed in 3DEC software. The variation in the energy content of elastic models is monitored, and potentially damaging events with compression-type and shear-type signatures are identified. The modeling results are compared with historic seismic data to evaluate the model performance in forecasting the seismic potential in each model. The results show the applicability of energy balance calculations for forecasting the approximate location and timing of destructive seismic events. © 2023 57th US Rock Mechanics/Geomechanics Symposium. All Rights Reserved.",TextMining
"Many clinical studies have shown that embryos of in vitro fertilization (IVF) are often prone to developmental arrest, which leads to recurrent failure of IVF treatment. Early embryonic arrest has always been an urgent clinical problem in assisted reproduction centers. However, the molecular mechanisms underlying early embryonic development arrest remain largely unknown. The objective of this study is to investigate potential candidate hub genes and key signaling pathways involved in early stages of embryonic development. RNA-seq analysis was performed on normal and arrest embryos to study the changes of gene expression during early embryonic development. A total of 520 genes exhibiting differential expression were identified, with 174 genes being upregulated and 346 genes being downregulated. Upregulated genes show enrichment in biosynthesis, cellular proliferation and differentiation, and epigenetic regulation. While downregulated genes exhibit enrichment in transcriptional activity, epigenetic regulation, cell cycle progression, cellular proliferation and ubiquitination. The STRING (search tool for the retravel of interacting genes/proteins) database was utilized to analyze protein-protein interactions among these genes, aiming to enhance comprehension of the potential role of these differentially expressed genes (DEGs). A total of 22 hub genes (highly connected genes) were identified among the DEGs using Cytoscape software. Of these, ERBB2 and VEGFA were upregulated, while the remaining 20 genes (CCNB1, CCNA2, DICER1, NOTCH1, UBE2B, UBE2N, PRMT5, UBE2D1, MAPK3, SOX9, UBE2C, UB2D2, EGF, ACTB, UBA52, SHH, KRAS, UBE2E1, ADAM17 and BRCA2) were downregulated. These hub genes are associated with crucial biological processes such as ubiquitination, cellular senescence, cell proliferation and differentiation, and cell cycle. Among these hub genes, CCNA2 and CCNB1 may be involved in controlling cell cycle, which are critical process in early embryonic development. Copyright © 2023 Zhang, Li, Li, Lv, Ma, Yin, Li, Sun, Chen, Lu, Li, Zhang and Yan.",TextMining
"Sentiment analysis of people’s opinions finds widespread application in numerous business and decision-making situations. Despite social media’s informal nature for sharing viewpoints, it has now become a prevalent tool in various business and decision-making contexts. Sentiment analysis, also known as opinion mining, encompasses the utilization of techniques such as text analysis, computational linguistics, natural language processing, and even biometrics to analyze and interpret sentiments, opinions, and emotions expressed within textual data. Subsequently, we conducted an in-depth analysis of this data using a diverse range of machine learning algorithms, including Naive Bayes, Support Vector Machine (SVM), and decision trees. We are proposing a new machine learning model, called a hybrid feature selection-based model, for identifying the sentiment polarity of statements. This model is different from other machine learning models because of its unique architecture. It uses 16 different linguistic features in its hidden layers. To validate and fine-tune the behavior of this algorithm, we employed the Analytic Hierarchy Process method. This technique has been utilized in a wide variety of research projects, and it has also been combined with other methodologies to solve decision-making challenges. By integrating various linguistic features, our model demonstrates enhanced performance compared to other state-of-the-art models, resulting in an improvement of up to 2.8% in Accuracy and 3% in terms of the weighted F1-score. © 2023, The Author(s), under exclusive licence to Springer Nature Switzerland AG.",TextMining
"Reserve estimation, most responsible and irreplaceable task, is carried out at all the stages of a mining project to estimate the quality and quantity of mineral deposits. Accurate reserve evaluation involves a precise assessment of quantity, quality, and sustainability. Various advanced mine planning software are globally available but due to high capital cost most of the mine operators opt for conventional methods for reserve estimation. The present study encompasses a case study of Manoharpur coal block comparing reserve estimation by the cross-sectional method and Minex software based on input data of 238 drill holes and comparison with the actual production. The estimated reserve obtained by the Cross-sectional method and Minex software was 6216695 t and 5619278.33 t respectively. However, the actual production of coal as per the proposed profile was 5251365.86 t. The surface profile of the mine has been obtained by a 3D terrestrial laser scanner. The slight variation in the surface profile, dilution, and cutting-edge outline could be the cumulative parameters affecting the actual production with 7% variation. The Minex software is observed to be more reliable in comparison to the conventional method as the former covers all small deviations in reserve profiles unlike in the latter method. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"This paper presents a visual traceability system for the Farm-to-Customer (F2C) IoT agricultural model, aimed at improving product traceability and quality. The system integrates intelligent hardware such as sensors, RFID chips, and smart labels, and employs blockchain, big data, cloud computing, and AI technologies for comprehensive product traceability services. The system uses a data-driven approach, leveraging data mining and analysis to provide consumers with intuitive and personalized traceability information. Its visual design, encompassing product identification, traceability information display, and data monitoring interfaces, is key to its success, offering a seamless user experience. This innovative system significantly enhances product quality and safety management, promoting a safe consumption environment. Its success relies on the integration of multiple technologies and continuous design refinement. Applicable across various industries, it ensures product quality and safety, boosting consumer confidence. © 2023 SPIE.",TextMining
"The obligation for research paper recommendation is high as scientific document recommendations like research paper recommendation frameworks are not many in number. The knowledge-centric semantically inclined framework for research paper recommendation HyResPR has been proposed. HyResPR is a hybridized research paper recommendation model which is implemented on the RARD II dataset. A hybridized research paper recommendation framework (HyResPR) is proposed. It uses user queries as input to obtain the query words after preprocessing, later these query words are induvial integrated with the domain ontologies. The dataset is subjected to preprocessing to create a synthesized knowledge map with the help of category term mapping and static domain ontology alignment. Features are extracted from the synthesized knowledge map and classified using logistic regression, the extracted query words are processed along with the top 75% of the instances classified. The experimentations are conducted on the RARD II dataset which is classified using the logistic regression classifier. The SemantoSim similarity measure and Cosine similarity measures are used to compute the similarity among the extracted instances from RARD II dataset. The query words obtained from input, and relevant research papers are recommended back to user depending on the value of the semantic similarity. Auxiliary knowledge is incorporated by using static domain ontology, topic modeling has been used experimentations have been computed for 1416 queries on the RARD II dataset. The proposed HyResPR framework achieved the highest average accuracy of 96.43%, recall of 97.05%, with a least FDR value of 0.05 observed. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",TextMining
"The rapid development of unmanned aerial vehicle (UAV) technology has enabled numerous open pit and underground mining companies to leverage this tool for slope stability assessment and the construction of geotechnical models. The use of aerophotogrammetry techniques with UAVs enables geotechnical and geological engineers to work in a safe and agile manner, maintaining a safe distance from hazardous areas. These techniques can identify the orientation of discontinuities in the rock mass, which is vital in evaluating slope stability. Moreover, new semi-automatic extraction techniques for discontinuities in rock masses allow aerophotogrammetric models to be utilized in geomechanical characterization in a more accessible and efficient way. With the use of 3D point cloud analysis software, the primary sets of discontinuities in a rock mass outcrop can be identified, measured, and utilized in various applications. This study presents a methodology for constructing three-dimensional models of a mine slope and utilizing them to determine the primary orientations of discontinuity sets using images captured through UAV survey. The method comprises four primary steps: (i) UAV flight and image capture, (ii) 3D point cloud construction using SfM technique, (iii) detection and measurement of discontinuities, and (iv) statistical data analysis. © 2023 57th US Rock Mechanics/Geomechanics Symposium. All Rights Reserved.",TextMining
"Multi-lane roundabouts allow drivers to change lanes by merging and diverging among circulating lanes, yielding weaving in the roundabout. Weaving yields traffic conflicts as crossing traffic slows down the circulating flow. Speed reduction creates significant gaps that reduce capacity. Thus, weaving is crucial due to its significant effect on roundabout capacity. However, little information is available on weaving in multi-lane roundabouts with inscribed circle diameters (ICD) of more than 100 m. A possible reason for the lack of weaving data is the difficulty of collecting lane change data due to the traffic flow complexity, which involves several lane changes and the required resources. Typical data collection methods include using ground-level recorders and surveyors. Ground-level recorders could only provide limited data points due to view coverage constraints. Increasing the workforce and equipment can overcome this limitation, but it may prolong the post-recording analysis due to more views for analysis. Conversely, Unmanned Aerial Vehicles (UAVs) can capture complex traffic interaction data in a single session. Extraction of UAV-based recording by traffic video analyser could provide a wide range of outputs in a shorter time than manual analysis. This paper proposes a novel methodology to extract UAV-based lane change data using a traffic video analyser. The fieldwork involves flying a UAV at a multi-lane roundabout with an ICD of 151 m in Kuching, Malaysia. Turning movement and lane change were obtained using a traffic video analyser. Virtual gates are specified at 10 m intervals to get lane change location. A lane change can be detected when a vehicle crosses two consecutive virtual gates over two adjacent circulating lanes. Weaving occurs when two lane change swap paths along circulating lanes. The findings show that 86% of lane change happens in the weaving section. This paper demonstrated that using UAV and traffic video analyser is feasible to investigate lane change in a multi-lane roundabout with ICDs more than 100 m. Since using a traffic video analyser on UAV-based data gives a promising outcome, it is worth considering this methodology in similar lane change studies in the traffic field. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",TextMining
"Non-negative Matrix Factorization (NMF) is a data dimensionality reduction method, which can process large scale and high dimensional data more efficiently. Among them, kernel-based non-negative matrix factorization maps data to high-dimensional space, which is a nonlinear NMF method and is mainly used to extract high-order features of image data. The feature information obtained by different kernel functions has different characteristics and makes different contributions to image classification. However, most of the researches only consider single-kernel NMF, and some multi-kernel NMF methods also have some problems such as uneven weight distribution, which loses the feature information of some kernel functions. Therefore, it is necessary to study the NMF method of multi-kernel fusion with adaptive weights. In this paper, a non-negative matrix factorization method based on mixed Gaussian kernels is proposed. By fusing multiple Gaussian kernels with different weights and updating weights adaptively, the feature information of different Gaussian kernels can complement each other, which has good performance on public datasets FERET, ORL and Yale Face, indicating that the algorithm can effectively improve the classification performance. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.",TextMining
"It is recognized that increased mechanization in mining has resulted in a larger number of workers exposed to longer durations of whole-body vibration (WBV) in mining work context. This physical agent is one of the leading causes for workplace disability and it is regarding of many mining operators that during daily activities use mining vehicles such as dozers, haul trucks, Load Haul Dump (LHD) vehicles and wheeled shovel. The present study was conducted in a typical mining context in order to investigate the effect of the WBV driver's exposure on different vehicles and determine whether differences that exist in WBV exposures between different model trucks. The measurements WBV exposures were calculated per ISO 2631-1 (1997) by a tri-axial accelerometer fixed on the driver's seat. The vehicles investigated are different and they carry out the same activities within the mining process. To further evaluate another important parameter, the effects of the vehicle wearing, the acceleration data were obtained on the same truck model of a precedent measurement campaign realized few years ago. The results point out that highest acceleration values were on the z-axis (vertical), the values respect the limits defined by the italian law and the data obtained in the previous campaign result comparable with the values obtained in this work. © 2023 International Multidisciplinary Scientific Geoconference. All rights reserved.",TextMining
"Feature selection (FS) is a fundamental technique in machine learning and data mining that aims to choose the most relevant and important features from a high-dimensional feature space. This process can enhance the performance and generalization ability of the classification model. However, classifying high-dimensional datasets presents challenges including high computational cost and stagnation in local optima. Evolutionary algorithms (EAs) have been widely applied in FS to mitigate these issues given their global search capabilities. In this study, we propose a multiobjective fuzzy competitive swarm optimization (MOFCSO) algorithm for FS on high-dimensional data. First, a fuzzy logic-based approach is proposed to classify the competitive particles, enabling better exploration of the search space. Then, a self-learning mechanism for failed particles is introduced to further enhance the global search. To demonstrate the proposed algorithm, we contrast it with multiple progressive algorithms. The experimental outcomes indicate the proposed algorithm is a valid method for choosing features in data with high dimensions. © 2023 IEEE.",TextMining
"This article proposes a novel approach to clustering called eCauchy, which is based on the Cauchy density function. This method is similar to the well-known possibilistic c-means clustering (PCM), which was developed to address the limitations of fuzzy c-means algorithms (FCM). Density-based clustering is particularly useful when dealing with noisy data and frequent outliers. The recursive measure of density can be adapted for various data mining tasks, including regression and classification. The eCauchy algorithm is simple to use and can handle big-data problems. It evolves dynamically by adding and removing clusters based on a few initial parameters, such as maximum and minimum density. This allows for the identification of clusters with different shapes and sizes and is robust to outliers and high levels of noise. The paper demonstrates the universality of this algorithm and its modifications through several simple examples that can also be found in more complex forms in real-world applications.  © 2023 IEEE.",TextMining
"Businesses constantly strive to build organizational capacity to use data strategically. As a result, there is a growing demand for business analytics professionals. While higher education systems worldwide have been adapting to build competencies, they must meet employees' expectations. Curriculum design for delivering business analytics competencies remains a challenge due to the rapidly evolving nature of business analytics as a discipline. The paper aims to decode the industry expectations for the Business Analytics profile. This study investigates the skills employers value by analyzing job descriptions. We use a text-mining approach to understand the weightage of different skills and mine skill clusters within business analytics roles. The core skill clusters are hard skills related to Big data, Business Intelligence, and analytical techniques. Results also suggest that traditional machine learning (ML) skills, typically expected in a data science profile, are also being sought after in a business analytics role. Surprisingly soft communication and stakeholder management skills are also emerging as essential skills for business analytics roles. This study provides a better understanding by investigating the interplay between the demand for skills in the job market and curriculum development. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Organic nonlinear optical (NLO) crystals are effective in light frequency conversion through nonlinear optical applications, such as optical rectification and second-harmonic generation, due to low dielectric constants and high molecular hyperpolarizabilities. Yet only a few organic NLO materials have been identified. Combining data mining for structures from the Cambridge Structural Database and density functional theory calculations, we discover new organic nonlinear optical crystals that generate intense terahertz (THz) radiation. To confirm our combination approach, we recrystallized and tested the newly discovered organic nonlinear materials. The results of THz experiments showed the THz generation capabilities exceed state-to-art THz generation crystals (DAST, OH-1 and BNA). © 2023 IEEE.",TextMining
"To reach autonomous control with good performance in shearer operated longwall mines, control algorithms have to be adapted to the system behaviour. Thus, one of the challenging tasks in this area is the identification of the behaviour, which is declared as complex and specific to each mining area. Therefore, it is necessary to determine a suitable model that reproduces the cut behaviour of a shearer loader and can be adapted to a real mining system. This paper shows and analyses possible model structures to predict the cutting path of a shearer loader in the direction of face advance, combined with the least squares method for parameter identification. Single-step, as well as multi-step prediction are considered. Especially results of multi-step prediction of the cutting path, compared to the reference path shows whether the model structure and the identified parameters are valid or not. Data source for the parameter identification and cutting path reference is a complex and iteratively working simulation tool developed in cooperation with a German mining company for the training of operators. Finally, a suitable, analytical model for parameter identification and prediction of the cutting horizon is pointed out. © 2023 International Multidisciplinary Scientific Geoconference. All rights reserved.",TextMining
"With the rapid increase of the data, not only the scale of data is very large, but also the dimensionality of the initial data is very high. It is increasingly difficult to perform feature extraction on high-dimensional datasets, called curse of dimensionality. Traditional manifold learning algorithms propose to explore the underlying local or global geometric structure of the high-dimensional datasets for feature extraction. However, such algorithms can only mine a set of local linear structures of the datasets, and it is extremely limited to uncover the higher-order non-Euclidean geometric structure. In this paper, we propose a new nonlinear manifold learning algorithm to exploit the curvature information of the dataset, which can quantify the spatial similarity between data points more accurately and improve the accuracy of feature extraction. We perform a group of clustering experiments on several types of image datasets, and the related experimental results show that our algorithm outperforms the existing manifold learning algorithms. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.",TextMining
"Analyzing the relationship between GEN Z employees job performance and online Short Video behavior is the focus of employment management and guidance in companies under the background of big data. This paper extracts the characteristics of employees' job burnout information and online Short Video behavior data, constructs the student label model with new employees as the research object, we use association rules to mine the relationship between employers performance and online behavior, and analyze the behavior characteristics with different performance. The results show that three typical portraits exists in A employees, three typical paths in A employees, two typical paths in C employees. These results guide employees’ online short video behavior, and provide the application of association rule mining and behavior analysis in job performance. © 2023 SPIE.",TextMining
"Data-driven methods used on structural magnetic resonance imaging (sMRI) have been successful in predicting disease subtypes within a population of subjects. Biclustering is a data-mining technique that can cluster rows and columns of a matrix to find submatrices corresponding to subtypes. One such method is N-BiC, which is an N-component biclustering algorithm. The limitation of this algorithm is that it is resource intensive, as it uses recursive Depth-First Search (DFS), which can be less efficient and time-consuming over iterative approaches. The biclusters enlisted in N-BiC are dependent on search order, and it requires a number of permutation operations to explore and merge the possible biclusters. In N-BiC, permutation refers to the order in which the components are sent to the modified DFS algorithm. The task of permutations in N-BiC is to find common subjects between components. For example, a permutation using three components (say 1, 2, and 3) relates to common subjects between components 1, 2, and 3. Similarly, yet another permutation 2, 3, and 1 relate to the same set of subjects between components 1, 2, and 3 in a different order, which is therefore redundant. Our proposed approach eliminates this repetitive process to obtain common subjects in a bicluster. Therefore, Modified N-BiC has optimized permutations and consumes reduced run time. It works on par with N-BiC and has reduced memory requirements. We also suggest that N-BiC algorithm does not find biclusters in the subject by voxel matrix as done by other biclustering studies but only in the decomposed loading matrix (subject by component). We also provide the necessary MATLAB codes for further research and application on other varied datasets. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",TextMining
"“Source-load” multiple timing uncertainties and the steady-state/dynamic diversity of reactive power equipment in a new type of distribution system (NDS) determine the need for joint optimization of reactive power allocation and operational regulation. Therefore, based on the “planning-operation” fusion framework, research on optimal allocation of reactive power resources in the “source-load” multi timing joint scenario of NDS is carried out. First, based on the development trend of new forms of NDS, a “planning-operation” joint optimization framework integrating big data analysis, multi time domain operation simulation, and comprehensive benefit evaluation is constructed. Then, based on capacitor steady-state and DSTATCOM dynamic reactive power equipment operation characteristics analysis, sequential optimization of location and capacity is determined. A “source-load” multi-scale joint timing scenario is constructed based on the K-means clustering method, and simulation analysis of NDS operation is achieved in hierarchical reactive power balance through coordination of steady-state/dynamic reactive power devices and deep mining of multi-scale adjustment resources. An NDS reactive power “planning-operation” evaluation index system is established to conduct comprehensive benefit evaluation of the entire process. Finally, taking the IEEE33-bus distribution network system as an example, a reactive power “planning-operation” joint optimization simulation analysis is conducted. The results show that the proposed model has the ability to adapt to the ""source-load"" uncertainty and multiple timing joint scenarios, and the planning scheme with embedded multi time domain operation simulation is more comprehensive and practical. © 2023 Power System Protection and Control Press. All rights reserved.",TextMining
"During the last years, many researchers used ontology-based technologies for developing ontology-learning processes for acquiring knowledge included in textual information. In our case, we focused such processes to study the contents of Portuguese manuscripts from the 17th century, aiming to explore the formalities of the language and characterize the elements contained in the texts. In particular, we worked over a very specific manuscript. In this paper, we present and describe the implementation of a semi-automatic ontology learning process for extracting the knowledge contained in the “Book of Properties”. This manuscript includes a detailed inventory of assets belonging to the Archbishop’s Table of Braga at the beginning of the 17th century. Our goal is to provide a fundamental computational instrument for studying and learning the geography, culture, agriculture, history, and genealogy in Portugal at that time. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"The leaf chlorophyll content (LCC) of vegetation is closely related to photosynthetic efficiency and biological activity. Jujube (Ziziphus jujuba Mill.) is a traditional economic forest tree species. Non-destructive monitoring of LCC of jujube is of great significance for guiding agroforestry production and promoting ecological environment protection in arid and semi-arid lands. Hyperspectral data is an important data source for LCC detection. However, hyperspectral data consists of a multitude of bands and contains extensive information. As a result, certain bands may exhibit high correlation, leading to redundant spectral information. This redundancy can distort LCC prediction results and reduce accuracy. Therefore, it is crucial to select appropriate preprocessing methods and employ effective data mining techniques when analyzing hyperspectral data. This study aims to evaluate the performance of hyperspectral data for estimating LCC of jujube trees by integrating different derivative processing techniques with different dimensionality reduction algorithms. Hyperspectral reflectance data were obtained through simulations using an invertible forest reflectance model (INFORM) and measurements from jujube tree canopies. The least absolute shrinkage and selection operator (LASSO) and elastic net (EN) were employed to identify the important bands in the original spectra (OS), first derivative spectra (FD), and second derivative spectra (SD). Support vector regression (SVR) was used to establish the estimation model. The results show that compared with full-spectrum modeling, LASSO and EN algorithms are effective methods for preventing overfitting in LCC machine learning estimation models for different spectral derivatives. The LASSO/EN-based estimation models constructed using FD and SD exhibited superior R2 compared to the OS. The important band of SD can best reveal the relevant information of jujube LCC, and SD-EN-SVR is the most ideal model in both the simulated dataset (R2 = 0.99, RMSE=0.61) and measured dataset (R2 = 0.89, RMSE=0.91). Our results provided a reference for rapid and non-destructive estimation of the LCC of agroforestry vegetation using canopy hyperspectral data. Copyright © 2023 Tuerxun, Zheng, Wang, Wang and Liu.",TextMining
"Along with the enlarging of post-mining towns, the use of abandoned mining areas for various purposes is gradually being approached. This raises the question of the safety of the closed shafts. The following article discusses the determination of attributes which can help to reveal stability problems of disused mine shafts with the increasing of mine water level in Ostrava Basin. The first part is devoted to the need to obtain the most relevant documents about each of the shafts. These documents include data from the treatment of the shaft, backfilling, historical data about excavation, collapses, geology, or data on gas emissions from shaft cap. The next part is focused on the study of historical shaft collapses both in Czech Republic and abroad, thorough study of the cases of their occurrence, their possible connection with the affection of mine water and its potential impact on the backfill material of reinforcement of the shaft. The last part explains the process of selecting key attributes for the compilation of the evaluation algorithm, their subsequent incorporation into the database and the resulting evaluation proposal for individual disused mine shafts within the Ostrava Basin. The goal is to use these findings for the future development of a universal stability evaluation system for all the disused mine shafts. © 2023 International Multidisciplinary Scientific Geoconference. All rights reserved.",TextMining
"Keeping high service levels of a fast-growing number of servers is crucial and challenging for IT operations teams. Online monitoring systems trigger many occurrences that experts find hard to keep up with. In addition, most of the triggered warnings do not correspond to real, critical problems, making it difficult for technicians to know which to focus on and address in a timely manner. Outlier and concept drift detection techniques can be applied to multiple streams of readings related to server monitoring metrics, but they also generate many False Positives. Ranking algorithms can already prioritize relevant results in information retrieval and recommender systems. However, these approaches are supervised, making them inapplicable in event detection on data streams. We propose a framework that combines event aggregations and uses a customized clustering algorithm to score and rank alarms in the context of IT operations. To the best of our knowledge, this is the first unsupervised, online, high-dimensional approach to rank IT ops events and contributes to advancing knowledge about associated key concepts and challenges of this problem. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"In the age of Artificial Intelligence (AI), the use of trained models is a common practice to solve a huge amount of different problems. However, it is highly complicated to understand the decision-making process of these models and how the used training data affect them during the production phase. For this reason, multiple techniques related to model extraction have appeared. These techniques consist of analyzing the behavior of a (sometimes partially) unknown model and generating a clone that reacts similarly. This process is relatively simple with basic models, but it becomes arduous when complex models must be analyzed and replicated. This paper tackles this issue by presenting the Neural NetwOrk Models (VENNOM) system. It is a general framework architecture to extract knowledge and provide explainability to unknown models. The proposed approach uses low-capacity, high-explainability neural networks to produce flexible and interpretable models. The proposed framework offers several advantages, particularly in terms of obtaining explanations through visual and textual content for models that are otherwise opaque. The framework has been tested on tabular data sets, demonstrating its performance and potential. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Recommender systems are an effective solution to address the issue of information overload and a thriving research field. This paper focuses on the efficient mining of user-item relationships and the aggregation of neighborhood information in bipartite graph-based recommender systems. Therefore, a Graph Contrastive Learning recommendation model with Feature Perturbation (GCL-FP) is proposed in this work. The proposed model utilizes a graph convolutional encoder with a residual structure, simplifying the feature transformation and the nonlinear activation in graph convolution. This approach helps alleviate the over-smoothing problem of node representation. Furthermore, a data augmentation method, incorporating graph convolution aggregation information into the random noise, is designed. By perturbing the graph node feature matrix in this way when generating the contrastive learning view, we ensure that the noise does not excessively alter the semantic information of node features. Finally, experiments on three benchmark datasets, namely Yelp2018, Douban-Book, and Alibaba-iFashion, were conducted. The experimental results show that our proposed model outperforms the baseline model Simple Graph Contrastive Learning (SimGCL) by improving the Recall evaluation metric by 2.2%, 5.4%, and 1.9%, respectively as well as the Normalized Discounted Cumulative Gain (NDCG) evaluation metric increases by 1.8%, 3.0%, and 1.8%, respectively. © 2023, International Association of Engineers. All rights reserved.",TextMining
"Understanding the coupled interaction of rock and water under stress is often a key factor in assessing slope stability in open pit mining. In this paper, a numerical modeling research project is presented which demonstrates the concept of hydromechanical coupling (HMC) and assesses the sensitivity of contributing parameters to pressure responses observed in a piezometer sensor due to excavation of a mine slope. Site monitoring data showing HMC effects within a mine in Nevada are analyzed and reproduced using FLAC. This research aims to promote the understanding of HMC in pit slopes and provide improved guidance on how to plan mining activity, monitoring and slope design to incorporate the benefit of HMC effects. © 2023 57th US Rock Mechanics/Geomechanics Symposium. All Rights Reserved.",TextMining
"During the European GoldenEye Project Type H2020 Number 869398, three drilling and blasting methods were analyzed in terms of the impact of the works on the environment, the choice of the most optimal scheme from the point of view of rock strength, the reduction of costs and the reduction of the impact of the environment. Here, the environmental footprint of the operation was significantly reduced. Analogous and graphic calculation methods were used using the programs Rhinoceros 3D combined with RhinoTerrain and O- Pitblast, but also topographical elevations with the drone necessary for the realization of the 3D geometrization of the open pit itself. The geomechanical parameters of the rock, geological and structural maps were used for the most accurate planning of the drilling and blasting site. A significant reduction in design times (77%) could be implemented in the design of the works. Optimizing rock mass removal was an important objective in the exploitation of mineral resources due to costs, risks regarding personnel protection. The method of extraction by using the drilling and blasting has been continuously improved by combining practical experience with the theory of explosions and the formation of explosive substances, statistical processing of the data obtained from the blasting, development of analytical, numerical, and graphic models. In the last period, the design activity of the grilling/blasting monograph has been perfected through numerical and graphic methods, facilitating the work of engineers in this field. This design is based on the data provided by the engineers detailing the geological structure of the rock mass to be extracted and the use of the mining product (crushing or grinding needs, use as rough stone, rock deposits, crushed stone, blasting rocks for slope stabilization). This paper analyzes the monograph for geomining and crushing/grinding conditions from Rosia Poieni. © 2023 International Multidisciplinary Scientific Geoconference. All rights reserved.",TextMining
"This paper focuses on evaluating the effects of confinement, charge factor and segmentation of holes in a blast round on blast-induced ground vibrations in a mine. The study involved conducting a series of experiments with different drillhole diameters and modifying design parameters. The results indicated that the initial blast designs were not optimised, resulting in to generation of higher magnitudes of ground vibrations. Based on the vibration data recorded, regression analysis was carried out to establish a best-fit relationship between the scaled distance and vibration. On the basis of the threshold values of peak particle velocity prescribed by the DGMS, the permissible maximum charge per delay at specific distances were determined. The permissible charge values were not workable and matching with the mine productivity. The subsequent experimental blast with a smaller drill hole diameter also did not significantly reduce the magnitudes of ground vibrations. However, the experiments conducted with reduced confinement conditions with less number of holes and optimized charge factors resulted in a notable reduction in the ground vibration magnitudes. An innovative technique of segmentation of total holes in a blasting round using electronic detonators demonstrated a significant decrease in vibration magnitudes with the potential of increased productivity. The findings of the study emphasize the importance of re-assessing the blast design parameters and charging patterns to mitigate ground vibrations and optimize the blast outcomes in mining operations. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Introduction: Scientific articles serve as vital sources of biomedical information, but with the yearly growth in publication volume, processing such vast amounts of information has become increasingly challenging. This difficulty is particularly pronounced when it requires the expertise of highly qualified professionals. Our research focused on the domain-specific articles classification to determine whether they contain information about drug-induced liver injury (DILI). DILI is a clinically significant condition and one of the reasons for drug registration failures. The rapid and accurate identification of drugs that may cause such conditions can prevent side effects in millions of patients. Methods: Developing a text classification method can help regulators, such as the FDA, much faster at a massive scale identify facts of potential DILI of concrete drugs. In our study, we compared several text classification methodologies, including transformers, LSTMs, information theory, and statistics-based methods. We devised a simple and interpretable text classification method that is as fast as Naïve Bayes while delivering superior performance for topic-oriented text categorisation. Moreover, we revisited techniques and methodologies to handle the imbalance of the data. Results: Transformers achieve the best results in cases if the distribution of classes and semantics of test data matches the training set. But in cases of imbalanced data, simple statistical-information theory-based models can surpass complex transformers, bringing more interpretable results that are so important for the biomedical domain. As our results show, neural networks can achieve better results if they are pre-trained on domain-specific data, and the loss function was designed to reflect the class distribution. Discussion: Overall, transformers are powerful architecture, however, in certain cases, such as topic classification, its usage can be redundant and simple statistical approaches can achieve compatible results while being much faster and explainable. However, we see potential in combining results from both worlds. Development of new neural network architectures, loss functions and training procedures that bring stability to unbalanced data is a promising topic of development. Copyright © 2023 Stepanov, Ivasiuk, Yavorskyi and Frolova.",TextMining
"In the world of technology, data have been available easily and in huge amounts. Because of the large amounts of data, Educational Data Mining (EDM) is increasingly gaining more importance. Educational data mining is trending as it is the analysis method for analyzing educational data. It involves checking the relationship between the characteristics of students and which features affect their final grades the most. It can also involve predictive modeling by predicting the final grades of students in the future to help educational institutes rescue failing students before they actually fail. Predictive analysis was the main focus in past years where most researchers targeted predicting grades of students. However, not all educational institutes are able to collect the amount of data suitable for machine learning models to achieve good accuracy. That is why the main target of the work presented in this paper is to develop an interactive interface that gives the ability to educational institutes to check by themselves the relation between different factors using correlation mining. The output of the tool is visual with message boxes to make it understandable by users. That is the best way to discover hidden patterns and trends without the need for a large amount of data in addition to removing the cost of deploying machine learning models. The second goal of the work is to give teachers the ability to check the quality of the content of their slides to help them provide a better learning process.  © 2023 IEEE.",TextMining
"With the rise of artificial intelligence technology in recent years, combining artificial intelligence technology with industry has become a popular research direction, and safety issues in industry have gradually become important. Gas data can directly show the health condition of gas, and the research of anomaly detection on gas data is one of the important means to improve gas safety. To address the gas data problem, this paper proposes a gas data anomaly detection method based on a time-series ARIMA model. Firstly, the data in the SCADA system is pre-processed, then the features of the gas data are extracted, then a time-series model is established using ARIMA, and finally the anomaly is determined by the difference between the model prediction data and the real data. And the method proposed in this paper is verified in real data, and the results show that the average values of the indexes of true positive rate, false positive rate and accuracy rate of the method in this paper are 0.18%, 0% and 96.6% respectively, which verifies the effectiveness of the method in this paper. © 2023 SPIE · 0277-786X ·",TextMining
"Over the past decade, multivariate time series forecasting is becoming a research hotspot. Despite the emergence of several deep learning-based models achieve superior performance, the lack of credible explanations limits their usability in many fields. To bridge this gap, we propose an interpretable forecasting model called XCTF (eXplainable CNN for multivariate Time series Forecasting), which combines a Dual-Attention Module and a Saliency Detection Module. The Dual-Attention Module is leveraged to extract variable features related to prediction and extract temporal features from the input data. The Saliency Detection Module has two main parts: ConvDown and ConvUp block. The ConvDown block can filter out the small, redundant features but keep the important information. The ConvUp block can enlarge the extracted feature map to obtain more accurate prediction data. Then, by using a method based on Grad-CAM, XCTF can generate an attribution map of feature importance. The attribution map can precisely demonstrate the important information of the input data. Experimental results on three benchmark datasets (ETTh1, ETTm1, and Exchange) demonstrate that XCTF has high performance when compares with current mainstream models. Moreover, XCTF offers strong interpretability and practical relevance by providing an attribution map. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.",TextMining
"While the COVID-19 pandemic morphs into less malignant forms, the virus has spawned a series of poorly understood, post-infection symptoms with staggering ramifications, i. e., long COVID (LC). This bibliometric study profiles the rapidly growing LC research domain [5,243 articles from PubMed and Web of Science (WoS)] to make its knowledge content more accessible. The article addresses What? Where? Who? and When? questions. A 13-topic Concept Grid presents bottom-up topic clusters. We break out those topics with other data fields, including disciplinary concentrations, topical details, and information on research “players” (countries, institutions, and authors) engaging in those topics. We provide access to results via a Dashboard website. We find a strongly growing, multidisciplinary LC research domain. That domain appears tightly connected based on shared research knowledge. However, we also observe notable concentrations of research activity in different disciplines. Data trends over 3 years of LC research suggest heightened attention to psychological and neurodegenerative symptoms, fatigue, and pulmonary involvement. Copyright © 2023 Porter, Markley and Newman.",TextMining
"With advances in computer network technology, the Internet has become an integral part of our daily lives. It goes without saying that providing security to network data is crucial. To this effect, the intrusion detection system (IDS) is vital for defending networks against cyberattacks. However, the high dimensionality of data is a significant issue that impacts categorisation accuracy. Therefore, we proposed a novel integrated feature extraction method called PC-UDAE that uses principal component analysis (PCA) and Unsupervised Deep Autoencoder (UDAE) to extract linear and nonlinear relationships. Also, to address the class imbalance, synthetic minority class samples are generated using the combination of Synthetic Minority Over Sampling Technique and Edited Nearest Neighbour (SMOTE-ENN). Finally, the extracted features are trained by using supervised machine learning models like Random Forest (RF), Extreme Gradient Boosting Machine (XGBM), Decision Tree (DT), Light Gradient Boosting Machine (LGBM), Extra Tree (ET), Support Vector Machine (SVM), AdaBoost (AB), and K-Nearest Neighbour (KNN) with the original imbalanced and balanced data. We analysed our suggested model using UNSW-NB 15, NSL-KDD, Ton-IoT data sets and obtained 98.85%, 99.59%, and 99.97% accuracy, respectively. Our experimental findings show that our proposed method outperformed all other competing methods. © 2023 World Scientific Publishing Company.",TextMining
"The article presents the results of studying activities on rehabilitation ecology during surface mining of coal deposits. Remote monitoring revealed the main trends in rehabilitation ecology with respect to the water and land resources. High environmental efficiency of the conducted environmental protection measures was noted. © 2023 Ugol' Journal Edition, LLC. All rights reserved.",TextMining
"Instance selection (IS) serves as a vital preprocessing step, particularly in addressing the complexities associated with high-dimensional problems. Its primary goal is the reduction of data instances, a process that involves eliminating irrelevant and superfluous data while maintaining a high level of classification accuracy. IS, as a strategic filtering mechanism, addresses these challenges by retaining essential instances and discarding hindering elements. This refinement process optimizes classification algorithms, enabling them to excel in handling extensive datasets. In this research, IS offers a promising avenue to strengthen the effectiveness of classification in various real-world applications. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"The advent of digital image and volume correlation has attracted wide use in fracture mechanics. The full-field nature of digital image and volume correlation allows for the integration of computational fracture mechanics to analyse cracked samples quantitatively. This review provides a comprehensive overview of current methods used to extract fracture properties from full-field displacement data. The term full-field fracture mechanics is introduced to highlight the uniqueness of using inherently noisy experiential data to extract fracture properties. The review focuses on post-processing-based approaches rather than integrated approaches, as these have less limitations and are more commonly employed. There are four approaches that are discussed in extracting fracture properties from experimentally computed displacement data: field-fitting, integral, crack-opening and cohesive zone modelling approaches. This is further developed to discuss problems associated with using digital image and volume correlation to extract properties, including application examples. © 2023 The Author. Strain published by John Wiley & Sons Ltd.",TextMining
"In order to overcome the problems of low recall rate, precision rate and long mining time of traditional methods, a consumer behaviour data mining of social e-commerce platform based on improved spectral clustering algorithm is proposed. Firstly, the collaborative filtering algorithm is used to predict the degree of user preference, and data crawler is designed according to the LDA theme model to crawl the consumer behaviour data of social e-commerce platform, the data is cleaned and processed. Then, the initial clustering centre optimisation algorithm is used to improve the spectral clustering algorithm, and the improved spectral clustering algorithm is used to cluster the data cleaning results to realise consumer behaviour data mining. Finally, the simulation experiment proves that the recall rate and precision rate of the proposed method are both high, and the data mining time is always less than 0.55 s.  © 2023 Inderscience Enterprises Ltd.",TextMining
"The forecasting of demand or cancellations is highly important for efficient revenue management in the hotel industry. Previous studies have mainly focused on the accuracy of the prediction of reservation number or cancellation rate on a specific accommodation or hotel chain; therefore, the application of the prediction to different accommodations or under the behavioral change of customers in response to natural or human events is difficult without the re-estimation of the prediction model. Information of the customer behavioral trend on the accommodation reservations is necessary for the construction of a general forecasting model. In this study, we focus on one of the general trends of customer behavior, that is, the reservation timing and the time changes of the cancellation probability using the big data of the reservation records provided by an online trip agency in Japan. We showed that the reservation timing and cancellation probability can be decomposed by five and six exponential functions of the days until the stay and the days from the reservations. We also showed that the significant factors influencing the time changing patterns are the guest numbers per room for both reservation and cancellation, composition of guests in terms of the number and gender of guests, and the stay length for reservation. These findings imply that the customer behavior during accommodation reservation could be categorized into multiple motivational factors toward reservations or cancellations. Our results contribute to the construction of a general forecasting model on the accommodation reservations. © 2023, The Author(s).",TextMining
"Many exploited mineral deposits are at the final stage of development. The depletion of mineral reserves leads to a reduction in the volume of production and output, as well as to the social tension of single-industry towns, whose activities are directly dependent on the mining and processing industries of the economy. In our research, the initial data are the materials of geological observations and testing of tailings storages of the copper ore beneficiation factories of Kazakhstan. Studies on the composition and properties of tailings of the ore beneficiation factories indicate the prospects of processing them as a special type of technogenic ore raw materials. Special field geological and mineralogical work has been carried out at tailings storages and laboratory mineralogical and experimental technological studies of tailings. Huge reserves of technogenic ores have been accumulated in the preserved tailings storages, which have real prospects for expanding the mineral resource base and can be processed to obtain additional amounts of copper and other valuable related components. The research results can serve as a basis for further research on the choice of reagents and a rational scheme for processing technogenic ore raw materials for extracting metals from it. © 2023 International Multidisciplinary Scientific Geoconference. All rights reserved.",TextMining
"This article has been retracted by Hindawi following aninvestigation undertaken by the publisher [1]. This investigationhas uncovered evidence of one or more of thefollowing indicators of systematic manipulation of thepublication process:(1) Discrepancies in scope(2) Discrepancies in the description of the researchreported(3) Discrepancies between the availability of data andthe research described(4) Inappropriate citations(5) Incoherent, meaningless and/or irrelevant contentincluded in the article(6) Peer-review manipulationThe presence of these indicators undermines our confidence in the integrity of the article's content and we cannot,therefore, vouch for its reliability. Please note that this noticeis intended solely to alert readers that the content of thisarticle is unreliable. We have not investigated whether authorswere aware of or involved in the systematic manipulationof the publication process.Wiley and Hindawi regrets that the usual quality checksdid not identify these issues before publication and havesince put additional measures in place to safeguard researchintegrity.We wish to credit our own Research Integrity and ResearchPublishing teams and anonymous and named externalresearchers and research integrity experts forcontributing to this investigation.The corresponding author, as the representative of allauthors, has been given the opportunity to register theiragreement or disagreement to this retraction. We have kepta record of any response received. © 2023 Hindawi Limited. All rights reserved.",TextMining
"Block production in Bitcoin, often referred to as mining, is becoming increasingly industrialized. Many nodes in the network are represented by registered business entities. The concept of Bitcoin as a Service is also pushing the industry to become more customer oriented. Services such as transaction validation, transaction status query or notification, and blockchain data indexing are in high demand among blockchain application providers and users. As service providers, nodes need to distinguish themselves from others and be identifiable. In this article, we introduce an efficient self-established identity system, called Miner ID, to enable nodes to be publicly identifiable. It is based on economic investment and active participation in the blockchain network. Moreover, Miner ID is optional for nodes, and it does not affect the consensus mechanism of the network. We explore use cases including instant transaction confirmation, blockchain attestation, public key infrastructure, and token recovery. Miner ID can also be used for secure communication with applications, services, users and peers. Copyright © 2023 Zhang.",TextMining
"In the past decade, several species of platygastroid wasps were found to be adventive in North America and Europe while under evaluation in quarantine as biological control agents of invasive pests. The scope and relative risk of this phenomenon is not fully known, but it is clearly a trend with implications for classical biological control. As a means of assessing the issue and to provide a global baseline, we implemented a data-mining approach with DNA sequences in the Barcode of Life Database, yielding 201 platygastroid BINs with intercontinental and island distributions. At least fifty-five BINs displayed exact COI barcode matches across continents, with many more BINs scored as inconclusive due to sequence length variation. These intercontinental and island BINs include biocontrol agents known to be adventive, as well as many species identified only to genus with uncertain geographic origins. We provide 2,500 identifications for platygastroid BOLD BINs, 88% to genus, to encourage additional research on this distributional phenomenon. The intercontinental BOLD BINs were compared to literature records and GBIF occurrences of cosmopolitan species to identify gaps and discordance across data sources. Smaller COI barcode datasets from localities in Florida and Germany, including topotypical specimens, revealed more intercontinental matches. We analyzed COI sequences in BOLD for the entirety of Insecta and Araneae to assess his phenomenon more broadly and because these taxa contain many hosts for platygastroid wasps. This method revealed that the intercontinental distribution phenomenon is widespread with implications for assessing biological diversity, taxonomic methodology and regulatory frameworks. © Matthew R. Moore et al. This is an open access article distributed under the terms of the CC0 Public Domain Dedication.",TextMining
"The sentiment analysis approach or opinion mining for product ranking deals with computing people’s opinions using structured and unstructured data from blogs, review sites/articles and social media. The fast pace of changing user preferences in different age groups and geographical regions has made product ranking a valuable research area. The product ranking based on user’s opinion for multi-criteria decision-making has gained prominence with the rise in e-commerce and online selling of goods and services. The reviews on online products display significant impacts on decisions made by consumers purchase. Ranking of the products through online reviews influences consumers’ purchase decisions and a source for sellers for evaluating market response to their product. The increasing number of competitive business models has made the right product selection by the end user based on other users opinion and feedback on different forums a challenging task. Aggregation of product features by the e-commerce portals based on data collected from various sources is not enough for the buyer to make decision on appropriate product choice. The present research introduces a novel approach for ranking the alternatives based on machine learning techniques, fuzzy analytical hierarchy process, the Technique for Order Preference by Similarity to Ideal Solution (TOPSIS), and wavelet transformations. Experiments are conducted over the real data sets, and efficacy of the proposed method is assessed and compared the results with the rank given by the domain experts. © Palestine Polytechnic University-PPU 2023.",TextMining
"Introduction: Hypertension is the leading cause of heart disease in the world, and discontinuation or nonadherence of antihypertensive medication constitutes a significant global health concern. Patients with hypertension have high rates of medication nonadherence. Studies of reasons for nonadherence using traditional surveys are limited, can be expensive, and suffer from response, white-coat, and recall biases. Mining relevant posts by patients on social media is inexpensive and less impacted by the pressures and biases of formal surveys, which may provide direct insights into factors that lead to non-compliance with antihypertensive medication. Methods: This study examined medication ratings posted to WebMD, an online health forum that allows patients to post medication reviews. We used a previously developed natural language processing classifier to extract indications and reasons for changes in angiotensin receptor II blocker (ARB) and angiotensin-converting enzyme inhibitor (ACEI) treatments. After extraction, ratings were manually annotated and compared with data from the US Food and Drug administration (FDA) Adverse Events Reporting System (FAERS) public database. Results: From a collection of 343,459 WebMD reviews, we automatically extracted 1867 posts mentioning changes in ACEIs or ARBs, and manually reviewed the 300 most recent posts regarding ACEI treatments and the 300 most recent posts regarding ARB treatments. After excluding posts that only mentioned a dose change or were a false-positive mention, 142 posts in the ARBs dataset and 187 posts in the ACEIs dataset remained. The majority of posts (97% ARBs, 91% ACEIs) indicated experiencing an adverse event as the reason for medication change. The most common adverse events reported mapped to the Medical Dictionary for Regulatory Activities were “musculoskeletal and connective tissue disorders” like muscle and joint pain for ARBs, and “respiratory, thoracic, and mediastinal disorders” like cough and shortness of breath for ACEIs. These categories also had the largest differences in percentage points, appearing more frequently on WebMD data than FDA data (p < 0.001). Conclusion: Musculoskeletal and respiratory symptoms were the most commonly reported adverse effects in social media postings associated with drug discontinuation. Managing such symptoms is a potential target of interventions seeking to improve medication persistence. © 2023, The Author(s), under exclusive licence to Springer Nature Switzerland AG.",TextMining
"The concept of smart city management is based on the implementation and use of advanced technologies, such as wireless sensors, intelligent vehicles, mobile networks, and data storage technologies. It involves integrating various information and communication technology solutions to efficiently manage a city's resources. Cities are investing in data-driven smart technologies to enhance performance and efficiency, thereby generating a large amount of data. Finding innovative ways to use this data helps improve city management and urban development. A data-driven city utilizes datafication to optimize its operations, functions, services, strategies, and policies. Datafication involves transforming various aspects of urban life into computerized data and extracting value from this information. This transformation is dependent on controlling the storage, management, processing, and analysis of the data, as well as utilizing the extracted knowledge to develop useful smart city solutions. Access to real-time data and information enables the provision of effective services that improve productivity, leading to environmental, social, and economic benefits. Both current and future smart cities have the potential to generate vast amounts of real-time data due to complex physical infrastructure and data-driven applications supported by social networks. This paper investigates how the emerging data-driven smart city is practiced and justified in terms of its innovative applied solutions. The aim of the paper is to explore the general conditions for implementing advanced data-driven technologies for smart city management, using knowledge from literature analysis and case studies. To understand this new urban phenomenon, a descriptive case study is used as a qualitative research methodology to examine and compare the possibilities of implementing data-driven approaches in knowledge-based smart city management. Seventeen case studies that use data-driven applications in real-world settings were identified from secondary sources and evaluated based on smart city indicators and related data-driven applications. Smart Cities were selected based on their rankings in the Digital Cities Index 2022, the Smart City Index 2022, and the IESE Cities in Motion Index 2022. © 2023 Academic Conferences Limited. All rights reserved.",TextMining
"We constructed a student classroom teaching video dataset, constructed a student classroom expression dataset through video frame extraction, face detection, face alignment, and facial extraction, and constructed a student classroom behavior dataset through object detection algorithm. Aiming at the characteristics that the annotation information of the students' classroom expression dataset constructed in this paper is limited and the data of some categories are less, an expression recognition method based on semi-supervised learning generative adversarial network (SSLGAN) is proposed. The problem of limited annotation information is solved through semi-supervised learning, and the problem of less data of some categories is solved through data enhancement of generative adversarial network. An intelligent classroom state mining method that integrates student expressions and behaviors has been proposed, achieving intelligent classroom state mining of teaching videos and automatic evaluation of classroom listening status for individual and overall students in different types of classrooms, such as interactive classes, discussion classes, and self-study classes. Compared with CNN, RMN, Temporal Ensembling and Mean Teacher, the proposed SSLGAN has achieved the highest accuracy in the benchmark dataset FER2013, JAFFE, RaFD and self-built student classroom expression dataset. In the case where there are few labels in the self-built student classroom expression dataset, the accuracy of student expression recognition results still reaches 76%, and the proposed intelligent classroom state mining method that integrates student expressions and behaviors for different types of classrooms also has high accuracy on the self-built student classroom teaching video dataset. © 2023 IEEE.",TextMining
"Introduction: Artisanal and small-scale mining (ASM) is the extraction of ore with minimal to no mechanization by individuals or group of people who do not have advanced technical knowledge. Though ASM has gained considerable acceptance, one reason for its unsustainable is because of slope collapses that occur affecting the health and safety of miners and surrounding community. In rock mechanics, slope stability analysis and design has received significant attention in large scale mining to mitigate the risk of slope collapse but minimal implementation in artisanal and small-scale mining. This paper reports back the implementation of slope analysis and design through field observations to demonstrate the process of estimating rock mass rating (RMR) and finding suitable slope angles using Bieniawski (1976) RMR and Heins and Terbrugge stability charts respectively. Further analysis through laboratory strength tests and using numerical modelling software to assess the slope stability of the current and proposed slope design was conducted. Results: The slope design used in the ASM operation is unsuitable and the slope analysis using estimation charts required further analysis. Rock strength results were then used in OPTUM G2 to attempt to imitate reality. Suggested mining methods were proposed and mapped in OPTUM G2 where the limit equilibrium analysis showed that the gravity multiplier had increased by 10.04 for the upper limit and 2.79 for the lower limit and the strength reduction factor increased by 1.5. Significance: It is essential to continuously refine critical issues and help establish desirable conditions for ASM operations because it has a high potential to contribute towards sustainable development. Implementing cost-effective slope stability analysis systems for sustainable mining and promote achieving Sustainable Development Goal 1, 3, 8 and 9. Conclusion:_The estimation process can be used with the guidance of a rock engineering practitioner during the design process of the mine after exposing the rock mass during the exploration stage. However, there may be other factors that can hinder the collection of data and modelling during the design phase as slope stability analysis systems were designed for large-scale mines. © 2023 57th US Rock Mechanics/Geomechanics Symposium. All Rights Reserved.",TextMining
"Knowledge Discovery in Database (KDD) is a process undertaken by many data scientists who aim to extract knowledge from previously collected, secondary data. KDD is difficult when the scientist must analyze big data without prior due to the amount of knowledge required to understand and select relevant features for propositionalization, which is the conversion of raw relational data (stored in several tables) to propositional data (stored as one table) which is more compatible with established feature selection and data mining techniques. In this paper, we describe the Database Attribute Health Feature Reduction process (DAHFR) which is used as a filter-method feature selection metric for Feature Selection before Propositionalization (FSbP) to reduce the scope of features for observation, analysis, harmonization, and propositionalization before data mining. We employ FSbP using DAHFR during the KDD of multi-sourced oil drilling data which is contained in about 20,000 features in about 700 tables in 1 database per source. Each database follows an identical schema but has varying feature-wide missingness and semantic patterns which makes effective propositionalization difficult. DAHFR is a semi-automated process which allows the user to measure relational missingness of each feature for feature reduction and compare missingness patterns across databases. DAHFR is an improvement to existing feature selection processes because it requires minimum initial knowledge of the database’s business rules and could be used with relational data without the need for direct data observation nor prior propositionalization. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",TextMining
"This study quantifies the elemental composition of soil, vegetation, and the level of trace elements in coals to identify the impacts associated with coal mining practices in the Longyearbyen and Barentsburg settlements, the Svalbard archipelago. The analysis is based on a data set that includes 26 chemical elements measured in 74 soil, 29 vegetation, and 4 coal samples provided by a catena-based survey strategy. The concentrations of lead (Pb), nickel (Ni), copper (Cu), zinc (Zn), chromium (Cr), and vanadium (V) in the soils did not exceed the European regulatory standards (the Finnish Standard and the Norwegian Soil Quality Standard), while arsenic (As) and cadmium (Cd) overstepped their threshold values in some soils. The Geoaccumulation Index (Igeo) values showed that soils were enriched in titanium (Ti), strontium (Sr), boron (B), and zirconium (Zr). The elemental screening of the exposed coals, soils, and vegetation revealed high concentrations of these four elements as well. The examination of geospatial patterns shows that the concentrations of Ti, Sr, Zr, and B in the soils are distributed evenly along the most of the sampling transects (catenas). While the distribution of elements in the soils between the transects (catenas) varies considerably, the highest concentrations for Ti, Sr, B, and Zr are observed near the currently operating coal mining and transportation facilities. © 2023 International Multidisciplinary Scientific Geoconference. All rights reserved.",TextMining
"Currently, the online data contains rich user emotional information and public opinion information. These data can provide massive support for network public opinion monitoring and analysis. However, there are two problems in the network public opinion analysis of the online data. On the one hand, a vast amount of online data with discursiveness and concealment are processed in the cloud platforms, which consumes a long time. On the other hand, the massive online public opinion data is disperse and hidden, resulting in the dependence on manual screening for the analysis of public opinion. Therefore, it is still an important challenge to study the efficient and low-latency extraction of valuable information from network public opinion. In this paper, we proposed a fog computing based framework using the technologies of intelligent semantic recognition and data mining for the analysis of network public opinion. Firstly, we build a fog computing architecture to collect the text data of network public opinion. Then, an efficient network public opinion model is constructed by intelligence semantic recognition. Finally, we achieve the function of public opinion analysis and early warning. The experimental results show that the method proposed in this paper achieves better performance against some existing methods. © 2023 John Wiley & Sons Ltd.",TextMining
"The objective of this study is to develop machine learning techniques to forecast seismic wave velocities in real-time amidst the constantly changing conditions of underground mining. As human-induced seismicity in underground mining can negatively impact productivity, safety, and operating costs, it is crucial to have an accurate predictor for the source of microseismic events. To simulate the dynamic conditions of underground mining, laboratory experiments using AE systems and concrete blocks mimicking homogeneous rocks were conducted. The concrete blocks were of various sizes with different hole diameters and lengths representing variations in extraction ratio with mine maturity. Stress-induced fractures were produced using a static cracking agent. The blocks were tested with the voids empty and filled with various cement to sand ratios representing backfill in mining. The data collected from AE measurements, such as seismic wave velocity, arrival time, AE hits, and energy, were utilized to train different machine learning models, including linear regression, neural networks, Random Forest Decision Tree, and Gradient Boosted Decision Tree. The Gradient Boosted Decision Tree model demonstrated the highest accuracy with a mean absolute error of 7.15 m/s. The capability to predict seismic wave velocity in real-time would lead to better identification of the location of seismic events, ultimately improving the safety and efficiency of underground mining operations. © 2023 57th US Rock Mechanics/Geomechanics Symposium. All Rights Reserved.",TextMining
"The purpose of this study is to employ a novel mixed method to better understand the differences in the customer service experience of the digital banking services in South Korea and the Philippines. Data mining techniques and customer journey mapping analysis were utilized to understand the proposed issues. The results indicate that there are four critical significant points of digital banking services between South Korea and the Philippines including the number of touchpoints, speed of results, registration requirements, and touchpoint deviations. Potential causes and implications are discussed in this article. The contribution of this study is using mixed approach to understand the issues which related to bank marketing in the digital era. Additionally, this study also enriches the investigations of customer service experience in banking across different countries. Overall, the findings of this study benefit the development of digital banking services, especially in the Asia Pacific countries. © 2023 IGI Global. All rights reserved.",TextMining
"Subject counseling may assist students in evaluating their courses and choosing the appropriate career path. This article intends to investigate, create, and apply efficient methods for assessing student course counseling, guidelines, and decision-making. We develop a way to automate the course selection recommendation using machine learning. One can realize what course will suit them based on historical data. We primarily focused on the detailed description and analysis of the dataset collected from the students that have already faced any online admission counseling session. A real dataset based on the diverse perspectives of pupils was designed. Over 100 students participated in the survey; their data were recorded, analyzed, and presented efficiently for the readers to understand. Due to limited data volume, the Synthetic Minority Oversampling Technique (SMOTE) has been used. Our work holds novelty to the existing system and usage. It can be further applied from the department to the university level. © 2023, The Author(s), under exclusive licence to Bharati Vidyapeeth's Institute of Computer Applications and Management.",TextMining
"Measuring innovation accurately and efficiently is crucial for policymakers to encourage innovation activity. However, the established indicator landscape lacks timeliness and accuracy. In this study, we focus on the country of Mauritius that is transforming its economy towards the information and communication technology (ICT) sector. We seek to extend the knowledge base on innovation activity and the status quo of innovation in Mauritius by applying an unsupervised machine learning approach. Building on previous work on new experimental innovation indicators, we combine recent advances in web mining and topic modeling and address the following research questions: What are potential areas of innovation activity in the ICT sector of Mauritius? Furthermore, do web mining and topic modeling provide sufficient indicators to understand innovation activities in emerging countries? To answer these questions, we apply the natural language processing (NLP) technique of Latent Dirichlet Allocation (LDA) to ICT companies’ website text data. We then generate topic models from the scraped text data. As a result, we derive seven categories that describe the innovation activities of ICT firms in Mauritius. Albeit the model approach fulfills the requirements for innovation indicators as suggested in the Oslo Manual, it needs to be combined with additional metrics for innovation, for example, with traditional indicators such as patents, to unfold its potential. Furthermore, our approach carries methodological implications and is intended to be reproduced in similar contexts of scarce or unavailable data or where traditional metrics have demonstrated insufficient explanatory power. © 2023, The Author(s).",TextMining
"Facing the extraction of hidden danger information of external breakage to transmission lines, we first introduce lidar and optical remote sensing image data acquisition, processing, and information extraction technologies, then analyze the characteristics of transmission corridors obtained by these two sensing methods, and summarize their respective advantages and disadvantages. On this basis, we propose a method for external breakage hidden danger information of transmission lines by combining remote sensing images and LiDAR point clouds. This method can simultaneously acquire the texture and spatial three-dimensional data of the external breakage target in the transmission corridor, and form high-quality spatial three-dimensional model data, which is conducive to the effective identification and accurate extraction of external breakage hidden danger. © 2023 SPIE.",TextMining
"From a coordination chemistry perspective, we aimed to advance the knowledge of Sr/Cs separation in the scheme of spent nuclear fuel reprocessing. Based on data mining of crystal structures and deep learning architecture, we summarized and analyzed coordination chemistry properties of Sr/Cs from complex structures (ca. 3. 3X104 samples) of 8 alkaline and alkaline earth elements, especially focusing on coordination bond lengths as a representative figure of merit. Applying a Bayesian optimization approach, we were able to establish a high-performing transformer model which could predict the(differential) coordinative affinities toward Sr/Cs of ligand molecules, with exceptional accuracy. As a proof-of-concept, we systematically analyzed ca. 9. 1 X 103 ligand molecules in terms of potential coordinative selectivity toward Sr/Cs and ranked them. In addition, we also determined different contribution of various functional groups for future molecular design of ligands with selectivity. The present study presented fundamental knowledge for coordination chemistry information in the context of radiochemistry and spent nuclear fuel reprocessing, provided guidance and reference for subsequent experiments regarding Sr/Cs separation. © 2023 Science Press. All rights reserved.",TextMining
"Study objectives: While zolpidem is considered as an example of a gender effect on drug response, there is insufficient evidence to reach a consensus. This study aimed to investigate gender differences in adverse events (AEs) of zolpidem. Methods: We estimated the difference between the reporting odds ratios (RORs) calculated in gender subgroups for the AEs signals detected in data mining using 2015–2019 Korea voluntary adverse drug events reporting system (KAERS) data. Different reporting risk by gender was evaluated by using the log RORs being significantly different by gender at the 5% significance level and the 95% confidence intervals of the gender ROR. Results: A total of 94 AE signals were detected. Among these, 35 signals showed significant disparities by gender at the 5% level or were detected only in one gender. When categorized by similarity of AEs, parasomnia including somnambulism and paroniria, and cardiovascular disorders including coronary thrombosis had higher reporting risks in women. Men were more likely to report cognitive disorders such as delirium, insomnia related disorders, and movement disorders. Among all AEs with gender differences in reporting risk, the difference in somnambulism was the most consistent and substantial. Conclusion: For several AEs associated with zolpidem, gender-based reporting disparities were evident. Notably, women exhibited a higher susbeptibility to somnambulism, potentially serious adverse effects of zolpidem. This underscores the need for further investigation into the underlying factors influencing these gender-specific reporting patterns. Copyright © 2023 Joung.",TextMining
"The development of many blockchain-based applications has been done by integrating loT devices for information collection and sharing. However, faced with the challenges of the heterogeneity of loT devices and their resource constraints, the security of their use in the majority of blockchain solutions relies heavily on the authentication of these devices. In this paper, we propose a fully decentralized security protocol for blockchain-based loT solutions that focuses on the integrity of the data provided by the collector nodes before it is written to the blockchain. The protocol introduces the detection of possible anomalies in the nodes using machine learning algorithms fed by the nodes' operation traces in the mining process itself. Anomaly detection thus becomes an integral and mandatory part of the mining process. The protocol has extremely low coupling and is therefore completely independent of any machine learning model. The performance of the designed and developed system was tested using three well-known machine learning models: Decision tree (DTs), support vector machine (SVM) and multilayer perceptron (MLP). The simulation results show that SVM offers the best compromise between precision and recall, followed closely by the DTs. Regarding the processing time, SVM takes more time followed by the MLP and finally the DTs. In the end, results obtained allow us to conclude that the protocol is realistic and feasible and shows its ability to improve the mining process.  © 2023 IEEE.",TextMining
"Collaboration is argued to be an important skill, not only in schools and higher education contexts but also in the workspace and other aspects of life. However, simply asking students to work together as a group on a task does not guarantee success in collaboration. Effective collaborative learning requires meaningful interactions among individuals in a group. Recent advances in multimodal data collection tools and AI provide unique opportunities to analyze, model and support these interactions. This study proposes an original method to identify group interactions in real-world collaborative learning activities and investigates the variations in interactions of groups with different collaborative learning outcomes. The study was conducted in a 10-week long post-graduate course involving 34 students with data collected from groups’ weekly collaborative learning interactions lasting ~ 60 min per session. The results showed that groups with different levels of shared understanding exhibit significant differences in time spent and maximum duration of referring and following behaviours. Further analysis using process mining techniques revealed that groups with different outcomes exhibit different patterns of group interactions. A loop between students’ referring and following behaviours and resource management behaviours was identified in groups with better collaborative learning outcomes. The study indicates that the nonverbal behaviours studied here, which can be auto-detected with advanced computer vision techniques and multimodal data, have the potential to distinguish groups with different collaborative learning outcomes. Insights generated can also support the practice of collaborative learning for learners and educators. Further research should explore the cross-context validity of the proposed distinctions and explore the approach’s potential to be developed as a real-world, real-time support system for collaborative learning. © 2023, The Author(s).",TextMining
"Rise in global wide population has created lot of demand across various fields and realm. As a result, many recent research mainly focuses on LCC (Land Cover Classification) which are associated with spatial distribution. Therefore, LCC plays an important role for government organizations, policy makers and farmers in order to enhance the process of decision making. In addition to that, LCC using remote sensing has possess various applications such as urban planning, precision agriculture. A massive volume of heterogeneous geographical images over a wide range of geographical areas associated with diversified imaging conditions generally cause photographic distortions, illumination change, and the scale variation, inaccuracy, inefficient due to implementation of ineffective algorithms in the existing studies that seriously decline the classification accuracy. Therefore, proposed study implemented deep learning techniques for overcoming these issues since it minimizes the computation time, makes the network converge much faster and reduces the over-fitting, moreover ResNet50 is light weight deep learning model which are fast to train when appropriately scaled for depth, width and input data resolution can provide comparable and even higher image classification accuracies. This is especially important in remote sensing where the volume of data is very large and increases constantly. Thereby gaining positive implications and delivering exceptional performances in land cover classification in the proposed study. Hence proposed study incorporated a D-CNN (Deep CNN) and ResNet50 for extracting the appropriate features from the pre-processed dataset. Once the data are extracted, dimensionality reduction takes by employing PCA (Principal Component Analysis) to rule out more number of irrelevant features. After employing PCA, classification of images takes place by implementing logistic weight updated hyper parameter tuned random forest method which classifies the extracted features. Finally, performance of the proposed model is evaluated using different performance metrics like accuracy, precision, recall and F1-score. Then the proposed method is further evaluated by comparing the proposed method with the existing methods for assessing the efficiency and efficacy of the proposed model. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"This study proposes an innovative approach to develop a regional-scale landslide forecasting model based on rainfall thresholds optimized for operational early warning. In particular, it addresses two main issues that usually hinder the operational implementation of this kind of models: (i) the excessive number of false alarms, resulting in civil protection system activation without any real need, and (ii) the validation procedure, usually performed over periods too short to guarantee model reliability. To overcome these limitations, several techniques for reducing the number of false alarms were applied in this study, and a multiple validation phase was conducted using data from different sources. An intensity-duration threshold system for each of the five alert zones composing the Liguria region (Italy) was identified using a semiautomatic procedure called MaCumBA, considering three levels of criticality: low, moderate, and high. The thresholds were developed using a landslide inventory collected from online newspapers by a data mining technique called SECaGN. This method was chosen to account for only those events that echo on the Internet and therefore impact society, ignoring landslides occurred in remote areas, not of interest for civil protection intervention, which would adversely affect the model performance because they would result in false alarms. A calibration phase was performed to minimize the impact of false alarms, allowing at least one false alarm per year over the moderate criticality level. In addition, an innovative approach to include antecedent rainfall as the third dimension of the intensity-duration thresholds was applied, generating a consistent reduction in false alarms. The results were validated through an independent landslide inventory and were compared with (i) the alert issued by the regional civil protection agency to observe the improvements achieved with the proposed model and to evaluate to what extent the proposed model is consistent with the assessments of the civil protection and (ii) a dataset of the national states of emergency to verify the suitability of the developed thresholds for alerting citizens. The thresholds obtained showed high predictive capabilities, confirming their suitability for implementation in an operational landslide early warning system. © 2023, The Author(s).",TextMining
"According to data made available by Pordata for the year 2021, about 8.3% of medium school students in Portuguese schools fail or drop out of the educational system, another 9.8% of students in this situation are still in basic education. Since education is one of the pillars of a country’s development, it is important to understand the reasons behind these statistics and discover what leads students to such failure in order to try to mitigate these results. In order to do so, it is necessary to acquire data about the students, thus emerging the area of Educational Data Mining. Early prediction of school failure can be the key piece of the effort to avoid it. So, this paper present a comparative study of machine learning models to indicate the best model to predict school failure. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.",TextMining
"Leaf miners are increasingly causing damage to plants, often causing their death. There are about 10 thousand species of leaf miners in the world. The purpose of this study is to establish the location, species diversity, as well as the degree of damage caused by leaf miners to the leaves of Ulmus L. genus trees in the Pavlodar Region. In the course of the study, a visual inspection of the affected areas was used, as well as the selection, drying of damaged foliage and, subsequently, the removal of larvae and adult insects from it, followed by their study. During the vegetation seasons in 2019–2022, in Pavlodar, Ekibastuz and Aksu cities, as well as in Zhelezinka and Koktobe villages, elm leaves were studied for the presence of leaf miners, a visual inspection of the damage locations was conducted, and samples were taken, which later became the material for growing and detailed study of insects at different development stages. The article considers phyllophagous insects mining elm leaves in the North-East of Kazakhstan (Pavlodar Region) in 2019–2022. In the course of the conducted studies on the territory of the Pavlodar Region, 8 species belonging to 5 genera were identified: Stigmella Schrank, 1802, Orchestes Illiger, 1798, Fenusa Leach, 1817, Bucculatrix Zeller, 1839 and Phyllonorycter Hubner, 1822. Leaf miners that belong to the Agromyza genus of the Agromyzidae family were also identified. All representatives are obligate leaf miners, developing at the larval stage in the mesophyll of elm leaves. Most of the leaf-mining insects are represented by Agromyza and Stigmella species. They are among the most dangerous for the biocoenosis of the Pavlodar Region. Moreover, Agromyza insects have high plasticity and may become a problem in other regions. The obtained data will help to contribute to further studies in this direction, and also show the development degree of an understudied problem: the influence of leaf miners on the nature of Kazakhstan. © 2023 Chemical and Biochemical Sciences. All rights reserved.",TextMining
"Complex traits like water use efficiency (WUE) and nitrogen use efficiency (NUE) are directly associated with crop yield and their stress-tolerant capacity. For developing climate-smart crops, it is crucial to identify new targets for capitalizing the benefits of WUE and NUE. However, understanding the molecular mechanism of WUE and NUE and their coordination with stress mitigation/signalling pathways are complicated. A multi-stress responsive transcription factor, Dehydration-Responsive Element Binding Protein 1C (DREB1C) has recently been recognized as a key component of nitrogen use efficiency (NUE) and yield in rice. Our data mining bioinformatic analysis suggest that DREB1C may be involved in signaling pathways of different hormones such as abscisic acid (ABA), ethylene, gibberellin (GA), and methyl jasmonate (MeJA). Our investigation also indicates that DREB1C is involved in various stress mitigation and signaling pathways, including drought, salt, cold, anaerobic environments, phosphorous starvation, and response to the rice blast fungus. Furthermore, repository data suggests that DREB1C may also be involved in morpho-physiological processes by controlling genes such as small subunits of ribulose-bisphosphate carboxylase, chlorophyll A/B binding protein, and protochlorophyllide reductase. Taken together, we emphasize the role of DREB1C in responding to climate-driven episodes of combined stress, with particular emphasis on to two broad-spectrum traits: WUE and NUE. In this short synthetic review, we make an effort to highlight the underlying connections of DREB1C with plants’ responses to drought and limited nitrogen conditions and emphasize its potential for future climate-smart breeding programs. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"In this article the statement after Equation 1 had an error in the published version. Please refer the correction as follows: “where ν = T#µ and T# is the push-forward of µ along the function T : X → Y” was incorrectly written as “where T# is the push-forward of µ along the function T : X → Y. Furthermore, Equation 1 itself was incorrectly formulated. Namely, the integral should have been over X and not over X × Y. The original article has been corrected. © 2023, The Author(s).",TextMining
"The development of object detection networks has reached a high point, and there have been significant improvements in accuracy and detection speed. Object detection is widely used in intelligent robots, self-driving cars, and other edge-intelligent terminals. Unfortunately, when a detector is allowed to learn new objects in an unfamiliar environment, it can catastrophically forget the objects it has already learned. In particular, reliable and stable knowledge cannot be extracted from old models. Based on this, a new multinetwork mean distillation loss function for open-world domain incremental object detection is presented. To better extract reliable and stable knowledge from old models, we enhanced the distillation output of the detector with a ResNet50 backbone and an output RoI head. The distillation output of the intermediate RPN is softened by adaptive distillation. To obtain more stable results, the ResNet50 backbone and RPN on the channel are zero-averaged. Various incremental steps and stability experiments are performed on two benchmark datasets, PASCAL VOC and MS COCO. The experimental results show the excellent performance of our method in different experimental scenarios, and it is superior to the most advanced methods. For example, in the setting of the batch task, incremental object detection on the PASCAL VOC and MS COCO datasets is improved by 3.4% and 2.1%, respectively.  © 2023 Jing Yang et al.",TextMining
"Geotechnical Asset Management is an approach that has been adopted by civil infrastructure and state highway departments to assess the ""value"" of rock slopes and develop a tool to assess the cost-effectiveness and importance of prioritizing slope and ground improvement projects to enhance transportation corridor reliability. The Ground Support Asset Management program aims to adopt an asset management framework for the underground construction and mining sectors. The University of Arizona operates the San Xavier Mining Laboratory south of Tucson, Arizona. The mine has adits and openings over three levels, including shaft access. The S.X. underground mine will be the launch site and be used as a testbed for trialing the Ground Support Asset Management program. Key aspects that degrade the useful life of elements are corrosion and deformation due to excessive convergence yielding ground in weak rock, deep, and high-stress environments. The primary focus will be on utilizing systems that collect high-resolution point clouds and spectral data to assess deformation and corrosion based on the point cloud data. A secondary project aim is to assess the rock mass and ground conditions for rock reinforcement and ground support design. The research project aims to develop a framework to assess the remaining useful life of ground support and rock reinforcement elements. Then, using the tools and logic developed in this project, the U.A. San Xavier mine and other mining companies can make informed decisions on when to rehabilitate access drifts and critical openings based on proper safety and economic basis. © 2023 57th US Rock Mechanics/Geomechanics Symposium. All Rights Reserved.",TextMining
"Masonry structures are widely used in construction practices worldwide, but they can still suffer severe damage when subjected to blast loadings. This study aims to investigate the impact of blasting activities, a critical component of the mining industry, on nearby masonry structures. Specifically, it focuses on two commonly employed types of brick masonry walls: English bond and Stretcher bond. The research utilizes ABAQUS CAE to develop models and conduct explicit analyses to assess the response of these walls. To accurately capture the behaviour of the brick materials, a simplified micro modeling technique is employed, which incorporates the Drucker-Prager hardening criteria to account for the plastic behaviour of the bricks and mortar. Geophone sensors were used to record blast data at the foundation level of residential structures in close proximity to a coal mine (recorded ppv ranging from 7 mm/sec–30 mm/sec). A comparative analysis of the in-plane (IP) and out-of-plane (OOP) behaviour was performed, aiming to evaluate the impact of the structures' orientation relative to the blast direction. The study observed that in addition to the generally considered in-plane (IP) conditions, the out-of-plane (OOP) loadings generated due to blasting can also endanger the safety of structures and occupants. Therefore, this work provides a helpful reference for the design of blast-resistant brick masonry walls and suggests measures to safeguard them against damage caused by both in-plane and out-of-plane loading conditions. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Multi-label feature selection is an essential component of data mining that can improve classification accuracy. By reducing redundant label information, the feature selection method can select a better feature subset. However, current methods remove too much redundant information and fail to preserve the original label information effectively. To address this problem, this paper proposes a new multi-label feature selection method called granular label dynamic feature selection (GLDFS). First, a label granularity algorithm is proposed to remove redundant label information by granulating highly correlated labels into the same information granule and representing the information granule with the label closest to the center. Second, an automatic granulation quantity algorithm is used to control the granularity size and reduce the loss of useful information. Third, dynamic relevance is introduced into multi-label feature selection from single-label feature selection to select a better feature subset. Finally, compared with six other methods, GLDFS outperforms other methods on three evaluation indicators of thirteen data sets in most cases. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.",TextMining
"To exploit coal from opencast mines, commercial explosives, in large quantities, are used for blasting of overburden rock. The increased use of commercial explosives creates a lot of problems due to the sprawl of urbanization and man’s increased sensitivity to blasting that ultimately necessitates cost-effective and safe rock excavation techniques. It is aimed at exploiting coal safely and productively from opencast mines without any health risk to the mine workers and people residing in the vicinity of the mine. The objective of the paper is to develop a strategic planning, categorization of different subsystem parameters and framing of guidelines to control dust and post-detonation fumes arising due to blasting which would directly help the mine management to control such unwarranted hazards by putting them below the regulatory safe levels. It would also help in generating a huge amount of multilateral data for formulating new sets of guidelines for the mining industry. Non-compliance of regulatory guidelines would otherwise lead to silicosis and other respiratory diseases to mine workers and neighbouring residents. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"A Hydrogeological investigation has been carried out around Rajgamar-dipside (SOI Toposheet no. 64J/15) to predict water inflow in a proposed underground coal mine. The Groundwater table in the study area, is in general, gently undulating and is shallow with an average elevation of 348 − 355 mamsl, and occurs at a depth of 0.5 − 6m below ground level depending upon topography. The groundwater flow-lines converges from north, south and east toward west-central part (Rajgamar) of the study area. Drainage morphometry indicate significant overland flow in the low topography areas leading to excessive soil erosion. Natural seepage rates vary between 4 − 43 ml/cm2/min. Solution sink-holes and pocks ranging in diameter of 4 − 10 cm to 0.5 − 1 m diameter occur densely within the rocks of Kamthi and Barakar Formations. These solution pits link up laterally and vertically to develop networks of channels that serve as free passage for fast infiltration and subsurface flow of water. Field data and petrophysical properties indicate a possible inrush of groundwater at places through underground solution channels and local fractures within shallow depths (~20 m) and a steady inflow of 4397 gpm to 19834 gpm distributed over a corresponding progressive depth of 10 m to 330 m respectively in a proposed underground coal mine for a gallery whose height is 2.5 m, width is 4 m and length is 1000 m. The study will help mine managers to optimise the pumping rate for dewatering during mining activity. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Environmental DNA (eDNA) sampling has attracted worldwide attention over the past few years as an emerging approach to characterising and monitoring biodiversity, and has become particularly important for species that are rare, elusive or endangered. Most animal studies to date have focused on aquatic taxa; studies on other metazoan taxa, particularly wildlife in terrestrial environments, are scarce, with only a handful utilizing soil sources. We aimed to investigate the use of DNA barcoding from soil eDNA in (1) detecting rare/elusive/threatened species and (2) as a tool to investigate and potentially monitor range distributions. Through extensive eDNA sampling along the west coast of South Africa, we aimed to refine the distributions of four golden mole species thought to occur there, and specifically to determine whether De Winton’s golden mole, Cryptochloris wintoni (IUCN Critically Endangered; Possibly Extinct), is in fact extant or extinct. Sequences were generated for three barcode markers (mtDNA cyt b, 12S and nuclear GHR) using next-generation amplicon sequencing. Tissue samples from four specimens were used to generate reference sequences for species identification, along with available GenBank sequences. We were able to (1) successfully detect all four species in our data, and (2) improve records of the distributions of these species. Furthermore, we uncovered cryptic diversity in Eremitalpa granti. Our data conclusively reveal the presence of the elusive Cryptochloris wintoni and suggest that this species may in fact be widespread, but not necessarily abundant, and certainly less so in areas subjected to mining activities, which continue to pose a threat to the species. © 2023, The Author(s).",TextMining
"Uncertainty in data naturally arises in various applications, such as data integration and Web information extraction. A few examples are the following. When information from different sources is conflicting, inconsistent, or simply presented in incompatible forms the result of integrating these sources necessarily involves uncertainty as to which fact is correct or which is the best mapping to a global schema. Data uncertainty is often ignored, or modeled in a specific, per-application manner. This may be an unsatisfying solution in the long run, especially when the uncertainty needs to be retained throughout complex and potentially imprecise processing of the data. In this paper, we study the basic activities of web resources that are affected by uncertainty, more specifically, modeling, programming and evaluation. We propose a probabilistic approach that treats uncertainty in all these activities. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"The growing utilization of lithium-ion batteries in new energy vehicles is emerging as a promising solution to address the global energy crisis and issues related to environmental pollution. Ensuring battery safety and reliability relies heavily on the precise assessment of the SOH, which is of utmost importance. However, the historical state information of batteries used in most data-driven methods may be incomplete or missing, especially in scenarios with small data sizes. In this research, we introduce a sliding window method to reconstruct battery charge and discharge data. This approach involves extracting voltage and current data segments during the battery's charging and discharging stages. These segments are used to construct a VI matrix. We propose a CNN-LSTM deep neural network model for estimating the SOH of lithium-ion batteries. Our model uses two CNN neural network layers to extract frequency domain information from the battery segment data and an LSTM neural network layer to extract the time-domain features of the data. The superiority and generalization capability of the proposed model was validated on the lithium-ion batteries dataset from CALCE by comparing the estimation results with those of single CNN and LSTM models.  © 2023 IEEE.",TextMining
"Short term load forecasting is a guarantee for the safe, stable, and economic operation of the power system. With the large-scale integration of distributed new energy, load fluctuations increase, and the input feature data dimension increases during forecasting. Therefore, it is particularly important to screen and process input features reasonably when using deep neural networks for prediction. In response to the varying degrees of influence of various feature factors at different time points, this paper proposes a feature screening and input feature reconstruction method based on the maximum information coefficient of MIC, which achieves feature impact analysis, screening, and input feature reconstruction at sampling point granularity. The BI-LSTM neural network with stronger information mining ability is introduced to achieve high-precision short-term load forecasting. The results show that using the proposed input feature reconstruction strategy and assigning input feature weights according to the degree of influence significantly improves the prediction accuracy of deep neural networks. The method proposed in this paper has good adaptability to load fluctuations..  © 2023 IEEE.",TextMining
"Objective/Context: The paper provides a comprehensive overview of Latin American mining his-tory, exploring cross-pollination opportunities between mining historians and scholars of the emerging field of the new history of capitalism. The analysis spans from the region’s integration into global markets during the 1500s to the twilight of export-led growth in the early twentieth century. Methodology: The study builds on an overview of both classic and contemporary literature, offering new insights into understanding existing data on mining history within a global context. By incorporating perspectives from geology, ecology, and economics, the article investigates the connections between specific mineral deposits and different paths of capitalistic development across Latin America. Originality: The paper sketches some of the gaps in the analysis of global and local flows of minerals and comments on notable contributions to the broader field of Latin American history. It introduces innovative approaches for the study of output cycles, geological and ecological endowments, technological spillovers, and mining economics. Conclusions: First, the existing literature has predominantly focused on precious metals, with few scholars studying non-precious metals and non-metallic minerals. Second, the narratives surrounding mining history have been primarily centered on silver, overshadowing the significance of bimetallism in understanding the emergence of global capitalism. Thirdly, examining the microeconomic dynamics of mining in the region may present fresh opportunities to explore the impact of mining on sectoral and managerial transformations. Finally, studies of the two-way interaction of capitalism and mining need to include research on the energy and environmental systems that underpinned mineral extraction and production. © 2023, Universidad de los Andes, Colombia. All rights reserved.",TextMining
"Background: Tooth decay, also known as dental caries, is a common oral health problem that requires early diagnosis and treatment to prevent further complications. It is a chronic disease that causes the gradual breakdown of the tooth’s hard tissues, primarily due to the interaction of bacteria and dietary sugars. Results: While numerous investigations have focused on addressing this issue using image-based datasets, the outcomes have revealed limitations in their effectiveness. In a novel approach, this study focuses on feature-based datasets, coupled with the strategic integration of Principle Component Analysis (PCA) and Chi-square (chi2) for robust feature engineering. In the proposed model, features are generated using PCA, utilizing a voting classifier ensemble consisting of Extreme Gradient Boosting (XGB), Random Forest (RF), and Extra Trees Classifier (ETC) algorithms. Discussion: Extensive experiments were conducted to compare the proposed approach with the chi2 features and machine learning models to evaluate its efficacy for tooth caries detection. The results showed that the proposed voting classifier using PCA features outperformed the other approaches, achieving an accuracy, precision, recall, and F1 score of 97.36%, 96.14%, 96.84%, and 96.65%, respectively. Conclusion: The study demonstrates that the utilization of feature-based datasets and PCA-based feature engineering, along with a voting classifier ensemble, significantly improves tooth caries detection accuracy compared to image-based approaches. The achieved high accuracy, precision, recall, and F1 score emphasize the potential of the proposed model for effective dental caries detection. This study provides new insights into the potential of innovative methodologies to improve dental healthcare by evaluating their effectiveness in addressing prevalent oral health issues. © 2023 Alsubai. All Rights Reserved.",TextMining
"This paper proposes a codec model based on feature reinforcement and text knowledge supplement. In the coding stage, the model extracts fine-grained features of static objects in the video through local and global feature intensification, improves the resolution of similar semantics of objects, and integrates visual semantics and video features into long short-term memory (LSTM). In the decoding stage, in order to mine the hidden information in the video that is not easy to be found by the machine, part of the frame of the video is intercepted and the visual target is detected. The obtained visual target is used to extract knowledge from the external knowledge language database to supplement the generation of description text, so as to produce a more novel and natural text description. The experimental results show that the proposed method has good performance, and the generated content information can show novel implicit information to a certain extent.  © 2023 IEEE.",TextMining
"In order to overcome the problems of low accuracy of data mining, high relative error of prediction and high time consumption of traditional methods, a purchasing behaviour prediction method of e-commerce platform users based on multidimensional data mining is proposed. FP-Growth algorithm is used to mine the multidimensional data of e-commerce platform users' purchasing behaviour, so as to extract the characteristics of users' purchasing behaviour. Combined with feature extraction results, the hidden Markov model is used to calculate the probability of user access and the probability of no access. If the probability of access is greater than the probability of no access, it is considered that the user will access in the next month, otherwise it will not. The experimental results show that the average data mining accuracy of this method is 96.39%, the maximum prediction relative error rate is 5%, and the time consumption is always below 0.8 s.  © 2023 Inderscience Enterprises Ltd.",TextMining
"New knowledge on the occurrence of Lower and Middle Miocene sediments in the southwestern surroundings of Brno has been acquired through geological mapping and documentation work during the recent years. Specific work was focused on: • preparation of the publication on the local national history of the cadastral territory of the village of Bohutice; • salvage study of the former reserved bentonite deposit Ivančice – Réna, which is being gradually remediated and turned into a recreational area; • the area in the foreground of the New Ivančice viaduct, which is susceptible to long-term slope instability; • the western edge of the village of Němčičky near Židlochovice, where extensive construction of family houses is underway; • the area between the municipalities of Moravany, Nebovidy and Ostopovice, where the excavations for new extra-high voltage pylons were documented. The detailed mapping, petrographic and biostratigraphic studies allowed to refine the distribution, lithological characteristics and age of Miocene sediments; specifically, a more extensive occurrence of Lower Miocene sediments compared to previous findings was confirmed (localities Ostopovice, Moravské Bránice – locality 5). These findings support earlier results from the area N of the City of Brno, where the known extent of Ottnangian sediments was expanded at the expense of Badenian sediments. The documentation and sampling of the new excavations (for family houses and extra-high voltage pylons) and old mining pits enabled the description and further study of the sediments. The acquired litho- and biostratigraphic data were correlated with engineering geological findings. In a construction pit in Bohutice, a completely new occurrence of tuffitic sediments of the Ottnangian age was discovered and geochemically verified. Furthermore, the Ottnangian gravels in Němčičky were newly discovered. These contain a large proportion of granitoid pebbles probably derived from the Brno Massif. It was found that the weakly consolidated lithologically variable Lower Miocene sediments are prone to landslides. In the case of the New Ivančice viaduct, extensive suffusion doline were identified, resulting from the ingress of rainwater from the wider area of the railway embankment foreground. Biostratigraphy of the sediments was based on micropaleontological analysis of foraminiferas. Ottnangian sediments were usually fossil-free and/or they contained reworked Cretaceous foraminiferas. Lower Badenian sediments are characterized by occurrence of abundant and diversified fauna represented by foraminifera species such as Martinotiella karreri (Cush.), Globigerinoides bisphericus Todd, Vaginulina legumen (L.), etc. © 2023 Czech Geological Survey. All rights reserved.",TextMining
"The advent of intelligent education systems and widespread distance learning have revolutionized the educational landscape. Extracting meaningful insights from this wealth of information is crucial for improving student learning outcomes. Knowledge tracking plays a pivotal role in monitoring and optimizing students’ comprehension by simulating their understanding of knowledge concepts. Previous studies on knowledge tracing models have largely overlooked the influence of forgetting law and lack effective representation methods for forgetting. To address this problem, we proposes a novel knowledge tracking model based on GRU-attention with integrated a forgetting law, abbreviated as FGAKT. FGAKT is composed of four essential modules: an embedding module that incorporates forgetting laws to optimize memory retention, an attention extraction module that employs an encoder-decoder structure for effective feature selection, a GRU module to capture long-term timing information, and a prediction module. To enhance the interpretability of the model, we introduce the weight of the attention extraction module’s output into the loss function, which encourages the model to prioritize features. Additionally, we use regulation parameters to balance the predictive performance and interpretability of the model. Experimental results demonstrate that FGAKT outperforms the baselines in terms of ACC and AUC. Furthermore, ablation experiments show the feasibility of each module and the impact of layers within the encoder-decoder structure. The student answering process is instantiated to provide an intuitive depiction of how the model simulates a student’s response. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.",TextMining
"The recent progress in computing has made iteasier to collect and store huge amounts of information in a text. The growing size of text datasets in text mining and the high dimensionality associated with knowledge discovery is a great challenge that makes it difficult to classify documents into various categories and sub- categories. This paper focuses on how text can be mined from social networks and then categorized using n-grams to determine specific trends and patterns. The main aim of Knowledge Discovery is to extract knowledge from data in the context of large databases. The volume of information that is available is increasing every day. This data ranges from that used in business transactions to scientific data, sensor data, pictures, videos, etc. There is, therefore, a need for a system capable of extracting the core of available information and automatically generating reports, opinions, or summaries of data to aid organizations in better decision-making. Knowledge Discovery is a repetitive process where evaluation measures are often enhanced, mining done on data can be refined, there is an integration of new data, and the data is transformed to get accurate and more appropriate results. The data collected from social networks need to be filtered to capture specific text that will be useful to a PR brand following what clients say about their products online. There is a need for a technique that will provide a quick and precise way of fetching specific text from huge amounts of data on social networks to help analyze the feedback. This research analyzes the use of n-grams to fetch specific text from near-real-time customer feedback that is in the form of large data on Twitter to help Public Relations agencies determine the trends and patterns that will help them align their brands with customer preferences.  © 2023 IEEE.",TextMining
"The article considers the intensity of the subsidence process of the given surface of the territory of the Central coal-mining district of Donbas from 2015 to 2021, according to radar data from the Sentinel-1 satellite. There are 26 mines on this territory, most liquidated by completely uncontrolled flooding of mining operations without further control of the hydrodynamic regime. This study aims to determine the dangerous zones formed due to soil subsidence to rank the territory, particularly minefields, according to the degree of degradation processes (on the example of the Main Anticline of Donbas). The satellite-based radar differential Interferometry (DInSAR) methodology based on the SNAP program was used to construct a map of the Earth's surface vertical movements. The obtained results show that on a regional scale within the region from the northwest to the southeast, there is an increase in the amplitude of the vertical movements of the daytime surface, which coincides with the direction of the rise in the intensity of neotectonic movements of the entire territory of Donbas. It was established that the part of the works is divided into two regions according to the characteristics of the manifestation of local upward movements: northwestern and southeastern, which are clearly distinguished by the morphology of their constituent structures of the field of the local component of the vertical movements of the Earth's crust. © 2023 International Multidisciplinary Scientific Geoconference. All rights reserved.",TextMining
"Antibiotic-resistant illnesses are on the rise worldwide, and the pipeline for developing new antibiotics is drying up. As a result, researchers need to create novel compounds with antimicrobial action. Recent decades have seen a dearth of novel antibiotics because of the reliance on conventional empirical screening procedures using both natural and synthetic chemicals to find them. There is hope that the massive amount of bacterial genome sequence data that has become accessible since the sequencing of the first bacterial genome more than 20 years ago might help lead to the development of new antibiotic drugs. Genes with significant levels of conservation both within and between bacterial species can be found using comparative genomic techniques; these genes may be involved in essential bacterial functions. Bioactive chemicals found in natural products have been successfully used in treating everything from infectious diseases to cancer, but over the past 20-30 years, the effectiveness of screening methods based on fermentation has decreased. Researchers urgently need answers to the unmet demand for bacterial infection resistance. Now more than ever, with the advent of cheap, high-throughput genomic sequencing technology, natural product discovery can be revitalized. Using bio-informatics, investigators may foretell whether or not a certain microbial strain would generate compounds with novel chemical structures, which may have novel modes of action in inhibiting bacterial growth. This manuscript describes how this potential might be utilised, with a particular emphasis on manipulating the expression of dormant biosynthetic gene clusters that are hypothesised to encode new antibiotics. Additionally, it consolidates the work of the past and the present to utilise bacterial genomic data in the identification and development of new antibiotics. © 2023 Bentham Science Publishers.",TextMining
"Induction motor temperature situation prediction provides a decision basis for preventive maintenance in coal mining companies. However, multi-step prediction of induction motor temperature is a challenge due to the complexity of working conditions and external disturbances in surface coal mines. This paper proposes a multi-sensor fusion multi-step prediction model based on Graph Convolutional Neural Network with Long Short-Term Memory Network (GCN-LSTM). Specifically, the model takes into account the spatial correlation and long-term temporal dependence of multi-source sensors as well as the temporal-spatial fusion correlation at different times. This thesis is based on multi-source temperature sequence data collected from a mining induction motor. Experimental results show that the model is able to achieve 31.3%, 38.7%, and 17.1% performance improvement compared to CNN, LSTM, and GCN methods. © 2023",TextMining
"Web usage mining is a crucial research area that aims to uncover user behavior patterns from web log data because web usage mining can be used to analyze a website’s usage. This study examined web usage mining to discover online users’ usage patterns and used the results to redesign and improve the government website. This study aims to help online customers obtain a better experience. A dataset was collected from the Metropolitan Electricity Authority (MEA) website. Various algorithms, including association rule mining (Apriori and Frequent Pattern-Growth (FP-Growth)) and sequential pattern mining (Generalized Sequential Pattern (GSP) and Prefix-Span), were used to mine the user usage data. The first 30 frequently visited patterns of web usage mining results were selected for analysis and to develop a prototype. It revealed that most pages were accessed directly. Moreover, most users were interested in alternative energy information, the Fuel Adjustment Charge (at the given time) or the FT rate, the power outage announcement page, and reducing electric expenses information. Furthermore, the analysis indicated that customers were interested in making online processes, such as using the contact-us feature, downloading forms, and calculating their electric expenses. A survey was conducted with 30 participants and the results were compared with the usage data from the weblog. Welch’s t-test was utilized to evaluate the prototype. The findings indicated that the newly implemented website, based on the user usage patterns, was more effective and reduced the user’s usage time. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.",TextMining
"Understanding the strength of rock discontinuities has been one of the core research topics in geomechanics over the past decades. This is unsurprising as many structural failures in underground excavations, including mining and tunnelling, occur at rock discontinuities. In oil, gas, and geothermal industry, the strength of rock discontinuities has also attracted a great deal of attentions because, for example, pre-existing discontinuities can significantly change the structures of hydraulic fracture networks. It is also anticipated that the strength of rock discontinuities will become increasingly important for leakage risk assessment of carbon dioxide geological sequestration projects. For all these reasons, we must achieve a good understanding of strength of natural rock discontinuities at the subsurface stress conditions, which, unfortunately, is not well explored. This problem can be primarily attributed to the limited numbers of valid rock samples that contain natural and undisturbed rock discontinuities, especially for the case of cohesive rock discontinuities. In this study, we obtained some rock specimens with naturally bonded shale-sandstone interface. We measured the geomechanical properties of the natural shale-sandstone interface under constant normal loads, using biaxial direct shear apparatus. The measured strength of interface indicates the combined effect of normal loading levels and natural interface roughness. Our characterization provides valuable geomechanical data of natural shale-sandstone interface at the subsurface conditions. These data can benefit all subsurface engineering projects where it is crucial to examine shale-sandstone interface failure for project success, including underground mining, tunnelling, fluid injection/extraction in sandstone reservoirs of shale caprocks. © 2023 57th US Rock Mechanics/Geomechanics Symposium. All Rights Reserved.",TextMining
"Occupational health and safety in mining operations hold paramount importance, encompassing multifaceted aspects aimed at ensuring the well-being of workers. Prolonged whole-body vibration (WBV) exposure among mining vehicle operators has been associated with a range of adverse health effects, most notably musculoskeletal disorders (MSDs) such as chronic low back pain and lumbar disc herniation. This study aims to develop a predictive model utilizing machine learning techniques, specifically Artificial Neural Networks (ANNs), to forecast the health risk associated with WBV exposure under different operational conditions. The vibration data of the tippers were acquired during its routine operation in an opencast mine in central India. The dataset encompassed various operational factors, including haul road type, operator weight, speed, and payload, under which an ANN model was trained to predict the resulting vibration exposure magnitude. ANN model was developed using Multilayer Perceptron (MLP) architecture to predict the health risk. Backpropagation was used to adjust the weights of the connections between neurons in order to minimize the difference between predicted and actual output. 70% of the total data was used for training and the others for data testing (15%) and validation (15%). The correlation coefficient for the training and test of the optimum network were found to be 97.58% and 97.4%, respectively indicating an excellent correlation between the predicted frequency weighted root mean square acceleration (awrms) for both training and test stages. AI has revolutionized the mining industry, bringing digitization and automation to the forefront. The predictive model presented here for WBV-related health risks is a powerful tool for mine safety engineering. By harnessing machine learning techniques, it improves risk assessment and enables targeted interventions, improving the quality of life of the mining workforce. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"This paper studies the correlation between students' concentration in class and learning interest, emotional state and other influencing factors. By collecting students' classroom status data, a data set suitable for data mining is constructed. Based on the idea of Apriori algorithm, the Anaconda Navigator programming tool is used to mine the association rules of students' classroom concentration. Through data mining based on Apriori algorithm, and the association rules between students' emotional state, learning interest and other factors and in-class test scores are output. The results of strong association rules show that the better students' emotional state, learning interest and other states are, the better their classroom concentration performance is. Mining the potential influencing factors of students' classroom concentration provides valuable reference theory for students to improve classroom concentration and teachers to improve classroom teaching effect, which is helpful for teachers and students to build a more efficient classroom together in the future.  © 2023 IEEE.",TextMining
"This study focused on the water-inrush risks associated with close-distance mining of thin coal seams under with pressure, using a single working face of the Yangcun coal mine as its focal point. After analyzing the tectonic characteristics and fault distribution of the mine’s floor strata, the primary water-inrush risks of the floor associated with mining were from the combined no. 13–14 aquifer group and the confined Ordovician limestone aquifer. An engineering geological numerical model was established to analyze the effects of mining stress and floor water pressure on the thin no. 16up and no. 17 coal seams. We determined the failure depth feature information of the floor components, with and without faults, as well as the height of the confined water in the fault zone. Finally, we combined the field-measured permeability resistance data of the 10605F5 fault and floors with different structures to systematically assess the water-inrush risks. We used both the safety factor method and the water-inrush coefficient method to evaluate these risks for both floor conditions in the working face. The results indicated that there was no water-inrush risk associated with the 10,703 working face floor, even with mining pressure. The study ideas and methods provide a valuable guide for assessing floor water-inrush risks in multi-layer coal seams with similar geological and mining conditions. © 2023, The Author(s) under exclusive licence to International Mine Water Association.",TextMining
"This study utilized the Google Earth Engine (GEE) service to analyze satellite images, aiming to determine human-induced spatial and temporal changes in the man-made water surface and identify anthropogenic alterations in the Solotvyno salt mine agglomeration. Traditional methods for measuring vertical topography changes using active satellite imagery are complex. GEE enabled efficient processing of large geospatial datasets in the cloud, employing masks and machine learning for a wide range of computational operations. The masking method, using threshold values and image pre-processing, offered a simpler approach to track vertical relief displacements. Additionally, it provided accurate and prompt research results. By employing water surface masks and analyzing Sentinel 1 and Sentinel 2 satellite images, it was observed that the area of land subsidence and water presence above flooded mining areas increased from 2015 to 2023, displaying a tendency for further expansion. These findings can be utilized to identify risk areas, inform decisions regarding ecosystem preservation and sustainable territorial development, and predict potential damage to critical infrastructure. The primary focus is on using threshold masks for active satellite data to detect inundation zones where vertical relief displacements occur, enabling the calculation of their areas and sizes. This approach was compared to passive data, which exhibited a similar trend over the entire time frame. The method offers a quicker and more accessible means of detecting vertical relief displacements compared to methods such as classification and interferometry. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"We consider the logistic metapopulation model over a stream network and use the metapopulation growth rate and the total biomass (of the positive equilibrium) as metrics for different aspects of population persistence. Our objective is to find distributions of resources that maximize these persistence measures. We begin our study by considering stream networks consisting of three nodes and prove that the strategy to maximize the total biomass is to concentrate all the resources in the most upstream locations. In contrast, when the diffusion rates are sufficiently small, the metapopulation growth rate is maximized when all resources are concentrated in one of the most downstream locations. These two main results are generalized to stream networks with any number of patches. Copyright © by SIAM.",TextMining
"By tapping into the human mobility of the urban rail transit (URT) network to understand the travel demands and characteristics of passengers in the urban space, URT managers are able to obtain more support for decision-making to improve the effectiveness of operation and management, the travel experience of passengers, as well as public safety. However, not all URT networks have sufficient human mobility data (e.g., newly-operated URT networks). It is necessary to provide data support for mining human mobility in data-poor URT networks. Therefore, we propose a method called Meta Long Short-Term Memory Network (Meta-LSTM) for passenger flow prediction at URT stations to provide data support for networks that lack data. The Meta-LSTM is to construct a framework that increases the generalization ability of a long short-term memory network (LSTM) to various passenger flow characteristics by learning passenger flow characteristics from multiple data-rich stations and then applying the learned parameter to data-scarce stations by parameter initialization. The Meta-LSTM is applied to the URT network of Nanning, Hangzhou, and Beijing, China. The experiments on three real-world URT networks demonstrate the effectiveness of our proposed Meta-LSTM over several competitive baseline models. Results also show that our proposed Meta-LSTM has a good generalization ability to various passenger flow characteristics, which can provide a reference for passenger flow prediction in the stations with limited data. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"As part of the GoldenEye project with European co-financing type H2020, the Academic Leapfrog Geo licensed program was purchased, with which a 3D modeling of the deposit body was made based on open source data, geological maps of the Romanian Geological Institute, non- secret data of CUPRUMIN company and drone flights. The ore has not been modeled in 3D up to now, this work presents for the first time the first consolidated modeling that highlights the size of the ore deposit body. These modelings will allow the taking of technical decisions regarding: the mode of exploitation ( open-pit /underground, redefining the depth of the exploitation limit, the location and development of waste dumps, the geometry of the open pit, the location of underground mining works and preparation works for underground exploitation, data from structural geology). The 1:1 scale geometry of the open pit was traced through topographical measurements from the ground, drone and satellite surveys using Copernicus images. These data were correlated to check the information flow and the efficiency of the internal reporting of the project team in close collaboration with the CUPRUMIN beneficiary team. Three large monitoring campaigns were carried out in the period August 2021-May 2022-September 2022, on the current geometric model of the open pit, the drillings of thousands of meters were positioned with the initial coordinates and lengths, the main faults, the state of stability/instability of the slopes, the identification of four major categories of rock types. © 2023 International Multidisciplinary Scientific Geoconference. All rights reserved.",TextMining
"Predicting academic success is essential in higher education because it is perceived as a critical driver for scientific and technological advancement and countries’ economic and social development. This paper aims to retrieve the most relevant attributes for academic success by applying educational data mining (EDM) techniques to a Portuguese business school bachelor’s historical data. We propose two predictive models to classify each student regarding academic success at enrolment and the end of the first academic year. We implemented a SEMMA methodology and tried several machine learning algorithms, including decision trees, KNN, neural networks, and SVM. The best classifier for academic success at the entry-level reached is a random forest with an accuracy of 69%. At the end of the first academic year, an MLP artificial neural network’s best performance was achieved with an accuracy of 85%. The main findings show that at enrolment or the end of the first year, the grades and, thus, the student’s previous education and engagement with the school environment are decisive in achieving academic success. © 2023 by the authors. Licensee ESJ, Italy.",TextMining
"Network Intrusion Detection System (IDS) is crucial in defending the target network from intrusions. However, due to information loss and insufficient feature dimensions during feature extraction, the majority of existing detection algorithms are unable to fully utilize the data present in the original network. To address the aforementioned issues, this study examines the presence of temporal and spatial characteristics in network traffic data and proposes a new intrusion detection model named CRNN-SA which combines hierarchical Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) and Self-Attention. This model extracts spatial features and temporal features by using CNN and RNN, respectively, and “connects” the features extracted by CNN and RNN to obtain fusion features. In order to express useful input information better, Self-Attention is utilized to allocate distinct weights to the combined characteristics. This model can effectively extract spatial and temporal features of data by increasing the granularity of synchronized input data. To ensure the accuracy of the model, it undergoes evaluation using the UNSW-NB15 dataset. The Accuracy and F1-score of the CRNN-SA model under the binary classification are 90.4 % and 91.3 %, respectively, and the metrics under the multi-class classification are 89.9 % and 77.5 %, respectively. Through experiments, it has been demonstrated that the combination of feature selection and deep learning models can significantly enhance the detection capability, resulting in a substantial decrease in the false positive rate. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"In markets with service models such as contractual banking, and merchants, new customer acquisition is much more expensive than customer retention. Banks should focus on various marketing activities by detecting the potential of losing customers by using data mining and machine learning methods. In this study, in a sample of a private bank in Turkey, the probability of leaving the next month is calculated by the customer loss analysis called the Churn Analysis of the member businesses determined by the brand in the retail sector and similar parameters. In this context, analysis was made with 128.721 samples and various performance metrics (Accuracy, Precision, Sensitivity, Area Under the Line, and Gini) in the data set created to calculate the separation probabilities. By using 75 different parameters such as transaction volume, number of transactions, number of products in the bank, number of complaints, size of work in the bank, current pricing, and dues payment order of the workplaces in the last 1 year, the leaving score and wallet share decrease scores were calculated for the workplaces. Decision Tree, Random Forest, Cat Boost, XGBoost and LightGBM machine learning algorithms were used for this research. Due to its performance, the LightGBM algorithm was chosen. © 2023 IEEE.",TextMining
"In recent research, the effectiveness of text clustering is the long-term pursuit goal, because the same clustering documents have the maximum correlation and internal connection, this technology can simplify the user's text processing process. This research study focuses on the very large-scale short text clustering with a case study of legal documents. First, the normal size short text clustering algorithm is studied, the encapsulation method is used, and the Term Frequency-Inverse Document Frequency (TFIDF) algorithm is selected. Then, after finding the shortcomings, the 2-step algorithm for very large short text clustering is proposed. First, the text similarity reduction serves as the pre-processing, and this study applies the iteration function together with the Simhash algorithm to achieve the goal. Second, the class-centric algorithm extension method is designed to effectively cluster massive information. The performance of the algorithm is evaluated by experiment in terms of time and accuracy.  © 2023 IEEE.",TextMining
"Social media has become an essential source of news for everyday users. However, the rise of fake news on social media has made it more difficult for users to trust the information on these platforms. Most research studies focus on fake news detection in the English language, and only a limited number of studies deal with fake news in resource-poor languages such as Urdu. This article proposes a globally weighted term selection approach named normalized effect size (NES) to select highly discriminative features for Urdu fake news classification. The proposed model is based on the traditional inverse document frequency (TF-IDF) weighting measure. TF-IDF transforms the textual data into a weighted term-document matrix and is usually prone to the curse of dimensionality. Our novel statistical model filters the most discriminative terms to reduce the data’s dimensionality and improve classification accuracy. We compare the proposed approach with the seven well-known feature selection and ranking techniques, namely normalized difference measure (NDM), binormal separation (BNS), odds ratio (OR), GINI, distinguished feature selector (DFS), information gain (IG), and Chi square (Chi). Our ensemble-based approach achieves high performance on two benchmark datasets, BET and UFN, achieving an accuracy of 88% and 90%, respectively. © 2023 Wasim et al. Distributed under Creative Commons CC-BY 4.0. All Rights Reserved.",TextMining
"Indonesia possesses many open-pit mining that require monitoring. This study aims to map open pit mining in Central Bangka Regency, Bangka Belitung Islands Province, Indonesia using multi-temporal Sentinel-2 imageries. The open pit mining was mapped using Enhanced Input Selection for Classification Process (EISCP) and Machine Learning. The EISCP systemically integrates band selection, texture analysis employing the Gray Level Co-Occurrence Matrix, and Principal Component Analysis. Multiple Machine Learning (ML) algorithms, including Random Forest (RF), Classification And Regression Trees Classifier (CART), and Support Vector Machine (SVM), were utilized to classify mining and non-mining areas. There were three band combination scenarios: (1) a combination of blue, green, red, red edge-1, red edge-2, red edge-3, Near-InfraRed (NIR) bands, red edge-4, Short-Wave InfraRed-1 (SWIR-1), and Short-Wave InfraRed-2 (SWIR-2); (2) a combination of red bands, red edge-1, and SWIR-2; and (3) using principal analysis (PC1) from the EISCP results as classification data input. High resolution image of SPOT-6 and PlanetScope data in 2021 was used as data reference for validation. We found that the SVM algorithm with EISCP input band scenarios produced the highest accuracy of 97.55% and a kappa coefficient of 0.91 among all combinations of band scenarios and ML algorithms. The implementation of RF and CART algorithms with EISCP input band scenarios resulted good accuracy, with differences of only 0.62% and 1.84% from SVM. The mapping outcomes from the ML algorithms demonstrated that utilizing EISCP can enhance the precision of open-pit mining mapping in the research area. © 2023, Indian Society of Remote Sensing.",TextMining
"Knowledge graphs are used for organizing and connecting individual entities to integrate the information extracted from different data sources. Typically, knowledge graphs are used to connect various real-world entities like persons, places, things, actions, etc. For the knowledge graphs created using the enterprise data, the knowledge graph entities can be of different types—static entities (e.g., people, projects), communication entities (e.g., emails, meetings, documents), derived entities (e.g., rules, definitions, entities from emails), etc. The graphs are used to connect these entities with enriched context (as edges and node attributes) and used for powering various search and recommendations applications. With the advent of large language models, the whole lifecycle of knowledge graphs involving –information extraction, graph construction, application of graphs, querying knowledge graphs, using the graph for recommendations, etc., – is impacted. With large language models such as GPT, LLaMA, PALM, etc., entity and relationship extraction can be improved. Similarly, one can answer different types of queries with the help of LLMs which were very difficult without them. This workshop is about improving the enterprise knowledge graphs and its applications using large language models. Enterprise graphs can be of different scopes—whether they contain data from individual users/customers, a sub-organization, or the whole enterprise. This workshop will also cover various privacy and access control related issues which are typical for any enterprise graph. These include privacy preserving federated learning, using LLMs to extract information from private data, querying the knowledge graph in a privacy preserving manner, etc. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",TextMining
"Due to the dynamic nature of the food supply ecosystem and rising reports on food-borne disease outbreaks, effective food safety risk monitoring has become crucial for public health and socioeconomic development. The Singapore Food Agency (SFA) is a statutory board that oversees the food safety and security of Singapore. Part of its functions is to monitor and detect potential food-borne incidents. Currently, SFA scientists rely on manual efforts to gather relevant information from various internal datasets for risk assessments and decision making. This is not only time-consuming but also susceptible to human errors. To tackle the problem, this paper proposes a system called SFA-FSM, which applies advanced AI technologies for predictive food safety risk monitoring. In particular, we fine-tune Transformer-based pre-trained language models such as BERT and XLNet into SFA-FSM for online food safety news monitoring, customer feedback monitoring, and named entity extraction. Moreover, we have conducted experiments to evaluate the proposed food safety monitoring approaches. The experimental results have shown that the proposed approaches have achieved promising performance. © 2023 IEEE.",TextMining
The proceedings contain 216 papers. The special focus in this conference is on Advanced Data Mining and Applications. The topics include: A Novel Variational Autoencoder with Multi-position Latent Self-attention and Actor-Critic for Recommendation; fair Re-Ranking Recommendation Based on Debiased Multi-graph Representations; FastNER: Speeding up Inferences for Named Entity Recognition Tasks; CPMFA: A Character Pair-Based Method for Chinese Nested Named Entity Recognition; STMC-GCN: A Span Tagging Multi-channel Graph Convolutional Network for Aspect Sentiment Triplet Extraction; exploring the Design Space of Unsupervised Blocking with Pre-trained Language Models in Entity Resolution; joint Modeling of Local and Global Semantics for Contrastive Entity Disambiguation; KFEA: Fine-Grained Review Analysis Using BERT with Attention: A Categorical and Rating-Based Approach; discovery of Emotion Implicit Causes in Products Based on Commonsense Reasoning; from Time Series to Multi-modality: Classifying Multivariate Time Series via Both 1D and 2D Representations; multi-modal Multi-emotion Emotional Support Conversation; exploiting Pseudo Future Contexts for Emotion Recognition in Conversations; generating Enlightened Suggestions Based on Mental State Evolution for Emotional Support Conversation; deep One-Class Fine-Tuning for Imbalanced Short Text Classification in Transfer Learning; EmoKnow: Emotion- and Knowledge-Oriented Model for COVID-19 Fake News Detection; popular Songs: The Sentiment Surrounding the Conversation; market Sentiment Analysis Based on Social Media and Trading Volume for Asset Price Movement Prediction; efficient Mining of High Utility Co-location Patterns Based on a Query Strategy; point-Level Label-Free Segmentation Framework for 3D Point Cloud Semantic Mining; CD-BNN: Causal Discovery with Bayesian Neural Network; exploring the Effectiveness of Positional Embedding on Transformer-Based Architectures for Multivariate Time Series Classification; a Preference-Based Indicator Selection Hyper-Heuristic for Optimization Problems; an Elastic Scalable Grouping for Stateful Operators in Stream Computing Systems; incremental Natural Gradient Boosting for Probabilistic Regression; discovering Skyline Periodic Itemset Patterns in Transaction Sequences; Double-Optimized CS-BP Anomaly Prediction for Control Operation Data.,TextMining
"A bibliometric analysis of current research, hotspots, and development trends was used to develop an overall framework of mechanisms of alpine grassland degradation on the Qinghai-Tibet Plateau. This investigation includes data from 1,330 articles on alpine grassland degradation on the Qinghai-Tibet Plateau, acquired from the Chinese Science Citation Database (CSCD) and Web of Science Core Collection (WOS). Research was divided into three themes: spatial scope and management of typical grassland degradation problems, dynamic mechanisms of grassland degradation and effects of ecological engineering, and grassland degradation risk based on remote sensing technology. The results of the analysis showed that the research can be summarized into three aspects: typical grassland degradation identification, dynamic mechanism analysis of grassland degradation, and grassland ecosystem stability strategy. The main findings can summarized, as follows: (1) Ecological analyses using the river source as a typical region defined the formation of ""black soil beach""type degraded grasslands in the region, and promoted the ecological environment management and protection of the alpine grassland by discussing the causes of regional ecological environment changes; (2) Dynamic mechanism analyses of climate change and characteristics analyses of grassland vegetation-soil degradation revealed that alpine grassland degradation is the result of multiple main factors; and (3) Risk prediction methods for grassland degradation, methods of grassland management and sustainable countermeasures for agriculture and animal husbandry development, and the development of a compre- hensive index of influencing factors on grassland degradation all indicate that selecting the right grassland restoration measures is the key to grassland restoration. Remote sensing monitoring and high-throughput sequencing technology should be used in future research on grassland ecosystems. In addition, multiscale, multidimensional, and multidisciplinary systematic research methods and long-term series data mining could help identify the characteristics and causes of alpine grassland system degradation. These findings can help identify a more effective coordination of landscape, water, lake, field, forest, grass, and sand management for the prevention of alpine grassland degradation.  © 2023 Xu et al.",TextMining
"Background: Kidney and ureter stones are the third pathologies in urological diseases. Less invasive treatments such as transureteral lithotripsy and extracorporeal shock wave lithotripsy are used to treat ureteral stones. Data mining has provided the possibility of improving decision-making in choosing the optimal treatment. In this paper predictive models for the detection of ureter stone treatment (first model) and its outcome (second model) is developed based on the patient's demographic, clinical, and laboratory factors. Methods and Material: In this cross-sectional study a questionnaire was used to identify the most effective features in the predictive models, and Information on 440 patients was collected. The models were constructed using machine learning techniques (Multilayer perceptron, Classification, and regression tree, k-nearest neighbors, Support vector machine, Naïve Bayes classifier, Random Forest, and AdaBoost) in the Bigpro1 analytical system. Results: Among the Holdout and K-fold cross-validation methods used, the Holdout method showed better performance. From the data-based balancing methods used in the second model, the Synthetic Minority oversampling technique showed better performance. Also, the AdaBoost algorithm had the best performance. In this algorithm, accuracy, sensitivity, specificity, precision, F- measure, and Area under the carve in the first model were 89%, 87%, 91%, 90%, 89%, and 94% respectively, and in the second model were 81%, 81%, 82%, 84%, 82%, and 85% respectively. Conclusions: The results were promising and showed that the data mining techniques could be a powerful assistant for urologists to predict a surgical outcome and also to choose an appropriate surgical treatment for removing ureter stones. © 2023 Wolters Kluwer Medknow Publications. All rights reserved.",TextMining
"We introduce a versatile approach for Boolean factorization of binary data matrices based on a projected hierarchical alternating least squares method. The general model considered in this work allows for an arbitrary Boolean combination of the binary rank-1 terms. The underlying approximation problem is tackled by relaxing the binary constraints and representing the combining function by a multivariate polynomial. This leads to closed-form and simple to implement updates of the alternating algorithm. Performance comparisons with other methods from the literature are presented for the standard Boolean ('OR') mixture model. We also pro-vide results on real data, as well as factorization examples using XOR and 3-term majority logical operators as combining functions. © 2023 IEEE.",TextMining
"According to reports, exposure to high concentrations of naturally occurring radioactive substances like Uranium-238, Thorium-232, and Potassium-40 poses serious health concerns. This review study aims to report the concentrations of radionuclides in various South African soil and their equivalent risk assessments, which have been sparingly reported. For South Africa, most radionuclide concentrations above the permissible limits of 33, 45, and 420 Bq.kg−1 for 238U, 232Th, and 40K, respectively, have been found in some soil samples taken near industrialization activities, including mining and oil exploration and production. Thus, the amount of radionuclides is a good indicator of the kind of soil, the local geology, and the mineral make-up of the parent rocks. The increases in radiation exposure to people and the environment have been reported to cause various radiological health hazards. Thus, this review study can be used as a data source to track probable radioactive contamination from soils found in South Africa. © 2023 Informa UK Limited, trading as Taylor & Francis Group.",TextMining
Objective： To explore the macroscopic medication pattern of traditional Chinese medicine （TCM）in treating esophageal cancer（EC）and provide medication references for the clinical application of TCM in EC treatment. Method： Relevant literature on TCM treatment of EC was retrieved from three major Chinese databases：China National Knowledge Infrastructure（CNKI），Wanfang Data，and VIP. Information about Chinese herbal medicines was entered into Excel to establish a prescription database for EC. The data were standardized，summarized，and subjected to frequency analysis，association rules，and cluster analysis of medication in the prescriptions. Based on the TCM classification of EC syndromes， clinical indications corresponding to each syndrome were identified，and high-frequency drugs and drug pairs were analyzed correspondingly with syndromes. Result：A total of 136 prescriptions containing 240 Chinese herbal medicines were screened，with a cumulative frequency of 1 853 times. The top 5 frequently used Chinese herbal medicines were Glycyrrhizae Radix et Rhizoma，Poria，Atractylodis Macrocephalae Rhizoma，Astragali Radix，and Pinelliae Rhizoma. In terms of functions，the Chinese herbal medicines were mainly deficiency-tonifying，urination-promoting and dampness-draining，deficiency-tonifying，deficiency-tonifying，and phlegm-resolving and cough and dyspnea-relieving ones. The statistical analysis of flavor，property，and meridian tropism showed that Chinese herbal medicines were mainly bitter and sweet，warm，cold，and neutral，and acted on the spleen，lung，and stomach meridians. Association rule analysis yielded nine potential drug combinations，and cluster analysis of high-frequency drugs resulted in four combination categories. The four TCM syndromes for EC corresponded to respective clinical indications， treatment drugs， and drug pairs. Conclusion： Tonifying deficiency，reinforcing healthy Qi，descending adverse Qi，resolving phlegm，activating blood，and resolving stasis are the basic principles of TCM treatment for EC，which are supplemented by clearing heat and dissipating mass while focusing on regulating and smoothing the qi movement. The drug combinations obtained from high-frequency drug and association rule analysis provide references for different TCM syndrome treatments of EC，offering valuable insights for clinical medication. © 2023 Chinese Journal of Endocrine Surgery. All rights reserved.,TextMining
"Support vector machine (SVM) is a machine learning algorithm based on statistics theory. It has advantages in solving problems of high dimension, local extreme value and structure selection, and is widely used in data mining. However, the choice of kernel width and penalty factor is directly related to the classification result of SVM. To solve the above problems, the optimization algorithm can be adopted to optimize the parameters, so as to improve the classification accuracy of support vector machine. Chicken flock optimization algorithm is a new global optimization algorithm proposed in recent years. It has the advantages of clear structure and excellent global search ability, and has been widely used in optimization problems. Based on this, a fault diagnosis method based on the support vector machine model of chicken flock optimization was proposed and applied in the field of bearing fault diagnosis. The results show that the accuracy of bearing health status assessment based on CSO-SVM reaches 97.5%, which is obviously better than that based on traditional machine learning model, and has better fault diagnosis and recognition effect.  © 2023 IEEE.",TextMining
"In gas condensate reservoirs, the dew point pressure (PDew) plays a significant role in gas and liquid assessment, reservoir characterisation, surface facility design, and reservoir simulation. Although field and laboratory measurements of PDew give accurate results, both approaches are time-consuming and resource-intensive; hence, a fast and accurate determination of PDew is very important. Equation of states (EoS) and empirical correlations are other alternative methods that are used for PDew determination. However, these methods are unable to fully capture the non-linear and complex relationships between fluid composition and PDew. Machine Learning (ML) methods, as reliable tools, have emerged in different aspects of engineering. In this study, for the first time, the application of different decision tree-based methods for the prediction of PDew is investigated. A comprehensive database, containing 681 samples (almost all the available experimental data set of pure and impure samples published from 1942 to 2018), is collected from open literature and different decision tree-based methods namely Decision Tree (DT), Random Forest (RF), Gradient Boosting (GB), and Extremely Randomised Tree (ET) are used for modelling. The statistical analysis of developed models' performance showed that the ET method yields the best predictions by Root Mean Squared Error (RMSE) and R 2 values of 441 psi and 0.9227, respectively for the testing dataset. Moreover, the results show that the novel ET model has a better performance compared with existing models in the literature and EoSs for the prediction of PDew of gas condensate reservoirs. © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",TextMining
"Predicting student performance stands as a critical task to comprehensively assess their academic achievements, whether they classified as the category of good, sufficient, or bad. The outcome of a student's final exam can be influenced by a multitude of factors, among which the quality of the learning process and teaching methodology hold considerable significance. Recognizing the intricate interplay of these factors, it becomes evident that the integration of a satisfaction survey becomes imperative. In the realm of this research, we harness the potential embedded within both student satisfaction survey data and their ultimate academic grades. Overcoming existing challenges by an imbalanced dataset, we employ a holistic approach by utilizing the Support Vector Machine - Synthetic Minority Oversampling Technique (SVM-SMOTE) to rectify the skewed distribution of data. To further enhance prediction capabilities, we introduced an innovative technique known as Deep Feature Synthesis. This advanced approach generating 36 novel features. The culmination of our research underscores the superiority of the random forest algorithm, especially when enriched by the harmonious merging of Deep Feature Synthesis and SVM-SMOTE through the strategic implementation of Random Search. Notably, our model achieves an impressive accuracy rate of 69%, complemented by 47% precision, 52% recall, and 47% F1-score. copy; 2023 IEEE. © 2023 IEEE.",TextMining
"To study the impact of port changes on the urban functional structure and reveal the interactive relationship between ports and cities, a functional sequence extraction model (FSEM) is constructed in this study. The model employs a fan-shaped sampling method to divide experimental areas, extracts the functional zone sequence from sea to land along each sample line to establish the sample data set and mines the optimal functional sequence in each experimental area through association rules. Qingdao Port, Johor Port, and Manila Port are selected as experimental areas to verify the model, and the random forest (RF) model is adopted to identify the urban functional zones during different periods. The results indicate that the development of ports has a profound impact on the spatial configuration and structure of functional zones from sea to land. This method is conducive to solving the technical problems associated with the spatial and interactive development of port cities and provides a model reference for studies of the spatial correlation in other regions. Only by overall control and planning, overall coordination of the distribution of various functional areas, and reasonable spatial layout will the development of ports and cities be sustainable. © 2023 The Society of Urban Technology.",TextMining
"Objective To obtain the core prescription and herb pairs of Chinese medicine in the treatment of type 2 diabetes mellitus with hyperlipidemia, by using data mining, network pharmacology, and molecular docking technology, which further helps explore the potential molecular mechanism. Method This research was built on the retrieval from database like CNKI, Wanfang, VIP, Web of Science and PubMed. Data mining, operated on R Studio, provided the foundation of the core prescription. Then the active ingredients and potential targets were collected from TCMSP, UniProt, and Swiss Target Prediction databases and disease targets from OMIM, Therapeutic Target Database. The network of the ingredient-target of the compound and protein-protein interaction (PPI) of intersection targets between disease and ingredients were constituted via Cytoscape 3.8.1. The core targets extracted from the PPI network were imported into the Metascape website to perform gene ontology (GO) function annotation and Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway enrichment analysis. In the end, the core ingredients and targes were verified by molecular docking seriatim. Results 256 prescriptions consisting of 236 herbs were founded in total. Based on data mining, the core prescription of eight Chinese materia medica (Salviae Miltiorrhizae Radix et Rhizoma, Astragali Radix, Poria, Alismatis Rhizoma, Dioscoreae Rhizoma, Crataegi Fructus, Atractylodis Macrocephalae Rhizoma, Puerariae Lobatae Radix) and herb pairs such as the combination of Crataegi Fructus-Salviae Miltiorrhizae Radix et Rhizoma and Puerariae Lobatae Radix-Astragali Radix were acquired. Through comprehensive screening, 132 active ingredients (i. e., apigenin, luteolin, isorhamnetin, dan-shexinkum A, etc.) and 878 potential targets (i. e., RXRα, TP53, AKT1, CAV1, etc.) were got. The main signal paths include Lipid and atherosclerosis, Chemical carcinogenesis- receptor activation, Insulin resistance, PPAR signalling pathway, etc. The molecular docking results indicated the ideal affinity between the core ingredients and targets. Conclusion The core prescription combination of traditional Chinese medicine for treating type 2 diabetes with hyperlipidemia can be regulated by multiple active ingredients at multiple targets and pathways, which can provide reference ideas for clinical application and drug development. © 2023 Tianjin Press of Chinese Herbal Medicines.",TextMining
"This article gives a brief overview of various aspects of data mining of multispectral image data. We focus on specifically the remote sensing satellite images acquired using multispectral imaging (MSI), given the technology used across multiple knowledge domains, such as chemistry, medical imaging, remote sensing, and so on with a sufficient amount of variation. In this article, the different data mining processes are reviewed along with state-of-the-art methods and applications. To study data mining, it is important to know how the data are acquired and preprocessed. Hence, those topics are briefly covered in the article. The article concludes with applications demonstrating the knowledge discovery from data mining, modern challenges, and promising future directions for MSI data mining research. This article is categorized under: Application Areas > Science and Technology Fundamental Concepts of Data and Knowledge > Knowledge Representation Fundamental Concepts of Data and Knowledge > Big Data Mining. © 2023 Wiley Periodicals LLC.",TextMining
"The transcriptome, proteome, and metabolome are the flexible material basis for the stable plant genotypes to produce the dynamic phenotypes that change with the environment. The fitting of the transcriptome, proteome, and metabolome into metabolic pathways in plants commonly requires complex and ectopic biotechnology experiments. Spatial multiomics technology led by mass spectrometry imaging (MSI) can provide the most intuitive in situ evidence chain through the spatial association of related transcription factors, functional proteins, and metabolites in the pathway. This spatial evidence can be associated with space, time, plant morphology, tissues and organs, and provides the most direct physiological evidence for the dynamic relationship between plant phenotypic changes and their macromolecular or small molecule components. The instrumental basis of how MSI can achieve high-throughput in situ spatial metabolic data acquisition and the factors affecting imaging quality are introduced. The last 3–4 years of this spatial evidence reflecting specific plant molecular physiology applications, including the spatial biosynthesis pathway of plant natural products, the material exchange between plant roots and the external environment, the physiological resistance of plants under abiotic stress, the chemical defense of plants under biological stress, and the interaction between plants and microorganisms are summarized. Finally, the possibility of spatial multiomics combined with phenotypic techniques to achieve spatiotemporal consistency in genotype-transcriptome-proteome-metabolome-phenotype in future plant physiology studies are discussed and the difficulty of mining plant physiological information from spatial data is examined. © 2023, The Author(s), under exclusive licence to Springer Nature B.V.",TextMining
"Document clustering is an integral and important part of text mining. In case of classical clustering, data item belongs to only one cluster, whereas in Plithogenic approach to fuzzy clustering, data point may fall into more than one cluster. Thus, Plithogenic approach fuzzy clustering leads to wherein each data point is associated with more than one membership function that expresses the degree to which individual data points belong to the cluster. Additionally, his speeches at the UN will be analyzed with a neutrosphic approach. With the help of this approaches, in this study, speeches of the UN sessions attended by Turkish diplomats in the United Nations (UN) will be analyzed to understand the priorities of the country in international politics, the change and continuity in these policies. The texts of the UN sessions attended by Turkish diplomats between 2015 and 2023 were taken as data set. Such a large volume of data was analyzed with the help of text mining. For this purpose, each year's data was analyzed separately using word frequencies and clustering analysis, and then topic modeling was performed for each year's data using the Latent Dirichlet Allocation (LDA) method. © 2023, American Scientific Publishing Group (ASPG). All rights reserved.",TextMining
"This review article serves to highlight radiological services as a major cost driver for the healthcare sector, and the potential improvements in productivity and cost savings that can be generated by incorporating artificial intelligence (AI) into the radiology workflow, referencing Singapore healthcare as an example. More specifically, we will discuss the opportunities for AI in lowering healthcare costs and supporting transformational shifts in our care model in the following domains: predictive analytics for optimising throughput and appropriate referrals, computer vision for image enhancement (to increase scanner efficiency and decrease radiation exposure) and pattern recognition (to aid human interpretation and worklist prioritisation), natural language processing and large language models for optimising reports and text data-mining. In the context of preventive health, we will discuss how AI can support population level screening for major disease burdens through opportunistic screening and democratise expertise to increase access to radiological services in primary and community care. 2023 Sim, Bhanu Prakash, Huang and Tan.",TextMining
"One of the main challenges in data mining is choosing the optimal number of clusters without prior information. Notably, existing methods are usually in the philosophy of cluster validation and hence have underlying assumptions on data distribution, which prevents their application to complex data such as large-scale images and high-dimensional data from the real world. In this regard, we propose an approach named CNMBI. Leveraging the distribution information inherent in the data space, we map the target task as a dynamic comparison process between cluster centers regarding positional behavior, without relying on the complete clustering results and designing the complex validity index as before. Bipartite graph theory is then employed to efficiently model this process. Additionally, we find that different samples have different confidence levels and thereby actively remove low-confidence ones, which is, for the first time to our knowledge, considered in cluster number determination. CNMBI is robust and allows for more flexibility in the dimension and shape of the target data (e.g., CIFAR-10 and STL-10). Extensive comparisof-the-art competitors on various challenging datasets demonstrate the superiority of our method. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"With the progress of society and the development of science and technology, data has become an indispensable part of human life. Nowadays, people are increasingly inseparable from electronic devices such as mobile phones and computers in their daily lives. With the increase of data, how to mine valuable data is a problem that every enterprise and organization must face. Machine learning is an important technology of data mining, which can process a large number of data and automatically discover the hidden rules and knowledge. In this context, people gradually began to try to apply machine learning technology to data analysis, which made it possible to mine valuable data and brought great benefits to enterprises and organizations. In enterprises, machine learning can be used not only for the classification and prediction of goods in the commercial field, but also for the prediction of markets and customers, helping enterprises to make scientific decisions. Machine learning is an intelligent technology, which uses algorithms and models to learn and analyze data, so as to discover the laws of things and improve work efficiency. The application of machine learning technology in data mining can help enterprises acquire more valuable information and knowledge. For enterprises, the application of machine learning technology to data analysis can not only bring huge benefits to enterprises, but also help enterprises save resources such as manpower and material resources.  © 2023 IEEE.",TextMining
"Knowledge tracing aims to diagnose the student’s knowledge status and predict the responses to the next questions, which is a critical task in personalized learning. The existing studies consider more academic features, while this paper introduces DKCT, a deep knowledge tracing model with concept trees, to integrate the hierarchical concept tree that describes the structure of concepts in a question. DKCT casts the knowledge concept tree (KCT) in a question from the views of feature, breadth, and difficulty into a KCT representation at first. Then, DKCT is composed of an encoder network with multi-head attention on the question representations and a decoder network with multi-head attention on the interaction embeddings. Finally, DKCT integrates the student embeddings by using fully connected networks to predict the responses to the next questions. Extensive experiments conducted on two real-world educational datasets show that DKCT has a higher prediction accuracy than the currently popular KT models. This work paves the way to consider KCT for knowledge tracing. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"Reversible data hiding in encrypted images (RDH-EI) can simultaneously protect secret data and the content of transmission carriers, so it has important applications in cloud computing, medicine, and other fields involving data privacy. Aiming at the problem of low embedding capacity in current RDH-EI algorithms, a separate algorithm based on interpolation prediction error quantization is proposed. First, we down-sample the cover image to obtain the sampled pixels. Then interpolate and predict non-sampled pixels to obtain auxiliary data such as prediction errors and classify the auxiliary data. By introducing a quantitative prediction error loss factor, auxiliary data can be compressed to various degrees, reducing the amount of auxiliary data. Next, auxiliary data is embedded into sampled pixels through reversible data hiding (RDH) technology, and the partial of non-sampled pixels. Finally, according to the hiding key, the mark data and secret data are embedded in the encrypted image. At the receiver, a legitimate user extracts secret data and recovers the cover image with owned keys. Experimental results show that the proposed algorithm can ensure the error-free extraction of secret data and provide lossy and lossless versions of the cover image. In lossy versions, the maximum embedding rate can be around 4bpp. Compared to other advanced algorithms, the proposed algorithm has the advantages of more flexibility, a high embedding rate, and recovery quality. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"The transition towards more sustainable practices requires companies to assess their impact on the social and ecological environment and establish new processes in complex inter-organisational systems. Process mining is a collection of data-driven techniques to visualise, analyse and improve business processes. Its potential to increase sustainable business processes has been acknowledged by academia and industry but not systematically reviewed. This work analyses process mining's application for sustainability by conducting two consecutive literature studies - the first on the broad domain of sustainability, and the second on the circular economy, a widely accepted approach for pursuing sustainability. Results show the potential of process mining for assessing and analysing sustainability in business processes, allowing for data-driven decision support and targeted improvement. They also show that process mining has yet to reach the sustainability domain. To enable collaboration between both communities, we present PM4S, a framework for applying process mining for sustainability.  © 2023 IEEE.",TextMining
"With the booming business scale of domestic telecom industry, its business order of magnitude presents exponential growth. Telecom operators put forward higher traffic forecasting requirements based on the rapid growth of network demand and increasingly complex network environment. The traditional single model network architecture is difficult to adapt to the current flexible network requirements and not able to extract the spatio-temporal correlations. In this paper, by integrating the Multi-scale convolutional and Multi-path residual block, integrating the Triple Direction Long Short Term Memory (MSMR-TriLSTM), This paper extracts the iterative features from the network traffic data set of a branch company of telecom, studies the time series prediction model in depth for the traffic data of telecom equipment and combines the clustering results of time series data, so as to realize the long-term prediction of complex traffic data. The experimental results of the proposed network model and algorithm show that, compared with the single model, the hybrid model has a significant advantage in predicting the long-term trend of server traffic. Analysis and comparison of experimental indicators show that Root Mean Square Error (RMSE), Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) both decreased and the Accuracy of the model was as high as 88%, which indicates that the model could extract the main features of the server traffic data and had the ability of accurate and stable long-term prediction.  © 2023 IEEE.",TextMining
"Power business data services explore the potential value of power data by analyzing and mining power big data to assist in the development of new power systems and smart grids. This paper looks into the potential of power data by exploring power business data services. To evaluate the service, we consider four aspects: service benefit, data quality, service quality, and data service performance. The DEMATEL-ISM method is used to simplify the indicator system. Additionally, the DEMATEL method is combined with the AHP and coefficient of variation methods to form a subjective-objective combination of weighting methods for determining the weights of the indicators. This method addresses the lack of objectivity in the weights caused by the interaction between indicators and the overlap of meanings. The proposed method is validated through examples to show its feasibility and validity.  © 2023 IEEE.",TextMining
"Graphical representations such as chart images are integral to web pages and documents. Automating data extraction from charts is possible by reverse-engineering the visualization pipeline. This study proposes a framework that automates data extraction from bar charts and integrates it with question-answering. The framework employs an object detector to recognize visual cues in the image, followed by text recognition. Mask-RCNN for plot element detection achieves a mean average precision of 95.04% at a threshold of 0.5 which decreases as the Intersection over Union (IoU) threshold increases. A contour approximation-based approach is proposed for extracting the bar coordinates, even at a higher IoU of 0.9. The textual and visual cues are associated with the legend text and preview, and the chart data is finally extracted in tabular format. We introduce an extension to the TAPAS model, called TAPAS++, by incorporating new operations and table question answering is done using TAPAS++ model. The chart summary or description is also produced in an audio format. In the future, this approach could be expanded to enable interactive question answering on charts by accepting audio inquiries from individuals with visual impairments and do more complex reasoning using Large Language Models.  © 2020 IEEE.",TextMining
"The discovery of frequent generators of high utility itemsets (FGHUIs) holds great importance as they provide concise representations of frequent high utility itemsets (FHUIs). FGHUIs are crucial for generating nonredundant high utility association rules, which are highly valuable for decision-makers. However, mining FGHUIs poses challenges in terms of scalability, memory usage, and runtime, especially when dealing with dense and large datasets. To overcome these challenges, this paper proposes an efficient approach for mining FGHUIs using a novel lower bound called lbu on the utility. The approach includes effective pruning strategies that eliminate non-generator high utility branches early in the prefix search tree based on lbu, resulting in faster execution and reduced memory usage. Furthermore, the paper introduces a novel algorithm, MFG-HUI, which efficiently discovers FGHUIs. Experimental results demonstrate that the proposed algorithm outperforms state-of-the-art approaches in terms of efficiency and effectiveness. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"This paper introduces a supply chain quality sustainability decision support system (QSDSS). It uses association rule techniques to provide better logistics plans and handle risk in the supply chain. An improved Multiobjective Crystal Structure Algorithm using centroid opposition based learning and gaussian perturbation is proposed to avoid premature convergence and escape from local optimal. The experimental study is carried out in two phases, using two classic benchmark suites and the 'DataCo SMART SUPPLY CHAIN' dataset for big data analysis.  © 2023 IEEE.",TextMining
"Aircraft components are subject to numerous, complex and often manual maintenance, repair and overhaul (MRO) procedures to ensure long operating cycles. In order to remain competitive in the long term, in spite of increased cost pressure, MRO service providers must improve the efficiency of their processes through the targeted use of internal knowledge sources. Techniques from the fields of Artificial Intelligence (AI) and Data Mining (DM) have already proven their potential in diverse domains. However, the application of such data-driven approaches is also associated with some hurdles that need to be eliminated in advance. Data are generated at the business process level, known as Information Technology (IT, e.g. Enterprise Resource Planning (ERP) systems), as well as at the equipment level, known as Operational Technology (OT, e.g. test equipment). The integration of both forms the basis for improving the maintenance activities of diagnostics and maintenance scheduling. However, creating a unified view and understanding of the manifold data related to the maintenance process is a major problem due to the heterogeneous data sources and formats included. In this context, the use of Semantic Technologies (ST) can be helpful to overcome these challenges and provide the foundation for improved data management. The objective of this contribution is to introduce an ontology that delineates fundamental domain concepts, facilitating the augmentation of maintenance process data for individual aircraft components with pertinent contextual information. The result is being applied within the scope of a proof of concept aimed at supporting the coherent digital services diagnostics and short-term maintenance planning. © 2023, The Author(s).",TextMining
"Emotion detection systems play a crucial role in enhancing human-computer interaction. Existing systems predominantly rely on machine learning techniques. This study introduces a novel emotion detection method that employs deep learning techniques to identify five basic human emotions and the pleasure dimensions (valence) associated with these emotions, using text and keystroke dynamics. To facilitate this, we develop a non-acted dataset, DEKT-345 × 2, which includes text and keystroke features. The dataset is created by inducing emotions in participants under controlled conditions. Deep learning models are subsequently employed to predict a person’s affective state using textual content. Semantic analysis of the text data is achieved by employing the global vector (Glove) representation of words. For both text and keystroke-based analysis, one-dimensional convolutional neural network (Conv1D), long short-term memory (LSTM), sandwich Conv1D, and sandwich LSTM models are employed. The robustness of our proposed method is assessed using the DEKT-345 × 2 dataset, which collects text and keystroke information from 69 participants. Through parameter tuning on training and validation data, we establish models that demonstrate superior performance compared to five related approaches and three machine learning classifiers. Our proposed framework achieves an accuracy of 88.57% using the LSTM model, 80% using the sandwich LSTM model, 71.42% using the Conv1D model, and 51.48% using the sandwich Conv1D model on text data across the five emotion classes. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Link prediction plays an important role in the research of complex networks. Its task is to predict missing links or possible new links in the future via existing information in the network. In recent years, many powerful link prediction algorithms have emerged, which have good results in prediction accuracy and interpretability. However, the existing research still cannot clearly point out the relationship between the characteristics of the network and the mechanism of link generation, and the predictability of complex networks with different features remains to be further analyzed. In view of this, this article proposes the corresponding link prediction indices Reg, DFPA and LW on regular network, scale-free network and small-world network respectively, and studies their prediction properties on these three network models. At the same time, we propose a parametric hybrid index HEM and compare the prediction accuracy of HEM and many similarity-based indices on real-world networks. The experimental results show that HEM performs better than other indices. In addition, we study the factors that play a major role in the prediction of HEM and analyze their relationship with the characteristics of real-world networks. The results show that the predictive properties of factors are closely related to the features of networks. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"Shared vocabularies facilitate data integration and application interoperability on the Semantic Web. An investigation of how vocabularies are practically used in open RDF data, particularly with the increasing number of RDF datasets registered in open data portals, is expected to provide a measurement for the adoption of shared vocabularies and an indicator of the state of the Semantic Web. To support this investigation, we constructed and published VOYAGE, a large collection of vocabulary usage in open RDF datasets. We built it by collecting 68,312 RDF datasets from 517 pay-level domains via 577 open data portals, and we extracted 50,976 vocabularies used in the data. We analyzed the extracted usage data and revealed the distributions of frequency and diversity in vocabulary usage. We particularly characterized the patterns of term co-occurrence, and leveraged them to cluster vocabularies and RDF datasets as a potential application of VOYAGE. Our data is available from Zenodo at https://zenodo.org/record/7902675. Our code is available from GitHub at https://github.com/nju-websoft/VOYAGE. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Multi-view clustering is a rapidly evolving research topic that exploits cross-view data obtained from different domains or modalities to describe the target object more comprehensively. Currently, many multi-view deep clustering algorithms are capable of extracting valuable information from miscellaneous multi-view data, thanks to their efficient learning from nonlinear data. However, no algorithm has extended fuzzy K-means (FKM) to simultaneously utilize deep networks for feature extraction and solve multi-view problems. This limitation hinders the performance of FKM and the scalability of practical applications. Therefore, we propose a novel deep multi-view fuzzy K-means with weight allocation and entropy regularization (DMFKM) algorithm for deep multi-view clustering. DMFKM flexibly integrates cross-view information by employing learnable view weights and utilizes a common membership matrix and centroid matrix for each view to capture consistent and complementary information, respectively. Additionally, DMFKM embeds deep networks, making it have a powerful and flexible learning capability of linear indivisible data, negotiating with the fuzzy clustering task and optimizing simultaneously. Finally, DMFKM applies an adaptive loss function to objectives with adaptive weights and entropy regularization to the membership matrix for enhancing the robustness of the model and avoid trivial solutions. We perform optimization of the model using an alternating optimization approach. Experimental results on several benchmark datasets demonstrate that DMFKM outperforms existing state-of-the-art clustering algorithms. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Ensuring the security of a network or system is crucial in today's digital age. One of the key measures to achieve this is intrusion detection, which involves identifying and stopping unauthorized access. With the increasing complexity of cyber threats, regular intrusion detection methods have been proven inadequate in providing robust security. Machine Learning (ML) algorithms have emerged as a reliable method to notice and prevent intrusion in real-time. Data mining techniques have been employed in intrusion detection systems (IDS) founded on ML to scrutinize network traffic and detect patterns and anomalies that may signify a possible threat. The data used in the model can be categorized into two types: labeled and unlabeled data. Labeled data is used to train the system to recognize known attacks, while unlabeled data is used to detect new and unknown attacks. There are several types of IDS that use ML algorithms. The proposed approach has several advantages over traditional rule-based IDS. This approach employs an ML technique that integrates various algorithms including Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (LR), and Decision Tree (DT). The proposed approach's comparative analysis will help provide a better intrusion detection method. It can provide a powerful tool for enhancing the safety of computer networks. By leveraging the power of ML algorithms, the proposed method can improve the accuracy and effectiveness of IDS and stay one step ahead of potential security threats. These algorithms can detect and prevent known and unknown attacks by utilizing labeled and unlabeled data. The comparative analysis of different ML approaches will provide valuable insights for developing robust IDS and better safeguarding our digital assets in an increasingly complex threat landscape.  © 2023 IEEE.",TextMining
"The need for advanced knowledge exploration and discovery tools has become paramount in an age defined by an overwhelming influx of information and ever-increasing data complexity. This paper presents the SKATEBOARD system that is designed to bridge the gap in semantic knowledge exploration. As a holistic solution, SKATEBOARD transcends conventional tools by offering an unparalleled approach to semantic exploration, encompassing data extraction, domain-specific ontology creation, ontology management, and interactive exploration. Through intelligent knowledge extraction, ontology construction, and interactive exploration, it equips researchers and practitioners with the means to confidently traverse the complexities of their domains, make informed decisions, and unearth knowledge that exceeds initial expectations. © 2023 Copyright for this paper by its authors.",TextMining
"The internet has a significant impact on how businesses are conducted globally today, and the tourism industry is no exception. According to the Statista 2020 survey, there were 4.13 billion Internet users worldwide in 2019. Tourist satisfaction affects destination selection, consumption, return visits, and reputation. The sentiment analysis technique was applied to analyze the data qualitatively. The most significant factor about which the tourists seemed to care was cleanliness. Most tourists were overwhelmed by the sheer number of people at a location on any given day. Security was a significant factor that the tourists considered. Many tourists complained of pickpocketers while others clearly stated having their things stolen, including their wallets. The current study’s findings suggest that tourist guides, photographers, and management must properly serve tourists to create positive E-WOM. Future studies can be taken in different parts of the world to know the composition of tourist satisfaction traits. © 2024 selection and editorial matter, Philip Kotler, Subhadip Roy, Satyajit Chakrabarti, Dipak Saha and Rabin Mazumder; individual chapters, the contributors.",TextMining
"This paper presents a hybrid method for accurately predicting Global Horizontal Irradiance (GHI) over the following 24 hours to forecast energy production from a photo-voltaic system in a positive energy building. The input data is preprocessed using the Variational Mode Decomposition (VMD) method to extract wide-bandwidth features and decompose them into smooth modes focused on specific frequency ranges. The Salp Swarm Algorithm (SSA) is utilized to identify the optimal VMD parameters for accurate extraction. The data analysis is employed to identify the most critical modes of input features. The model's efficiency is further enhanced by performing a residual preprocessing step between the observed solar radiance data and the decomposed modes. The Stacking technique (ST) is employed to predict the 24-hour GHI modes and the residual, which are summed to reconstruct the final signal. The proposed method's performance is evaluated using the Normalized Root Mean Square Error (NRMSE) and Normalized Mean Absolute Error (NMAE) metrics on three years of available data (2019-2022) in Rabat, and compared with the model based on raw data. The results show that the proposed method achieved promising results with an NRMSE of 1.35% and NMAE of 0.82% on a cloudy day.  © 2023 IEEE.",TextMining
"Purpose: Drawing on the pleasure-arousal-dominance (PAD) emotion model, the emotional states of consumers embedded in online reviews can be described through three dimensions, that is, pleasure, arousal and dominance, rather than only the one-dimensional positive and negative polarity, as in previous studies. Therefore, this study aims to explore the effect of online review emotion on perceived review helpfulness based on these three basic emotional dimensions. Design/methodology/approach: A lexicon-based method is developed to analyze PAD emotions of online reviews from JD.com. The zero-inflated negative binomial regression is utilized to empirically validate the study hypothesis. The authors examine the influence of pleasure, arousal, dominance, emotion diversity and emotion deviation on review helpfulness, as well as the moderating effect of product type on the relationship between all independent variables and online review helpfulness. Findings: The study results show that the pleasure emotion impairs the helpfulness of online reviews, while the arousal and dominance emotions have a positive impact. Moreover, the authors find that compared with search products, the effects of pleasure, arousal and dominance on perceived helpfulness are strengthened for experience products. However, the emotional diversity and emotional deviation have opposite effects on the helpfulness of search products and experience products. Additionally, the results show that dominance emotion plays a more important role in the interaction effect. Originality/value: The empirical findings confirm the applicability of PAD in the online review context and extend the existing knowledge of the influence of review emotion on helpfulness. A feasible scheme for extracting PAD variables from Chinese text is developed. The study findings also have significant implications for reviewers, merchants and platform managers of e-commerce websites. © 2023, Emerald Publishing Limited.",TextMining
"With the development of information technology, the network black industry continues to expand, and cybercrime is becoming increasingly rampant. As a hotbed of crime, the darknet, with its anonymity, has also become a new front for online black market, bringing huge challenges to investigation and digital forensics. This article designs an automated darknet data crawling program that can achieve protocol conversion between darknet and surface networks, as well as data crawling of target sites on darknet. At the same time, the developed visualization program and data analysis program can achieve the display of target data in multiple dimensions. Combined with the periphery investigation technology to the website and social engineering, it can realize the mining of the criminal intelligence of the hidden network and provide reference for the investigation department.  © 2023 IEEE.",TextMining
"The heart, an essential organ of the body, pumps blood filled with oxygen to every area of the body through a complex network of veins and arteries. Any condition affecting the heart is referred to as heart disease. It is essential to start the right treatments early on in order to reduce the death toll. Predicting cardiac disease before heart attacks or strokes is therefore a significant challenge for the healthcare industry. This article introduces a methodology for predicting heart disease which consists of the three steps: (1) pre-processing, (2) feature extraction, and (3) disease prediction. Initially, the input data is pre-processed using improved data normalization. Next, the features are extracted from the normalized data; they are higher-order statistical features, information gain-based features, mutual information-based features, and improved entropy-based features. The results are then decided utilising an improved score-level fusion procedure, which is used to the suggested hybrid classification model that incorporates models like Deep Maxout and QNN algorithms. By adjusting the Deep Maxout and QNN classifiers' ideal weights, a self-improved Beluga whale optimisation is developed for optimal training to increase the performance of the hybrid model. When using dataset 1, the Hybrid + SI-BWO produced a precision of 94.25%, while CNN, DBN, Bi-LSTM, SVM, RNN, DL, and RF all produced precisions of 75.04%, 77.38%, 80.17%, and 86.52%, respectively. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Various office software based on cloud computing platforms have gradually become an important technical tool for scientific management, thus improving the quality and efficiency of enterprise management. These application systems generate a large amount of text data during operation and are stored in the relevant databases. Existing management systems can only perform simple queries on this data and are therefore un-able to carry out intelligent analysis of human behavioural characteristics. The intelligent management system needs to perform data mining on human behavioural characteristics, so as to uncover the hidden features of the massive data. To address the above prob-lems, an intelligent text mining and sentiment classification system based on K-means clustering analysis is constructed. First, the behavioural feature data of enterprise employees are pre-processed. Then, the K-means clustering algorithm is used to analyse the massive amount of historical data generated in the course of daily work in order to evaluate the employees. Secondly, an adaptive differential evolutionary algorithm based on dynamic subpopulation is proposed in order to overcome the shortcomings of the traditional K-means algorithm, and it is used to improve the K-means algorithm. Finally, the improved K-means algorithm was implemented in the Spark platform and the employee behavioural trait evaluation metrics were constructed. The experimental results show that the improved K-means algorithm effectively improves the clustering quality and convergence speed, thus effectively obtaining accurate and comprehensive employee sentiment assessment results. © 2023, Taiwan Ubiquitous Information CO LTD. All rights reserved.",TextMining
"Heterogeneous network link prediction is an important network information mining problem. Existing link prediction methods for heterogeneous networks typically require predefined meta-paths with prior knowledge. To address the problem, we propose a new model, named Heterogeneous Line Graph Neural Network (HLGNN), in this paper. Firstly, we design a line graph transformation module to encapsulate node features and transform the heterogeneous network into a heterogeneous line graph. Then, we propose an intra-type aggregation component to collect the same type of edges. As we have aggregated node information in each type, we design an inter-layer aggregation to combine messages from multiple node types. Finally, we put the aggregation results into a multilayer perceptron to achieve link prediction. The experimental results show that, compared to the state-of-the-art baselines, the proposed method achieves superior performance. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Background: Myocardial infarction remains a disease with high morbidity and death rate among cardiovascular diseases. Macrophages are abundant immune cells in the heart. Under different stimulatory factors, macrophages can differentiate into different phenotypes and play a dual pro-inflammatory and anti-inflammatory role. Therefore, a potential strategy for the treatment of myocardial infarction is to regulate the energy metabolism of macrophages and thereby regulate the polarization of macrophages. Tan IIA is an effective liposolubility component extracted from the root of Salvia miltiorrhiza and plays an important role in the treatment of cardiovascular diseases. On this basis, this study proposed whether Tan IIA could affect phenotype changes by regulating energy metabolism of macrophages, and thus exert its potential in the treatment of MI. Methods: Establishing a myocardial infarction model, Tan IIA was given for 3 days and 7 days for intervention. Cardiac function was detected by echocardiography, and cardiac pathological sections of each group were stained with HE and Masson to observe the inflammatory cell infiltration and fibrosis area after administration. The expression and secretion of inflammatory factors in heart tissue and serum of each group, as well as the proportion of macrophages at the myocardial infarction site, were detected using RT-PCR, ELISA, and immunofluorescence. The mitochondrial function of macrophages was evaluated using JC-1, calcium ion concentration detection, reactive oxygen species detection, and mitochondrial electron microscopic analysis. Mechanically, single-cell transcriptome data mining, cell transcriptome sequencing, and molecular docking technology were used to anchor the target of Tan IIA and enrich the pathways to explore the mechanism of Tan IIA regulating macrophage energy metabolism and phenotype. The target of Tan IIA was further determined by gene knockdown and overexpression assay. Results: The intervention of Tan IIA can improve the cardiac function, inflammatory cell infiltration and fibrosis after MI, reduce the expression of inflammatory factors in the heart, enhance the secretion of anti-inflammatory factors, increase the proportion of M2-type macrophages, reduce the proportion of M1-type macrophages, and promote tissue repair, suggesting that Tan IIA has pharmacological effects in the treatment of MI. In terms of mechanism, RNA-seq results suggest that the phenotype of macrophages is strongly correlated with energy metabolism, and Tan IIA can regulate the PGK1-PDHK1 signaling pathway, change the energy metabolism mode of macrophages, and then affect its phenotype. Conclusion: Tan IIA regulates the energy metabolism of macrophages and changes its phenotype through the PGK1-PDHK1 signaling pathway, thus playing a role in improving MI. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Recently, the gut microbiota-based live biotherapeutics (LBPs) development, the interaction between gut microbial species and the host, and the mining of new antimicrobial peptides, enzymes and metabolic pathway have received increasing attention. Culturing gut microbial species is therefore of great importance. This review systemically compared the construction advances of gut microbial culture banks and also analyzed the differences of methods used by research groups to give insight into the construction and enrichment of gut microbial resources. Presently, the gut microbial culture banks have included more than 1 000 bacterial species, belonging to 12 phyla, 22 classes, 39 orders, 96 families, and 358 genera. Among these, Firmicutes, Proteobacteria, Bacteroidota, and Actinomycetota exhibited the greatest diversities at the species level. The sequencing data showed that there are more than 2 000 species inhibited in the human gut. Therefore, the cultured gut microbial species are far from saturation. In terms of the construction method, the stool samples were pre-treated with ethanol or directly spread and cultured in the non-selective nutritional rich medium (represented by Gifu anaerobic medium) to obtain single colony. Then single colony was further purified. Generally, a simplified isolation and culture method is sufficient to obtain the most common and important intestinal bacterial species, such as Bifidobacteria-Lactobacillus, Akkermansia muciniphila, Faecalibacterium prausnitzii, Prevotella and S24-7 family strains. Finally, microbial resources with great diversities at the strain level are required for further functional research and product development. Samples covering hosts with distinct physiological status, diets or regions are necessary. ©2023 Chin J Biotech, All rights reserved.",TextMining
"Disputes are common and widespread in subcontracting practices and would ultimately lead to litigation resulting in significant negative consequences including delay, increased cost, and tarnished reputation of contracting parties. Although considerable studies have analyzed disputes in construction projects, research efforts still fall short in investigating causes of disputes in subcontracting practices. To bridge the knowledge gap, this paper investigated the causes of disputes in subcontracting practices by automatically examining 3150 litigation cases that are publicly available in China using text mining and NLP (natural language processing) techniques. Documents of litigation cases were presented into vectors by data preprocessing and vector presentation. Clustering analysis of the data was conducted by using an improved K-Means model, K-Means++. Finally, 37 causes of disputes were discovered in the subcontracting litigation cases. Results showed that variations due to unforeseen circumstances, labor service issues from subcontractors, disagreement on engineering quantities between subcontractors and other contracting parties, invalid signature of subcontractors for obtaining more payment, payment issues between subcontractors and clients or general contractors, contradictory on the return of performance bond, disagreement on the interest of late payment, and arrears issues suffered by subcontractors were the top eight significant causes of disputes in subcontracting practices in China. This study contributes by systematically exploring the causes of disputes in subcontracting practices using automated text analysis approaches instead of manual content analysis. The findings of this study can provide construction practitioners a deeper understanding of disputes in subcontracting and thereby helping them increase their capacity to handle disputes. © 2023 Informa UK Limited, trading as Taylor & Francis Group.",TextMining
"Chemical exposure known as chemical hazards and toxic substances (CHTS), which occur through inhalation, ingestion, and skin contact, causes serious illness, irritation, corrosion, injury, and even death. The chemicals analyzed are limited to the reagents used in the mineral ore production process, in addition to dermal exposure. Data on hazard identification and exposure evaluation were collected. The utilization of CHTS will continue to increase in the coming years, thereby leading to health impacts on work-ers. Global data released by ILO showed a 270 million (62.8%) and 160 million (37.2%) rise in work accidents and illnesses, culminating in 430 million per year. Data on the number of workers who received benefits from the Work Accident Insurance program of the National Social Security Agency for Employment (known as BPJSTK), showed that 210,789 people (4,007 fatal) 221,740 people (3,410 fatal), and 234,370 people (6,552 fatal) experienced work-related accidents and illnesses in Indonesia. Therefore, this qualitative study aims to examine and analyze the health risks of mining workers exposed to CHTS through inhalation-using the observation method. The Chemical Health Risk Assessment (CHRA) method issued by the Malaysian Department of Safety and Health in 2018 was used to assess the inhalation exposure rate. The analyzed chemicals were limited to reagents used in production with data collected through the semi-quantitative method. The results showed that the inhalation exposure risk level is categorized as moderate and capable of causing health defects related to acute toxicity and specific target organ toxicity-single exposure (STOT-SE). Furthermore, 4 (four) out of 6 (six) reagents were identified as having significant inhalation exposure risk, hence, controls related to Occupational Health and Safety (OHS) in the mineral ore processing process must be in-creased. © 2023, Universitas Negeri Semarang. All rights reserved.",TextMining
"Acquiring innovative styles and compositions from intricate and heterogeneous artistic imagery has emerged as a pivotal research quandry within contemporary new media art image conception. In a concerted effort to adeptly distill the quintessence of artistic styles and elements embedded within these visuals, an innovative methodology is posited herein, underpinned by an enhanced U-net segmentation framework and harmoniously fused with the surface extraction image reconstruction algorithm. This meticulous amalgamation endeavors to attain accurate segmentation and tridimensional reconstruction of the artistry encapsulated in these images. Primarily, the imagery is meticulously partitioned, culminating in an output that artfully encapsulates the inherent artistic attributes. Subsequently, this segmentation outcome is adeptly reconstituted, bestowing form to a three-dimensional artistry model. Empirical validation substantiates the efficacy of this approach, with the method’s Mean Intersection over the Union (MIoU) parameter yielding an impressive score of 0.939 in segmentation performance. Moreover, the peak signal-to-noise ratio and structural similarity attain commendable zeniths of 38.16 and 0.9808, respectively, underscoring the excellence of the reconstruction process. The proposed methodology demonstrates its prowess in exacting segmentation and comprehensive reconstruction of semantic intricacies and nuanced features pervading the realm of artistic imagery. Consequently, this novel methodology augments artists’ capacity to discern diverse artistic paradigms and fabricate superlative new media art compositions of heightened caliber. © 2023 Wang Distributed under Creative Commons CC-BY 4.0. All Rights Reserved.",TextMining
"Soil features are important in agricultural production because they allow crops to develop more efficiently through root feeding while using less energy. Data mining is a new area of study in crop production analysis. In the agriculture industry, yield prediction is crucial. Crop fertility and crop output rise when fertiliser application, growth, and root growth rate are stable. Farmers must be equipped with technology in order to make the greatest use of the farm's limited resources. Analyse the different associated parameters such as location, alkalinity and pH value of the soil. Furthermore, third-party apps such as APIs for temperature and weather, nutrient value and type of soil in that place, soil composition, quantity of rainfall in that region are used to compute percentages of nutrients such as nitrogen (N), phosphorus (P), and potassium (K). All of these data properties will be examined, and the data will be processed using a variety of machine learning approaches to build a classification model. In a changing climate, the technique can help determine the best place to study crop adaptation under certain nutrient supply as well as provide insight into nutrient appropriate evaluations for specific crops. © 2023 Trans Tech Publications Ltd, Switzerland.",TextMining
"Purpose: The extant literature underlines the inadequacies of legal and policy frameworks addressing the safety and health concerns of sandstone mineworkers in India. Notably, Rajasthan, a state renowned for its extractive industries, mirrors these concerns. Against this backdrop, this paper aims to critically evaluate the relevant legal and policy landscape, with an emphasis on the recent central statute: the Occupational Safety, Health and Working Conditions Code of 2020 (OSHWCC). Given that the Code subsumes the key legislation pertaining to the safety and health of mineworkers, an in-depth critical analysis is essential to forge suitable policy interventions to address continued gross violations of human rights. Design/methodology/approach: The critical analysis of legal and policy frameworks on silicosis in sandstone mineworkers is based on a comprehensive reading of existing literature. The literature includes relevant laws, case law, reports of the Rajasthan State Human Rights Commission and National Human Rights Commission, publicly available data and key scholarly contributions in the field. Findings: Although the OSHWCC has made some changes to the existing regulatory architecture of mines in India, it has failed to safeguard the safety and health of mineworkers. Notably, the vast majority of mines in India – constituting approximately 90%, which are informal, seasonal and small-scale – remain beyond the jurisdiction of this Code. In Rajasthan, there are specific policies on silicosis, but these policies are poorly implemented. There is a serious shortage of doctors to diagnose silicosis cases, leading to under-diagnosis. The compensation for silicosis victims is insufficient; the distribution mechanism is complex and often delayed. Research limitations/implications: The central and many state governments have not established the regulatory institutions envisaged under the OSHWCC 2020; therefore, the working of the regulatory institutions could not be critically examined. Originality/value: The paper critically evaluates laws and policies pertaining to silicosis in sandstone mineworkers, with a special emphasis on the state of Rajasthan. It offers a comprehensive critique of the OSHWCC of 2020, which has not received much attention from previous studies. © 2023, Emerald Publishing Limited.",TextMining
"Keyword extraction for traditional Chinese medicine (TCM) constitution identification refers to using keyword extraction methods to extract critical symptoms from task corpora to achieve the TCM constitution identification task. In this paper, we constructed a dataset for keyword extraction in TCM constitution identification and implemented keyword extraction using sequence labeling methods. However, we discovered an issue of uneven category distribution during the keyword extraction process, which affected the model's performance. To address this problem, we propose a model training method based on batch data hybrid sampling algorithm. This method divides the training dataset into several batches. It strategically balances the ratio of common and rare category data within each batch, achieving an even distribution of data categories within each training batch and reducing the impact of insufficient learning on rare categories by the model. Experimental results demonstrate that our proposed method improves the performance of keyword extraction for TCM constitution identification, with an average F1 score improvement of 4.29% for rare category keyword extraction.  © 2023 IEEE.",TextMining
"The autonomous underwater vehicle (AUV) frequently operates in harsh underwater environments, and timely fault diagnosis of the AUV can prevent mission failure and equipment loss. Data-driven methods based on a single data source have been widely utilized for fault diagnosis of the AUV because they do not require the construction of complex mechanism models and have high fault diagnosis accuracy. However, these methods face challenges in accomplishing complex fault diagnosis tasks because the single data source provides very restricted fault features. To address this issue, an attention mechanism-based multisensor data fusion neural network (MDFNN) for AUV fault diagnosis is proposed in this work. First, a feature extraction layer based on the two-dimensional (2D) convolutional method with a 1D kernel is introduced to extract features from each sensor data separately, significantly optimizing the model architecture. Second, an efficient channel attention mechanism-based feature fusion layer is proposed to reassign weights to the features of each sensor data, enabling the model to focus more on crucial features. Finally, the fused features are input to the fully connected layers and softmax layer to realize the fault diagnosis of multisensor data. In the end, the diagnostic performance of the proposed MDFNN is evaluated utilizing real AUV experimental data. The experiment shows that the proposed MDFNN has a very fast convergence speed and 98.37% fault diagnosis accuracy, demonstrating its excellent fault diagnosis performance. The proposed MDFNN provides a generalized and simply structured fault diagnosis framework for the AUV with multiple types of sensor data, providing significant engineering value. © 2023 Wiley Periodicals LLC.",TextMining
"The rapid growth of both the financial industry and digital technologies in Indonesia has been promoting market competition among commercial banks. In this paper, we aim to examine smart digital marketing in social media and obtain market insight by investigating online social media data, particularly the Twitter platform. The 7P marketing mix-Product, People, Process, Place, Physical Environment, Promotion, and Prices-is used to assess customer perception. The descriptive quantitative and exploratory statistics approach was used to compare the most prominent conventional and sharia banks in Indonesia: Bank Central Asia (BCA) and Bank Syariah Indonesia (BSI). First, an analysis of sentiment and opinion mining are conducted, and then further statistical evaluation is used to confirm the findings. Our results suggest an extremely imbalanced marketing element that focuses solely on the Process element, 65% and 51% in BCA and BSI respectively, and left other marketing elements insufficiently managed and optimized. Therefore, the banking industry should maximize the opportunity for effective marketing of comprehensive marketing elements to win the competition. © 2023 IEEE.",TextMining
"Latest scientific evidence for healthcare decisions are applied by doctors and patients jointly through decision support tools. As it is already known, anomaly detection in time series is an important data mining task for discovering unusual patterns in time series data. For instance, in the medical domain, early and precise detection of types of heart arrhythmia is important to help in making decision, detect heart disease and choose an appropriate treatment using the electrocardiogram (ECG) as a tool. The present work aims to provide a review of tools and methods in detection anomalies. The study shows that, globally speaking, the main approaches for that purpose are ECG signal processing tools, statistical and mathematical tools, pattern recognition tools and artificial intelligence algorithms.  © 2023 IEEE.",TextMining
"Currently, most research focuses on users' behavioral preferences while ignoring the impact of food properties on human health. This article extracts a large amount of knowledge about the relationship between food properties and human health from multiple heterogeneous data sources. Based on this, a knowledge graph in the field of food is constructed for special populations to help them plan their diet more reasonably and reduce the risk of common diseases. Using background data sources such as Baidu Baike and Wikipedia, the BERT-BiLSTM-MHA-CRF method is proposed to extract food-related attributes from more than 14,731 descriptions of food properties. Combined with the differentiated features of special populations, a knowledge graph in the field of food is constructed. The knowledge graph mainly includes six entity types: food nutrition, efficacy and function, food name, population, dish name, and seasoning, with a total of 11,218 entities and 96,186 relationships. The experiment shows that compared with traditional static word vector models, BERT can generate dynamic word vectors based on context in large-scale corpus, making semantic encoding more accurate. The multi-head self-attention mechanism weights various entities in the food domain to reduce the interference of invalid information, making the model more accurate in capturing entity features. The BERT-BiLSTM-MHA-CRF method proposed in this article achieves P, R, and F1 greater than 90%.  © 2023 IEEE.",TextMining
"The large language model ChatGPT developed by the American artificial intelligence company OpenAI has quickly become a hot topic in the global media as soon as it is launched. The “Pseudo-Environment” and “discourse field” formed by these media reports have profound implications for governments, industries, and the public. By exploring the core issues and key debates in media coverage of ChatGPT, it is possible to effectively map media attitudes, industry perceptions, and public sentiment. In this study, text mining methods such as sentiment analysis and Latent Dirichlet Allocation (LDA) topic modeling were employed to analyze 2,829 valid news data obtained from the LexisNexis news database. The research results reveal that the news coverage of ChatGPT primarily involves areas such as technological development, functional applications, and social impact. Sentiment analysis indicates that the media generally hold a positive attitude towards ChatGPT, albeit with some negative evaluations. Topic mining results demonstrate that the core issues and key debates include “new challenges of intelligent automation for human labor,” “novel human-machine collaboration paradigms,” “a new milestone in artificial intelligence,” and “new tests for AI ethics and societal issues.“ © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Audio event detection is a widely studied field, with applications ranging from self-driving cars to healthcare. In-the-wild datasets such as Audioset have propelled research in this field. However, many efforts typically involve manual annotation and verification, which is expensive to perform at scale. Movies depict various real-life and fictional scenarios which makes them a rich resource for mining a wide range of audio events. In this work, we present a dataset of audio events called Subtitle-Aligned Movie Sounds (SAM-S). We use publicly available closed-caption transcripts to automatically mine over 110K audio events from 430 movies. We identify three dimensions to categorize audio events: sound, source, quality, and present the steps involved to produce a final taxonomy of 245 sounds. We discuss the choices involved in generating the taxonomy, and also highlight the human-centered nature of sounds in our dataset. We establish a baseline performance for audio-only sound classification of 34.76% mean average precision, and show that incorporating visual information can further improve the performance by 5%. Data and code are made available for research at https://github.com/usc-sail/mica-subtitle-aligned-movie-sounds © 2023 IEEE.",TextMining
"Neuropsychiatric Symptoms (NPS) are often manifested in People Living with Dementia (PwD), with agitation being one of the most common symptoms. Agitated behavior in PwD causes distress and raises the risk of injury to patients and caregivers. Therefore, detecting agitation events is essential for the safety of PwD and the people around them. AI-powered tools can monitor agitation behavior, alert care providers to instances of agitation, and help them respond quickly and effectively to improve the quality of life for PwD. Furthermore, research shows that selecting the proper set of features significantly affects the outcomes of a machine learning model and performance. This work investigates using a new set of features with various machine learning models to detect individual patterns of NPS. These features are extracted from sensor data collected by multi-modal wearable devices from 17 PwDs admitted to a specialized Dementia Unit in Canada. Several machine learning models are trained using these features, and our findings show that Extra Trees achieves higher performance with the new feature set compared to the state-of-the-art feature set known to date. Performance evaluation shows that the new models successfully classified behavioral symptoms from personalized models with a median AUC of 0.941. © 2023 IEEE.",TextMining
"Ground Penetrating Radar (GPR) is a non-destructive geophysical technique that has been in use at Saskatchewan potash mines for over four decades. The GPR system is an innovative technology used in imaging salt beds above or below a mined room. The borer mounted GPR application has proven to be a reliable tool for mapping the roof beam thickness which is normally a meter from the mine roof to the immediate clay seam above. Utilizing an automated picking algorithm, real-time data interpretation is provided to borer operators to make informed safety decisions. Hence, it's important that an auto-picking algorithm is adequately tuned to declutter noise and identify geologic features seen within the mine roof.This paper presents a series of studies aimed at understanding and improving data interpretation of the GPR during active mining as geologic variations within the mine roof can lead to GPR data degradation. An approach to this challenge was to develop a robust and intelligent auto-picking algorithm called the Cluster Ratio Derivative (CRD) that utilizes a data reduction technique to improve the signal to noise ratio (SNR) and machine learning to pick the clay seam in the GPR data. Additional work was performed by developing numerical earth models of a potash mine using gprMax. The generated synthetic datasets, also served as testbed in developing the CRD algorithm.The success of this work has led to the implementation of the novel CRD auto-picking algorithm on borer GPR software. The goal is to continue to ensure that meaningful GPR interpretations are provided to operators during active mining. © 2023 IEEE.",TextMining
"Document-level relation extraction aims to identify the relations between the entities in an unstructured text and represents them in a structured way for downstream tasks such as knowledge graphs and question answering. In recent years, graph neural network-based methods have made significant progress in relation extraction. However, these methods usually require extracting all the entities in the document first, then a classifier is used to analyze the relations between the entities regardless of whether they have any relation. This wastes a lot of time analyzing the relations of irrelevant entity pairs and reduces the classifier’s attention to relevant entity pairs. To address this issue, this paper proposes a relation extraction module that integrates Relational Reasoning and Heterogeneous Graph neural Networks (RRHGN). The method finds a meta-path for each entity pair in a document and uses multi-hop reasoning to analyze the entities on the meta-path to determine whether there is a strong reasoning path between the entity pair. The relational reasoning module built into the method makes the classifier focus more on the relevant entity pairs in the document, thus reducing the task burden of the classifier and improving the accuracy of entity relation extraction. Experimental results on the large-scale document-level relation extraction dataset DocRED show that the proposed method achieves significant performance improvement compared with existing methods. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Argument mining is to analyze argument structure and extract important argument information from unstructured text. An argument mining system can help people automatically gain causal and logical information behind the text. As argumentative corpus gradually increases, like more people begin to argue and debate on social media, argument mining from them is becoming increasingly critical. However, argument mining is still a big challenge in natural language tasks due to its difficulty, and relative techniques are not mature. For example, research on non-tree argument mining needs to be done more. Most works just focus on extracting tree structure argument information. Moreover, current methods cannot accurately describe and capture argument relations and do not predict their types. In this paper, we propose a novel neural model called AutoAM to solve these problems. We first introduce the argument component attention mechanism in our model. It can capture the relevant information between argument components, so our model can better perform argument mining. Our model is a universal end-to-end framework, which can analyze argument structure without constraints like tree structure and complete three subtasks of argument mining in one model. The experiment results show that our model outperforms the existing works on several metrics in two public datasets. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"One of the major issues in Educational Artificial Intelligence is detecting university student dropouts. Student dropout prediction is a growing research area since dropouts have financial, social, and national consequences. To deal with this issue, we examined the performance of ten machine learning algorithms with different feature sets in predicting university student dropout. Used algorithms are: Decision Trees, K-Nearest Neighbors, Naïve Bayes, Logistic Regression, Stacking Classifier, Adaboost, XGBoost, Random Forest, Support Vector Machines, and Multi Layer Perceptrons. The Synthetic Minority Oversampling Technique (SMOTE) balancing algorithm is used in the training process, to balance training data since the used dataset has an imbalanced nature. On the student dataset from Tecnologico de Monterrey in Mexico, we obtained 92 % accuracy on the XGBoost algorithm with a sub-feature set. We showed that the selected data features are as important as the selected method. Considering different performance metrics other than accuracy for imbalanced data is important. Having economic and historical score data increases accuracy. We also have seen that XGBoost and Random Forrest algorithms were the best for this task. © 2023 IEEE.",TextMining
"A large amount of data is collected during geological hazard monitoring, which is extremely valuable for further data mining, hazard monitoring and decision analysis. However, in the process of data collection and transmission may be affected by interference and other factors, resulting in the generation of abnormal data. To extract higher value information from these basic data, it is necessary to improve the quality of source data first, so it is necessary to detect the abnormal data. The monitoring data of the geological disaster are time-series data, which have the characteristics of time-series correlation. The nearest neighbor difference jump anomaly detection algorithm is suitable for monitoring anomalous data of geological disaster system, but there are shortcomings in selecting floating values and correlation perception. To address these problems, the nearest neighbor difference jumping algorithm is improved and a algorithm is proposed to detect anomalous data of geological disasters, i.e., the data series are segmented by using sliding windows, the selection of floating values is improved, the calculation range of difference values is expanded to enhance the correlation of data, and the concept of change speed is incorporated to better perceive the trend of change before and after the data, and finally the anomaly is determined by using the anomaly probability and correlation. After the experimental comparison and analysis, the accuracy and recall rate of the proposed method on the detection of geological disaster data are improved and meet the expected results. © 2023 IEEE.",TextMining
"Background. Alzheimer’s disease (AD) is a disease that manifests itself with a deterioration in all mental activities, daily activities, and behaviors, especially memory, due to the constantly increasing damage to some parts of the brain as people age. Detecting AD at an early stage is a significant challenge. Various diagnostic devices are used to diagnose AD. Magnetic Resonance Images (MRI) devices are widely used to analyze and classify the stages of AD. However, the time-consuming process of recording the affected areas of the brain in the images obtained from these devices is another challenge. Therefore, conventional techniques cannot detect the early stage of AD. Methods. In this study, we proposed a deep learning model supported by a fusion loss model that includes fully connected layers and residual blocks to solve the abovementioned challenges. The proposed model has been trained and tested on the publicly available T1-weighted MRI-based KAGGLE dataset. Data augmentation techniques were used after various preliminary operations were applied to the data set. Results. The proposed model effectively classified four AD classes in the KAGGLE dataset. The proposed model reached the test accuracy of 0.973 in binary classification and 0.982 in multi-class classification thanks to experimental studies and provided a superior classification performance than other studies in the literature. The proposed method can be used online to detect AD and has the feature of a system that will help doctors in the decision-making process. © 2023 Alhudhaif and Polat Distributed under Creative Commons CC-BY 4.0. All Rights Reserved.",TextMining
"Due to the increasing number of electric vehicle charging events, an enormous data volume can be generated and recorded in very large databases. A deeper analysis of the data collected by the monitoring systems could provide significant information to characterize the behavior of the electric vehicle charging stations. Unfortunately, the features of occupancy patterns or the typical power demand profiles corresponding to the charging stations are many and various and can be hard to identify and interpret without adequate techniques. In this context, a flexible clustering-based data mining framework has been proposed to extract the main features (the number of hours when there is at least one charging, number of electric vehicles, and total energy consumption) associated with the occupancy patterns of the charging stations and to determine the typical electric vehicle charging demand profiles. The efficiency of the proposed framework has been demonstrated using a database containing information from the monitoring systems of CSs installed in a city in Spain.  © 2023 IEEE.",TextMining
"Skyline frequent utility patterns have been extensively studied. However, the existing skyline pattern mining algorithms are inefficiency and time consuming, and can be inadequate in practical applications, as sometimes traditional skyline pattern may obtain points that are relatively extreme in one dimension. These one-sided extreme points are not the points that the user would like to see in many applications, and the user prefer to see the skyline itemsets with relatively balanced two dimensions. Therefore, this paper proposes a new pattern of skyline mining with threshold settings. In the process of new skyline pattern mining, multiple thresholds are used to exclude extreme points that do not satisfy the user’s needs in certain dimensions, while also greatly reducing the number of search size and improving the speed of searching the target itemsets. In addition, the intelligent recommendation system of an online shopping website is taken as an example to demonstrate the application potential of the new pattern in a service AI system. In this paper, the UFmax array structure is applied so that it can be used not only to get the itemsets with the highest utility at the same frequency, but also to exclude the set of items whose utility and frequency both do not satisfy the threshold. The SFUTPMiner algorithm is introduced to make skyline pattern mining more accurate and efficient. Experiments were conducted on six databases respectively, and the proposed algorithm was compared with the current popular mining algorithm. The results show that the designed new pattern of skyline mining with threshold settings not only provides a streamlined and optimised set of result items, but also surpasses the previous traditional pattern in the aspect of runtime, search space and memory consumption. © 2023, Taiwan Ubiquitous Information CO LTD. All rights reserved.",TextMining
"Roof vertex information is vital for 3D roof structures. Reconstructing 3D roof structures from point cloud data using traditional methods remains a challenge because their extracted roof vertices are affected by uncertainty and additional errors from roof plane segmentation and supplementary sub-steps for extracting primitives. In this study, instead of segmenting roof planes and then extracting primitives based on them, a flexible rule-based method is proposed to directly detect the vertices of building roofs from point cloud data without the requirement of training data. The point cloud data is first voxelized with a dominant direction-based rotation. Based on the different features of the interior roof points and vertices, rules for voxel filtering and structure line determination are defined to extract the roof vertices. The experimental results on a custom dataset in Trondheim, Norway demonstrate that the proposed method can effectively and accurately extract roof vertices from point cloud data. The comparative experimental results with an unfine-tuned deep learning-based method on custom and benchmark datasets with different point densities further show that the proposed method has good generalization and can adapt to changes of datasets. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",TextMining
"The development of new digital traction power system is very rapid. And a large amount of heterogeneous data will be generated from the distribution network edge terminal device under the infiltration of renewable new energy. It will bring great data load pressure to the distribution network operation and maintenance platform. This problem causes data processing delay and makes user-side response unreal-time. For solving this problem, deep data mining and weight removal on the distribution side are needed to reduce. Traditional mining techniques for heterogeneous data generally use data mining methods based on dynamic time regularity. But the disadvantage of this method is that the mining efficiency is too low. It can not be weighted for multi-source heterogeneous data with low similarity. For this reason, this paper presents an edge-side processing algorithm for heterogeneous data based on Euclidean distance weighted optimization, which calculates the similarity between heterogeneous data from multiple sources to eliminate data redundancy, data mining and weighting. Finally, the effect of data mining technology in the edge computing security protection system is analyzed and verified based on the actual sample data of the distribution network comprehensive energy station.  © 2023 IEEE.",TextMining
The proceedings contain 216 papers. The special focus in this conference is on Advanced Data Mining and Applications. The topics include: A Novel Variational Autoencoder with Multi-position Latent Self-attention and Actor-Critic for Recommendation; fair Re-Ranking Recommendation Based on Debiased Multi-graph Representations; FastNER: Speeding up Inferences for Named Entity Recognition Tasks; CPMFA: A Character Pair-Based Method for Chinese Nested Named Entity Recognition; STMC-GCN: A Span Tagging Multi-channel Graph Convolutional Network for Aspect Sentiment Triplet Extraction; exploring the Design Space of Unsupervised Blocking with Pre-trained Language Models in Entity Resolution; joint Modeling of Local and Global Semantics for Contrastive Entity Disambiguation; KFEA: Fine-Grained Review Analysis Using BERT with Attention: A Categorical and Rating-Based Approach; discovery of Emotion Implicit Causes in Products Based on Commonsense Reasoning; from Time Series to Multi-modality: Classifying Multivariate Time Series via Both 1D and 2D Representations; multi-modal Multi-emotion Emotional Support Conversation; exploiting Pseudo Future Contexts for Emotion Recognition in Conversations; generating Enlightened Suggestions Based on Mental State Evolution for Emotional Support Conversation; deep One-Class Fine-Tuning for Imbalanced Short Text Classification in Transfer Learning; EmoKnow: Emotion- and Knowledge-Oriented Model for COVID-19 Fake News Detection; popular Songs: The Sentiment Surrounding the Conversation; market Sentiment Analysis Based on Social Media and Trading Volume for Asset Price Movement Prediction; efficient Mining of High Utility Co-location Patterns Based on a Query Strategy; point-Level Label-Free Segmentation Framework for 3D Point Cloud Semantic Mining; CD-BNN: Causal Discovery with Bayesian Neural Network; exploring the Effectiveness of Positional Embedding on Transformer-Based Architectures for Multivariate Time Series Classification; a Preference-Based Indicator Selection Hyper-Heuristic for Optimization Problems; an Elastic Scalable Grouping for Stateful Operators in Stream Computing Systems; incremental Natural Gradient Boosting for Probabilistic Regression; discovering Skyline Periodic Itemset Patterns in Transaction Sequences; Double-Optimized CS-BP Anomaly Prediction for Control Operation Data.,TextMining
"The main purpose of knowledge graph embedding (KGE) is to complete the missing part of triplets. By learning from existing models, we found that adding graph convolutional networks (GCN) to KGE models achieved good performance. These models mainly use the local structural characteristics of data. However, their main goal is to learn an aggregator rather than a feature vector for each node. To address the problems with existing models, we proposed a knowledge graph link prediction model based on attentional relational graph convolutional networks (ARGCN). First, we capture the relationship attribute features between nodes by adding an attention mechanism and extract important node attribute features for visualization. Then, through a relational graph convolutional neural network, we capture the associated attributes between nodes and extract the feature information that can best represent nodes. Finally, we use DistMult as the scoring function. Our experiments show that our proposed is effective on standard FB15k-237 and WN18RR datasets. Compared with other models, it has relative improvements in Hits@1, Hits@3 and Hits@10. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Compared with other classification algorithms, random forest algorithm has obvious advantages in terms of classification accuracy, generalization error and training speed, and is widely used in data mining. However, when faced with unbalanced data, the classification performance of random forest algorithm can be greatly limited. To better deal with imbalanced data, an improved random forest algorithm (oversampling & FeatureSelecctionRandomForest,OF-RF) based on oversampling and feature selection is proposed in the paper. The algorithm firstly, from the data level, uses the Borderline-SMOTE algorithm to preprocess the imbalanced data set and introduces the LOF algorithm to improve the Borderline-SMOTE algorithm in order to eliminate outliers and thus improve the processing performance for negative class samples. Secondly, from the algorithm level, the ReliefF algorithm is used to assign different weights to the balanced processed data, while excluding irrelevant and redundant features, so as to perform dimensional simplification. Finally, the classification performance of the algorithm is further improved by using the weighted voting principle. The experimental results show that the improved OF-RF algorithm exhibits higher evaluation metrics in processing unbalanced data compared with the traditional random forest algorithm, proving that the algorithm has significant advantages in classification performance of unbalanced data.  © 2023 IEEE.",TextMining
"Abstract: Sepsis is a life-threatening condition whose early recognition is key to improving outcomes for patients in intensive care units (ICUs). Artificial intelligence can play a crucial role in mining and exploiting health data for sepsis prediction. However, progress in this field has been impeded by a lack of comparability across studies. Some studies do not provide code, and each study independently processes a dataset with large numbers of missing values. Here, we present a comparative analysis of early sepsis prediction in the ICU by using machine learning (ML) algorithms and provide open-source code to the community to support future work. We reviewed the literature and conducted two phases of experiments. In the first phase, we analyzed five imputation strategies for handling missing data in a clinical dataset (which is often sampled irregularly and requires hand-crafted preprocessing steps). We used the MIMIC-III dataset, which includes more than 5,800 ICU hospital admissions from 2001 to 2012. In the second phase, we conducted an extensive experimental study using five ML methods and five popular deep learning models. We evaluated the performance of the methods by using the area under the precision-recall curve, a standard metric for clinical contexts. The deep learning methods (TCN and LSTM) outperformed the other methods, particularly in early detection tasks more than 4 hours before sepsis onset. The motivation for this work was to provide a benchmark framework for future research, thus enabling advancements in this field. Graphical Abstract: [Figure not available: see fulltext.]. © 2023, The Author(s).",TextMining
"The booming of cryptocurrencies in the last decade brought about the burst of cryptomining for obtaining cryptocurrencies in recent years. Only those users with plenty of computing resources are able to gain profits according to the design of block chain. As a result, this brings out more and more criminal attacks to maliciously plunder private and public computing resources through networks. Consequently, the detection of malicious cryptomining behavior is particularly important for network security and management. In this paper, we designed Mining Vanguard, realizing the recognition of mining behavior through the detection of DNS behavior. By constructing a comprehensive feature set that includes both traditional DNS resolution features and morpheme features, we combine network characteristics with semantic characteristics, aiming to achieve early recognition. Through a large number of targeted experiments, it is verified that Mining Vanguard is promising for detecting mining behaviors on the Internet. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"At present, data obtained from the Global Positioning System (GPS) is significantly valuable in mobility research. However, GPS-based data lacks include trip purpose information. Consequently, many researchers have endeavoured to predict or impute these missing attributes. Existing studies have focused on constructing more features to improve prediction accuracy, but paid less attention to the model's applicability and transferability. In this study, five trip purposes are extracted, including education, recreation, personal, shopping, and transportation, from Chengdu Household Travel Survey (HTS) data. The individual and trip characteristics that are common and can be easily derived from GPS data are carefully selected and extracted. Point of Interest (POI) data of the trip destination are also collected to enhance input characteristics. To obtain more accurate results, an ensemble learning model, Gradient Boosting Decision Trees (GBDT), is employed to predict trip purposes. grid search and cross-validation techniques are used to optimize the hyper-parameters. Empirical results show that the proposed model achieves 0.788 accuracy, which is 22.17%, 14.53%, 10.36%, and 6.77% higher than Multinominal Logit (MNL), Artificial Neural Network (ANN), Random Forest (RF), and Deep Belief Network (DBN), respectively. It is also found that although increasing trip features improve the model's accuracy, it simultaneously impairs model's transferability and generalizability. © 2023 The Authors. IET Intelligent Transport Systems published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.",TextMining
"Currently, the calibration of electric energy meters often involves manual meter reading, dismantling inspection, or regular sampling inspection conducted by professionals. To improve work efficiency and verification accuracy, this research integrates machine learning into the scheme of online verification and management of gateway meter flow in the power system. The approach begins by applying the Faster Region Convolutional Neural Network (Faster-RCNN) model and the Single Shot MultiBox Detector (SSD) model to the recognition system for dial readings. Then, the collected measurement data is pre-processed, excluding data collected under light load conditions. Next, an estimation error model and a solution equation for the electricity meter are established based on the pre-processed data. The operation error of the electricity meter is estimated, and the estimation accuracy is verified using the limited memory recursive least squares algorithm (LMRLSA). Furthermore, business assistant decisionmaking is carried out by combining the remote verification results with the estimation outcomes. The proposed dial reading recognition system is tested using 528 images of meter readings, achieving an accuracy of 98.49%. In addition, the influence of various parameters on the error results of the electricity meter is also explored. The results demonstrate that a memory length ranging from 600 to 1,200 and a line loss error of less than 5% yield the most suitable accuracy for estimating the electricity meter error. Meanwhile, it is advisable to remove measurement data collected under light load to avoid unnecessary checks. The experiments manifest that the proposed algorithm can properly eliminate the influence of old measurement data on the error parameter estimation, thereby enhancing the accuracy of the estimation. The adjustment of the memory length ensures real-time performance in estimating meter errors and enables online monitoring. This research has certain reference significance for achieving the online verification and management of gateway meter flow in the power system. © 2023 Li et al. Distributed under Creative Commons CC-BY 4.0. All Rights Reserved.",TextMining
"We propose to adopt statistical regression as the projection operator to enable data-driven learning of the operators in the Mori-Zwanzig formalism. We present a principled method to extract the Markov and memory operators for any regression models. We show that the choice of linear regression results in a recently proposed data-driven learning algorithm based on Mori's projection operator, which is a higher-order approximate Koopman learning method. We show that more expressive nonlinear regression models naturally fill in the gap between the highly idealized and computationally efficient Mori's projection operator and the most optimal yet computationally infeasible Zwanzig's projection operator. We performed numerical experiments and extracted the operators for an array of regression-based projections, including linear, polynomial, spline, and neural network-based regressions, showing a progressive improvement as the complexity of the regression model increased. Our proposition provides a general framework to extract memory-dependent corrections and can be readily applied to an array of data-driven learning methods for stationary dynamical systems in the literature. © 2023 Society for Industrial and Applied Mathematics Publications. All rights reserved.",TextMining
"Kidney failure is a condition with far-reaching, potentially life-threatening consequences on the human body. Leveraging the power of machine learning and data mining, this research focuses on precise disease prediction to equip decision-makers with critical data-driven insights. The accuracy of classification systems hinges on the dataset's inherent characteristics, prompting the application of feature selection techniques to streamline algorithm models and optimize classification precision. Various classification methodologies, including K-Nearest Neighbor, J48, Artificial Neural Network (ANN), Naive Bayes, and Support Vector Machine, are employed to detect chronic renal disease. A predictive framework is devised, blending ensemble methods with feature selection strategies to forecast chronic kidney disease. Specifically, the predictive model for chronic kidney disease is meticulously constructed through the fusion of an information gain-based feature evaluator and a ranker search mechanism, fortified by the wrapper subset evaluator and the best first algorithm. J48, in tandem with the Info Gain Attribute Evaluator and ranker search system, exhibits a remarkable accuracy rate of 97.77%. The Artificial Neural Network (ANN), coupled with the Wrapper Subset Evaluator and the highly effective Best First search strategy, yields precise results at a rate of 97.78%. Similarly, the Naive Bayes model, when integrated with the Wrapper Subset Evaluator (WSE) and the Best First search engine, demonstrates exceptional performance, achieving an accuracy rate of 97%. Furthermore, the Support Vector Machine algorithm achieves a notable accuracy rate of 97.12% when utilizing the Info Gain Attribute Evaluator. The K-Nearest Neighbor Classifier, in conjunction with the Wrapper Subset Evaluator, emerges as the most accurate among the foundational classifiers, boasting an impressive prediction accuracy of 98%. A second model is introduced, incorporating five diverse classifiers operating through a voting mechanism to form an ensemble model. Investigative findings highlight the efficacy of the proposed ensemble model, which attains a precision rate of 98.85%, as compared to individual base classifiers. This research underscores the potential of combining feature selection and ensemble techniques to significantly enhance the precision and accuracy of chronic kidney disease prediction. © (2023), (Science and Information Organization). All Rights Reserved.",TextMining
"China's power enterprises use mature information storage technology in information construction. Since the implementation of the 95598 power supply service hotline, a large amount of real business data has been accumulated in the customer service systems of various enterprises. However, enterprises only use traditional data processing methods to obtain indicators such as manual service rate and satisfaction, making it difficult to discover hidden business rules in the data and even more difficult to abstract mathematical models with business characteristics. Data mining can extract useful information from massive amounts of data and construct descriptive or predictive models to help enterprises solve practical problems and make correct judgments and decisions. Research the application technology of power system work order analysis based on artificial intelligence, solve the problem that 95598 work orders have weak ability to support professional management, form the AI structured processing and model training module for power business work orders, and realize the integration application of unstructured single data and structured data.  © 2023 IEEE.",TextMining
"The field of clinical medicine involves complex data analysis and mining, and text classification task in natural language processing can assist in case screening, etiology analysis, disease prediction, and other aspects in the medical field, thereby improving research efficiency and accuracy. However, obtaining supervised data is difficult due to the fact that medical texts such as cases often contain sensitive patient information. This difficulty partially explains why existing text classification methods do not perform well in medical tasks. Although the prompt tuning performs better than traditional neural networks and fine tuning methods in few-shot learning and interpretability. Chinese requires at least two characters to express complex semantics, which makes it challenging to apply the prompt tuning method that is primarily designed for English in Chinese text classification tasks. To address this issue, we propose Knowledge Enhanced Multi-Token Prompt Tuning (KMPT). KMPT first uses multiple tokens as label words to have complete Chinese semantics, and then uses external knowledge to expand the label words set, improving coverage and reducing bias. The experimental results on the Chinese medical dataset CHIP-CTC show that KMPT outperforms baseline methods in Chinese medical text classification tasks and has better interpretability and convergence speed than fine tuning. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Inequality in the distribution of food is a problem that is still being faced in Indonesia. This is indicated by the existence of areas that experience surpluses and deficits in the number of certain types of food. Therefore, achieving national food security, which is one of the targets of Indonesian government, is obstructed. One solution that can be applied is to apply clustering, which is a data mining technique to identify and create groupings of several areas with similar characteristics such as the tendencies of receiving food supplies, transporting food supplies, and consuming food supplies. The purpose is to provide information regarding the mapping of certain areas that receive a certain food distribution. There are several studies that examine the distribution of a food product. However, the solutions offered are still not applicable to cases of food inequality because these solutions can only be applied in a narrow and limited research environment. In addition, these solutions will require large computational resources due to the size of food distribution dataset. Moreover, this research paper will discuss the utility of polygon objects which form those areas in geographical setting and to compute the distance between areas. This research will utilize the CRISP-DM methodology, and the results of the research will be obtained by clustering the dataset. This study aims to find condition of food distribution by applying clustering, as well as proposing the most optimal way to distribute food based on the distances computed. © 2023 IEEE.",TextMining
"The article’s subject matter is the processing of abdominal EMG recordings and finding breathing patterns. The goal is to automatically classify respiratory patterns into two classes, or clusters, by two breathing patterns, regular and irregular, using machine learning (ML) methods. The object of the study was to obtain a dataset of 40 randomly picked abdominal EMG recordings (sampling rate equal to 200 Hz) borrowed from the complete dataset published by the Computational Clinical Neurophysiology Laboratory and the Clinical Data Animation Laboratory of Massachusetts General Hospital. The tasks to be solved are as follows: finding ETS (errors-trend-seasonality) model for the EMG series using the exponential smoothing method; obtaining denoised and detrended signals; obtaining the Hurst exponents for EMGs using the power-law decaying of correlograms for the denoised and detrended signals; describing the variabilities, SNR, the outlier fractions, and Hurst exponents by robust statistics, performing correlation analysis, and Principal Components Analysis (PCA); analyzing the structure of the distant matrix by a graph-based technique; obtaining the periodograms in the frequency domain using the known Wiener-Khinchin theorem; and finding the best models and methods of classification and clusterization and evaluating them within modern Machine Learning methods. The methods used are exponential smoothing, the Wiener-Khinchin theorem, the graph theory method, principal component analysis, programing within MAPLE 2020, and data processing by Weka. The authors obtained the following results: 1) wide data variability has been rated with the median absolute deviations, which is the most robust statistic in this case; 2) most of the signals (38 of 40) showed frequent outliers: from a few percent up to 24.6 % of emissions; 3) these four variables: outliers' percentage, variability, SNR, and persistency factors – form the attributes of input vectors of the subjects for further Machine Learning with Weka software; 4) Manhattan distances matrix among subjects' vectors in 4D attributes space allows imaging the data set as a weighted graph, the vertices of which are subjects; 5) the weights of the graph's edges reflect distances between any pair of them. ""Closeness centralities"" of vertices allowed us to cluster the data set on two clusters with 11 and 29 subjects, and Weka clustering algorithms confirmed this result. 6) The learning curve shows that a sufficiently small data set (from 25 subjects) might be suitable for classification purposes. Conclusions. The scientific novelty of the results obtained is as follows: 1) the Error-Trend-Seasonality model was the same for all data sets. Abdominal EMG of sleeping patients had additive errors and undamped trends without any seasonality; 2) the correlograms' decaying according to power law had been set, and Hurst exponents were in the range (of 0.776–0.887). This testifies to ""long memory"" (high persistence) of abdominal EMGs; 3) the modified Z-scores and robust statistics with the highest breakdown values were used for the EMG parameters because of many outliers; 4) breathing patterns were set using the periodograms in the frequency domain using the Wiener-Khinchin theorem; 5) the new graph-based method was successfully exploited to cluster the dataset. Parallel clustering with Weka algorithms confirmed the graph-based clustering results. © Gennady Chuiko, Yevhen Darnapuk, Olga Dvornik, Yaroslav Krainyk, 2023",TextMining
"In today's digital era, online articles have become the primary source of knowledge acquisition, replacing traditional library research. However, the ease of online editing by web users, especially on platforms like Wikipedia, poses a significant challenge of detecting and mitigating malicious destruction in web-based articles. Existing studies have employed web-mining techniques and cross-language learning with the Gradient Tree machine learning algorithm to identify vandalism on specific web contents, achieving up to 80% accuracy. To address this pressing issue, our research proposes a text-based online web articles vandalism detector using a Decision Tree algorithm. Building upon previous studies, we aim to enhance the accuracy performance of the proposed Vandalism Detector System on Wikipedia pages by implementing both basic and advanced machine learning pre-processing techniques with a Logistic Regression learning model. To create a reliable dataset, we cleaned the Wiki Data and merged it with the current Wikidata Vandalism Corpus, comprising four CSV files (edits.csv, annotators.csv, annotations.csv, and and gold-Annotators.csv). The resulting cleaned dataset, termed 'wikivand.csv,' served as the primary source dictionary, prepared using Python libraries and the Label Binarizer technique. Our proposed model was then trained to predict Yes or No labels, enabling it to identify whether a web article contains vandalism content. © 2023 IEEE.",TextMining
The proceedings contain 216 papers. The special focus in this conference is on Advanced Data Mining and Applications. The topics include: A Novel Variational Autoencoder with Multi-position Latent Self-attention and Actor-Critic for Recommendation; fair Re-Ranking Recommendation Based on Debiased Multi-graph Representations; FastNER: Speeding up Inferences for Named Entity Recognition Tasks; CPMFA: A Character Pair-Based Method for Chinese Nested Named Entity Recognition; STMC-GCN: A Span Tagging Multi-channel Graph Convolutional Network for Aspect Sentiment Triplet Extraction; exploring the Design Space of Unsupervised Blocking with Pre-trained Language Models in Entity Resolution; joint Modeling of Local and Global Semantics for Contrastive Entity Disambiguation; KFEA: Fine-Grained Review Analysis Using BERT with Attention: A Categorical and Rating-Based Approach; discovery of Emotion Implicit Causes in Products Based on Commonsense Reasoning; from Time Series to Multi-modality: Classifying Multivariate Time Series via Both 1D and 2D Representations; multi-modal Multi-emotion Emotional Support Conversation; exploiting Pseudo Future Contexts for Emotion Recognition in Conversations; generating Enlightened Suggestions Based on Mental State Evolution for Emotional Support Conversation; deep One-Class Fine-Tuning for Imbalanced Short Text Classification in Transfer Learning; EmoKnow: Emotion- and Knowledge-Oriented Model for COVID-19 Fake News Detection; popular Songs: The Sentiment Surrounding the Conversation; market Sentiment Analysis Based on Social Media and Trading Volume for Asset Price Movement Prediction; efficient Mining of High Utility Co-location Patterns Based on a Query Strategy; point-Level Label-Free Segmentation Framework for 3D Point Cloud Semantic Mining; CD-BNN: Causal Discovery with Bayesian Neural Network; exploring the Effectiveness of Positional Embedding on Transformer-Based Architectures for Multivariate Time Series Classification; a Preference-Based Indicator Selection Hyper-Heuristic for Optimization Problems; an Elastic Scalable Grouping for Stateful Operators in Stream Computing Systems; incremental Natural Gradient Boosting for Probabilistic Regression; discovering Skyline Periodic Itemset Patterns in Transaction Sequences; Double-Optimized CS-BP Anomaly Prediction for Control Operation Data.,TextMining
"The high-throughput exploration and screening of molecules for organic electronics involves either a ‘top-down’ curation and mining of existing repositories, or a ‘bottom-up’ assembly of user-defined fragments based on known synthetic templates. Both are time-consuming approaches requiring significant resources to compute electronic properties accurately. Here, ‘top-down‘ is combined with ‘bottom-up‘ through automatic assembly and statistical models, thus providing a platform for the fragment-based discovery of organic electronic materials. This study generates a top-down set of 117K synthesized molecules containing structures, electronic and topological properties and chemical composition, and uses them as building blocks for bottom-up design. A tool is developed to automate the coupling of these building blocks at their C(sp2/sp)-H bonds, providing a fundamental link between the two dataset construction philosophies. Statistical models are trained on this dataset and a subset of resulting top-down/bottom-up compounds, enabling on-the-fly prediction of ground and excited state properties with high accuracy across organic compound space. With access to ab initio-quality optical properties, this bottom-up pipeline may be applied to any materials design campaign using existing compounds as building blocks. To illustrate this, over a million molecules are screened for singlet fission. tThe leading candidates provide insight into the features promoting this multiexciton-generating process. © 2023 The Authors. Advanced Materials published by Wiley-VCH GmbH.",TextMining
"To enhance the ability to evaluate the mental health status of physical education students, a method of evaluating the mental well-being state of physical education students based on multi-source heterogeneous data mining is proposed. A fuzzy information detection model of multi-source heterogeneous data on the mental health status of physical education students is constructed, with four factors as dependent variables: compulsion, interpersonal sensitivity, hostility, and depression. Combined with the hierarchical index parameter detection and analysis method, the statistical analysis of multi-source heterogeneous info is accomplished. Based on the factor extraction outcomes of multi-source heterogeneous info, combined with the subspace heterogeneous fusion method, an estimated parameter feature clustering model is established. Combining the results of characteristic distributed clustering and linear regression analysis, the psychological well-being state evaluation of physical education students is realized. The results of empirical analysis show that this method has higher accuracy and better feature resolution in the evaluation of the mental well-being state of physical education students, which improves the reliability and confidence level of the assessment of the mental well-being status of physical education students. © (2023), (Science and Information Organization). All Rights Reserved.",TextMining
"Process mining has significantly transformed business process management by introducing innovative data-based analysis techniques and empowering organizations to unveil hidden insights previously buried within their recorded data. The analysis is conducted on event logs structured by conceptual models. Traditional models were defined based on only a single case notion, e.g., order or item in the purchase process. This limitation hinders the application of process mining in practice for which new data models are developed, a.k.a, multi-dimensional Event Knowledge Graph (EKG) and Object-Centric Event Log (OCEL). While several tools have been developed for OCEL, there is a lack of process mining tooling around the EKG. In addition, there is a lack of comparison about the practical implication of choosing one approach over the other. To fill this gap, the contribution of this paper is threefold. First, it defines and implements an algorithm to transform event logs represented as EKG to OCEL. The implementation is then used to transform five real event logs based on which the approach is evaluated. Second, it compares the performance of analyzing event logs represented in these two models. Third, it reveals similarities and differences in analyzing processes based on event logs represented in these two models. The results highlight ten important findings, including different approaches in calculating directly-follows relations when analyzing filtered event logs in these models and issues that need to be considered in analyzing event lifecycle and inter-log relations using OCEL. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"In this paper, we consider user privacy issues in location-based social networks (LBSNs). To encourage users to upload personal trajectory data for the benefit of society, we propose a novel privacy-preserving model to protect user trajectory data during the transmission and in the data center (the cloud). The proposed encryption model consists of a Gaussian-whiten encoder and a rotation matrix for the encryption key. The advantage of this model is that the encrypted data can be used for machine learning tasks and generative tasks, even it is not decrypted. We design a feasible interaction strategy to share the model between users and the cloud, and protect the encryption keys from cloud and external eavesdroppers. We apply our model to the trajectory dataset and feed the encrypted data to two classification tasks. Simulation results show that the proposed privacy-preserving model can protect user privacy at an acceptable cost of accuracy loss for classification tasks. Meanwhile, it outperforms classical differential privacy (DP) methods in terms of classifier accuracy loss and privacy preservation ability. © 2023 IEEE.",TextMining
"As the data landscape continues to expand, the task of identifying relevant documents becomes increasingly complex, especially when dealing with diverse and varied data sources. Traditional keyword-based search systems struggle to capture the subtle contextual meaning of search queries. Semantic-based search, leveraging open data knowledge graphs, offers a solution by understanding contextual meaning. However, its effectiveness relies heavily on the quality and completeness of the underlying data used to define these semantics. However, incomplete data can lead to spurious results and a lack of relevance in the retrieved documents. To bridge this gap between user search interest and retrieval outcomes, we propose integrating domain-specific alignment into the search process. Our research aims to achieve this through the development of a semantic-driven data processing pipeline, laying the foundation for seamless semantic-oriented retrieval. This approach includes metadata extraction, considering domain-specific keywords and structural metadata from heterogeneous data sources. We enhance metadata by identifying latent terms using language models. Furthermore, we incorporate latent concepts and domain-specific information gathered from domain experts into a special knowledge graph construct- a ‘concept graph’. Our primary focus is on identifying relevant concepts from this graph, aligning with semantic and contextual aspects of the specified search intent. Our proposed document retrieval system, which combines the concept graph with semantics, is implemented using data from the Government of Karnataka, India. This approach addresses the administrative need to extract relevant documents from data silos, offering an alternative approach to traditional methods. Extensive evaluations demonstrate the proposed system’s superior performance in terms of true positive results compared to baseline systems like Lucene, Elasticsearch, and Doc2Vec. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",TextMining
"The 534 protein kinases encoded in the human genome constitute a large druggable class of proteins that include both well-studied and understudied ""dark""members. Accurate prediction of dark kinase functions is a major bioinformatics challenge. Here, we employ a graph mining approach that uses the evolutionary and functional context encoded in knowledge graphs (KGs) to predict protein and pathway associations for understudied kinases. We propose a new scalable graph embedding approach, RegPattern2Vec, which employs regular pattern constrained random walks to sample diverse aspects of node context within a KG flexibly. RegPattern2Vec learns functional representations of kinases, interacting partners, post-translational modifications, pathways, cellular localization, and chemical interactions from a kinase-centric KG that integrates and conceptualizes data from curated heterogeneous data resources. By contextualizing information relevant to prediction, RegPattern2Vec improves accuracy and efficiency in comparison to other random walk-based graph embedding approaches.Weshow that the predictions produced by our model overlap with pathway enrichment data produced using experimentally validated Protein-Protein Interaction (PPI) data from both publicly available databases and experimental datasets not used in training. Our model also has the advantage of using the collected random walks as biological context to interpret the predicted protein-pathway associations. We provide high-confidence pathway predictions for 34 dark kinases and present three case studies in which analysis of meta-paths associated with the prediction enables biological interpretation. Overall, RegPattern2Vec efficiently samples multiple node types for link prediction on biological knowledge graphs and the predicted associations between understudied kinases, pseudokinases, and known pathways serve as a conceptual starting point for hypothesis generation and testing.  © 2023 Salcedo et al.",TextMining
"Flight parameter data plays a crucial role in comprehensively capturing the operational characteristics of various aircraft components and recording essential flight status information. This data holds significant value and finds extensive application in the domains of aircraft repair, maintenance, support, troubleshooting, and system optimization. However, due to the vast number of parameters present in flight record bus data and the generation of massive datasets at the gigabyte level, direct extraction becomes challenging. Therefore, it is necessary to filter the flight parameter data to enable efficient utilization for targeted problem analysis. This paper proposes an auxiliary method for analyzing flight parameter data using multi-text clustering and multi-timescale alignment. Additionally, an automated tool is designed and developed to address the complexities of synchronizing and concatenating parameters across multiple data buses, facilitating the effective extraction of flight parameter data and unlocking its true value. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Data provenance can effectively ensure the correctness of data mining results. To realize efficient and trusty data provenance, we propose an efficient blockchain data trusty provenance architecture based on the W3C PROV model. First, we integrate the W3C PROV model into the blockchain system to offer a unified provision information standard so as to form convincing assessments about its quality, reliability, or trustworthiness. Second, we design multi-bucket indexes within blocks and a skip list index among blocks to improve the query efficiency of the provenance information on blockchain. Finally, we design hash-linked list indexes to improve the verification efficiency of the completeness and correctness of the provenance information and propose a verifiable data query algorithm based on the above index. Experiential results show that our proposed architecture performance is effective and efficient. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Self-organizing Map (SOM) is one of the artificial neural networks and well applied to datamining or feature visualization of high-dimensional datasets. Recently, SOMs are actively used for market research, political decision-making, and social analysis using a huge number of live text-data. The SOM, however, needs a large number of parameters and iterative calculations like Deep Learning, so that specialized accelerators for SOM are strongly required. In this paper, we newly propose a scalable SOM accelerator based on FPGA, in which all neurons in the SOM are mapped onto an internal memory, or BRAM (Block-RAM) in FPGA to maintain high parallelism in the SOM itself. We implement the proposed SOM accelerator on an Alveo U50 (Xilinx, Ltd.) and evaluate its performance: the accelerator shows high scalability and runs 102.0 times faster than software processing with Intel Core i7, which is expected to be enough for the real-time datamining and feature visualization. © 2023, International Society of Artificial Life and Robotics (ISAROB).",TextMining
"Label ambiguity is one of the key issues in Facial Expression Recognition (FER). Previous works tackle this issue by modifying the original annotations to another one or characterizing them with soft labels, but this is often insufficient or redundant. Different from these methods, we analyze ambiguous samples from the perspective of label compensation with the subjectivity of FER into consideration. To this end, we propose an Adaptive Compensatory Label Mining model (ACLM), which adaptively learns compensatory labels for ambiguous samples while remaining original labels. The Compensated Label Mining (CLM) module is used to evaluate the confidence and importance of the learned compensatory labels. Qualitative and quantitative experiments have demonstrated the superiority of using an adaptive combination of original labels and compensatory labels to guide FER models. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"This paper investigates the impact of government investment and private investment on economic development in Xinjiang based on data mining techniques, analyses the current situation of government investment and economic development based on theoretical foundations, and analyses the contribution of government investment to economic growth from an empirical perspective. The findings show that government investment has a positive impact on economic growth in the long-term equilibrium relationship, and private investment has a driving effect on economic growth in the short-term fluctuation relationship, and the econometric model effectively illustrates that the benign coordination of government investment and private investment can promote the economic transformation and upgrading.  © 2023 IEEE.",TextMining
"COVID-19 has become a global pandemic that has affected not only the health sector but also economic, social, and psychological well-being. Individuals are using social media platforms to communicate their feelings and sentiments about the pandemic. One of the most debated topics in that regard is the vaccine. People are divided mainly into two groups, pro-vaccine and anti-vaccine. This article aims to explore Arabic Sentiment Analysis for Vaccine-Related COVID-19 Tweets (ASAVACT) to quantify sentiment polarity shared publicly, and it is considered the first and the largest human-annotated dataset in Arabic. The analysis is done using state-of-the-art deep learning models that proved superiority in the field of language processing and analysis. The models are the stacked gated recurrent unit (SGRU), the stacked bidirectional gated recurrent unit (SBi-GRU), and the ensemble architecture of SGRU, SBi-GRU, and AraBERT. Additionally, this article presents the largest Arabic Twitter corpus on COVID-19 vaccination, with 32,476 annotated Tweets. The results show that the ensemble model outperformed other singular models with at least 7% accuracy enhancement. © 2023 Alhumoud et al. Distributed under Creative Commons CC-BY 4.0. All Rights Reserved.",TextMining
"Time series data, an increasingly common form of data in real-world applications, is typically time-dependent. Time series forecasting seeks to extract potential information from time series data to forecast future trends. The complexity and nonlinearity of current time series data make it difficult for traditional forecasting algorithms to handle them, hence this paper suggests a branching time series forecasting method based on convolutional neural network (CNN) and long short-term memory network (LSTM). The method initially uses CNN to extract features from time series data, then uses CNN and LSTM to map these features to future prediction values, and lastly inputs to the fully connected layer to obtain the prediction results. According to the experimental findings, the branching prediction method based on CNN and LSTM has superior time series prediction accuracy and stability.  © 2023 IEEE.",TextMining
"Data analysis is an essential component of decision support in various industries that includes industrial and educational institutions. This research proposes Data Mining (DM) techniques to improve the efficiency of higher education (HE) institutions. DM has a substantial impact on different higher education activities including student performances, management of student’s life cycle, selection of courses, monitoring of retention rate, grants & funds management by using technique’s such as clustering, decision trees (DT), and association. Educational Data Mining (EDM) is an interdisciplinary study topic that focuses on getting DM to the fields of education by leveraging methods from (ML) statistics, (DM), and (DA) to get important insights from educational sets of data. EDM is critical in transforming raw data into useful information, allowing for a greater knowledge of students and their academic settings, as well as promoting better teacher assistance and ESD (Educational System Decisions). The study's goal is to provide a complete overview of EDM (Educational Data Mining), highlighting its various applications and benefits in the context of higher education. © 2023, American Scientific Publishing Group (ASPG). All rights reserved.",TextMining
"Mining as a human activity shares the fate of humanity in all global situations that affect the planet. These are, to a lesser extent, positive effects such as the opening of the world market, the industrial revolution, etc., and, to a greater extent, negative effects such as various conflicts or pandemics that have a global character. The COVID-19 pandemic has had an unprecedented impact on all sectors of human society, justifying a scientific interest in assessing its impact at global and local levels. Recently, the World Health Organization declared the end of the pandemic, after which the Croatian government did the same. This also marks the end of the research period for the preparation of this paper. The paper is about the study of the impact of the pandemic on the Croatian mining sector in Croatia. In addition to statistical data on production and the number of employees in the mining sector, the results of a survey of economic entities and conclusions about the management of companies in crisis situations were processed. © 2023, Faculty of Political Sciences, University of Zagreb. All rights reserved.",TextMining
"With the continuous development of Internet of Things (IoT) technology and the widespread application of IoT by enterprises, enterprise IoT is facing increasingly complex and frequent malicious attack threats. To effectively detect malicious attacks in enterprise IoT and timely take corresponding security protection measures, an intelligent detection method was proposed for malicious attacks in enterprise IoT based on graph neural networks. Pre-processing enterprise IoT data, extracting data features, analyzing data packet transmission characteristics, and employing a graph neural network to extract time series features were involved in this method. To mitigate feature gradient disappearance, additional connections were incorporated. Data containing interactive nodes was filtered using these features, and a three-layer model was established for classifying the data, thus facilitating intelligent detection of malicious attacks. Experimental results show that this method can accurately describe the changing characteristics of malicious attacks on enterprise IoT and overcome the shortcomings of current malicious attacks on enterprise IoT. It achieves a 100% accuracy rate on the KDD (Knowledge Discovery and Data Mining) Cup 1999 dataset and enterprise IoT and is consistent with the imported data information. The average malicious node detection rate of this method is 97.26% on the two datasets. The method outperforms node-centered control algorithms, mutual information-based methods, and GWB-LSSVM joint methods. The proposed intelligent detection method exhibits strong feasibility, high accuracy, and important practical application value. © 2023 School of Science, IHU. All rights reserved.",TextMining
"The increasing adoption of distributed systems has led to a growing need to understand and analyze user behavior in these environments. However, obtaining service-specific event logs for such systems, suitable for process mining and data modeling tasks, remains a significant challenge due to the complexities associated with distributed architectures and data privacy concerns. In addition, traditional approaches for acquiring event logs often result in incomplete or low-quality data, which hinders effective data analysis. In response to these challenges, this paper presents a novel methodology for generating event logs from applications in distributed environments through the instrumentation of available services while maintaining data quality standards. Our hybrid approach leverages event logs derived from the University authentication server and Client-Side event logs as a sample training set to enable the projection and analysis of user activities, offering a more comprehensive understanding of user behavior in distributed systems. Using two case studies, we demonstrate our methodology’s validity, robustness, and generalization through empirical evaluations in real-life scenarios. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"The rapid growth of radio broadcast services has created a vast amount of audio data that can provide insights into public opinion and emotions. This research extends the boundaries of sentiment analysis to audio data and aims to propose a computational approach which is termed as bifurcate and mix, for sentiment analysis and emotion detection that leverages advanced natural language processing techniques from audio sentiment analysis tools like Vokaturi, transcription services like AssemblyAI and text sentiment analysis lexicons like VADER to extract and categorize sentiments from the audio data to generate a more efficient real-time sentiment analysis model. The results of the analysis reveal patterns and trends in the sentiments expressed in radio broadcasts by the News Service Division: All India Radio-'Akashwani'. This research's methodology will contribute to the development of novel applications for sentiment analysis in the media industry and provide valuable insights into public opinion and emotions.  © 2013 IEEE.",TextMining
"The proceedings contain 62 papers. The special focus in this conference is on Research in Engineering, Technology and Science. The topics include: Data Cleaning in Medical Procurement Database: Performance Comparison of Data Mining Classification Algorithms for Tackling Missing Value; Optimal Position of Two Fans Cooling a Large PV Panel; possibilities to Construct Combined Mine Waste Dump Facility with Better Operational Sequence; stochastic Longitudinal Autopilot Tuning for Best Autonomous Flight Performance of a Morphing Decacopter; a Quantitative Blockchain-Based Model for Construction Supply Chain Risk Management; comparative Experimental and Theoretical Study on the Structure of Potassium 2,4-Hexadienoate: Structure-Activity Relationship; alternative Aviation Fuel Types Used in Aircraft Engine; on the Development of the Fluorescence Excitation-Emission Etalon Matrix Algorithm of Wine; Green Hydrogen from PV-Supplied Sono-Electrolysis: Modelling and Experimental Investigations of the Mechanism and Performance; SaaS Model Assessment-A DEA Approach; microstructure and Mechanical Properties Analysis of Al-6061/B4C Composites Fabricated by Conventional and Bobbin Tool Friction Stir Processing; an App for the Registration of Traffic Injuries; a Proposed Conceptual Design for a Computer-Based Ambulance System in Libya Using IoT; non-linear Viscoelastic Beams Under Periodic Strains: An Approach for Analyzing of Longitudinal Fracture; research on Media Presentation and Public Reaction to the First Health Digital Assistant in Croatia; computer-Aided Planning of Radial and Diameter Routes in Local Public Transport Networks; effect of Urea Usage Rate on Thixotropic Behavior of Cementitious Systems; estimation of Red Meat Production in Turkey according to the Grey-Markov Chain Model; Blockchain Security-Efficiency Analysis based on DEA-SBM Model; renewal Energy Efficiency Assessment.",TextMining
"Here we present additional information for the manuscript entitled &#x201C;A Local Iterative Approach for the Extraction of 2D Manifolds from Strongly Curved and Folded Thin-Layer Structures&#x201D;. Due to page limitations, this information did not fit into the main manuscript. This includes information about the algorithm by Algarni and Sundaramoorthi [1], which was the starting point for the development of our algorithm. In addition, we present results for two related state-of-the-art algorithm by Schultz et al. [7] as well as Dambrogio et al. [4]. Furthermore, we also include a mathematical proof for a stated theorem in the main manuscript. IEEE",TextMining
"The application of data mining technology has intensively advanced tribology research. While recent lubrication studies have highlighted the importance of data mining, researchers have not fully bridged the gap between massive lubrication data and intrinsic lubrication mechanisms. Thus, by revisiting lubrication modelling from the data-driven and physics-informed perspectives, we aim to construct a hybrid approach for hydrodynamic lubrication classification and prediction, where data-driven methods are combined with physics-informed approaches to achieve a fast and accurate prediction of the hydrodynamic lubrication scenario. Our approach will spur the application of data mining methods in lubrication studies. © IMechE 2023.",TextMining
"Currently, resource scarcity and climate change are among the main global problems. Governments are actively seeking regenerative solutions so that humans and nature can co-exist in harmony in the face of ecological destruction and resource limitations. One of these solutions is green consumption. Making greener consumption decisions is necessary for society to become sustainable. If sustainable consumption is to be promoted, public perception must shift, and achieving this shift will be simpler if society's shift toward green consumption is understood. This research aims to explore the sentiment and attitudes towards sustainable consumption on YouTube, a popular online platform with a vast pool of user-generated content. We employ a combination of data mining techniques and sentiment analysis to process and analyze a large dataset of YouTube videos and comments related to sustainable consumption topics. The data collection includes videos from various categories, such as reviews of eco-friendly products, vlogs of sustainable living, and informative content on environmentally responsible practices. The study focusses on understanding user engagement, sentiment polarity, and the factors influencing positive or negative attitudes toward sustainable consumption. In this way, the attitude of society toward green consumption and the role of social networks in public opinion can be understood. Overall, the study shows how data mining techniques and social networks have the potential to help with the shift to more sustainable growth paths. © 2023 Published by ISRES Publishing: www.isres.org.",TextMining
"Knowledge Graph (KG) can provide semantic information about items, which can be used to mitigate the sparsity problem in recommendation systems. In recent years, the trend in knowledge-aware recommendation methods has been to leverage Graph Neural Networks (GNNs) to aggregate node information in KG. However, many of these methods focus on mining the item knowledge association on KG, but ignore the potential item auxiliary information in user’s history interaction outside KG. Furthermore, these methods equally aggregate all neighbor entities of the item on KG, which will inevitably introduce irrelevant entity-interaction behaviors. To address these issues, we propose a novel model, called Multi-level Noise Filtering and Preference Propagation Enhanced Recommendation (MNFP). Technically, we employ self-attention mechanisms to model the user’s interaction sequence to mine the item’s auxiliary information. Then, we design a twin-tower preference propagation mechanism that iteratively expands item auxiliary information on KG. Additionally, we propose a multi-level noise filtering mechanism. By learning the relationship consistency between the item and its neighbor entities, the model can guide the item to selectively link highly related neighbors in preference propagation, thus reducing the introduction of noise. We evaluate MNFP on three real-world datasets: MovieLens-1M, Last.FM and Book-Crossing. Results show that MNFP significantly outperforms state-of-the-art methods on AUC and F1. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Anomaly detection in energy consumption for buildings plays a critical role in improving energy efficiency. In distributed systems, federated learning (FL) has gained widespread adoption due to its ability to train robust models while preserving privacy. However, most FL algorithms face challenges in handling heterogeneous data across different buildings, where distribution gaps exist. Moreover, addressing the heterogeneity in data necessitates additional efforts in model personalization, resulting in significant computational overhead, especially in large-scale FL settings. To address these challenges, we propose a sparse attentive aggregation-based federated anomaly detection approach (SAA-FAD). SAA-FAD comprises an extraction network and a lightweight recognition network. The extraction network employs a variational Bayes scheme to extract statistical characteristics from the raw data for computing similarities between clients while preserving privacy. Then the recognition network is trained with the extracted statistical features. The model is trained in a sparse attentive aggregation manner, which leads to superior anomaly detection performance on heterogeneous data. Additionally, SAA-FAD achieves a time and memory complexity of O(N&#x2219;logN) for computing similarity. Simulation results demonstrate that SAA-FAD outperforms other baseline models, particularly in scenarios with heterogeneous data, while offering a significant advantage in terms of computation time. IEEE",TextMining
"Attribute graph clustering requires joint modeling of both graph structure and node properties, which is challenging. In recent years, graph neural networks have been utilized to mine deep information on attribute graphs through feature aggregation, learning node embeddings, and using traditional methods to obtain clustering results, exhibiting excellent clustering performance. However, these approaches often face the following issues: the original graph structure and node features contain noise, and the quality dramatically affects the clustering results; the two-step framework of first learning node embeddings and then clustering is often suboptimal as it is not target-oriented and prone to producing suboptimal results. Through research, we propose an attribute graph clustering method called FK-SENet based on a self-supervised spectral embedding network. It utilizes Laplacian smoothing filters to smooth and denoise node features. It optimizes the initial graph structure by leveraging shared neighbor information to improve the quality of the original data, thereby enhancing clustering performance. Soft labels are generated from the node embeddings themselves to achieve self-supervision, and they jointly guide the clustering process with spectral clustering loss, iteratively optimizing the clustering results. The effectiveness of this model has been demonstrated through extensive experiments and comparisons with baseline methods.  © 2013 IEEE.",TextMining
"Sentiment analysis (SA) and text emotion detection (TED) are two computer techniques used to analyze text. SA categorizes text into positive, negative, or neutral opinions, while TED can identify a wide array of emotional states, allowing an automated agent to respond appropriately. These techniques can be helpful in areas such as employee and customer management, online support, and customer loyalty, where identifying human emotions is crucial. Among other approaches, research has been conducted using machine learning (ML) algorithms, and labeled datasets have been created to train these models. Current state-of-the-art research for supervised ML algorithms reports good performance for TED (approximately 80% accuracy) and even better results for SA (above 90%). After conducting an extensive review of 30 surveys, the primary objective of this manuscript is to point out that most of these articles (94%) focus heavily on comparing the applied computational methods (the algorithm). At the same time, relatively diminished attention is paid to three other critical factors, namely the selection of an appropriate emotion model (mentioned only in 23% of cases), the corpora utilized for training (30%), and the data source employed during analysis and evaluation (20%). The lack of standardization across these essential elements presents a significant challenge when performing meaningful performance comparisons among algorithms. Consequently, the absence of a unified framework for comparison hampers the practical implementation of SA and TED techniques within mission-critical scenarios within real-world mission-critical scenarios.  © 2013 IEEE.",TextMining
"With the promotion of energy transformation, the utilization ratio of electrical power is progressively rising. Since electrical power is challenging to store, real-time production and consumption become imperative, imposing significant demands on the dependability and operational efficiency of electrical power apparatus. Suppose the load distribution among multiple transformers within a transformer network exhibits inequality. In such instances, it will amplify the total energy consumption during the voltage conversion process, and local, long-term high-load transformer networks become more susceptible to failures. In this article, we scrutinize the matter of transformer energy utilization in the context of electricity transmission within grid systems. We propose a methodology grounded on genetic algorithms to optimize transformer energy usage by dynamically redistributing loads among diverse transformers based on their operational status monitoring. In our experimentation, we employed three distinct approaches to enhance energy efficiency. The experimental findings evince that this approach facilitates swifter attainment of the optimal power level and diminishes the overall energy consumption during transformer operation. Moreover, it exhibits a heightened responsiveness to fluctuations in power demand from the electrical grid. Experimental results manifest that this technique can truncate monitoring time by 27% and curtail the overall energy consumption of the distribution transformer network by 11.81%. Lastly, we deliberate upon the potential applications of genetic algorithms in the realm of power equipment management and energy optimization issues. © 2023 Lin et al. Distributed under Creative Commons CC-BY 4.0. All Rights Reserved.",TextMining
"The performance of any communication system heavily relies on the efficient routing of interventions. This article addresses the significant issue of routing protocol selection for optimal path determination in networks. Particularly, when wireless communication occurs among mobile nodes with limited resources, such as batteries, the routing problem becomes even more challenging. This article proposes the Fuzzy Control Energy Efficient (FCEE) routing protocol to overcome these challenges. The FCEE protocol combines the Ad-Hoc On-Demand Distance Vector (AODV) protocol with fuzzy logic techniques to enhance network lifetime and performance. The proposed approach introduces a memory-based channel integrated with fuzzy logic methodologies, which effectively restricts the forwarding of unnecessary broadcast packets based on the energy availability of the operating node. Through extensive simulations, demonstrate the promising capabilities of FCEE as a routing protocol for wireless mesh networks. To further assess the effectiveness of the FCEE protocol, the proposed article compares it with two existing routing protocols: AODV and Intelligent Routing AODV (IRAODV). The simulation results shows that the FCEE routing protocol significantly enhances the reliability of the conventional AODV, providing improved link connectivity and longer route lifetimes. Additionally, our proposed protocol enhances the quality of service (QoS) for mesh routing, with an average throughput of 351.374 (Kbps) compared to 90 (Kbps) for IRAODV and 39 (Kbps) for AODV. Moreover, FCEE exhibits superior energy efficiency with an average energy consumption of 14, while IRAODV and AODV consume 40 and 90 joules, respectively. In conclusion, the FCEE routing protocol demonstrates its potential to address the challenges of efficient routing in wireless mesh networks. By leveraging fuzzy logic and integrating it with AODV, FCEE enhances network lifetime, performance, and energy efficiency, making it a promising solution for future wireless communication systems. © 2023 Alameri et al. All Rights Reserved.",TextMining
"Artemisia argyi Lev. et Vant. (A. argyi) is a perennial grass in the Artemisia family, the plant has a strong aroma. Methyl jasmonate (MeJA) is critical to plant growth and development, stress response, and secondary metabolic processes. The experimental material Artemisia argyi was utilized in this study to investigate the treatment of A. argyi with exogenous MeJA at concentrations of 100 and 200 μmol/L for durations of 9 and 24 h respectively. Transcriptome sequencing was conducted using the Illumina HiSeq platform to identify stress resistance-related candidate genes. Finally, a total of 102.43 Gb of data were obtained and 162,272 unigenes were identified. Differential analysis before and after MeJA treatment resulted in the screening of 20,776 differentially expressed genes. The GO classification revealed that the annotated unigenes were categorized into three distinct groups: cellular component, molecular function, and biological process. Notably, binding, metabolic process, and cellular process emerged as the most prevalent categories among them. The results of KEGG pathway statistical analysis revealed that plant hormone signal transduction, MAPK signaling pathway-plant, and plant-pathogen interaction were significant transduction pathways in A. argyi’s response to exogenous MeJA-induced abiotic stress. With the alteration of exogenous MeJA concentration and duration, a significant upregulation was observed in the expression levels of calmodulin CaM4 (ID: EVM0136224) involved in MAPK signaling pathway-plant and auxin response factor ARF (ID: EVM0055178) associated with plant-pathogen interaction. The findings of this study establish a solid theoretical foundation for the future development of highly resistant varieties of A. argyi. Copyright © 2023 Wang, Cui, Li, Gao, Zhang and Shen.",TextMining
"Learner modelling and performance prediction have seen numerous advances in the last decade which include Neural Network (NN) based approaches like Deep Knowledge Tracing (DKT), Factorisation machines for estimation and automatic detection of skill tags amongst others. Intelligent Tutoring Systems (ITSs), which try to tailor each user's learning by adaptively scheduling problems depend upon learner modelling and the accurate prediction of learner performance to operate. ITSs have led to the availability of large-scale datasets enabling the development of richer models. The classical Bayesian approaches have been overtaken by faster, more scalable and more accurate models like DASH and DAS3H. Despite recent gains in prediction accuracy by NN based models, they are getting increasingly complex and computationally expensive. The issues with the scalability of recent models hinder their widespread adoption in Massive Online Open Courses (MOOCs) which outnumber ITSs by several magnitudes. NN models have very limited transferability. In this paper, the state-of-the-art approach involving Logistic Regression (LR) is examined on 8 public datasets and an alternative system based on variational encoding is presented. The proposed system outperforms the LR model in accuracy for 4 datasets. The new model is applied to the biggest Educational Data Mining (EDM) dataset available and shows that training on such a large dataset is possible without batching, which is not possible by other techniques. The paper focuses on the increase in scalability with a smaller memory footprint (requiring 22.5 ± 7.45 % less memory). The system also had a reduction in runtime for 5 among the 8 datasets. However, the variance in reduction is high with an average of $10.12\pm 21.55 \%$ reduced run times. The proposed system was developed specifically for lightweight MOOCs with limited Learning Management Systems (LMS) such as Moodle. By estimating a learner ability parameter, the proposed system provides richer information to downstream applications like adaptive scheduling. The proposed model retains a high level of interpretability and transferability.  © 2013 IEEE.",TextMining
"We propose the LLMs4OL approach, which utilizes Large Language Models (LLMs) for Ontology Learning (OL). LLMs have shown significant advancements in natural language processing, demonstrating their ability to capture complex language patterns in different knowledge domains. Our LLMs4OL paradigm investigates the following hypothesis: Can LLMs effectively apply their language pattern capturing capability to OL, which involves automatically extracting and structuring knowledge from natural language text? To test this hypothesis, we conduct a comprehensive evaluation using the zero-shot prompting method. We evaluate nine different LLM model families for three main OL tasks: term typing, taxonomy discovery, and extraction of non-taxonomic relations. Additionally, the evaluations encompass diverse genres of ontological knowledge, including lexicosemantic knowledge in WordNet, geographical knowledge in GeoNames, and medical knowledge in UMLS. The obtained empirical results show that foundational LLMs are not sufficiently suitable for ontology construction that entails a high degree of reasoning skills and domain expertise. Nevertheless, when effectively fine-tuned they just might work as suitable assistants, alleviating the knowledge acquisition bottleneck, for ontology construction. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"Racial bias is a well-documented problem in natural language processing (NLP). The dialectal language used by marginalized groups is often misclassified or mischaracterized by language models, which in turn can further disenfranchise these populations. Previous works have noted that some popular language identification (LID) models perform worse when classifying tweets that contain African-American Vernacular English (AAVE) than when classifying tweets that contain White-Aligned English (WAE). This work examines the factors that contribute to racial bias in language models for the LID task. The contributions of this work are two-fold. First, a thorough analysis demonstrates that a lack of &#x201C;unique&#x201D; language-specific n-gram features in an LID model can lead to poor performance on dialectal data, especially on shorter-length inputs like those typically found on social media. Second, based on these findings, this work introduces and illustrates the efficacy of two simple yet accurate solutions: i.) mining &#x201C;unique&#x201D; n-gram features and ii.) including examples of dialectal English in training data. These solutions mitigate the accuracy gap between WAE and AAVE which some language identification models demonstrate when classifying shorter inputs. Mining for unique features and training with a more diverse dataset can improve the disparity on short-length sequences by 6&#x0025; and 9.8&#x0025; respectively. IEEE",TextMining
"Despite significant advancements in artificial intelligence technology, image processing (classification) has not made as much progress as other fields, especially natural language processing. Slowly, technologies such as Transformers are being implemented in the field of image processing, but due to disparities in data format, they are not widely utilized. Moreover, the size of image data is typically quite large, limiting the amount of data that can be used for training. Therefore, we wish to optimize existing models and proposes a framework for the automatic detection, extraction, and classification of report table images from financial analysis. The framework is designed to address the difficulties encountered by the financial industry, where table data shapes can vary, making it difficult to extract and utilize the data and necessitating extensive manual labor. Detected tables with 99.9% accuracy using Cascade-TabNet and filtered out unnecessary data with 97.93% accuracy using DenseNet. For classification of tables, we developed a mix model that combines various features to achieve 95.2% precision. The overall framework achieved an average precision of 97.37%, making it suitable for automated environments requiring minimal human intervention. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"Volunteering efforts are important for achieving collective goals during crisis time. To facilitate such efforts, this study uses volunteer and task information to predict the likelihood of volunteers' future collaboration with machine learning approaches. This study adopts data collected from the mobile crowdsourcing app 'Anti-Pandemic Pioneers' used for organizing volunteers during the COVID-19 pandemic in Shenzhen, China. Volunteer information is constructed as an undirected, weighted graph, and this task can be considered as a link prediction problem in network theory. Multiple methodologies are experimented with for this problem, such as topology based-methods, node attribute-based methods, and mixed methods. This study also evaluates the performance of the node embedding approach. Finally, the experiment results show that the ensemble model of the Jaccard index, Adamic-Adar index, and resource allocation index outperforms all other approaches, achieves an accuracy score of 0.85333 for the private test, and ranks 2nd on the task2 leaderboard. © 2023 IEEE.",TextMining
"Knowledge base population seeks to expand knowledge graphs with facts that are typically extracted from a text corpus. Recently, language models pretrained on large corpora have been shown to contain factual knowledge that can be retrieved using cloze-style strategies. Such approach enables zero-shot recall of facts, showing competitive results in object prediction compared to supervised baselines. However, prompt-based fact retrieval can be brittle and heavily depend on the prompts and context used, which may produce results that are unintended or hallucinatory. We propose to use textual entailment to validate facts extracted from language models through cloze statements. Our results show that triple validation based on textual entailment improves language model predictions in different training regimes. Furthermore, we show that entailment-based triple validation is also effective to validate candidate facts extracted from other sources including existing knowledge graphs and text passages where named entities are recognized. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"Acid mine drainage (AMD) is one of the main causes of environmental threats resulting from mining activities, yet efficient characterization and prediction of AMD potential of wastes play an important role in preventing AMD. In this study, the chemical and mineralogical properties of fresh waste samples, collected from waste ponds of the Görgü (Malatya) zinc-lead ore processing plant, were determined and the results were used to explain its AMD potential. Alteration properties of the wastes in water was investigated by monitoring certain properties of the prepared suspension with respect time. Additionally, pyrite concentrate particles were added into the suspensions at certain proportions to evaluate its effect on the AMD generation and alteration. Analysis and test results showed that the raw waste was rich in carbonate and poor in pyritic sulfur, and hence did not have the AMD generation potential. The pH, electrical conductivity, and metal ions concentrations of the suspension medium were determined at regular intervals, and obtained data were found very beneficial to explain the time-dependent behavior of waste in water. After the depletion of liquid in the suspension, the remained solid residuals were chemically and mineralogically analyzed to compare with raw waste. It was concluded that sufficient aeration and stirring of suspension is required for noticeable alteration of the waste. © Wroclaw University of Science and Technology",TextMining
"Place has gained significant attention in geographic information science. Places are described by users that make a huge amount of user-generated textual contents. This research introduces a novel approach to extract place functionality using crowdsourcing textual data, which are shared in the form of online reviews. The proposed method can help users to find places that afford a specific functionality and can improve decisions in urban planning. To achieve this goal, salient features are modeled as directions in a domain-specific semantic space. We propose an unsupervised method that only requires a Bag-of-Words (BoW) of place reviews. Finally, a probabilistic multi-label functionality for each place is predicted using the semantic space constructed based on the salient feature directions, and the maximum probability is considered as the main functionality of place. The functionality of &#x2018;Hotels&#x2019; is determined with an average accuracy of 88.52%, while the efficiency of extracting &#x2018;Attractions&#x2019;, &#x2018;FoodPlaces&#x2019;, and &#x2018;Shoppings&#x2019; functionalities is 65.66%, 64.99%, and 12.70%, respectively. Authors",TextMining
"Parkinson's Disease (PD) recognition generally depends on the valuation of clinical signs and medical observations, which includes the characterization of various motor symptoms. However, classical diagnostic techniques may undergo bias since they depend on activity assessment that can be irregularly delicate to human vision and thus tough to categorize, causing probable misclassification. Simultaneously, initial non-motor PD indications will be insignificant, and others will occur in many other circumstances. Hence, such indications were often unnoticed, making PD diagnosis at an initial stage challenging. For solving such complexities and for refining the assessment procedures and diagnosis of PD, Deep Learning (DL) approaches were applied for classifying PD and vigorous controls or patients who have clinical performances (for example, other Parkinsonian syndromes or movement disorders). This study develops an Automated PD Detection using Feature Selection with Optimal Stacked Autoencoder (APDD-FSOSAE) technique. The presented APDD-FSOSAE technique focuses on assessing PD using Feature Selection (FS) and DL approaches. To attain this, the presented APDD-FSOSAE model comprises the design of a chicken swarm optimization-based FS approach for the selection of optimum features. Next, the APDD-FSOSAE technique utilizes SAE for detecting and classifying PD. Finally, the hyperparameters of the SAE model can be optimally selected by the Bayesian Optimization (BO) model. The investigational output evaluation of the APDD-FSOSAE approach is examined on a benchmark PD dataset. The experimental outputs suggested that the APDD-FSOSAE approach results in improved PD detection results over other models. © 2023 Journal author. All rights reserved.",TextMining
"Motor imagery (MI) electroencephalography (EEG) has been used in consumer products supported by brain-computer interfaces (BCI), with existing electronics covering a wide range of domains from artificial intelligence (AI) to the Internet of Things (IoT). However, the limitation in decoding MI-EEG signals has restricted the further development of the related Consumer Electronics (CE) industry. To address this problem, this paper proposes an attention-based multiscale spatial-temporal convolu-tional network (AMSTCNet). First, a multi-branch structure is designed to extract high-dimensional spatial-temporal represent-tations at different scales. Second, Squeeze-Excite-Compress (SEC) blocks are proposed to highlight feature responses within a single scale and weighted to fuse these features to reduce information redundancy. Finally, the attention-based temporal convolutional network is used to obtain deep temporal information of the signal to dynamically fuse features at different scales. In addition, the AMSTCNet model is an end-to-end decoder using raw EEG signals as input. We evaluated the decoding performance of the AMSTCNet model using the BCI IV 2a dataset and the High Gamma dataset, and achieved recognition accuracies of 87.55% and 96.35%, respectively. Compared with existing methods, our method achieves satisfactory decoding performance and can greatly facilitate the application of BCI technology in CE. IEEE",TextMining
"In the semiconductor industry, protecting Integrated Circuits (IC) throughout the IC supply chain has become a major concern. In-depth research has been done on logic encryption, split manufacturing, and layout camouflaging to safeguard ICs against attacks at various stages of the supply chain. In this work, we introduce a hybrid, method called Hybrid Shielding (which amplifies the power of camouflaging and logic locking) to protect ICs at each stage of the supply chain, including the foundry, the testing facility, and the end user. We take advantage of the spin-based device, called the Giant Spin-Hall Effect (GSHE) switch, multi-functionality, post-fabrication reconfigurability, and run-time polymorphism to make dynamic camouflaging resistant to SAT-based attacks and test-data mining-based attacks. These characteristics are not available to designers in CMOS. We define two metrics for circuit nodes: stability and weight. Hybrid Shielding replaces all of the selected gates with polymorphic gates. It uses a simulator to ascertain the internal state of the selected nodes. The camouflaged internal state will be used to corrupt the functionality of the primary outputs. The resulting locked circuit has high output corruption rates and is resilient to the SAT attack, Hack Test, as well as several other attacks. These results are demonstrated experimentally using standard benchmark circuits.  © ; 2023 The Authors.",TextMining
"Semantic geospatial applications, such as geographic question answering, have benefited from knowledge graphs incorporating information regarding geographic entities and their relations. However, one of the most critical limitations of geographic knowledge graphs is the lack of semantic relations between geographic entities. The most extensive knowledge graphs specifically tailored to geographic entities are extracted from unstructured sources, with these graphs often relying on datatype properties to describe the entities, resulting in a flat representation that lacks entity relationships. Therefore, predicting links between geographic entities is essential for advancing semantic geospatial applications. Existing neural link prediction methods for knowledge graphs typically rely on pre-existing entity relations, making them unsuitable for scenarios where such information is absent. In this paper, we tackle the challenge of predicting spatial links in sparsely interlinked knowledge graphs by introducing two novel approaches: supervised spatial link prediction (SSLP) and unsupervised inductive spatial link prediction (USLP). These approaches leverage the wealth of literal values in geographic knowledge graphs through spatial and semantic embeddings. To assess the effectiveness of our proposed methods, we conduct evaluations on the WorldKG geographic knowledge graph, which incorporates geospatial data extracted from OpenStreetMap. Our results demonstrate that the SSLP and USLP approaches substantially outperform state-of-the-art link prediction methods. © 2023, The Author(s).",TextMining
"Vehicle-cargo matching is a key task in freight O2O platform, which involves the complex interactions of drivers, vehicles, cargos, cargo owners and environmental context. Many existing works mainly study the matching of vehicle routing problems, the matching based on the credit evaluation of both drivers and cargo owners, and the matching based on game theory from the perspective of management. Since the freight O2O platform is also the producer of big data, this study proposes a driver CTR prediction model for vehicle-cargo matching task from the perspective of data mining. Specifically, we first use the bottom-level attention network to model fine-grained preferences in driver historical behaviors, such as route interest and search interest, as well as fine-grained preferences such as vehicle type and vehicle length interest, and route interest in cargo owner historical behaviors. Then, the driver basic profile vector, cargo owner basic profile vector, cargo description vector, driver preferences vector and cargo owner preferences vector are feeded into the neural network composed of two deep components for feature interactions learning, and then a top-level attention network is used to learn the influencing factors of different information on the vehicle-cargo matching task. Finally, a multi-classifier is used for matching prediction. We conduct comprehensive experiments on real dataset, and the results show that, compared with the existing solutions, considering user preferences and adopting deep components collaborative modeling can improve the performance of vehicle-cargo matching to a certain extent, which verifies the effectiveness and superiority of the proposed model. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Student academic performance can be affected by social, economic, and educational factors. Many research works studied these factors applying to different levels in the educational organizations’ models. The importance spans giving professional educational advice to vulnerable students, supporting the student’s development of special education-related skills, and encouraging students to handle their education challenges. For educational organizations, dealing with pandemics and other obstacles has proven to be essential for education sustainability. One way is to be proactive and use the power of exploring and discovering educational data to predict students’ performance and attitude. Mining educational data can benefit from Business Intelligence (BI) in visualizing, organizing, and extracting insights for student’s performance. Educational Data Mining (EDM) is used in this research to predict students' performance. A novel data fusion framework is introduced for Business Intelligence using educational data mining. This study aims to show the techniques that predict students' performance and the most effective methods for each of them. The proposed framework used the advantage of business intelligence concepts and tools to highlight the metrics providing better statistical and analytical understanding. © 2023, American Scientific Publishing Group (ASPG). All rights reserved.",TextMining
"In recent years, land subsidence issues have become relatively prominent in the northern plain area of Anhui province, and there is lack of quantitative research on the driving forces of regional land subsidence. In order to further investigate the developmental characteristics of subsidence disasters and provide scientific, this paper takes Bozhou City as an example. Based on 62 scenes of Sentinel-1 data, SBAS-InSAR technology is employed to obtain the spatial-temporal distribution characteristics of land subsidence from October 2021 to October 2022. Additionally, a geographic weighted regression model is applied to explore the main driving factors of land subsidence in Bozhou city. The research results indicate: (1) The main subsidence rate in Bozhou City ranges from 5 to 30 mm/year,with an average subsidence rate of 5.7 mm /year. (2) The most serious subsidence area is located north of Gongji Temple Town in Woyang County, with an amplitude of 84.3 mm/year, mainly caused by coal mining. In non-coal mining subsidence areas, the maximum subsidence rate is 25.8 mm/year, located in the northeast of Qiaocheng District. (3) The contribution order of various driving factors to ground subsidence is as follows: fluctuation of deep water level, fluctuation of middle-deep water level, burial depth of middle-deep groundwater, burial depth of deep groundwater, GDP per unit area, thickness of loose layer, road density, and population density. The study results can provide basic data support for geological disaster prevention and control. © 2019 Chinese Journal of Geological Hazard and Control. All rights reserved.",TextMining
"With the abundant emergence of remote sensing (RS) data sources, multimodal remote sensing observation has become an active field. Extracting valuable information from multimodal data has the potential to make a significant contribution to applications such as urban planning and monitoring. However, existing studies are deficient in extracting spectral and spatial features from hyperspectral (HS) remote sensing data. Meanwhile, the method of fusing multimodal features has limitations and poses a challenge to the convergence of the model loss function, which increases the complexity of the network model optimization process. Therefore, this article proposes an adaptive multiscale spatial-spectral enhancement network for classification of hyperspectral and light detection and ranging (LiDAR) data called AMSSE-Net. First, we perform deep mining of spectral features in hyperspectral images (HSIs) by the involution operator. The main idea is to take full advantage of the involution operator in characterizing spectral features by using the property that the convolution kernel shares the feature channels within the group. Furthermore, the multibranching approach is used to extract the multiscale information, and then the spectral-spatial features are formed with the strategy of hierarchical fusion. Meanwhile, we employ three-layer convolution for extracting shallow features from LiDAR data, offering supplementary information. Finally, we propose the 'adaptive feature fusion module (AFFM),' an innovative and comprehensive mechanism designed for the fusion of features from diverse sources in multisource data fusion. These dynamically assigned weights guide the selection of the optimal model, which is determined by the joint loss across the three methods, ultimately leading to the generation of an accurate prediction map. This approach not only helps to deeply explore the spectral spatial information in the hyperspectral data, but also fuses the hyperspectral information effectively with the elevation information from the LiDAR data. The expression ability of model features is rapidly improved by adaptive weighting, which in turn enhances the performance and generalization ability of the model. Compared with some existing methods, extensive experiments on three popular HSI and LiDAR datasets show that our proposed AMSSE-Net can achieve better classification performance. The codes will be available at https://github.com/haofeng0003/AMSSE-Net, contributing to the RS community.  © 1980-2012 IEEE.",TextMining
"Due to their many benefits, decision trees are extensively utilized to solve a variety of classification problems in the real world. Consequently, creating efficient and effective decision trees remains a common challenge for researchers in the fields of machine learning and data mining. In the literature, various decision tree algorithms with different attribute selection criteria are introduced. Although the currently available decision tree algorithms achieve different performances, none of them can produce optimal decision trees for a range of data sets. In this study, the efficacy of two traditional decision tree techniques is contrasted with the efficacy of two more recent decision tree approaches. On eleven real-world data sets, the four methods are compared in terms of four evaluation metrics: classification accuracy, tree depth, leaf nodes, and tree construction time.  © 2023 IEEE.",TextMining
"As one of the important pillars of China's industrial sector, the mining industry is critical to China's modernization and energy security. Based on China's provincial panel data, this paper collects the information on government's environmental management and estimates the impact of environmental regulation on China's mining industry's energy and carbon performance. The study further collects information on the industries' technological innovation and analyzes the technological innovation's moderating effect on environmental regulation. The research results indicate that the interconnection between the intensity of environmental regulations and the energy and carbon performance of the mining industry is inverted U-shaped, and mining enterprises with high levels of technological innovation have better adaptability when facing pressure from external environmental regulations. Regarding policy recommendations, it is imperative that the government should enhance the environmental policy framework, develop clean energy, and incentivize mining firms to advance technological innovation. © 2023 IGI Global. All rights reserved.",TextMining
"We investigate the k-closest pair problem in high dimensions, that is finding the k≥ 1 closest pairs of points in a set S⊆ X in a metric space (X, dist ). This is a fundamental problem in computational geometry with a wide variety of applications, including network science, data mining, databases, and recommender systems. We propose an exact algorithm with a controllable failure probability, thus allowing the user to specify the desired recall. Our algorithm has expected subquadratic running time under mild assumption on the distance distribution, relying only on the existence of a Locality Sensitive Hash family for the metric at hand. We complement our theoretical analysis with an experimental evaluation, showing that our approach can provide solutions orders of magnitude faster than current state-of-the-art data structures designed for specific metrics. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"The mining of patient data in the health care industry is becoming an increasingly important field because of the direct effect it has on the lives of patients. In the field of medicine, one use of data mining is the early diagnosis of medical diagnostic conditions. However, extracting information from medical records is a laborious process that involves a lot of time and effort. Communities that are dominated by females have an elevated risk of developing breast cancer. Even though mammography is one of the most common ways to use computer-assisted diagnostics, there is still a chance that breast cancer will not be found even if it is one of the most common ways to find and screen for the disease. This indicates that just thirty percent of breast cancers are diagnosed at the appropriate time. Digital image pre-processing includes grayscale-to-binary conversion, noise reduction, and character separation. Most picture recognition algorithms employ statistical, syntactic, and template matching. Neural networks and support vector machines have enabled recent photo identification advances. This article discusses the second stage of the pre-processing procedure, which is adding a filter to the image after it has been segmented in order to make it seem more appealing. It works to identify the area of interest and improve the image by removing the breast border in order to apply filtering algorithms. The breast image’s edge is reconstructed using morphological processes in the segmentation method that has been proposed, and breast masses are found by subtracting the two images. In addition, a modified bi-level histogram and homomorphic filters were used in order to improve the image’s quality by reducing noise and enhancing contrast. © 2023 Tehnicki Glasni. All rights reserved.",TextMining
"This work aims to use the chatGPT algorithm to analyze and summarize cases in medical literature of the Song Dynasty, understand the clinical practice experience of ancient Chinese medicine, and provide historical reference for the clinical application and research of modern Chinese medicine. Firstly, the application of Artificial Intelligence (AI) in medicine is explained through literature research. Secondly, the prescription recognition technology related to AI is introduced, and a method combining supervised learning and semi-supervised learning for prescription entity recognition is proposed. Combined with chatGPT technology, medical data mining is carried out to obtain information and knowledge of medical research in the Song Dynasty. chatGPT is applied to the identification of ancient Chinese medical prescriptions and the analysis of case data. The results show that: (1) The machine classifier performs well in classifying different flavor compounds, effective and ineffective prescriptions can be distinguished, and the accuracy increases with the increase of samples. (2) Data mining reveals the differences in disease stages, the primary and secondary contradictions in patients&#x2019; bodies, and the primary and secondary differences in drug use. (3) Frequency statistics show that warm drugs account for 45.46%, confirming that warm drugs are the main ones for treating phlegm. Therefore, it is recommended to use chatGPT as an auxiliary tool in medical-related analysis and combine it with professional medical knowledge and clinical practice for comprehensive judgment and decision-making. Ancient medical prescriptions can be better identified, and case data can be analyzed by combining chatGPT technology in AI. It can well support ancient medicine study and lay a solid foundation for developing modern medical information data warehouse. Authors",TextMining
"Student desertion is one of the main social problems around the world. Consequently, to propose this issue, there are several studies under different circumstances or scenarios. For this reason, this research creates four datasets, which take the common variables of easy extraction to the academic process. These variables have been grouped under common characteristics such as general student profile information, admission process information, financial information, academic information, and academic performance information. Thus, the method used in this research is analytical, since it is intended to analyze each subset of data in order to identify the variables with the greatest impact on university dropout. As a result, have been identified the variables with impact on university dropout, For this, a neural network model has been implemented using Python and Keras. In conclusion, the research evidence that academic information is mostly related to college dropout related to university dropout, while admission, financial, and student profile information are not significant in detecting or predicting college dropout. However, with the data obtained, it has been shown that the prediction is not early but in many cases late, since the notes would have already been delivered to students. Therefore, future research is intended to identify the causes that originate academic problems. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"This article aims to introduce the terms NI-Natural Intelligence, AI-Artificial Intelligence, ML-Machine Learning, DL-Deep Learning, ES-Expert Systems and etc. used by modern digital world to mining and mineral processing and to show the main differences between them. As well known, each scientific and technological step in mineral industry creates huge amount of raw data and there is a serious necessity to firstly classify them. Afterwards experts should find alternative solutions in order to get optimal results by using those parameters and relations between them using special simulation software platforms. Development of these simulation models for such complex operations is not only time consuming and lacks real time applicability but also requires integration of multiple software platforms, intensive process knowledge and extensive model validation. An example case study is also demonstrated and the results are discussed within the article covering the main inferences, comments and decision during NI use for the experimental parameters used in a flotation related postgraduate study and compares with possible AI use. © Wroclaw University of Science and Technology",TextMining
"The Apriori and FP-growth algorithms have gained widespread popularity in various business applications. In the retailing industry they are widely used for market-basket data analysis and frequent pattern mining to gain valuable insights into customer purchasing behaviour. In this study, we conducted a comprehensive analysis of these two prominent association rules mining algorithms, utilizing six benchmark datasets from the UCI machine learning repository. Our investigation involved a thorough comparison of the execution time and the number of rules generated by both algorithms. Execution time is measured once by varying the support levels and next by varying the number of transactions and the support levels. Number of rules generated is estimated by varying the support levels of the rules. Through our rigorous experimentation, we derived insightful inferences that elucidated the utility of association rule mining in the retail industry. Moreover, we employed the Big-O method to compare the performance of the two algorithms and formulated a theorem that established FP-growth as Big-O of Apriori, substantiating the differences observed in their performance. © 2023 School of Science, IHU. All Rights Reserved.",TextMining
"User reviews contain many key phrases that are crucial for business understanding, but they are often obscured by the sheer volume of reviews. Extracting key phrases from user reviews could help to understand what users are concerned about and provide timely improvement suggestions. Current pattern-based methods for target phrase extraction usually analyze reviews at a coarse-grained level, making the extracted topics unfocused and useless. Hence, in order to address this issue, we proposed a fine-grained analysis approach (KFEA) to extract, cluster, and visualize key phrases from e-commerce reviews. In order to fully utilize the relevant information from comments, KFEA fuses the information like categories and ratings from a large volume of user reviews, and then extracts key phrases with the help of a pre-trained model. A method is also designed to cluster and visualize the extracted key phrases for business understanding. Our evaluation on 6,088 reviews from 6 products shows that KFEA can effectively extract key phrases and perform clustering and visualization. In particular, KFEA achieved an precision of 76.6% and a recall of 81.8% in extracting key phrases from manually annotated data. KFEA’s cross-categories effectiveness is also validated on 16,772 reviews from products like mobile phones, laptops, and furniture. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Adaptive protection schemes (APS) have gained prominence in maintaining the integrity of overcurrent relay (OCR) settings in reconfigurable networks. While many APSs rely on supervisory control and data acquisition systems, they are very expensive and expose the system to vulnerabilities arising from communication failures. Recent studies have proposed communication-less APSs to address this issue by relying on data-mining algorithms equipped with real-time fault voltage-current information. However, the OCR settings are computed and updated as the fault occurs, inevitably causing prolonged OCR tripping in these schemes. This contradicts with the APS&#x0027; original purpose of minimizing OCR operation time and consequent equipment damage. Thus, a load flow-based APS that addresses this flaw is proposed to achieve primary-backup OCR coordination in a highly reconfigurable system. Network topologies are first categorized into OCR setting groups via clustering analysis. A nonparametric probability model is developed to evaluate the probability of network topologies at a measured load flow. Then, a machine learning model deployed in a local controller selects the correct setting groups based on the calculated probabilities. The proposed APS achieves high accuracies and low OCR operating times in the IEEE 33-bus test distribution system under varying load conditions and network topologies. IEEE",TextMining
"Process mining is a field that focuses on extracting insights from end-to-end business processes. In traditional process mining, techniques are applied using batch processing in an offline setup. However, online process mining, or stream process mining, offers the potential to analyze a stream of events as they occur, enabling real-time monitoring of business processes. This paper presents a systematic literature review that highlights online process mining techniques and categorizes them based on their characteristics. The review provides a comprehensive overview of the field and contributes to a better understanding of online process mining techniques and how they can be used to analyze and monitor business processes in real-time. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"Mobile crowdsensing (MCS) is a new mode for collecting and mining data and intelligent decision-making with mobile intelligent devices. The key to the high performance of MCS is the efficient method of task allocation. The traditional algorithm (greedy algorithm or ant algorithm) assumes that workers and tasks are static. It’s not fit for the scene where the position and time of workers and tasks change continuously. In addition, the existing methods usually make decisions by the central server based on the collected information, which usually leads to leakage of workers’ privacy. Therefore, we propose a task allocation method based on deep reinforcement learning (DRL) with privacy protection. Firstly, aiming to maximize the two-way benefits of workers and platforms and realize Nash equilibrium, the task allocation is modeled as a dynamic programming problem of multi-objective optimization. Secondly, the model based on proximal policy optimization (PPO) of DRL for training and learning model parameters is proposed. Finally, we use the local differential privacy method to add random noise to the sensitive information of workers to protect privacy. The central server trains the whole model to obtain the optimal allocation strategy. In this paper, the astringency, revenue and task cover rate are experimentally evaluated. The results show that the proposed method has significant improvement in different indexes, and can protect the privacy of workers, compared with the traditional methods and other DRL based methods. © 2023 Science Press. All rights reserved.",TextMining
"Drug discovery is a major focus of modern research, and predicting drug-target interactions is one of the strategies to facilitate this research process. Traditional laboratory methods have long time cycles and are relatively costly, so the use of high-precision virtual screening is essential. Previous virtual screens have only considered the sequence structure of the drug or the graph structure of the drug, without considering the role of the drug subgraph structure. Therefore, this paper adopts a method for extracting drug subgraphs and designs a strategy for extracting drug subgraph fingerprints. Then, the fingerprint vector data of the drugs are trained by the graph neural network to produce drug information vectors containing the spatial structure of the drug subgraph. Finally, the subgraph attention mechanism is used to update the information on protein targets, facilitating the model to extract more information about the target site. The experimental results show that the model can predict drug-target interactions well, outperforming the state-of-the-art model in all metrics. And it is also effective in both classification prediction and affinity regression prediction. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"The primary goal of the proposed study is to measure a student's Emotional Quotient (EQ) for job placement and to correlate the EQ with the ability of the student to survive in the industry. EQ is expected to be influenced by several demographic factors such as age, gender, academic performance, location, parental education, parental income, and family structure. However, the previous studies did not consider these factors. To validate the correlation of demographic factors with EQ, developed a data set considering the above-mentioned factors followed by designing several Machine Learning (ML) based ensemble techniques. Ratings for each parameter ranged from 1 to 10. Based on that, evaluating the results to choose the best approach. The primary goal of this inquiry was to identify the factors other than academic performance that prompt a student to get hired by a company more quickly. The final grade for all students is determined by ascertaining a student's emotional and intellectual ability. The fundamental contribution of this study is the establishment of a student's emotional calculation, along with an explanation of how to evaluate it, the advantages of such a concept, its psychometric validity, and its difficulties. The background and variety of validation studies will show how measurements can accurately and rigorously evaluate the behavioral level of EQ.  © 2013 IEEE.",TextMining
"There is a growing interest in the optimization of vehicle fleets management in urban environments. However, limited attention has been paid to the integrated optimization of electric taxi fleets accounting for different operations as well as complex spatiotemporal demand dynamics. To this end, this study develops a real-time recommendation framework based on deep reinforcement learning (DRL) for electric taxis (E-taxis) to improve their system performance with explicit modeling of multiple vehicle actions and varying travel demand across space and over time. Spatiotemporal patterns of urban taxi travels are extracted from large-scale taxi trajectories. Spatiotemporal strategies are proposed to coordinate E-taxis’ repositioning and recharging with optimized recommendation for next destinations and charging stations. A spatiotemporal double deep Q-network (ST-DDQN) is embedded in the DRL framework to maximize the daily profit. A prototype real-time recommendation system for E-taxis is implemented for the decision-making of E-taxi drivers and sensitivity analyses are carried out. The experimental results in Shenzhen, China suggest that the proposed framework could improve the overall performance. This study will benefit the promotion of connected E-taxis and the development of clean and smart transportation. © 2023 Informa UK Limited, trading as Taylor & Francis Group.",TextMining
"To fuse and mine multi-source and multi-modal data in monitoring a complex industrial processes effectively, a new dimensionality reduction method called Multiple Collaborative Preserving Projection (MCPP) has been proposed. MCPP is innovative in sense that it is capable of extracting and preserving the correspondences of heterogeneous data in temporal series and spatial structure. In temporal series, both of local and global correlations of raw datasets are preserved; in spatial structure, local structure of data is extracted based on capture global structure and a data projection method is integrated to reduce adverse impact of industrial noise in raw data. Moreover, the collaboration among multiple views is achieved by specifying the direction in projecting to subspaces; this maintains the consistency of common features in multiple views for a lower-dimensional subspace. The effectiveness of MCPP has been verified in the case studies of the Tennessee Eastman process (TEP) and an industrial process to monitor the conditions of tuyere raceway in an actual blast furnace. IEEE",TextMining
"G protein-coupled receptor 56 (GPR56/ADGRG1) is a multifunctional adhesion GPCR involved in diverse biological processes ranging from development to cancer. In our earlier study, we reported that GPR56 is expressed heterogeneously in glioblastoma (GBM) and is involved in the mesenchymal transition, making it a promising therapeutic target (Ganesh et al., 2022). Despite its important role in cancer, its mechanism of action or signaling is not completely understood. Thus, based on transcriptomic, proteomic, and phosphoproteomic differential expression data of GPR56 knockdown U373-GBM cells included in our above study along with detailed literature mining of the molecular events plausibly associated with GPR56 activity, we have constructed a signaling pathway map of GPR56 as may be applicable in mesenchymal transition in GBM. The map incorporates more than 100 molecular entities including kinases, receptors, ion channels, and others associated with Wnt, integrin, calcium signaling, growth factors, and inflammation signaling pathways. We also considered intracellular and extracellular factors that may influence the activity of the pathway entities. Here we present a curated signaling map of GPR56 in the context of GBM and discuss the relevance and plausible cross-connectivity across different axes attributable to GPR56 function. Graphical abstract: GPR56 signaling and mesenchymal transition [Figure not available: see fulltext.] © 2023, The International CCN Society.",TextMining
"With the growing concerns on data security and user privacy, a decentralized mechanism is implemented for federated data mining (FDM), which can bridge data silos and collaborate diverse devices in ubiquitous IoT (Internet of Things) systems and services to extract global and shareable knowledge, i.e., encoded in deep neural networks (DDNs). Moreover, compared with FDM in synchronous mode, asynchronous FDM (AFDM) is more suitable to accommodate devices with diversified computing resources and distinguishable working statuses. However, as AFDM is still in its infancy, how to harness heterogeneous resources and biased knowledge of learning participants within the asynchronous context remains to be addressed. Such that, this paper proposes an adaptive and integrated mechanism, named AiFed, in which, a layer-wise optimization of AFDM is implemented based on the integration of two dedicated strategies, i.e., an adaptive local model uploading strategy (ALMU), and an adaptive global model aggregation strategy (AGMA). As shown by the evaluation results, AiFed can outperform five state-of-the-art methods to reduce communication costs by about 61.76&#x0025; and 56.88&#x0025;, improve learning accuracy by about 1.66&#x0025; and 3.05&#x0025;, and accelerate learning speed by about 22.16&#x0025; and 37.81&#x0025; under IID (independent and identically distributed) and Non-IID settings of four standard datasets, respectively. IEEE",TextMining
"In the rapidly evolving digital health landscape, technology plays a pivotal role in transforming the healthcare industry. With the exponential growth of data, uncovering valuable insights has become a daunting task. In today&#x0027;s data-driven world, healthcare businesses must leverage emerging technologies to stay informed about trends in their field. This research article presents a novel approach to deriving business insights in digital health enabled by technology, including artificial intelligence, and other cutting-edge advancements. We propose a methodology that utilizes news mining techniques and the global data on events, location, and tone database as the primary data source. By employing natural language processing, we developed a practical way of extracting relevant insights from vast amounts of public data. We implemented named-entity recognition (NER) enriched with the DBpedia knowledge base and relationship extraction. In addition, we leveraged graph analytics to identify and analyze the most significant concept relationships within the text corpus and their evolution in time. By integrating these advanced techniques, healthcare businesses can extract actionable insights from public datasets, empowering them to stay abreast of emerging trends and advancements in digital health, such as telehealth, precision medicine, or medical imaging. Authors",TextMining
"This paper describes a project carried out between the University and a course provider company, where an early dropout prediction system has been developed in fully online private higher education. The aim is to be able to predict students at risk of dropping out as soon as possible in order to help them and put them back on success track again. A classical Cross-Industry Standard Process for Data Mining development methodology has been employed over anonymized and unbalanced data from 16,673 students enrolled in 517 fully online courses. The project objective is to determine both the optimal approach for grouping the data and to identify the most accurate classification algorithm and balancing method for predicting dropout. The experiments conducted showed that grouping the data into cumulative periods/quartiles and utilizing the XGBoost machine learning algorithm with SMOTE data balancing method obtained the best results with the highest AUC and True Positive prediction values. However, the approach of grouping the data on a weekly basis and employing the LSTM deep learning algorithm with weights obtained the highest values in F-1 measure and True Negative indicator. The latter approach was finally the selected one for being implemented in the early prediction system. © 2023 CEUR-WS. All rights reserved.",TextMining
"Knowledge Graphs are a widely used method to represent relations between entities in various AI applications, and Graph Embedding has rapidly become a standard technique to represent Knowledge Graphs in such a way as to facilitate inferences and decisions. As this representation is obtained from behavioural data, and is not in a form readable by humans, there is a concern that it might incorporate unintended information that could lead to biases. We propose EXTRACT: a suite of Explainable and Transparent methods to ConTrol bias in knowledge graph embeddings, so as to assess and decrease the implicit presence of protected information. Our method uses Canonical Correlation Analysis (CCA) to investigate the presence, extent and origins of information leaks during training, then decomposes embeddings into a sum of their private attributes by solving a linear system. Our experiments, performed on the MovieLens-1M dataset, show that a range of personal attributes can be inferred from a user's viewing behaviour and preferences, including gender, age and occupation. Further experiments, performed on the KG20C citation dataset, show that the information about the conference in which a paper was published can be inferred from the citation network of that article. We propose four transparent methods to maintain the capability of the embedding to make the intended predictions without retaining unwanted information. A trade-off between these two goals is observed. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",TextMining
"In the field of data mining, machine learning (ML) has been utilized in the search for solutions to various problems. One widely used model process for ML application development is the Cross Industry Standard Process for Data Mining (CRISP-DM). On the other hand, Scrum has emerged as the most popular agile method for software development in recent years. In this research, we proposed an ML application development guideline for data mining by incorporating relevant Scrum concepts into CRISP-DM. The process involves analyzing CRISP-DM and the development situation through interviews with experienced ML software developers. Furthermore, an analysis of the implementation of Scrum concepts in CRISP-DM is conducted. The proposed guideline is represented in Essence and tested through a case study, qualitative evaluation, and evidence map. The evidence map is used to analysis the importance of proposed guideline components is examined. The results indicate that the proposed guideline can be utilized to assist in the development of ML software. copy; 2023 IEEE. © 2023 IEEE.",TextMining
"Neural ordinary differential equations (NODEs) have achieved remarkable performance in many data mining applications that involve multivariate time series data. Its adoption in the data-driven discovery of dynamic systems, however, was hindered by the lack of interpretability due to the black-box nature of neural networks. In this study, we propose a simple yet effective NODE architecture inspired by the highly successful generalised additive models. Our proposed model combines linear and nonlinear components to capture interpretable evolution rules with only a marginal loss of model expressiveness. Experiments show that our model can effectively recover interactions among variables in a complex dynamic system from observation data. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Key Information Extraction (KIE) is the process of extracting important data in a text or an image, such as the content of a military document. One popular method for performing KIE is by utilizing pattern matching with Regular Expression on texts from documents. However, this method is not efficient due to the fixed nature of RegEx, where we need an exclusive RegEx rule to extract certain data entities. To solve this flexibility issue, a deep learning method with Named Entity Recognition (NER) has been proposed. NER is applied to the scanned document using a transformer-based model called XLM-RoBERTa. This model has been chosen for the development of the KIE module as it supports Indonesian and has demonstrated good accuracy in previous studies. The model has been trained on a military document dataset in the Indonesian language, achieving an f1-score of 86.55%. This method has also been proven to be flexible, as the model can extract the same entities across different document types. © 2023 IEEE.",TextMining
"Land surface deformation created by mining activities can have negative impacts on the environment. Measuring them can be a tool for managing the environmental impacts of mining. Synthetic Aperture Radar Interferometry is a remote sensing method for measuring deformations. The main aim of this research is to investigate the deformation phenomenon on a region scale and extend our understanding of it to all mining deformation areas across the country. This paper used Small Baseline Subset Interferometric Synthetic Aperture Radar technology to obtain deformations information in the Sangan mine based on mining activities. We used 48 scenes of Single Look Complex (SLC) data acquired by the Sentinel-1A, C-band of the European Space Agency descending orbit paths from 2014 to 2020. The Time Series of SBAS results show that the deformation velocity rate is about ¡20 to ¡35 mm/yr, and the displacement is attributed to approximately ¡120 mm in the Line of Sight direction. The main deformation zone is situated in the mining area on the main alluvial fan. This study presented the relationship between deformations and mining activity's effects on the ground. Mining activities were accompanied by ground deformation in the mining area: the ground deformation is exacerbated by the increasing mining quantity, and as a result will cause erosion, flood, and other geomorphologic phenomena in the area. We compared the results of the SBAS technique with leveling data for validating the data of SBAS. Their comparison shows approximately suitable agreement with the results of SBAS. © Central Mining Institute, Katowice, Poland.",TextMining
"Extracting road networks from remote sensing images holds critical implications for various applications including autonomous driving, path planning, and road navigation. Despite its importance, the task remains arduous due to the complex backdrops in remote sensing imagery, intricate road geometries, and the challenges arising from vegetation and structural obstructions. To address these multifaceted issues, we introduce a specialized model for road extraction in remote sensing images, termed DRCNet. This model employs a pre-trained DenseNet-121 as its encoder and is fortified with both Recurrent Criss-Cross Attention (RCCA) and Convolutional Block Attention Module (CBAM). RCCA facilitates the capture of global contextual information across all pixels, thereby enriching the model's understanding of global image relationships. Simultaneously, CBAM is integrated within the skip connections to optimize the network's focus on significant road features. Comprehensive experiments conducted on both the DeepGlobe Road and Massachusetts Road datasets substantiate that DRCNet outperforms other benchmark models in road detection tasks.  © 2013 IEEE.",TextMining
"Causal Reinforcement Learning (CRL) is an emerging field where two essential areas for the development of artificial intelligence are integrated. Existing works in the area have shown how causality can contribute to mitigate some of the limitations of reinforcement learning (RL), ranging from data-inefficiency, lack of interpretability, and long learning times, among others. However, how to use reinforcement learning to support causal discovery (CD) has so far been less explored. In this article, we introduce CARL, a Causality-Aware Reinforcement Learning framework for simultaneously learning and using causal models to speed-up the policy learning in online Markov decision process (MDP) settings. In a synergistic way, our method alternates between: (i) (RL for CD), where it promotes the selection of actions to obtain better causal models in fewer episodes than traditional methods of obtaining data in RL, (ii) (CD), where a score-based algorithm is used to learn causal models and (iii) (RL using CD), where the learned models are used to select actions that speed up the learning of the optimal policy by reducing the number of interactions with the environment. Experiments in simulated environments show that our method achieves better results in policy learning than traditional model-free and model-based algorithms while it is also able to learn the underlying causal models. We also demonstrate how the learned causal models can be directly transferred to a similar task of greater complexity, significantly reducing the number of episodes required to learn an optimal policy Finally, the method's scalability to high-dimensional states, where the action-value function needs to be represented with deep neural networks, was verified.  © 2013 IEEE.",TextMining
"In modern society, environmental sustainability is a top priority as one of the most promising entities in the new energy sector. Electric vehicles (EVs) are rapidly gaining popularity due to their promise of better performance and comfort. Above all, they can help address the problem of urban air pollution. Nonetheless, lithium batteries, one of the most essential and expensive components of EVs, have posed challenges, such as battery aging, personal safety, and recycling. Precisely estimating the remaining useful life (RUL) of lithium battery packs can effectively assist in enhancing the personal safety of EVs and facilitating secondary trading and recycling in other industries without compromising safety and reliability. However, the RUL estimation of batteries involves many variables, and the operating conditions of EV batteries are highly dynamic as they change with the environment and the driving style of the users. Many existing methods exist to estimate the RUL based on batteries’ state of health (SOH), but only some are suitable for real-world data. There are several difficulties as follows. Firstly, obtaining data about battery usage in the real world takes work. Secondly, most of these estimation models must be more representative and generalized because they are trained on separate data for each battery. Lastly, collecting data for centralized training may lead to a breach of user privacy. In this article, we propose an RUL estimation method utilizing a deep learning (DL) approach based on long short-term memory (LSTM) and federated learning (FL) to predict the RUL of lithium batteries. We refrain from incorporating unmeasurable variables as inputs and instead develop an estimation model leveraging LSTM, capitalizing on its ability to predict time series data. In addition, we apply the FL framework to train the model to protect users’ battery data privacy. We verified the results of the model on experimental data. Meanwhile, we analyzed the model on actual data by comparing its mean absolute and relative errors. The comparison of the training and prediction results of the three sets of experiments shows that the federated training method achieves higher accuracy in predicting battery RUL compared to the centralized training method and another DL method, with solid training stability. © 2023 Chen et al. Distributed under Creative Commons CC-BY 4.0. All Rights Reserved.",TextMining
"Emoji symbols are widely used in digital communication to express emotions, feelings, and moods. However, their potential for structuring and visualizing ctional and real life empirical concepts has not been fully explored. In this paper, we propose a novel technology of using emoji symbols to create and analyze digital representations of literary texts and cultural icons. We apply our technology to two case studies: the poetry of the twentieth century Cuban poet José Ángel Buesa and the image of Borys Grinchenko as a patron of the Borys Grinchenko Kyiv University. We use the Emoji Maker program to construct emoji signs that capture the essence and sensuality of the lyrical images and concepts. We also use the Voyant Tools web application to visualize the corpus data based on text mining and keyword analysis. We demonstrate that our technology enhances the understanding and appreciation of literary texts and cultural icons by activating students’ thinking, developing creative attention, and fostering comprehensive digital literacy. Our technology oers a new model of digital presentation of ction and culture that relies on the poly-functional emoji ousia and the polylaterial metalinguistic multimodality of the sign meaning. Our technology also poses some challenges, such as the technical limitations of the Emoji Maker platform, the subjective interpretation of emoji symbols, and the ethical issues of using emoji in academic contexts. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",TextMining
"Data cleaning is an important process for improving the quality of decision-making information. One of today's popular cleaning tools is data mining techniques. In this paper, we focused on using data mining classification algorithms to resolve missing values in medical purchasing databases. To serve this purpose, the predictive performance of four different classifiers: Decision Tree, Naïve Bayes, K-Nearest Neighbor, and Support Vector Machine (SVM) were compared in this study. We used 2,311 medical data records from procurement database in Thailand between July 2019 and December 2019 in the experimental process. We also discussed the function of feature selection and test options that support analysis to improve model performance. The results showed that the SVM algorithm outperforms with a maximum accuracy of 89.61%. Additionally, we discussed the strengths and weaknesses of these data mining techniques for data cleaning and future research. © 2023 Published by ISRES Publishing: www.isres.org.",TextMining
"Deep-learning-based intelligent diagnosis is a popular method to ensure the safe operation of rolling bearings. However, practical diagnostic tasks are often subject to a lack of labeled data, resulting in poor performance in scenarios with insufficient training samples. Moreover, conventional intelligent diagnosis methods suffer from a deficiency in interpretability. In this article, an auto-embedding transformer (AET) method is proposed to implement the interpretable few-shot fault diagnosis of rolling bearings. First, an auto-embedding module is developed to improve the embedding quality of the signal, which is designed based on a novel asymmetric convolutional encoder&#x2013;decoder architecture. This module can leverage the merits of unsupervised learning in data mining and allow the transformer to learn more diagnostic knowledge from limited data. Second, an attention scoring method is proposed that utilizes positionwise attention to quantify the importance of each signal embedding for diagnosis, thereby interpreting the AET method. Experimental results confirm that, even with limited training samples, the AET method outperforms various comparison methods in terms of recognition accuracy and convergence rate. Furthermore, the attention scores assigned to each embedding facilitate the interpretability of the AET method. IEEE",TextMining
"Attention deficit/hyperactivity disorder (ADHD) is a neurodevelopmental disorder affecting various aspects of life. Some features of the mental disorders affect people's movement patterns. In the recent decade, researchers have paid attention to the analysis of gait and balance pattern using new technological tools, as well as artificial intelligence algorithms. Therefore, the present study aims to propose an intelligent method to identify ADHD in children using gait and balance pattern features extracted from the person’s movements obtained from the skeleton data. Given that designing and extracting effective motor features for diagnosing the aforementioned disorder is the main objective. In the present applied development experimental study, human movement samples related to the gait and balance were recorded in the standard test of perceptual-motor development, from healthy and ADHD-diagnosed children. After preprocessing the data recorded by the Kinect device, effective features for diagnosis are designed and extracted from the appropriate special movement tests. Comparing the features extracted from gait and balance tests by skeleton data, the results indicated that the data based on other types of methods for differentiation into healthy and ADHD groups are in line with those of the present study. The results of diagnosis and separation of healthy children from those with disorders in the different movement tests, standing on the ground with the superior foot, standing on a balance stick with the superior foot, and walking heel forward on a balance stick, to identify ADHD by SVM classification method are 86.4%, 90.2%, and 88.1%, respectively. The obtained significant results have been achieved relying on machine learning-based methods using the effective features obtained from skeleton gait and balance data of children along with analyzing the descriptive statistics of the features of gait and balance tests. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Music plays an important role in our daily life. It can have a powerful effect on our emotions, mental health, and even the community we live in. Although numerous studies have been conducted to prove the great impact music has on humans, few investigations place an emphasis on the exploration of the relationship between music and listener’s sentiment. To this end, we first examined three song demographics: Beats Per Minute, Key, and Length, and six song metrics: Danceability, Energy, Speechiness, Acousticness, Liveness, and Valence of popular songs, and then conducted an empirical study to examine the potential correlation between song demographics/metrics and the sentiment expressed as in written text (such as social media). To accomplish this, we scraped around 20 million tweets referencing the most popular songs from 2018 to 2022 as shown on Spotify’s Top Global chart, as well as the immediate surrounding tweets, and performed a double sentiment analysis on the data. Our study concludes that there exists a significant correlation between all the pairs of song metrics. From the sentiment analysis of tweets, our results indicate that there may not be a significant correlation between the sentiment expressed in tweets of a song’s listeners and the song itself. Our study provides empirical evidence for a deeper understanding of popular songs using data mining techniques. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Data mining reproduces colonialism, and Indigenous voices are being left out of the development of technology which relies on data, such as artificial intelligence. This research stresses the need for inclusion of Indigenous Data Sovereignty and centres on the importance of Indigenous rights over their own data. Inclusion is necessary in order to integrate Indigenous knowledge into the design, development, and implementation of data-reliant technology. To support this hypothesis and address the problem, the CARE Principles for Indigenous Data Governance (Collective Benefit, Authority to Control, Responsibility and Ethics) are applied. We cover how the colonial practices of data mining do not align with Indigenous convictions. The included case studies highlight connections to Indigenous rights in relation to the protection of data and environmental ecosystems, thus stablishing how data governance can serve both the people and the Earth. By applying the CARE Principles to the issues that arise from data mining and neocolonialism, our goal is to provide a framework that can be used in technological development. The theory is that this could reflect outwards to promote data sovereignty generally, and create new relationships between people and data which are ethical as opposed to driven by speed and profit. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"The practical implications of these findings lie in their ability to extract features that benefit coaches, analysts, and stakeholders in optimizing team strategies and predicting match outcomes. While recognizing limitations, such as the reliance on a specific dataset from the Qatar FIFA World Cup 2022 league matches and the exclusion of contextual elements, it is crucial to acknowledge the need for future research to validate and expand upon these findings. This can be achieved by incorporating diverse datasets and considering additional contextual factors during the feature selection process for data analysis. The real-world implications of these studies can be found in their capacity to extract traits that help coaches, analysts, and stakeholders optimize team plans and anticipate match outcomes. While noting limitations such as the use of a single dataset from the Qatar FIFA World Cup 2022 league matches and the removal of contextual components, it is vital to recognise the need for additional research to validate and expand on these findings. This is possible by integrating several datasets and taking additional contextual elements into account during the feature selection process for data analysis.  © 2023 IEEE.",TextMining
"The growing of mining sector is generally accompanied by socio-economic and environmental consequences. Most previous work has either analyzed economic, social, or environmental effects without considering all three dimensions of sustainable development at once. Similarly, the perceptions of the populations living near mining companies are not widely considered in these studies. The objective of this paper is to analyze the populations' perception of the effects of industrial gold mining on environment (noise, air pollution, and land degradation), social (prostitution, banditry, and alcoholism), and household income in Burkina Faso. A probit model is used on a sample of 251 households living near four industrial mining sites. The results show that mining activity has contributed to improve the per capita income of the households surrounding certain industrial mining sites. However, it has contributed to a decline in the quality of life of the households due to noise and air pollution and social problems such as banditry. The government must protect mining areas from banditry and support households with local economic infrastructure to avoid a drop in their income after the mines close. © 2023 United Nations.",TextMining
"Objectives: To automatically label chest radiographs and chest CTs regarding the detection of pulmonary infection in the report text, to calculate the number needed to image (NNI) and to investigate if these labels correlate with regional epidemiological infection data. Materials and methods: All chest imaging reports performed in the emergency room between 01/2012 and 06/2022 were included (64,046 radiographs; 27,705 CTs). Using a regular expression-based text search algorithm, reports were labeled positive/negative for pulmonary infection if described. Data for regional weekly influenza-like illness (ILI) consultations (10/2013–3/2022), COVID-19 cases, and hospitalization (2/2020–6/2022) were matched with report labels based on calendar date. Positive rate for pulmonary infection detection, NNI, and the correlation with influenza/COVID-19 data were calculated. Results: Between 1/2012 and 2/2020, a 10.8–16.8% per year positive rate for detecting pulmonary infections on chest radiographs was found (NNI 6.0–9.3). A clear and significant seasonal change in mean monthly detection counts (102.3 winter; 61.5 summer; p <.001) correlated moderately with regional ILI consultations (weekly data r = 0.45; p <.001). For 2020–2021, monthly pulmonary infection counts detected by chest CT increased to 64–234 (23.0–26.7% per year positive rate, NNI 3.7–4.3) compared with 14–94 (22.4–26.7% positive rate, NNI 3.7–4.4) for 2012–2019. Regional COVID-19 epidemic waves correlated moderately with the positive pulmonary infection CT curve for 2020–2022 (weekly new cases: r = 0.53; hospitalizations: r = 0.65; p <.001). Conclusion: Text mining of radiology reports allows to automatically extract diagnoses. It provides a metric to calculate the number needed to image and to track the trend of diagnoses in real time, i.e., seasonality and epidemic course of pulmonary infections. Clinical relevance: Digitally labeling radiology reports represent previously neglected data and may assist in automated disease tracking, in the assessment of physicians’ clinical reasoning for ordering radiology examinations and serve as actionable data for hospital workflow optimization. Key Points: • Radiology reports, commonly not machine readable, can be automatically labeled with the contained diagnoses using a regular-expression based text search algorithm. • Chest radiograph reports positive for pulmonary infection moderately correlated with regional influenza-like illness consultations (weekly data; r = 0.45; p <.001) and chest CT reports with the course of the regional COVID-19 pandemic (new cases: r = 0.53; hospitalizations: r = 0.65; p < 0.001). • Rendering radiology reports into data labels provides a metric for automated disease tracking, the assessment of ordering physicians clinical reasoning and can serve as actionable data for workflow optimization. © 2023, The Author(s).",TextMining
"Introduction: Ordinal traits are important complex traits in crops, while genome-wide association study (GWAS) is a widely-used method in their gene mining. Presently, GWAS of continuous quantitative traits (C-GWAS) and single-locus association analysis method of ordinal traits are the main methods used for ordinal traits. However, the detection power of these two methods is low. Methods: To address this issue, we proposed a new method, named MTOTC, in which hierarchical data of ordinal traits are transformed into continuous phenotypic data (CPData). Results: Then, FASTmrMLM, one C-GWAS method, was used to conduct GWAS for CPData. The results from the simulation studies showed that, MTOTC+FASTmrMLM for ordinal traits was better than the classical methods when there were four and fewer hierarchical levels. In addition, when MTOTC was combined with FASTmrEMMA, mrMLM, ISIS EM-BLASSO, pLARmEB, and pKWmEB, relatively high power and low false positive rate in QTN detection were observed as well. Subsequently, MTOTC was applied to analyze the hierarchical data of soybean salt-alkali tolerance. It was revealed that more significant QTNs were detected when MTOTC was combined with any of the above six C-GWAs. Discussion: Accordingly, the new method increases the choices of the GWAS methods for ordinal traits and helps to mine the genes for ordinal traits in resource populations. Copyright © 2023 Yang, Wen, Zheng, Zhang, Zhao and Feng.",TextMining
"As an extended version of frequent itemset patterns, periodic itemset patterns concern both the frequency and periodicity of itemsets at the same time, so they contain more information than frequent itemset patterns, which only concern the frequency. With further research, we found that, in some cases, the periodic itemset patterns with higher frequency, or with optimal periodicity, or with both higher frequency and optimal periodicity have higher application value. However, there is currently no work focusing on such a kind of periodic itemset patterns. In view of this, this paper first proposes a new concept of skyline periodic itemset patterns, and states the problem of skyline periodic itemset pattern mining, then presents an algorithm called SLPIM (SkyLine Periodic Itemset pattern Miner) for skyline periodic itemset pattern mining. SLPIM first adopts the well-known FP-Growth algorithm to mine all frequent itemset patterns, and then uses an effective judgment strategy to determine which frequent itemset patterns are skyline periodic itemset patterns. Finally, experiments are conducted on two real-world and two simulated datasets. The results show that SLPIM is competent for mining skyline periodic itemset patterns. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Processes tend to interact with other processes and operate on various objects of different types. These objects can influence each other creating dependencies between sub-processes. Analyzing the conformance of such complex processes challenges traditional conformance-checking approaches because they assume a single-case identifier for a process. To create a single-case identifier one has to flatten complex processes. This leads to information loss when separating the processes that interact on some objects. This paper introduces an alignment approach that operates directly on these object-centric processes. We introduce alignments that can give behavior-based insights into how closely related the event data generated by a process and the behavior specified by an object-centric Petri net are. The contributions of this paper include a definition for object-centric alignments, an algorithm to compute them, a publicly available implementation, and a qualitative and quantitative evaluation. The qualitative evaluation shows that object-centric alignments can give better insights into object-centric processes because they correctly consider inter-object dependencies. Findings from the quantitative evaluation show that the run-time grows exponentially with the number of objects, the length of the process execution, and the cost of the alignment. The evaluation results motivate future research to improve the run-time and make object-centric alignments more applicable for larger processes. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Previous studies indicate that applying solely financial ratios (FR) provides limited SME bankruptcy prediction performance. On the other hand, the application of non-financial features is cost-ineffective for SMEs. Intellectual capital (IC) features provide a meaningful alternative to analyse SMEs’ financial performance since companies with higher IC regularly achieve consistently higher sales growth. This paper aims to examine the possibilities of applying intellectual capital features in predicting SME bankruptcy. 14 IC features and 27 FR of 54,003 SMEs from 2016 to 2021 were collected from financial statements. Three groups of XGBoost and CatBoost models were developed–with only IC features, with only FR and combining FR and IC features. The results show that IC features are a practical addition to FR, with the best AUC equal to 89%, and their combination outperforms models using only FR by an average of 2.3%. Moreover, IC features such as capital employed efficiency and structural capital reduced the likelihood of SMEs’ bankruptcy. The implication of this study is that SME bankruptcy models perform better using IC features without significantly increasing financial cost or processing time, which can be helpful for financial institutions. Additionally, this can contribute to developing other methods of measuring IC. © 2023 Informa UK Limited, trading as Taylor & Francis Group.",TextMining
"The increasing amount of data in the era of Industry 4.0 brings complexity to data mining implementation. SUSENAS data, which is complex with a large number of mixed data type attributes, has not been fully utilized by the government. The Keluarga Harapan Program (PKH), as a social assistance program, also faces issues regarding improper beneficiary selection. Therefore, this study aims to maximize the processing of SUSENAS consumption module data to support the PKH program and provide insights into the relationship between consumption patterns and family nutrition. The focus of this research is attribute selection and processing of mixed data types to align with input association rules and provide information about attribute relationships. The CRISP-DM methodology is used as the research approach, with the FP-Growth algorithm chosen for association rules analysis. After performing data transformation using one-hot encoding, 37 association rules were discovered with an average confidence value of 0.89 and an average support value of 0.30. One interesting rule identified is the relationship between family size, poverty status, and nutritional adequacy, where medium-sized families tend to experience protein and calorie deficiencies. By employing this approach, this research contributes to understanding consumption patterns and family nutrition through association rule analysis on SUSENAS data. The findings of this study are expected to support the PKH program and assist the government in making more informed decisions regarding social assistance for impoverished families. © 2023 IEEE.",TextMining
"Graph neural networks (GNNs) have been extensively explored due to semi-supervised learning on graphs, which uses few labels to complete tasks without employing costly labeling information. Related methods are dedicated to mitigating the over-smoothing phenomenon to generate reliable node representations. However, existing methods lack correct guidance for neighbors and links from graph characteristics to node representations, resulting in incorrect neighbor information aggregation and poor representation discriminability. In this paper, we introduce a novel encoding and decoding framework that correctly leverages structure guided by labels and uses features for self-supervision of representations to alleviates the over-smoothing phenomenon, dubbed as Iterative Encode-and-Decode Graph Neural Network (IEDGNN). First, we offer a central component reconstruction module to correct the category centers of node representations, lowering the likelihood of aggregating neighbor information across categories. Then, we propose a feature self-reconstruction module that enables node representations to contain valid original attributes, making representations more informative in downstream classification tasks. We also theoretically analyze the impact of different encoder-decoder combinations on representation generation in our design. Extensive experiments demonstrate that our IEDGNN outperforms the state-of-the-art models on eight graph benchmark datasets with three label ratios. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
The proceedings contain 22 papers. The special focus in this conference is on Artificial Intelligence and Green Computing. The topics include: Maximization of Lifetime in Wireless Sensor Networks Using Pattern Search Algorithm; task Deadline-Based Computation Offloading Algorithm for Service Time Minimization in Mobile Edge Computing; detection of Web-Based Attacks using Tree-Based Learning Models: An Evaluation Study; energy Minimization in Wireless Sensor Networks Based Bio-Inspired Algorithms; Heuristic Optimization of the LEACH Routing Protocol in Wireless Sensor Networks; toward Understanding the Impact of Demographic Factors on Cybersecurity Awareness in the Moroccan Context; health Data Security in a Big Data Environment; Handling the ED Problem Using a DTSA in Smart Grids; Multivariate Time Series Data Prediction Based on Social Sentiments Community and LSTM Method (S-S-LSTM); longitudinal Study of the Thyroid Surgery Effect Based on Computer Vision; improving Wheat Yield Estimating by Using Satellites Data and Machine Learning—Deep Learning Algorithm-In Morocco; online Process Mining: A Systematic Literature Review; machine Learning with Nighttime Lights to Predict Morocco’s Gross Domestic Product; pectoral Muscle Segmentation Using Mammogram Images in Medio Lateral Oblique View; a Nearest Neighbor-Based Hamiltonian Clustering Algorithm; an Acoustic Analysis of Voice Before and After Thyroidectomy; estimation of Water Turbidity by Image-Based Learning Approaches; an Image Compression Approach Based on Convolutional AutoEncoder; offline Writer Identification Based on Diagonal Gradient Angle of Small Fragments; Enhanced Aircraft Time Delay Prediction Using Weighted Hybrid ML and Dimensionality Reduction.,TextMining
"SKP1 (S-phase kinase protein1) is an essential regulatory component of SCF (Skp1-cullin-F-box) E3 ubiquitin ligases involved in maintenance of cellular protein homeostasis through ubiquitin mediated proteasome system (UPS). UPS play a key role in stress response and grain yield. Earlier, we isolated TaSKP1-6B-4, highly induced in flag leaf tissues (Accession No. KJ830759.1) of developing wheat caryopses under heat stress. To further assess the functional role of SKP1, genetic variability analysis was carried out in a panel of 25 contrasting germplasm through extensive phenotyping and transcript profiling of TaSKP1-6B-4 during anthesis under ambient and terminal heat stress (THS) in field experiments for two consecutive years. The analysis of variance revealed significant variations for all the traits studied. Higher H2(%), GCV, PCV, GA and GA% mean observed in tiller number per plant (23.81, 17.65, 5.71, 28, 30.86%) and grain number per head (30.27, 82.79, 60.16, 105.00, 108.64%) under THS over ambient temperature. Higher fold induction of TaSKP1-6B-4 transcripts was recorded in 10 genotypes viz. HD2967 (9.9), IC145456 (6.18) in flag leaf; while C-306 (15.88), RAJ3765 (8.37) in ear head. Allele mining of SKP1-6B-4 showed genotypic sequence variations. Whole genome wide search of SKP1 gene family identified 95 SKP1 genes which were structurally characterized. Grain yield, leaf senescence and other agronomic-morpho-physiological parameters combined with transcript profiling, cvHD2967, was found to be the best positively responsive to THS which by pedigree was not heat tolerant. We report a novel 2 year comprehensive field based analysis on collective genetic variability and SKP1/UPS modulation under a natural environmental setting. The data reveals potential functional role of UPS under THS and tolerant cultivars can be further utilized for clarifying the role of UPS mechanistically at the molecular level and for developing terminal heat stress tolerant wheat. © 2023, The Author(s), under exclusive licence to Springer Nature B.V.",TextMining
"Objective: Traditional Chinese medicine (TCM) has been used for the treatment of chronic liver diseases for a long time, with proven safety and efficacy in clinical settings. Previous studies suggest that the therapeutic mechanism of TCM for hepatitis B cirrhosis may involve the gut microbiota. Nevertheless, the causal relationship between the gut microbiota, which is closely linked to TCM, and cirrhosis remains unknown. This study aims to utilize two-sample Mendelian randomization (MR) to investigate the potential causal relationship between gut microbes and cirrhosis, as well as to elucidate the synergistic mechanisms between botanical drugs and microbiota in treating cirrhosis. Methods: Eight databases were systematically searched through May 2022 to identify clinical studies on TCM for hepatitis B cirrhosis. We analyzed the frequency, properties, flavors, and meridians of Chinese medicinals based on TCM theories and utilized the Apriori algorithm to identify the core botanical drugs for cirrhosis treatment. Cross-database comparison elucidated gut microbes sharing therapeutic targets with these core botanical drugs. MR analysis assessed consistency between gut microbiota causally implicated in cirrhosis and microbiota sharing therapeutic targets with key botanicals. Results: Our findings revealed differences between the Chinese medicinals used for compensated and decompensated cirrhosis, with distinct frequency, dosage, properties, flavors, and meridian based on TCM theory. Angelicae Sinensis Radix, Salviae Miltiorrhizae Radix Et Rhizoma, Poria, Paeoniae Radix Alba, Astragali Radix, Atrctylodis Macrocephalae Rhizoma were the main botanicals. Botanical drugs and gut microbiota target MAPK1, VEGFA, STAT3, AKT1, RELA, JUN, and ESR1 in the treatment of hepatitis B cirrhosis, and their combined use has shown promise for cirrhosis treatment. MR analysis demonstrated a positive correlation between increased ClostridialesvadinBB60 and Ruminococcustorques abundance and heightened cirrhosis risk. In contrast, Eubacteriumruminantium, Lachnospiraceae, Eubacteriumnodatum, RuminococcaceaeNK4A214, Veillonella, and RuminococcaceaeUCG002 associated with reduced cirrhosis risk. Notably, Lachnospiraceae shares key therapeutic targets with core botanicals, which can treat cirrhosis at a causal level. Conclusion: We identified 6 core botanical drugs for managing compensated and decompensated hepatitis B cirrhosis, despite slight prescription differences. The core botanical drugs affected cirrhosis through multiple targets and pathways. The shared biological effects between botanicals and protective gut microbiota offer a potential explanation for the therapeutic benefits of these key herbal components in treating cirrhosis. Elucidating these mechanisms provides crucial insights to inform new drug development and optimize clinical therapy for hepatitis B cirrhosis. Copyright © 2023 Zhou, Wei, Yu, Yang, Liu, Jia, Wang, Sun, Yang and Xiao.",TextMining
"User transaction data are rich, valuable, but sensitive. With the huge amounts of transaction data, data mining algorithms can make many applications practical, such as customer-behavior analysis, marketing, and forensics. The value behind the transaction data analysis on the other hand raises the risk of data leak. In this paper, we introduce a Crypto-based KMeans clustering algorithm (CTKM) on the Transaction data of web users for user clustering and data protection as well. Considering the categoricalness of user transaction data, a taxonomy-based distance has been employed, which is applicable to the data encryption process also. In order to obtain efficient computations on the distance, a distance batch computing(DBC) protocol is designed and deployed in a two-server platform. We theoretically estimate both the computation and communication costs of the algorithm. Experimental results on a real data set demonstrate its practical value on web user clustering. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Deep convolutional neural networks (CNNs) can improve recognition rate in license plate to improve traffic. However, these methods may refer to big computational costs and a lot of parameters. In this paper, we propose a knowledge distillation with a fast CNN for license plate detection (KDNet). KDNet uses knowledge distillation to guide a CNN to optimize parameters and quickly obtain a detector for license plate. To overcome naive effect of local information, a non-local similarity mechanism is used into a CNN to enhance effect of global information for extracting salient information in license plate detection. Experimental results that this proposed KDNet is superior to detection speed for license plate. The code of KDNet can be obtained at <uri>https://github.com/hellloxiaotian/KDNet</uri>. IEEE",TextMining
"The length and extension of legal processes are two of the main problems of contemporary justice. Adopting process analysis techniques can serve to understand the course of these processes, to identify bottlenecks, and to propose improvements. This paper showcases an exploration of legal event logs using process mining techniques. First, we discuss the results obtained by applying state-of-the art process discovery techniques to data obtained from public tenders. Then, we show how to use natural language processing to automatically extract events and dates from the texts of the tenders and leverage this information for improving the results of process mining techniques. As a proof-of-concept, we propose a comparison of the French, Spanish, and Italian cases through process discovery based on calls for tenders from the European TED repository. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"With the gradual integration of artificial intelligence and production processes, will the traditional business model of enterprises change? Based on the data of China's manufacturing companies listed in Shanghai and Shenzhen A-shares from 2008 to 2021, we study the impact of enterprise intelligent transformation on customer concentration. Using text mining and machine learning tools, this study measures the degree of enterprise intelligent transformation and constructs an index based on the relevant words in annual reports. A multiphase DID model results show that enterprise intelligent transformation reduces customer concentration. A series of robustness tests and endogeneity tests validate this finding. This study shows that enterprise intelligent transformation improves information disclosure quality, strengthens innovation ability, and expands business boundaries, thus reducing customer concentration. Our findings provide empirical evidence to strengthen enterprise intelligent transformation further and maintain robust supply chain relationships. © 2023 IGI Global. All rights reserved.",TextMining
"Pre-trial detention is a debated measure in different legal systems since it deprives defendants of their liberty prior at the initial stage of proceedings. To order this measure, the judge must justify it by highlighting the risks that the arrested person presents to society and to the criminal procedure itself. An example of a factor related to preventive custody, in countries such as Italy and Brazil, is involvement in criminal organizations. The paper presents the results of experimental research with supervised learning, in particular using XAI techniques, such as decision trees and Shapley Additive Explanations. Our corpora are composed of unstructured data (texts of judicial decisions) and structured data (factors extracted from such judicial decisions), from the case law of Italian and Brazilian Supreme Courts. As a result, we have identified a collection of factors that play an important role in the reasoning of the judge and in predicting outcomes, including common factors between the two countries. In particular, we have verified that involvement in criminal organizations consistently leads to the decision to maintain imprisonment in the Brazilian scenario, while in the Italian context, this is unclear. Finally, we conclude that data structuring based on the extraction of factors from the decision texts not only increases the prediction’s quality but also allows for their interpretation and explanation. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"Structured knowledge bases (KBs) are the backbone of many knowledge-intensive applications, and their automated construction has received considerable attention. In particular, open information extraction (OpenIE) is often used to induce structure from a text. However, although it allows high recall, the extracted knowledge tends to inherit noise from the sources and the OpenIE algorithm. Besides, OpenIE tuples contain an open-ended, non-canonicalized set of relations, making the extracted knowledge’s downstream exploitation harder. In this paper, we study the problem of mapping an open KB into the fixed schema of an existing KB, specifically for the case of commonsense knowledge. We propose approaching the problem by generative translation, i.e., by training a language model to generate fixed-schema assertions from open ones. Experiments show that this approach occupies a sweet spot between traditional manual, rule-based, or classification-based canonicalization and purely generative KB construction like COMET. Moreover, it produces higher mapping accuracy than the former while avoiding the association-based noise of the latter. Code and data are available. (https://github.com/Aunsiels/GenT, julienromero.fr/data/GenT ) © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"The characteristic analysis of car-following behavior in different scenarios is important for studying microscopic traffic flow models. This study first used roadside light detecting and ranging (LiDAR) to collect traffic 3-D point cloud data to reveal the driving behavior characteristics of localized urban intersections. The background subtraction method is used to filter out the background objects. The density-based spatial clustering of applications with noise algorithm detects and identifies vehicle objects. The traffic target tracking method based on historical frame data fusion obtained the vehicle trajectory. Second, this article designed a method to extract high-resolution microscopic traffic information. This method constructs the boundary box model of traffic objects by finding fixed point features. Then, the speed, distance, and other information are calculated through the coordinate relationship of vehicle position. Finally, the velocity and gap distance characteristics are analyzed in car-following behavior. This study found a significant correlation between the speed of the front and rear vehicles in the car-following process. A linear function can effectively fit the relationship between speed and gap distance. This article also verifies the asymmetric characteristics of driving behavior under acceleration and deceleration conditions at urban intersections. IEEE",TextMining
"In this paper we address an extension of the sequential pattern mining problem which aims at detecting the significant differences between frequent sequences with respect to given classes. The resulting problem is known as contrast sequential pattern mining, since it merges the two notions of sequential pattern and contrast pattern. For this problem we present a declarative approach based on Answer Set Programming (ASP). The efficiency and the scalability of the ASP encoding are evaluated on two publicly available datasets, iPRG and UNIX User, by varying parameters, also in comparison with a hybrid ASP-based approach. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"The rapid development of the digital age has led to a qualitative leap in social media. To meet the cognitive needs of users, social media platforms have been mining users&#x2019; private information and disseminating information through various means. However, these platforms lack effective management of information release and various forms of emotional expressions make public propaganda increasingly diverse and complex. Therefore, accurately identifying the relationships between multimodal data poses a challenge. An effective modal representation must consider both the consistency of multimodal data and the complementarity of single-modal data. However, existing methods focus on fusing different modal features into a unified feature representation, while neglecting to evaluate the reliability of prediction results. In this article, we disentangle the consistency and complementarity in the fused representation problem of multimodal data. We construct the modal private task (unique) by using the Dirichlet distribution and evidence theory to solve the uncertainty of each modal prediction. The model can output the uncertainty of prediction and learn complementary information through the fusion of decision layers. At the same time, we construct the modal common task using a low-rank tensor fusion model to learn consistent features. Finally, we compare the model with the current mainstream methods on three public datasets, and the experimental results show that the performance of our method reaches the level of current advanced algorithms. IEEE",TextMining
The proceedings contain 216 papers. The special focus in this conference is on Advanced Data Mining and Applications. The topics include: A Novel Variational Autoencoder with Multi-position Latent Self-attention and Actor-Critic for Recommendation; fair Re-Ranking Recommendation Based on Debiased Multi-graph Representations; FastNER: Speeding up Inferences for Named Entity Recognition Tasks; CPMFA: A Character Pair-Based Method for Chinese Nested Named Entity Recognition; STMC-GCN: A Span Tagging Multi-channel Graph Convolutional Network for Aspect Sentiment Triplet Extraction; exploring the Design Space of Unsupervised Blocking with Pre-trained Language Models in Entity Resolution; joint Modeling of Local and Global Semantics for Contrastive Entity Disambiguation; KFEA: Fine-Grained Review Analysis Using BERT with Attention: A Categorical and Rating-Based Approach; discovery of Emotion Implicit Causes in Products Based on Commonsense Reasoning; from Time Series to Multi-modality: Classifying Multivariate Time Series via Both 1D and 2D Representations; multi-modal Multi-emotion Emotional Support Conversation; exploiting Pseudo Future Contexts for Emotion Recognition in Conversations; generating Enlightened Suggestions Based on Mental State Evolution for Emotional Support Conversation; deep One-Class Fine-Tuning for Imbalanced Short Text Classification in Transfer Learning; EmoKnow: Emotion- and Knowledge-Oriented Model for COVID-19 Fake News Detection; popular Songs: The Sentiment Surrounding the Conversation; market Sentiment Analysis Based on Social Media and Trading Volume for Asset Price Movement Prediction; efficient Mining of High Utility Co-location Patterns Based on a Query Strategy; point-Level Label-Free Segmentation Framework for 3D Point Cloud Semantic Mining; CD-BNN: Causal Discovery with Bayesian Neural Network; exploring the Effectiveness of Positional Embedding on Transformer-Based Architectures for Multivariate Time Series Classification; a Preference-Based Indicator Selection Hyper-Heuristic for Optimization Problems; an Elastic Scalable Grouping for Stateful Operators in Stream Computing Systems; incremental Natural Gradient Boosting for Probabilistic Regression; discovering Skyline Periodic Itemset Patterns in Transaction Sequences; Double-Optimized CS-BP Anomaly Prediction for Control Operation Data.,TextMining
"The time-consuming nature of chemical testing techniques makes them lag behind mineral processing. Therefore, this article combines visible-infrared reflectance spectroscopy with machine learning (ML) algorithms to achieve rapid detection of iron ore grades and meet the requirements of mining production. First, the standard normal variate (SNV) and de-trending (DT) are used to eliminate noise and baseline drift in the original spectral data. Then, extraneous signals are removed using direct orthogonal signal correction (DOSC). In addition, fractional-order derivative (FOD) is performed on the DOSC spectrum to further amplify the spectral details. To extract spectral features and reduce the spectral dimension, a multilayer incremental extreme learning machine autoencoder (MIELM-AE) is proposed in this article. MIELM-AE can automatically match the optimal number of network nodes and network layers to minimize the reconstruction error. The experimental results show that the Pearson correlation coefficient (R2) of the extreme learning machine (ELM) built using MIELM-AE improves from 0.715 to 0.821, compared with the ELM built without the dimensionality reduction method. To increase the measurement accuracy, this article uses Tikhonov regularization and truncated singular value decomposition (TSVD) to alleviate the ill-conditioned matrix of the hidden layer of the ELM and uses the incremental method to match the optimal network nodes. Finally, double-regularization incremental ELM (DRIELM) is proposed in this article. Experiments show that DRIELM obtained the highest detection accuracy with an R2 of 0.932 at an FOD of 0.4.  © 1963-2012 IEEE.",TextMining
"Given a Social Network how to select a small number of influential users to maximize the influence in the network has been studied extensively in the past two decades and formally referred to as the Influence Maximization Problem. Among most of the existing studies, it has been implicitly assumed that there exists a single probability value that represents the influence probability between the users. However, in reality, the influence probability between any two users is dependent on the context (formally referred to as tag e.g.; a sportsman can influence his friends related to any news related to sports with high probability). In this paper, we bridge the gap by studying the Tag-Based Influence Maximization Problem. In this problem, we are given with a social network where each edge is marked with one probability value for every tag and the goal here is to select k influential users and r influential tags to maximize the influence in the network. First, we define a tag-based influence function and show that this function is bi-submodular. We use the orthent-wise maximization procedure of bi-submodular function which gives a constant factor approximation guarantee. Subsequently, we propose a number of efficient pruning techniques that reduces the computational time significantly. We perform an extensive number of experiments with real-world datasets to show the effectiveness and efficiency of the proposed solution approaches. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Several definitions exist for Digital Twins, which are based on industry 4.0 technologies. Going beyond, a wider definition is proposed which is focused on obtaining knowledge and foresight to improve re-and pro-active decision-making, for enhancing validation, assessment and control. A six-level classification schema is proposed, equally applicable to buildings, embedded systems and processes at all phases from design to demolition. A digital twin is seen as the marriage of semantic with numeric, namely the fusion of semantic methods with numerical methods first of all computational engineering but also sensing, data mining and Artificial Intelligence methods. © 2023, European Council on Computing in Construction (EC3). All rights reserved.",TextMining
"The concept of sustainable tourism development is derived from sustainable development. Building tourism with the framework of sustainable development has become a necessary effective way. This study examined the abstracts and titles of 1783 sustainable development and 692 sustainable tourism development related papers from 2012 to 2021 as textual data sources through the Web of Science core database. Using text mining and semantic network as analysis methods, this paper summarizes eight main clusters of sustainable development and sustainable tourism development in the past 10 years. Based on this, this paper compares the differences between the two researches and explores four potential research areas in sustainable tourism development: (1) threats to sustainability; (2) ecology and health; (3) stakeholder cooperation and roles; and (4) tourism development planning. In addition, the visual network knowledge structure intuitively captures the relationship between the different keywords in the clustering, which provides an important reference value for broadening the future research direction of sustainable tourism development. © 2023 ERP Environment and John Wiley & Sons Ltd.",TextMining
"Online platforms have revolutionized the way we access and consume music, offering vast libraries of content at our fingertips. These platforms serve as vital bridges, facilitating thousands of daily sales and enabling direct connections between artists and their fans. However, the sheer volume of music available presents us with new and unique challenges. In this study, we present a method of classifying music using the phonemes present in the individual lyrics of the songs. It focuses on the use of these phonemes to predict genre or emotional labels from the Million Song Dataset project. The results show that utilizing phonemes achieves similar accuracy to utilizing lyrics as features. Additionally, combining comprehensive lyric representations with the phoneme approach yields marginally superior results, suggesting potential for further exploration. This research suggests delving deeper into identifying the most valuable predictive phonemes and their connection to emotions, which may lead to an optimized set of features for modeling. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"Initially, the focus of process mining was on processes evolving around a single type of objects, e.g., orders, order lines, payments, deliveries, or customers. In this simplified setting, each event refers to precisely one object and the automatically discovered process models describe the lifecycles of the selected objects. Dozens of process-discovery and conformance-checking techniques have been developed using this simplifying assumption. However, real-life processes are more complex and involve objects of multiple types interacting through shared activities. Object-centric process mining techniques start from event logs consisting of events and objects without imposing the classical constraints, i.e., an event may involve multiple objects of possibly different types. This paper introduces object-centric event logs and shows that many of the existing process-discovery and conformance-checking techniques can be adapted to this more holistic setting. This provides many opportunities, as demonstrated by examples and the tool support we developed. © 2023, The Author(s), under exclusive licence to Springer Nature Switzerland AG.",TextMining
"High-dimensional datasets manifest as r-separable matrices in a wide range of applications such as hyperspectral imaging, text mining, astronomy, and archetypal analysis of scientific imaging data. In this work, we consider the problem of reconstructing high-dimensional r-separable matrices from their compressive and noiseless linear measurements. We propose to exploit the convex geometry and latent sparsity of r-separable matrices to pose their desketching from compressive measurements as a constrained nonconvex optimization. The resulting nonconvex optimization is then solved as a sequence of reweighted convex optimizations, each of which is solved individually using Alternating Direction Method of Multipliers (ADMM). We conduct extensive numerical experiments with synthetic datasets to demonstrate the efficacy of our proposed iterative procedure in desketching high-dimensional r-separable matrices and inferring their convex geometry from their compressive and noiseless linear measurements. © 2023 IEEE.",TextMining
"Text categorization is one of the most important jobs in knowledge retrieval and data mining. This study seeks to investigate several vector space model (VSMs) variants using the K-Nearest Neighbor algorithm (k-NN) method. 242 abstract Arabic documents that they used was utilized in this paper. The comparison is often based on well-known text assessment metrics, recall calculation, precision measurement, and measurement F1. Cosine outperformed in tests conducted on Saudi data sets, according to the results. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"The cross-modal oil painting image generated by traditional methods makes it easy to miss the important information of the target part, and the generated image lacks realism. This paper combines the feature extraction technology of multimedia data with the generation confrontation network in deep learning, puts forward a generation model of classic oil painting, and applies it to university teaching. Firstly, the key frame extraction algorithm is used to extract the key frames in the video, and the channel attention network is introduced into the pre-trained ResNet-50 network to extract the static features of 2D images in short oil painting videos. Then, the depth feature mapping is carried out in the time dimension by using the double-stream I3D network, and the feature representation is enhanced by combining static and dynamic features. Finally, the high-dimensional features in the depth space are mapped to the two-dimensional space by using the opposition generation network to generate classic oil painting pictures. © 2023 IGI Global. All rights reserved.",TextMining
"Deep Learning (DL) has been effectively utilized in various complicated challenges in healthcare, industry, and academia for various purposes, including thyroid diagnosis, lung nodule recognition, computer vision, large data analytics, and human-level control. Nevertheless, developments in digital technology have been used to produce software that poses a threat to democracy, national security, and confidentiality. Deepfake is one of those DL-powered apps that has lately surfaced. So, deepfake systems can create fake images primarily by replacement of scenes or images, movies, and sounds that humans cannot tell apart from real ones. Various technologies have brought the capacity to change a synthetic speech, image, or video to our fingers. Furthermore, video and image frauds are now so convincing that it is hard to distinguish between false and authentic content with the naked eye. It might result in various issues and ranging from deceiving public opinion to using doctored evidence in a court. For such considerations, it is critical to have technologies that can assist us in discerning reality. This study gives a complete assessment of the literature on deepfake detection strategies using DL-based algorithms. We categorize deepfake detection methods in this work based on their applications, which include video detection, image detection, audio detection, and hybrid multimedia detection. The objective of this paper is to give the reader a better knowledge of (1) how deepfakes are generated and identified, (2) the latest developments and breakthroughs in this realm, (3) weaknesses of existing security methods, and (4) areas requiring more investigation and consideration. The results suggest that the Conventional Neural Networks (CNN) methodology is the most often employed DL method in publications. According to research, the majority of the articles are on the subject of video deepfake detection. The majority of the articles focused on enhancing only one parameter, with the accuracy parameter receiving the most attention. This article is categorized under: Technologies > Machine Learning Algorithmic Development > Multimedia Application Areas > Science and Technology. © 2023 Kadir Has University. WIREs Data Mining and Knowledge Discovery published by Wiley Periodicals LLC.",TextMining
"High-dimensional and incomplete (HDI) data are omnipresent in a variety of Big Data-related applications. Latent feature analysis (LFA) is a typical representation learning method that can extract useful yet latent knowledge from HDI data via low-rank embedding. Existing LFA-based models mostly adopt a single-metric-based modeling strategy, where the representation designed for the embedding Loss function is fixed and exclusive. However, real-world HDI data are commonly heterogeneous and have large diverse underlying patterns, making a single-metric-based model cannot represent such HDI data in a comprehensive and unbiased fashion. Motivated by this discovery, this paper proposes a multi-metric latent feature (MMLF) model whose ideas are two-fold: 1) two vector spaces and three Lp-norms are simultaneously adopted to develop six LFA variants, each of which possesses a unique merit, and 2) all the variants are aggregated with a tailored, self-adaptive weighting strategy. As such, the proposed MMLF enjoys the merits originated from a set of disparate metric spaces all at once, achieving the comprehensive and unbiased representation of HDI data. Theoretical study guarantees that MMLF attains evident performance gain. Extensive experiments on ten real-world HDI matrices, spanning a wide range of industrial and scientific areas, verify that the proposed MMLF significantly outperforms nine state-of-the-art, shallow and deep counterparts. IEEE",TextMining
"A high utility co-location pattern (HUCP) is a set of spatial features, which is supported by groups of neighboring spatial instances, and the pattern utility ratios (PUR) of the spatial feature set are greater than a minimal utility threshold assigned by users, can reveal hidden relationships between spatial features in spatial datasets, is one of the most important branches of spatial data mining. The current algorithm for mining HUCPs adopts a level-wise search style. That is, it first generates candidates, then tests these candidates, and finally determines whether the candidates are HUCPs. It performs mining from the smallest size candidate and gradually expands until no more candidates are generated. However, in mining HUCPs, the UPR measurement scale does not hold the downward-closure property. If the level-wise search style is adopted, unnecessary candidates cannot be effectively pruned in advance, and the mining efficiency is extremely low, especially in large-scale and dense spatial datasets. To overcome this, this paper proposes a mining algorithm based on a query strategy. First, the neighboring spatial instances are obtained by enumerating maximal cliques, and then these maximal cliques are stored in a hash map structure. Neighboring spatial instances that support candidates can be quickly queried from the hash structure. Finally, the UPR of the candidate is calculated and a decision is made on it. A series of experiments are implemented on both synthetic and real datasets. Experimental results show that the proposed algorithm gives better mining performance than existing algorithms. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Knowledge extraction and reuse are critical topics for manufacturing companies willing to strengthen their Product-Service Systems (PSS) offerings. In manufacturing’s maintenance processes, effectiveness and efficiency depend on the ability to learn from past field interventions. Dealing with unstructured descriptions of maintenance activities has prevented manufacturing companies from analyzing them, causing the loss of useful information. Natural Language Processing (NLP) demonstrated high potential, allowing simplified text knowledge extraction and summarization. Besides, the literature presents only a few applications of topic modeling for maintenance improvement in the manufacturing domain. Using a case study, the paper demonstrates the potentialities of NLP adoption to improve not only the maintenance management and execution but also the asset design and management, impacting the whole PSS. In other words, implications will have effects on the operational (e.g. maintenance execution), managerial (e.g. maintenance management), and business levels (e.g. PSS offering definition) of manufacturing firms. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",TextMining
"In order to accelerate the research on the property optimization of titanium alloy based on high-throughput methods, it is necessary to reveal the relationship between hardness and other mechanical properties which is still unclear. In this work, taking Ti20C alloy as research object, almost all the microstructure of dual-phase titanium alloys were covered by traversing over 100 heat treatment schemes. Then, massive experiments including microstructure characterization and performance test were conducted, obtaining 51,590 pieces of microstructure data and 3591 pieces of mechanical property data. Subsequently, based on large-scale data-driven technology, the quantitative mapping relationship between hardness and other mechanical properties was deeply discussed. The results of random forest models showed that the correlation between hardness (H) and Charpy impact energy (A k) (or elongation, A) was hardly dependent on the microstructure types, while the relationship between H and tensile strength (R m) (or yield strength, R p0.2) was highly dependent on microstructure types. Specifically, combined with statistical analysis, it was found that the relationship between H and A k (or A) were negatively linear. Interestingly, the relationship between H and strength was positively linear for equiaxed microstructure, and strength was linked to d −1/2 (d, equivalent circle diameter) of α-grains in the form of classical Hall–Petch formula; but for other microstructures, the relationships were quadratic. Furthermore, the above rules were nearly the same in the rolling direction and transverse direction. Finally, a ""four-quadrant partition map"" between H and R p0.2/R m was established as a versatile material-screening tool, which can provide guidance for on-demand selection of titanium alloys. Graphical abstract: [Figure not available: see fulltext.] © 2023, Youke Publishing Co.,Ltd.",TextMining
"Purpose: The purpose of this paper is to show how data mining techniques can improve the performance management of the judiciary, helping judges in steering position with specific and timely measures. It explores different approaches to analyse the length of trials, based on the case of an Italian judicial office. Design/methodology/approach: The paper presents a temporal analysis to compare the timeliness of trials, using data and process mining approaches with the support of a specific software to represent graphically the results. Data were gathered directly from the office data base, improving precision and the opportunity to monitor specific phases of the trials. Findings: The results highlight the progress that can be reached using data mining approaches to develop performance analyses helping courts to correct inefficiencies and to manage the personnel distribution, overcoming the critical comments arisen against traditional KPI (Raine, 2000). The work proposes a methodology to analyse cases deriving from different juridical matters useful to set up a performance monitoring system that could be diffused to different courts. Research limitations/implications: The limitations of the research regard the analysis of a selected, limited number of cases in terms of judicial matters. Practical implications: Data mining techniques can improve the performance management processes in providing more accurate feedback to the judicial offices leaders and increasing the organisational learning. Social implications: The performance of the judiciary is one of the relevant issues that emerged in the recent decade in the field of public sector reforms. Several reasons explain this interest, which has gone beyond the specific legal disciplines to involve public policy, management, economics and ICT studies. Originality/value: Considering the literature on the judiciary (Visser et al., 2019; Di Martino et al., 2021; Troisi and Alfano, 2023) the contribution differs as both the methodological approach and the predictive analysis considers the intrinsic differences that define cases belonging to different juridical matters performing a cross-sectional analysis, with a specific focus of process variants. © 2023, Emerald Publishing Limited.",TextMining
"Objectives. To investigate adverse events (AEs) associated with upadacitinib in the real world using data mining from the FDA Adverse Event Reporting System (FAERS). Methods. Disproportionality analysis, including the reporting odds ratio (ROR), the proportional reporting ratio (PRR), the Bayesian confidence propagation neural network (BCPNN), and the multiitem gamma Poisson shrinker (MGPS) algorithms, was used to quantify the signals of upadacitinib-associated AEs. Results. The study found 23683 reports of AEs associated with upadacitinib. A total of 149 substantial disproportionality preferred terms (PTs) that complied with all algorithms were identified. The infections discovered matched those mentioned in the specification and clinical trials, including pneumonia, upper respiratory tract infection, herpes zoster, and acne. Malignant and thrombotic AEs were also noted. Diverticulitis, myocardial infarction, transient ischaemic attack, and dysstasia were among the new AEs found. Upadacitinib-related AEs had a median onset time of 237 days and an interquartile range (IQR) of 78-509 days. Conclusions. The findings of our study were in line with clinical observations, and we also identified potential novel and unexpected AEs signals for upadacitinib, indicating the necessity for prospective clinical trials to corroborate these findings and demonstrate their link. Our results offered significant support for additional upadacitinib safety research.  © 2023 Yazheng Zhao et al.",TextMining
"Table detection played a vital role in scanned document mining and understanding. The complex nature of tables has made table detection cumbersome and resource-intensive. In this paper, a novel two-path semi-supervised single-shot object detection framework was proposed for automatic detection of table in scanned documents. The proposed framework includes a shared VGG16 network and a two-path single-shot object detection model comprising of supervised and unsupervised subnetworks for table detection and classification. CascadeTabNet General dataset was employed to validate the effectiveness of the proposed framework. Experimental results demonstrated that the model implemented under the proposed framework is robust across various amount of available annotated documents (labeled data) for training. It can detect and classify tables in scanned document effectively even when training on very limited labeled data. For example, the precision of the proposed model is within 3% of a supervised model (SSD300) when training on only 10% of labeled data and 90% of unlabeled data. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"Zircon is the most important accessory mineral in geological research, and it records information on isotopes and trace elements, which is of great significance in Earth science research. Trace elements in zircons can be used to analyze the genesis of zircons, calculate the magma temperature and oxygen fugacity, and trace the magma source. Due to the limitation of visual dimensions, zircon information is mainly shown by low-dimensional diagrams in present studies, so high-dimensional relationships are difficult to determine during trace element analysis of zircons. However, with the development of machine learning, mining the high-dimensional relationships during trace element analysis of zircons has become possible. In this paper, four supervised learning algorithms including random forest, support vector machine, decision tree, and eXtreme Gradient Boosting, were implemented to analyze the trace elements of 3907 magmatic zircons from the GEOROC database, and a precise 13-dimensional data classifier model was established to distinguish the volcanic rift, ocean island, and convergent margin tectonic settings. Based on the results of accuracy, precision, recall, and F1 score, eXtreme Gradient Boosting is the best machine learning approach in this paper and its results for accuracy, precision, recall, and F1 score are 0.906, 0.907, 0.907, and 0.905, respectively. In summary, eXtreme Gradient Boosting could provide a high-dimensional discriminative approach to distinguish tectonic settings. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",TextMining
"The flowering time is one of the important traits in maize. It is of great significance to analyze the genetic basis and to mine the key core genes in flowering for maize varieties with wide adaptability. A natural population consisting of 580 maize inbred lines were planted for three years, to determine the three flowering traits (including days to anthesis, days to silking, and anthesis silking interval). Genome-wide association analysis was conducted using 31,826 SNPs distributed throughout the whole genome. Combined with transcriptome data of 14 different developmental stages of inbred line B73, weighted gene co-expression network analysis was performed to select tissue specific modules and key genes related to maize flowering time. A total of 14 SNPs for four flower traits under multiple environments and 10 potential candidate genes were mined by GWAS, WGCNA was used to mine 17 potential candidate genes in flowering time, three candidate genes were jointly mined by both approaches. Zm00001d052180 encodes a MADS box transcription factor 19, Zm00001d016814 encodes the NAC transcription factor 133, Zm00001d048082 encodes MADS box transcription factor 8, mainly involved in regulating inflorescence growth and development, which has certain research value and significance. These results provide a reference for the genetic basis and molecular mechanisms of flowering time related traits in maize. © 2023 Institute of Crop Sciences. All rights reserved.",TextMining
"Although students’ test scores provide an important reference for teaching and learning, research scholars still need to objectively analyze the scores. Under the current situation where English performance of vocational education students does not achieve satisfactory results, this research uses a clustering algorithm to improve on the ant colony optimization algorithm. This ant colony clustering analysis algorithm is improved by incorporating two optimization strategies, and the test scores of vocational education students are introduced as the original data for cluster analysis. The optimal number of ant colonies is nine, when the three error values of the two ant colony algorithms are minimized. The convergence values of the three ant colony algorithms are smallest when there are 200 training cycles or when the training batch size is 1000, resulting in upgraded ant colony clustering algorithm convergence values of 0.498 and 1.523, respectively. The performance of the student evaluation model combined with the ant colony clustering optimization algorithm improved, followed by CF, FOA, and BP. KNN had the worst performance. Data mining on student performance can be done via research that can provide specialized advice on students' issues. Copyrights © 2023 The Institute of Electronics and Information Engineers.",TextMining
"The relevance of the study is caused by the need to systematize information on the methods and procedure for obtaining data for a comprehensive geoecological assessment of territories disturbed by mining, based on the initial state of natural and modified components of the environment with the processes and phenomena occurring in it. This enables us to obtain information about the territories required for the development of methods and techniques for the subsequent reclamation of lands disturbed by mining. Objective: using various methods and techniques, to analyze methodological approaches that allow generating the necessary and sufficient volume of primary and required information synthesized on its basis, to proceed from a general to a comprehensive and detailed geoecological assessment of territories and areas disturbed and/or planned to be disturbed by mining operations. Objects: Russian territories in mining regions disturbed by mining operations. Methods. Pre-selection of materials published since 2000 was carried out. Russian (E-library, VINITI RAS) and international (Scopus, GeoRef) information systems, websites of specialized and general scientific journals, library collections, and authors’ materials were used. When querying, the following basic terms and phrases were used in various combinations: «geoecological assessment», «assessment methods», «territories disturbed by mining», «remote sensing», «environmental condition». Of more than 1000 pre-identified publications, mostly Russian, devoted to various aspects of collecting and obtaining information on assessing the environmental condition in mining areas, more than 150 were selected. Publications were analyzed taking into account the most complete representation by region and publication. Additionally, materials published by federal and regional management and control authorities were used. The most important and representative ones were included in the review. Results. Existing and promising methods for collecting various data used in the geoecological assessment of territories disturbed by mining are considered. If required, these data will be further processed. Environmental, economic and social problems caused by the influence of mining operations are identified, the solution of these problems requires the generation of various information. The role of reliable and representative primary data measured on various scales is formulated to make a correct assessment of their impact on basic environmental components. The influence of the conditions of mining coal and ore deposits on environmental situation of the territories is considered. The necessity of using a set of methods for collecting and processing information, selected with regard to peculiarities of each mining area and mining specifics of various mineral deposits, is shown. © 2023 Tomsk Polytechnic University, Publishing House. All rights reserved.",TextMining
"In the era of big data and ubiquitous internet connectivity, user feedback data plays a crucial role in product development and improvement. However, extracting valuable insights from the vast pool of unstructured text data found in user feedback presents significant challenges. In this paper, we propose an innovative approach to tackle this challenge by combining the Contextualized Topic Model (CTM) and the Masked and Permuted Pre-training for Language Understanding (MPNet) model. Our approach aims to create a more accurate and context-aware topic model that enhances the understanding of user experiences and opinions. To achieve this, we first search for the optimal number of topics, focusing on generating distinguishable, general, and unique topics. Next, we perform hyperparameter optimization to fine-tune the model and maximize coherence metrics. The result is an exceptionally effective model that outperforms established topic modeling methods, including LSI, NMF, LDA, HDP, NeuralLDA, ProdLDA, ETM, and the default CTM, achieving the highest coherence CV score of 0.7091. In this study, the combination of CTM and MPNet has proven highly effective in the context of user feedback topic modeling. This model excels in generating coherent, distinguishable, and highly relevant user feedback topics, capturing the nuanced nature of user feedback data. The topics generated from this model include &#x2019;Music and Audio Streaming,&#x2019; &#x2019;Application Performance,&#x2019; &#x2019;Banking, Financial Services, and Customer Support,&#x2019; &#x2019;User Experience,&#x2019; &#x2019;Other Topics,&#x2019; &#x2019;Application Content,&#x2019; and &#x2019;Application Features.&#x2019; Our contributions include a powerful tool for developers to gain deeper insights, prioritize actions, and enhance user satisfaction by incorporating feedback into future product iterations. Furthermore, we introduce a new dataset as an open-source resource for further exploration and validation of user feedback analysis techniques and general natural language processing applications. With our proposed approach, we strive to drive business success, improve user experiences, and inform data-driven decision-making processes, ultimately benefiting both developers and users alike. Authors",TextMining
"Tropical river basins–crucial components of global water and carbon cycles–are threatened by logging, mining, agricultural conversion, and climate change. Thus, decision-makers require hydrological impact assessments to sustainably manage threatened basins, such as the ∼68,000 km2 Essequibo River basin in Guyana. Emerging global data products offer the potential to better understand sparsely-gauged basins. We combined new global meteorological and soils data with established in situ observations to build the first physically-based spatially-distributed hydrological model of the Essequibo. We developed new, open source, methods to translate global data (ERA5-Land, WFDE5, MSWEP, and IMERG) into a grid-based SHETRAN model. Comparing the performance of several global and local precipitation and evaporation datasets showed that WFDE5 precipitation, combined with ERA5-Land evaporation, yielded the best daily discharge simulations from 2000 to 2009, with close water balances (PBIAS = −3%) and good discharge peaks (NSE = 0.65). Finally, we tested model sensitivity to key parameters to show the importance of actual to potential evapotranspiration ratios, Strickler runoff coefficients, and subsurface saturated hydraulic conductivities. Our data translation methods can now be used to drive hydrological models nearly anywhere in the world, fostering the sustainable management of the Earth’s sparsely-gauged river basins. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",TextMining
"Multi-view learning is dedicated to integrating information from different views and improving the generalization performance of models. However, in most current works, learning under different views has significant independency, overlooking common information mapping patterns that exist between these views. This paper proposes a Structure Mapping Generative adversarial network (SM-GAN) framework, which utilizes the consistency and complementarity of multi-view data from the innovative perspective of information mapping. Specifically, based on network-structured multi-view data, a structural information mapping model is proposed to capture hierarchical interaction patterns among views. Subsequently, three different types of graph convolutional operations are designed in SM-GAN based on the model. Compared with regular GAN, we add a structural information mapping module between the encoder and decoder wthin the generator, completing the structural information mapping from the micro-view to the macro-view. This paper conducted sufficient validation experiments using public imaging genetics data in Alzheimer&#x0027;s Disease Neuroimaging Initiative (ADNI) dataset. It is shown that SM-GAN outperforms baseline and advanced methods in multi-label classification and evolution prediction tasks. IEEE",TextMining
"The objective of this study was to evaluate the potential of big data technology for spectral feature extraction rice plants under different water management. In this study, we performed reflectance spectral analysis of rice grown under different water management schedules based on big data and machine learning approaches. We applied water management at the tillering, jointing, and heading stages of rice growth and collected visible to near-infrared reflectance spectra to analyze the spectral characteristics of rice grown under different water management schedules. Then, we constructed a data mining model based on the spectral analysis results using the Hadoop and Spark frameworks, and analyzed the characteristic bands of rice grown under each schedule using a parallel machine learning algorithm run in both local and cluster modes. The ChiSqSelector algorithm showed characteristic bands in the range of 400–1000 nm, with bands at approximately 474, 558, 632, 735, and 855 nm for water management in the tillering stage; 472, 551, 627, 721, and 843 nm in the jointing stage; and 471, 545, 642, 725, and 849 nm in the heading stage. By contrast, the UnivariateFeatureSelector algorithm showed characteristic bands at approximately 462, 665, 755, 833, and 937 nm in the tillering stage; 475, 671, 744, 848, and 932 nm in the jointing stage; and 470, 678, 757, 857, and 942 nm in the heading stage. These results demonstrate the feasibility and efficiency of applying big data and data mining technologies for spectral analysis of rice grown under different water management schedules. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Purpose: This study aims to explore the use of time series analyses to examine changes in travelers’ preferences in accommodation features by disentangling seasonal, trend and the COVID-19 pandemic’s once-off disruptive effects. Design/methodology/approach: Longitudinal data are retrieved by online traveler reviews (n = 519,200) from the Canary Islands, Spain, over a period of seven years (2015 to 2022). A time series analysis decomposes the seasonal, trend and disruptive effects of six prominent accommodation features (view, terrace, pool, shop, location and room). Findings: Single accommodation features reveal different seasonal patterns. Trend analyses indicate long-term trend effects and short-term disruption effects caused by Covid-19. In contrast, no long-term effect of the pandemic was found. Practical implications: The findings stress the need to address seasonality at the single accommodation feature level. Beyond targeting specific features at different guest groups, new approaches could allow dynamic price optimization. Real-time insight can be used for the targeted marketing of platform providers and accommodation owners. Originality/value: A novel application of a time series perspective reveals trends and seasonal changes in travelers’ accommodation feature preferences. The findings help better address travelers’ needs in P2P offerings. © 2023, Emerald Publishing Limited.",TextMining
"Events represent fundamental constituents of the world, and investigating expressions of opinion centered around events can enhance our comprehension of events themselves, encompassing their underlying causes, effects, and consequences. This helps us to understand and explain social phenomena in a more comprehensive way. In this regard, we introduce ChatGPT-opinion mining as a framework that transforms event-centric opinion mining tasks into question-answering (QA) utilizing large language model. We employ this approach in the context of the event-centric opinion mining task that utilizes an event-argument structure. In our study, we primarily leverage in-context learning methods to construct demonstrations. Through comprehensive comparative experiments, we illustrate that the model achieves superior results within the ChatGPT-opinion mining framework when the demonstrations exhibit diversity and possess higher semantic similarity, comparable to those of supervised models. Moreover, ChatGPT-opinion mining surpasses the supervised model, particularly when there is limited availability of the same data. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",TextMining
"Human-Object Interaction (HOI), as an important problem in computer vision, requires locating the human-object pair and identifying the interactive relationships between them. The HOI instance has a greater span in spatial, scale, and task than the individual object instance, making its detection more susceptible to noisy backgrounds. To alleviate the disturbance of noisy backgrounds on HOI detection, it is necessary to consider the input image information to generate fine-grained anchors which are then leveraged to guide the detection of HOI instances. However, it has the following challenges. <inline-formula><tex-math notation=""LaTeX"">$i)$</tex-math></inline-formula> how to extract pivotal features from the images with complex background information is still an open question. <inline-formula><tex-math notation=""LaTeX"">$ii)$</tex-math></inline-formula> how to semantically align the extracted features and query embeddings is also a difficult issue. In this paper, a novel end-to-end transformer-based framework (FGAHOI) is proposed to alleviate the above problems. FGAHOI comprises three dedicated components namely, <bold>multi-scale sampling (MSS)</bold>, <bold>hierarchical spatial-aware merging (HSAM)</bold> and <bold>task-aware merging mechanism (TAM)</bold>. MSS extracts features of humans, objects and interaction areas from noisy backgrounds for HOI instances of various scales. HSAM and TAM semantically align and merge the extracted features and query embeddings in the hierarchical spatial and task perspectives in turn. In the meanwhile, a novel training strategy <bold>Stage-wise Training Strategy</bold> is designed to reduce the training pressure caused by overly complex tasks done by FGAHOI. In addition, we propose two ways to measure the difficulty of HOI detection and a novel dataset, <inline-formula><tex-math notation=""LaTeX"">$i.e.$</tex-math></inline-formula>, HOI-SDC for the two challenges (<bold>Uneven Distributed Area in Human-Object Pairs</bold> and <bold>Long Distance Visual Modeling of Human-Object Pairs</bold>) of HOI instances detection. Experiments are conducted on three benchmarks: HICO-DET, HOI-SDC and V-COCO. Our model outperforms the state-of-the-art HOI detection methods, and the extensive ablations reveal the merits of our proposed contribution. The code is available at <uri>https://github.com/xiaomabufei/FGAHOI</uri>. IEEE",TextMining
"3D point cloud data semantic mining plays a key role in 3D scene understanding. Although recent point cloud semantic mining methods have achieved great success, they require large amounts of expensive manual annotated data. More importantly, the lack of large-scale annotated datasets limits those approaches in many real-world applications, especially for point-level semantic mining tasks such as point cloud semantic segmentation. In this work, we propose a novel point cloud segmentation framework, called Point-level Label-free Segmentation framework (PLS), that does not require point-level annotations. In this framework, the point cloud semantic mining task is formulated as a clustering problem based on mutual information. Meanwhile, our method can directly predict clusters that correspond to the given semantic classes in a single feed-forward pass of a neural network. We apply the proposed PLS to the shape part segmentation task. Experiments on the benchmark ShapeNetPart dataset demonstrate that our method has the ability to discover clusters that match semantic classes, and it can produce comparable results with methods using incomplete labels on several categories. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Smart healthcare based on the Internet of Things (IoT) is becoming increasingly important in the era of cutting-edge digital technology to combat the ongoing COVID-19 pandemic. The Internet of Healthcare Things (IoHT) is a potential technique for quick diagnosis, on-going tracking and monitoring, improved therapy, and control without further virus propagation. Different cutting-edge and ground-breaking computer technologies are already having amazing effects in other industries. IoT, blockchain, machine learning, data mining, natural language processing, image processing, cloud computing, and many other technologies are among these. Thus, the healthcare sector stands a better a chance to advance with the use of the IoT to tackle any future pandemics seamlessly without loss of resources in all areas of human endeavor. Additionally, the cost-effective implementation of emergency measures can reduce the pressures caused by medical device scarcity and maintain a systematic database for modeling and predicting disease activity for better planning, preparedness, and online consultation. Moreover, this research is timely as it will aid in guiding policy makers in the health sector on how to effectively tackle the internal and external factors slowing down e-health. This chapter discusses the role of IoT-based technologies during the pandemic, IoT-based solutions in containing the pandemic, the state-of-the-art-architecture, applications, platforms, and the SWOT of IoHT. © 2023 Elsevier Inc. All rights reserved.",TextMining
"The surge in online shopping has led to an increase in online customer reviews (OCRs), posing challenges for product selection based on product features and customer sentiment. This is where the combination of multicriteria decision-making (MCDM) and sentiment analysis (SA) methods come in. In this article, we propose a hybrid approach for product ranking that addresses challenges identified in previous studies. These challenges include accurately considering feature interdependencies, identifying hesitancy and uncertainty in consumer purchase decisions, and using a more robust method for ranking alternative products. In doing so, we utilize SA and unsupervised machine learning to extract features from OCRs. We employ a combination of association rule mining (ARM) and fuzzy cognitive maps (FCM) to calculate feature weights based on interdependencies among features. In addition, we formulate a decision matrix using sentiment orientation and intuitionistic fuzzy theory. The interval-valued intuitionistic fuzzy (IVIF) theory ensures reliable decision-making information. The IVIF-multiobjective optimization by ratio analysis plus full multiplicative form method (MULTIMOORA) is applied to rank alternative products. Using Amazon comments, five mobile phones are ranked to demonstrate the methodology. The proposed framework improves decision-making in product selection based on OCRs by considering feature interdependencies. Sensitivity analysis and comparisons with other MCDM methods evaluate its robustness. By addressing previous limitations and incorporating interdependencies among features, this comprehensive approach provides reliable decision-making in product selection based on OCRs. IEEE",TextMining
"Attribute reduction, also known as feature selection, for decision information systems is one of the most pivotal issues in machine learning and data mining. Approaches based on the rough set theory and some extensions were proved to be efficient for dealing with the problem of attribute reduction. Unfortunately, the intuitionistic fuzzy sets based methods have not received much interest, while these methods are well-known as a very powerful approach to noisy decision tables, i.e., data tables with the low initial classification accuracy. Therefore, this paper provides a novel incremental attribute reduction method to deal more effectively with noisy decision tables, especially for high-dimensional ones. In particular, we define a new reduct and then design an original attribute reduction method based on the distance measure between two intuitionistic fuzzy partitions. It should be noted that the intuitionistic fuzzy partition distance is well-known as an effective measure to determine important attributes. More interestingly, an incremental formula is also developed to quickly compute the intuitionistic fuzzy partition distance in case when the decision table increases in the number of objects. This formula is then applied to construct an incremental attribute reduction algorithm for handling such dynamic tables. Besides, some experiments are conducted on real datasets to show that our method is far superior to the fuzzy rough set based methods in terms of the size of reduct and the classification accuracy. © 2023 CRL Publishing. All rights reserved.",TextMining
"Discovering valuable knowledge from massive time series data is challenging due to sophisticated temporal relationships and inherent uncertainties. This paper proposes a new multigranularity fuzzy association analysis of multigranularity incorporated with three-way decisions inspired by humans. In particular, different fuzzy association rules are first mined at multiple time granularities. A three-way decision model is then designed to evaluate the credibility of each rule as a &#x201C;positive&#x201D;, &#x201C;negative&#x201D;, or &#x201C;unknown&#x201D; correlation. Further, we propose a novel deep learning approach to integrate the three-way fuzzy decisions across different granularities. By integrating the three-way decisions, more comprehensive and reliable fuzzy association knowledge can be obtained from Big Data from time series at different granularities, achieving more comprehensive and reliable discoveries than existing techniques. Extensive experiments demonstrate significant performance gains in real-world data sets from various domains. The synergistic integration of multigranularity mining, three-way decisions, and deep learning underpins a new problem solving paradigm to advance temporal knowledge discovery. IEEE",TextMining
"Density-based clustering techniques are widely used in data mining on various fields. DBSCAN is one of the most popular density-based clustering algorithms, characterized by its ability to discover clusters with different shapes and sizes, and to separate noise and outliers. However, two fundamental limitations are still encountered that is the required input parameter of Eps distance threshold and its inefficiency to cluster datasets with various densities. For overcoming such drawbacks, a statistical based technique is proposed in this work. Specifically, the proposed technique utilizes an appropriate k-nearest neighbor density, based on which it sorts the dataset in ascending order and, using the statistical Chebyshev’s inequality as a suitable means for handling arbitrary distributions, it automatically determines different Eps values for clusters of various densities. Experiments conducted on synthetic and real datasets have demonstrated its efficiency and accuracy. The results indicate its superiority compared with DBSCAN, DPC, and their recently proposed improvements. © 2023 Slovene Society Informatika. All rights reserved.",TextMining
"Data is found in a variety of digital compositions: email messages, spreadsheets, images, sound files. Many tools have been designed to assist in automatically extracting data from certain formats. Optical Character Recognition (known as OCR) can be used to convert images into text, though not always in a structured and useful format. Natural-language processing (known as NLP) allows computers to extract information from text written in the natural language form. Is there a method to allow multiple forms of information to be received by a system and automatically pull the desired data from those different formats? For example, if a customer submits a purchase order as a scanned image that we want to automatically pull item numbers from, what is the ideal method for processing that file and information? Similarly, if a customer submits an order in an email message in prose or with an embedded table, what are our options for extracting the desired information? This paper will review technologies that use OCR, NLP, and artificial intelligence to determine optimal options for extracting data from a variety of inputs. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",TextMining
"Purpose: On the one hand, this paper is to further understand the residents' differentiated power consumption behaviors and tap the residential family characteristics labels from the perspective of electricity stability. On the other hand, this paper is to address the problem of lack of causal relationship in the existing research on the association analysis of residential electricity consumption behavior and basic information data. Design/methodology/approach: First, the density-based spatial clustering of applications with noise method is used to extract the typical daily load curve of residents. Second, the degree of electricity consumption stability is described from three perspectives: daily minimum load rate, daily load rate and daily load fluctuation rate, and is evaluated comprehensively using the entropy weight method. Finally, residential customer labels are constructed from sociological characteristics, residential characteristics and energy use attitudes, and the enhanced FP-growth algorithm is employed to investigate any potential links between each factor and the stability of electricity consumption. Findings: Compared with the original FP-growth algorithm, the improved algorithm can realize the excavation of rules containing specific attribute labels, which improves the excavation efficiency. In terms of factors influencing electricity stability, characteristics such as a large number of family members, being well employed, having children in the household and newer dwelling labels may all lead to poorer electricity stability, but residents' attitudes toward energy use and dwelling type are not significantly associated with electricity stability. Originality/value: This paper aims to uncover household socioeconomic traits that influence the stability of home electricity use and to shed light on the intricate connections between them. Firstly, in this article, from the perspective of electricity stability, the characteristics of the power consumption of residents' users are refined. And the authors use the entropy weight method to comprehensively evaluate the stability of electricity usage. Secondly, the labels of residential users' household characteristics are screened and organized. Finally, the improved FP-growth algorithm is used to mine the residential household characteristic labels that are strongly associated with electricity consumption stability. Highlights: The stability of electricity consumption is important to the stable operation of the grid. An improved FP-growth algorithm is employed to explore the influencing factors. The improved algorithm enables the mining of rules containing specific attribute labels. Residents' attitudes toward energy use are largely unrelated to the stability of electricity use. © 2023, Emerald Publishing Limited.",TextMining
"Event argument extraction (EAE), aiming at identifying event arguments over multiple sentences, mainly faces data sparsity problem. Cross-domain data augmentation can leverage annotated data to augment training data, but always encounters the issue of noise. The noise mainly consists of two aspects: boundary annotation differences and domain knowledge discrepancy, which may significantly impact the effectiveness of data augmentation. In this paper, we propose a new framework NTDA (Noise-Tolerant Data Augmentation) to solve the above two issues. For annotation differences, we introduce region-based loss function to mitigate the model’s sensitivity towards entity boundaries. To address the knowledge discrepancy problem, we propose a dynamic data selection strategy. Additionally, we further combine the two denoising techniques. Through conducting comprehensive experiments on three datasets, we have demonstrated the superior effectiveness of our framework compared to previous methods. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",TextMining
"Over the past few years, several software companies have emerged that offer process mining tools to assist enterprises in gaining insights into their process executions. However, the effective application of process mining technologies depends on analysts who need to be proficient in managing process mining projects and providing process insights and improvement opportunities. To contribute to a better understanding of the difficulties encountered by analysts and to pave the way for the development of enhanced and tailored support for them, this work reveals the challenges they perceive in practice. In particular, we identify 23 challenges based on interviews with 41 analysts, which we validate using a questionnaire survey. We provide insights into the relevancy of the process mining challenges and present mitigation strategies applied in practice to overcome them. While mitigation strategies exist, our findings imply the need for further research to provide support for analysts along all phases of process mining projects on the individual level, but also the technical, group, and organizational levels. © 2023, The Author(s).",TextMining
"Process mining is a family of techniques that exploit data collected from process execution to analyze and improve process efficiency, quality, and security. Over the years, many modeling languages have been proposed for process model specification, with different expressiveness, features, and computational properties. We propose a new logic-based declarative formalism, Constraint Formulae, to compose process specifications expressed in heterogeneous process modeling languages without altering their original semantics. We formalize common process mining tasks for Constraint Formulae, study their computational properties, and provide an implementation in Answer Set Programming. © 2023 Proceedings of the International Conference on Knowledge Representation and Reasoning. All rights reserved",TextMining
"The article aims to identify memorable gastronomic experiences reported online and verify their relationships with the type of cuisine served and restaurant location. This study used text mining, LDA, Pearson’s chi-squared test and sentiment analysis. All 48,378 English reviews posted by TripAdvisor users concerning 155 restaurants in Krakow were scraped. Eight features that characterise MGEs were identified (service/staff, atmosphere, cuisine/food (taste), drinks, local specialities, location/setting, price & value and table booking). There are statistically significant differences in the frequency of the topic experiences depending on the location of restaurants in the city. © 2023, Polska Akademia Nauk. All rights reserved.",TextMining
"Several recent studies have generated experimental performance data for narrow-gap thermionic energy conversion devices. This investigation explores the use of genetic algorithm methods to fit existing data from literature with physics-inspired model equations. The resulting model equations can be used for performance prediction for system design optimization, or to explore parametric effects on performance. The model equations incorporate Richardson’s law for current density, including both the saturated and Boltzmann regimes, with appropriate relations for power delivered to the external load. The transition regime is characterized using two separate models, each accounting for non-uniformity in emission surfaces and other irregularities in the manufacturing process that impact the output power density. The trained models enable performance prediction of a small-gap thermionic energy conversion device with inputs of only emitter temperature and load resistance. The prototype data considered here tested a thermionic energy conversion device to determine the output current and output power as a function of diode voltage and the emitter temperature. In this study, the prototype test data is used with postulated work function for the emitter and the collector materials and two additional parameters to characterize the transition region. As a result, these postulated functions are substituted into the physics-inspired models, yielding performance models with three adjustable constants. Optimized values of these constants are determined using a genetic algorithm to best fit the experimentally determined performance data for prototype thermionic conversion devices tested in earlier studies. This process yields four insightful results. First, this work demonstrated two pathways to a model that can accurately predict performance trends. The developed models can also be used for design optimization and provide a pathway to a data-driven performance model. The two performance models each provide a method for extracting work function information from performance data.The extracted work function ultimately proves to be independent of the performance model used, as both models produce the same effective work function values for the prototype device. Finally, both of the final three-regime models illuminate the transition region between the saturated and Boltzmann regime. Copyright © 2023 by ASME.",TextMining
The proceedings contain 216 papers. The special focus in this conference is on Advanced Data Mining and Applications. The topics include: A Novel Variational Autoencoder with Multi-position Latent Self-attention and Actor-Critic for Recommendation; fair Re-Ranking Recommendation Based on Debiased Multi-graph Representations; FastNER: Speeding up Inferences for Named Entity Recognition Tasks; CPMFA: A Character Pair-Based Method for Chinese Nested Named Entity Recognition; STMC-GCN: A Span Tagging Multi-channel Graph Convolutional Network for Aspect Sentiment Triplet Extraction; exploring the Design Space of Unsupervised Blocking with Pre-trained Language Models in Entity Resolution; joint Modeling of Local and Global Semantics for Contrastive Entity Disambiguation; KFEA: Fine-Grained Review Analysis Using BERT with Attention: A Categorical and Rating-Based Approach; discovery of Emotion Implicit Causes in Products Based on Commonsense Reasoning; from Time Series to Multi-modality: Classifying Multivariate Time Series via Both 1D and 2D Representations; multi-modal Multi-emotion Emotional Support Conversation; exploiting Pseudo Future Contexts for Emotion Recognition in Conversations; generating Enlightened Suggestions Based on Mental State Evolution for Emotional Support Conversation; deep One-Class Fine-Tuning for Imbalanced Short Text Classification in Transfer Learning; EmoKnow: Emotion- and Knowledge-Oriented Model for COVID-19 Fake News Detection; popular Songs: The Sentiment Surrounding the Conversation; market Sentiment Analysis Based on Social Media and Trading Volume for Asset Price Movement Prediction; efficient Mining of High Utility Co-location Patterns Based on a Query Strategy; point-Level Label-Free Segmentation Framework for 3D Point Cloud Semantic Mining; CD-BNN: Causal Discovery with Bayesian Neural Network; exploring the Effectiveness of Positional Embedding on Transformer-Based Architectures for Multivariate Time Series Classification; a Preference-Based Indicator Selection Hyper-Heuristic for Optimization Problems; an Elastic Scalable Grouping for Stateful Operators in Stream Computing Systems; incremental Natural Gradient Boosting for Probabilistic Regression; discovering Skyline Periodic Itemset Patterns in Transaction Sequences; Double-Optimized CS-BP Anomaly Prediction for Control Operation Data.,TextMining
"The Musan mine, situated in Musan County, Hamgyong Province, North Korea, stands as a prominent open-pit iron mine on the Korean Peninsula. This study focuses on estimating the mining and dumping activities within the Musan mine area by analyzing digital elevation model (DEM) changes. To calculate the long-term volume changes in the Musan mine, we digitized and converted the 1:200,000-scale third topographic map of the Joseon published in 1918 and compared with interferometric synthetic aperture radar (InSAR) DEMs, including Shuttle Radar Topography Mission DEM (2000) and Copernicus DEM (2011–2015). The findings reveal that over a century, Musan mine yielded around 1.37 billion tons of iron ore, while approximately 1.06 billion tons of waste rock were dumped. This study is particularly significant as it utilizes a historical topographic map predating the full-scale development of Musan mine to estimate a century’s mining production and waste rock deposition. It is expected that this research provides valuable insights for future investigation of surface change of North Korea where the acquisition of in situ data remains challenging. Copyright © 2023 by The Korean Society of Remote Sensing.",TextMining
"Compared with English Named Entity Recognition (NER), Chinese Named Entity Recognition (CNER) has a high difficulty in word segmentation, and accurate extraction of contextual semantic feature information is a key work of CNER. For that, we propose a CNER model to extract both local and global contextual semantic feature information. First, we propose to apply the dynamic convolutional kernel to the convolutional layer of TCN to enhance the local features of contextual semantic feature information. Second, we define a dynamic scaling factor computation method to compute the correlation between named entity characters in the multihead attention, which to process the problem of sparse distribution of named entities, and can efficiently extract the global features of contextual semantics. We validated the effectiveness of the proposed model on the Weibo dataset with an F1 value of 89.24%, which is better than commonly used models.  © ; 2023 The Authors.",TextMining
"Cotton is one of the most significant cash crops in the world, and it is also the main source of natural fiber for textiles. It is crucial for cotton management to identify the spatiotemporal distribution of cotton planting areas timely and accurately on a fine scale. However, previous research studies have predominantly concentrated on specific years using remote sensing data. Challenges still exist in the extraction of cotton areas for long time series with high accuracy. To address this issue, a novel cotton sample selection method was proposed and the machine learning method is employed to effectively identify the long time series cotton planting areas at a 30-m resolution scale. Bortala and Shuanghe in Xinjiang, China, were selected as the study cases to demonstrate the approach. Specifically, the cropland in this study was extracted by using an object-oriented classification method with Landsat images and the results were optimized as the vectorized boundary of croplands. Then, the cotton samples were selected using the Normalized Difference Vegetation Index (NDVI) series of Moderate Resolution Imaging Spectroradiometer (MODIS) based on its phenological characteristics. Next, cotton was identified based on the croplands from 2000 to 2020 by using the machine learning model. Finally, the performance was evaluated, and the spatiotemporal distribution characteristics of cotton planting areas were analyzed. The results showed that the proposed approach can achieve high accuracy at a fine spatial resolution. The performance evaluation indicated the applicability and suitability of the method, there is a good correlation between the extracted cotton areas and statistical data, and the cotton area of the study area showed an increasing trend. The cotton spatial distribution pattern developed from dispersion to agglomeration. The proposed approach and the derived 30-m cotton maps can provide a scientific reference for the optimization of agricultural management. © 2023 Wuhan University. Published by Informa UK Limited, trading as Taylor & Francis Group.",TextMining
"Estimating the impact of economic policy uncertainty (EPU) on enterprise ambidextrous innovation can provide insight into firms’ current innovation choice orientation, but few studies systematically reveal the relationship between the two. We have developed a new investment valuation construct that includes three parts: the direct net present value, growth option value, and strategic preemption value. Based on this, we systematically expound the relationship between EPU and enterprise ambidextrous innovation and explore the moderating effect of government subsidies and managerial ownership. Using the patent text mining data of Chinese A-share listed companies in Shanghai and Shenzhen from 2010 to 2019 and exploiting the world average temperature as an instrument for EPU, we find that EPU promotes enterprise’s exploitative innovation and inhibits enterprise’s exploratory innovation through the redistribution of R&D investment in ambidextrous innovation. Government subsidies negatively moderate the relationship between EPU and enterprise exploitative innovation, but have no moderating effect on the relationship between EPU and enterprise exploratory innovation. While managerial ownership positively moderates the relationship between EPU and enterprise exploitative innovation, no evidence of a moderating effect was found in the relationship between EPU and enterprise exploratory innovation. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Complex industrial process modelling is critically important within the context of industrial intelligence. In recent years, soft sensor techniques based on neural networks have become increasingly popular for modelling nonlinear industrial processes. This paper proposes an integrated framework of neural network modelling and evaluation for nonlinear dynamic processes. This framework achieves an integrated solution for modelling, prediction, evaluation, and network structure parameter selection. It can be applied to noisy sensors and dense data in the time domain. The framework's proposed evaluation mechanism employs two novel evaluation metrics, the variational auto-encoder (VAE)-based Kullback–Leibler (KL) divergence metric and the maximum likelihood estimation-based J metric, which both evaluate the model by mining the statistical properties of the residuals. The framework models the dynamic process with a model order based-gated recurrent units (MOb-GRU) neural network and a modified transformer model. Numerical experiments demonstrate that the evaluation mechanism functions properly in scenarios with multiple signal-to-noise ratios and multiple noise statistical properties and that the framework produces accurate modelling results. © 2023 Canadian Society for Chemical Engineering.",TextMining
"Civil servants play a crucial role in serving the government and the people, requiring them to possess both competent skills and organizational performance to fulfill the objectives of their respective organizations. To ensure the acquisition of high-quality civil servants with the right competencies and potential for promotion, a robust selection system is necessary. This paper focuses on utilizing data mining techniques to predict employee performance based on talent pool assessment results, thereby aiding in the identification of suitable candidates for target positions. The study employs predictive analytics to analyse the assessment data and predict the performance of employees in their designated roles. The data preprocessing stage involves the utilization of techniques such as one-hot encoding and feature selection to enhance the accuracy of the subsequent analysis. Several classification algorithms, including Naïve Bayes, Decision Tree, Random Forest, Support Vector Machine, and K-NN, are utilized to train models and attain the highest possible accuracy for the assessment system. The application of data mining techniques in the field of Human Resources, particularly in the government sector, offers valuable insights for predicting the suitability and qualification of candidates for specific positions. By leveraging these techniques, organizations can effectively identify individuals who possess the necessary competencies to thrive in their assigned roles. Overall, this paper emphasizes the importance of a robust selection process for civil servants and presents a practical approach utilizing data mining techniques to predict employee performance. The results obtained from this study can contribute to the development of more efficient and reliable assessment systems in the public sector, enabling organizations to make informed decisions when assigning individuals to key positions. © 2023, Success Culture Press. All rights reserved.",TextMining
"The data encountered by Session-based Recommendation System(SBRS) is typically highly sparse, which also serves as one of the bottlenecks limiting the accuracy of recommendations. So Contrastive Learning(CL) is applied in SBRS owing to its capability of improving embedding learning under the condition of sparse data. However, existing CL strategies are limited in their ability to enforce finer-grained (e.g., factor-level) comparisons and, as a result, are unable to capture subtle differences between instances. More than that, these strategies usually use item or segment dropout as a means of data augmentation which may result in sparser data and thus ineffective self-supervised signals. By addressing the two aforementioned limitations, we introduce a novel dual-granularity CL framework. Specifically, two extra augmentation views with different granularities are constructed and the embeddings learned by them are compared with those learned from original view to complete the CL tasks. At factor-level, we employ Disentangled Representation Learning to obtain finer-grained data, with which we can explore connections of items on latent factor independently and generate factor-level embeddings. At item-level, the star graph is deployed as the augmentation method. By setting an additional satellite node, non-adjacent nodes can establish additional connections through satellite nodes instead of reducing the connections of the original graph, so data sparsity can be avoided. Compare the learned embeddings of these two views with the learned embeddings of the original view to achieve CL at two granularities. Finally, the item-level and factor-level embeddings obtained are referenced to generate personalized recommendations for the user. The proposed model is validated through extensive experiments on two benchmark datasets, showcasing superior performance compared to existing methods. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"As powerful and complex language models are being released to the public, understanding their behaviour is more important than ever. Although Explainable Artificial Intelligence (XAI) approaches have been widely applied to NLP models, the explanations they provide may still be complex to understand for human interpreters as these may not be aligned with the reasoning process they apply in language-based tasks. Furthermore, such a misalignment is also present in most XAI datasets as they are not structured to reflect such a fundamental property. Striving to bridge the gap between model and human reasoning, we propose ad hoc formalizations to structure and detail the thought process applied by human interpreters when performing a set of NLP tasks of interest. Hence, we define rationale mappings, i.e., representations that organize humans' analytical reasoning steps when identifying and associating the essential parts of the texts involved in a language-based task leading to its output. These are organized in tree structures referred to as rationale trees and characterized for each task to enhance their expressiveness. Furthermore, we describe their data collection and storage process. We argue these structures would result in a better alignment between model and human reasoning, hence improving models' explanations, while still being suited for standard explainability processes. © 2023 CEUR-WS. All rights reserved.",TextMining
"As more and more netizens participate in financial market transactions, online discussions on asset price movements are becoming more comprehensive and timely. Online text, especially from social media, has the potential to be an important data source for financial opinion mining. Market sentiment analysis mainly includes direct analysis methods in the form of text-based surveys and indirect inference methods based on structured data such as price, trading volume, and volatility. In theory, the former is helpful for us to understand investor sentiment earlier, but due to the difficulty of obtaining a sufficient number of objective survey samples, its obtained research attentions are far less than the latter. To combine the advantages and offset the weakness of these two approaches, this paper uses Valence Aware Dictionary and Sentiment Reasoner (VADER) and Fast Fourier Transform (FFT) to construct social media sentiment indexes based on plenty of daily discussion texts about Bitcoin (BTC) and S &P500 (SPX) from Reddit for analyzing their interaction with prices. We also propose a new time series synchronization verification method called Rolling Time-lagged Cross-correlation (RTLCC) surface, and corresponding feature constructing methods, in which RTLCC helps us observe Time-lagged Cross-correlation from the perspective of Rolling Correlation while determining the hyperparameters (Window Size & Time Offset) for features construction. Finally, based on these features, we use four machine learning classifiers for modeling and verify the effectiveness of the proposed market sentiment analysis pipeline, in which on the prediction of 10-day price movements, the best model achieves 89.9% in accuracy (ACC) and 92.5% in AUC. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",TextMining
"Parking violation is a common urban problem in major cities all over the world. Traditional approaches for detecting parking violations mainly rely on fixed deployed sensors and enforcement agencies, which suffer from high deployment costs and limited coverage. With the rapid development of mobile networks, Mobile CrowdSensing (MCS) has been an effective sensing paradigm. The crowdsensing data can help predict the future parking violation distribution, and the prediction results can provide guidance for user scheduling, i.e., sending the mobile users to patrol areas where many parking violation events may occur. Inspired by this idea, we propose a comprehensive data-driven crowdsensing framework, which incorporates the nested design of a generative model for spatial-temporal data and a user scheduling model. The generative model extracts parking violation hotspots via a data completion module and violation prediction module. Since crowdsensing data is usually temporally sparse and unevenly distributed, a data completion module is proposed to infer the missing statistics in unsensed areas. The violation prediction module then predicts the parking violation distribution. Given the predicted results, the deep reinforcement learning-based user scheduling model coordinates users to visit hotspots for violation detection. Iteratively, the newly collected data can be used to predict the future violation distribution. Finally, we conduct extensive simulations based on two real-world datasets from two large urban cities. The simulation verifies the prediction accuracy and scheduling effectiveness of the proposed framework compared with the baselines. IEEE",TextMining
"The challenge of concept drift detection is crucial in machine learning, especially in dynamic contexts where the underlying data distribution can vary over time. For the purpose of identifying concept drift, we suggest a sliding adaptive beta distribution model (SABeDM) in this study. SABeDM combines the adaptive sliding window and beta distribution techniques to track modifications in the underlying distribution of the data stream. Several synthetic and real-world datasets are used to assess the proposed model, and it is then contrasted with cutting-edge drift detection systems. Regarding detecting true positive, false positive, false negative, and delay, our experimental results demonstrate that SABeDM works better than the currently used methods (SRP, ADWIN, DDM, and EDDM). Accuracy, precision, recall, and F1-score were also utilised as evaluation criteria. When used in a variety of applications, such as online learning, data stream mining, and real-time monitoring systems, SABeDM offers an effective and fast way to identify concept drift in a dynamic context. The proposed approach is a promising tool for machine learning practitioners to use in practical applications since it can help to enhance the dependability and accuracy of decision-making systems in dynamic situations. © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",TextMining
"Dimensionality reduction (DR) is important for feature extraction and classification of hyperspectral images (HSIs). Recently proposed superpixel-based DR models have shown promising performance, where superpixel segmentation techniques were applied to segment an HSI and then DR models like principal component analysis (PCA) or linear discriminant analysis (LDA) were employed to extract the local and/or global features. However, superpixelwise PCA (SuperPCA)-based local features are unsatisfactory because PCA aims to extract features with high variance, which could be inefficient in superpixels with mixed objects or strong noise/outliers. In addition, superpixelwise unsupervised LDA (SuperULDA) based global features may neglect local (spatial-contextual) information. To address these issues, we propose a new spectral-spatial and superpixelwise unsupervised LDA (S3-ULDA) model for unsupervised feature extraction from HSIs. Specifically, the HSI is first segmented into various superpixels with pseudo labels. Then, superpixel-based local reconstruction for HSI denoising is conducted. Next, SuperULDA is performed on both the original HSI and locally reconstructed data to extract global features. Then, superpixelwise unsupervised local Fisher discriminant analysis (SuperULFDA) is developed for local feature extraction, where each superpixel and its adjacent superpixels (along with their pseudo-labels) are fed into local Fisher discriminant analysis (LFDA) to extract local features. The superpixel-level local manifold structures can be effectively modeled by the proposed SuperULFDA. Finally, by fusing the extracted global and local features, novel global-local and spectral-spatial features can be obtained. Our experimental results on several benchmark HSIs demonstrate the superiority of the proposed method over state-of-The-Art methods. The code of the proposed model is available at https://github.com/XinweiJiang/S3-ULDA. © 1980-2012 IEEE.",TextMining
"In the domain of tunnel lining defect detection, object detection algorithms have been widely employed. However, existing algorithms suffer from inadequate extraction of global information and low detection accuracy. To address these issues, a novel algorithm called Tunnel Defect Detection You Only Look Once (TDD-YOLO) is proposed, leveraging the YOLOv7 framework. The TDD-YOLO algorithm incorporates several enhancements to improve global and local information extraction capabilities, thereby enhancing defect detection accuracy. Firstly, MobileViT is utilized as the backbone feature extraction network, augmenting the network's ability to extract comprehensive information from both global and local contexts. Secondly, a Coordinate Attention (CA) module is introduced after the upsampling and downsampling stages of the feature pyramid network. This module highlights defect-related features while eliminating background interference. Lastly, a convolutional module called TP Block is devised to further enhance the network's feature extraction capability with reduced computational complexity. To validate the effectiveness of the proposed algorithm, a comparative analysis is conducted against five existing algorithms: SSD, Faster-RCNN, EfficientDet, YOLOv5, and YOLOv7. Experimental results demonstrate that the TDD-YOLO algorithm achieves superior performance with an F1 score of 77.43% and a mean Average Precision (mAP) of 77.52%. These results surpass those of the other five algorithms, establishing the TDD-YOLO algorithm as the most accurate and suitable solution for defect detection tasks in tunnels.  © 2013 IEEE.",TextMining
"In recent years, optical remote sensing image (ORSI) scene analysis has attracted increasing interest. However, existing networks show a trend of bifurcation. Lightweight networks have very high inference speed but poor inference of contextual information in highly complex backgrounds. In contrast, networks with high-performance contextual information reasoning capability require many parameters and are computationally expensive. Since the knowledge distillation method can greatly lighten the model, we propose a graph semantic guided network (GSGNet) that utilizes knowledge refinement for ORSI scenario analysis, which has a high inference speed while maintaining practical contextual inference capability. Rich semantic and detailed information facilitates semantic segmentation of optical remote sensing images. We design adjacent dynamic capture and local-global map inference modules that can effectively extract low-level spatial details and high-level contextual semantics. To improve the attention map relearning performance of the distillation method, we designed semantically guided fusion modules to locate spatial information and refine edge information. We also employed a structural relationship transfer distillation method in which the structural relationship knowledge of the teacher model (GSGNet-T) was used to guide the student model (GSGNet-S). We compared the performances of GSGNet-T and the GSGNet-S with knowledge distillation (GSGNet-S*) with those of several state-of-the-art methods on the Vaihingen and Potsdam datasets. Extensive experiments showed that GSGNet-S* outperformed most advanced methods with only 19.61M parameters and a computation cost of 2.9G FLOPs. The experimental results and code of our network can be accessed at the following URL: https://github.com/LYZ00918/GSGNet-KD. IEEE",TextMining
"Dump sites with broken overburden layers in surface mines have the risk of instability due to their loose bulk structures. In this study, deformations at a dump site of the Kangal/Kalburçayırı open-pit coal mine and their long-term behaviours were revealed with InSAR data for a total period of 4.5 years. Firstly, 9-periods involving different time ranges were created considering the presence of LiCSAR products. Then, the deformation velocities of each period were calculated by LiCSBAS software using LiCSAR products. The area where high deformations were concentrated from the LiCSBAS result products was determined and divided into 4 zones for more detailed evaluations. At the final stage, the period-deformation velocity graphs were drawn separately for each zone with the data obtained using two different approaches from the deformation velocities of all periods, and long-term deformation behaviours were determined. More reliable future behaviour projections could be made considering the current increasing or decreasing trend of deformation behaviours. It was revealed that vertical deformations at the dump site had an increasing trend in the first periods and a decreasing trend in the later periods. Maximum vertical deformation velocities ranging between −111.4 mm/year and −178.0 mm/year in the first 4 months reached the highest values (ranging from −141.9 mm/year to −261.8 mm/year) at the end of two years and decreased to values ranging from −33.0 mm/year to −44.3 mm/year in the later periods. It was found that horizontal deformation velocities ranged between +0.5 mm/year and +55.4 mm/year in the east–west direction and between −7.0 mm/year and −56.8 mm/year in the west-east direction, were approximately 5 times lower than vertical velocities and did not have a constantly increasing or decreasing trend in any direction. It was observed that deformations exhibited a behaviour resulting from the structural property of the dump bulk material. The results of the evaluations showed that the risk of instability gradually decreased at the dump site. The methodology of this study can enable the determination of similar areas that may pose a threat in a short time, the prioritization of risky areas, the planning of more detailed studies, and taking the necessary measures in a timely manner. © 2023 COSPAR",TextMining
"Nitrogen (N) is an essential factor for limiting crop yields, and cultivation of crops with low nitrogen-use efficiency (NUE) exhibits increasing environmental and ecological risks. Hence, it is crucial to mine valuable NUE improvement genes, which is very important to develop and breed new crop varieties with high NUE in sustainable agriculture system. Quantitative trait locus (QTL) and genome-wide association study (GWAS) analysis are the most common methods for dissecting genetic variations underlying complex traits. In addition, with the advancement of biotechnology, multi-omics technologies can be used to accelerate the process of exploring genetic variations. In this study, we integrate the substantial data of QTLs, quantitative trait nucleotides (QTNs) from GWAS, and multi-omics data including transcriptome, proteome, and metabolome and further analyze their interactions to predict some NUE-related candidate genes. We also provide the genic resources for NUE improvement among maize, rice, wheat, and sorghum by homologous alignment and collinearity analysis. Furthermore, we propose to utilize the knowledge gained from classical cases to provide the frameworks for improving NUE and breeding N-efficient varieties through integrated genomics, systems biology, and modern breeding technologies. © 2023 Society for Experimental Biology and John Wiley & Sons Ltd.",TextMining
"The proceedings contain 28 papers. The special focus in this conference is on Knowledge Graph and Semantic Computing. The topics include: A Generalized Strategy of Chinese Grammatical Error Diagnosis Based on Task Decomposition and Transformation; conversational Search Based on Utterance-Mask-Passage Post-training; financial Fraud Detection Based on Deep Learning: Towards Large-Scale Pre-training Transformer Models; GERNS: A Graph Embedding with Repeat-Free Neighborhood Structure for Subgraph Matching Optimization; feature Enhanced Structured Reasoning for Question Answering; conditional Knowledge Graph: Design, Dataset and a Preliminary Model; ODKG: An Official Document Knowledge Graph for the Effective Management; CCD-ASQP: A Chinese Cross-Domain Aspect Sentiment Quadruple Prediction Dataset; move Structure Recognition in Scientific Papers with Saliency Attribution; causE: Towards Causal Knowledge Graph Embedding; Moral Essential Elements: MEE-A Dataset for Moral Judgement; improving Adaptive Knowledge Graph Construction via Large Language Models with Multiple Views; single Source Path-Based Graph Neural Network for Inductive Knowledge Graph Reasoning; a Graph Learning Based Method for Inductive Knowledge Graph Relation Prediction; LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base; Robust NL-to-Cypher Translation for KBQA: Harnessing Large Language Model with Chain of Prompts; in-Context Learning for Knowledge Base Question Answering for Unmanned Systems Based on Large Language Models; a Military Domain Knowledge-Based Question Answering Method Based on Large Language Model Enhancement; Advanced PromptCBLUE Performance: A Novel Approach Leveraging Large Language Models; exploring the Logical Expressiveness of Graph Neural Networks by Establishing a Connection with C2 ; research on Joint Representation Learning Methods for Entity Neighborhood Information and Description Information; harvesting Event Schemas from Large Language Models; NTDA: Noise-Tolerant Data Augmentation for Document-Level Event Argument Extraction; Event-Centric Opinion Mining via In-Context Learning with ChatGPT; relation Repository Based Adaptive Clustering for Open Relation Extraction.",TextMining
"Conventional methods of vacation preparation that rely on online reviews from numerous sources are frequently time-consuming and impersonal. Trip planning has a lot of options and many interesting insights can be generated by the rise of user-generated content. It has been examined already that with the aid of crowdsourcing, many difficult problems can be solved in a very limited time with less cost. This review provides a brief overview of all the mechanisms for crowdsourcing where multiple user-generated contents provide travelers with personalized trip information. Generally, the visitor ratings about the hotels are gathered from TripAdvisor. Similarly, image data from Flickr, and transportation rates between locations from Uber are collected. First, information on tourist sites from Flickr using geographic data mining techniques is extracted, and thereafter, natural language processing (NLP) is used to identify the multifaceted properties of hotels, and graph analysis to suggest travel routes. Second, researchers created a web-based interface that allows users to engage with the system and offers integrated recommendations for hotels, attractions, and restaurants. On the other hand, this chapter surveys various state-of-the-art techniques and recognizes the most encouraging research trend in tourism recommendation. The many selected methods evaluate the pipeline for mining tourism data streams to find techniques and technologies for real-time predictions guided by design principles for accountability, responsibility, and transparency. © 2024 Taylor & Francis Group, LLC.",TextMining
"Graph representations in fixed dimensional feature space are vital in applying learning tools and data mining algorithms to perform graph analytics. Such representations must encode the graph&#x0027;s topological and structural information at the local and global scales without posing significant computation overhead. This paper employs a unique approach grounded in networked control system theory to obtain expressive graph representations with desired properties. We consider graphs as networked dynamical systems and study their controllability properties to explore the underlying graph structure. The controllability of a networked dynamical system profoundly depends on the underlying network topology, and we exploit this relationship to design novel graph representations using controllability Gramian and related metrics. We discuss the merits of this new approach in terms of the desired properties (for instance, permutation and scale invariance) of the proposed representations. Our evaluation of various benchmark datasets in the graph classification framework demonstrates that the proposed representations either outperform (sometimes by more than 6 results to the state-of-the-art embeddings. IEEE",TextMining
"Artificial Intelligence (AI) is relatively new neurocomputational science employed in oil industry to solve wide spectrum of non-linear problems with high parallelism, fault and noise tolerance. AI seems very attractive for its remarkable capabilities of processing-correlating data and learning attributes. This paper briefs a successful implementation of an ecosystem between AI and physics-based models in a smart field, that support accurate well allocation process during the project start-up when testing facilities were not available. This case study is presented in a smart field during the commissioning of a new phase-project incorporating 45 new strings at a time. Reconciliation between wells and fiscal meters vanished after incorporating the newly commissioned wells with no flow-tests. An innovative AI-model was developed to estimate well rates from real-time surface parameters (pressure, temperature, choke &gas lift rate) to assist the allocation process for those strings, utilizing extensive well test history and subsurface data from pre-existing nearby wells. Data mining and physics-based models were integrated to develop an ecosystem that can virtually measure daily oil, water and gas rates with reasonable accuracy enhancing well back-allocation process. Initial newly-strings models were built using only one commissioning test, consisting of diverting wells to a portable separator for few hours. This practice usually overestimates the productivity index since rates are captured in transient mode. Later, when wells are flowing for longer and cleaned up, production rates decrease after stabilization. Fortunately, these changes of performance over time are well-captured by the real time parameters. Therefore, this paper proposal can be extended to other digital fields to track the well performance and minimize the error in back allocated rates as it was observed in this field application, demonstrating how reconciliation factor was continuously enhanced day after day, once AI-virtual rate prediction was introduced. AI-model prediction was later verified against actual flow tests via portable separators with an average error below 20%. Virtual rates were predicted using machine learning (ML) techniques multilinear regression, Artificial Neural-Network (ANN) and Self-Organizing Maps (SOM). The results were used to update models for better well performance prediction. The performance of these ML techniques were improved with intelligent inputs and proper segregated and intuitive training to machine. As a practical application, an ecosystem was developed combining AI and physics to predict well-performance of newly-drill wells under gas lift and natural flow, using real-time measurement and the digital framework, to provides reasonably accurate in simulating both training and test time-dependent well performance inferred from pressure, temperature, gas-lift rate and choke. The novelty of this paper consists in the developed data cleansing and association technics that enable the implementation of successful AI-models in wells with no flow test data for training, levering Real-Time data usage. © 2023, Society of Petroleum Engineers.",TextMining
"The development of mobile internet has made it easier for negative emotions, cognitions and behaviours expressed by customers to be spread, and the damage caused by negative customer engagement behaviours (NCEBs) to the company's brand value and reputation has gradually been amplified. Therefore, this study aims to explore the formation process of NCEBs in online brand community by combining qualitative method with quantitative method. Xiaomi Community was selected as the data source platform, using Python programming language to crawl users’ comments in ‘11Ultra circle’ and machine learning methods to obtain negative emotional polarity comments. The text coding and classification of negative emotion polarity comments are mainly based on manual coding and supplemented by machine learning. Perform binary logistic regression on the classified data to obtain the impact of various factors on NCEBs. The results showed that there were differences in the impact of different factors on NCEBs. This article obtains a different result from existing literature, that is, cognition and emotion are no longer necessary factors for the generation of NCEBs. Company managers should start with pricing, users’ cognition mining, and identifying and solving key issues reported by users to suppress the occurrence of NCEBs. © 2023 Informa UK Limited, trading as Taylor & Francis Group.",TextMining
"Cross-media web video hot topic detection has become a new research hotspot. However, there is less text; information to describe video, which makes the space of text semantic features sparse, resulting in weak correlation between text semantic features, which increases the difficulty of mining hot topics. The existing methods mainly enrich the text semantic feature space through visual information. However, due to the heterogeneity between visual and text information, the semantic features of text and visual are quite different under the same topic. This further reduces the correlation strength between text semantics under the same topic, and also brings great challenges to cross-media hot topic detection based on web videos. Therefore, we propose a new cross-media semantic association enhancement method. Firstly, the core semantic features of the text from the word and sentence levels through double-layer attention are captured; Secondly, by understanding the visual content, a large number of text descriptions highly related to the video content are generated to enrich the text semantic space; Then, through text semantic similarity and visual semantic similarity, the text semantic map and visual semantic map are constructed, and the time decay function is constructed to establish the correlation between cross-media data from the time dimension, so as to enhance the correlation strength between text and visual semantics, and smoothly fuse the two semantic maps into a hybrid semantic map to realize cross-media semantic complementarity; Finally, hot topics are detected by graph clustering method. A large number of experimental results show that the proposed model is superior to the existing methods. © 2023 Science Press. All rights reserved.",TextMining
"The demand for permanent magnets is expected to increase in the 2021–2030 decade, which will require a commensurate increase in the production of samarium (Sm) and neodymium (Nd). Since these metals are considered critical and due to their abundance in Brazilian territory, the Brazilian government and mining companies must master the refining of these metals through autochthonous technologies. Thus, we developed a process to separate the light (La, Ce, Pr and Nd) from the medium (Sm, Eu and Gd) and heavy (Tb-Lu and Y) rare earth elements (REE) with D2EHPA by empirical modeling of solvent extraction (SX) processes. The experimental methodology included three phases: equilibrium data acquisition from batch experiments, solvent extraction simulation, and continuous process trials to validate the model on a mini-pilot scale. Our simulation predicted 99.5% Sm organic recovery and 80% Nd aqueous recovery in a seven-stage process and 0.30 A/O ratio, validated in the continuous trial. This work paves the way for establishing Brazilian technology to obtain the constituent elements of permanent magnets. © 2023, The Author(s) under exclusive licence to Associação Brasileira de Engenharia Química.",TextMining
"Rapid societal and technological changes have driven enormous educational developments in learning styles and assessment. Due to the Coronavirus 2019 (COVID-19) epidemic, the world’s education system has recognized distance education’s importance in dealing with and solving asynchronous learning. Consequently, hybrid and blended learning have been proposed to support a learning process through a combination of face-to-face (onsite) and online learning. The learning process and activities arise from a more versatile and flexible teaching strategy than traditional learning patterns; however, the reliance on educational technology results in the dissemination and collection of massive amounts of data called big data. Thus, educational data mining and learning analytics have been applied for statistical and qualitative data analysis in hybrid learning and blended learning. Although these methods can be optimized for distinctive learning formats, the implementation varies depending on course structure and dataset characteristics. Therefore, this study analyzes and reviews different educational data mining and learning analytics methods and applications in hybrid and blended learning aspects. © 2023 Seventh Sense Research Group®",TextMining
"Lung cancer is a substantial health issue globally, and it is one of the main causes of mortality. Malignant mesothelioma (MM) is a common kind of lung cancer. The majority of patients with MM have no symptoms. In the diagnosis of any disease, etiology is crucial. MM risk factor detection procedures include positron emission tomography, magnetic resonance imaging, biopsies, X-rays, and blood tests, which are all necessary but costly and intrusive. Researchers primarily concentrated on the investigation of MM risk variables in the study. Mesothelioma symptoms were detected with the help of data from mesothelioma patients. The dataset, however, included both healthy and mesothelioma patients. Classification algorithms for MM illness diagnosis were carried out using computationally efficient data mining techniques. The support vector machine outperformed the multilayer perceptron ensembles (MLPE) neural network (NN) technique, yielding promising findings. With 99.87% classification accuracy achieved using 10-fold cross-validation over 5 runs, SVM is the best classification when contrasted to the MLPE NN, which achieves 99.56% classification accuracy. In addition, SPSS analysis is carried out for this study to collect pertinent and experimental data.  © 2023 the author(s), published by De Gruyter.",TextMining
"Feature selection algorithms are frequently employed in preprocessing machine learning pipelines applied to biological data to identify relevant features. The use of feature selection in gene expression studies began at the end of the 1990s with the analysis of human cancer microarray datasets. Since then, gene expression technology has been perfected, the Human Genome Project has been completed, new microarray platforms have been created and discontinued, and RNA-seq has gradually replaced microarrays. However, most feature selection methods in the last two decades were designed, evaluated, and validated on the same datasets from the microarray technology's infancy. In this review of over 1200 publications regarding feature selection and gene expression, published between 2010 and 2020, we found that 57% of the publications used at least one outdated dataset, 23% used only outdated data, and 32% did not cite data sources. Other issues include referencing databases that are no longer available, the slow adoption of RNA-seq datasets, and bias toward human cancer data, even for methods designed for a broader scope. In the most popular datasets, some being 23 years old, mislabeled samples, experimental biases, distribution shifts, and the absence of classification challenges are common. These problems are more predominant in publications with computer science backgrounds compared to publications from biology and can lead to inaccurate and misleading biological results. This article is categorized under: Algorithmic Development > Biological Data Mining Technologies > Machine Learning. © 2023 Wiley Periodicals LLC.",TextMining
"The objective of this paper is to share and introduce the Wells Around Formation Issues [WAFI] tool, which was developed by Petroleum Development Oman LLC [PDO] - collaboration between Well Engineering and Data Science teams. This tool's function is to extract Formation Issues from the Daily Drilling Operation Reports [DDOR\ & Other Reports entered by Drilling Site team and display them per formation per field. WAFI is a cutting-edge Well Engineering solution that employs Text Mining techniques to automatically provide offset well information, significantly enhancing efficiency and reducing manual labor spent on data extraction from disparate databases and analysis in Excel. This advanced solution facilitates a deeper understanding of complex relationships between neighboring wells and the well to be drilled. By optimizing this process, our approach aims to effectively pinpoint potential challenge areas, thereby augmenting drilling operations and sustaining overall project success. The tool was trialed in 3 fields in PDO, and it managed to pick up most of the drilling and formation issues identified and expected in each field and in offset wells, based on the Trained Machine Learning Model. The tool picks up the Depth at which the issue occurred, and it links it to the Formation being drilled. The results are viewed in a formation level view or at a Well level view, so it will give an overview of the field issues in offset wells. This will help Team for better planning and preparing for the upcoming wells, and of understanding of the Fields issues. The tool picks up the following Issues: Tight spots, Over Pulls, Reaming and Back Reaming, Vibrations, Stick & Slip, Bit Balling, Fish, Lost Circulation, Fluid Influx, Stuck Pipe & Drill String Failure. The parameters being picked by the model are: Loss Rate range, Flow Rate, Torque, RPM, Overpull and ROP [Rate of Penetration]. This is Phase One of the Tool development, and next plan for Phase Two will include more functionalities and more features, Parameters and enhancements to the tool. Both phases will be discussed in this paper. © 2023, Society of Petroleum Engineers.",TextMining
"The implementation of innovation and entrepreneurship education is inseparable from professional education, so it is important for the rich data in the education platform to mine the connection between professional courses and between grades and courses. The study of association rule algorithm based on education data mining improves the time performance efficiency and accuracy of Apriori algorithm. The study improves the time efficiencies of Apriori algorithm by maintaining Map table and splitting transaction database; the accuracy is improved by using mixed criteria to measure the accuracy and filtering deformation rules based on the inference of confidence. The results of the validation of the time efficiency of the algorithm show that the running time of the improved algorithm in solving frequent itemsets is improved by about 93.86%, 92.48% and 92.76%, respectively, compared with the other three algorithms. The running time of the algorithm for generating frequent itemsets of all orders is about 91.35 ms, which is 66.13% and 83.72% better than the Apriori algorithm and AprioriTid algorithm, respectively. The mining results of student examination data based on the education platform are reasonable and practical, which are of good practical significance for the innovation and entrepreneurship engineering education platform to develop training plans and improve teaching quality.is assumed. © 2023 SCPE.",TextMining
"The monitoring of the quality of the mine tailings from the La Tahona mining waste dump in 2018, located east of the city of Hualgayoc, is an important issue that must be analyzed, as it still represents a severe risk to the health of the city's inhabitants. In this way, the Grey Clustering method provides an alternative to evaluate the level of contamination of the sources near the mining tailings, taking into account the monitoring data with file number 0038-2018-DSEM-CMIN, carried out by the Directorate of Environmental Supervision in Energy and Mines of the Environmental Evaluation and Oversight Agency (OEFA), analyzing seven parameters of Prati index and Environmental Quality Standard, pH, Zinc, Suspended Solids, Arsenic, Lead, Iron and Cadmium. The results showed that the monitoring points of the water bodies near the effluent to the environmental liabilities of La Tahona were classified as high risk, which means that the efforts made to remediate the mentioned liabilities by the General Directorate of Mines of the Ministry of Energy and Mines (MINEM) do not comply with the quality parameters. Finally, the results obtained may be of help to OEFA, MINEM and the authorities of the Cajamarca region of Peru in the search for the correct treatment of the tailings effluents mentioned above. © 2023 Seventh Sense Research Group®",TextMining
"This letter investigates the problem for Spectrum Sensing Data Falsification (SSDF) attacks in the Cognitive Internet of Vehicles (CIoV) network. The high-speed movement of Vehicle Users (VUs) leads to rapid changes in Channel State Information (CSI) and location. This leads to unstable detection probabilities and unstable probabilities of reporting errors. These unstable probabilities increase the error rate of traditional methods to identify VUs as Malicious Vehicle Users (MVUs). And high-speed movement makes it difficult to detect MVUs, which may result in massive MVUs&#x2019; attacks. To address the above problems, this letter establishes the Cooperative Spectrum Sensing (CSS) and spectrum access process under a Directed Acyclic Graph (DAG) blockchain framework, models MVUs&#x2019; attack strategy selection which is determined by revenue as an evolutionary game, and proposes a smart contract that changes the mining difficulty of VUs based on the correctness of local spectrum sensing decisions to influence VUs&#x2019; revenue. Finally, the simulation results verify the theoretical analysis and prove that the proposed method is superior to the traditional method. IEEE",TextMining
"Data mining plays a crucial role in extracting meaningful knowledge from large-scale data repositories, such as data warehouses and databases. Association rule mining, a fundamental process in data mining, involves discovering correlations, patterns, and causal structures within datasets. In the healthcare domain, association rules offer valuable opportunities for building knowledge bases, enabling intelligent diagnoses, and extracting invaluable information rapidly. This paper presents a novel approach called the Machine Learning based Association Rule Mining and Classification for Healthcare Data Management System (MLARMC-HDMS). The MLARMC-HDMS technique integrates classification and association rule mining (ARM) processes. Initially, the chimp optimization algorithm-based feature selection (COAFS) technique is employed within MLARMC-HDMS to select relevant attributes. Inspired by the foraging behavior of chimpanzees, the COA algorithm mimics their search strategy for food. Subsequently, the classification process utilizes stochastic gradient descent with a multilayer perceptron (SGD-MLP) model, while the Apriori algorithm determines attribute relationships. We propose a COA-based feature selection approach for medical data classification using machine learning techniques. This approach involves selecting pertinent features from medical datasets through COA and training machine learning models using the reduced feature set. We evaluate the performance of our approach on various medical datasets employing diverse machine learning classifiers. Experimental results demonstrate that our proposed approach surpasses alternative feature selection methods, achieving higher accuracy and precision rates in medical data classification tasks. The study showcases the effectiveness and efficiency of the COA-based feature selection approach in identifying relevant features, thereby enhancing the diagnosis and treatment of various diseases. To provide further validation, we conduct detailed experiments on a benchmark medical dataset, revealing the superiority of the MLARMC-HDMS model over other methods, with a maximum accuracy of 99.75%. Therefore, this research contributes to the advancement of feature selection techniques in medical data classification and highlights the potential for improving healthcare outcomes through accurate and efficient data analysis. The presented MLARMC-HDMS framework and COA-based feature selection approach offer valuable insights for researchers and practitioners working in the field of healthcare data mining and machine learning. © 2023 CRL Publishing. All rights reserved.",TextMining
"The recommendation system (RS) on the strength of Graph Neural Networks (GNN) perceives a user-item interaction graph after collecting all items the user has interacted with. Afterward the RS performs neighborhood aggregation on the graph to generate long-term preference representations for the user in quick succession. However, user preferences are dynamic. With the passage of time and some trend guidance, users may generate some short-term preferences, which are more likely to lead to user-item interactions. A GNN recommendation based on long- and short-term preference (LSGNN) is proposed to address the above problems. LSGNN consists of four modules, using a GNN combined with the attention mechanism to extract long-term preference features, using Bidirectional Encoder Representation from Transformers (BERT) and the attention mechanism combined with Bi-Directional Gated Recurrent Unit (Bi-GRU) to extract short-term preference features, using Convolutional Neural Network (CNN) combined with the attention mechanism to add title and description representations of items, finally inner-producing long-term and short-term preference features as well as features of items to achieve recommendations. In experiments conducted on five publicly available datasets from Amazon, LSGNN is superior to state-of-the-art personalized recommendation techniques. © 2023 CRL Publishing. All rights reserved.",TextMining
"In remote sensing change detection (RSCD) tasks, high-resolution remote sensing images can provide fine image details and complex texture features. Deep learning (DL)-based RSCD methods have achieved the state-of-the-art (SOTA) performance. However, most of these methods only consider vertical multiscale features when extracting features, while ignoring the problem of loss of contextual features due to scale changes. Hence, in order to overcome the above issues, a deeper multiscale encoding-decoding feature fusion network (DMEDNet) is proposed in this letter. The encoding stage is considered in both horizontal (features of the same scale in the same layer) and vertical (different scale features in different layers) dimensions, allowing the model to fully extract deeper multiscale features. The decoding phase further overcomes the problem of contextual information loss by reusing the obtained same scale features. In addition, a parallel convolutional block attention module (PCBAM) is applied to better focus on the most representative features, thereby improving the detection effect of the model. The proposed method is compared with several other SOTA CD methods on the season-varying CD dataset (CDD). The experimental results show that the proposed method obtains the highest F1 score of 97.4% and exhibits stronger robustness in dealing with complex scenes and small change targets.  © 2004-2012 IEEE.",TextMining
"Deep representation learning has improved automatic remote sensing change detection (RSCD) in recent years. Existing methods emphasize primarily convolutional neural networks (CNNs) or transformer-based networks. However, most of them neither effectively combine CNNs and transformers nor use prior geometric information to refine regions. In this article, a novel geometric representation transformer (GeoFormer) is proposed for high-resolution RSCD. GeoFormer utilizes convolutional information to guide the transformer by employing geometric prior knowledge. Specifically, the proposed GeoFormer consists of three carefully designed components: the geometric-based Swin transformer (Geo-Swin Transformer) encoder, the Laplace attention fusion (LAFusion) module, and the UNet++CD decoder. First, the Geo-Swin Transformer is a novel-designed nonlocal Siamese encoder that combines geometric convolution with a transformer to provide local geometric representation information for remote contextual features. Then, an LAFusion module is proposed to achieve robust bi-temporal feature fusion, which is founded on attention mechanism and edge information. Finally, UNet++CD decodes fine-grained information from the fused features by a dense multiscale upsampling process. Experimental results demonstrate that the proposed GeoFormer performs better than benchmark methods on four change detection datasets (LEVIR-CD, WHU-CD, DSIFN-CD, and CDD) and is able to detect the edges of change regions more precisely. Our code is available at https://github.com/Jiaxzhao/GeoFormer.  © 1980-2012 IEEE.",TextMining
"Since customer retention costs much less than attracting new customer, the problem of customer churn is a major challenge in various fields of work and particularly Hotel Industry. In this research, a solution based on an intelligent decision support system using text mining and nested ensemble techniques is presented, which combines the advantages of stacking and voting methods. In the proposed system, after the text mining of the data collected from the hotels of Kish Island, the effective feature selection is done using the gravity search algorithm. In the first level of nested ensemble technique method, stacking deep learning methods are used. Voting is used in the MetaClassifier section, which includes Random Forest, Xgboost and Naïve Bayes methods. The results of the implementation and comparison of the proposed system, show that the performance of the proposed system has increased the accuracy by 0.04 compared to the best existing method. © Operational Research Society 2023.",TextMining
"Joint biomedical entity and relation extraction is essential in biomedical text mining. It automatically identifies entities and uncovers the relation between them from biomedical texts. However, due to the relatively complex semantics of biomedical texts, the current methods are unable to effectively leverage the interaction between the two subtasks. In this work, in order to use the interaction between the subtasks, we propose to model entity labels and relation labels with table-filling. We assume that the table structure facilitates the information exchange between entities and relations. Additionally, a feature filtering module is designed in the model to enhance this interaction. After passing through the feature filtering module, the table was constructed based on the selected global features. Our model was evaluated on two tasks, the task of extracting adverse drug events between drug and disease entities, and the task of extracting interaction between drug entities. Compared with the state-of-the-art systems in these tasks, our model improved the F1 scores of the first task by 0.97% in entity recognition and 1.43% in relation extraction, and that of the second task by 1.14% in relation extraction.  © 2013 IEEE.",TextMining
"Decision tree models are widely used for classification tasks in data mining. However, privacy becomes a significant concern when training data contain sensitive information from different parties. This paper proposes a novel framework for secure two-party decision tree classification that enables collaborative training and evaluation without leaking sensitive data. The critical techniques employed include homomorphic encryption, function secret sharing (FSS), and a custom secure comparison protocol. Homomorphic encryption allows computations on ciphertexts, enabling parties to evaluate an encrypted decision tree model jointly. FSS splits functions into secret shares to hide sensitive intermediate values. The comparison protocol leverages FSS to securely compare attribute values to node thresholds for tree traversal, reducing overhead through efficient cryptographic techniques. Our framework divides computation between two servers holding private data. A privacy-preserving protocol lets them jointly construct a decision tree classifier without revealing their respective inputs. The servers encrypt their data and exchange function secret shares to traverse the tree and obtain the classification result. Rigorous security proofs demonstrate that the protocol protects data confidentiality in a semihonest model. Experiments on benchmark datasets confirm that the approach achieves high accuracy with reasonable computation and communication costs. The techniques minimize accuracy loss and latency compared to prior protocols. Overall, the paper delivers an efficient, modular framework for practical two-party secure decision tree evaluation that advances the capability of privacy-preserving machine learning. © 2023 Kun Liu and Chunming Tang.",TextMining
"The ranking pipelines of modern search platforms commonly exploit complex machine-learned models and have a significant impact on the query response time. In this paper, we discuss several techniques to speed up the document scoring process based on large ensembles of decision trees without hindering ranking quality. Specifically, we study the problem of document early exit within the framework of a cascading ranker made of three components: 1) an efficient but sub-optimal ranking stage; 2) a pruner that exploits signals from the previous component to force the early exit of documents classified as not relevant; and 3) a final high-quality component aimed at finely ranking the documents that survived the previous phase. To maximize speedup and preserve effectiveness, we aim to increase the accuracy of the pruner in identifying non-relevant documents without early exiting documents that are likely to be ranked among the final top-k results. We propose an in-depth study of heuristic and machine-learning techniques for designing the pruner. While the heuristic technique only exploits the score/ranking information supplied by the first sub-optimal ranker, the machine-learned solution named LEAR uses these signals as additional features along with those representing query-document pairs. Moreover, we study alternative solutions to implement the first ranker, either a small prefix of the original forest or an auxiliary machine-learned ranker explicitly trained for this purpose. We evaluated our techniques through reproducible experiments using publicly available datasets and state-of-the-art competitors. The experiments confirm that our early-exit strategies achieve speedups ranging from 3× to 10× without statistically significant differences in effectiveness.  © 2013 IEEE.",TextMining
[No abstract available],TextMining
"Unsupervised Domain Adaptation (UDA) aims to transfer knowledge acquired from the labeled source domain to the unlabeled target domain. However, the quality of samples can vary greatly. While partial samples are dominated by highquality domain-invariant class-related information, others may only contain irrelevant domain-specific information or useless random noise. Treating all samples equally may lead to negative transfer, significantly impairing the performance. To address the issue of varying sample quality, we propose an attention module to emphasize the samples that are most suitable for transfer. Within the attention module, we have designed a fuzzy inference system to assess the quality of data based on its class and domain information. Such a fuzzy inference attention module (FIA) demonstrates strong interpretability due to its consideration of the fuzzy nature inherent in class and domain information within the data. FIA also has high flexibility and extensibility as the rule base can be easily adjusted by expert knowledge. More importantly, FIA does not use any parameters requiring training and has a low overhead. This makes it fast and applicable to most existing unsupervised domain adaptation methods. The experiments on several benchmark datasets prove that FIA can bring significant improvement to existing methods IEEE",TextMining
"We analyzed the symptoms composition of Interstitial Cystitis (IC), the regularity of the evolution of symptoms before and after treatment, and the visualization of the community network, to provide a reference for clinical diagnosis and treatment of Interstitial Cystitis. Based on the outpatient electronic case data of 552 patients with Interstitial Cystitis, we used a complex network community discovery algorithm, directed weighted complex network, and Sankey map to mine the data of the symptoms composition of Interstitial Cystitis, the evolution of symptoms before and after treatment and the visualization of the community network, to analyze the epidemiological characteristics of interstitial cystitis symptoms in the real world. By the community division of the complex network of interstitial cystitis symptoms, We finally obtained three core symptom communities. Among them, symptom community A (bladder-related symptoms) is the symptom community with the highest proportion of nodes (60.00%) in the complex network of Interstitial Cystitis, symptom community B (non-bladder-related symptoms 1) ranks second (32.00%) in a complex network of Interstitial Cystitis, and symptom community C (non-bladder-related symptoms 2) has the lowest proportion (8.00%). There is a complex evolutionary relationship between the symptoms of Interstitial Cystitis before and after treatment. Among the single symptoms before and after treatment, the decreased rate of Day frequency is 93.22%, and the reduced urgency rate is 93.07%. The decline rate of Nocturia was 82.33%. From the perspective of different communities, the overall symptoms of symptom community A decreased by 34.39% after treatment, the general symptoms of symptom community B decreased by 35.37%, and the prevalent symptoms of symptom community C decreased by 71.43%. In the case of using diet regulation treatment to treat bladder pain, the cure rate of bladder pain can reach 22.67%. The cure rate of burning in bladders can get 15.38% with Percutaneous Sacral neuromodulation, 96.95% with diet regulation treatment, and 100% with Percutaneous Sacral neuromodulation. When using behavioral physiotherapy to treat bladder pain, 3.57% of the patient's symptoms change to bladder discomfort; 4% of the patient's symptoms change to bladder discomfort when using oral medicine to treat bladder pain.Symptom research methods based on community findings can effectively explore the rule of symptom outcome of Interstitial Cystitis before and after treatment, and the results are highly interpretable by professionals. © 2023 The Authors. IET Systems Biology published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.",TextMining
"In this paper, we explore a novel online learning setting, where the online learners are presented with &#x201C;doubly-streaming&#x201D; data. Namely, the data instances constantly streaming in are described by feature spaces that over-time evolve, with new features emerging and old features fading away. The main challenge of this problem lies in the fact that the newly emerging features are described by very few samples, resulting in weak learners that tend to make error predictions. A seemingly plausible idea to overcome the challenge is to establish a relationship between the old and new feature spaces, so that an online learner can leverage the knowledge learned from the old features to better the learning performance on the new features. Unfortunately, this idea does not scale up to high-dimensional feature spaces that entail very complex feature interplay. Specifically. a tradeoff between onlineness, which biases shallow learners, and expressiveness, which requires deep models, is inevitable. Motivated by this, we propose a novel paradigm, named Online Learning Deep models from Data of Double Streams (OLD3S), where a shared latent supspace is discovered to summarize information from the old and new feature spaces, building an intermediate feature mapping relationship. A key trait of OLD3S is to treat the model capacity as a learnable semantics, aiming to yield optimal model depth and parameters jointly in accordance with the complexity and non-linearity of the input data streams in an online fashion. To ablate its efficacy and applicability, two variants of OLD3S are proposed namely, OLD-Linear that learns the relationship by a linear function; and OLD-FD learns that two consecutive feature spaces pre-and-post evolution with fixed deep depth. Besides, instead of re-starting the entire learning process from scratch, OLD3S learns multiple newly emerging feature spaces in a lifelong manner, retaining the knowledge from the learned and vanished feature space to enjoy a jump-start of the new features&#x0027; learning process. Both theoretical analysis and empirical studies supstantiate the viability and effectiveness of our proposed approach. The code is available online at <uri>github.com/X1aoLian/OLD3S-L</uri>. IEEE",TextMining
"In the field of process mining, the discovery of process patterns from event logs remains a challenging topic and has always interested many researchers. Exploiting the process model remains a major challenge and is highly dependent on event log characteristics, such as dataset size, the completeness of the event trace, and especially the complexity of the process model structure. The ρ (rho)-algorithm is a powerful process mining algorithm that can mine all the structured information control net (SICN), such as sequential, selective, parallel, and iterative. The ρ -algorithm also faces challenges when mining complex process patterns, consisting of many SICN primitive patterns combined at multiple levels that satisfy properties matched pairing and the proper nesting. This paper presents a new approach, defines the formalization of the multi-level and compound control-flow gateways (ML-CCFG) and a series of rules for decision-making these gateways, and proposes an algorithm extending from ρ -algorithm (we named it ρ MC-algorithm), that can efficiently discover the SICN-oriented process model containing ML-CCFG from process instances event log. We developed an implementation system ρ MC-algorithm to discover and visualize in a graphical form SICN-oriented process models from the datasets of the IEEE XES-formatted process enactment event logs. We also perform a series of experimental analyses using the implemented system on the process enactment event log datasets to verify the proposed algorithm.  © 2013 IEEE.",TextMining
"Multi-exposure image fusion (MEF) technology is to generate a normally exposed image by fusing images with different exposure levels. Most of the existing models use CNNs to capture the features, which may have difficulty modeling the responses between pixels that are far apart in the spatial domain due to the fixed receptive field, especially for pixel-dense ultra high definition (UHD) images. Furthermore, most models are trapped by the parameter size and cannot process high-resolution images in real time with limited resources. To address these problems, we propose a local and global aware bilateral learning approach (LGABL) in this paper. Our model integrates the local and global features. We design the Non-stem MLP-Mixer to extract global information in different dimensions without CNN stems. In addition, the local features are obtained by the generalized CNN model. Finally, the merged features are utilized to yield a bilateral grid to reconstruct the images, and a grid pooler is set behind to constrain the outlier points. Experimental results demonstrate that LGABL has the capability to run a 4&#x00A0;K resolution image on a single RTX 3090 GPU shader with 24G RAM in real time, and our model exhibits favorable performance compared to state-of-the-art methods on various benchmarks. IEEE",TextMining
"Clustering is one of the most prevalent and important data mining algorithms ever developed. Currently, most clustering methods are divided into distance-based and density-based. In 2014, the fast search and find of density peaks clustering method was proposed, which is simple and effective and has been extensively applied in several research domains. However, the original version requires manually assigning a cut-off distance and selecting core points. Therefore, this article improves the density peak clustering method from two aspects. First, the Gaussian kernel is substituted with a k-nearest neighbors method to calculate local density. This is important as compared with selecting a cut-off distance, calculating the k-value is easier. Second, the core points are automatically selected, unlike the original method that manually selects the core points regarding local density and distance distribution. Given that users' selection influences the clustering result, the proposed automatic core point selection strategy overcomes the human interference problem. Additionally, in the clustering process, the proposed method reduces the influence of manually assigned parameters. © 2023 John Wiley & Sons Ltd.",TextMining
"The oil and gas industry are facing a few challenges, including the need to attract and retain top talent, the need to manage cost escalation, and compliance to new and stricter regulations. One of the key challenges that the industry is facing is to align competencies with job requirements. This is especially true in the case of technical talents, who are essential for the safe and efficient operation of oil and gas facilities. This paper provides a comprehensive and professional account of a centralized data analytics approach designed to effectively manage the competencies of technical talents within PETRONAS Upstream's Surface operation and engineering fraternities. The study tackles the crucial challenge of aligning competencies with job requirements by utilization of data analytics and analysis to generate valuable insights into competency gaps. With a primary focus on Technical Executives, the approach extends its applicability to encompass offshore-specific talent competencies within Regional/Business Units that play a vital role in supporting field operations. The proposed approach introduces dynamic and interactive dashboards that empower heads and superiors to promptly intervene and support talent development plans. These dashboards serve as a powerful decision-making tool, facilitating the identification of specific areas necessitating further development and enabling the implementation of highly targeted training and development initiatives. The general principle used consists of the following four key elements: i. Data collection: The first phase involves collecting data on technical talents competencies, as well as the job requirements for their positions. This data can be collected from a variety of sources, such as job descriptions, performance appraisals, and training records. ii. Data analysis: The second phase involves analyzing the collected data to identify competency gaps. This can be done using a variety of data analytics techniques, such as statistical analysis, machine learning, and text mining; iii. Competency gap remediation: The third phase involves remediating the identified competency gaps. This can be done through a variety of interventions, such as training, mentoring, and job rotation; and iv. Evaluation: The fourth phase involves evaluating the effectiveness of the competency gap remediation interventions. This can be done by tracking the performance of technical talents over time. The successful implementation of this centralized data analytics approach has demonstrated significant improvements in talent competency management within PETRONAS Upstream's surface operation and engineering fraternities, resulting in elevated competency levels among technical talents. The implementation of the proposed centralized data analytics approach has resulted in significant improvements in talent competency management within PETRONAS Upstream. The live dashboards have enabled heads and superiors to intervene and support talent development plans, resulting in increased competency levels among technical talents. The approach has also led to more targeted training and development initiatives, resulting in increased efficiency and productivity. This proposed approach can be adapted and applied to other oil and gas companies. Additionally, this approach could provide some insights for broader talent management strategies on talent competencies at the section, business unit, and regional levels. By using data analytics and algorithms to manage competencies, companies can ensure the right competencies to the right positions, ultimately resulting in improved efficiency, productivity, and safety. © 2023, Society of Petroleum Engineers.",TextMining
"Background and Aim: The association between proton-pump inhibitors (PPIs) and rhabdomyolysis were unclear. The aim of this study was to explore and systematically analyze the potential link between five PPIs and the rhabdomyolysis events using the FDA Adverse Event Reporting System (FAERS) database. Methods: Suspected rhabdomyolysis events associated with PPIs were identified by data mining with the reporting odds ratio (ROR), proportional reporting ratio (PRR), the information component (IC), and Empirical Bayes Geometric Mean (EBGM). Demographic information, drug administration, and outcomes of PPI-induced rhabdomyolysis events were also analyzed. Results: There were 3311 reports associated with PPI-induced rhabdomyolysis that were identified. After removing duplicates, 1899 cases were determined to contain complete patient demographic data. The average age was 65 ± 18 year and 57% were male. Omeprazole and pantoprazole had the same largest percentage of reports. Lansoprazole had the highest ROR index of 12.67, followed by esomeprazole (11.18), omeprazole (10.27), rabeprazole (10.06), and pantoprazole (9.24). PRR, IC, and EBGM showed similar patterns. This suggested that lansoprazole exhibited the strongest correlation with rhabdomyolysis. In rhabdomyolysis events, PPIs were mainly “concomitant” (>60%), and only a few cases were “primary suspects” (<15%). Rabeprazole showed the lowest death rate while lansoprazole showed the highest. Conclusions: The study suggested that significant rhabdomyolysis signals were associated with PPIs. Further research should be performed in drug safety evaluation for a more comprehensive association. © 2023 Journal of Gastroenterology and Hepatology Foundation and John Wiley & Sons Australia, Ltd.",TextMining
"Surface-to-inseam (SIS) pre-drainage has become the most common method to pre-drain coal mine methane (CMM) for safer mining operations, improve gas recovery in areas of overlapping coal seam gas (CSG or CBM) and mining tenures, and provide beneficial use methane for mining operations. Coal permeability is the key discriminator in gas recovery and SIS wells have been less successful in draining tight low-permeability coals. To improve well productivity, fracture stimulation using indirect hydraulic fracturing (IHF) from horizontal wells deployed below potentially mineable coal seams has been applied using 23 stages in a 1000-meter lateral on the first application for mining pre-drainage. To improve IHF treatments, micro-proppants could be injected to increase the stimulated reservoir volume (SRV) by maintaining conductive fluid flow paths in natural fractures and cleats, countering detrimental pressure-dependent permeability (PDP) effects. This paper demonstrates key aspects to the co-application of lateral, multi-stage IHF and micro-proppant injection in coal seam gas drainage. Successful IHF cases applied to date in the Cooper and Bowen Basins, Australia, have provided valuable insights on key considerations in planning and deploying IHF treatments. In addition to increased production from the IHF wellbore relative to a standalone SIS well, intersections of the IHF treatments with offsetting SIS wells are observable and when properly designed and are a method to improve the surrounding SIS well productivity. Key reservoir data and a multidisciplinary approach integrating well test analyses, hydraulic fracturing modelling, and reservoir simulation are used to quantify the potential benefits of the IHF/SIS co-application process. Finally, past laboratory and modelling studies provide insight into the potential benefits of the additional co-application of micro-proppants in IHF treatments. This paper primarily demonstrates the benefits of co-application of IHF and SIS wells based on varying SIS well drainage and interconnecting IHF wells for a Permian coal case in the Bowen Basin. Recovery predictions for the SIS wells are made using various permeability and spacing patterns, then compared with the recovery of IHF deployed within the pattern of SIS wells. This paper highlights the optimal well placement/spacing between the IHF and SIS wells, number of fracture stages along the IHF well, and optimised fracture treatment schedules (e.g., injection rates, fluid parameters, proppant considerations, etc.), based on permeability, permeability anisotropy, and current Australian economic parameters. Finally, investigations regarding the co-application of micro-proppants indicate that an additional benefit is most apparent in low permeability applications. This paper provides workflows detailing the practical aspects of the design, execution, and evaluation of these technologies for both CSG and CMM applications. This technology is particularly suited to other Eastern Hemisphere areas (e.g., China, India, Africa, North America) where: strike-slip regimes complicate hydraulic fracturing; overlapping tenures prevent the placement of steel-based completions in potentially mineable seams; or inseam drilling is unstable or risky based on geomechanics. © 2023, Society of Petroleum Engineers.",TextMining
"For the successful engagement of users with incoming interventions, the delivery of Just-In-Time (or opportune moment&#x2014;OM) interventions is of the utmost importance. This can be accomplished with a machine learning model that utilizes user context data. Smartwatch and smartphone interactions further open the space for further improvement by considering the user&#x2019;s state and environmental information. In this work, a novel feature engineering approach for predicting smartphone user receptivity to Just-In-Time (JIT) interventions is proposed. Proposed approach utilizes rich information from user-smartphone interactions and smartwatch sensor data to extract contextually filtered features. The superiority of the proposed feature engineering method is demonstrated by developing a machine learning model that predicts a participant&#x2019;s receptivity prior to administering an Experience Sampling Method (ESM) questionnaire. The proposed approach is evaluated using the KEmoPhone dataset, which contains 3,334 ESM answers collected over the course of one week from 73 participants. To reduce the bias that may result in selecting specific classifier, multiple classifiers are tested and their average ROC-AUC metrics are compared. The results show that the proposed feature engineering method -CFF improves the prediction performance, achieving an ROC-AUC of 56.5% as opposed to 54.7% obtained using conventional features (statistical moments of time series over an 80 min window). Such superior performance is consistent across multiple machine learning classification algorithms. Full research code will be released in jupyter notebooks for facilitating the research in the domain at https://github.com/Jumabek/receptivity upon the publication of this research work. Authors",TextMining
"The field of text mining has increasingly relied on Non-negative matrix factorization (NMF) for its ability to perform high-dimensional data reduction and visualization. This paper aims to employ NMF in analyzing a dataset of 1,500 documents and 12,419 words in bags-of-words format, obtained from the UCI Machine Learning Repository. Our analysis demonstrates the utility of NMF in effectively classifying ambiguous and sparse textual data into distinct topics and extracting meaningful contents through the identification of relevant keywords. Further, we demonstrate the robustness of NMF in topic clustering by exploring the semantic relationship between extracted keywords and the topics to which they belonged. Our findings offered valuable insights into the application of NMF in text mining and suggested that universities in Vietnam could leverage this technique to analyze feedback and suggestions from students. © 2023, © ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.",TextMining
"Rapid advances in remote sensing technology have allowed its extensive use in defense, land use planning, urban traffic monitoring, and natural disaster warning. Remote sensing technology has penetrated every aspect of modern life. However, some problems need to be solved in the use of remote sensing data, such as the presence of clouds in images. Efficient air-ground data transmission can be realized by performing cloud rejection on remote sensing images before satellite data transmission. Therefore, in this study, remote sensing images were analyzed, and an effective cloud detection algorithm was designed. A dense-connected-strategy-based spectral-spatial feature extraction module that can realize the independent extraction of spectral and spatial information was designed. To enhance the effective information and suppress the useless information, spatial and channel attention modules based on the self-attention mechanism were designed and added after the spectral information extraction and spatial information extraction modules, respectively. Finally, the contextual dynamic convolution module was designed to adjust the convolution kernel parameters adaptively and enhance the characterization ability of the network.  © 1980-2012 IEEE.",TextMining
"Multiple data streams from sensing devices in intelligent settings have improved life quality thanks to the internet of things (IoT). Anomalies and imbalanced data sources are unavoidable due to system complexity and IoT device rollout issues. An imbalanced dataset has more data for one group than another, which may influence the results. IoT data streams are unbalanced, making anomaly detection harder. Data mining and machine learning classification approaches perform poorly on imbalanced datasets in the current setup. To address this, the proposed system suggests an effective anomaly detection method and oversampling approach (ADO) to improve IoT’s ability to identify abnormal behaviours in imbalanced data. After clustering of lower and upper boundary standardisation (CLUBS) detects anomaly samples, the ADO technique provides synthetic samples for minority classes. ADO lowers class region overlaps and enhances classification methods. The experimental results using an imbalanced dataset and three classification algorithms, namely K-nearest neighbour (KNN), random forest (RF), support vector machine (SVM) and multilayer perceptron (MLP), show that the ADO approach increases classification accuracy (0.64% for KNN, 4.27% for RF and 6.33% for SVM) by removing anomalies and oversampling data. Copyright © 2023 Inderscience Enterprises Ltd.",TextMining
"This paper addresses the problem of predicting the occupancy of urban public transport vehicles with a network-wide framework where the effects of the interactions between multiple lines are jointly considered. In particular, we propose and compare several occupancy predictors, each of them differing in the amount of information used and in the prediction model adopted. We consider two prediction models: a behavioral model that assumes an explicit relation between some observed variables and the occupancy, and a machine learning model based on the LightGBM algorithm. We evaluate the proposed network-wide prediction framework on two real-world case studies related to the public transport network of the Swiss city of Zurich. The results show that predicting the occupancy for a target line while simultaneously considering the other lines in the network allows significant improvements in the accuracy of the predictions, especially in the corridors served by different interacting lines. The described methodology could be used by public transport agencies to improve the accuracy of the crowding information provided to passengers and to increase the attractiveness of public transport systems. Authors",TextMining
"Recently, single image super-resolution (SISR) has been an activate research topic for decades, which is a classical fundamental problem in low-level computer vision tasks. With the growth of digital twins technology, metaverse is constructed successfully in many areas. Then with the development of VR/AR equipment, a more efficient SISR network urgently needs to be proposed to meet the application needs of consumer electronics. However, in most SISR methods, the heavy computation and parameters are detrimental to the application in mobile edge computing. And the most lightweight methods lack the ability to retain long-range information and account to a nasty degradation of SR results. To alleviate above problems, we design a hybrid attention feature refinement network (HAFRN) to achieve multi-level information with a few parameters. Moreover, we also propose a newly local concatenate learning strategy, which can use coarse feature maps of shallow layers to maximum the authenticity of SR images step-by-step. In order to capture more feature details in channel, spatial and pixel, an efficient attention mechanism is performed on the network to make sure the interaction among different dimensions. Extensive experiments on five benchmark datasets have proven that the advantages of our method over the state-of-the-art approaches. IEEE",TextMining
"This book presents the basics and recent advancements in natural language processing and information retrieval in a single volume. It will serve as an ideal reference text for graduate students and academic researchers in interdisciplinary areas of electrical engineering, electronics engineering, computer engineering, and information technology. This text emphasizes the existing problem domains and possible new directions in natural language processing and information retrieval. It discusses the importance of information retrieval with the integration of machine learning, deep learning, and word embedding. This approach supports the quick evaluation of real-time data. It covers important topics including rumor detection techniques, sentiment analysis using graph-based techniques, social media data analysis, and language-independent text mining. Features: Covers aspects of information retrieval in different areas including healthcare, data analysis, and machine translation. Discusses recent advancements in language- and domain-independent information extraction from textual and/or multimodal data. Explains models including decision making, random walk, knowledge graphs, word embedding, n-grams, and frequent pattern mining. Provides integrated approaches of machine learning, deep learning, and word embedding for natural language processing. Covers latest datasets for natural language processing and information retrieval for social media like Twitter. The text is primarily written for graduate students and academic researchers in interdisciplinary areas of electrical engineering, electronics engineering, computer engineering, and information technology. © 2024 selection and editorial matter, Muskan Garg, Sandeep Kumar and Abdul Khader Jilani Saudagar chapters.",TextMining
"Limited labeled training samples constitute a challenge in hyperspectral image classification, with much research devoted to cross-domain adaptation, where the classes of the source and target domains are different. Current cross-domain few-shot learning (FSL) methods only use a small number of sample pairs to learn the discriminant features, which limits their performance. To address this problem, we propose a new framework for cross-domain FSL, considering all possible positive and negative pairs in a training batch and not just pairs between the support and query sets. Furthermore, we propose a new kernel triplet loss to characterize complex nonlinear relationships between samples and design appropriate feature extraction and discriminant networks. Specifically, the source and target data are simultaneously fed into the same feature extraction network, and then, the proposed kernel triplet loss on the embedding feature and the cross-entropy loss on the softmax output are used to learn discriminant features for both source and target data. Finally, an iterative adversarial strategy is employed to mitigate domain shifts between source and target data. The proposed method significantly outperforms state-of-the-art methods in experiments on four target datasets and one source dataset. The code is available at https://github.com/kkcocoon/CFSL-KT.  © 1980-2012 IEEE.",TextMining
"The growth of frequency bandwidths and applications with the forthcoming generations of wireless networks will give rise to a multitude of wireless transmission scenarios, topologies and channel structures. In this work, we go beyond existing learning-based channel estimation methods tailored for specific scenarios, to develop an adaptive learning-based channel state information (CSI) estimation approach. We offer the adaptivity in the learning approach through extracting the scenario embeddings of CSI and adjusting the channel estimation method with the extracted information automatically in each scenario. Specifically, Learning-Based Scenario-Adaptive Channel Estimation Algorithm (LACE) is designed. LACE is based on a <italic>Scenario-Aware Hyper-Network</italic> (SAH-Net) that incorporates the <italic>embedding loss</italic> to make the Convolutional Neural Network (CNN) based encoder learn to extract the effective scenario embeddings from the time-space two dimensional features of the CSI. The extracted embeddings are utilized by a Multi-Layer Perceptron (MLP) based tuning module to tune the parameters of the channel estimation method. Our learning design is complemented with analysis to verify that the theoretical performance of LACE is strictly superior to that of the mix-training method, which involves conventionally training the deep network-based channel estimation method using samples from all scenarios. Our results show that the performance of LACE trained in finite scenarios is comparable to that of the deep network-based channel estimation method trained in each scenario, while having lower complexity. Further more, the performance of LACE trained in infinite scenarios is demonstrated to be superior to that of the mix-training method in all test scenarios. IEEE",TextMining
"Recommendation systems (RSs) are frequently used to provide suggestions to users based on their preferences. With so much information on the Internet, RS have proven beneficial for combating information explosions and alleviating multiple over-choice difficulties. Various applications, such as e-commerce, medical, transportation, agribusiness, and entertainment, have welcomed RSs as automated online assistants. The trick is how quickly the recommendations are provided; otherwise, the opportunity may be missed. This chapter presents a near-real-time RS based on utility itemset mining by employing the highly efficient EAHUIM (Enhanced Absolute High-Utility Itemset Mining) algorithm, which has been proposed for finding the associations between items in a database. Also, as the real-world data is dynamic, the problem of transaction-stream fluctuation has been considered, and an adaptive load strategy has been proposed for the model. Various experiments on a real-world dataset result in near-real-time and customized recommendations, demonstrating the model’s efficacy. © 2024 selection and editorial matter, Muskan Garg, Sandeep Kumar and Abdul Khader Jilani Saudagar chapters.",TextMining
"E-commerce growth has been increasing rapidly for the past few years, and it’s already become an important part for customers or retailers to sell and buy products with no bound of distances. With e-commerce having a lot of transaction data, it will be hard to make the most effective selling strategy by only using bare eyes. Thus, in this study, we adopt k-means clustering technique for clustering analysis to gain useful patterns and insights about total transaction and seasonal correlation on online retail shop dataset with the aim of giving these retail shops a more strategic sales plan. The result shows that different countries had its peak sales in different seasons, these insights can be applied for many e-commerce stores to give a deeper sales strategy to various target market. © 2023, Success Culture Press. All rights reserved.",TextMining
"Anthropogenic activities and climate change have caused environmental alterations in marine ecosystems, inducing stress conditions that diminish coral regeneration capacity and increase their susceptibility to bleaching and mortality. In order to determine the environmental factors associated with thermal stress events during the last 16 years in the coral reefs of Isla Tesoro - Colombia, remote sensor and reanalysis data mining of available information was performed. The results of a Principal Component Analysis (PCA) showed that not only the sea-surface temperature is related to coral stress, but also variables such as chlorophyll-a, photosynthetic radiation, pH, and sediments transported. These results, together with those of previous studies in this area, demonstrated that remote sensing technologies could facilitate the study of coral ecosystems, simplifying data collection in zones where access is limited. Hence, this document presents a database with historical information related to heat stress events and environmental variables for the coral nursery area on Tesoro Island in Los Corales del Rosario and San Bernardo National Natural Park, belonging to the Caribbean Territorial Directorate of National Natural Parks of Colombia  © 2023 Author(s).",TextMining
"Human Resource is the most valuable asset for any organization that drives the firm’s overall growth. Hence, performance evaluation becomes essential to ensure that the right talent has been allocated to the right job at the right time. Human Resource (HR) analytics plays an essential role in performance evaluation. While evaluating performance, most organizations consider only organizational factors and overlook the social and psychological factors. This paper attempts to study the impact of organizational, social, and psychological factors on employees’ performance by using data mining and machine tools for intelligent automated decisions. The machine learning models are developed using the employees’ databases via which predictions of employees’ performance are being made. This study provides a forecasting model for employee performance that allows Human Resource professionals to forecast employee performance and emphasize human capability criteria to improve the quality of life and human capital’s performance appraisal process. The study helps optimize HRM in organizations for the betterment in the long run. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.",TextMining
"Numerical association rule mining (NARM) is a popular method under the umbrella of data mining, focused on finding relationships between attributes in transaction databases. Numerical association rules for time series are a new paradigm that extends the applicability of NARM to the domain of time series. Association rule mining algorithms result in numerous rules, the interpretation of which is sometimes not easy for human experts. Therefore, various visualization methods have been developed to improve the explanation results of the rule mining process. This article is a novel contribution to the development of a new visualization method capable of presenting the association rules for time series developed according to the principles of explainable artificial intelligence. The experiments are conducted in the context of smart agriculture (i.e., agricultural time series data), and show the great potential of the proposed visualization method for the future. © 2023 John Wiley & Sons Ltd.",TextMining
"The data on the reptilian fauna of the state of Goiás are one-off and reveal a lack of information about this group. The aim of the research was to know the composition of the reptile fauna within the area of the Anglo American mining company, evaluating the relationship of the species with the years, the types of environments and the presence of indicator species. Fieldwork was carried out during seven years, from 2007 to 2013. Sampling was performed through active search, pitfall traps, occasional encounters, and third-party records. We recorded 36 reptile species: 15 lizards and 21 snakes. The most common lizards were Anolis meridionalis, Cnemidophorus sp, and the most abundant snakes were Apostolepis cerradoensis and Bothrops moojeni. There was no relationship between the species and the years. On the other hand, there was relationship between the species and the environments or between the species and the types of habitats. The lizard Ameivula ocellifera was found as an indicator species of Cerrado areas, as well as the snake Leptotyphlops dulcis We have seen that lizards are specific to their habitat, making it essential to preserve open and forested areas for the conservation of the species that live there. © 2023 Informa UK Limited, trading as Taylor & Francis Group.",TextMining
"Sacha Inchi (Plukenetia volubilis L.) is a plant native in the Amazon rainforest in South America known for its edible seeds, which are rich in lipids, proteins, vitamin E, polyphenols, minerals, and amino acids. Rural communities in developing nations have been using this plant for its health benefits, including as a topical cream for rejuvenating and revitalising skin and as a treatment for muscle pain and rheumatism. Although Sacha Inchi oil has been applied topically to soften skin, treat skin diseases, and heal wounds, its protein-rich seeds have not yet received proper attention for extensive investigation. Proteins in Sacha Inchi seeds are generally known to have antioxidant and antifungal activities and are extensively used nowadays in making protein-rich food alternatives worldwide. Notably, large-scale use of seed proteins has begun in nanoparticle and biofusion technologies related to the human health-benefitting sector. To extract and identify their proteins, the current study examined Sacha Inchi seeds collected from the Malaysian state of Kedah. Our analysis revealed a protein concentration of 73.8 ± 0.002 mg/g of freeze-dried seed flour. Employing liquid chromatography-tandem mass spectrometry (LC–MS/MS) and PEAKS studio analysis, we identified 217 proteins in the seed extract, including 152 with known proteins and 65 unknown proteins. This study marks a significant step towards comprehensively investigating the protein composition of Sacha Inchi seeds and elucidating their potential applications in the food and biopharmaceutical sectors. Our discoveries not only enhance our knowledge of Sacha Inchi’s nutritional characteristics but also pave the way for prospective research and innovative advancements in the realms of functional food and health-related domains. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"This study aims to investigate the potential of educational data mining (EDM) to address the issue of delayed completion in undergraduate student thesis courses. The problem of delayed completion of these courses is a common issue that impacts both students and higher education institutions. The study employed clustering analysis to create clusters of thesis topics. The research model was constructed by using expert labeling to assign each thesis title to a computer science ontology standard. Cross-referencing was employed to associate supporting courses with each thesis title, resulting in a labeled dataset with three supporting courses for each thesis title. This study analyzed five different clustering algorithms, including K-Means, DBScan, BIRCH, Gaussian Mixture, and Mean Shift, to identify the best approach for analyzing undergraduate thesis data. The results demonstrated that K-Means clustering was the most efficient method, generating five distinct clusters with unique characteristics. Furthermore, this research investigated the correlation between educational data, specifically GPA and the average grades of courses that support a thesis title and the duration of thesis completion. Our investigation revealed a moderate correlation between GPA, thesis-supporting course average grades, and the time to complete the thesis, with higher academic performance associated with shorter completion times. These moderate results indicate the need for further studies to explore additional factors beyond GPA and the average grades of thesis-supporting courses that contribute to thesis completion delays. This study contributes to understanding and evaluating the educational outcomes within study programs as defined in the curriculum, particularly concerning the design and implementation of thesis topics. Additionally, the clustering results serve as a foundation for future research and offer valuable insights into the potential of using EDM techniques to assist in selecting appropriate thesis topics, thereby reducing the risk of delayed completion. Authors",TextMining
"The insatiable demand for rock supplies has enticed numerous building and construction enterprises to participate in stone quarrying. This paper examines the environmental impact of quarrying on air quality in Ebonyi State, Nigeria. To achieve the main aim of the study, an objective was set to detect air pollutants at the quarry sites. A total of 220 air samples were measured from six points around the quarry locations and recorded in situ for analysis. The samples were measured three times a day (morning, afternoon, and evening) for three days. Gas monitors were used to monitor air pollutants. The generated data were subjected to completely random design (CRD) sampling techniques. The separation of means and tests was performed using Fisher's Least Significant Difference (FLSD) at a significance probability level of 5%. Based on statistical analysis, the findings detected significantly higher concentration levels of particulate matter, nitrogen dioxide, hydrogen sulfide, carbon monoxide, sulfur dioxide, chlorine, volatile organic compounds, ammonia, and hydrogen cyanide in the quarry areas than the value detected in the control area. The findings also confirmed higher noise levels in the locations. It was also observed that the concentration levels of the parameters differed from point to point and at different times of the day. This really means the occurrence of a high rate of air pollution in the study locations. Based on the above findings, it is highly recommended that air pollution control equipment be installed at quarry sites in order to reduce gaseous (pollutant) emissions. © 2023 Wiley Periodicals LLC.",TextMining
"Traffic flow on highways is a dynamic process in which characteristics of road segments vary in time and space. Traffic congestion is the adverse effect caused dby an increase in travel time which is unprecedented by time and space. Temporal and spatial information of traffic flow is an integral component in the assessment of highway traffic flow. The spatial–temporal traffic flow dependency on highways can be well assessed when temporal traffic information in preceding time instances is sequenced. Thus, the SCAE-LSTM network is proposed considering time and space. This study investigates the estimation of traffic flow on highways based on spatial and temporal traffic sequences. Sequencing highway traffic information has motivated the authors to propose the method. The performance of the method is experimented on State Highways SH 49 and SH 49-A of Chennai Metropolitan City, Tamil Nadu, India. The computational complexity of the method is analyzed empirically. The significant outcome of the proposed method is reported in the experimental study. The traffic flow estimated using the proposed method has shown reduced complexity compared to other baseline methods. Finally, research directions to work in future are presented towards the end. © 2023 IETE.",TextMining
"Face forgery detection is essential in combating malicious digital face attacks. Previous methods mainly rely on prior expert knowledge to capture specific forgery clues, such as noise patterns, blending boundaries, and frequency artifacts. However, these methods tend to get trapped in local optima, resulting in limited robustness and generalization capability. To address these issues, we propose a novel Critical Forgery Mining (CFM) framework, which can be flexibly assembled with various backbones to boost their generalization and robustness performance. Specifically, we first build a fine-grained triplet and suppress specific forgery traces through prior knowledge-agnostic data augmentation. Subsequently, we propose a fine-grained relation learning prototype to mine critical information in forgeries through instance and local similarity-aware losses. Moreover, we design a novel progressive learning controller to guide the model to focus on principal feature components, enabling it to learn critical forgery features in a coarse-to-fine manner. The proposed method achieves state-of-the-art forgery detection performance under various challenging evaluation settings. The source code is available at: https://github.com/LoveSiameseCat/CFM. IEEE",TextMining
"The medical community is a vast area, there are affluent data collected within the medical system. The biomedical text mining technique is one of the best analyzing tools to recognize hidden relationships and drift in the data. The disease is a particular quality or disposition regarded as adversely affecting a person. The number of suffering people per day due to diseases in the real world is beyond all decent contemplations. As such, the aim of this chapter is to give a model for the primary diagnosis of disease. Due to the various scenarios such as the rise of population and infinite queuing system, there is an essence of developing a model for automated dictation of diseases based on the patient's symptoms. Therefore, this chapter includes a natural language processing approach to classify certain types of diseases based on the symptoms reported. The same is a challenging task to conduct due to similar symptoms for different diseases. Hence, the count vectorization approach is adopted here for multilabel symptom classification. Based on the symptoms and frequency count, an algorithm is developed to classify a certain type of disease. The verified symptoms are updated in the dataset to improve the efficiency of the system. Further, it is demonstrated for both the test and the new dataset. Then, the obtained results are reported here, and found a good agreement with the actual results. Besides, the decision tree classifier is also considered to get the prediction confidence score. © 2023 Elsevier Inc. All rights reserved.",TextMining
"It is always a hot and challenging problem to extract the characteristic information of roller bearings from strong noise interference. Conventional Hilbert-Huang Transform (HHT), Local Mean Decomposition (LMD), Local Feature-Scale Decomposition (LCD), and so on have some issues like overenvelope, under-envelope, frequency-chaos, end-point effect, and so on. Symplectic Geometry Mode Decomposition (SGMD) is one of the most efficient approaches to reconstruct this model. But SGMD has a drawback that the computation efficiency is reduced quickly with an increase in the quantity of data, and the degradation precision is influenced by the non-valid Symplectic Geometric Component (SGC). On this basis, a Regularized Composite Multiscale Fuzzy Entropy (RCMFE) is proposed, which is used to estimate the complexity of the reconstructed original individual parts and restrict the minimum amount of remaining power. This paper presents a Partial Reconstruction Symplectic Geometry Mode Decomposition (PRSGMD) approach. The simulation results indicate that PRSGMD can not only enhance the precision of SGMD but also enhance its robustness and validity. Finally, a maximal distance evaluation technique (DET) is employed in combination with a more interpretable tree-based Light Gradient Boosting Machine (LightGBM) for the intelligence fault diagnosis for rolling bearings.  © ; 2023 The Authors.",TextMining
"Purpose: Warranty-based big data analysis has attracted a great deal of attention because of its key capabilities and role in improving product quality while minimizing costs. Information and details about particular parts (components) repair and replacement during the warranty term, usually stored in the after-sales service database, can be used to solve problems in a variety of sectors. Due to the small number of studies related to the complete analysis of parts failure patterns in the automotive industry in the literature, this paper focuses on discovering and assessing the impact of lesser-studied factors on the failure of auto parts in the warranty period from the after-sales data of an automotive manufacturer. Design/methodology/approach: The interconnected method used in this study for analyzing failure patterns is formed by combining association rules (AR) mining and Bayesian networks (BNs). Findings: This research utilized AR analysis to extract valuable information from warranty data, exploring the relationship between component failure, time and location. Additionally, BNs were employed to investigate other potential factors influencing component failure, which could not be identified using Association Rules alone. This approach provided a more comprehensive evaluation of the data and valuable insights for decision-making in relevant industries. Originality/value: This study's findings are believed to be practical in achieving a better dissection and providing a comprehensive package that can be utilized to increase component quality and overcome cross-sectional solutions. The integration of these methods allowed for a wider exploration of potential factors influencing component failure, enhancing the validity and depth of the research findings. © 2023, Emerald Publishing Limited.",TextMining
"Substance use treatment is aimed at improving the well-being of the receiving clients. Given the clinician–client interactions inherent in treatment, understanding clinician influence on treatment outcomes is important. Utilizing clinical data mining, we used existing data from the clinical files of 444 clients who received substance use day treatment. Using multinomial logistic regression and linear regression, we examined whether and which client strengths and weaknesses perceived and recorded by clinicians during a client’s assessment predict client engagement and treatment completion. The results showed that willingness to seek treatment and outside support increased the likelihood of completing treatment, while financial support decreased it. We also found that clinician perceptions of a client’s inability to benefit from treatment predicted low levels of engagement in treatment. We then discuss implications for social work of this study. © 2023 Taylor & Francis Group, LLC.",TextMining
"In recent years, with the increasing number of computers in the world, the construction and application of computer networks have also developed rapidly. However, with the rapid and convenient transmission of information, the information security problem is becoming more and more serious. Support vector machine (SVM) is a new generation of data mining method developed on the basis of statistical learning theory, which has been well applied in the fields of character recognition, handwriting recognition, image classification, bioinformatics and so on. Compared with traditional methods such as neural network, it has many advantages, such as strong generalization ability, insensitive dimension, convergence to the global optimum, etc., and solves the problems of over-learning, dimension disaster, local extremum, etc. It has become a very active research direction in the field of data mining in recent years. Now support vector machine is widely used in automatic text classification, handwritten digit recognition, biological information and other fields. Identity authentication and access control technology, encryption / decryption technology, firewall technology and other security technologies emerge one after another. As the core technology of information security, cryptography has attracted more and more attention. Data encryption technology effectively protects the security of network data by encrypting the effective information into meaningless random code according to certain rules. © 2023 IEEE.",TextMining
"In Malaysia, the used car market frequently lacks transparency and fair pricing, making it difficult for buyers and sellers to make wise decisions. In-depth research on the creation of a machine learning-based pricing prediction model created exclusively for the Malaysian used car market is presented in this paper. The main goal of this project is to develop a reliable and open model that predicts used car pricing based on essential variables including age, condition, location, and the availability of comparable models on the market. Numerous techniques, like the neural network and regression model, are used to accomplish this purpose. The scope of the project also encompasses the identification of challenges and limitations in the current used car market in Malaysia, along with proposed solutions to improve transparency and fairness for all stakeholders. The methodology involves data collection, preprocessing, feature selection, model training, and evaluation. The results demonstrate that the developed model provides precise and transparent pricing information, empowering buyers and sellers to make informed decisions regarding their transactions. This project holds significant potential for enhancing transparency and fairness in the Malaysian used car market, while also serving as a valuable reference for similar initiatives in other countries and markets. © 2023 IEEE.",TextMining
"Aiming at the problem that features of communication emitter data without label information are different to extract and the classification acquisition is not high, this paper cites the contrastive learning theory, constructs a residual network with two parameters sharing as the backbone network, conducts contrastive learning on the rectangular integral bispectral features of signal augmented samples, and further extracts the feature presentation with more differentiation. To this end, the feature separability between samples from different emitters is enhanced. Then, the new features extracted are used for contrastive learning at the cluster level to complete the tasks of classification and identification. Compared with other unsupervised learning algorithms, the proposed method achieves a better identification accuracy of about 78% through experiences on the data set of measured ultra-short wave communication stations. © 2023 SPIE.",TextMining
"One of the main public health problems is child malnutrition, since it negatively affects the individual throughout his life, limits the development of society and makes it difficult to eradicate poverty.The first objective of this research is to apply data mining techniques for preprocessing, cleaning, reduction and transformation to a data lake that has allowed analyzing anemia in children under 5 years of age, the second objective is to apply Machine Learning algorithms to obtain the best model to predict anemia in children under 5 years of age.The data set was extracted from the open data platform of the government of Peru that corresponds to South Lima, North Lima, East Lima, Central Lima and rural Lima, which collected a total of 138,369 instances and 36 variables of which 30 are categorical and 6 numeric, being an unbalanced data set.In order to obtain the best predictor variables, the Anova F-test and Chi Square filters were used, and it was possible to reduce them to 10 variables, cases were also carried out without considering one of the filters and both filters.To find the best prediction model, the algorithms have been tested: decision tree, logistic regression, K nearest neighbors, random forest and naive bayes.As a result, we show that the best algorithm to predict anemia in children under 5 years of age is the Naive Bayes algorithm with the highest recall of 74%, precision of 43% and accuracy of 70%. © 2023 Instituto Politecnico Nacional. All rights reserved.",TextMining
"Optical fiber intrusion presents new features of being more subtle, advanced and frequent, which puts forward higher requirements for optical fiber intrusion detection. Distributed optical fiber intrusion location detection technology has the advantages of long detection distance, anti-electromagnetic interference and easy maintenance, and has become one of the most promising technologies in the field of long-distance security detection. In this paper, the distributed optical fiber intrusion identification algorithm based on DL(Deep learning) is studied. With the help of DL technology, the spatial and temporal characteristics of traffic data are considered comprehensively. Firstly, CNN (Convolutional Neural Network) is used to extract the spatial features of traffic data, and then BPNN (BP neural network) is used to extract the temporal features of traffic data. By stacking CNN+BPNN modules and gradually increasing the learning granularity, the purpose of effectively extracting both spatial features and temporal features is achieved. The research results show that the distributed optical fiber intrusion identification algorithm based on CNN+BPNN can identify common intrusion events, and the recognition rate is as high as 93%. The algorithm in this paper is suitable for all three kinds of optical fiber artificial signals, and the feature extraction time is reduced by about 25% compared with the original algorithm. The validity and superiority of the distributed optical fiber intrusion identification algorithm based on CNN+BPNN proposed in this paper are verified. © 2023 IEEE.",TextMining
"This research, conducted in Zaruma, southern Ecuador, seeks to evaluate the seismic vulnerability and performance level of the Humberto Molina Hospital's reinforced concrete buildings. The study employs an examination of national and international seismic codes for rehabilitation, along with the implementation of recommended techniques. Structural characteristics of the buildings were identified through auscultation, surveys of reinforcing steel, and the extraction of concrete cores. The amassed data, coupled with a seismic hazard analysis of the site, facilitated a structural assessment of the blocks, conducted in accordance with national (MIDUVI) and international (ASCE/SEI) codes. The Federal Emergency Management Agency (FEMA) subsequently proposed rehabilitation alternatives for each block. Due to the importance of the hospital's functions, data collection was limited to blocks B3 and B4. The structural system, composed of moment-resisting concrete frames, exhibits potential vulnerabilities due to knocking (collision) and torsion, attributed to its irregular form. Structural evaluation revealed that block B4 adheres to the drift limits stipulated by the ASCE 41-13 standard (below 2%), while block B3 exceeds these limits (2.05-2.80%). Recommended rehabilitation strategies for B3 encompass mass reduction (removal of the second floor, representing a dead load of 700kg/m2 and a live load of 200kg/m2), and the introduction of additional rigidity and strength (extension of structural elements). For block B4, it is suggested that each sub-block be made independent. These interventions aim to facilitate the hospital's reopening, thereby benefiting the Zaruma Mining District community. © 2023 WITPress. All rights reserved.",TextMining
"Considering that in the process of microblog information dissemination, the opinion of each network user is influenced by the opinions of the previous network user. Therefore, we propose a Bayesian opinion evolution model based on weibo data mining. With ""dynamic zero policy is the general policy of China's fight against the epidemic"" as the key word, Python is used to crawl the Weibo comment data. After data preprocessing and word segmentation, the Bayesian opinion evolution model is empirically analyzed. Empirical analysis shows that the timely guidance of public opinion by official media plays an important role in sentiment evolution tendency. © 2023 Editorial Borad of Complex Systems and Complexity Science. All rights reserved.",TextMining
"Administrative procedures in various organizations produce numerous crucial records and data. These records and data are also used in other processes like customer relationship management and accounting operations.It is incredibly challenging to use and extract valuable and meaningful information from these data and records because they are frequently enormous and continuously growing in size and complexity.Data mining is the act of sorting through large data sets to find patterns and relationships that might aid in the data analysis process of resolving business issues. Using data mining techniques, enterprises can forecast future trends and make better business decisions.The Apriori algorithm has been introduced to calculate the association rules between objects; the primary goal of this algorithm is to establish an association rule between various things. The association rule describes how two or more objects are related.We have employed the Apriori property and Apriori Mlxtend algorithms in this study and we applied them on the hospital database; and, by using python coding, the results showed that the performance of Apriori Mlxtend was faster, and it was 0.38622, and the Apriori property algorithm was 0.090909. That means the Apriori Mlxtend was better than the Apriori property algorithm. © 2023 University of Baghdad. All rights reserved.",TextMining
"Nowadays, many countries view profitable telemedicine as a viable strategy for meeting healthcare needs, especially during the pandemic. Existing appointment models are based on patients’ structured data. We study the value of incorporating textual patient data into telemedicine appointment optimization. Our research contributes to the healthcare operations management literature by developing a new framework showing (1) the value of the text in the telemedicine appointment problem, (2) the value of incorporating the textual and structured data in the problem. In particular, in the first phase of the framework, a text-driven classification model is developed to classify patients into normal and prolonged service time classes. In the second phase, we integrate the classification model into two existing decision-making policies. We analyze the performance of our proposed policy in the presence of existing methods on a data set from the National Telemedicine Center of China (NTCC). We first show that our classifier can achieve 90.4% AUC in a binary task based on textual data. We next show that our method outperforms the stochastic model available in the literature. In particular, with a slight change of actual distribution from historical data to a normal distribution, we observe that our policy improves the average profit of the policy obtained from the stochastic model by 42% and obtains lower relative regret (18%) from full information than the stochastic model (148%). Furthermore, our policy provides a promising trade-off between the cancellation and postponement rates of patients, resulting in a higher profit and a better schedule strategy for the telemedicine center. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Background: To effectively combat the rising incidence of syphilis, the Brazilian Ministry of Health (MoH) created a National Rapid Response to Syphilis with actions aimed at bolstering epidemiological surveillance of acquired, congenital syphilis, and syphilis during pregnancy complemented with communication activities to raise population awareness and to increase uptake of testing that targeted mass media outlets from November 2018 to March 2019 throughout Brazil, and mainly areas with high rates of syphilis. This study analyzes the volume and quality of online news content on syphilis in Brazil between 2015 and 2019 and examines its effect on testing. Methods: The collection and processing of online news were automated by means of a proprietary digital health ecosystem established for the study. We applied text data mining techniques to online news to extract patterns from categories of text. The presence and combination of such categories in collected texts determined the quality of news that were analyzed to classify them as high-, medium-and low-quality news. We examined the correlation between the quality of news and the volume of syphilis testing using Spearman’s Rank Correlation Coefficient. Results: 1,049 web pages were collected using a Google Search API, of which 630 were categorized as earned media. We observed a steady increase in the number of news on syphilis in 2015 (n = 18), 2016 (n = 26), and 2017 (n = 42), with a substantial rise in the number of news in 2018 (n = 107) and 2019 (n = 437), although the relative proportion of high-quality news remained consistently high (77.6 and 70.5% respectively) and in line with similar years. We found a correlation between news quality and syphilis testing performed in primary health care with an increase of 82.32, 78.13, and 73.20%, respectively, in the three types of treponemal tests used to confirm an infection. Conclusion: Effective communication strategies that lead to dissemination of high quality of information are important to increase uptake of public health policy actions. Copyright © 2023 Pinto, Lacerda, Silva, Araújo, Fontes, Lima, Miranda, Sanjuán, Gonçalo Oliveira, Atun and Valentim.",TextMining
"Order-preserving submatrix (OPSM) is an important qualitative biclustering method of gene expression data. OPSM first sorts the expression values of gene and replaces them with corresponding column labels, and then mines the local patterns of the column label sequence set, where some rows rise and fall together under some columns. This paper proposes an order-preserving subsequence mining method (Charm_Seq) based on the Charm algorithm, and Charm_Seq makes full use of Charm’s efficient Itemset-Tidset prefix search tree to mine frequent closed patterns of column label sequence set. Meanwhile, Charm_Cla can effectively improve classification performance by restoring frequent closed sequences to training samples. Experiments were conducted on actual gene expression datasets, and the experimental results verified the efficiency and effectiveness of this method. © 2023 SPIE.",TextMining
"The research on landslide displacement prediction can help the early warning and prevention of landslide disasters in mining areas. In view of the problem that BP neural network is prone to local convergence and considering that the network trained based on time-series cumulative displacement may produce large errors in prediction, this paper proposes a method combining displacement increment and CS-BP (Cuckoo Search-Back Propagation) neural network to predict landslide displacement. Compared with the conventional landslide displacement prediction methods, this method uses displacement increment instead of the commonly used cumulative displacement as the network input data, selects the CS algorithm with fewer parameters and easy to implement to optimize the BP network to construct the prediction model, and predicts the corresponding amount of displacement change at the next moment by the historical landslide displacement increment. Combined with the measured data of three feature points of a mine in Xinjiang, China, obtained by the micro-deformation monitoring radar, the displacement prediction accuracy of the proposed model on the three measured data sets is compared with the prediction accuracy of the BP, GA-BP (Genetic Algorithm, GA), and FA-BP (Firefly Algorithm, FA) network prediction models based on cumulative displacement and incremental displacement, respectively. The experimental results show that this method achieves superior performance with an average root mean square error of 0.3261 and an average mean absolute error of 0.2785 across the three feature points, outperforming the other models, and holds promising applications in disaster prevention and control work. © 2023, Electromagnetics Academy. All rights reserved.",TextMining
"Evaluating typical rural characteristics reveals certain advantages of rural revitalization and is crucial for understanding rural disparities and promoting development. Field research and statistical data can reflect the spatial distribution of local resources and development models. However, due to cost limitations and statistical constraints, it is impossible to effectively compare and evaluate the characteristics of rural development at the long time series, large scale and fine granularity required for sustainable regeneration. This study proposes a web-based method for the extraction and evaluation of rural revitalization characteristics (WERRC). The BERT-BiLSTM-Attention model categorizes rural web texts according to five themes: industrial prosperity, ecological livability, rural civilization, effective governance, and prosperous life. The Term Frequency-Inverse Document Frequency (TF-IDF) algorithm extracts rural characteristics, and the relative advantages of these features are compared among 100 Chinese villages. WERRC extracts the typical characteristics, obtains the spatial distribution and relative advantage, and then ranks them according to the five themes. The relationship between national policy guidance and rural development is explored. The results support further exploration of differentiated, high-quality development modes that incorporate rural advantages into policy, adjust industrial structure, and optimise revitalization strategies at the rural scale. © 2023 Informa UK Limited, trading as Taylor & Francis Group.",TextMining
"This paper describes the background and architecture of the Intelligent Radar for Aragonese Tourism (RITA), a data-driven social media surveillance system, which aims to enhance the tourist experience by helping the Aragonese government to make informed data-driven decisions and therefore empowering its tourism sector. The system is built over a customizable platform that integrates multiple data mining techniques to collect, clean, process and extract explicit and implicit knowledge from various sources such as social media networks, web pages, RSS feeds and structured data files. RITA employs state-of-the-art Natural Language Processing technologies combined with data analysis and modelling techniques to analyse social perception of the region and link that information with organizational data. The platform integrates pre-trained and fine-tuned language models based on transformers architectures for solving different NLP tasks including opinion and emotion analysis, semantic classification and entities recognition. The knowledge gathered is made available to the tourism professionals via an interactive and customizable web application.  © 2023 Copyright for this paper by its authors.",TextMining
"This paper demonstrates that modernization and adoption of innovative technology, equipment and materials do influence the competitiveness of metals producers, make a significant contribution to the assortment of final products, help reduce the amount of generated waste by processing it into valuable products and raise the recovery of valuable components from ore. Considering the current policy of import substitution, such approach plays an important role for Russian production companies. The paper looks at the Kola MMC and the company’s effort to find the most innovative technology, equipment and materials that are at different stages of development – from actual developments to patented and certified solutions, prototypes and commercial products, which can be used for process optimization and reducing the cost of consumables or reagents. The paper explains why the company focuses on certain areas when searching new technology. This includes the technology that enables to produce new materials with high added value from the company’s raw material, recycle industrial waste thus minimizing the environmental impact; the technology and equipment for production process optimization, new data analysis techniques and process optimization on the basis of automatic decision making algorithms. Thanks to the proven mechanism of searching and analyzing projects and techniques established in the period of 2022–2023, the company managed to identify and build up a pool of innovative projects that rely on novel technology. The company has been engaged in research and development and trial work in order to adopt them in the future, while also utilizing patented and certified solutions. © 2023, Ore and Metals Publishing house. All rights reserved.",TextMining
"In the Internet of Vehicles (IoV), location-based service providers rely on collecting and analyzing user-generated trajectory data to deliver high-quality experiences anytime and anywhere. However, the utilization of data mining technologies raises concerns regarding the potential inference of personal privacy information, posing security risks to user privacy. Existing studies typically use differential privacy to obfuscate actual trajectories, albeit at the cost of reduced data utility. To address this challenge and strike a balance between privacy and data utility, we propose DLPriv, a dynamic location privacy mechanism. DLPriv leverages a Long Short-Term Memory (LSTM) network to predict a driver's next location, which in turn determines the level of data obfuscation. This mechanism considers two optimization objectives, trajectory privacy and utility, and enables fine-grained control over privacy levels. Experimental results demonstrate that our proposed mechanism improves data utility by 37% compared to existing work, while providing the same level of privacy.  © 2023 IEEE.",TextMining
"The composition, interactions, and properties of bioactive peptides found in the most abundant milk protein, CSN2, are the focus of goat milk peptidomics. The peptidome of goat milk is regarded as a valuable source of a large number of biologically active peptides as well as health-promoting activities. Through data mining for bioactive peptide selection associated with current bioactive peptide data algorithms resulting in bioactive peptide profiles and visualization of three-dimensional protein structure, in silico analysis on bioinformatic approaches has led to enhancements of global knowledge regarding the health benefits of dairy products. Biological potentials for cardiovascular and nervous diseases, as well as metabolic and immune treatments, are identified using these techniques, in order to increase the commercialization of goat milk bioactive peptides as a functional food and promising natural source treatments. © Published under licence by IOP Publishing Ltd.",TextMining
The proceedings contain 143 papers. The topics discussed include: lithology identification algorithm of cuttings based on one-dimensional convolutional neural network for mineral element content data; research on rock image classification algorithm based on multi-task learning and pseudo-labels; research on intelligent recognition algorithm for common roadbed diseases based on radar images; pre-planning of individualized talus implants based on computed tomography-automated segmentation; mining order-preserving submatrix based on charm for gene expression data; an improved watershed algorithm and its application in image edge extraction; research on augmented reality registration method based on SA-PSO algorithm; a personalized test paper generation model for English examination based on knowledge tracking; and improved ACLPSO algorithm for automatic parameter optimization.,TextMining
"Purpose: Upon the realization of the need for guideline in cross-organizational data integration, in an exploratory manner, this study developed a public data governance framework, specifically, the governance for integrated public data (GIPD) framework and identified the influential factors of its successful implementation. This framework was then subjected to an analysis of a real data integration case in the South Korean public sector to test its efficacy. Design/methodology/approach: To develop the GIPD framework, the authors conducted an extensive meta study, focus group interviews and the analytic hierarchy process involving field experts. Further, the authors performed topic modeling on documents from Korean research and development data integration projects, and compared the extracted factors to those of the GIPD to illustrate the latter's usefulness in a real case. Findings: Legislation, policy goals and strategies, operation organization, decision-making council, financial support size and objective, system development and operation, data integration, data generation, system/data standardization and master data management were derived as the 10 important factors in implementing the GIPD framework. The illustrative case of Korea revealed that decision-making council, financial support size and objective, legislation, data generation and data integration were insufficient. Research limitations/implications: Although this study reveals important findings, it has a few limitations. First, the potential factors for data governance might vary depending on the attribute of the “interviewee” (such as their career or experience period) and the goal and area of GIPD framework building. Second, the inherent limitation of topic modeling in determining topics from groups of extracted keywords means that topics may be interpreted in various ways, depending on the perspective of the expert. Practical implications: This study is highly significant in that it provides a starting point for discussions on the issue of data integration among public institutions. Therefore, although this study examined public data governance based on R&D data, it will contribute to providing a sufficient guideline for any type of inter-institutional data governance framework, what to discuss and how to discuss between institutions. Originality/value: The findings are expected to provide a roadmap to formulate practical guidelines on inter-institutional data cooperation and a diagnostic matrix to improve the existing data governance system, especially in the public sector, from the existing practice of empirical analysis using a mixed methodology approach. © 2023, Emerald Publishing Limited.",TextMining
"The article presents the results of research, which consist in studying the features of the spatio-temporal propagation of seismic waves from technological blasts, according to the data obtained by seismic recorders installed on the earth's surface, to increase the level of safety of protected facilities, the stability of slopes and more rational use reserves of mineral deposits in the near-edge zone developed by the open method. To achieve this goal, the main objectives of the study were solved, i.e. the seismic effect of technological blasts on protected facilities and the near-edge rock masses in various mining and geological conditions of complex-structured deposits of the Urals, Siberia, Karelia and Kazakhstan was studied using direct field measurements; the analysis of the deviations of the actual rock mass vibrations from the calculated values at different coefficients of soil conditions was carried out, and clarifying dependences for calculating the permissible vibration rates of the rock mass based on the physical and mechanical properties of rocks with their different structural weakening were obtained; on the basis of data on the properties of rocks and the propagation of seismic vibrations in them during large-scale blasts, an express method has been developed that allows determining the earthquake-safe parameters of drilling and blasting operations in the near-edge zone of the quarry, to ensure the stability of slopes, as well as to predict the seismic impact of the blasting operations on protected facilities. © 2023, Scientific and Industrial company 'Gemos Ltd.'. All rights reserved.",TextMining
"The role of marketing strategy in the industrial structure adjustment and development of financial institutions in the era of the digital economy has changed marketing strategy and made the industrial structure adjustment of financial institutions in the era of the digital economy a hot spot. However, in the process of changing the marketing strategy of financial institutions, there are problems such as poor marketing concepts, weak online sales capabilities, network data analysis, and small mining volume. The main reason is that the traditional marketing model does not use information management technology to restrict the development of financial institutions. Therefore, this paper proposes a marketing method based on information management technology to plan the marketing strategies of financial institutions with different networks. First, phyton software is used to collect financial institutions' marketing data from the Guoan Tai database in 2018~2022, and according to the collected data of 33 financial institutions for analysis. Then, the judgment of marketing strategy is based on information management technology to improve the accuracy of financial institutions' selection of marketing strategy. The adjustment results show that under the background of the digital economy, information technology can improve the marketing strategy selection of financial institutions, promote the optimization of marketing strategies of financial institutions, and respond to the requirements of the financial market. Information technology can improve the accuracy and effect of marketing strategy selection of financial institutions, making its accuracy greater than 90%, which is significantly better than 80% of the manual identification method. At the same time, information technology can improve the recognition rate of marketing strategy, which is more than 80%, and provide support for the formulation of marketing strategy. Therefore, under the condition of a digital economy, industrial structure has a significant impact on the marketing strategy of financial institutions, while information technology methods can identify strategic indicators, improve the effect and accuracy of strategy formulation, and promote the development of financial institutions. Copyright © 2023 by Author/s.",TextMining
"Uncertainty exists widely in practical engineering. It is an important challenge in engineering structural analysis. In truss structures, the uncertainties of axial stiffness of bolted joints will significantly affect the mechanical behavior of the structure as the axial load is dominated by the member internal forces. Structural response analysis based on determined structural parameters is a common forward problem that can be solved by modeling analysis methods. However, the uncertainties parameter of axial stiffness of bolted joint cannot be determined during the design and analysis of truss structure in the direct nonlinear analysis method. Structural parameter identification based on structural response is a typical inverse problem in engineering, which is difficult to solve using t raditional analysis tools. In this paper, an inverse model based on Graph Neural Network (GNN) is proposed. The feature encoding method for transforming truss structures into graph representations of GNN is defined. A paramet erized acquisition method for large-scale datasets is presented, and an innovative inversion model based on GNN for the inversion of uncertain parameters of t russ structures is proposed. The proposed method is shown to perform well with an inversion accuracy, and accurate results can be obtained with limited data sets. The inversion method has strong data mining capability and model interpretability, making it a promising direction for exploring engineering structural analysis. © 2023 by The Hong Kong Institute of Steel Construction. All rights reserved.",TextMining
"Metal pollution is a major environmental problem which affects agriculture and human health. Turkey has significant Cu mining areas in Diyarbakır and its surrounding areas (Southeast Anatolia). Several crop plants cultivated in these areas are irrigated with water from the Tigris, and most agricultural lands are contaminated with Cu. Brassica nigra and B. juncea are well-known metal accumulator plant species which can hyperaccumulate metals, including copper, in their shoots. The purpose of this study is to evaluate their potential for the phytoremediation of Cu from these contaminated areas as an environmentally friendly and cost-effective means of reducing Cu-contamination. In this research, B. nigra and B. juncea plants were grown in soil at different Cu concentrations (0 to 1000 µM) and showed no toxicity symptoms while accumulating a significant amount of metal in their leaves. In the leaves of both species, the Cu content increased significantly with the increase in the Cu level in the media. HMA1 (Heavy Metal ATPase 1) in the leaves of both plant species gradually increased with increased Cu levels until 50 μM, then its expression slowly decreased with the further increase in Cu levels. The expression of HMA3 also increased with an increase in Cu in the leaves of both plant species. However, its expression pattern differed from that of HMA1. Our data showed that an increase in Cu levels in the leaves triggers the expression of both genes, suggesting that they play an active role in Cu detoxification. We propose that these plant species could be used for the decontamination of Cu from polluted soils. These data also indicate that Cu accumulation and tolerance in both plant species is probably a multi-genetic response, possibly involving several other transporter genes in the stress signal pathway. Hence, we also explored the expression of the other metal transporters, such as other HMAs (HMAs 5‒8), Nramps (e.g., Nramp3), COPT proteins, and some Cu chaperons in these plant species. © 2023 Institute of Botany and Botanical Garden Jevremovac, Belgrade",TextMining
"Due to refined and new diagnostic possibilities and improved medical care, in the future anesthesiologists will be more frequently confronted with patients suffering from rare diseases. As the physicians providing perioperative care often have little or no experience with the diseases of such patients, the access to high-quality specific literature is essential. In this respect they must be able to assess and classify the quality of the information which is predominantly available online, especially as when evidence-based knowledge is available, it is only available to a very limited extent. Patients with rare diseases mostly present with recurring problem constellations. A systematic assignment to the most important problem areas (airway, circulation, metabolism, etc.) as well as a structured and interdisciplinary approach are decisive for a successful perioperative treatment of these patients. Due to low prevalence, lack of personal experience and lack of evidence-based data, anesthesia in patients with SE is an absolute challenge, especially in time-critical situations. © 2023, The Author(s), under exclusive licence to Springer Medizin Verlag GmbH, ein Teil von Springer Nature.",TextMining
"The purpose of the paper is to examine the effect of the Arctic Hectare program on the development of Russian cities in the Arctic region. In particular, the study analyzes the role of the program in changing the borders of settlements and the possibility of their regulation. The research employs a qualitative approach, including the collection of data from government documents, research literature, and electronic resources associated with urban development, regional development, and the Arctic Hectare program. Data analysis shows that most Arctic cities continue to compress: with pre-served infrastructure, entire houses and areas of settlements go empty. In contrast, the Gulf of Ob shows an increase in settlements, as its mining areas actively expand. The area demonstrates a principle characteristic of circumpolar urban development, e.g., a fractal system of settlement growth with the development of the next branch of the city tree. The restart of empty suburbs outside the zone of active mining is attributed to the stage program of Arctic Hectare. As a result, the authors identify two concepts of urban planning: one that emphasizes development along outbound highways, and another that assumes the development of satellite cities. In the near future, the familiar urban landscape may change, as its outskirts may be supplemented by low-rise development. A large share of applicants use the Arctic Hectare to solve the housing problem. It becomes clear that the suburbs are a realistic way of habitation in the Arctic region. The researchers argue that the sustainability theory can allow predicting urban development in the territory based on adaptive cycles. © 2023, Belgorod V G Shukhov State Technology University. All rights reserved.",TextMining
"Background: Osteoporotic fractures can result in significant health complications and an increased risk of death. Registry studies could provide better treatment options and improve patient outcomes by providing useful information about the disease. The present study describes the protocol for an osteoporosis registry in Iran. Materials and methods: This registry is a prospective multicenter cohort study recruiting patients with osteoporosis from Iran. The inclusion criteria of the study are individuals diagnosed with primary or secondary osteoporosis according to the diagnostic criteria of the study; patients will be identified and recruited from outpatient clinics in this registry. All patients diagnosed with primary or secondary osteoporosis are the target population of the study. Our expected sample size is 1000 participants and the study will continue for at least 2 years. The measurements of the Iranian Osteoporosis Registry include four parts: (i) variables measured by the specific questionnaires package, (ii) bone mineral density (BMD, (iii) clinical examination, and (iv) lab data. The final questionnaire package includes “demographics information”, “socioeconomic status”, “lifestyle”, “reproductive health”, “medical history and medication”, “Osteoporosis diagnosis gap”, “Osteoporosis adherence and treatment gap”, “fracture history and fall risk assessment”, “FRAX ® tool ”, “hospitalization and death outcomes”, “low back pain”, “hospitalization history”, “attitude toward osteoporosis”, “osteoporosis awareness”, “osteoporosis related-performance”, “quality of life (Iranian version of SF12 questionnaire)”, and “food frequency questionnaire (FFQ)”. Clinical examination of this registry includes anthropometric measurements (including height, weight, body mass index (BMI), waist circumference, hip circumference, and right wrist circumference), and blood pressure. The baseline questionnaires will be filled out right after patients are diagnosed with osteoporosis and then osteoporotic patients will be followed up regularly on a yearly basis. In the follow-up visit, variables that may have changed over time are updated. The main outcomes include registration of fall, fracture, hospitalization, medication adherence, and death. An online web-based user-friendly software is also developed for data collection. Data analysis will be conducted with the collaboration of data-mining experts and epidemiologists at the end of each follow-up. Conclusion: The Iran Osteoporosis Registry will be a valuable source of information regarding osteoporosis outcomes (i.e. fractures, hospitalizations, adherence, and death at the national level), and its results will be very beneficial and practical for policy makers in the field of musculoskeletal diseases. © 2023, The Author(s), under exclusive licence to Tehran University of Medical Sciences.",TextMining
"Ovarian cancer is a malignant tumor that primarily forms in the ovaries. It often goes undetected until it has spread to the pelvis and abdomen, making it more challenging to treat and often fatal. Historically, natural products and their structural analogues have played a pivotal role in pharmacotherapy, especially for cancer. Numerous studies have demonstrated the therapeutic potential of Linum usitatissimum against ovarian cancer, but the specific molecular mechanisms remain elusive. This study combines data mining, network pharmacology, and molecular docking analysis to pioneer an innovative approach for ovarian cancer treatment by identifying potent phytochemicals. Findings of current study revealed that Apigenin, Vitamin E, Palmitic acid, Riboflavin, Isolariciresinol, 5-Dehydro-avenasterol, Cholesterol, Pantothenic acid, Nicotinic acid, Campesterol, Beta-Sitosterol, Stigmasterol, Daucosterol, and Vitexin suppress tumor growth by influencing AKT1, JUN, EGFR, and VEGFA. Kaplan–Meier survival analysis spotlighted AKT1, JUN, EGFR, and VEGFA as potential diagnostic and prognostic biomarkers for ovarian cancer. However, it is imperative to conduct in vivo and in vitro examinations to ascertain the pharmacokinetics and biosafety profiles, bolstering the candidacy of L. usitatissimum in ovarian cancer therapeutics. Copyright © 2023 Islam, Sreeharsha, Alshabrmi, Asif, Aldhubiab, Anwer, Krishnasamy and Rehman.",TextMining
"With the over-exploitation of mineral resources leading to major conflicts such as water shortage, water quality deterioration, and water ecology deterioration, the risks arising from water ecology in mining areas have received extensive attention from scholars at home and abroad. Using the Web of Science core collection as the data source, 1939 papers from 2007-2021 were used as research objects. CiteSpace and VOSviewer were used to draw a knowledge map for literature visualization and analysis, with the aim of exploring the inner rules, research hotspots and evolutionary trends in the field of water ecology risks in mining areas. The study shows that: (1) The number of publications has been steadily increasing, with China being the country with the highest number of publications. (2) Many studies are conducted within research teams, but cooperation between teams is not strong enough. (3) The current research area has shifted from single substances to coupled research on multiple substances generated by mining. (4) Pollutants from mining areas have a direct impact on the ecological and health safety of humans. © 2023, HARD Publishing Company. All rights reserved.",TextMining
"The article justifies the topicality of studying man-induced seismicity during large-scale mining operations in rockburst hazardous ore deposits. Occurrence conditions have been formulated for natural and man-caused earthquakes as well as various mechanisms of strong seismic events. It is shown, that revealing the stressed state of the intact rock mass, possible deformations and additional stresses due to large-scale rock mass excavation as well as the conditions for the accumulated energy to release due to the impact of blasting activities during roadheading and ore breaking are considered to be very important. Criteria are considered for various forms of rock failure during strong seismic events. A methodology to identify critical states of the geological environment is proposed to assess the geomechanical situation in the mining area and to manage the geodynamic risks. This methodology allows to give a forecast assessment of changes in the stress-and-strain state of the rock mass based on analyzing mining and geological data of instrumental measurements and finite element modelling as well as to select technical solutions to ensure the safety of mining operations. Principles of safe mining operations at rockburst hazardous deposits are formulated, approaches to the choice of the mining system for the ore deposits and to the order of stoping operations at the mine level are justified. © 2023, Scientific and Industrial company 'Gemos Ltd.'. All rights reserved.",TextMining
"Packed beds of particles have various applications in different sectors such as mining, chemical, and food industries. Determination of heat exchange rate between solid particles and fluid has been of great interest in various energy-related activities. Therefore, the main objective of this study is to investigate the influence of particle size on the overall performance of the thermal energy storage system. In order to investigate the effect of design and operating parameters on heat transfer characteristics of packed bed, an extensive numerical study followed by multi-objective optimization based on response surface methodology is conducted in the present study. A comparison between the obtained results for volume-average-based models (local thermal equilibrium and local thermal non-equilibrium) and experimental data is made. The numerical results show an accurate prediction of thermocline only when local thermal non-equilibrium model is used. After validating the numerical results, the desirability function is used to find the optimum particle diameter for different values of pumping power. The particle diameter that yields the highest energy storage capacity and lowest fan power is reported for the considered thermal energy storage system. The optimization procedure is further extended such that the optimal particle diameter for different values of fan power is also reported. © 2023 Begell House Inc.. All rights reserved.",TextMining
"In order to ensure effective layered water injection, it is of great significance to establish the functional relationship among the equivalent diameter of damage, leakage and pressure of sealing cylinder. In this paper, the experimental and numerical simulation experiments were carried out to study the relationship between gap flow rate, pressure drop and equivalent diameter of sealing cylinder under the conditions of uniform corrosion, fracture non-uniformity and random groove non-uniform distribution and scratches in different tubing, equivalent diameters and gap widths. Through a lot of data analysis, the relationship between the damage state and the leakage quantity is established and evaluated by physical simulation test. The research shows that the error between the established model function relation and the test data is no more than 10%. By simulating the damage condition of the shock sealing cylinder and quantitatively detecting the defect of the sealing cylinder, the model function relation can well predict the corresponding damage situation. Therefore, this model function can be used to solve sealing cylinder inspection problem, so as to judge the seal defect and leakage quantity which is independent of the experience of the person in charge of the site and able to use the data as a basis for judgment. This research provides a new technology for the effective prediction of the damage of sealing cylinder, and provides theoretical guidance for selecting matching sealing tools and realizing layered mining. © Published under licence by IOP Publishing Ltd.",TextMining
"This article has been retracted by Hindawi following an investigation undertaken by the publisher [1]. This investigation has uncovered evidence of one or more of the following indicators of systematic manipulation of the publication process: (1) Discrepancies in scope (2) Discrepancies in the description of the research reported (3) Discrepancies between the availability of data and the research described (4) Inappropriate citations (5) Incoherent, meaningless and/or irrelevant content included in the article (6) Peer-review manipulation The presence of these indicators undermines our confidence in the integrity of the article s content and we cannot, therefore, vouch for its reliability. Please note that this notice is intended solely to alert readers that the content of this article is unreliable. We have not investigated whether authors were aware of or involved in the systematic manipulation of the publication process. In addition, our investigation has also shown that one or more of the following human-subject reporting requirements has not been met in this article: ethical approval by an Institutional Review Board (IRB) committee or equivalent, patient/ participant consent to participate, and/or agreement to publish patient/participant details (where relevant). Wiley and Hindawi regrets that the usual quality checks did not identify these issues before publication and have since put additional measures in place to safeguard research integrity. We wish to credit our own Research Integrity and Research Publishing teams and anonymous and named external researchers and research integrity experts for contributing to this investigation. The corresponding author, as the representative of all authors, has been given the opportunity to register their agreement or disagreement to this retraction.We have kept a record of any response received. © 2023 Journal of Sensors.",TextMining
"Cancer is a common and dangerous disease based on the World Health Organization. Much research has been done on new and effective cancer treatments, including cancer vaccines and the prediction of neoantigens using machine learning. The purpose of this study is to review articles that use machine learning to design cancer vaccines. This study is a rapid review study using search strategies and related keywords in Google Scholar, PubMed, and science direct databases from 2010 to 2021 in 2021 and revised in August 2023. 1250 articles were searched and 13 articles were selected for this review. We investigated them and then due to the importance and popularity of using machine learning in cancer vaccines recently, we compared them based on their machine learning technique. it is shown that neural networks with Python are used to predict neoantigens in 4 articles and with MATLAB in 2 articles, one article was about using the Fontom, one article with PERL, and one article with R; Other studies were about data mining with flowsom algorithm, multiple linear regression, logistics, and oncopepVCA, and the rest of articles do not provide information about machine learning implementation tools. Providing neural networks with Python is useful in the prediction of neoantigens due to the precision and examination of complex data sets. They use to predict HLA and peptide binding affinity, vaccines outcome, personalized cancer vaccines based on new data, the immune response, processing RNA and DNA sequences, and immunological analysis. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"As one of the graduation requirements at the university level, students must complete a thesis or final project. In practice, students often find it difficult to determine the theme or topic of research. The research topic is expected to be in accordance with the student's ability, based on the academic value that has been achieved in the previous lecture process. For this reason, in this study, an analysis will be carried out on what course recommendations can support the students' thesis and final project processes, which are expected to assist students in determining the theme or research topic, based on the values of the courses that have been taken by students in the learning process. previously. The analysis was carried out using the k-means algorithm. The results of this research will provide recommendations to help lecturers and students in determining the themes of the thesis that will be made. © School of Engineering, Taylor’s University.",TextMining
"In the production process of cellulosic ethanol, all sections are closely related. It is difficult to study its producing law and key factors that affect the process only by experimental means. Computer simulation has a powerful data mining ability, which can analyze, design, and evaluate the production process of cellulosic ethanol. Specifically, it can use data calculated by Aspen Plus before, and analyze the impact of cellulose ethanol production on the environment by life cycle assessment (LCA). Results show that the total environmental impact value of the whole process is 0.20 1/40.37 person·a/t. And in the whole process, the growth stage and the production stage have the biggest impact. © Published under licence by IOP Publishing Ltd.",TextMining
"In the context of ""smart healthcare"", due to the substantial increase in medical data and patient diagnostic needs, conventional diagnostic methods are gradually unable to meet the current diagnostic requirements. Therefore, a network medical image information feature diagnosis method based on big data is designed to improve the effect of disease diagnosis. The convolutional deep belief network is used to extract the information features of the network medical image in the network medical image. The t-SNE algorithm is used to select the more valuable network medical image information features in the extracted features. Using stacking to integrate AdaBoost and Bagging algorithm, the disease diagnosis results are obtained. The artificial bee colony algorithm is used to optimize the weights of the multi-level ensemble learning algorithm to improve the accuracy of disease diagnosis. In the multi-level ensemble learning algorithm after weight optimization, the selected network medical image information features are input and the disease diagnosis results are output. Experiments show that this method can effectively extract the information features of network medical images and accurately diagnose diseases. At different spatial resolutions of network medical images, the Kappa values of disease diagnosis of this method are high, and the lowest Kappa value is about 0.875, which means that this method has high disease diagnosis performance. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"The advent of the Fourth Industrial Revolution has precipitated a digital metamorphosis in oil companies, presenting a singular path towards cost reduction and heightened efficiency. As a pivotal direction, the intelligent oilfield represents an intricate, integrative information system. Its capacity to orchestrate petroleum exploration, production decisions, and other relevant sectors through data technology facilitates the standardization and automation of oilfield exploitation. In pursuit of this goal, we propose a novel digital technology solution specifically designed for offshore oilfields. Harnessing state-of-the-art computer technologies such as big data, cloud computing, edge computing, optical fiber communication, and IoT, our aim is to establish an inclusive data integration platform and deliver unified data services to enhance the efficiency of information utilization. Within the landscape of the digital oilfield, offshore production monitoring and optimization emerges as a promising sector where data processing and advanced analytics can be employed to boost revenue, curtail costs, and mitigate risks. Constructing a data mining and analytics engine to utilize data from wells, equipment, facilities, and field personnel, however, poses a formidable challenge. The workflow of data acquisition from offshore production platform groups-comprising main production platforms, sub-production platforms, transport vessels, and FPSOs-along with the transmission, processing, and timely analysis of data, are major factors in formulating a data service solution. Consequently, an integrative system encapsulating all necessary tools can significantly expedite addressing these challenges in a timely manner. This paper provides a comprehensive technical elucidation of the currently devised intelligent oilfield production monitoring system. The data service system encompasses four subsystems: (I) Production management, encompassing remote operation monitoring, production dynamic tracking, reservoir dynamic management, and well pattern injection and production deployment management; (II) Equipment and facilities management, which includes equipment health management, submarine pipeline operation and maintenance management, submarine cable management, and inventory management; (III) Scheduling management, integrating personnel dynamic dispatching, ship dynamic dispatching, and meteorological and hydrological monitoring; and (IV) Safety management, ensuring operational safety and personnel status and location management. These subsystems are seamlessly integrated and engage in intercommunication, functioning as microservices, cloud-based container services, or edge computing services. They provide a comprehensive solution for real-time offshore production optimization and monitoring. The edge-cloud collaborative system, established on this blueprint, has undergone successful testing and application in a Bohai oilfield. This paper will be beneficial for oil and gas organizations contemplating the implementation of an offshore intelligent oilfield as part of their digital transformation strategy. Moreover, it will offer valuable insights to any parties interested in acquiring a deeper understanding of intelligent oilfields. © 2023, Society of Petroleum Engineers.",TextMining
"Unchecked breast cell growth is one of the leading causes of death in women globally and is the cause of breast cancer. The only method to avoid breast cancer-related deaths is through early detection and treatment. The proper classification of malignancies is one of the most significant challenges in the medical industry. Due to their high precision and accuracy, machine learning techniques are extensively employed for identifying and classifying various forms of cancer. Several data mining algorithms were studied and implemented by the author of this review and compared them to the present parameters and accuracy of various algorithms for breast cancer diagnosis such that clinicians might use them to accurately detect cancer cells early on. This article introduces several techniques, including support vector machine (SVM), K star (K∗) classifier, Additive Regression (AR), Back Propagation Neural Network (BP), and Bagging. These algorithms are trained using a set of data that contains tumor parameters from breast cancer patients. Comparing the results, the author found that Support Vector Machine and Bagging had the highest precision and accuracy, respectively. Also, assess the number of studies that provide machine learning techniques for breast cancer detection. © 2023 Tech Science Press. All rights reserved.",TextMining
"In view of the lack of interpretability and data dependence of RNN-based deep knowledge tracking model, a deep knowledge tracing model integrating attention mechanism is proposed. First, learn the embedded representation of students' historical interaction, and then learn specific weights based on the topic's attention mechanism to identify and strengthen the impact of students' historical interaction on the knowledge state at each moment to different degrees; Comparative experiments will be carried out on two data sets, and the best performance will be achieved in the ASSISTments2012 data set, and the problem of long sequence dependence will be alleviated to some extent. This model can capture students' knowledge state more accurately and predict students' future performance more efficiently. © 2023 SPIE.",TextMining
"We study the network untangling problem introduced by Rozenshtein et al. (Data Min. Knowl. Disc. 35(1), 213–247, 2021), which is a variant of Vertex Cover on temporal graphs–graphs whose edge set changes over discrete time steps. They introduce two problem variants. The goal is to select at most k time intervals for each vertex such that all time-edges are covered and (depending on the problem variant) either the maximum interval length or the total sum of interval lengths is minimized. This problem has data mining applications in finding activity timelines that explain the interactions of entities in complex networks. Both variants of the problem are NP-hard. In this paper, we initiate a multivariate complexity analysis involving the following parameters: number of vertices, lifetime of the temporal graph, number of intervals per vertex, and the interval length bound. For both problem versions, we (almost) completely settle the parameterized complexity for all combinations of those four parameters, thereby delineating the border of fixed-parameter tractability. © 2023, The Author(s).",TextMining
"Estimating the axial force of rock bolts is vital for the stability and safety of underground excavations. Current methods suffer from being labor-intensive, time-consuming, and prone to inaccuracies. This paper presents a novel method for estimating the axial force of a rock bolt, a critical element in underground engineering, by analyzing the deformation field of the bearing plate. This innovative approach combines 3D laser scanning for data acquisition with a developed convolutional neural network (CNN) model for data processing, resulting in an efficient and non-destructive external monitoring technique. The proposed method was verified with 27 laboratory experiments. The results showed an accurate estimation of the axial forces of rock bolts with an average error of ± 5 kN, underlining the method’s potential for in-situ application in underground engineering. This research not only contributes to the development of intelligent systems in rock mechanics and engineering but also has significant implications for industries, such as mining, tunneling, and underground engineering. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature.",TextMining
"The article presents the results of research aimed at development of a method for preventing gas-dynamic phenomena in roof rocks in entries to potassium stratum II at Belaruskali’s Mine Management 3. The geological and mining conditions of spontaneous roof collapse in the U-turn chamber of potassium stratum II were analyzed. The spontaneous collapse of roof rocks in the U-turn chamber according to the conditions of the roof rock failure behavior and consequences is classified as a delayed gas-dynamic phenomenon in the form of a sudden rock fall accompanied by gas release under the influence of free gas pressure in gas clusters induced in the contact areas in roof rocks undermined in the course of the U-turn chamber heading. The mechanism of delayed collapses of roof rocks accompanied by gas release in underground openings is analyzed as a case-study of entries to potassium stratum II using the in-mine experimental data on gas-dynamic characteristics of roof rocks non-undermined and undermined by stoping in potassium stratum III. Based on the estimates of the possible development of delayed gas-dynamic phenomena, the necessity of preventive degassing of roof rocks in the U-turn chambers and in other underground openings with a similar span is shown. The parameters of preventive degassing drilling in roof rocks of potassium stratum II in different geotechnical conditions are proposed with regard to the estimated patterns of contact clusters of free gases in roof rocks. © 2023, Ore and Metals Publishing house. All rights reserved.",TextMining
"It is crucial to determine the content and distribution of heavy metals in soil in a timely and accurate manner. Based on GaoFen-5 hyperspectral images, this study investigates a large-scale inversion of soil Cd content in Tongguan County. The competitive adaptive reweighting algorithm and genetic algorithm (CARS-GA) are coupled via feature coding and random mutation to accurately screen the characteristic bands of Cd and improve the inversion accuracy of the model. The characteristic bands of Cd are searched for, first based on the global search strategy and then local search. Under the two spectral enhancement methods of standard normal variate (SNV) and first differential (FD), the accuracy values of the partial least squares (PLSR) models established using the CARS-GA method and other band selection methods (correlation coefficient analysis method and CARS algorithm) are compared. Finally, the optimal model is selected and applied to the entire bare-land area of Tongguan County. The experimental results show that when the CARS-GA method is used for band selection, the accuracy values of the PLSR model constructed based on the two spectral transformation datasets are significantly higher than those constructed using the correlation coefficient analysis method and the CARS algorithm. During the FD spectral transformation, the coefficient of determination of the validation set increases by 0. 288 and 0. 093, respectively. In the SNV-transformed spectrum, the coefficient of determination of the validation set increases by 0. 372 and 0. 088, respectively. This study demonstrates that the band selection based on the CARS-GA algorithm can effectively enhance the robustness of the Cd-content estimation model, providing improved data support for environmental pollution assessment and ecological protection. © 2023 Universitat zu Koln. All rights reserved.",TextMining
"Because feature extraction from electroencephalogram (EEG) signals is essential for cognitive investigations, effective feature extraction approaches are needed to improve the practical recognition accuracy of EEG signals. In this paper, a strategy is presented for fusing both the linear and nonlinear features from EEG signals to improve the accuracy of motor imagery classification. First, principal component analysis (PCA) is used to extract the linear features from EEG, and linear discriminant analysis (LDA) is introduced to supplement the discriminant features by utilizing the label information of the training data. Second, we use parametric t-distributed stochastic neighbor embedding (PTSNE) to extract the nonlinear features reflecting the original manifold structure of the EEG data. Third, these linear and nonlinear features are fused to generate the final features for classification. After feature extraction, we choose the hierarchical extreme learning machine (HELM) algorithm, which has a high classification accuracy for EEG signal classification of motor imagery. To verify the validity of the strategy, we compare the accuracy of the proposed method with that of other methods on the motor imagery dataset. We achieve a high accuracy of 95.89% and an average accuracy of 93.45%. The performance shows that the accuracy of the proposed feature fusion strategy is effective for classification and that the recognition accuracy is improved compared with other state-of-the-art methods. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",TextMining
"Various techniques such as data mining, network pharmacology, molecular docking and molecular dynamics simulation were used in this study to screen and validate effective herbal medicines for the treatment of idiopathic pulmonary fibrosis (IPF) and to reveal their mechanisms of action at the molecular level. The use of this approach will provide new tools and ideas for future drug screening, especially for the application of herbal medicines in the treatment of complex diseases. Among them, the five identified core targets, including IL6, TP53, AKT1, VEGFA, and TNF, as well as a series of major active compounds, will be important references for future anti-IPF drug development. This information will accelerate the discovery and development of relevant drugs. Meanwhile, this study further confirmed the potential value of four Chinese herbal medicines, including Gancao, Danshen, Huangqin, and Sanqi, in the treatment of IPF. This will promote more clinical trials and practices to confirm and optimise the application of these herbs. Finally, this study is an important theoretical guide to enhance the advantages of Chinese herbal medicines in the prevention and treatment of major and difficult diseases, as well as to understand and utilise the potential efficacy of Chinese herbal medicines. This will further promote the scientific research and clinical application of herbal medicines and provide more possibilities for future disease treatment Communicated by Ramaswamy H. Sarma. © 2023 Informa UK Limited, trading as Taylor & Francis Group.",TextMining
"Artificial Intelligence (AI) has recently experienced a significant rise in its implementation, as evidenced in several industries, such as telerehabilitation. Regarding the digital transformation in telerehabilitation, some companies have already utilized machine learning techniques to analyze the dataset collected via sensors or cameras and then support distance medical experts in diagnosing through the Internet. This research proposes a novel two-stage data mining framework combining gait analysis and interval-based sequential pattern mining. Potential problems or diseases are discerned in the first stage by analyzing gait videos captured from a camera. A series of walking postures captured frame by frame can be transposed into a sequence of events. For instance, a particular frame might depict a gait indicative of a possible Parkinsonian gait. Since these events are recorded temporally, a series of similar events can be merged to form an interval-based event, described by its starting and ending points. Subsequently, the second stage involves extracting and recognizing patterns from a dataset of interval-based temporal sequences through sequential pattern mining. This preliminary experiment collected twenty real-life samples and corroborated the usefulness of the proposed model. © WCSE 2023.All rights reserved.",TextMining
"This Indonesia has a vast number of tourist destinations, and it can be overwhelming for people to decide where to go, either because they have many options to choose from or because they are bored with places they have visited before. To address this issue, this research uses collaborative filtering-based recommendation systems to provide users with personalized recommendations based on their previous ratings. The research will compare five recommendation system algorithms: the Hybrid Algorithm with ContentKNN (Content K Nearest Neighbors) and RBM (Restricted Boltzmann Machine), SVD++ (Singular Value Decomposition++), Efficient Deep Learning, Scalable Deep Learning, and Naïve Bayes. These algorithms will be tested based on their evaluation metrics, namely RMSE (Root Mean Squared Error) and MAE (Mean Absolute Error). The model that has the best evaluation metrics will be selected to provide travelling place recommendations. To develop algorithm models for the recommendation system, the research will use the CRISP-DM (Cross-Industry Standard Process for Data Mining) model. Based on the workflow, Efficient Deep Learning has the best RMSE and MAE value from all of the models, with these following parameters: 250 neurons and SELU (Scaled Exponential Linear Unit) activation type. Future works for this research includes additional rating dataset, adding different combinations of fields, distance metrics, and other evaluation metrics. © 2023 IEEE.",TextMining
"Coal mining is generally carried out through open pit mining methods which have an impact and become an obstacle to changes in the chemical, physical, and biological properties of the soil. Revegetation of reclaimed land is a priority in restoring ecosystems disrupted by mining activities. This study aims to assess the success of the direct planting method in accelerating the growth of Pterocarpus indicus plants in coal mining reclamation areas. Field data and observations are used to evaluate the growth of plants directly planted in reclaimed post-mining land. The growth parameters observed include plant height, stem diameter, and leaf count using both seedling and stemcutting planting materials. The research results indicate that the direct planting method has a significant impact on accelerating the growth of Pterocarpus indicus plants. The plant height, diameter, and leaf count growth from the ANOVA test results showed a significant effect or significance at p<0.05 for the interaction between planting material, fertilizer, and dosage. The Duncan test results for the average plant height, stem diameter, and leaf count indicate the optimal use of bokashi fertilizer. The effective bokashi fertilizer dosage for each variable is 3 kg/plant-ing hole, resulting in a plant height of 102.31 cm; 3 kg/planting hole, resulting in a stem diameter of 24.26 cm; and 5 kg/planting hole, resulting in a leaf count of 41.32. © (2023), (Polskie Towarzystwo Inzynierii Ekologicznej (PTIE)). All Rights Reserved.",TextMining
"The 1,2,3-triazole scaffold has become very attractive to identify new chemical entities in drug discovery projects. Despite the widespread use of click chemistry to synthesize numerous 123Ts, there are few drugs on the market that incorporate this scaffold as a substructure. To investigate the true potential of 123Ts in protein-ligand interactions, we examined the noncovalent interactions between the 1,2,3-triazole ring and amino acids in protein-ligand cocrystals using a geometrical approach. For this purpose, we constructed a nonredundant database of 220 PDB IDs from available 123T-protein cocrystal structures. Subsequently, using the Protein Ligand Interaction Profiler web platform (PLIP), we determined whether 1,2,3-triazoles primarily act as linkers or if they can be considered interactive scaffolds. We then manually analyzed the geometrical descriptors from 333 interactions between 1,4-disubstituted 123T rings and amino acid residues in proteins. This study demonstrates that 1,2,3-triazoles exhibit diverse preferred interactions with amino acids, which contribute to protein-ligand binding. © 2023 American Chemical Society.",TextMining
"Fully-mechanized caving mining with a substantial mining height is inevitably accompanied by alterations in the surrounding rock, coal seam fractures, and stress field. To predict these problems, this study employs the utilization of microseismic monitoring technology to dynamically observe the behavior of the surrounding rock and coal seam during the mining process at Tongxing Coal Mine. By analyzing the microseismic data obtained from this monitoring, the migration patterns of the surrounding rock and the evolution of crack propagation during the advancement of the mining face are examined. The investigation demonstrates that microseismic monitoring technology can proficiently oversee the fractures in the surrounding rock and serves as an effective measure to prevent roof instability. The occurrence patterns of microseismic events replicate the entire process of rock movement and fracture, elucidating the scope of rock motion and the distribution of stress in the surrounding rock, while also effectively predicting the fracture zone, failure range, and failure strength of the enveloping rock. This monitoring technology offers comprehensive oversight of the movement of the surrounding rock in fully mechanized caving faces within extra-thick coal seams, enabling a comprehensive understanding of the damage incurred by the surrounding rock. Concurrently, in conjunction with the theory of rock mass pressure, it can scientifically and reliably detect anomalous geological structures within the working face, as well as the movement patterns and stress fluctuations of the surrounding rock. The findings of this study provide valuable technical support for the application of microseismic monitoring technology in the monitoring of surrounding rock within deep underground spaces. © 2023, The Author(s), under exclusive licence to Springer Nature Switzerland AG.",TextMining
"Stance detection estimates the stance of a user towards a specific target through the text that the user posts. As an important step in public-opinion mining, stance detection has great potential for wide application and provides necessary data for decision-making by governments and enterprises. On social media, people exchange ideas by replies, in which the texts of replies are closely related to the context. Existing works in this regard focus mainly on the method of aggregating the context, but overlook the fact that the theme of texts alters with the progress of the response. Therefore, we propose a stance detection model that can effectively learn the thematic information, where contrastive learning is used to enhance the learning effect of thematic information. Experiments were performed on CreateDebate and Kialo datasets, and our proposed model achieved an accuracy of 68.0% and 69.6% on the two datasets, respectively. Experiments have proved that our method can improve the performance of stance detection. © 2023 SPIE.",TextMining
"Purpose: While there has been extensive research on understanding the effects of online reviews on product sales, there is not enough investigation of the inter-relationships between online reviews, online search and product sales. The study attempts to address this gap in the context of the Indian car market. Design/methodology/approach: The research uses text mining and considers six important review features volume, valence, length, deviation of valence, sentiment and readability within the heuristic and systematic model of information processing. Panel data regression is used along with mediation analysis to study the inter-relationships between features of reviews, online search and sales. Findings: The study finds that numerical heuristic features significantly affect sales and online search, numerical systematic feature affects sales and the textual heuristic and systematic features do not affect sales or online search in the Indian car market. Further, online search mediates the association between features of reviews and sales of cars. Research limitations/implications: Although only car sales data from India is considered in this research, similar relationships between review features, online search and sales could exist for the car market of other countries as well. Originality/value: This research uncovers the unique role of online search as a mediator between review features and sales, whereas prior literature has considered review features and online search as independent variables that affect sales. © 2023, Emerald Publishing Limited.",TextMining
"The prevention and treatment of addiction (moderate to severe substance use disorder—SUD) have remained challenging because of the dynamic and complex interactions between multiple biological and social determinants that shape SUD. The pharmacological landscape is ever changing and the use of multiple drugs is increasingly common, requiring an unraveling of pharmacological interactions to understand the effects. There are different stages in the trajectory from drug use to addiction that are characterized by distinct cognitive and emotional features. These are directed by different neurobiological processes that require identification and characterization including those that underlie the high co-morbidity with other disorders. Finally, there is substantial individual variability in the susceptibility to develop SUD because there are multiple determinants, including genetics, sex, developmental trajectories and times of drug exposures, and psychosocial and environmental factors including commercial determinants that influence drug availability. Elucidating how these factors interact to determine risk is essential for identifying the biobehavioral basis of addiction and developing prevention and treatment strategies. Basic research is tasked with addressing each of these challenges. The recent proliferation of technological advances that allow for genetic manipulation, visualization of molecular reactions and cellular activity in vivo, multiscale whole brain mapping across the life span, and the mining of massive data sets including multimodality human brain imaging are accelerating our ability to understand how the brain functions and how drugs influence it. Here, we highlight how the application of these tools to the study of addiction promises to illuminate its neurobiological basis and guide strategies for prevention and treatment. © 2023, This is a U.S. Government work and not under copyright protection in the US; foreign copyright protection may apply.",TextMining
"This study examines the causal effects of the key characteristics of Monetary Policy Statement (MPS) on the decision made for the overnight policy rate (OPR). It constructs the monetary data on hawkish and dovish sentiment from 106 MPS released by Bank Negara Malaysia (BNM) between May 2004 and November 2020, by using text mining method. Data were mined by identifying selected 12 hawkish and dovish words as well as the characteristics of MPS. The findings showed that MPS content can be used to predict OPR decision. The study further found that while hawkishness is associated with a decision of increased OPR, dovishness is conversely related with a decision of decreased OPR. Accordingly, the study established that the day of the week when a particular MPS is released, together with Zeti’s leadership in May 2000 - April 2016 period, are factors associated with decisions to increase OPR. However, the number of days between two MPS statements are released is shown to be associated with OPR decrease. This study therefore suggests that MPS release appear predictive of BNM’s monetary conduct. © 2023 Penerbit Universiti Kebangsaan Malaysia. All rights reserved.",TextMining
"As an important part of smart grid development strategy, on-line monitoring system of transmission lines has the important characteristics of informationization, networking and automation. With the continuous expansion of power grid scale, there are more and more inspection and maintenance work of transmission lines under complex terrain conditions. Through highly sharing multi-source heterogeneous monitoring information and data mining, intelligent management of transmission line operation and maintenance, safety early warning of transmission lines and their surrounding environment and health status evaluation of transmission lines are realized. In this paper, the construction strategy of transmission line condition monitoring and analysis system based on improved particle swarm optimization (PSO) algorithm is proposed. Through the actual measurement of transmission line parameters, more accurate and detailed parameters can be used in power system analysis and research, thus further improving the calculation accuracy of power system analysis and ensuring the safe and stable operation of power grid. © 2023 IEEE.",TextMining
"Soil moisture (SM) serves as a vital indicator reflecting environmental water conditions, but significant uncertainties still persist regarding how human activity and climate change affect SM. In this study, we quantified the influences of human activity and climate change on growing-season SM in the Qinghai–Tibet grasslands from 2000 to 2020. Climate change led to a decline in spatially mean SM at a rate of −0.01 and −0.06 g g−1 year−1 at 0–10 and 10–20 cm, respectively. Nonetheless, climate change caused the soil to become wetter in 39.97% and 22.29% areas at 0–10 and 10–20 cm, respectively. Human activity resulted in a decline in spatially mean SM by 36% and 21% at 0–10 and 10–20 cm, respectively. Nonetheless, human activity caused soil to become wetter in 2.82% areas at 0–10 cm and 30.03% areas at 10–20 cm. Therefore, both climate change and human activity have contributed to a pattern where the whole Qinghai–Tibet grasslands became drier while specific parts became wetter during the last 20 years. In addition to temperature and precipitation change, we should also pay attention to the response of SM to radiation change. Copyright © 2023 Xiao, Yu and Fu.",TextMining
"With the continuous growth of scie & tech, network technology has been widely used, which has brought great convenience to people's life and work. However, the rapid improvement of network technology has also given network viruses an opportunity, which has caused harm to the information security of computer users. In order to improve the adaptability to the network environment, it is more effective to use data mining (DM) to prevent and control viruses. Through the use of this technology, the control effect of network security management can be improved, and the effective support for the later network security development can be realized. This article will discuss the related modes of DM, study the practical application of DM to computer network virus defense, and build a computer network information security assessment model based on DM. The simulation results show that the proposed model can achieve a recall rate of 94.8% and an accuracy rate of 95.5%, both of which are better than the random forest model. DM has been effectively applied in the stage of protecting computer network virus, which greatly improves the security of computer network system, and then ensures the stability of computer system operation. © 2023 IEEE.",TextMining
"Background: While there is recognition of the relationship between loneliness and depression, specific behavioural patterns distinguishing both are still not well understood. Objectives: Our objective is to identify distinct behavioural patterns of loneliness and depression from a passively collected dataset of college students, understand their similarities and interrelationships and assess their effectiveness in identifying loneliness and depression. Methods: Utilizing the StudentLife dataset, we applied regression analysis to determine associations with self-reported loneliness and depression. Mediation analysis interprets the relationship between the two conditions, and machine learning models predict loneliness and depression based on behavioural indicators. Results: Distinct behavioural patterns emerged: high evening screen time (OR = 1.45, p = 0.002) and high overall phone usage (OR = 1.50, p = 0.003) were associated with more loneliness, whereas depression was significantly associated with fewer screen unlocks (OR = 0.75, p = 0.044) and visits to fewer unique places (OR = 0.85, p = 0.023). Longer durations of physical activity (OR = 0.72, p = 0.014) and sleep (OR = 0.46, p = 0.002) are linked to a lower risk of both loneliness and depression. Mediation analysis revealed that loneliness significantly increases the likelihood of depression by 48%. The prediction accuracy of our XGBoost-based machine learning approach was 82.43% for loneliness and 79.43% for depression. Conclusion: Our findings show that high evening screen time and overall phone usage are significantly associated with increased loneliness, while fewer screen unlocks and visits to fewer unique places are significantly related to depression. The findings can help in developing targeted interventions to promote well-being and mental health in students. © The Author(s) 2023.",TextMining
"Machine learning models have received significant attention for their exceptional performance in classifying electroencephalography (EEG) data. They have proven to be highly effective in extracting intricate patterns and features from the raw signal data, thereby contributing to their success in EEG classification tasks. In this study, we explore the possibilities of utilizing contemporary machine learning algorithms in decoding brain activity signals for a quick and efficient feature extraction in a potential BCI application. Specifically, the EEG data is associated with movement imagination as well as the state of relaxation. A total of 4 models based on neural networks, with distinct structures, were implemented and evaluated on a proprietary subject-specific dataset: EEGNet, EEG Inception, Spatial-Temporal Tiny Transformer (S3T), DeepConvNet. The experiments resulted in promising prediction accuracy. However, the performance of classifiers was not evaluated for new subjects or different hardware. © 2023 IEEE.",TextMining
"This article presents an analysis of the ways of ecological modernization of technological units, apparatuses and machines of the mining and processing industry, as well as other various industries. In particular, the main sources of pollution of the air basin of settlements, the mechanism of dust formation and the flow of dispersed aerosol, the classification of various kinds of dust-collecting devices, the problems of creating low-waste technologies and waste-free technological complexes are considered. Comparative parameters of classification of types of industrial environmental pollution by machines and apparatuses of various industries and industries are presented and analyzed. Comparative data on emissions of harmful substances into the atmospheric air from stationary sources in a number of cities of the Commonwealth of Independent States (CIS) countries are presented. According to the results of the analysis, it was found that at the moment there is no single international methodology for environmental modernization (improvement) of a technological unit (apparatus, machine or in combination), in the development of which at the present stage there is an urgent need to protect the environment from the functioning of industrial sectors and industries. © 2023 Publishing house Mining book. All rights reserved.",TextMining
"By now at least ten different criteria have been proposed to assess the rockburst hazard. Some of them are used only in certain countries and some only for certain deposits. This raises the problem of selecting a universal rockburst hazard criterion that can be used when standard test equipment is available at different deposits. To solve this problem, the rockburst hazard assessment of rocks from the deposits in Russia and Kazakhstan has been performed according to the Kaiser criterion, the Stavrogin criterion, the criterion of the Mining Institute of the KSC RAS and the energy criterion. Based on the data obtained, the results of the rockburst hazard assessment were analyzed and compared according to the criteria considered. The limits of their applicability and the correlation between the results obtained are established. The main advantages and disadvantages of the criteria are highlighted. A universal approach to assessing the rockburst hazard has been proposed, consisting in the combined use of several criteria. © 2023, Scientific and Industrial company 'Gemos Ltd.'. All rights reserved.",TextMining
"The article addresses the issue of gas-dynamic phenomena that take place during mining operations in the host rocks of the 'International' kimberlite pipe. The reasons causing gas-dynamic phenomena are reviewed, an analysis of geological and technological features is provided, an assessment of the geomechanical conditions of occurrence of the gas-dynamic phenomena is carried out. Basic methods of forecasting (based on the initial maximum gas seepage rate) and prevention (advanced shot-firing) of gasdynamic phenomena are currently used in conditions of the deposit. Application of these methods has made a significant contribution to the efforts of the mine personnel to control the gas-dynamic phenomena, and it also helped to gain an insight into the processes in progress. However, rock and gas outbursts continue to occur in the field under various conditions, including the conditions of the peripheral shot-firing, which makes finding further solutions a topical issue. The data presented in the article are a prerequisite for the theoretical development for modeling of gas-dynamic processes that take place during mining operations in the host rocks of a diamond kimberlite pipe. © 2023, Scientific and Industrial company 'Gemos Ltd.'. All rights reserved.",TextMining
"The current study investigated the perceived impact of informal coal mining on the environment of a rural community in Blaauwbosch, KwaZulu-Natal Province, in South Africa. Data was extracted through questionnaires, focus group discussions and key informant interviews targeting perceptions from community members, government officials, informal coal miners, learners and educators of a local school on the environmental impacts of informal coal mining. After stratifying the participants, community members aware of the environmental impacts of coal mining cited poor air quality as the most critical impact of coal mining, while educators and learners mentioned landscape transformation. Community members were generally not satisfied with government's interventions towards containing the impact of coal mining, while educators and learners were somewhat satisfied as they felt government response was slow and laboured. Therefore, in addition to awareness campaigns within the community to improve information access regarding the disadvantages of informal coal mining, the government should intensify its efforts by implementing effective follow-ups on proposed responses. The government should also design interventions to address the area's high poverty and unemployment levels to reduce community engagement in informal coal mining activities. © 2023 Informa UK Limited, trading as Taylor & Francis Group.",TextMining
"The main function of intrusion detection technology is to discover the endless attack attempts, attacks and attack results, and to ensure the confidentiality, integrity and availability of system resources through technical means, and finally form a dynamic and effective protection strategy. The application of data mining (DM) makes the computer fault detection more efficient, which can detect the computer faults well and ensure the correct operation and use of the computer. Feature selection can well eliminate redundancy and noise features, which is beneficial to improve the detection speed and effect of Intrusion Detection System (IDS). This article presents a computer network intrusion detection model based on feature selection algorithm, and then realizes remote computer fault detection. The simulation results show that IDS constructed by the feature selection algorithm proposed in this article has better performance than IDS without feature selection in detection time, detection accuracy of known attacks and detection accuracy of unknown attacks. © 2023 IEEE.",TextMining
"Raster images contain regions such as plot segments, log headers, depth track etc. which provide valuable information about well logs. The automatic extraction of these regions from raster documents is necessary for well log digitization which can further open-up numerous possibilities of processing the well log data such as well log prediction and correlation. As the first step towards raster digitization, in this work, we address the raster segmentation task to automatically extract important raster regions such as plot segment, depth track, and log headers. Next, we propose to identify the number of well logs recorded in the raster. Further, we aim to extract depth information using Optical Character Recognition (OCR) in the extracted depth track region given by the raster segmentation. Specifically, we propose a novel two stage Deep Learning (DL)-based approach using conditional Generative Adversarial Network (c-GAN) for raster image segmentation where for each raster image we detect plot segments, log headers, and depth track regions. The raster image segmentation is carried out using a DL-based image-to-image translation strategy. In the image-to-image translation, input raster image is processed to get an output segmentation mask. In the next step of raster digitization, we identify different well logs by processing the log header region extracted in the raster segmentation step. We propose a faster RCNN-based model to delineate each log header instance from the log header section of a raster image. In the third step, for depth values extraction, we use the depth track region extracted by the above raster segmentation model. We use OCR to extract the depth values in the depth track image. Output from the OCR can be noisy due to inferior quality raster images. The OCR output is denoised to obtain accurate depth values at each point in the depth track region. We evaluate the proposed raster segmentation and well log instance detection model on a test dataset of variety of raster images with varying quality. We achieve an excellent mean intersection over union (mIoU) of 85.6% in the case of raster segmentation. The above results are due to the novel approach of raster segmentation using c-GAN, and data augmentation strategy used to create large data using limited training data of raster images. Similarly, we achieve mIoU of 91.82% in the log header instance detection task. Furthermore, denoising module for depth values extraction delivers robust performance in automatic extraction of depth values. We measure the performance of the depth track extraction module in terms of ability to correctly identify the extreme values (start and end) in the depth track. Our method attains an outstanding 90.5% accuracy addressing OCR failure modes (due to noisy raster images). © 2023, Society of Petroleum Engineers.",TextMining
"From the perspective of big data, making full use of data information in news reports is like adding an innovative news value to general topics. When mining exclusive news, the participation of big data makes the competition among peers shine. In daily work, traditional journalists have many difficulties in searching for news clues and finding news topics, but the large-scale open-source data has given media staff a new dawn, which can be described as a new way. This paper studies the design of news data analysis (NDA) system based on UML. This paper briefly discusses the necessity of NDA and UML model, and analyzes the design of NDA system and system function design based on UML computer-aided technology; The algorithm of news event data analysis is proposed. Through the test of the accuracy and coverage of NDA in different fields, the effectiveness and feasibility of the NDA system based on UML computer-aided technology proposed in this paper are verified. © 2023 IEEE.",TextMining
"In a randomized trial that collects text as an outcome, traditional approaches for assessing treatment impact require that each document first be manually coded for constructs of interest by human raters. An impact analysis can then be conducted to compare treatment and control groups, using the hand-coded scores as a measured outcome. This process is both time and labor-intensive, which creates a persistent barrier for large-scale assessments of text. Furthermore, enriching one’s understanding of a found impact on text outcomes via secondary analyses can be difficult without additional scoring efforts. The purpose of this article is to provide a pipeline for using machine-based text analytic and data mining tools to augment traditional text-based impact analysis by analyzing impacts across an array of automatically generated text features. In this way, we can explore what an overall impact signifies in terms of how the text has evolved due to treatment. Through a case study based on a recent field trial in education, we show that machine learning can indeed enrich experimental evaluations of text by providing a more comprehensive and fine-grained picture of the mechanisms that lead to stronger argumentative writing in a first- and second-grade content literacy intervention. Relying exclusively on human scoring, by contrast, is a lost opportunity. Overall, the workflow and analytical strategy we describe can serve as a template for researchers interested in performing their own experimental evaluations of text. © 2023 AERA.",TextMining
"Introduction: In 2016 diplomatic personnel serving in Havana, Cuba, began reporting audible sensory phenomena paired with onset of complex and persistent neurological symptoms consistent with brain injury. The etiology of these Anomalous Health Incidents (AHI) and subsequent symptoms remains unknown. This report investigates putative exposure-symptom pathology by assembling a network model of published bio-behavioral pathways and assessing how dysregulation of such pathways might explain loss of function in these subjects using data available in the published literature. Given similarities in presentation with mild traumatic brain injury (mTBI), we used the latter as a clinically relevant means of evaluating if the neuropsychological profiles observed in Havana Syndrome Havana Syndrome might be explained at least in part by a dysregulation of neurotransmission, neuro-inflammation, or both. Method: Automated text-mining of >9,000 publications produced a network consisting of 273 documented regulatory interactions linking 29 neuro-chemical markers with 9 neuropsychological constructs from the Brief Mood Survey, PTSD Checklist, and the Frontal Systems Behavior Scale. Analysis of information flow through this network produced a set of regulatory rules reconciling to within a 6% departure known mechanistic pathways with neuropsychological profiles in N = 6 subjects. Results: Predicted expression of neuro-chemical markers that jointly satisfy documented pathways and observed symptom profiles display characteristically elevated IL-1B, IL-10, NGF, and norepinephrine levels in the context of depressed BDNF, GDNF, IGF1, and glutamate expression (FDR < 5%). Elevations in CRH and IL-6 were also predicted unanimously across all subjects. Furthermore, simulations of neurological regulatory dynamics reveal subjects do not appear to be “locked in” persistent illness but rather appear to be engaged in a slow recovery trajectory. Discussion: This computational analysis of measured neuropsychological symptoms in Havana-based diplomats proposes that these AHI symptoms may be supported in part by disruption of known neuroimmune and neurotransmission regulatory mechanisms also associated with mTBI. Copyright © 2023 Chacko, Toole, Morris, Page, Forsten, Barrett, Reinhard, Brewster, Costanzo and Broderick.",TextMining
"Event extraction stands as a significant endeavor within the realm of information extraction, aspiring to automatically extract structured event information from vast volumes of unstructured text. Extracting event elements from multi-modal data remains a challenging task due to the presence of a large number of images and overlapping event elements in the data. Although researchers have proposed various methods to accomplish this task, most existing event extraction models cannot address these challenges because they are only applicable to text scenarios. To solve the above issues, this paper proposes a multi-modal event extraction method based on knowledge fusion. Specifically, for event-type recognition, we use a meticulous pipeline approach that integrates multiple pre-trained models. This approach enables a more comprehensive capture of the multidimensional event semantic features present in military texts, thereby enhancing the interconnectedness of information between trigger words and events. For event element extraction, we propose a method for constructing a priori templates that combine event types with corresponding trigger words. This approach facilitates the acquisition of fine-grained input samples containing event trigger words, thus enabling the model to understand the semantic relationships between elements in greater depth. Furthermore, a fusion method for spatial mapping of textual event elements and image elements is proposed to reduce the category number overload and effectively achieve multi-modal knowledge fusion. The experimental results based on the CCKS 2022 dataset show that our method has achieved competitive results, with a comprehensive evaluation value F1-score of 53.4% for the model. These results validate the effectiveness of our method in extracting event elements from multi-modal data. © 2023 Tech Science Press. All rights reserved.",TextMining
"Purpose: Influenced by the constantly changing manufacturing environment, no single dispatching rule (SDR) can consistently obtain better scheduling results than other rules for the dynamic job-shop scheduling problem (DJSP). Although the dynamic SDR selection classifier (DSSC) mined by traditional data-mining-based scheduling method has shown some improvement in comparison to an SDR, the enhancement is not significant since the rule selected by DSSC is still an SDR. Design/methodology/approach: This paper presents a novel data-mining-based scheduling method for the DJSP with machine failure aiming at minimizing the makespan. Firstly, a scheduling priority relation model (SPRM) is constructed to determine the appropriate priority relation between two operations based on the production system state and the difference between their priority values calculated using multiple SDRs. Subsequently, a training sample acquisition mechanism based on the optimal scheduling schemes is proposed to acquire training samples for the SPRM. Furthermore, feature selection and machine learning are conducted using the genetic algorithm and extreme learning machine to mine the SPRM. Findings: Results from numerical experiments demonstrate that the SPRM, mined by the proposed method, not only achieves better scheduling results in most manufacturing environments but also maintains a higher level of stability in diverse manufacturing environments than an SDR and the DSSC. Originality/value: This paper constructs a SPRM and mines it based on data mining technologies to obtain better results than an SDR and the DSSC in various manufacturing environments. © 2023, Emerald Publishing Limited.",TextMining
"The article first introduces the principle of the C4.5 algorithm in detail and introduces it to the construction cost industry. Based on the C4.5 algorithm, it models and analyzes the bill of quantities cost of a case construction project, extracts the classification rules, and then randomly selects cases to verify the universal applicability of the classification rules. The results show that the classification rule is universally applicable, which can help practitioners of engineering cost to make rapid predictions and improve the efficiency of decision-making analysis. © 2023 IEEE.",TextMining
"CRoss Industry Standard Process for Data Mining (CRISP-DM) is a data mining project development methodology that establishes tasks and levels of abstraction, hierarchically structured to facilitate its implementation through a set of actions that help in making decisions. Essence is a theory that helps identify best practices and essential, common, and universal elements to all endeavor in the software development cycle. In the literature, there are different models of representation of the CRISP-DM methodology, such as verbal model, conceptual model, process understanding model, and ontology. However, it considered that these representation models lack the incorporation of some elements, such as, activities, work products, and roles of the CRISP-DM methodology. In this paper we propose a representation based on Essence of the CRISP-DM methodology, incorporating the essential elements that we believe are missing from existing representations. With the representation in Essence that is proposed, the aim is to improve the understanding of best practices and the essential, common, and universal elements of the CRISP-DM methodology for future implementations in data mining projects. In addition, it seeks to validate that Essence can be used in different of data mining projects. © 2023 Instituto Politecnico Nacional. All rights reserved.",TextMining
"Few-shot 3D point cloud segmentation segments novel categories in point cloud scenes with only limited annotations. However, most current methods do not consider query content when exploring support prototypes, and thus suffer from intra-class variations between objects and incomplete representation of category information from annotated support samples. In this paper, we propose a novel Query-Guided support Prototype exploration Network (QGPNet) to tackle this challenge. Firstly, we present a point feature alignment module, which leverages geometry relationship between prototypes and query points, to tackle data misalignment caused by intra-class variations, and thus prevents incorrect label propagation from prototypes to query points. Secondly, we design a prototype feature mining strategy, which progressively harvests diverse support prototypes in the interaction with query features, to fully utilize the category information provided by annotated samples. Additionally, we introduce a semantic-aware data augmentation strategy for query samples in the training process, potentially improving the generalization ability of support prototypes on query samples. Extensive experiments on two indoor 3D datasets S3DIS and ScanNet demonstrate that QGPNet outperforms previous state-of-the-art methods by a large margin. IEEE",TextMining
"A business intelligence (BI) system was designed to create a proactive, reactive, and precursor decision tool to improve safety of bus operations at the Massachusetts Bay Transportation Authority (MBTA). The system’s development was motivated in part by recommendations of a safety inspection by the Federal Transportation Administration, and the realization that the MBTA has access to vest amounts of data that are not being used to create information effectively. The developers reduced the complexity of the BI system by incorporating analytics to determine the areas of focus where safety has the most impact. Challenges were posed by the need to integrate internal and external databases with various formats and structures, and the desire to create a self-service BI solution for multiple MBTA users. The resulting BI solution includes applications that support key performance indicator analyses, root cause investigations, and targeted improvement actions. These applications represent an enhanced approach that combines data for a more holistic analysis and eliminates the need to transfer datasets or data analyses by email. The system includes various forms of visualizations to help users navigate the myriad of information, including geospatial maps, interactive pie, line, and bar charts, and word frequency and relationship mapping. The paper details the system’s development and how analytical approaches were used to expose important information that is hidden in the data. Examples of applications are shown using screenshots and a general workflow is presented that could be applicable to agencies with fewer resources. © National Academy of Sciences: Transportation Research Board 2023.",TextMining
"The operation status of the power distribution network is mainly reflected by the line loss and line loss ratio, which are reduced to facilitate the efficient use of electrical energy. The user electricity theft behaviors are harmful and are considered to be important aspects affecting the line loss rate. The identification of electricity stealing users is conducive to reducing the losses of power companies. In this paper, the user electricity consumption behavior evaluation index system is constructed by combining the causes of the user’s electricity consumption, line loss, and abnormal. The index system can dynamically reflect the power consumption behavior of users and help the fine management of power system. An anti-theft system based on Levenberg Marquardt (LM) neural network model is proposed to identify the user stealing electricity behavior. The 4-month electricity consumption data of 138 users of State Grid Shanghai Electric Power Company is taken as a research object. The classical decision tree model Classification and Regression Tree (CART) is compared, and the results showed that the accuracy of LM neural network model is as high as 97.2%, and it has more advantages in terms of training speed and computational accuracy. This study is beneficial for power enterprises to accurately and quickly find suspected users of electricity theft, so as to reduce the loss of power energy and the economic loss of electric power enterprises, and promote the further improvement and development of the electric power system. © 2023 SPIE.",TextMining
"Consensus algorithm is widely used in blockchain system, which can solve the problems of fault tolerance, consensus and security. Proof-of-work (PoW) algorithm is one of the most widely used consensus algorithms to ensure the security and consensus on transaction data of the Bitcoin system. However, as an important part of the Bitcoin system, mining pool is often subjected to distributed denial of service (DDoS) attack by malicious nodes at the network layer, which makes it suffer significant economic losses. In order to reduce the loss of mining pools caused by DDoS attack when the Bitcoin system carries out data consensus of PoW, this paper proposes an evolutionary game model based on mining pools. This model studies how to choose effective mining strategy to get the best profit in the face of DDoS attack. At the same time, we also set up the replication dynamic equation to analyze and solve the game model. The experimental results show that honest mining has the best profit under the condition of poor network for the mining pools. In the case of better network condition, the mining pools can get the best reward by attacking each other. At the same time, the experimental results are consistent with the theoretical conclusions, which proves that our model is effective.  © 2023 IEEE.",TextMining
"The project T2Know presents the use of natural language processing technologies for the creation of a semantic platform of scientific documents via knowledge graphs. This knowledge graph will link relevant parts of each document with those of other documents in such a way that trend analysis and recommendations can be achieved. The goals addressed within the scope of this project include entity recognizers development, profile definition and documents linkage through the use of transformers technologies. As a result, the relevant parts of the documents to be extracted are related not only to the title and affiliation of the authors, but also to article topics such as references, which are also considered relevant parts of the scientific article.  © 2023 Copyright for this paper by its authors.",TextMining
[This retracts the article DOI: 10.1155/2021/5187837.]. Copyright © 2023 Journal of Healthcare Engineering.,TextMining
"Multi-view clustering is a long-standing important task, however, it remains challenging to exploit valuable information from the complex multi-view data located in diverse high-dimensional spaces. The core issue is the effective collaboration of multiple views to holistically uncover the essential correlations between multi-view data through graph learning. Furthermore, it is indispensable for most existing methods to introduce an additional clustering step to produce the final clusters, which evidently reduces the uniform relationship between graph learning and clustering. Based on the above considerations, in this paper, we present a novel method named multi-view clustering via graph collaboration (MCGC). Based on the low-dimensional representation space developed by MCGC, it first perceives the correlations between samples in each individual view under the supervision of the Hilbert-Schmidt independence criterion (HSIC). Then, MCGC proposes learning a consensus graph by adaptively collaborating between all the views, which is able to uncover the essential structure of the multi-view data. Meanwhile, by imposing the rank constraint on the Laplacian matrix of the consensus graph to partition the multi-view data naturally into the required number of clusters, the optimal clustering results can be obtained directly without any postprocessing steps. Finally, the resulting optimization problem is solved by an alternating optimization scheme with guaranteed fast convergence. Extensive experiments on 5 benchmark multi-view datasets demonstrate that MCGC markedly outperforms the state-of-the-art baselines.  © 2022 IEEE.",TextMining
"News is widely forwarded and commented on the Internet, and constantly updated, which hides unfavorable remarks, which have an important impact on the security of cyberspace and the stability of the real society. In this paper, a network news information dissemination model based on data mining algorithm is established, and a parallel adaptive topic tracking algorithm based on N-Gram is designed by combining the advantages of NB(naive Bayesian) classification algorithm and both, which can improve the topic tracking accuracy and improve the topic drift phenomenon. Calculate the attribute credibility of news reports belonging to each news topic, select the news reports with greater than the minimum attribute credibility to update the training set, and update the topic model to complete the news topic tracking. Simulation results show that the important users identified by this model are more active than those obtained by other methods. As the number of nodes increases, the speedup ratio of the algorithm also increases, which proves that the algorithm in this paper has strong scalability. © 2023 IEEE.",TextMining
"Telecom fraud has become a pressing issue, with most research targeting effective countermeasures. However, extracting valuable rules from fraud data to improve case handling efficiency remains under-explored. The Apriori algorithm, commonly used for association rule mining, faces challenges due to its low efficiency and scalability arising from numerous frequent and candidate item sets. To address this problem, we propose a fast Apriori algorithm. The main idea is as follows: First, we establish a similarity measurement model based on information entropy, and combine similar items to significantly reduce the number of frequent item sets and candidate item sets. Second, we optimize the process of generating frequent item sets and candidate item sets and reduce the number of database scans. Third, we apply the improved algorithm to mine the data set of telecom fraud cases in a city, and obtain some meaningful association rules that reflect the relationships among the duration of the crime, the reporting time, and the amount of fraud. These rules provide a new perspective and idea for investigating telecom fraud cases. © 2023 SPIE.",TextMining
The proceedings contain 114 papers. The topics discussed include: application of machine learning and artificial intelligence in credit risk assessment; application of artificial intelligence in computer network technology; research on tackle recognition of football players based on deep reinforcement learning; design of adaptive learning quantitative training algorithm based on deep neural network algorithm; smart library construction and service mode driven by big data; application of big data fusion model in the architecture design of smart departure service platform; construction of intelligent transportation information management system based on artificial intelligence technology; optimal design of UUV autonomous navigation and positioning algorithm based on TDOA positioning model; and simulation of computer network information security assessment model based on data mining.,TextMining
"To avoid economic losses on loan borrowers who are in default, financial institutions and companies employ plenty of debt collection measures like making phone calls, sending messages and even resorting to legal action. Since these measures also incur non-negligible costs and differ significantly in expenses, debt collection scoring models are proposed to assess the likelihood of a client’s payment delinquency thus helping companies in determining appropriate collection measures and improving effectiveness on allocating resources. Traditional methods in this area utilize clients’ personal information and are highly dependent on the accuracy of data which in practice can’t be guaranteed. In this work, we formulate collection scoring as a trajectory classification method and build a discriminative network that mines clients’ personal car trajectories which is an informative and stably accessible data resource in the car loan business scenario. We first propose a novel preprocessing method to extract features and transform raw trajectories into sequences of fixed-shape tensors. Then a convolutional auto-encoder is employed to condense extracted tensors into a low-dimensional representation. Finally, a Bi-LSTM is adopted to capture latent characteristics in the feature sequences and makes a prediction. Experiments on a real-world collected dataset confirm the effectiveness of our model. © 2023 SPIE.",TextMining
"Such geodynamic phenomena as rock bursts and strong man-made earthquakes with a hypocenter depth much greater than the depth of mining operations; the occurrence of seismic activations at large distances from the influence area to the Earth interior; localization of epicenters of strong seismic events at the periphery of the foreshock and aftershock zone, the existence and functioning of the block structure of the earth's crust and its degassing along reactivated faults; “slow slip” earthquake; the existence of a power frame in the earth's crust and its response to geodynamic processes in the depths require further research. The main purpose of the publication is to summarize the factual data on the manifestation of the listed geodynamic phenomena in industrial areas from the viewpoint of the hypothesis that within the earth crust there exists a layer of the critical stress state with the thickness from the earth's surface to a certain depth in order to further reveal the nature of the interaction of global geodynamic and local geomechanical processes in the mining areas. Geodynamic effects associated with the critical stress state of the earth's interior are considered using the examples of strong earthquakes in industrial areas (Bachat (2013, M = 6.1), Neftegorsk (1995, M = 7–7.2), Wenchuan (2008, M = 7,8)) the man-made nature of which is assumed and discussed. Also seismic activations in the areas of mining operations and the area of geothermal projects, block structures of the earth's crust of the Kemerovo and Moscow regions are considered. © 2023, Scientific and Industrial company 'Gemos Ltd.'. All rights reserved.",TextMining
"Objective: To investigate adverse events (AEs) associated with denosumab (Dmab) and zoledronic acid (ZA), compare their association strengths, and explore potential applications to provide clinical reference. Methods: We collected data from FAERS from January 2004 to November 2022 and mined AE signals for Dmab and ZA using ROR values. We compared signal intensity for same AEs and investigated off-label use. We also examined their AEs in adjuvant therapy for breast and prostate cancer. Results: 154,735 reports of primary suspect drugs were analyzed in the FAERS database (Dmab: 117,857; ZA: 36,878). Dmab and ZA had 333 and 1,379 AE signals, with 189 overlaps. The AEs of Dmab included death (ROR:3.478), osteonecrosis of jaw (ROR:53.025), back pain (ROR:2.432), tooth disorder (ROR:16.18), bone pain (ROR:6.523). For ZA, the AEs included osteonecrosis (ROR:104.866), death (ROR: 3.645), pain (ROR:3.963), osteonecrosis of jaw (ROR: 91.744), tooth extraction (ROR: 142.143). Among overlap signals, Dmab showed higher strength in exostosis of the jaw (ROR: 182.66 vs. 5.769), atypical fractures (ROR: 55.589 vs. 9.123), and atypical femur fractures (ROR:49.824 vs. 4.968). And ZA exhibited stronger associations in abscess jaw (ROR: 84.119 vs. 11.12), gingival ulceration (ROR: 74.125 vs. 4.827), increased bone formation (ROR: 69.344 vs. 3.218). Additionally, we identified 528 off-label uses for Dmab and 206 for ZA, with Dmab mainly used in prostate cancer (1.04%), breast cancer (1.03%), and arthritis (0.42%), while ZA in breast cancer (3.21%), prostate cancer (2.48%), and neoplasm malignant (0.52%). For Dmab in breast cancer treatment, AEs included death (11.6%), disease progression (3.3%), and neutropenia (2.7%), while for ZA included death (19.8%), emotional disorder (12.9%), osteomyelitis (11.7%). For prostate cancer treatment, Dmab`s AEs were death (8.9%), prostate cancer metastatic (1.6%), renal impairment (1.7%), while ZA`s included death (34.4%), general physical health deterioration (19.9%), and hemoglobin decreased (18.9%). Conclusion: Our analysis of FAERS database provided postmarketing surveillance data and revealed different strengths of reported AE signals between Dmab and ZA in some of their common AEs. It’s also worth noting that both drugs have potential off-label applications, which could introduce new AEs. This highlights the necessity for safety monitoring when using Dmab and ZA off-label. Copyright © 2023 Su, Wu, Zhou, Peng, Zhao, Wang and Li.",TextMining
"The implementation of the sustainable development strategy and the formation of a “green” economy model provide for the reorientation of financial resources, accounting by economic entities and public authorities and management of ESG-principles and the development of “green” financing tools. The purpose of the paper is to develop theoretical provisions and modeling of the impact of “green” financing on the socio-economic development of the subjects of the Russian Federation. Methods of data mining were used with temporary delays and corresponding lags responses of endogenous indicators, as well as cluster and correlation analysis. The result of the study was the specification of the economic content of the definition of “green” financing, as well as the construction of econometric models of the degree of interrelationship between “green” financing and the socio-economic development of the regions of Russia. The authors described the economic content of the definition of “green” financing, developed econometric models of the degree of interdependence of “green” financing and socioeconomic growth of Russia’s regions, calculated an integral indicator of sustainable socio-economic development of the regions of the Russian Federation taking into account ESG-factors (social risks, environmental risks, quality of management). Clustering of Russian regions according to the level of influence of “green” financing on their socio-economic development has also been carried out. The article concludes that the relationship between the level of socio-economic development of the regions of the Russian Federation and the volume of “green” financing is direct, strong, and can be expressed by increasing linear regression. The prospects for further research may be related to the assessment of the real needs of the volumes of “green” financing in the context of ensuring sustainable economic growth. © Semenova N.N., Ivanova I.А., Eremina О.I., 2023.",TextMining
"Aiming at the problems of short duration, low intensity, and difficult detection of micro-expressions (MEs), the global and local features of ME video frames are extracted by combining spatial feature extraction and temporal feature extraction. Based on traditional convolution neural network (CNN) and long short-term memory (LSTM), a recognition method combining global identification attention network (GIA), block identification attention network (BIA) and bi-directional long short-term memory (Bi-LSTM) is proposed. In the BIA, the ME video frame will be cropped, and the training will be carried out by cropping into 24 identification blocks (IBs), 10 IBs and uncropped IBs. To alleviate the overfitting problem in training, we first extract the basic features of the preprocessed sequence through the transfer learning layer, and then extract the global and local spatial features of the output data through the GIA layer and the BIA layer, respectively. In the BIA layer, the input data will be cropped into local feature vectors with attention weights to extract the local features of the ME frames; in the GIA layer, the global features of the ME frames will be extracted. Finally, after fusing the global and local feature vectors, the ME time-series information is extracted by Bi-LSTM. The experimental results show that using IBs can significantly improve the model’s ability to extract subtle facial features, and the model works best when 10 IBs are used. © 2023 Tech Science Press. All rights reserved.",TextMining
"Background & Study Aim: The recent outbreak of the COVID-19 virus, which has spread worldwide, started in December 2019, with confirmed cases continuing to occur in 2022. As of July 7, 2022, the cumulative number of COVID-19 cases was about 500 million, and the death toll was about 6.34 million. The World Health Organization declared COVID-19 a pandemic on March 11, 2020 and labelled it the highest level of infectious disease risk. The purpose of this study was knowledge both about likely changes facing athletes in Korea owing to the spread of COVID-19 and how they are coping with these – specifically taekwondo kyorugi athletes. Material & Methods: A qualitative approach was chosen – an open-ended questionnaire was designed comprising four demographic questions and two questions addressing the impact of COVID-19 and coping methods. Questionnaire data from 184 adult taekwondo athletes were collected. For the text analysis, the latent Dirichlet allocation topic modelling algorithm was applied, and the coherence score index was used to select the number of topics. All data processing was performed using Python 3. Results: From the coherence scores, three topics were identified under COVID-19 impacts and two under coping, as most suitable. The derived topics based on keyword distribution probabilities and the topic modelling analysis were as follows: first, the key impacts on the taekwondo athletes caused by COVID-19 were confirmed as anxiety due to training restrictions, self-care due to game postponement, and career instability due to game cancellation; second, the taekwondo athletes coped with COVID-19 by maintaining their performance through personal training and preparing for matches through personal quarantine Conclusions: In the event of a similar situation in the future, new ways need to be identified that allow for training as well as competition during a pandemic. Additionally, preliminary efforts should focus on how to minimize anxiety among athletes whose careers and livelihoods are tied to their sport. © 2023, the Authors.",TextMining
"SBAS-InSAR technology has been widely researched and applied in the large-scale monitoring of mining areas, but due to the influence of spatial and temporal discorrelation, atmospheric delay and noise on the deformation results, as well as the requirements on image quantity, quality and spatial continuity, the SBAS-InSAR technology inferior to the levelling monitoring results in terms of measurement accuracy and reliability. Taking the Yuncheng coal mine as the research area, and after using SBAS InSAR to monitor the subsidence, the levelling monitoring data was used as the constraint to construct the subsidence error surface by polynomial surface fitting, and then the SBAS-InSAR subsidence monitoring results were be corrected. The experimental results show that the settlement difference is better than ±50mm/a, which effectively improves the overall accuracy of SBAS-InSAR settlement monitoring. The experimental results verify the feasibility and effectiveness of using the level monitoring results to correct the deformation monitoring results of SBAS InSAR, and provide effective reference information for improving the accuracy of the deformation monitoring results by multi-source fusion processing.  © Published under licence by IOP Publishing Ltd.",TextMining
"The analysis of constitutional interpretation has received much attention in recent years. This article is a contribution to research using text mining methods to account for markers of constitutional reasoning in big data-sized text corpora. We examine how often the Hungarian Constitutional Court (the HCC) reflected on the various methods of interpretation. For this purpose, we have created a com-plex corpus covering all HCC decisions and orders between 1990 and 2021. We found evidence that the methodological practice of the HCC is not self-reflexive in general as only 44% of its decisions make a reference to at least one method of interpretation. We also show that the self-reflexive nature is even more prevalent (in fact, ubiquitous) in 100 doctrinally important decisions from the 30 years of jurisprudence in question. While this study is a first step towards the quantitative analysis of the reasoning of the constitutional judiciary, further mixed methods research is needed to account for intertemporal changes in such data and to refine the measurement of constitutional interpretation. © 2023, Wydawnictwo Uniwersytetu Marii Curie-Sklodowskiej w Lublinie. All rights reserved.",TextMining
"Background: The relationship between Protein Convertase Subtilisin Kexin Type 9 inhibitor (PCSK9i) and psychiatric adverse events (AEs) remains unclear due to the limitations of clinical trials. In this study, PCSK9i-related psychiatric AEs were realistically observed and systematically summarized in the real world by data mining the FDA AE Reporting System (FAERS). Method: Total AEs between the third quarter of 2015 and the first quarter of 2023 were obtained from FAERS. Psychiatric AEs were identified using disproportionality analysis and clinical prioritization of signals using a rating scale, followed by univariate logistic regression to explore factors influencing psychiatric AEs. Results: Psychiatric AEs accounted for 6.7% of the total number of PCSK9i reports. Eighteen psychiatric AEs were defined as PCSK9i-related psychiatric adverse events (ppAEs) (lower 95% CI of both ROR >1 and IC025 > 0). The median age of ppAE reports was 68 years, and female patients accounted for 22.67% of reports, including 41.40% of reports with a serious outcome. Eleven (61.11%) and seven (38.89%) ppAEs were classified as weak and moderate clinical priority, respectively. The median time to onset of ppAEs was 149 and 196 days after treatment with evolocumab and alirocumab, respectively. Patients weighing ≥80 kg were 1.59 times more likely to experience ppAEs. Conclusion: The results of this study facilitate the prioritization of psychiatric AE signals by healthcare professionals with the goal of mitigating the risk of PCSK9i-related psychiatric AEs. However, as an exploratory study, our findings need to be confirmed in large-scale prospective studies. © 2023 The Authors. CNS Neuroscience & Therapeutics published by John Wiley & Sons Ltd.",TextMining
"Geospatial Analysis Applied to Mineral Exploration: Remote Sensing, GIS, Geochemical, and Geophysical Applications to Mineral Resources presents state-of-the-art approaches on recent remote sensing and GIS-based mineral prospectivity modeling for Earth scientists, researchers, mineral exploration communities and mining companies. This book will help readers solve high complexity issues in remote sensing data processing, geochemical data analysis, geophysical data analysis, and appropriate applications of GIS techniques for data fusion designed for mineral exploration purposes. It contains updated knowledge of remote sensing imagery, geochemistry, geophysics and geospatial techniques that can assist in delineating the signatures and patterns linked to deep-seated, covered, blind or buried mineral deposits. © 2023 Elsevier Inc. All rights reserved.",TextMining
"In view of the problems in the field of non-coal mine, such as high pressure of perception data acquisition and transmission, cloud analysis and processing, insufficient ability of active safety risk analysis, and poor timeliness, this paper discusses the necessity of building a non-coal mine safety risk monitoring and early warning system using edge computing technology against the requirements of major disaster risk prevention and control construction in non-coal mine. It analyzes the technical requirements of edge computing for data security and data intelligent analysis of non-coal mine safety risks, propose the edge computing architecture of non-coal mine safety risk. Designed intelligent risk analysis equipment for non-coal mine safety risks, implementing functions such as data collection and aggregation, data association analysis, video intelligent analysis, and data security control. This research improved the level of intelligent warning on the edge of non-coal mine safety risks, with great significance in preventing and extricating major safety production accidents in non-coal mining enterprises. © 2023 SPIE.",TextMining
"In recent years, Graph Neural Networks (GNNs) have witnessed rapid development. Their strengths in capturing topological information of graph data contribute to significant performance improvements in tasks such as knowledge graph (KG) link prediction. To understand the reason for this performance improvement, it is necessary to extract the subgraph patterns learned by GNNs from KGs. Nevertheless, the accuracy of existing GNN interpreters has not been validated in explaining multi-relation graph data, such as KGs, and related tools have not been implemented yet, leading to difficulties in extracting explanation subgraphs. To address this problem, this paper proposes a KG link prediction model that converts multi-relation KGs into uni-relation graphs. This model combines entities in the KG into new nodes, and treats relations as features of the new nodes, thereby creating a graph with only a single relation. A denoising autoencoder is then trained on the new graph for link prediction, and a GNN interpreter is used to generate subgraph explanations. Experiments on three benchmark datasets show that the proposed model based on uni-relation graph transformation significantly enhances the relative AUC, as compared to GraIL without transformation. Finally, an explanation subgraph extraction experiment is performed on the FB15K-237 dataset, demonstrating the effectiveness of the model in directly extracting link predictions for explanation. © 2023 SPIE.",TextMining
"Pumping stations and sluice stations in polder areas generally undertake many tasks such as flood control and drainage in polder areas. The topography and topography of polder areas are flat and low-lying, and most of them are located in areas with dense river networks, so water resources are abundant. During the flood period, the water level of the river outside the polder area is often higher than that of the fields, which is more prone to natural disasters such as floods. Due to the aging equipment, many pump gates are poorly managed, which makes the operation and maintenance of pump gates difficult. Therefore, based on the feature extraction algorithm, this paper establishes a gate pump MIS (Management Information System) to monitor the hydrology and water resources of the river. The construction of gate pump MIS is based on database design and information retrieval algorithm, combined with information feature extraction and optimized information scheduling technology. The feature extraction algorithm is used to adaptively fuse and cluster the semantic correlation features of distributed data in large-scale MIS, and the feature compressor is used to reduce the dimension of the storage space of large-scale MIS, which improves the target data mining ability and the adaptive scheduling ability of gate pump MIS. © 2023 IEEE.",TextMining
"A poultry farm company has customers across various regions and needs customer segmentation for a more effective marketing strategy. This research aims to perform the company customer segmentation through a comparative analysis using K-Means and K-Medoids algorithms. Customer segmentation was performed using the Cross-Industry Standard Process for Data Mining (CRISP-DM) technique on three distinct sales datasets. We selected the attributes of the datasets based on the Recency-Frequency-Monetary (RFM) model. The number of clusters was established utilizing the Elbow approach, and the assessment of clustering was carried out using the Davies-Bouldin Index (DBI) methodology. Through a comparative examination, it becomes evident that the superiority of the K-Means algorithm is demonstrated in comparison to the K-Medoids algorithm. This outcome is derived from the observation that the DBI value for K-Means is lower than the DBI value for K-Medoids across the three sales datasets. Based on these results, it is recommended to determine customer segmentation using the K-Means algorithm. We obtained four customer segments: superstar, typical, newcomer, and dormant. The superstar segment has the most recent recency value, the highest frequency, and the most significant monetary value. The results of this customer segmentation became a consideration for the company in making marketing strategies that are right on target. This study can be used as a reference for current issue in the poultry farm company for supporting and preparing food, supports current issue in the sustainable development goals (SDGs). © School of Engineering, Taylor’s University.",TextMining
"Logistics is a new industry in China, and its initial development is particularly important. Therefore, doing a good job in logistics forecasting plays a vital role in the development prospect of the whole logistics industry. Because of the complex working conditions of vehicle freight in logistics and distribution, especially in urban distribution, there are not only many freight points, various kinds of goods and complex road network, but also uneven distribution of transportation outlets in transportation service areas. Based on this, this paper puts forward a logistics forecasting algorithm based on neural network optimization genetic algorithm (GA), thus constructing the decision model of logistics intelligent distribution system. The simulation results show that the logistics forecasting algorithm in this paper has small errors and high accuracy, which can reach 96.45%. From the results, it can be seen that neural network optimization GA is feasible in this kind of problems, and has great development potential in scheduling optimization, decision support and so on. The data mining model combining neural network with GA can make the whole logistics network layout and facility location predictable and adaptive for the future. © 2023 IEEE.",TextMining
"The Tashtagolsky iron ore deposit was furnished with the GITS seismic monitoring system developed by VNIMI JSC early in 2022. The system includes underground seismic pavilions equipped with three-component DRC-11 accelerometer sensors, as well as the day-light surface part with a recording unit and a computer for signal processing. Control of the system, adjustment of the registration parameters and data processing is made via remote Internet connection. At present the system is mainly used to locate focal point of seismic events and to plot zones of seismic activity and rock-bump hazards. Seismic events are recorded in the computer memory when the vibration amplitude exceeds the threshold levels on several sensors. The recorded events are processed by the operator, their coordinates and energy are calculated and noise is removed. As the result, a registry is generated that includes the exact time, coordinates and energy of each recorded event. Data from such registries makes it possible to plot changes in the main parameters of seismic activity, identify spatial zones of seismic events concentration and their location in relation to areas of mining operations. The rock-bump hazards is controlled based on observations of formation and migration of the seismic activity zones.Сontinuous readings of each seismic sensor during the background vibrations, which reflect the state of the rock mass hic et nunc, could be a further development of seismic monitoring systems in deep ore and mineral mines in addition to the existing monitoring methods. The authors propose a method to process long continuous records (staring from one day or longer) of the seismic noise, during which it is not the signal itself that is analyzed, but its spectral characteristics, and the objective is to detect changes in the spectral composition just before a strong seismic event is registered. © 2023, Scientific and Industrial company 'Gemos Ltd.'. All rights reserved.",TextMining
"Unstructured data constitutes a sizable portion of every organization. When left unattended, it becomes dark redundant data with associated storage costs. This paper introduces a novel approach to information extraction for data management in the oil and gas industry. The data management system (DMS) is a web application that seamlessly integrates structured and unstructured data at the back end, providing actionable insights to users on the front-end. The DMS offers intuitive and interactive features tailored for diverse use cases, including operations planning, sales planning, tender planning, and competition-market share analysis. The approach consists of two key components: automated extraction and enrichment pipelines, and workflows based on natural language processing (NLP) and machine learning (ML). The automated pipelines efficiently extract, ingest, enrich, and quality-check data from multiple sources. Meanwhile, the NLP workflows focus on unstructured textual data and perform tasks such as named entity recognition (NER), relation extraction, and operation classification to extract relevant information. State-of-the-art language models, such as bidirectional encoder representations from transformers (BERT), are employed to contextualize operational comments and assign labels to the operations. To evaluate the effectiveness and benefits of the DMS application in addressing various operational challenges, a series of experiments and surveys were conducted, comparing it with existing tools and methods. The results demonstrate that the DMS effectively delivers accurate and relevant information in a user-friendly manner. The key advantage of the DMS lies in its ability to bridge silos between different business lines, enabling stakeholders and users to monitor and analyze data from diverse sources, such as daily drilling reports (DDRs), daily workover reports (DWRs), production, testing, and rigless data. © 2023, Society of Petroleum Engineers.",TextMining